DISTRIBUTED OPERATING SYSTEMSIEEEPress
445 Hoes Lane,P.O. Box 1331
Piscataway, NJ 08855-1331
EditorialBoard
John B. Anderson, Editorin Chief'
P.M.Anderson A.H.Haddad P.Laplante
M.Eden R. Herrick R. S. Muller
M.E.El-Hawary G. F. Hoffnagle W. D. Reeve
S. Furui R. F.Hoyt D. J.Wells
S. Kartalopoulos
Dudley R. Kay, DirectorofBook Publishing
John Griffin, SeniorEditor
LisaDayne,Assistant Editor
LindaMatarazzo, Editorial Assistant
Denise Phillip, Associate Production Editor
IEEE CommunicationsSociety, Sponsor
Tom Robertazzi, C-S Liaison to IEEE Press
Technical Reviewers
Dr.Walter Kohler, DigitalEquipment Corporation
Mr. Harold Lorin, The Manticore Consultancy
Ms.Celine Vaolt
Dr.Wayne Wolf,Princeton University
Also from IEEEPress
Computer Communications andNetworks, SecondEdition
John Freer
Copublished with VeLPress
1996 Hardcover 400ppIEEEOrder No, PC5654 ISBN 0-7803-1179-5
Engineering Networks forSynchronization, CCS7andISDN:Standards, Protocols,
Planning, andTesting
P.K. Bhatnagar
1997 Hardcover 528ppIEEEOrder No. PC5628 ISBN 0-7803-1158-2
SONET-SDH: ASourcebook ofSynchronous Networking
editedbyCurtis A.Siller, Jr. and Mansoor Shafi
1996 Hardcover 406pp IEEEOrder No. PC4457 ISBN0-7803-1168-XDISTRIBUTED OPERATING SYSTEMS
Concepts andDesign
PradeepK. Sinha
CentreforDevelopment ofAdvanced Computing
~IEEECOMPUTER~SOCIETY PRESS®
+.IEEE
PRESS®
IEEECommunications Society,Sponsor
The Institute of Electrical and Electronics Engineers, Inc., New YorkANOmTOrasREADER
Thisbookhasbeenelectronically reproduced from
digitalinformation storedatJohn Wiley&Sons,Inc.
Wearepleasedthattheuse oftbisnewtechnology
willenableustokeepworksofenduring scholarly
valueinprintaslongasthereisa reasonable demand
forthem. Thecontentofthisbookis identicalto
previousprintings.
This book maybepurchased atadiscount from the publisher
whenorderedin bulkquantities. Contact:
IEEE Press Marketing
Attn:SpecialSales
445HoesLane, ~O.Box 1331
Piscataway, NJ08855-1331
Fax:(732)981-9334
Formoreinformation on theIEEEPress, visit the IEEE home page:
http://www.ieee.org/
©1997 by theInstituteofElectrical andElectronics Engineers, Inc.,
3ParkAvenue, 17thFloor,NewYork,NY10016-5997
Allrights reserved. No partofthisbookmay bereproduced inanyform,
nor may itbestoredin aretrieval systemortransmitted inany form,
without written permission from the publisher.
Printed in the United States of America
109876543
ISBN0-7803-1119-1
IEEEOrderNumber: PC470S
Libraryof Congress Cataloging-in-Publication Data
Sinha, Pradeep K. (Pradeep Kumar)
Distributed operating systemslPradeep K. Sinha.
p.em.
Includes bibliographical references and index.
ISBN0-7803-1119-1 (cloth)
I.Distributed operating systems(Computers) I.Title.
QA76.76.063S568 1996 96..26565
005.4'4--dc20 CIPContents
Pr.face xi
Acknowledgments xv
Abbreviations QndAcronyms xvii
Chapter 1: Fundamentals 1
1.1 What Is a Distributed Computing System?
1.2Evolution ofDistributed Computing Systems 3
1.3Distributed Computing System Models 5
1.4 Why Are Distributed Computing Systems GainingPopularity? 12
1.5 What Is a Distributed Operating System? 16
1.6 Issues in Designing aDistributed Operating System 19
1.7Introduction toDistributed Computing Environment (DCE) 34
1.8Summary 38
Exercises 39
Bibliography 41
Pointers to Bibliographies on the Internet 44
vvi
ChapterI:Computar Networks 46
2.1 Introduction 46
2.2 Networks Types 47
2.3 LAN Technologies 48
2.4WANTechnologies 59
2.5Communication Protocols 64
2.6Intemetworking 83
2.7 ATMTechnology 91
2.8 Summary 104
Exercises 105
Bibliography 108
Pointers to Bibliographies on the Internet 112
Chapter3: Messag_ Passing 114
3.1 Introduction 114
3.2 Desirable Features of a Good Message-Passing System 1153.3 Isses in IPC
byMessage Passing 118
3.4Synchronization 120
3.5 Buffering 122
3.6 Multidatagram Messages 125
3.7 Encoding and Decoding of Message Data 126
3.8 Process Addressing 127
3.9 Failure Handling 130
3.10 Group Communication 139
3.11 Case Study: 4.38SDUNIX IPC Mechanism 153
3.12 Summary 157
Exercises 160
Bibliography 163
Pointers to Bibliographies on the Internet 166
Chapter4: Remota Procedure Calls 167
4.1 Introduction 167
4.2 The RPCModel 168
4.3 Transparency of RPC 170
4.4 Implementing RPCMechanism 171
4.5 Stub Generation 174
4.6 RPC Messages 174
4.7 Marshaling Arguments and Results 177
4.8 Server Management 178
4.9 Parameter-Passing Semantics 183ContentsContents vii
4.10CallSemantics 184
4.11Communication Protocols forRPCs
4.12Complicated RPCs 191
4.13Client-Server Binding 193
4.14Exception Handling 198
4.15Security 198
4.16SomeSpecialTypesofRPCs 199
4.17 RPC inHeterogeneous Environments
4.18Lightweight RPC 204
4.19Optimizations forBetterPerformance
4.20CaseStudies: Sun RPC, r)CI~RPC
4.21Summary 222
Exercises 224
Bibliography 227
Pointers toBibliographies on theInternet187
203
208
212
230
Chapter5:Distributed SharedMemory 231
233
234
237
281266
267
2705.1Introduction 231
5.2General Architecture ofI)SMSysterns
5.3DesignandImplementation Issuesof DSM
5.4Granularity 235
5.5Structure ofSharedMemory Space
5.6Consistency Models 238
5.7Replacement Strategy 262
5.8Thrashing 264
5.9OtherApproaches toDSM
5.10Heterogeneous DSM
5.11Advantages ofDSM
5.12Summary 272
Exercises 274
Bibliography 275
Pointers toBibliographies on theInternet
Chapter6:Synchronization 282
6.1Introduction 282
6.2ClockSynchronization 283
6.3EventOrdering 292
6.4MutualExclusion 299
6.5Deadlock 305
6.6EJection Algorithms 332
6.7Summary 336viii
Exercises 337
Bibliography 341
Pointers toBibliographies on theInternet 345Contents
Chapter7: "-source MQnQgcament 347
7.1Introduction 347
7.2Desirable Features of aGoodGlobalScheduling Algorithm 348
7.3 Task Assignment Approach 351
7.4Load-Balancing Approach 355
7.5Load-Sharing Approach 367
7.6Summary 371
Exercises 372
Bibliography 374
Pointers toBibliographies on theInternet 380
Chapter8:ProcessManagement 381
8.1Introduction 381
8.2ProcessMigration 382
8.3Threads 398
8.4Summary 414
Exercises 415
Bibliography 418
Pointers toBibliographies on theInternet 420
Chapter9:Distributed FileSystems 421
9.1Introduction 421
9.2Desirable Features of aGoodDistributed File System 423
9.3 File Models 426
9.4File-Accessing Models 427
9.5File-Sharing Semantics 430
9.6File-Caching Schemes 433
9.7FileReplication 440
9.8FaultTolerance 447
9.9AtomicTransactions 453
9.10DesignPrinciples 474
9.11CaseStudy:DeEDistributed FileService 475
9.12Summary 484
Exercises 486
Bibliography 489
Pointers toBibliographies on theInternet 495Contents
Chapter10:Naming 496ix
10.1Introduction 496
10.2Desirable Features of a Good NamingSystem
10.3Fundamental Terminologies andConcepts
10.4System-Oriented Names 509
10.5Object-Locating Mechanisms 512
10.6Human-Oriented Names 515
10.7 Name Caches 541
10.8Naming andSecurity 544
10.9 Case Study: DCE Directory Service 546
10.10Summary 556
Exercises 558
Bibliography 560
Pointers toBibliographies on theInternet 564
Chapter11:Security 565497
499
11.1Introduction 565
11.2Potential AttackstoComputer Systems 567
11.3Cryptography 575
11.4Authentication 586
11.5 Access Control 607
11.6DigitalSignatures 623
11.7 Design Principles 626
11.8 Case Study: DeESecurity Service 627
11.9Summary 630
Exercises 631
Bibliography 634
Pointers toBibliographies onthe Internet 640
Chapter12:CaseStudies 642
12.1Introduction 642
12.2Amoeba 643
12.3V-System 659
12.4 Mach 674
12.5Chorus 696
12.6 A Comparison of Amoeba, V-System, Mach, and Chorus 714
12.7Summary 718
Exercises 722
Bibliography 725
Pointers toBibliographies on theInternet 730
Index 731Preface
Motivation
Theexcellent price/performance ratio offered by microprocessor-based workstations over
traditional mainframe systems and the steady improvements innetworking technologies
have made distributed computing systems very attractive. While the hardware issues of
building such systems have been fairly well understood for quite some time, the major
stumbling block until now has been the availability of gooddistributed operating systems.
Fortunately, recent researchanddevelopment work in academic institutions andindustries
have helped us betterunderstand the basic concepts and design issues in developing
distributed operating systems. Distributed operating systems are no more only in research
laboratories but are now commercially available.
With the proliferation ofdistributed computing systems, it has become increasingly
important forcomputer science and computer engineering students to learn about
distributed operating systems. As a result, a numberofuniversities haveinstituted regular
courses on distributed operating systems at the graduate level. Even in various
undergraduate-level operating systems courses, the fundamental concepts and design
principles ofdistributed operating systems have been incorporated.
However, there is still a lack of good textbooks that can provide a comprehensive and
solidintroduction todistributed operating systems in an orderly manner. Exceptfor a few
xixii Preface
recently published books,almostallbooksin this area are research monographs.
Therefore, for both an educator and astudent, thecreation ofanoverallimageof
distributed operating systems iscurrently acomplicated andtime-consuming task.
Furthermore, computer professionals andstartingresearchers who want to get an overall
pictureofdistributed operating systemsso as toidentifythevariousresearch anddesign
issueshavedifficulty infindinga good text for theirpurpose.
Motivated by these factors, I decided to doresearch towardthepreparation of a
textbook ondistributed operating systems. Myprimaryobjective was toconcisely present
aclearexplanation ofthecurrentstateofthe art in distributed operating systemsso that
readerscan gain sufficient background toappreciate moreadvanced materials ofthis
field.
The book is designed toprovideacleardescription of thefundamental concepts and
designprinciples thatunderlie distributed operating systems. It does not concentrate on
anyparticular distributed operating systemorhardware. Instead, it discusses, in ageneral
setting,thefundamental concepts anddesignprinciples that areapplicable to avarietyof
distributed operating systems. However, casestudiesareincluded in the text to relate the
discussed concepts with real distributed operating systems.
Thematerial in the book has been drawnlargelyfrom the research literature in the
field.Ofthe vastamountofresearch literature available in this field, effortwas made to
selectand give more emphasis to thoseconcepts that are of practical value in real systems,
ratherthan those that are only oftheoretical interest.
Eachchaptercontains carefully designed exercises that are meant to test the
understanding of thematerials in the text and to stimulate investigation.
Anextensive setofreferences and a list ofselectedpointerstoon-linebibliographies
on theInternethavebeenprovided at the end ofeachchapterto allow interested readers
toexplore moreadvanced materials dealingwith finer detailsabouteachchapter's
topics.
Throughout the book, the style ofpresentation used ismotivational andexplanatory
innature.
Chapter1provides anintroduction todistributed computing systems, distributed operating
systems, and the issues involved indesigning distributed operating systems. It also
provides abriefintroduction toDistributed Computing Environment (DCE),whose
components aredescribed as casestudiesofkeytechnologies inseveralchapters ofthe
book.
Chapter 2presents abriefintroduction tocomputer networks anddescribes the
currentstateofthe art in networking technology.Preface xiii
Chapters 3, 4, and 5 describe the various communication techniques used for
exchange of information among the processes of adistributed computing system. In
particular, these three chapters deal with the issues involved in the design ofinterprocess
communication mechanisms and thecommonly usedpractical approaches to handle these
issues. Chapter 3 deals with the message-passing mechanism. Chapter4 deals with the
remote procedure call mechanism, andChapter5deals with the distributed shared­
memory mechanism for interprocess communication.
Synchronization issues to be dealt with in a distributed system, such as clock
synchronization, mutualexclusion, deadlock, andelectionalgorithms, are discussed in
Chapter6.
Chapter 7 presents adiscussion of thecommonly usedapproaches for resource
management indistributed systems.
Chapter 8 deals with the process management issues. In particular, it presents a
discussion of process migration mechanisms andmechanisms to support threads
facility.
Adiscussion of the issues and the approaches fordesigning a file system for a
distributed system is given in Chapter9.
Chapter 10deals with the issues and mechanisms for naming and locating objects in
distributed systems.
The security issues and security mechanisms fordistributed systems are discussed in
Chapter11.
Finally,Chapter 12contains case studies of four existing distributed operating
systems to relate the concepts discussed in thepreceding chapters with real distributed
operating systems.
Audience
The book is suitable for anyone who needs a concise and informal introduction to
distributed operating systems.
It can serve as an ideal textbook for a course on distributed operating systems. It can
also be used for advanced undergraduate andpostgraduate courseson operating systems,
which often need to cover the fundamental concepts and design issues of distributed
operating systems in addition to those of centralized operating systems.
The book can also be used as a self-study text by system managers, professional
software engineers, computer scientists, and researchers, whoeitherneed to learn about
distributed operating systems or are involved in the design and development ofdistributed
operating systems or distributed application systems.
Advanced researchers will also find the rich set ofreferences and the pointers to on­
linebibliographies on the Internet provided at the end of each chaptervery helpful in
probing further on any particular topic.
Although full care has been taken to make the subject matter simple and easy to
understand bya wide range of readers, I have assumed that the reader has a knowledge
ofelementary computer architecture and is familar with basic centralized operating
systems concepts discussed instandard operating systems textbooks.xiv
AboutPointerstoBibliographies ontheInternetPreface
In addition to a good number of references provided in theend-of-chapter bibliographies,
I have also provided lists of selected pointers to the on-line bibliographies ofinterest on
the Internet. The purpose of these pointers is twofold:
1. Theend-of-chapter bibliographies containonly selected references. A large number of
references on the topics covered in a chapterare not included in the chapter's
bibliography due to space limitations. The pointers may be used by interested readers
to locate such references.
2. Theend-of-chapter bibliographies contain references to only already published
documents. Distributed operating systems is currently an active area of research, and
a large volume of new documents are published almost every month. Since the on-line
bibliographies on the Internet are updated from time to time, interested readers may use
the pointers to locate those documents that are published after the publication of this
book. Thus, in addition to the information contained in it, the book also provides a way
for its readers to keep track of on-going research activities on the topics covered and
related topics.
Note that the end-of-chapter lists of pointers to on-line bibliographies are by no
means exhaustive. I have provided pointers for only those on-line bibliographies that I
knew about and I felt would be useful in easily locating references ofinterest. Moreover,
it is often the case that there are many mirrors for an on-line bibliography (the same
bilbiography exists on multiple sites). For such cases, Ihave provided only one pointer for
a bibliography.
Also note that most of theon-line bibliographies are not about on-line documents, but
about on-line references todocuments. A vast majority of documents referenced in the on­
linebibliographies only exist in hard-copy form. However, a few of the referenced
documents do have an on-line version on the Internet. For such documents, the
bibliographies normally contain URLs (Uniform Resource Locators) pointing to the on­
line version ofthe document. If you find a reference containing such a URL, justfollow
theURLto access the on-line version of the corresponding document.Acknowledgments
Many people have contributed to this book, either directly or indirectly. To start with, I
must thank all the researchers who have contributed to the fields of distributed computing
systems and distributed operating systems because the book is based on their research
results.
Mamoru Maekawa, my Ph.D. supervisor, provided me with the opportunity to do
research in the area of distributed operating systems. Without this opportunity, this book
would not have been possible.
Livelydiscussions with the members of the Galaxy distributed operating system
project, including Kentaro Shimizu, Xiaohua Jia, Hyo Ashishara, Naoki Utsunomiya,
Hirohiko Nakano, Kyu Sung Park, and Jun Hamano, helped a lot in broadening my
knowledge of distributed operating systems.
Without the efforts of all the people who collected references and made them
available on the Internet, it would not have been possible for me to provide the end-of­
chapterpointers to the bibliographies on the Internet.
Several anonymous reviewers of mydraftmanuscript provided invaluable feedback
concerning organization, topic coverage, t.ypographical errors, and parts of the text that
were not as clear as they are now.
Myproduction editor at IEEE Press, Denise Phillip, did an excellent job in numerous
ways to present the book in its current form. IEEE Press Director DudleyKay,Senior
xvxvi Acknowledgements
Acquisitions Editor John Griffin, and review coordinators Lisa Mizrahi and Lisa Dayne
wereofgreat help in improving the overall quality ofthe book and in bringing it out in
a timely manner.
Finally, I thank my wife, Priti, for preparing theelectronic version of theentirehand­
written draft manuscript. I also thank her for her continuous patienceand sacrificesduring
the entire period ofthis long project. Without her loving supportand understanding, I
would never have succeeded incompleting this project.
PradeepK. SinhaAbbreviations Qnd
Acronyms
AAL ATM Adaptation Layer CDS CellDirectory Service/Server
ACL Access Control List CERN European CentreforNuclear
AFS AndrewFile System Research
ANSI American National Standards CFS Cedar File System
Institute CICS Customer Information Control
API Application Programming System
Interface CLP Cell Loss Priority
APPN Advanced Peer-to-Peer eMH Chandy-Misra-Hass
Networking CMIP Common Management
ARP Address Resolution Protocol Information Protocol
ARPANET Advanced Research Projects COOL ChorusObject-Oriented Layer
AgencyNETwork CSMAlCD CarrierSense Multiple Access
ASN.I Abstract Syntax Notation withCollision Detection
ATM Asynchronous Transfer Mode CSRG Computer Systems Research
BIOS BasicInputOutput System Group
B-ISDN Broadband Integrated Services DCE Distributed Computing
DigitalNetwork Environment
CBR Constant Bit Rate DDLeN Distributed Double-Loop
CCITT International Telegraph and Computer Network
Telephone Consultative DEC DigitalEquipment Corporation
Committee DES DataEncryption Standard
xviixviii Abbreviations andAcronyms
DFS Distributed FileService IP InternetProtocol
DI DirectoryIdentifier IPC Inter-Process Communication
DIB DirectoryInformation Base ISDN IntegratedServices Digital
OIT DirectoryInformation Tree Network
DME Distributed Management ISO International Standards
Environment Organization
ON Distinguished Name lTV International
ONS DomainNamelNaming Telecommunications Union
Service/System KDBMS Kerberos Database Management
DoD Department of Defense Server
DSM Distributed SharedMemory KDC KeyDistributionCenter
DSVM Distributed SharedVirtual LAN LocalArea Network
Memory LEC LANEmulationClient
DTS Distributed TimeService LES LAN EmulationServer
Email Electronic Mail LRPC Lightweight RemoteProcedure
ERB Expanding RingBroadcast Call
FOOl FiberDistributed Data MAN Metropolitan AreaNetwork
Interface MBone MulticastBackbone
FIFO First-InFirst-Out Mbps Megabitsper second
FLIP Fast LocalInternetProtocol MIG MachInterfaceGenerator
FTP FileTransferProtocol MMU MemoryManagementUnit
Gbps Gigabitsper second MTBF MeanTimeBetween Failures
GDA GlobalDirectory Agent MTU Maximum Transfer Unit
GDS GlobalDirectory Service/Server NCA NetworkComputing
GEOS Geostationary Operational Architecture
Environmental Satellites NCS NetworkComputing System
GFC GenericFlowControl NFS NetworkFile System
GNS GlobalNameService NIC NetworkInformation Center
GNU Gnu's NotUnix NIST NationalInstitutefor Standards
GPS GlobalPositioning System andTechnology
HEe HeaderErrorControl NRMB Non-Replicated Migrating
HRPC Heterogeneous Remote Block
Procedure Call NRNMB Non-Replicated Non-Migrating
IBM International BusinessMachines Block
ICMP InternetControlMessage NSAP NetworkServiceAccess Point
Protocol NTP NetworkTime Protocol
IOL InterfaceDefinition Language NVMA Non-Uniform MemoryAccess
IEEE InstituteofElectrical and OC-n OpticalCarrierlevel n
Electronics Engineers OLTP On LineTransaction
IETF InternetEngineering TaskForce Processing
IMS Information Management OPC OutputPortController
System OSF OpenSoftware Foundation
INRIA InstituteNationalde Recherche OSI OpenSystem International
enInformatique et PCB ProcessControlBlock
Automatique PEM PrivacyEnhancedMailAbbreviations andAcronyms xix
PKM Public Key Manager STS-n Synchronous Transport Signal
PMD Physical Medium Dependent leveln
POSIX Portable Operating System TC Transmission Convergence
Interface for Computer TCF Transparent Computing Facility
Environments TCP Transport Control Protocol
PRAM Pipelined Random Access TFTP Trivial File Transfer Protocol
Memory TI-RPC Transport Independent-Remote
PSE Packet Switching Exchange Procedure Call
PTI PayloadType Identifier TP Transport Protocol
RARP Reverse Address Resolution TWFG Transaction Wait-For-Graph
Protocol VCP Unilateral Commit Protocol
RON Relative Distinguished Name UDP User Datagram Protocol
RFS Remote File Server UDS Universal Directory Service
RFT Request For Technology UNI User Network Interface
RMB Replicated Migrating Block UTC Coordinated UniversalTime
RNMB Replicated Non-Migrating VUID Universally Unique Identifier
Block VBR VariableBit Rate
RPC Remote Procedure Call vel VirtualChannel Identifier
RPCL Remote Procedure Call VM VirtualMemory
Language VMTP Versatile MessageTransfer
RR Round-Robin Protocol
RSA Rivest-Shamir-Adleman VPI VirtualPath Identifier
RSS Research Storage System WAIS WideArea InformationServers
SDH Synchronous Digital Hierarchy WAN WideArea Network
SEAL Simple and EfficientAdaptation WFG WaitFor Graph
Layer WWW \\lorld WideWeb
SLIP Serial Line Internet Protocol X-IPe eXtcnted Inter-Process
SMTP Simple Mail Transfer Protocol Communication
SNA System Network Architecture XDR eXternal Data Representation
SNMP Simple Network Management XDS X/Open DirectoryServer
Protocol XNS Xerox Networking System
SONET Synchronous Optical NETwork XOM X/Open Object ManagementCHAPTER1
Fundamentals
1.1WHATISADISTRIBUTED COMPUTING SYSTEM?
Over the past two decades, advancements in microelectronic technology have resulted in
the availability of fast, inexpensive processors, and advancements in communication
technology have resulted in the availability of cost-effective and highly efficient computer
networks.The net result of the advancements in these two technologies is that the price­
performance ratio has nowchanged to favor the useof interconnected, multiple processors
in place of a single, high-speed processor.
Computer architectures consisting of interconnected, multiple processors are
basically of two types:
I.Tightly coupled systems. In these systems, there is a single systemwide primary
memory (address space) that is shared by all the processors [Fig. l.1(a)]. If anyprocessor
writes, for example, the value 100 to the memory location x,any other processor
subsequently reading from location xwill get the value 100. Therefore, in these systems,
anycommunication between the processors usually takes place through the shared
memory.
2. Loosely coupled systems. In these systems, the processors do not share memory,
and each processor has itsown local memory [Fig. l.1(b)].Ifa processor writes the value
12 Chap.1 •Fundamentals
CPU CPUSystemwideCPU CPUsharedmemory
Interconnection hardware I
(a)
Localmemory Localmemory Localmemory Localmemory
CPU CPU CPU CPU
Communication network
(b)
Fig_1.1 Difference between tightly coupled and loosely coupled multiprocessor
systems: (a)a tightly coupled multiprocessor system; (b)a loosely coupled
multiprocessor system.
100 to the memory location x, this write operation will only change the contents of its
local memory and will not affect the contents of the memory ofany other processor.
Hence,ifanother processor reads the memory location x, it will get whatever value was
there before in that location of its own local memory. In these systems, all physical
communication between the processors is done by passing messages across the network
that interconnects the processors.
Usually, tightly coupled systems are referred to as parallel processing systems, and
loosely coupled systems are referred to as distributed computing systems, or simply
distributed systems. Inthis book, however, the term "distributed system"will be used only
for truedistributed systems-distributed computing systems that use distributed operating
systems (see Section 1.5).Therefore, before the term "true distributed system" is defined
in Section 1.5, the term "distributed computing system" will beused to refer to loosely
coupled systems. In contrast to the tightly coupled systems, the processors of distributed
computing systems can be located far from each other to cover a wider geographical area.
Furthermore, in tightly coupled systems, the number of processors that can be usefully
deployed is usually small and limited bythe bandwidth of the shared memory. This is not
thecase with distributed computing systems that are more freely expandable and can have
an almost unlimited number of processors.Sec. 1.2 • Evolution ofDistributed Computing Systems 3
Inshort,adistributed computing systemisbasically acollection ofprocessors
interconnected by acommunication networkinwhicheachprocessor has its ownlocal
memoryandother peripherals, andthecommunication betweenanytwoprocessors ofthe
system takes place by message passing over the communication network. For a particular
processor, its own resources are local,whereas the other processors and their resources are
remote.Together, a processor and its resources are usually referred to as a nodeorsiteor
machine of thedistributed computing system.
1.2EVOLUTION OFDISTRIBUTED COMPUTING SYSTEMS
Earlycomputers were very expensive (they cost millions of dollars) and very large in size
(theyoccupied a big room). There were very few computers and were available only in
research laboratories of universities and industries. These computers were run from a
console by an operatorand were not accessible to ordinary users. The programmers would
write their programs and submit them to the computer center on some media, such as
punched cards, for processing. Before processing a job, the operator would set up the
necessary environment (mounting tapes, loading punched cards in a card reader, etc.) for
processing thejob. Thejob was then executed and the result, in the form of printed output,
was later returned to the programmer.
The job setup time was a real problem in early computers and wasted most ofthe
valuable central processing unit (CPU) time. Several new concepts were introduced in the
1950sand 1960s to increase CPU utilization of these computers. Notable among these are
batching together of jobs with similar needs before processing them, automatic
sequencing of jobs, off-line processing by using the concepts of buffering and spooling,
and"multiprogramming. Batching similar jobs improved CPU utilization quite a bit
because now the operatorhad tochange theexecution environment only when anew batch
ofjobshad to be executed and not before starting the execution of every job. Automatic
jobsequencing with the use of control cards to define the beginning and end of a job
improved CPU utilization by eliminating the need for human job sequencing. Off-line
processing improved CPU utilization by allowing overlap of CPU and input/output (I/O)
operations byexecuting those two actions on two independent machines (110devices are
normally several orders of magnitude slower than the CPU). Finally, multiprogramming
improved CPU utilization by organizing jobs so that the CPU always had something to
execute.
However, none of these ideas allowed multiple users to directly interact with a
computer system and to share its resources simultaneously. Therefore, execution of
interactive jobsthat arecomposed of many short actions in which the next action depends
on the result of a previous action was atedious and time-consuming activity.Development
anddebugging ofprograms are examples of interactive jobs. It was not until the early
1970s that computers started to use the concept of time sharing to overcome this hurdle.
Earlytime-sharing systems had several dumb terminals attached to the main computer.
These terminals were placed in a room different from the main computer room. Using
these terminals, multiple users could now simultaneously execute interactive jobsand
share the resources of the computer system. In a time-sharing system, each user is given4 Chap.1 •Fundamentals
the impression that he or she has his or her own computer because the system switches
rapidly from one user'sjob to the next user'sjob, executing only a very small part of each
jobat a time. Although the idea of time sharing was demonstrated as early as 1960, time­
sharingcomputer systems were not common until the early 1970s because they were
difficultand expensive to build.
Parallel advancements in hardware technology allowed reduction in the size and
increase in the processing speed of computers, causing large-sized computers to be
gradually replaced by smaller and cheaper ones that had more processing capability than
their predecessors. These systems were called minicomputers.
The advent of time-sharing systems was the first step toward distributed computing
systems because itprovided us with two important concepts usedindistributed computing
systems-the sharing of computer resources simultaneously by many users and the
accessing of computers from a place different from the main computer room. Initially, the
terminals of a time-sharing system were dumb terminals, and all processing was done by
the main computer system. Advancements in microprocessor technology in the 1970s
allowed the dumb terminals to bereplaced by intelligent terminals so that the concepts of
off-line processing and time sharing could becombined to have the advantages of both
concepts in a single system. Microprocessor technology continued to advance rapidly,
making available in the early 1980s single-user computers called workstations that had
computing power almost equal to that of minicomputers but were available for only a
small fraction of theprice of aminicomputer. For example, thefirst workstation developed
at Xerox PARC (called Alto) had a high-resolution monochrome display, a mouse, 128
kilobytes of main memory, a 2.5-megabyte hard disk, and a microprogrammed CPU that
executed machine-level instructions at speeds of 2-6f.Ls.These workstations were then
used as terminals in the time-sharing systems. In these time-sharing systems, most of the
processing of a user'sjob could be done at the user'sown computer, allowing the main
computer to be simultaneously shared by a larger number of users. Shared resources such
as files, databases, and software libraries were placed on the main computer.
Centralized time-sharing systems described above had a limitation in that the
terminals could not beplaced very far from the maincomputer room since ordinary cables
were used to connect the terminals to the main computer. However, in parallel, there were
advancements incomputer networking technology in the late 1960s and early 1970s that
emerged as twokey networking technologies-LAN (local area network) andWAN(wide­
areanetwork). The LAN technology allowed several computers located within a building
or a campus to be interconnected in such a way that these machines could exchange
information with each other at data rates of about 10megabits per second (Mbps). On the
other hand, WAN technology allowed computers located far from each other (may be in
different cities or countries or continents) to be interconnected in such a way that these
machines could exchange information witheach other atdata rates of about 56kilobits per
second (Kbps). The first high-speed LAN was the Ethernet developed at Xerox PARein
1973, and the first WAN was the ARPAnet (Advanced Research Projects Agency
Network) developed by the U.S. Department of Defense in 1969. The data rates of
networks continued to improve gradually in the 1980s, providing data rates of up to 100
Mbps for LANs and data rates of up to 64 Kbps for WANs.Recently (early 1990s) there
has been another major advancement in networking technology-the ATM(asynchronousSec.1.3 • Distributed Computing SystemModels 5
transfer mode) technology. The Al'Mtechnology is anemerging technology that is still
not very well established. It will make very high speed networking possible, providing
datatransmission rates up to 1.2gigabitspersecond (Gbps) in both LANandWAN
environments. Theavailability of such high-bandwidth networks will allow future
distributed computing systems to support a completely new class of distributed
applications, calledmultimedia applications, that deal with the handling of a mixture of
information, including voice, video, and ordinary data. Theseapplications werepreviously
unthinkable withconventional LANs and WANs.
The merging of computer andnetworking technologies gave birth to distributed
computing systems in the late 1970s. Although the hardware issues of building such
systems were fairly well understood, the major stumbling block at that time was the
availability ofadequate software for making these systems easy to use and for fully
exploiting their power. Therefore, starting from the late 1970s, a significant amountof
research work was carriedout in both universities andindustries in the area ofdistributed
operating systems. Theseresearch activities have provided us with the basic ideas of
designing distributed operating systems.Although the field is still immature, with ongoing
activeresearch activities, commercial distributed operating systems have already started
to emerge. These systemsare based on already established basic concepts. This book deals
with these basic concepts and their use in the design and implementation ofdistributed
operating systems. Several of these concepts areequallyapplicable to the design of
applications fordistributed computing systems, making this book also suitable for use by
thedesigners ofdistributed applications.
1.3DISTRI8UTED COMPUTING SYSTEMMODELS
Variousmodels are used for building distributed computing systems. These models can be
broadlyclassified into five categories-minicomputer, workstation, workstation-server,
processor-pool, and hybrid. They are briefly described below.
1.3.1Minicomputer Model
Theminicomputer modelis a simple extension of thecentralized time-sharing system. As
shown in Figure 1.2,a distributed computing system based on this model consistsof a few
minicomputers (they may be large supercomputers as well) interconnected by a
communication network. Each minicomputer usually has multiple users simultaneously
logged on to it. For this, several interactive terminals areconnected to eachminicomputer.
Each user is loggedon to one specific minicomputer, with remote access to other
minicomputers. The network allows a user to access remote resources that are available on
some machine other than the one on to which the user is currently logged.
Theminicomputer model may be used when resource sharing (such as sharingof
information databases of different types, with each type ofdatabase located on a different
machine) with remote users is desired.
The early ARPAnet is an example of adistributed computing system based on the
minicomputer model.6
Mini­
computeChap.1 • Fundamentals
/TerminalS
Mini·
compute
Mini­
computer
Fig_1.2 A distributed computing system based on the minicomputer model.
1.3.1Workstation Mod.1
As shown in Figure 1.3, a distributed computing system based on the workstation model
consists of several workstations interconnected by acommunication network. A
company's office or a university department may have several workstations scattered
throughout abuilding orcampus, each workstation equipped withitsown disk and serving
as a single-user computer. It has been often found that in such an environment, atanyone
time (especially at night), a significant proportion of the workstations are idle (not being
used), resulting in the waste of large amounts of CPU time. Therefore, the idea of the
workstation model is to interconnect all these workstations byahigh-speed LAN so that
idle workstations may be used to process jobs of users who are logged onto other
workstations and do not have sufficient processing power at their own workstations to get
theirjobsprocessed efficiently.
In this model, a user logs onto one of the workstations called his or her "home"
workstation and submits jobs for execution. When the system finds that the user's
workstation does not have sufficient processing power for executing the processes of
the submitted jobsefficiently, it transfers one or more of the processes from the user's
workstation to some other workstation that is currently idle and gets the process
executed there, and finally the result of execution is returned to the user's
workstation.
This model is not so simple to implement as it might appear at first sight because
several issues must beresolved. These issues are [Tanenbaum 1995] as follows:Sec. 1.3 • Distributed Computing System Models
li'ig.1.3 A distributed computing system based on the workstation model.7
1.How does the system find an idle workstation?
2. How is a process transferred from one workstation to get itexecuted on another
workstation?
3. What happens to a remote process if a user logs onto a workstation that was
idle until now and was being used to execute a process of another
workstation?
Ways to handle the first two issues are described in Chapters 7 and 8, respectively.
Threecommonly used approaches for handling the third issue are as follows:
1. The first approach is to allow the remote process share the resources of the
workstation along with its own logged-on user'sprocesses. This method is easy to
implement, but it defeats the main idea of workstations serving as personal computers,
becauseifremoteprocesses are allowed to execute simultaneously with the logged-on
user'sown processes, the logged-on user does not get his or her guaranteed
response.
2. The second approach is to kill the remote process. The main drawbacks of this
method are that all processing done for the remote process gets lost and the file system
may be left in an inconsistent state, making this method unattractive.
3. The third approach is to migrate the remote process back to its home
workstation, so that its execution can be continued there. This method is difficult to
implement because it requires the system to support preemptive process migration
facility. The definition of preemptive process migration and the issues involved in
preemptive process migration are given in Chapter8.8 Chap.I •Fundamentals
The Sprite system [Ousterhout et al. 1988] and an experimental systemdeveloped at
XeroxPARe[Shoch and Hupp 1982] are two examples ofdistributed computing systems
basedon theworkstation model.
1.3.3Workstatlon-S.rver Model
Theworkstation model is a networkofpersonal workstations, each with its own disk and
a local file system. A workstation with its own local disk is usually calledadiskful
workstation and aworkstation withouta local disk is calledadiskless workstation. With
theproliferation ofhigh-speed networks, disklessworkstations havebecomemorepopular
innetworkenvironments than diskful workstations, making the workstation-server model
morepopularthan the workstation model for building distributed computing systems.
As shown in Figure 1.4, a distributed computing system based on the workstation­
servermodel consistsofa fewminicomputers and several workstations (mostofwhich are
diskless, but a few ofwhich may be diskful) interconnected by acommunication
network.
Mini­
com.puter
usedas
file
serverMini­
compute
usedas
database
serverMini­
computer
usedas
print
server
Fig. 1.4 A distributed computing system based on the
workstation-server model.
Note that when diskless workstations are used on anetwork, the file system tobe used
by these workstations must be implemented eitherbya diskful workstation orbya
minicomputer equipped with a disk for file storage. The minicomputers are used for this
purpose. Oneormore oftheminicomputers areusedfor implementing thefilesystem. Other
minicomputers may be used for providing othertypesofservices, such as database service
and print service. Therefore, eachminicomputer is used as a servermachine toprovideone
or more types ofservices. Hence in the workstation-server model, in addition to the
workstations, there are specialized machines (may bespecialized workstations) forrunning
serverprocesses (calledservers)formanaging andproviding access to shared resources.Sec. 1.3 • Distributed Computing SystemModels 9
For a number of reasons, such as higher reliability and better scalability, multiple
servers are often used for managing the resources of a particular type in a distributed
computing system. For example, there may be multiple file servers, each running on a
separateminicomputer and cooperating via the network, for managing the files of all the
users in the system. Due to this reason, a distinction is often made between the services
that are provided to clients and the servers that provide them. That is, a serviceis an
abstract entity that is provided by one or more servers. For example, one or more file
servers may be used in a distributed computing system to provide file service to the
users.
In this model, a user logs onto a workstation called his or her home workstation.
Normal computation activities required by the user'sprocesses are performed at the user's
home workstation, but requests for services provided by special servers (such as a file
serveror adatabase server) are sentto a server providing that type of servicethatperforms
theuser'srequested activity and returns the result of request processing to the user's
workstation. Therefore, in this model, the user'sprocesses need not be migrated to the
server machines for getting the work done by those machines.
For better overall system performance, the local disk of a diskful workstation is
normally used for such purposes as storage of temporary files, storage of unshared files,
storage of shared files that are rarely changed, paging activity in virtual-memory
management, and caching of remotely accessed data.
As compared to the workstation model, the workstation-server model has several
advantages:
1. In general, it is much cheaper to use a few minicomputers equipped with large,
fast disks that are accessed over the network than a large number of diskful workstations,
with each workstation having a small, slow disk.
2.Diskless workstations are also preferred to diskful workstations from a system
maintenance point of view.Backup and hardware maintenance are easier to perform with
a few large disks than with many small disks scattered all over a building or campus.
Furthermore, installing new releases of software (such as a file server with new
functionalities) is easier when the software is to be installed on a few file server machines
than on every workstation.
3. In the workstation-server model, since all files are managed bythe file servers,
users have the flexibility to use any workstation and access the files in the same manner
irrespective of which workstation the user is currently logged on. Note that thisis not true
with the workstation model, in which each workstation has its local file system, because
different mechanisms are needed to access local and remote files.
4. In the workstation-server model, the request-response protocol described above is
mainly used to access the services of the server machines. Therefore, unlike the
workstation model, this model does notneed aprocess migration facility,whichisdifficult
to implement.
Therequest-response protocol is known as the client-server modelof communica­
tion. In this model, a client process (which in this case resides on a workstation) sends a10 Chap.1 • Fundamentals
requestto a server process(which in this case resides on a minicomputer) for getting some
servicesuch as reading a block of a file. The server executes the request and sends back
a reply to the client that contains theresultof request processing.
Theclient-server modelprovides aneffective general-purpose approach to the
sharingofinformation andresources indistributed computing systems. It is not only
meantfor use with the workstation-server model but also can be implemented in a variety
ofhardware and software environments. Thecomputers used to run the clientand server
processes need not necessarily beworkstations andminicomputers. They can be ofmany
types and there is no need to distinguish between them. It is even possible for both the
clientandserverprocesses to be run on the same computer. Moreover, some processes are
both client and server processes. That is, a server process may use the servicesofanother
server,appearing as a client to the latter.
5. A user has guaranteed response timebecause workstations are not used for
executing remote processes. However, the model does not utilize the processing capability
ofidleworkstations.
The V-System [Cheriton 1988] is an exampleofadistributed computing system that
is based on the workstation-server model.
1.3.4Proc.ssor-Pool Mod.1
Theprocessor-pool modelis based on the observation that most of the time a user does
not need any computing powerbutoncein awhilehe or she may need a very large amount
ofcomputing powerfor a short time (e.g., when recompiling aprogram consisting ofa
largenumberoffiles after changing a basic shared declaration). Therefore, unlike the
workstation-server model in which a processor isallocated to each user, in the processor­
pool model the processors are pooled together to be shared by the users as needed. The
poolofprocessors consistsofa largenumberofmicrocomputers andminicomputers
attached to the network. Each processor in the pool has its own memory to load and run
asystemprogram or anapplication program ofthedistributed computing system.
As shown in Figure1.5, in the pure processor-pool model, the processors in the pool
have no terminals attached directlyto them, and users access the system from terminals
that are attached to thenetwork via special devices. These terminals areeithersmall
disklessworkstations or graphic terminals, such as X terminals. A special server (called
arunserver)manages and allocates theprocessors in the pool to different users on a
demandbasis. When a user submits a jobforcomputation, anappropriate number of
processors aretemporarily assigned to his or her jobby the run server. For example, if the
user'scomputation jobis thecompilation ofaprogram havingnsegments, in which each
of thesegments can becompiled independently toproduce separate relocatable object
files,nprocessors from the pool can be allocated to thisjobtocompileall thensegments
inparallel.When the computation iscompleted, theprocessors arereturnedto the pool for
use byotherusers.
In theprocessor-pool model there is no conceptof a home machine. That is, a user
does not log onto a particular machine but to the system as a whole. This is in contrastSec. 1.3 • Distributed Computing SystemModels
Fig. 1.5 A distributed computing system
based on the processor-pool model.Terminals
~
PoolofprocessorsFile
serve11
to other models in which each user has a home machine (e.g., a workstation or
minicomputer) onto which he or she logs and runs most of his or her programs there
by default.
Ascompared to theworkstation-server model, the processor-pool model allows
betterutilization of the available processing power of a distributed computing system.
Thisis because in the processor-pool model, the entireprocessing powerofthe system is
available for use by the currently logged-on users, whereas this is not true for the
workstation-server model in which several workstations may be idle at a particular time
but they cannot be used for processing thejobsofotherusers.Furthermore, the processor­
pool model provides greaterflexibility than the workstation-server model in the sense that
thesystem's services can be easily expanded without the need to install any more
computers; theprocessors in the pool can be allocated to act as extra servers to carry any
additional load arising from an increased userpopulation or to provide new services.
However, the processor-pool model is usually considered to be unsuitable for high­
performance interactive applications, especially those using graphics or window systems.
This is mainly because of the slow speed of communication between the computer on
which the application program of a user is being executed and the terminal via which the
user isinteracting with the system. The workstation-server model is generally considered
to be more suitable for such applications.
Amoeba [Mullender eta1.1990], Plan 9 [Pike et at1990], and the Cambridge
Distributed Computing System[Needham and l-lerbert 1982] are examples of distributed
computing systems based on the processor-pool model.12 Chap.1 •Fundamentals
1.3.5 Hybrid Mod.'
Out of the four modelsdescribed above, the workstation-server model, isthe most widely
used model forbuilding distributed computing systems.This is because a large number of
computer users only perform simple interactive tasks such as editing jobs, sending
electronic mails, andexecuting smallprograms. The workstation-server model is ideal for
such simple usage.However,ina workingenvironment that hasgroups of users whooften
perform jobs needing massive computation, the processor-pool model is more attractive
and suitable.
To combine the advantages of both the workstation-server and processor-pool
models, a hybrid model may be used to build a distributed computing system. The
hybrid model is based on the workstation-server model but with the addition of a pool
of processors. The processors in the pool can be allocated dynamically for computations
that are too large forworkstations or that require several computers concurrently for
efficient execution. In addition to efficient execution of computation-intensive jobs, the
hybrid model gives guaranteed response to interactive jobs by allowing them to be
processed on local workstations of the users. However, the hybrid model is more
expensive to implement than the workstation-server model or the processor-pool
model.
1.4WHYAREDISTRIBUTED COMPUTING SYSTEMS
GAINING POPULARnv?
From the models of distributed computing systems presented above, it is obvious that
distributed computing systems are much more complex and difficult to build than
traditional centralized systems(those consisting of a single CPU, its memory,peripherals,
and one or more terminals). The increased complexity is mainly due to the fact that in
addition to being capable of effectively using and managing a very large number of
distributed resources, the system software of a distributed computing system should also
be capable of handling the communication and security problems that are very different
from those of centralized systems. For example, the performance and reliability of a
distributed computing system depends toa great extent on the performance and reliability
of the underlying communication network. Special software is usually needed to handle
loss of messages during transmission across the network or to prevent overloading of the
network, which degrades the performance and responsiveness to the users. Similarly,
special software security measures are needed to protect the widely distributed shared
resources and services against intentional or accidental violation of access control and
privacy constraints.
Despite theincreasedcomplexity andthe difficultyofbuilding distributed computing
systems, the installation and use of distributed computing systems are rapidly increasing.
This is mainly because the advantages of distributed computing systems outweigh their
disadvantages. The technicalneeds, theeconomic pressures, and themajoradvantages that
have led to the emergence and popularity of distributed computing systems are described
next.Sec.1.4 • WhyAreDistributed Computing SystemsGainingPopularity?
1.4.1Inherently Distributed Applications13
Distributed computing systems come into existence in some very natural ways. For
example, several applications are inherently distributed in nature and require a distributed
computing system for their realization. For instance, in an employee database of a
nationwide organization, the data pertaining to a particular employee are generated at the
employee's branch office, and in addition to the global need to view the entire database,
there is a local need for frequent and immediate access to locally generated data at each
branch office.Applications such as these require that some processing power be available
at the many distributed locations for collecting, preprocessing, and accessing data,
resulting in the need for distributed computing systems. Some other examples of
inherently distributed applications are a computerized worldwide airline reservation
system, acomputerized banking system in whicha customer can deposit/withdraw money
from his or her account from any branch of the bank, and a factory automation system
controlling robots and machines all along an assembly line.
1.4.2Information SharingamongDistributed Users
Another reason for the emergence of distributed computing systems was adesire for
efficient person-to-person communication facility by sharing information over great
distances. In a distributed computing system, information generated by one of the users
can be easily and efficiently shared by the users working at other nodes of the system.
This facility may be useful in many ways. For example, a project can be performed by
two or more users who are geographically far off from each other but whose computers
are a part of the same distributed computing system. In this case, although the users
are geographically separated from each other, they can work in cooperation, for
example, bytransferring the files ofthe project, logging onto each other'sremote
computers to run programs, and exchanging messages by electronic mail to coordinate
the work.
The use of distributed computing systems by a group of users to work cooperatively
isknown as computer-supported cooperative working(CSCW), or groupware. Groupware
applications depend heavily on the sharing of data objects between programs running on
different nodes of a distributed computing system. Groupware is an emerging technology
that holds major promise for software developers.
1.4.3Resource Sharing
Information is not the only thing that can be shared in a distributed computing system.
Sharing of software resources such as software libraries and databases as wellas hardware
resources suchas printers, hard disks, and plotters can also bedone ina veryeffective way
among all the computers and the users of a single distributed computing system. For
example, we saw that in a distributed computing system based on the workstation-server
model the workstations may have no disk or only a small disk (10-20megabytes) for
temporary storage, and access to permanent files on a large disk can be provided to all the
workstations by a single file server.14 Chap.1 •Fundamentals
This is one of the most important reasons for the growing popularity ofdistributed
computing systems. With the rapidly increasing powerandreduction in the price of
microprocessors, combined with the increasing speedofcommunication networks,
distributed computing systemspotentially have a much better price-performance ratio than
a single large centralized system. For example, we saw how a small numberofCPUs in a
distributed computing system based on the processor-pool model can be effectively used by
a largenumberofusers from inexpensive terminals, giving a fairly high price-performance
ratio ascompared toeither acentralized time-sharing system or a personal computer.
Anotherreason for distributed computing systemstobemore cost-effective thancentralized
systemsis that they facilitate resource sharingamong multiple computers. Forexample, a
single unit ofexpensive peripheral devicessuch ascolorlaserprinters,high-speed storage
devices, and plotters can beshared among all the computers of the same distributed
computing system. If these computers are not linked together with acommunication
network, eachcomputer must have its own peripherals, resulting in higher cost.
1.4.5ShorterResponse nmesandHigherThroughput
Due tomultiplicity ofprocessors, distributed computing systems are expected tohave better
performance thansingle-processor centralized systems. The two most commonly used
performance metrics are response time and throughput of userprocesses. That is, the
multipleprocessors ofadistributed computing system can beutilized properly for providing
shorter response times and higher throughput than a single-processor centralized system.
Forexample, if there are two different programs to be run, two processors are evidently
morepowerful than one because the programs can besimultaneously run ondifferent
processors. Furthermore, if aparticular computation can bepartitioned into anumberof
subcomputations that can run concurrently, in a distributed computing system all the
subcomputations can besimultaneously run with each one on a different processor.
Distributed computing systems with very fast communication networks areincreasingly
being used asparallel computers tosolve single complex problems rapidly.Anothermethod
often used in distributed computing systems for achieving better overall performance is to
distribute the load more evenly among the multiple processors bymovingjobsfrom
currently overloaded processors to lightly loaded ones. For example, in adistributed
computing system based on the workstation model, ifa user currently has twoprocesses to
run, outofwhich oneisan interactive processandtheother isaprocess thatcan berun inthe
background, it may be advantageous to run the interactive processon the home node of the
user and the otherone on aremote idle node (ifany node is idle).
1.4.6HigherReliability
Reliability refers to the degree of tolerance against errors and component failures in a
system[Stankovic 1984].A reliable system prevents loss of information even in the event
ofcomponent failures. The multiplicity ofstoragedevicesandprocessors in adistributed
computing system allows the maintenance of multiple copies of critical information withinSec. 1.4 • WhyAreDistributed Computing SystemsGaining Popularity? 15
the system and the execution ofimportant computations redundantly to protect them
againstcatastrophic failures. With this approach, ifone of the processors fails, the
computation can besuccessfully completed at the other processor, and ifone of the storage
devices fails, the information can still be used from the other storage device. Furthermore,
thegeographical distribution of theprocessors and other resources in adistributed
computing system limits the scope offailurescausedby natural disasters.
Animportant aspectofreliability is availability, whichrefers tothefraction oftimefor
which a system is available for usc. In comparison to acentralized system, a distributed
computing system also enjoys the advantage of increased availability. For example, if the
processor of acentralized system fails (assuming that it is a single-processor centralized
system), the entire system breaks down and no useful work can be performed. However, in
the case of a distributed computing system, a few parts of the system can bedown without
interrupting thejobs ofthe userswhoare using theother parts ofthesystem,Forexample, if
aworkstation of adistributed computing system that is based on the workstation-server
model fails, only the user of that workstation is affected. Otherusers of the system are not
affected bythisfailure. Similarly, ina distributed computing system based ontheprocessor­
pool mode), ifsome of the processors in the pool are down at any moment, the system can
continue tofunction normally, simply with some loss in performance that isproportional to
the number of processors that are down. In this case, none of the users is affected and the
users cannot even know that some of the processors are down.
Theadvantage of higher reliability is an important reason for the use ofdistributed
computing systems for critical applications whose failure maybe disastrous. However,
oftenreliability comes at the cost of performance. Therefore, it is necessary to maintain
a balance between the two.
1.4.7Extensibility andIncremental Growth
Another majoradvantage ofdistributed computing systems is that they are capable of
incremental growth. That is, it is possibletogradually extend the power and functionality
of adistributed computing system by simply adding additional resources (both hardware
and software) to the system as and when the need arises. For example, additional
processors can be easily added to the system to ha~dlethe increased workload of an
organization thatmighthave resulted from its expansion. Incremental growth is a very
attractive feature because for most existing andproposed applications itispractically
impossible topredictfuture demands ofthe system. Extensibility is alsoeasierin a
distributed computing system because addition ofnew resources to an existing system can
beperformed withoutsignificant disruption ofthe normal functioning ofthe system.
Properly designed distributed computing systems that have the property of extensibility
andincremental growth are called opendistributed systems.
1.4.8 Setter Flexibility inM••tlngUsers'Needs
Different types ofcomputers are usually more suitableforperforming different types of
computations. For example, computers with ordinary powerare suitable for ordinary data
processing jobs,whereas high-performance computers are more suitable for complex16 Chap.1 •Fundamentals
mathematicalcomputations.Inacentralizedsystem,theusershavetoperformalltypesof
computationson the only availablecomputer.However,a distributedcomputing system
may have a poolof differenttypesof computers,in whichcase the mostappropriateone
canbeselected for processing a user's job depending on the nature of the job. For
instance,wesawthatinadistributedcomputingsystemthatisbasedonthehybridmodel,
interactivejobs can be processedat a user's.own workstationand the processors in the
pool may beused to process noninteractive, computation-intensivejobs.
Note that the advantages of distributed computing systems mentioned above are not
achieved automatically but depend on the careful design of a distributed computing
system. This book deals with the various design methodologies that may be used to
achieve these advantages.
1.5WHATISADISTRI8UTED OPERATING SYSTEM?
TanenbaumandVanRenesse[1985]definean operating system asaprogramthatcontrols
the resources of a computer system and provides its users with an interface or virtual
machine that is more convenient to use than the bare machine. According to this
definition, the two primary tasksof an operating system are as follows:
1.To present users with a virtual machine that is easier to program than the
underlyinghardware.
2. To manage the various resources of the system.This involves performing such
tasksaskeepingtrackof whoisusingwhichresource,grantingresourcerequests,
accountingfor resourceusage,and mediatingconflictingrequests from different
programsand users.
Therefore, the users' view of a computer system, the manner in which the users
accessthe variousresourcesof thecomputersystem,and the waysin whichthe resource
requests are granted depend to a great extent on the operating system of the computer
system.The operatingsystemscommonlyused fordistributedcomputingsystemscan be
broadly classified into two types-network operating systems anddistributed operating
systems.The threemostimportantfeaturescommonlyusedtodifferentiatebetweenthese
two types of operating systems are system image, autonomy, and fault tolerance
capability.These featuresare explainedbelow.
1. System image. The mostimportantfeatureused to differentiatebetween the two
typesofoperatingsystemsistheimageofthedistributedcomputingsystemfromthepoint
of viewof its users.Incaseofa networkoperatingsystem,the usersviewthedistributed
computing system as a collection of distinct machines connected by a communication
subsystem.Thatis,theusersareawareofthefactthatmultiplecomputersare beingused.
On the other hand, a distributed operating system hides the existence of multiple
computersand providesa single-systemimageto its users.That is, it makes a collectionSec.1.5 •WhatIsaDistributed Operating System? 17
of networked machines act as a virtualuniprocessor. The difference between the two types
ofoperating systems based on this feature can bebestillustrated with the help of
examples. Two such examples are presented below.
In the case ofa network operating system, although a user can run a job on any
machine of the distributed computing system, he or she is fully aware of the machine
on which his or her job is executed. This is because, by default, a user'sjob is
executed on the machine on which the user is currently logged. If the user wants to
execute a job on a different machine, he or she should either log on to that machine
by using some kind of "remote login" command or use a special command for remote
execution to specify the machine on which the job is to be executed. In either case,
the user knows the machine on which the job is executed. On the other hand, a
distributed operating system dynamically and automatically allocates jobs to the
various machines of the system for processing. Therefore, a user of a distributed
operating system generally has no knowledge of the machine on which a jobis
executed. That is, the selection of a machine for executing a job is entirely manual in
the case of network operating systems but is automatic in the case of distributed
operating systems.
With a network operating system, a user is generally required to know the location
of a resource to access it,and different sets of system calls have to beused for accessing
local and remote resources. On the other hand, users of a distributed operating system
need not keep track of the locations of various resources for accessing them, and the same
set of system calls is used for accessing both localand remote resources. For instance,
users of a network operating system are usually aware of where each of their files is stored
and must use explicit file transfer commands for moving a file from one machine to
another, but the users of a distributed operating system have no knowledge of the location
of their files within the system and use the same command to access a file irrespective of
whether it is on the local machine or on a remote machine. That is, control over file
placement is done manually by the users in a network operating system but automatically
by the system in a distributed operating system.
Notice that the key concept behind this feature is "transparency." We will see later in
thischapterthatadistributed operating systemhas tosupport several fOnDSoftransparency
toachieve thegoalofproviding asingle-system imagetoitsusers. Moreover, itisimportant
tonotehere that withthecurrent stateoftheartindistributed operating systems, thisgoal is
not fully achievable. Researchers are still working hard toachieve this goal.
2. Autonomy. A network operating system is built on a set of existing centralized
operating systems and handles the interfacing and coordination of remote operations and
communications between these operating systems. That is, in the case of a network
operating system, each computer of the distributed computing system has its own local
operating system (the operating systems ofdifferent computers may be the same or
different), and there is essentially no coordination at aJIamong the computers except for
the rule that when two processes of different computers communicate with each other,
they must use a mutually agreed on communication protocol. Each computer functions
independently of other computers in the sense that each one makes independent decisions
about the creation and termination of their own processes and management of local18 Chap. 1 • Fundamentals
resources. Notice that due to the possibility of difference in local operating systems, the
system calls for different computers of the same distributed computing system may be
different in this case.
On the other hand, with a distributed operating system, there is a single systemwide
operating system and each computer of the distributed computing system runs a part of
this global operating system. The distributed operating system tightly interweaves all the
computers of the distributed computing system in the sense that they work in close
cooperation with each other for the efficient and effective utilization of the various
resources ofthe system. That is, processes and several resources are managed globally
(some resources are managed locally). Moreover, there is a single set of globally valid
system calls available on all computers of the distributed computing system.
The set of system calls that an operating system supports are implemented by a set
of programs called the kernelof the operating system. The kernel manages and controls
the hardware of the computer system to provide the facilities and resources that are
accessed by other programs through system calls,To make the same set of system calls
globally valid, with a distributed operating system identical kernels are run on all the
computers of a distributed computing system. The kernels of different computers often
cooperate with each other in making global decisions, such as finding the most suitable
machine for executing a newly created process in the system.
In short, it can be said that the degree of autonomy of each machine of a distributed
computing system that uses a networkoperating system is considerably high as compared
to that of machines of a distributed computing system that uses a distributed operating
system.
3. Fault tolerance capability. A network operating system provides little or no
fault tolerance capability in the sense that if10% of the machines of the entire
distributed computing system are down at any moment, at least 10% ofthe users are
unable to continue with their work. On the other hand, with a distributed operating
system, most of the users are normally unaffected by the failed machines and can
continue to perform their work normally, with only a 10% loss in performance of the
entire' distributed computing system. Therefore, the fault tolerance capability of a
distributed operating system is usually very high as compared to that of a network
operating system.
The following definition of a distributed operating system given by Tanenbaum and
Van Renesse [1985] covers most of its features mentioned above:
A distributed operating system is one that looks to its users like an ordinary centralized
operating system but runs on multiple, independent central processing units (CPUs). The
key concept here is transparency.In other words, the use of multiple processors should be
invisible (transparent) to the user.Another way of expressing the same idea is to say that
the user views the system as a "virtual uniprocessor," not as a collection of distinct
machines. [P.419].
A distributed computing system that uses a network operating system is usually
referred to as a network system, whereas one that uses a distributed operating system isSec. 1.6 • Issuesin Designing aDistributed Operating System 19
usuallyreferred to as atrue distributed system (orsimplyadistributed system). In this
book, the term distributed systemwill be used to mean a true distributed system.
Notethatwith the currentstateofthe art in distributed operating systems, it is not
possible todesignacompletely truedistributed system. Completely truedistributed
systemsare theultimate goalofresearchers working in the area ofdistributed operating
systems.
1.6ISSUESINDESIGNING ADISTRIBUTED OPERATING
SYSTEM
Ingeneral, designing adistributed operating systemis more difficult thandesigning a
centralized operating systemforseveralreasons. In thedesignofacentralized operating
system,it isassumed that the operating systemhasaccesstocomplete andaccurate
information abouttheenvironment in which itisfunctioning. Forexample, acentralized
operating systemcanrequeststatusinformation, beingassured that the interrogated
component will not changestate while awaiting adecision basedon that status
information, sinceonly the single operating systemaskingthequestion may give
commands. However, adistributed operating systemmustbedesigned with the
assumption thatcomplete information aboutthesystemenvironment willneverbe
available. In adistributed system,theresources arephysically separated, there is no
common clockamongthemultiple processors, delivery ofmessages isdelayed, and
messages couldevenbe lost. Due to all these reasons, adistributed operating systemdoes
not have up-to-date, consistent knowledge aboutthe stateofthevariouscomponents ofthe
underlying distributed system.Obviously, lackofup-to-date andconsistent information
makesmanythings(such asmanagement ofresources andsynchronization ofcooperating
activities) muchharderin thedesignofadistributed 'operating system.Forexample, it is
hard toschedule theprocessors optimally iftheoperating systemis not sure how many of
them are up at the moment.
Despitethesecomplexities anddifficulties, adistributed operating systemmust be
designed toprovidean theadvantages ofadistributed systemto its users. Thatis, the users
shouldbe able to view a distributed systemas a virtual centralized systemthat isflexible,
efficient, reliable, secure,and easy to use. To meetthischallenge, thedesigners ofa
distributed operating systemmust deal with severaldesignissues.Someofthe keydesign
issuesaredescribed below. The rest of the chapters of this book basically containdetailed
descriptions ofthesedesignissues and the commonly usedtechniques to deal with
them.
1.6.1Transparency
We saw that one ofthe main goals ofadistributed operating systemis tomakethe
existence ofmultiple computers invisible (transparent) andprovide asinglesystem
imageto its users. Thatis, adistributed operating systemmustbedesigned insucha
way that a collection ofdistinctmachines connected byacommunication subsystem20 Chap.1 • Fundamentals
appears to its users as a virtual uniprocessor. Achieving complete transparency is a
difficulttask and requires that several different aspects of transparency besupported by
thedistributed operating system. The eight forms of transparency identified by the
International Standards Organization's Reference Model for Open Distributed Process­
ing [ISO 1992] are access transparency, location transparency, replication transparency,
failure transparency, migration transparency, concurrency transparency, performance
transparency, and scaling transparency. These transparency aspects are described
below.
AccessTransparency
Accesstransparency means that users should not need or be able to recognize whether a
resource (hardware or software) is remote or local. This implies that the distributed
operating system should allow users to access remote resources in the same way as local
resources. That is, the user interface, which takes the form of a set of system calls, should
notdistinguish between local and remote resources, and it should be the responsibility of
thedistributed operating system to locate the resources and to arrange for servicing user
requests in a user-transparent manner.
Thisrequirement calls for a well-designed set of system calls that are meaningful in
bothcentralized and distributed environments and a global resource naming facility. We
will see in Chapters 3 and 4 that due to the need to handle communication failures in
distributed systems, it is not possible to design system calls that provide complete access
transparency. However, the area of designing a global resource naming facility has been
wellresearched withconsiderable success. Chapter 10deals with the concepts and design
of a global resource naming facility.The distributed shared memory mechanism described
inChapter5 is also meant to provide a uniform setof system calls for accessing both local
and remote memory objects. Although this mechanism is quite useful in providing access
transparency, it is suitable only for limited types of distributed applications due to its
performance limitation.
Location Transparency
The two main aspects of location transparency are as follows:
1. Nametransparency. This refers to the fact that the name of a resource (hardware
orsoftware) should not reveal any hint as to the physical location of the resource. That is,
the name ofa resource should be independent of the physical connectivity or topology of
the system or the current location of the resource. Furthermore, such resources, which are
capableofbeing moved from one node to another in a distributed system (such asafile),
must beallowedto move without having their names changed. Therefore, resource names
mustbeunique systemwide.
2.Usermobility.This refers tothe fact that nomatter which machine a user islogged
onto, he or she should beable to access a resource with the same name. That is, the user
should not be required to use different names to access the same resource from. twoSec. 1.6 • Issuesin Designing aDistributed Operating System 21
differentnodesofthe system.Inadistributed systemthat supportsusermobility,userscan
freelylogon toany machinein thesystemandaccessany resourcewithoutmakingany
extraeffort.
Both name transparency and user mobility requirements call for a systemwide, global
resource naming facility.
Replication Transparency
For better performance and reliability, almost all distributed operating systems have
the provision to create replicas (additional copies) of files and other resources on
different nodes of the distributed system. In these systems, both the existence of
multiple copies of a replicated resource and the replication activity should be
transparent to the users. That is, two 'important issues related to replication transpar­
ency are naming of replicas and replication control. It is the responsibility of the
system to name the various copies of a resource andto map a user-supplied name of
the resource to an appropriate replica of the resource. Furthermore, replication control
decisions such as how many copies of the resource should be created, where should
each copy be placed, and when should a copy be created/deleted shouldbemade
entirelyautomatically bythe system in a user-transparent manner. Replica manage­
ment issues are described inChapter9.
FailureTransparency
Failure transparency deals with masking from the users' partial failures in the system,
such as a communication link failure, a machine failure, or a storage device crash. A
distributed operating system having failure transparency property will continue to
function, perhaps in a degraded form, in the face of partial failures. For example,
suppose the file service of a distributed operating system is to be made failure
transparent. This can be done by implementing it as a group of file servers that closely
cooperate with each other to manage the files of the system and that function in such
a manner that the users can utilize the file service even if only one of the file servers
is up and working. In thiscase, the users cannot notice the failure of one or more file
servers, except for slower performance of file access operations. Any type of service
can beimplemented in this way for failure transparency. However, in this type of
design, care should be taken to ensure that the cooperation among multiple servers does
notadd too much overhead to the system.
Complete failure transparency is not achievable with the current state of the art in
distributed operating systems because all types of failures cannot be handled in a user­
transparent manner. For example, failure of the communication network of a distributed
system normally disrupts the work of its users and is noticeable by the users. Moreover,
an attempt to design a completely failure-transparent distributed system will result in a
very slow and highly expensive system due to the large amount ofredundancy required
for tolerating all types of failures. The design of such a distributed system, although
theoretically possible, is not practically justified.22 Chap.1 •Fundamentals
Migration Transparency
For better performance, reliability,andsecurity reasons, an object that is capable of being
moved (such as a process or a file) is often migrated from one node to another in a
distributed system. The aim of migration transparency is to ensure that the movement of
the object is handled automatically by the system in a user-transparent manner. Three
important issues in achieving this goal are as follows:
1. Migration decisions such as which object is to be moved from where to where
shouldbemade automatically by the system.
2. Migration of an object fromonenode toanother should not require any change in
its name.
3. When the migrating object is a process, the interprocess communication
mechanism should ensure thata message sent to the migrating process reaches it
without the need for the senderprocess to resend it if the receiver process moves
to another node before the message is received.
Chapter 7 deals with the first issue. The second issue calls for a global resource
naming facility, which is described in Chapter 10. Ways to handle the third issue are
described in Chapter 8.
Concurrency Transparency
In a distributed system, multiple users who are spatially separated use the system
concurrently. In such a situation, it is economical to share the system resources
(hardware or software) among the concurrently executing user processes. However,
since the number of available resources in a computing system is restricted, one user
process must necessarily influence the action of other concurrently executing user
processes, as it competes for resources. For example, concurrent update to the samefile by two different processes should
beprevented. Concurrency transparency means
that each user has a feeling that he or she is the sole user of the system and other
users do not exist in the system. For providing concurrency transparency, the resource
sharing mechanisms of the distributed operating system must have the following four
properties:
1. An event-ordering property ensures that all access requests to various system
resources are properly ordered to provide a consistent view to all users of the
system.
2. A mutual-exclusion property ensures that at any time at most one process
accesses a shared resource, which must not be used simultaneously by multiple
processes if program operation is to be correct.
3. A no-starvation property ensures that if every process that is granted a resource,
which must not beused simultaneously by multiple processes, eventually releases it,
every request for that resource is eventually granted.Sec. 1.6 • Issuesin Designing aDistributed Operating System 23
4. Ano-deadlock property ensures that a situation will never occurin which
competing processes prevent their mutual progress even though no single one requests
moreresources than available in the system.
Chapter6 deals with the above-mentioned issues of concurrency transparency.
Performance Transparency
The aimof performance transparency istoallowthesystem tobeautomatically reconfigured
to improve performance, as loads vary dynamically in the system. As far as practicable, a
situation in which one processor of the system is overloaded with jobs while another
processor is idle should not be allowed to occur. That is, the processing capability ofthe
system should be uniformly distributed amongthecurrently availablejobs inthe system.
Thisrequirement calls for the support of intelligent resource allocation and process
migration facilities in distributed operating systems. Chapters 7 and 8 deal with these two
issues.
ScalingTransparency
The aim of scaling transparency is to allow the system to expand in scale without
disrupting the activities of the users. This requirement calls foropen-system architecture
and the use of scalable algorithms fordesigning thedistributed operating system
components. Section 1.6.3 of this chapter and Section 2.6 of Chapter2 focus on the issues
ofdesigning an opendistributed system. On the other hand, since every component of a
distributed operating system must use scalable algorithms, this issue has been dealt with
in almost all chapters of the book.
1.6.2Rallabillty
In general, distributed systems are expected to be more reliable than centralized systems
due to the existence of multiple instances of resources. However, the existence of multiple
instances of the resources alone cannot increase the system's reliability. Rather, the
distributed operating system, which manages these resources, must be designed properly
toincreasethesystem's reliability by takingfull advantage of this characteristic feature of
adistributed system.
Afaultis a mechanical or algorithmic defect that may generate an error. A fault in a
system causes system failure. Depending on the manner in which a failed system behaves,
system failures areoftwo types-fail-stop [Schlichting andSchneider 1983)and Byzantine
[Lamport eta1.1982]. In the case of fail-stop failure,the system stops functioning after
changing to a state in which its failure can be detected. On the other hand, in the case of
Byzantine failure,the system continues tofunction but produces wrong results. Undetected
software bugs often cause Byzantine failureof a system. Obviously, Byzantine failures are
much more difficult to deal with than fail-stop failures.
For higher reliability, the fault-handling mechanisms of adistributed operating
system must be designed properly to avoid faults, to tolerate faults, and to detect and24 Chap.1 •Fundamentals
recoverfrom faults. Commonly used methods for dealing with these issues are briefly
described next.
FaultAvoidance
Faultavoidance deals with designing the components of the system in such a waythat the
occurrence offaults is minimized. Conservative design practices such as using high­
reliability components-are often employed for improving the system's reliability based on
the ideaoffault avoidance. Although a distributed operating system often has little or no
role to play in improving the fault avoidance capability of a hardware component, the
designers ofthe various software components of thedistributed operating system must test
themthoroughly to make these components highly reliable.
FaultTolerance
Fault tolerance is the ability of a system to continue functioning in the event ofpartial
system failure. The performance of the system might be degraded due to partial failure,
butotherwise the system functions properly. Some of the important concepts that may be
used to improve the fault tolerance ability ofa distributed operating system are as
follows:
1.Redundancy techniques. The basic idea behind redundancy techniques is to avoid
single points offailure by replicating critical hardware and software components, so that
if oneofthem fails, the others can be used to continue. Obviously, having two or more
copies of a critical component makes it possible, at least in principle, to continue
operations in spite of occasional partial failures. For example, a critical process can be
simultaneously executed on two nodes so that if one of the two nodes fails, the execution
ofthe process can be completed at the other node. Similarly, a critical file may be
replicated on two or more storage devices for better reliability.
Notice that with redundancy techniques additional system overhead is needed to
maintain twoor more copies ofareplicated resource and tokeepallthecopies ofaresource
consistent. For example, ifafile isreplicated ontwoor more nodesof a distributed system,
additional disk storage space is required, and for correct functioning, it is often necessary
that all the copies of the file are mutually consistent. In general, the larger is the number of
copies kept, the better is the reliability but the larger is the system overhead involved.
Therefore, a distributed operating system must be designed to maintain a properbalance
between the degree of reliability and the incurred overhead. This raises an important
question: How much replication is enough? For an answer to this question, note that a
system is said to be k-fault tolerant if it can continue to function even in the event of the
failure of kcomponents [Cristian 1991, Nelson 1990]. Therefore, if the system is to be
designed totolerate kfail-stop failures,k+1replicas are needed. If kreplicas arelostdue to
failures, the remaining one replica can beusedfor continued functioning of the system. On
theotherhand,ifthe system isto bedesigned totolerate kByzantine failures, aminimum of
2k+1replicas are needed. This is because a voting mechanism can be used to believe the
majorityk+1ofthereplicas when kreplicas behave abnormally.Sec.1.6 • IssuesinDesigning aDistributed Operating System 2S
Replication and consistency control mechanisms for memory objects are described in
Chapter5 and for file objects are described in Chapter 9.
Another application of redundancy technique is in the design of a stable storage
device, which is a virtual storage device that can even withstand transient 110faults and
decay of the storage media. The reliability of a critical file may be improved by storing
iton a stable storage device. Stable storage devices are described in Chapter9.
2. Distributed control. For better reliability, many of the particular algorithms or
protocols used in a distributed operating system must employ a distributed control
mechanism to avoid single points of failure. For example, a highly available distributed
file system should have multiple and independent file servers controlling multiple and
independent storage devices. In addition to file servers, a distributed control technique
could also be used for name servers, scheduling algorithms, and other executive control
functions. It is important to note here that when multiple distributed servers are used in a
distributed system toprovide a particular typeof service, the servers must be independent.
That is, the design must not require simultaneous functioning ofthe servers; otherwise, the
reliability will become worse instead of getting better.Distributed control mechanisms are
described throughout this book.
FaultDetection and Recovery
The fault detection and recovery method of improving reliability deals with the use of
hardware and software mechanisms to determine the occurrence of a failure and then to
correctthesystemtoastateacceptable forcontinued operation. Someofthecommonly used
techniques for implementing this method inadistributed operating system are asfollows:
1. Atomic transactions. An atomic transaction (or just transaction for short) is a
computation consisting of a collection of operations that take place indivisibly in the
presence of failures and concurrent computations. That is, either all of the operations are
performed successfully or none of their effects prevails, and other processes executing
concurrently cannot modify or observe intermediate states of the computation.
Transactions help to preserve the consistency of a set of shared data objects (e.g., files) in
the face of failures.andconcurrent access. They make crash recovery much easier, because
a transaction can only end in two states: Either all the operations of the transaction are
performed or none of the operations of the transaction is performed.
In a system with transaction facility, if a process halts unexpectedly due to a
hardware fault or a software error before a transaction is completed, the system
subsequently restores any data objects that were undergoing modification to their original
states. Notice that if a system does not support a transaction mechanism, unexpected
failure of a process during the processing of an operation may leave the data objects that
were undergoing modification in an inconsistent state. Therefore, without transaction
facility,itmay be difficult or even impossible in some cases toroll back (recover) the data
objects from their current inconsistent states to their original states. Atomic transaction
mechanisms are described in Chapter9.
2. Stateless servers. Theclient-server model isfrequently used indistributed systems
to service user requests. In this model, a server may be implemented by using anyoneof26 Chap.1 •Fundamentals
the following two service paradigms-stateful or stateless. The two paradigms are
distinguished by one aspect of the client-server relationship, whether or not the history of
the serviced requests between aclient and aserver affects theexecution of the next service
request. The stateful approach does depend on the history of the serviced requests, but the
stateless approach does not depend on it. Stateless servers have a distinctadvantage over
stateful servers inthe event of a failure. Thatis, the stateless service paradigm makes crash
recovery very easy because no client state information is maintained by the server. On the
other hand, the stateful service paradigm requires complex crash recovery procedures.
Both theclientand server need to reliably detect crashes. The server needs to detect client
crashes so that itcan discard any state itis holding for theclient, and the client must detect
server crashes so that it can perform necessary error-handling activities. Although stateful
service becomes necessary in some cases, to simplify the failure detection and recovery
actions, the stateless service paradigm must be used wherever possible. Stateless and
stateful servers are described in Chapters 4 and 9.
3. Acknowledgments and timeout-based retransmissions ofmessages. In a dis­
tributed system, events such as a node crashor a communication link failure may interrupt
acommunication that was in progress between two processes, resulting in the loss of a
message. Therefore, a reliable interprocess communication mechanism must have ways to
detect lost messages so that they can be retransmitted. Handling of lost messages usually
involves return of acknowledgment messages and retransmissions on the basis of
timeouts. That is, the receiver must return an acknowledgment message for every message
received, and if the sender does not receive any acknowledgment for a message within a
fixed timeout period, it assumes that the message was lost and retransmits the message. A
problemassociated with this approach is that of duplicate messages. Duplicate messages
may be sent in the event of failures or because of timeouts. Therefore, a reliable
interprocess communication mechanism should also be capable of detecting and handling
duplicate messages. Handling of duplicate messages usually involves a mechanism for
automatically generating and assigning appropriate sequence numbers to messages. Useof
acknowledgment messages, timeout-based retransmissions of messages, and handling of
duplicate request messages for reliable communication are described in Chapter3.
Themechanisms described above may be employed to create a very reliable
distributed system. However, the main drawback of increased system reliability is
potential loss ofexecution time efficiency due to the extra overhead involved in these
techniques. For many systems it is justtoo costly to incorporate a large number of
reliability mechanisms. Therefore, the major challenge for distributed operating system
designers is to integrate these mechanisms in a cost-effective manner for producing a
reliable system.
1.6.3Flexibility
Another important issue in the design of distributed operating systems is flexibility.
Flexibility is the most important feature for open distributed systems. The design of a
distributed operating system should be flexible due to the following reasons:Sec.1.6 • Issuesin Designing aDistributed Operating System 27
1. Easeofmodification. From the experience of system designers, it has been found
that some parts of the design often need to be replaced/modified eitherbecausesome bug
isdetected in the design or because the design isno longer suitable for the changedsystem
environment ornew-user requirements. Therefore, itshould be easy to incorporate
changes in the system in a user-transparent manner or with minimum interruption caused
to the users.
2. Easeofenhancement. In every system, new functionalities have to be added from
time to time to make it more powerful and easy to use. Therefore, it should be easy to add
new services to the system. Furthermore, ifa group of users do not like the style in which
aparticular service is provided by theoperating system, they should have the flexibility
to add and use their own service that works in the style with which the users of that group
are more familiar and feel more comfortable.
The most important design factor that influences the flexibility of a distributed
operating system is the model used for designing its kernel. The kernelof anoperating
system is its central controlling part that provides basic system facilities. It operates in a
separate address space that is inaccessible to user processes. It is the only part of an
operating system that a user cannotreplace or modify. We saw that in the case of a
distributed operating system identical kernels are run on all the nodes of the distributed
system.
The two commonly used models for kernel design in distributed operating systems
are themonolithic kernel and the microkernel (Fig. 1.6). In the monolithic kernelmodel,
mostoperating system services such as process management, memory management,
devicemanagement, filemanagement, namemanagement, andinterprocess communica­
tion areprovided bythe kernel. As a result, the kernelhas a large, monolithic structure.
Manydistributed operating systems that are extensions or imitations ofthe UNIX
operating system use the monolithic kernel model. This is mainly because UNIX itselfhas
a large,monolithic kernel.
On the other hand, in the microkernel model, the main goal is to keep the kernel as
small as possible. Therefore, in this model, the kernel is a very small nucleus of software
that provides only the minimal facilities necessary for implementing additional operating
system services. The only services provided by the kernel in this model are interprocess
communication, low-level devicemanagement, a limited amount of low-level process
management, and some memory management. All other operating system services, such
as filemanagement, namemanagement, additional process, and memory management
activities, and much system call handling are implemented as user-level server processes.
Each server process has its own address space and can be programmed separately.
Ascompared to themonolithic kernel model, the microkernel model has several
advantages. In the monolithic kernel model, the large size of the kernel reduces the overall
flexibility and configurability of the resulting operating system. On the other hand, the
resulting operating system of the microkernel model is highly modular in nature. Due to
thischaracteristic feature, the operating system of the microkernel model iseasy to design,
implement, and install. Moreover, since most of the services are implemented as user-level
serverprocesses, itis also easy to modify the design or add new services. This also allows28
Node1 Node 2Chap.1 • Fundamentals
Noden
User User User
applications applications applications
...
Monolithic kemel Monolithic kernel Monolithic kernel
(includesmost (Includesmost (includesmostasservices) OSservices) OSservices)
INetworkhardware I
(a)
Node1 Node2 Noden
User User User
applications applications applications
Server/manager Server/manager ... server/manager
modules modules modules
Mlcrokemel Microkemel MicrokerneJ
(hasonlyminimal (hasonlyminimal (hasonlyminimal
facilities) facilities) facilities)
INetworkhardware I
(b)
Fig.l.6 Models of kernel design in distributed operating systems: (a)The monolithic
kernel model. The level above the kernel level can be partitioned by the
users into whatever hierarchical levels are appropriate. (b)Themicrokernel
model. Although the figure shows a two-level heirarchy above the kernel
level, users can extend the hierarchy to whatever levels are appropriate.
those users who do not like a particular service provided by the operating system to
implement and use their own service. Furthermore, for adding orchanging a service, there
is no need to stop the system and boot a new kernel, as in the case ofa monolithic kernel.
Therefore, changes in the system can be incorporated without interrupting the users.
The modular design of a system based on the microkemel model, however, is
potentially subject to a performance penalty. This is because in the microkernel model
each server is an independent process having itsown address space.Therefore, the servers
have to use some form of message-based interprocess communication mechanism to
communicate with each other while performing some job. Furthermore, message passing
between server processes and the microkernel requires context switches, resulting in
additional performance overhead. In the monolithic kernel model, however, since all the
services are provided by the kernel, the same address space is shared by all of them.
Therefore, no message passing and no context switching are required while the kernel is
performing thejob. Hence a request may be servicedfaster in themonolithic kernel model
than in the microkemel model.Sec.1.6•IssuesinDesigning aDistributed Operating System 29
In spite of its potential performance cost, the microkemel modelis being preferred
for the design of modemdistributed operating systems. The two mainreasons for this are
as follows:
1. The advantages of the microkemel model more than compensate for the
performance cost. Notice thatthe situation here is very similar to theone that caused high­
levelprogramming languages to be preferred to assembly languages. In spite of the better
performance of programs written in assembly languages, most programs are written in
high-level languages due totheadvantages ofease ofdesign, maintenance, and portability.
Similarly, the flexibility advantages of the microkernel model previously described more
than outweigh its small performance penalty.
2. Some experimental results have shown that although in theory the microkernel
model seems to have poorer performance than the monolithic kernelmodel, this isnot true
in practice. This is because other factors tend to dominate, and the small overhead
involved in exchanging messages is usually negligible [Douglis et a1.1991].
Details of several distributed operating systems whose design is based on the
microkernel model are presented in Chapter12.
1.6.4Performance
If a distributed system is to be used, its performance must be at least as good as a
centralized system. That is, when a particular application is run on a distributed system,
its overall performance should be better than or at least equal to thatof running the same
application on a single-processor system. However, to achieve this goal, itisimportant
that the various components of the operating system of a distributed system bedesigned
properly; otherwise, the overall performance of thedistributed systemmay turn out to be
worse than a centralized system. Some design principles considered useful for better
performance are as follows:
1. Batchifpossible. Batching often helps in improving performance greatly. For
example, transfer of data across the network in large chunks rather than as individual
pages is much more efficient. Similarly, piggybacking of acknowledgment of previous
messages with the next message during a series of messages exchanged between two
communicating entities also improves performance,
2. Cache whenever possible. Caching of data at clients'sites frequently improves
overall system performance because it makes data available whereverit is being currently
used, thus saving a large amount of computing time and network bandwidth. In addition,
caching reduces contention on centralized resources.
3. Minimize copyingofdata.Data copying overhead (e.g., movingdata in and out of
buffers) involves a substantial CPU cost of many operations. For example, while being
transferred from its sender to its receiver, a message data may takethe following path on
the sending side:30 Chap.1 •Fundamentals
(a) From sender'sstack to its message buffer
(b) From the message buffer in the sender's address space to the message buffer in
thekernel'saddress space
(c) Finally, from the kernel to the network interface board
On the receiving side, the data probably takesa similar path in the reverse direction.
Therefore, in this case, a total of six copy operations are involved in the message transfer
operation. Similarly, in several systems, the data copying overhead is also large for read
and write operations on block 1/0devices. Therefore, for better performance, it is
desirable to avoid copying of data, although thisis not always simple to achieve. Making
optimal use of memory management often helps in eliminating much data movement
between the kernel, block 1/0devices, clients, and servers.
4.Minimize networktraffic.System performance may also be improved by reducing
internode communication costs. For example, accesses to remote resources require
communication, possiblythrough intermediate nodes.Therefore, migrating aprocesscloser
to the resources it is using most heavily may behelpful in reducing network traffic in the
systemifthedecreased cost of accessing itsfavoriteresource offsets thepossible increased
costofaccessing its less favored ones. Another wayto reduce network traffic is to use the
process migration facility to clustertwo or more processes that frequently communicate
with each other on the same node of the system. Avoiding the collection of global state
information formaking some decision also helps inreducing network traffic.
5.Takeadvantage offine-grain parallelismfor multiprocessing. Performance canalso
beimproved by taking advantage offine-grain parallelism for multiprocessing. For
example, threads (described in Chapter8) are often used for structuring server processes.
Servers structured as a group of threads can operate efficiently because they can
simultaneously service requests from several clients. Fine-grained concurrency control of
simultaneous accesses by multiple processes to a shared resource is another example of
application ofthis principle for better performance.
Throughout the book we will come across the use of these design principles in the
design ofthe various distributed operating systemcomponents.
1.6.5SCQlablllty
Scalability refers to the capability of a system to adapt to increased service load. It is
inevitable that adistributed system will grow withtimesince itis very common toadd new
machines or an entire subnetwork to the system to take care ofincreased. workload or
organizational changes in a company. Therefore, a distributed operating system should be
designed to easily cope with the growth of nodes and users in the system. That is, such
growth should not cause serious disruption of serviceor significant loss ofperformance to
users. Someguiding principles for designing scalabledistributed systems are as follows:
1. Avoid centralized entities.In the design of a distributed operating system, use of
centralized entities such as a single central file server or a single database for the entire
system makes the distributed system nonscalable due to the following reasons:Sec. 1.6 • Issuesin Designing aDistributed Operating System 31
(a) The failure of the centralized entity often brings the entire system down. Hence,
the system cannot tolerate faults in a graceful manner,
(b) Theperformance of thecentralized entity often becomes a system bottleneck
whencontention foritincreases with the growing numberof users.
(c) Even if the centralized entity has enough processing and storage capacity, the
capacity of the network that connects thecentralized entity with other nodes of
the system often gets saturated when the contention for the entity increases
beyond a certain level.
(d) In a wide-area network consisting of several interconnected local-area networks,
it isobviously inefficient to always get a particular typeofrequest serviced at a
server node that is several gateways away. This also increases network traffic.
Local area and wide-area networking concepts aredescribed inChapter2.
Therefore, the use of centralized entities should be avoided in the design. Replication
of resources and distributed controlalgorithms are frequently used techniques to achieve
this goal. In fact, for better scalability, as far as practicable, a functionally symmetric
configuration should be used inwhich all nodes of the system have a nearly equal role to
play in the operation of the system.
2. Avoid centralized algorithms. Acentralized algorithm is one that operates by
collecting information fromallnodes,processing thisinformation on a single node and
thendistributing the results toother nodes. The use of such algorithms in the design of a
distributed operating system isalso not acceptable from ascalability point of view. The
reasons for this are very similar to those mentioned in the use of centralized entities. For
example, a scheduling algorithm that makes scheduling decisions by first inquiring from
all the nodes and then selecting the most lightly loaded node as a candidate for receiving
jobs has poor scalability factor.Such an algorithm mayworkfine for small networks but
gets crippled when applied to largenetworks. This is because the inquirer.receives a very
large number of replies almost simultaneously and the time required to process the reply
messages for making a host selection is normally too long. Moreover, since the
complexity of the algorithm is O(n2),it creates heavy network traffic and quickly
consumes network bandwidth. Therefore, in the design of a distributed operating system,
onlydecentralized algorithms shouldbe used. In these algorithms, global state information
ofthe system is not collected or used, decision at a node is usually based on locally
available information, and it isassumed that a systemwide global clock does not exist (the
clocks of all nodes are not synchronized).
3. Perform most operations on client workstations. If possible, an operation should
be performed on the client'sownworkstation rather than on a server machine. This is
because a server is a common resource for several clients, and hence server cycles are
more precious than the cycles of client workstations. This principle enhances the
scalability of the system, since it allows graceful degradation of system performance as
the system grows in size, by reducing contention for shared resources. Caching is a
frequently used technique for the realization of this principle.
Throughout the book, wewill come across the use of these design principles in the
design of the various distributed operating systemcomponents.32 Chap.I •Fundamentals
A heterogeneous distributed system consists of interconnected sets of dissimilar
hardware or software systems. Because ofthe diversity, designing heterogenous
distributed systems is far more difficult than designing homogeneous distributed
systems in which each system is based on the same, or closely related, hardware
and software. However, as a consequence oflarge scale, heterogeneity is often
inevitable indistributed systems. Furthermore, oftenheterogeneity is preferred by
many users because heterogeneous distributed systems provide the flexibility to their
users of different computer platforms for different applications. For example, a user
may have the flexibility of a supercomputer for simulations, a Macintosh for
document processing, and a UNIX workstation for program development.
Incompatibilities in aheterogeneous distributed system may be of different
types. For example, the internal formatting schemes of different communication
and host processors may be different; or when several networks are interconnected
via gateways, the communication protocols and topologies of different networks
may be different; or the servers operating at different nodes of the system may
be different. For instance, some hosts use 32-bit word lengths while others use
word lengths of 16 or 64 bits. Byte ordering within these data constructs can
vary as well, requiring special converters to enable data sharing between incom­
patible hosts.
In a heterogeneous distributed system, some form of data translation is neces­
sary for interaction between two incompatible nodes. Some earliersystems left this
translation to the users, but this is no longer acceptable. The data translation job
may be performed either at the sender's node or at the receiver's node. Suppose
thisjobis performed at the receiver's node. With this approach, at every node
there must be a translator to convert each format in the system to the format used
on the receiving node. Therefore, if there are ndifferent formats, n-1 pieces of
translation software must besupported at each node, resulting ina total of n(n-1)
pieces of translation software in the system. This is undesirable, as adding a new
typeofformat becomes a more difficult task over time. Performing the translation
jobat thesender's node instead of the receiver's node also suffers from the same
drawback.
The software complexity ofthis translation process can begreatly reduced by
using an intermediate standard data format. In this method, an intermediate standard
data format is declared, and each node only requires a translation software for
converting from its own format to the standard format and from the standard format
to its own format. In this case, when two incompatible nodesinteractat the sender
node, the data to be sent is first converted to the standard format, the data is moved
in the format of the standard, and finally, at the receiver node, the data is converted
from the standard format to the receiver's format.Bychoosing the standard format to
be the most common format in the system, the number of conversions canbe
reduced.
Various techniques to deal with heterogeneity indistributed systems are described
in Chapters 2, 4, 5, and 8.Sec.1.6 • Issuesin Designing aDistributed Operating System
1.6.7Security33
Inorderthat the users can trust the systemand rely on it, the various resources ofa
computer system must be protected againstdestruction andunauthorized access.
Enforcing security in a distributed systemis more difficult than in a centralized
systembecause ofthe lack of a single point ofcontrol and the use ofinsecure
networks for data communication. In acentralized system,allusers are authenticated
by the system at login time, and the system can easilycheckwhether a user is
authorized toperform therequested operation on anaccessed resource. In a dis­
tributed system, however, since the client-server model is oftenused for requesting
andproviding services, when a client sends a requestmessage to a server, the server
must have some way· ofknowing who is the client. This is not so simple as it might
appearbecause any clientidentification field in the message cannotbe trusted. This
isbecause anintruder (a person or program trying to obtainunauthorized access to
systemresources) maypretendto be an authorized clientor may change the message
contents duringtransmission. Therefore, ascompared to acentralized system,
enforcement ofsecurity in adistributed system has the following additional
requirements:
1. It should be possible for thesenderof amessage to know that the message was
received by the intended receiver.
2. It should be possiblefor thereceiverof amessage to know that the message was
sent by the genuinesender.
3. It should be possible for both the senderandreceiver of amessage to be
guaranteed that the contents of the message were not changed while it was in
transfer.
Cryptography (described inChapter 11) is the only known practical methodfor
dealing with these security aspects of a distributed system. In this method, comprehension
ofprivateinformation isprevented byencrypting theinformation, which can then be
decrypted only byauthorized users.
Another guidingprinciple for security is that a systemwhose security depends on
the integrity of the fewest possible entitiesis more likely to remainsecure as it grows.
Forexample, it is much simplerto ensure securitybased on the integrity ofthe much
smallernumber of servers rather than trustingthousands ofclients. In this case, it is
sufficient to only ensure the physical security ofthese servers and the software they
run.Chapter 11 deals with the commonly usedtechniques fordesigning secure
distributed systems.
1.6.8Emulation ofExistingOpcsrating Systems
Forcommercial success, it is important that a newly designed distributed operating system
be able to emulateexistingpopularoperating systemssuch as UNIX. With this property,
newsoftware can be written using the system call interface ofthe newoperating system34 Chap.I •Fundamentals
to take full advantage of its special features of distribution, but a vast amount of already
existing old software can also be runon the same system without the need torewrite them.
Therefore, moving to the new distributed operating system will allow both types of
software to berun side by side.
We will see in Chapter 12 how some of the existing distributed operating systems
have been designed to support UNIX emulation facility.
1.7INTRODUmON TODISTRIBUTED COMPunNG
ENVIRONMENT (DeE)
Chapter 12 of the book presents case studies of four distributed operating systems:
Amoeba, V-System, Mach, and Chorus. In addition, examples of key technologies of
individual distributed operating system components that have either become or are poised
to become de facto international standards are presented in individual chapters wherever
such industry examples are available. In particular, the following technologies are
presented as case studies:
• Ethernet, IEEE Token Ring, the Internet Protocol suite, and the Internet are
presented as case studies of networking technologies in Chapter2.
• The 4.3BSD UNIX interprocess communication mechanism is presented as a case
study of message-passing technology in Chapter 3.
• SUN RPC and DeERPC are presented as case studies of Remote Procedure Call
(RPC) technology in Chapter 4.
• IVY and Munin are presented as case studies of Distributed Shared Memory
(DSM) technology in Chapter 5.
• DCE Distributed Time Service (DTS) is presented as a case study of clock
synchronization technology in Chapter 6.
• The DCE threads package is presented as a case study of threads technology in
Chapter 8.
•DeEDistributed File Service (DFS) ispresented as a case study of distributed file
system technology in Chapter 9.
• The various components of DeEnaming facility are presented as case studies of
naming technology in Chapter 10.
• The Kerberos authentication system and DeESecurity Service are presented as
case studies of security technology in Chapter 11.
Notice from the above list that almost half of the key technologies presented as case
studies in the variouschapters of this book aretools and services that belong to DCE.This
is because of the way in which DCE was created (described next). Therefore, for a better
understanding of these key technologies, it will be useful to know something about DCE
before going into the details of its key components. This section presents a brief
introduction to DCE.Sec.1.7 • Introduction toDistributed Computing Environment (DeE)
1.7.1WhatIsDeE?35
Avendor-independent distributed computing environment, DCE was defined by the Open
Software Foundation (OSF), a consortium ofcomputer manufacturers, including IBM,
DEC, and Hewlett-Packard. It is not an operating system, nor is it an application. Rather,
itis anintegrated setofservices and tools that can be installed as a coherent environment
on top of existingoperating systems and serve as a platform for building and running
distributed applications.
A primary goal of DeEis vendor independence. It runs on many different kinds of
computers, operating systems, and networks produced by different vendors. For example,
some operating systems to which DeEcan be easily ported include OSF/I,AIX,
DOMAIN OS, ULTRIX, HP-UX, SINIX, SunOS, UNIX System V, VMS, WINDOWS,
and OS/2. On the other hand, it can be used with any network hardware and transport
software, including TCPIIP, X.25, as welJ as other similarproducts.
As shown in Figure 1.7, DeEis amiddleware software layered between the DCE
applications layer and the operating system and networking layer.The basic idea is to take
acollection of existing machines (possibly from different vendors), interconnect them by
acommunication network, add the DCE software platform on top of the native operating
systems of the machines, and then be able to build and run distributed applications. Each
machine has its own local operating system, which may be different from that of other
machines. The DeEsoftware layer on top of the operating system and networking layer
hides the differences between machines byautomatically performing data-type conver­
sions when necessary. Therefore, theheterogeneous nature of the system is transparent to
theapplications programmers, making their jobof writing distributed applications much
simpler.
DCEapplications
DCE software
Fig.J.7Position ofDeEsoftware in a
DeE-based distributed system.
1.7.2 How Was DCECreated?Operating systemsandnetworking
TheaSFdid not create DeEfrom scratch. Instead, it created DCE by taking
advantage of work already done at universities and industries in the area of
distributed computing. For this, OSF issued a requestfor technology (RFT), asking
for tools and services needed to build a coherent distributed computing environment.
To be a contender, a primary requirement was that actual working code must
ultimately be provided. The submitted bids were carefully evaluated by OSF employ­
ees and a team ofoutside experts. Finally, those tools and services were selected that
themembers of theevaluation committee believed provided the best solutions. The
codecomprising the selected tools and services, almost entirely written in C, was36 Chap.1 • Fundamentals
thenfurtherdeveloped byOSFtoproduce asingleintegrated package that was made
available to theworldas DCE. Version 1.0 ofDCEwasreleased byOSFinJanuary
1992.
1.7.3DeECOmpo.Ats
Asmentioned above,DeEis a blend ofvarioustechnologies developed independently
andnicelyintegrated by OSF. Each of these technologies forms acomponent ofDCE. The
maincomponents ofDeEare as follows:
1. Threads package. Itprovides asimpleprogramming modelforbuilding
concurrent applications. Itincludes operations tocreateandcontrol multiple threadsof
execution in a single process and tosynchronize access to globaldatawithinan
application. Detailsare given in Chapter8.
2. Remote ProcedureCall (RPC)facility. Itprovides programmers with anumberof
powerful toolsnecessary to buildclient-serverapplications. In fact, the DCERPC facility
is thebasisfor allcommunication in DCEbecausetheprogramming modelunderlying all
ofDCEis theclient-server model. It is easy to use, is network- andprotocol-independent,
provides securecommunication between aclientand a server, and hidesdifferences in
datarequirements byautomatically converting data to the appropriate formsneededby
clientsand servers. Detailsare given in Chapter4.
3. Distributed limeService (DTS). Itcloselysynchronizes theclocksofall the
computers in the system. It also permitsthe useoftimevaluesfromexternaltimesources,
such as those oftheu.s.National Institute forStandards andTechnology (NIST), to
synchronize theclocksofthecomputers in thesystemwithexternaltime. This facility can
also be used to synchronize theclocksof thecomputers ofonedistributed environment
with the clocksofthecomputers ofanotherdistributed environment. Detailsare given in
Chapter6.
4. Name services. The name servicesofDCEincludetheCellDirectory Service
(CDS),theGlobalDirectory Service(GDS),and theGlobalDirectory Agent(GDA).
Theseservices allowresources such asservers,files,devices, and so on, to be uniquely
namedandaccessed in alocation-transparent manner.DetailsaregiveninChapter 10.
5. Security Service. Itprovides the tools neededforauthentication andauthorization
toprotectsystemresources againstillegitimate access.DetailsaregiveninChapter 11.
6. Distributed FileService(DFS). Itprovides asystemwide filesystemthat has such
characteristics aslocationtransparency, highperformance, and high availability. Aunique
featureofDeEDFS is that it can also providefileservicestoclientsofotherfilesystems.
DetailsaregiveninChapter9.
TheDCEcomponents listedabove are tightly integrated. It isdifficult to give a
pictorial representation oftheirinterdependencies because they are recursive. For
example, the name services use RPC facility for internalcommunication among itsSec.1.7 • Introduction toDistributed Computing Environment (DeE) 37
various servers, but the RPC facility uses the name services to locate the destination.
Therefore, the interdependencies of the various DeEcomponents can be best depicted in
tabular form, as shown in Figure 1.8.
Fig. 1.8 Interdependencies ofDCE
components.Component Othercomponents usedbyIt
name
Threads None
RPe Threads,name,security
DTS Threads,RPC,name,security
Name Threads,RPe,DTS,security
Security Threads,RPC,DTS,name
DFS Threads,RPC,DTS,name,security
1.7.4DeE(.lIs
TheDeEsystem is highly scalable in the sense that a system running DeEcan have
thousands of computers and millions of users spread over a worldwide geographic area.
Toaccommodate such large systems, DCE uses the concept of cells. This concept helps
break down a large system into smaller, manageable units called cells.
In aDeEsystem, a cellis a group of users, machines, or other resources that
typically have a common purpose and share common DCE services. The minimum cell
configuration requires a cell directory server, a security server, a distributed time server,
and one or more client machines. Each DeEclient machine has client processes for
security service, cell directory service, distributed time service, RPC facility, and threads
facility.A DCE client machine may alsohave a process for distributed file service if acell
configuration has aDeEdistributed file server. Due to the use of the method of
intersection for clock synchronization (described in Chapter 6),it is recommended that
each cell in a DeEsystem should have at least three distributed time servers.
Animportant decision to bemade while setting up a DCE system is todecide the cell
boundaries. The following four factors should be taken into consideration for making this
decision [Tanenbaum 1995, Rosenberry et al. 1992, aSF1992]:
1. Purpose. The machines of users working on a common goa) should be put in the
same cell, as they need easy access to a common set of system resources. That is, users
of machines in the same cell have closer interaction with each other than with users of
machines in different cells. For example, if a company manufactures and sells various38 Chap.1 •Fundamentals
types of products, depending on the manner in which the company functions, either a
product-orientedor a function-orientedapproachmay be takento decide cell boundaries
[Tanenbaum 1995].In the product-orientedapproach, separatecells are formed for each
product, with the usersof the machinesbelongingto the samecell being responsible for
all types of activities(design, manufacturing,marketing,andsupport services) related to
oneparticularproduct.Ontheotherhand,inthe function-oriented approach,separatecells
are formed for each type of activity, with the users belonging to the same cell being
responsible for a particular activity,such as design, of all types of products.
2. Administration. Each system needs an administratorto register new users in the
systemandtodecidetheiraccessrightstothesystem'sresources.Toperformhisorherjob
properly,anadministratormustknowtheusersandtheresourcesof thesystem.Therefore,
to simplify administrationjobs, all the machines and their users that are known to and
manageableby an administratorshouldbe put in a singlecell.For example, all machines
belongingtothesamedepartmentofacompanyora universitycan belongtoasinglecell.
Fromanadministrationpointofview,eachcellhasadifferentadministrator.
3. Security. Machinesof those users who have greatertrust in each other should be
put in the same cell. That is, users of machinesof a cell trusteach other more than they
trust the users of machines of other cells. In such a design, cell boundaries act like
firewalls in the sensethat accessinga resourcethat belongstoanother cell requires more
sophisticated authenticationthan accessinga resource that belongs to a user's own cell.
4. Overhead. SeveralDeEoperations,suchas nameresolutionand user authentica­
tion, incur more overhead when they are performed between cells than when they are
performedwithinthesamecell.Therefore,machinesofuserswhofrequentlyinteractwith
each other and the resources frequentlyaccessed by them should be placed in the same
cell. The need to access a resource of another cell should arise infrequently for better
overall system performance.
Noticefromtheabovediscussionthatindeterminingcellboundariestheemphasisis
on purpose, administration, security,and performance.Geographicalconsiderations can,
butdo nothaveto, playapartincelldesign.Forbetterperformance,itisdesirabletohave
as few cells as possible to minimize the number of operations that need to cross cell
boundaries. However,subject to securityand administrationconstraints, it is desirable to
have smaller cells with fewer machinesand users. Therefore, it is important to properly
balancetherequirementsimposedbythefourfactorsmentionedabovewhiledecidingcell
boundaries in a DeEsystem.
1.8SUMMARY
A distributed computing system is a collection of processors interconnected by a
communication network in which each processor has its own local memory and other
peripheralsandcommunicationbetweenany two processorsofthe system takes place by
message passing over the communication network.Chap. I • Exercises 39
Theexistingmodels for distributed computing systems can be broadly classified into
fivecategories: minicomputer, workstation, workstation-server, processor-pool, and
hybrid.
Distributed computing systems are muchmore complex and difficultto build than the
traditional centralized systems. Despite the increased complexity and the difficulty of
building, the installation and use of distributed computing systems are rapidly increasing.
This is mainly because the advantages ofdistributed computing systemsoutweigh its
disadvantages. The main advantages of distributed computing systems are (a) suitability
forinherently distributed applications, (b)sharing of information amongdistributed users,
(c) sharing of resources, (d) better price-performance ratio, (e) shorterresponse times and
higher throughput, (f)higher reliability, (g) extensibility andincremental growth, and (h)
better flexibility in meeting users' needs.
Theoperating systemscommonly used for distributed computing systems can be
broadlyclassified into two types: network operating systems and distributed operating
systems. As compared to anetworkoperating system, a distributed operating system has
bettertransparency and fault tolerance capability and provides the image of a virtual
uniprocessor to the users.
The main issues involved in the design ofadistributed operating system are
transparency, reliability, flexibility, performance, scalability, heterogeneity, security, and
emulation ofexistingoperating systems.
EXERCISES
1.1. Differentiate among the following types of operating systems by defining their essential
properties:
(a) Time sharing
(b)Parallel processing
(c)Network
(d) Distributed
1.2.In what respect are distributed computingsystems better than parallel processing systems?
Give examples of three applications for whichdistributed computing systems will be more
suitable than parallel processingsystems.
1.3. What were the major technological, economical, and social factors that motivated the
development of distributed computingsystems?What are some of the main advantages and
disadvantages of distributed computingsystemsover centralized ones?
1.4.Discuss the relativeadvantagesand disadvantages of the variouscommonlyused modelsfor
configuringdistributedcomputing systems.Whichmodeldo youthinkisgoingtobecomethe
most popular model in future? Give reasonsfor your answer.
1.5.Consider thecase of a distributedcomputingsystem based on the processor-poolmodel that
hasPprocessors in the pool. In this system, suppose a user starts a computation job that
involvescompilation of a program consistingof Fsource files (F<P).Assume that at this
time this user is the only user usingthesystem.What maximumgain in speedcan be hoped
for thisjob in thissystemas comparedtoitsexecutionon a single-processorsystem(assume
that alltheprocessorswearetalkingaboutareofequalcapability)?Whatfactorsmightcause
the gain in speed to be less than this maximum?40 Chap. 1 • Fundamentals
1.6. Explainthe difference betweenthe terms serviceandserver.In thedesignof a distributed
operating system,discusstherelative advantages anddisadvantages of usinga singleserver
andmultipleserversforimplementing aservice.
1.7.Why aredistributed operating systemsmoredifficultto designthanoperatingsystemsfor
centralized time-sharing systems?
1.8.What is groupware? Why is it considered tobeapromising technology forsoftware
development?
1.9.Whatarethemain differences betweena networkoperating systemanda distributed operating
system?
1.10. Whatare the majorissuesin designing adistributed operating system?
1.11. Adistributed operating systemmakesa collection ofnetworked machines toactlikeavirtual
uniprocessor. Whatare the main advantages of thisvirtual-machine architecture for a user?
What issues are important for adistributed operating system designer in achieving this
goal?
1.12.Concurrency transparency is animportant issue in the design of a distributed operating
system.Is it alsoan important issuein thedesignof an operating systemfor a centralized
system?Ifno, explainwhy.Ifyes,listsome mechanisms thatarecommonly usedinoperating
systemsfor centralized systemsto supportthis feature.
1.13.Discusssomeofthe important conceptsthata distributed operating systemdesignermightuse
to improvethe reliability ofhisorher system.Whatisthemain probleminmakingasystem
highlyreliable?
1.14.Differentiate betweenthemonolithic kernelandmicrokernel approaches fordesigning a
distributed operating system.Discusstheir relativeadvantages anddisadvantages.
1.15. In the microkernel approach fordesigning adistributed operating system, what are the
primarytasksthatthekernelmust perform?
1.16. Figure 1.6 indicatesthata layered approachis usedtodesigna distributed system.Whatare
the mainadvantages of usingthis approach?
1.17.Discussthemainguiding principles thatadistributed operating systemdesignermustkeepin
mindfor the good performance of hisor her system.
1.18.Whyisscalability animportant featurein thedesignof a distributed system?Discusssome
of the guiding principles fordesigning ascalabledistributed system.
1.19.Why isheterogeneity unavoidable in manydistributed systems? What are some of the
commontypesof incompatibilities encountered inheterogeneous distributed systems?What
arethe commonissueswithwhichthedesignerof a heterogeneous distributed systemmust
deal?
1.20.Suppose a component ofadistributed systemsuddenly crashes.How will this event
inconvenience theuserswhen:
(a) The systemusesthe processor-pool modelandthecrashed component is aprocessor
in the pool.
(b) The system uses the processor-pool modeland the crashed component is a user
terminal.
(c) Thesystemusesthe workstation-server modelandthecrashed component is a server
machine.
(d) The systemuses the workstation-server modeland the crashed component is a user
workstation.Chap. 1 • Bibliography 41
1.21. Compare the following types of systems in terms of cost, hardware complexity,operating
system complexity,potential parallelism,and programmability (how easily users can write
efficient programs):
(a) A multiprocessorsystem havinga singleshared memory.
(b)Amultiprocessorsysteminwhicheachprocessorhasitsownlocalmemoryinaddition
toashared memory used by allprocessors inthe system.
(c) A multiprocessorsystemin whicheachprocessorhas itsownmemory.Allprocessors
are kept in a big hall and are interconnectedby a high-capacitycommunicationline
forming a network. Each processorcan communicatewith other processorsonly by
exchanging messages.
(d) Amultiprocessor system in which each processor has its own memory. The
processors are located far from each other (may bein different cities of acountry)
and are interconnected by a low-capacity communication line forming a network.
Each processor can communicate with other processors only by exchanging
messages.
For comparingthe systems,considerthree cases-(a) numberof processorsis small (2-8);
(b) numberof processorsis large (16-32);and(c) numberof processorsis verylarge(more
than100).
BIBLIOGRAPHY
[Accetta et al.1986]Accetta,M., Baron,R., Golub,D., Rashid,R.,Tevanian,A., and Young,M.,
"Mach:ANewKernelFoundationforUNIXDevelopment,"In: Proceedings ofthe Summer 1986
USENIX Technical Conference, pp.93-112(July1986).
[Avresky andPradhan 1996]Avresky,D.,and Pradhan, D. (Eds.), Fault-Tolerant Parallel and
Distributed Systems, IEEEComputer SocietyPress,LosAlamitos, CA (1996).
[Black et al. 1992] Black, D. L., Golub, D. B., Julin, D. P.,Rashid, R. F., Draves, R. P.,Dean, R.
W., Forin, A.,Barrera, L, Tokuda, H., Malan, G., and Bohman, D., "Microkernel Operating
SystemArchitectureand Mach,"In: Proceedings ofthe USENIX Workshopon Microkernels and
Other Kernel Architectures, USENIX, pp.11-30(1992).
[BoykinandLoVerso 1990] Boykin, J., andLoVerso,l,"Recent Developments in Operating
Systems," IEEE Computer, pp.5-6(May1990).
[BrazierandJohansen 1993]Brazier,F.,andJohansen,D. (Eds.),Distributed Open Systems, IEEE
ComputerSociety Press,Los Alamitos,CA (1993).
[Butler1993]Butler,M.,Client Server, Prentice-Hall, London,UK(1993).
[Casavant andSinghal1994]Casavant, T. L.,and Singhal, M. (Eds.), Readings inDistributed
Computing Systems, IEEEComputerSocietyPress,LosAlamitos, CA (1994).
[Cheriton 1984]Cheriton, D. R.,"TheVKernel:ASoftwareBaseforDistributedSystems," IEEE
Software, Vol.1,No.2,pp.19-42(1984).
[Cheriton 1988]Cheriton, D. R.,"TheVDistributedSystem," Communications ofthe ACM, Vol.
31,No.3,pp.314-333 (1988).
[Coulouris etal,1994] Coulouris, G. F., Dollimore,1., and Kindberg, T., Distributed Systems
Concepts and Design, 2nd ed.,Addison-Wesley, Reading,MA (1994).
[Cristian-1991] Cristian,F.,"Understanding Fault-Tolerant DistributedSystems," Communications
ofthe ACM, Vol.34,pp.56-78(February 1991).42 Chap.1 •Fundamentals
[Critchley and Batty 1993] Critchley, T.,andBatty,K., Open Systems: The Reality, Prentice-Hall,
London, UK(1993).
[Deitel1990] Deitel, H. M., An Introduction to Operating Systems, 2nd ed.,Addison-Wesley,
Reading,MA (1990).
(Douglis et al, 1991]Douglis,F., Ousterhout,1. K., Kaashoek, M. F.,and Tanenbaum, A. S., "A
ComparisonofTwoDistributedSystems:Amoebaand Sprite," Computing Systems, Vol.4, pp.
353-384 (1991).
[Ghafoor andYang 1993J Ghafoor, A., and Yang,J., "A Distributed Heterogeneous Super­
computingManagementSystem," IEEE Computer, Vol.26,No.6,pp.78-86(1993).
[Gien 1990] Gien, M., "Micro-Kernel Architecture: Key to ModernOperatingSystemsDesign,"
UNIX Review, p. 10(November1990).
[GienandGrob1992]Gien, M., and Grob,L., "Microkernel BasedOperatingSystems:Moving
UNIX on to ModernSystemArchitectures,"In: Proceedings oftheUniForum'92 Conference,
USENIX,pp. 43-55(1992).
[Golubetal,1990] Golub, D., Dean, R., Forin,A., and Rashid, R., "UNIX as an Application
Program,"In: Proceedings ofthe Summer 1990 USENIX Conference, USENIX,pp.87-95 (June
1990).
(Goscinski 1991] Goscinski,A., Distributed Operating Systems, The Logical Design, Addison­
Wesley,Reading,MA (1991).
[Haririet al.1992] Hariri, S., Choudhary, A., and Sarikaya, B,"Architectural Support for
Designing Fault-Tolerant OpenDistributedSystems," IEEE Computer, Vol.25,No.6,pp.50-62
(1992).
[Hunter1995]Hunter,P., Network Operating Systems: Making the Right Choice, Addison-Wesley,
Reading,MA (1995).
[Islam1996] Islam, N., Distributed Objects: Methodologies for Customizing Operating Systems,
IEEEComputerSocietyPress,LosAlamitos,CA (1996).
[ISO1992]Basic Reference Model ofOpen Distributed Processing, Part 1:Overview and Guide to
Use,ISO/IECJTCI/SC212IWG7 CDI0746-1, International StandardsOrganization(1992).
[Jalote1994JJalote, P., Fault Tolerance in Distributed Systems, Prentice-Hall, EnglewoodCliffs,
NJ(1994).
[Khanna 1994]Khanna. R. (Ed.), Distributed Computing: Implementation and Management
Strategies, Prentice-Hall, EnglewoodCliffs,NJ (1994).
[Khokhar et al.1993]Khokhar, A., Prasanna, V.K., Shaaban, M. E., and Wang, C. L.,
"Heterogeneous Computing: Challengesand Opportunities," IEEE Computer, Vol.26,No.6, pp.
18-27(1993).
[Lampson 1983]Lampson,B.W.,"HintsforComputerSystemDesign,"In: Proceedings ofthe 9th
Symposium on Operating Systems Principles (October1983).
[Lamport et al.1982]Lamport,L.,Shostak,R.,andPease,M.,"TheByzantineGeneralsProblem,"
ACMTransactions on Programming Languages and Systems, Vol.4,No.3,pp. 382-401
(1982).
[Lelann1981]Lelann,G.,"Motivations,Objectives,and Characterization ofDistributedSystems,"
Distributed Systems-Architecture and Implementation, LectureNotes in Computer Science, Vol.
105,Springer-Verlag, NewYork,NY (1981).
[Lockhart Jr.1994]LockhartJr.,H.W., OSF DCE: Guide to Developing Distributed Applications,
IEEEComputerSocietyPress,LosAlamitos,CA (1994).Chap.I •Bibliography 43
[Marcaand Bock 1992] Marca,D.,andBock,G. (Eds.), Groupware: SoftwareforComputer­
Supported Cooperative Work,IEEEComputer SocietyPress,LosAlamitos, CA(1992).
[Martin etal.1991]Martin,B.E.,Pedersen, C.H.,andRoberts, 1.B.,"AnObject-Based
Taxonomy forDistributed Computing Systems," IEEEComputer, Vol. 24,No.8(1991).
[Milenkovic 1992]Milenkovic, M.,Operating Systems: Concepts and Design, 2nd ed., McGraw­
Hill, New York (1992).
[Mullender 1987]Mullender, S.J.,HDistributed Operating Systems," Computer Standards and
Interfaces, Vol. 6, pp. 37-44(1987).
[Mullender 1993]Mullender, S.J.(Ed.),Distributed Systems, 2nd ed., Addison-Wesley, Reading,
MA(1993).
[Mullender andTanenbaum 1984]Mullender, S. 1., and Tanenbaum, A. S.,"Protection and
Resource ControlinDistributed Operating Systems," Computer Networks, Vol. 8, pp. 421-432
(1984).
[Mullender etal,1990)Mullender, S. 1., Van Rossum, G.,Tanenbaum, A. S., Van Renesse,R.,and
VanStaverene, H.,"Amoeba: ADistributed Operating Systemfor the1990s,"IEEE Computer,
Vol. 23,No.5,pp.44-53(1990).
[Needham andHerbert 1982]Needham, R. M., and Herbert, A. 1.,The Cambridge Distributed
Computing System, Addison-Wesley, Reading,MA(1982).
[Nelson 1990] Nelson,V.P.,"Fault-Tolerant Computing: Fundamental Concepts," IEEE Computer,
Vol. 23,No.7,pp.19-25(1990).
[Nicoletal.1993]Nicol,J.R.,Wilkes,C.T.,andManola,F.A.,"ObjectOrientation inHeterogeneous
Distributed Computing Systems," IEEE Computer, Vol.26,No.6,pp. 57-·67 (1993).
[Notkin et al, 1987]Notkin,D.,Hutchinson, N.,Sanislo, 1., andSchwartz, M.,"Heterogeneous
Computing Environments: ReportontheACMSIGOPS Workshop onAccommodating
Heterogeneity," Communications ofthe ACM, Vol. 30,No.2,pp.132-140 (1987).
[Nutl1991]Nutt, G. J.,Centralized andDistributed Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ (1991).
[Nutt1992]Nutt, G.1.,Open Systems, Prentice-Hall, Englewood Cliffs,NJ(1992).
[OSF1992]Introduction to OSFDeE,Prentice-Hall, Englewood Cliffs, NJ (1992).
[Ousterhout etal,1988]Ousterhout, J.K.,Cherenson, A.R.,Douglis, F.,Nelson,M.N., and
Welch, B. B., "TheSpriteNetwork Operating System," IEEE Computer, Vol. 21,No.2,pp.
23-36(1988).
[Pike et al, 1990] Pike,R.,Presotto, D.,Thompson, K., and Trickey, H., "Plan9 from Bell Labs,"
In:Proceedings oftheSummer1990 UKUUG (UK Unix Users Group) Conference, pp.1-9(July
1990).
[PopekandWalker1985]Popek,G., and Walker, B., TheLOCliSDistributed SystemArchitecture,
MIT Press, Cambridge, MA (1985).
[Rashid 1985]Rashid,R. F.,"Network Operating Systems," In:Local Area Networks: An Advanced
Course, Lecture Notes in Computer Science, Vol. 184, pp. 314-340, Springer-Verlag, New York,
NY (1985).
[RitchieandThompson 1974]Ritchie,D., andThompson, K.,"TheUNIXTime-Sharing System,"
Communications oftheACM,Vol. 17,No.7,pp.365-375 (1974).
[Rosenberry et ale1992]Rosenberry, W., Kenney, D., and Fisher,G.,OSFDISTRIBUTED
COMPUTING ENVIRONMENT, Understanding DeE,O'Reilly, Sebastopol, CA(1992).44 Chap. 1 • Fundamentals
[Schlichting andSchneider 1983]Schlichting,R.D.,andSchneider, F.B.,"Fail-Stop Processors:
AnApproachtoDesigningFault-TolerantComputingSystems," ACMTransactions on Computer
Systems, Vol.1,No.3,pp.222-238 (1983).
(ShochandHupp1982]Shoch,J. F.,andHupp,1.A., "The WormPrograms:Early Experiences
witha DistributedComputation," Communications ofthe ACM, Vol.25,No.3,pp. 172-180
(1982).
[Silberschatz andGalvin1994]Silberschatz,A., and Galvin,P. B.,Operating Systems Concepts,
4th ed.,Addison-Wesley, Reading,MA (1994).
[SinghalandShivaratri 1994]Singhal,M.,andShivaratri,N.G., Advanced Concepts in Operating
Systems,McGraw-Hili,New York,NY(1994).
[Stalling 1995]Stalling, W.,Operating Systems, 2nd ed., Prentice-Hall, Englewood Cliffs, NJ
(1995).
[Stankovic 1984]Stankovic, J.A., "A Perspective on Distributed Computer Systems," IEEE
Transactions on Computers, Vol.C-33, No. 12,pp. 1102-1115(1984).
[Surietal,1994]Suri,N.,Walter,C. J., and Hugue,M. M. (Eds.), Advances in Ultra-Dependable
Distributed Systems,IEEEComputer SocietyPress, LosAlamitos,CA (1994).
[Tanenbaum 1995]Tanenbaum, A. S.,Distributed Operating Systems, Prentice-Hall,Englewood
Cliffs, NJ (1995).
[Tanenbaum andVan Renesse 1985] Tanenbaum, A. S.,and Van Renesse, R., "Distributed
Operating Systems," ACMComputing Surveys, Vol.17,No.4,pp.419-470 (1985).©ACM,
Inc., 1985.
[Umar1993]Umar,A., Distributed Computing: A Practical Approach, Prentice-Hall,Englewood
Cliffs, NJ (1993).
[Vaughn 1994] Vaughn,L.T.,Client/Server System Design and Implementation, IEEEComputer
Society Press,LosAlamitos,CA (1994).
[Wittie1991]Wittie,L. D.,"Computer Networksand DistributedSystems," IEEE Computer, pp.
67-75 (1991).
POINTERS TO818UOGRAPHIES ONTHEINTERNET
Bibliography containing references onOperating Systemscan befoundat:
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/os.html
Bibliography containing references onTaxonomies forParallel and Distributed Systems
can be foundat:
ftp:ftp.cs.umanitoba.calpublbibliographieslParalleVtaxonomy.html
Bibliography containing references onDistributed Computing can be foundat:
ftp:ftp.cs.umanitoba.ca/publbibliographieslDistributedlOsser.html
Bibliographies containing references onDistributed Systemscanbefoundat:
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedlDcs-l.O.html
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedldist.sys.l.htmlChap.1 •PointerstoBibliographies on theInternet 4S
Bibliography containing references onOpenSystemsandOpenComputing canbefound
at:
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/opencomp.html
Bibliography containing references on Fault Tolerant Distributed Systemscan be found
at:
ftp:ftp.cs.umanitoba.calpub/bibliographieslDistributed/fauIt.tolerant.html
Bibliographies containing references on Computer Supported Cooperative Work (CSCW)
can be found at:
ftp:ftp.cs.umanitoba.ca/pub/bibliographies/Distributed/CSCWBiblio.html
ftp:ftp.cs.umanitoba.calpub/bibliographieslDistributed/CSCW92.htmI
List of publications of the MIT Parallel &Distributed Operating Systems (PDOS)group
can be found at:
http:www.pdos.lcs.mit.eduIPDOS-papers.html
List of publications of the Stanford Distributed Systems Group (DSG) can be found at:
http:www-dsg.stanford.edulPublications.html
List of publications of the Distributed Systems Research Group (DSRG) at Oregon
Graduate Institute can be found at:
http:www.cse.ogi.edu/DSRG/osrg/osrg.html#Current Paper
List ofpublications of the Distributed Systems Group at Trinity College, Dublin, can be
found at:
http:www.dsg.cs.tcd.ie/dsgpublications/bibsCHAPTER2
Computer Networks
2.1 INTRODUmON
Acomputer network is a communication system that links end systems by communication
lines and software protocols to exchange data between two processes running on different
end systems of the network. The end systems are often referred to as nodes, sites, hosts,
computers , machines, and so on. The nodes may vary in size and function. Sizewise, a
node may be a small microprocessor , a workstation, a minicomputer, or a large
supercomputer. Functionwise, a node may be a dedicated system (such as a print server or
a file server) without any capability forinteractive users, asingle-user personal computer,
or ageneral-purpose time-sharing system.
As already mentioned in Chapter 1, a distributed system is basically a computer
network whose nodes have their own local memory and may also have other hardware and
software resources. A distributed system, therefore, relies entirely on the underlying
computer network for the communication of data and control information between the
nodes of which they are composed. Furthermore, theperformance and reliability of a
distributed system depend to a great extent on the performance and reliability of the
underlying computer network. Hence a basic knowledge ofcomputer networks is required
for the study ofdistributed operating systems. A comprehensive treatment ofcomputer
networks will require a complete book in itself, and there are many good books available
on this subject [Tanenbaum 1988, Black 1993, Stallings 1992b, Ramos et at. 1996].
46Sec.2.2 • Networks Types 47
Therefore, thischapter dealsonly withthe most importantaspectsof networkingconcepts
anddesigns,withspecialemphasistothoseaspectsthatare neededasabasisfordesigning
distributed operating systems.
2.2NETWORKS TYPES
Networksarcbroadlyclassified intotwotypes: local area networks (LANs)andwide-area
networks (WANs). The WANs are also referred to as long-haul networks. The key
characteristics thatare often usedtodifferentiate between these twotypesof networksare
as follows [Abeysundara and Kamal 1991]:
1.Geographic distribution. The maindifference between the two types of networks
is the way in which they are geographically distributed. A LAN is restricted to a limited
geographic coverage of afew kilometers, but aWAN spans greater distances and may
extend over several thousand kilometers.Therefore, LANs typically provide communica­
tion facilities within a building or acampus, whereas WANsmay operate nationwide or
even worldwide.
2. Data rate. Data transmission rates are usually much higher in LANs than in
WANs.Transmission rates inLANs usuallyrange from0.2 megabitper second(Mbps)to
1gigabit per second (Gbps). On theother hand,transmission rates inWANsusuallyrange
from1200bits per second to slightly over 1Mbps.
3.Error rate. Local area networks generally experience fewer data transmission
errors than WANsdo. Typically, bit error rates are in the range of 10--8- 10-12with LANs
as opposed to 10-5--10-7withWANs.
4.Communication link.The most common communication Jinksused in LANs are
twisted pair, coaxial cable, and fiber optics. On the other hand, since the sites in a WAN
are physically distributed over a largegeographic area, the communication linksused are
by default relatively slow and unreliable.Typicalcommunication links used inWANsare
telephone lines, microwave links, andsatellite channels.
5.Ownership. A LAN is typically owned by a single organization because of its
limited geographic coverage. A WAN, however, is usually formed by interconnecting
multiple LANs each of which may belong to a different organization. Therefore,
administrative and maintenance complexities and costs for LANs are usually much lower
than forWANs.
6.Communication cost.The overall communication costs of a LANis usuallymuch
lower than that of a WAN.The main reasons for this are lower error rates, simple (or
absence of) routing algorithms, and lower administrative and maintenance costs.
Moreover,thecost to transmit data in a lJANis negligible sincethe transmission medium
is usually owned by the user organization. However, with a WAN,this cost may be very
high because the transmission media used are leased lines or public communication
systems, such as telephone lines, microwave links, and satellite channels.48 Chap.2 • Computer Networks
Networks that share some of the characteristics of both LANs and WANs are
sometimes referred to as metropolitan area networks (MANs) [Stallings 1993a]. The
MANs usually cover a wider geographic area (up to about 50km in diameter) than LANs
and frequently operate at speeds very close to LAN speeds. A main objective of MANs
is to interconnect LANs located in an entire city or metropolitan area. Communication
links commonly used for MANs are coaxial cable and microwave links.
We saw in Chapter 1that the performance of a distributed system must be at least as
good as a centralized system. That is, when a particular application is run on a distributed
system, its overall performance should not be appreciably worse than running the same
application on a single-processor system. The data transmission rates of LANs and MANs
are usually 'considered to be adequate to meet this requirement for many applications.
However, with the current technology, the transmission rates of WANs cannot fully meet
this requirement of distributed systems. Therefore, WAN-based distributed systems are
used mainly for those applications for which performance is not important. Several
inherently distributed applications that require information sharing among widely
distributed users/computers belong to this category.
Although current WANs cannot fully meet the performance requirements of
distributed systems, with the emergence of Broadband Integrated Services Digital
Network (B-ISDN) [Kawarasaki and Jabbari 1991] and Asynchronous Transfer Mode
(ATM) technologies [Vetter 1995], future WANs are expected to have data transmission
rates that will be adequate for the construction of WAN-based distributed systems and the
implementation of a wide range of applications on these distributed systems. ISDN
[Helgert 1991] refers to telecommunication networks that transfer many types of data,
such as voice, fax, and computer data, in digital form at data transmission rates that are
multiples of a basic channel speed of 64 kilobits per second (Kbps). B-ISDN are ISDN
networks that provide point-to-point data transmission speeds of 150 Mbps and above.
B-ISDN networks are considered to be suitable for high-bandwidth applications, such as
applications involving high-quality video and bulk data transmissions. ATM technology
can provide data transmission rates of upto 622Mbps. (ATMtechnology isdescribed later
in this chapter.)
2.3LANTECHNOLOGIES
This section presents a description of topologies, principles of operation, and case studies
ofpopularLANs.
2.3.1LANTopologl8s
The two commonly used network topologies for constructing LANs are multiaccess
bus and ring. In a simple multiaccess bus network, all sites are directly connected to
a single transmission medium (called the bus) that spans the whole length of the
network (Fig. 2.1). The bus is passive and is shared by all the sites for any message
transmission in the network. Each site is connected to the bus by a drop cable using
a T-connection or tap. Broadcast communication is used for message transmission.Sec.2.3 • LAN Technologies
~Sites
Sharedbus
Fig. 2.1 Simplemultiaccess bus network topology.49
That is, a message is transmitted from one site to anotherby placing it on the shared
bus. An address designator isassociated with the message. As the message travels on
the bus, each site checkswhetheritisaddressed to it and the addressee site picks up
the message.
A variant of the simple multiaccess bus network topology is the multiaccess
branching bus network topology. In such a network, two or more simple multiaccess bus
networks areinterconnected byusingrepeaters (Fig. 2.2). Repeaters are hardware devices
used toconnectcable segments. They simply amplify and copy electric signals from one
segment of a network to its next segment.
Shared bus
/
~Siles
Fig. 2.2 Multiaccess branching bus network topology.so Chap. 2 • Computer Networks
Theconnection cost of amultiaccess bus network islow and grows only linearly with
theincreasein number of sites. The communication cost is also quite low, unless there is
heavycontention for the shared bus and the bus becomes a bottleneck. A disadvantage of
multiaccess bus topology is that message signals, transmitted over the single shared
medium, suffer more attenuation anddistortion compared to the shorter point-to-point
links of other topologies. Therefore, especially in the case of fiber-optic bus networks,
only a few sites can usually be supported.
In aring network, each site is connected to exactly two other sites so that a loop is
formed (Fig. 2.3).A separate link is used toconnect two sites. The links are interconnected
by using repeaters. Data is transmitted in one direction around the ring by signaling
between sites. That is, to send a message from one site to another, the source site writes
thedestination site'saddress in the message header and passes itto its neighbor. A site that
receives the message checks the message headerto see if the message is addressed toit.
If not, the site passes on the message to its own neighbor. In this manner, the message
circulates around the ring until some site removes it from the ring. In some ring networks,
thedestination site (to which the message is addressed) removes the message from the
ring, while in others it is removed by the source site (which sent the message). In the latter
case, the message always circulates for onecomplete round on the ring. Generally, in ring
networks, one of the sites acts as a monitorsiteto ensure that a message does not circulate
indefinitely (that is, in case the source site or the destination site fails). The monitor site
also perform other jobs, such as housekeeping functions, ring utilization, and handling
othererrorconditions.
MonitorIsite
Fig. 2.3 Ring network topology.Sec.2.3 • LANTechnologies 51
Theconnection costofa ringnetwork is low and growsonlylinearly with the
increase innumberofsites.Theaveragecommunication costisdirectlyproportional to
thenumberofsites in the network. Iftherearensites, at most(n-l)links have to be
traversed by amessage to reach its destination. Anoften-quoted disadvantage ofring
topology is thevulnerability ofringnetworks due to site or link failures; thenetwork is
partitioned by asinglelinkfailure.Variations ofthe basic ring topology, such as using
bidirectional links,providing doublelinksbetween twoneighbors, and siteskipping links
with each site joinedto its two immediate predecessors, havebeenconsidered toimprove
network reliability.
2.3.2Medium-Access ControlProtocols
In case of both multiaccess bus and ring networks, we saw that a singlechannel is
sharedby all the sites ofanetwork, resulting in amultiaccess environment. In such an
environment, it ispossible thatseveralsites will want to transmit information overthe
sharedchannel simultaneously. In this case, the transmitted information maybecome
scrambled and must be discarded. Theconcerned sites must be notified aboutthe
discarded information, so that they can retransmit theirinformation. If nospecial
provisions aremade,thissituation may berepeated, resulting indegraded performance.
Therefore, specialschemes areneededin amultiaccess environment tocontrolthe
accessto asharedchannel. Theseschemes areknownasmedium-access control
protocols.
Obviously, in amultiaccess environment, the use ofamedium havinghigh
raw data rate aloneis notsufficient. Themedium-access controlprotocol usedmust
alsoprovide forefficient bandwidth useofthemedium. Therefore, themedium­
accesscontrol protocol has asignificant effecton the overallperformance ofa
computer network, andoftenitis by such protocols that the networks differthe
most. The three mostimportant performance objectives ofamedium-access control
protocol are high throughput, highchannel utilization, and low message delay. In
addition tomeeting theperformance objectives, someotherdesirable characteristics
ofamedium-access control protocol are as follows [Abeysundara and Kamal
1991J:
1. Forfairness, unlessapriorityschemeisintentionally implemented, theprotocol
shouldprovideequalopportunity to all sites in allowing them to transmit their
information overthesharedmedium.
2.Forbetterscalability, sitesshouldrequire aminimum knowledge ofthe
network structure (topology, size, or relative location ofothersites), and
addition, removal, ormovement ofa site from one placetoanother in the
network shouldbepossible without the need to changetheprotocol. Fur­
thermore, itshouldnot benecessary to have a knowledge oftheexactvalue
oftheend-to-end propagation delayofthenetwork for the protocol to
function correctly.
3. Forhigherreliability, centralized controlshouldbeavoidedand theoperation of
theprotocol shouldbecompletely distributed.52 Chap.2 •Computer Networks
4. For supporting real-time applications, the protocol should exhibit bounded-delay
properties. That is, the maximum message transfer delay from one site to another
in the network must be known and fixed.
It is difficult to achieve all of the previously mentioned characteristics at the same
time while achieving the performance objectives of high throughput, high channel
utilization, and low message delay.
Several protocols have been developed for medium-access control in a multiaccess
environment. Of these, the Carrier Sense Multiple Access with Collision Detection
(CSMNCD) protocol is the one most commonly used for multiaccess bus networks, and
the token ring and slotted ring are the two commonly used protocols for ring networks.
Thesemedium-access control protocols are described next.
Note that for efficient and fair use of network resources, a message is often divided
into packets prior to transmission. In this case, a packetis the smallest unit of
communication. It usually contains a header and a body. The body contains a part of the
actual message data, and the header contains addressing information (identifiers of the
sender and receiversites) and sequencing information (position of the packet data within
the entire message data).
The CSMAlCD Protocol
TheCSMAlCD scheme [IEEE 1985a] employs decentralized control of the shared
medium, In this scheme, each site has equal status in the sense that there is no central
controller site.The sites contend with each other for use of the shared medium and the site
that first gains access during an idle period of the medium uses the medium for the
transmission ofits own message. Obviously, occasional collisions of messages may occur
when more than one site senses the medium to be idle and transmits messages at
approximately the same time. The scheme uses collision detection, recovery, and
controlled retransmission mechanisms to deal with this problem. Therefore, the scheme is
comprised of the following three mechanisms and works as described next
1. Carrier sense and defer mechanism. Whenever a site wishes to transmit a
packet, it first listens for the presence of a signal (known as a carrierby analogy with
radio broadcasting) on the shared medium. If the medium is found to be free (no carrier
is present on the medium), the site starts transmitting its packet. Otherwise, the site
defers its packet transmission and waits (continues to listen) until the medium becomes
free. The site initiates its packet transmission as soon as it senses that the medium is
free.
2. Collision detection mechanism. Unfortunately, carrier sensing does not prevent all
collisions because of the nonzero propagation delay of the shared medium. Obviously,
collisions occur only within a short time interval following the start of transmission, since
after this interval all sites will detect that the medium is not free and defer transmission.
This time interval is called the collision window orcollision interval and is equal to the
amount of time required for a signal to propagate from one end of the shared medium to
the other and back again. If a site attempts to transmit a packet, it must listen to the sharedSec.2.3 • LAN Technologies 53
medium for atime period that is at least equal to the collision interval in ordertoguarantee
that thepacketwill notexperience acollision.
Collision avoidance bylistening to the shared medium for at least the collision
interval time before initiation ofpackettransmission leads toinefficient utilization of the
medium whencollisions are rare. Therefore, instead of trying to avoid collisions, the
CSMAlCD scheme allows collisions to occur, detects them, and then takes necessary
recovery actions.
Adecentralized collision detection mechanism is used when a site transmits its
packet through its outputport,italso listens on its input port and compares the two signals.
A collision is detected when adifference is found in the two signals. On detection of a
collision, the siteimmediately stopstransmitting theremaining data in the packet and
sends a special signal, called a jamming signal,on the shared medium to notify all sites
that acollision has occurred. On seeing thejamming signal, all sites discard the current
packet. The sites whose packets collided retransmit theirpacketsat some later time.
Notethat, for ensuring thatallcollisions aredetected, alower bound onpacket length is
needed. To illustrate this, let us assume that the maximum propagation delay between two
sitesofanetwork is t.Ifthe two sites start transmitting their packets almost atthe sametime,
it will take at least time tfor the sites to start receiving the other site'spacketdata and to
detect the collision. Henceifthe packet size issosmall that ittakes less than time tfor asite
topump allitsdataonthe network, thesites willnotdetect the collision because thetwosites
complete their packet transmission before they see the other site'spacket data. However,
any other site on the same network for which the propagation time from thetwo sites is less
thantwillreceivescrambled data of the packets ofboth the sites.
3. Controlled retransmission mechanism. After acollision, the packets that became
corrupted due to the collision must beretransmitted. If all the transmitting stations whose
packets were corrupted bythecollision attempt to retransmit their packets immediately
after the jamming signal,collision willprobably occuragain. To minimize repeated
collisions and toachieve channel stability under overload conditions, acontrolled
retransmission strategy is used in which the competition for the shared medium isresolved
using adecentralized algorithm.
Retransmission policieshave two conflicting goals: (a) scheduling a retransmission
quickly to get the packetout and maintain use ofthe shared medium and (b) voluntarily
backing off to reduce the site'sload on a busy medium. A retransmission algorithm is used
tocalculate the delay before a site should retransmit its packet. After a collision takes
place, the objective is to obtain delay periods that will reschedule each site at times
quantized in steps at least as large as a collision interval. This time quantization iscalled
theretransmission slot time. Toguarantee quick use of the medium, this slot time should
be short; yet to avoid collisions it should be larger than a collision interval.Therefore, the
slot time is usually set to be a little longer than the round-trip time of the medium. The
real-time delay is the productof someretransmission delayD(a positive integer) and the
retransmission slot time (St).
A good example ofthecontrolled retransmission mechanism is the binary
exponential back-off algorithm used in Ethernet. This algorithm isdescribed later in this
chapterduring the description ofEthernet (a case study ofLANtechnology).54 Chap.2 •Computer Networks
TheCSMNCD scheme works best on networks having a bus topology with
bursty asynchronous transmissions. It has gained favor for transmission media that
have relatively low speeds (around 10 Mbps) mainly because of its ease of
implementation and its channel utilization efficiency. Notice that the performance of
theCSMAlCD scheme depends on the ratio of packet length to propagation delay. The
higher the ratio, the better the performance because the propagation delay is the
interval during which a packet is vulnerable to collision. After that interval, all sites
will have "heard"the transmission and deferred. As this ratio diminishes, the collision
frequency increases, causing significant performance degradation. Because this per­
formance becomes more pronounced when the ratio of packet length to propagation
delay is too low, CSMAlCD is unsuitable for high data rates and/or long distances.
For instance, for a transmission medium having photonic speeds (hundreds of
megabits per second or gigabits per second) the efficiency of CSMA/CD is often
unacceptable.
In addition to being unsuitable for systems having high data rates, small-size
packets, and long cable lengths, the CSMNCD scheme has the following drawbacks:
(a) It does not possess a bounded-delay property. Because the loading. of the shared
medium is variable, it is impossible to guarantee the delivery of a given message within
any fixed time, since the network might befully loaded when the message is ready for
transmission. (b) It is not possible to provide priorities for the use of the shared
transmission medium. Since all sites are equal, none have priority over others, even
though some sites may require greater use of the facilities due to the nature of a
particular application.
The Token Ring Protocol
This scheme also employs decentralized control of the shared medium. In this scheme,
access to the shared medium is controlled by using a single token that is circulated
among the sites in the system. A tokenis a special type of message (having a unique
bit pattern) that entitles its holder to use the shared medium for transmitting its
messages. A special field in the token indicates whether it is free or busy. The token
is passed from one site to the adjacent site around the ring in one direction. A site that
has a message ready for transmission must wait until the token reaches it and it is free.
When it receives the free token, it sets it to busy, attaches its message to the token,
and transmits it to the next site in the ring. A receiving site checks the status of the
token. If it is free, it uses it to transmit its own message. Otherwise, it checks to see
if the message attached to the busy token is addressed to it. If it is, it retrieves the
message attached to the token and forwards the token without the attached message to
the next site in the ring. When the busy token returns to the sending site after one
complete round, the site removes it from the ring, generates a new free token, and
passes it to the next site, allowing the next site to transmit its message (if it has any).
The free token circulates from one site to another until it reaches a site that has some
message to transmit. To prevent a site from holding the token for a very long time, a
token-holding timer is used to control the length of time for which a site may occupy
the token.Sec.2.3 • LAN Technologies 55
Toguarantee reliableoperation, the token has to be protected against loss or
duplication. That is, if the token gets lost due to a site failure, the system must detect
the loss and generate a newtoken.This is usually done bythemonitorsite. Moreover,
ifa siteicrashes, the ring must be reconfigured so that site i-Iwill send the token
directly to site i+1.
Anadvantage of the token ring protocol is that the message delay can be bounded
becauseof theabsenceofcollisions. Anotheradvantage is that it can work with both large
and small packet size as well as variable-size packets. In principle, a message attached to
the token may be ofalmostany length. A major disadvantage, however, is the initial
waiting time to receive a free token even at very light loads. This initial waiting time could
beappreciable, especially in large rings.
A variant of the token ring protocol described above is the IEEE 802.5 standard
Token Ring protocol [IEEE 1985c]. This protocol is described later in this chapterduring
thedescription ofIEEE Token Ring (a case study of LAN technology).
TheSlotted-Ring Protocol
In this scheme, a constant numberoffixed-length message slotscontinuously circulate
around the ring. Each slot has two parts-control and data. The control part usually has
fields to specify whetherthe slot is full or empty, the source and destination addresses of
the message contained in a full slot, and whether themessage in it was successfully
received at thedestination. On the other hand, the data part can contain a fixed-length
message data.
A site that wants to send a message first breaks down the message into packets of size
equal to the size ofthe data part of the slots. Itthen waits for the arrival of an empty slot.
As soon as an empty slot arrives, it grabs it, places one packet ofits message in its data
part, sets the source and destination addresses properly, sets the full/empty field to full,
and puts itback on the ring. This slot then circulates on the ring and the site again waits
for the arrival ofanotherempty slot. The site continues doing this until ithastransmitted
all the packets ofthe message.
Each site inspects every full slot to check if itcontainsa packetaddressed to it. If not,
it simply forwards the slot to the next site on the ring. Otherwise, itremoves the packet
from the slot, properly alters the field in the slot showing that the message in the slot was
successfully received at thedestination, and then forwards the slot to the next site in the
ring. When the slot returns back to its senderaftercompleting itsjourneyround the ring,
the sender changesits full/empty field to empty,making it available fortransmission of
any other message in the system.
This scheme prevents hogging of the ring and guarantees fair sharing of the
bandwidth of the shared medium among all sites. It also allows messages from multiple
sites to be simultaneously transmitted (in the token ring scheme, only one site can transmit
at a time). However, it requires a long message to be broken into smaller packets (this is
notrequired in the token ring scheme).
Theslotted-ring scheme is used in the Cambridge Ring [Wilkes and Wheeler 1979],
which was developed atCambridge University in the 1970s and is widely used in Britain.
Furtherdetailsofthis protocol can be found in [King and Mitrani 1987].56 Chap.2 •Computer Networks
2.3.3LANT.chnology (aseStudl.s:Ethernet andIEEE
Tok.nRing
Ethernet
Ethernet is the most widely used LAN technology for building distributed systems
because it is relatively fast and economical. It wasintroduced by DEC (Digital Equipment
Corporation), Intel, and Xerox in 1980, and subsequently, a slightly modified version of
itwas adopted bythe IEEE as a standard LAN technology, known as the IEEE 802.3
standard [IEEE 1985a].
The network topology used for Ethernet is a simple multiaccess bus or a multiaccess
branching bus topology. The communication medium used is low-loss coaxial cable
having a data transfer rate of 10Mbps.
A message is transmitted from one site to another by breaking itup into packets
(called/rames in Ethernet) and then by broadcasting the packets to the bus. An address
designator is associated with each packet. As a packet travels on the bus, each site checks
whether the packet is addressed to it and the addressee site picks up the message.
Formedium-access control, Ethernet uses ·the CSMNCD protocol with a binary
exponential back-offalgorithm as the controlled retransmission mechanism. In the binary
exponential back-off algorithm of Ethernet, the value of retransmission delay (D)is
selected as a random number from a particular retransmission interval between zero and
some upper limit (L).That is, if the packets of two sites collide, one will retransmit after
an interval of X XSI(SIis the retransmission slot time) and the other will retransmit after
an interval of Y XSt,where X and Yarelikely to be different since they were chosen
randomly. To control the shared medium and keep it stable under high load, the value of
Lis doubled with each successive collision, thus extending the range for the random
selection of the value of D. In Ethernet, on first collision, the value of Dis randomly
chosen to be 0 or 1;on the second collision, itis randomly chosen to be 0, 1,2, or 3; and
on theithsuccessive collision, it is randomly chosen to be an integer in the range °and
2;-1(both inclusive). Thus, the more often that a sender fails (due to repeated collisions),
the longer potential period of time it will defer before attempting to retransmit. This
algorithm has very short retransmission delays at the beginning but will back off quickly,
preventing the medium from becoming overloaded.
Notice that after some number of back-offs, the retransmission interval becomes
large. To avoid undue delays and slow response to improved medium characteristics, the
doubling of the retransmission interval is usually stopped at some point, with additional
retransmissions still being drawn from this interval, before the transmission is finally
aborted. This is referred to as the truncated binaryexponential back-off algorithm.
The structure of a packet in Ethernet is shown in Figure 2.4. The destination
and source addresses occupy 6 bytes each. The destination address may be a single­
site address (specifies a single site), a multicast address (specifies a group of sites),
or a broadcast address (specifies all sites). The address consisting of all l'sis the
broadcast address. The sites that belong to a multicast address have their network
interfaces configured to receive all packets addressed to the multicast address.
Moreover, to distinguish multicast addresses from single-site addresses, the higherSec.2.3 • LANTechnologies
6bytes 6bytes 2bytes 46bytesslengths1500bytes 4bytes57
Destination SourceType Messagedata Checksumaddress address
Fig.2.4 Structure of a packet in Ethernet.
orderbitofamulticast addressisalways1,whereas this bitofasingle-site address
isalways O.
The type field is usedtodistinguish amongmultiple typesofpackets. This field is
used by higherlayercommunication protocols (communication protocol layersare
described later in this chapter).
Themessage data field is the only field in the packetstructure that may have
variable length.Itcontains theactualmessage data to be transmitted. Thelengthof
this field may vary from 46 to 1500 bytes. The minimum lengthof46 bytes for this
field is necessary toensurethatcollisions arealwaysdetected in theCSMAlCD
schemeused for medium-access control. On theotherhand, the maximum lengthof
1500 bytes for this field is used to alloweach site in the network toallocate buffer
spacefor thelargestpossible incoming packetand toavoidasendersitewaitingfor
a long time for the communication channel tobecome free.Sincethere is no field to
indicate thelengthofthemessage data field, an intervalof9.6J..lsis usedbetween
thetransmission oftwopackets to allow receiving sites to detectthe end of
transmission ofapacket.
The last4bytesofapacketalwayscontainachecksum generated by thesenderand
used by the receiver(s) tocheckthevalidityofthereceived packet.Areceiver simply
dropsapacketthatcontains anincorrect checksum. Due to this, message delivery is not
guaranteed inEthernet. This is the reasonwhysimpledatagram protocols used in local
networks arepotentially unreliable. Ifguaranteed message delivery isneeded,theupper
layerofthecommunication protocol (communication protocol layers are described later
in thischapter) must use acknowledgments for thereceiptofeachpacketandtimeout­
basedretransmissions forunacknowledged packets.
EveryEthernet hardware interface isassigned auniqueaddressby themanufacturer.
Thisallowsall the sites ofa set of interconnected Ethernets to haveuniqueaddresses.
IEEEacts as an allocation authority forEthernet addresses. Aseparate rangeof48-bit
addresses isallocated to eachmanufacturer ofEthernet hardware interfaces.
IEEEToken Ring
Another commonly used LAN technology forbuilding distributed systems is theIEEE
Token Ring technology, knownas theIEEE802.5standard [IEEE1985b]. IBM has
adopted thistechnology as abasisfor itsdistributed systemproducts.
Thenetwork topology used in the IEEETokenRingtechnology is ringtopology, and
themedium-access controlprotocol used is the tokenringprotocol. Initiallyitoperated at58 Chap. 2 • Computer Networks
a speed of 4Mbps but was later upgraded to 16Mbps. It can use a cheap twisted pair or
optical fiber as thecommunication medium and has almost no wasted bandwidth when all
sites are trying to send.
A single token of 3 bytes keeps circulating continuously around the ring. The token
may either be busy or free. A site willing to send a message attaches its message to the
token and changes its status to busy, when the circulating token arrives at the sender'ssite
with free status. Therefore, a busy token has a message packet attached to it whose
structure is shown in Figure 2.5.
3bytes 6bytes 6bytes length s5000bytes 4bytes
et
s
e)Token
Destination Source Message dataChecksumIIaddress address
! 1
Packet control information(1 byte) Pack
statu
Priority and status information (1 byte) (1 byt
,
Startingdelimeter (1 byte) End
delimiter
(1 byte)
Fig.2.5 Structureof a packet inIEEEToken Ring.
The first byte of the token contains a fixed bit pattern that enables sites to recognize
the start of a packet and synchronize to the data transmission rate. The second byte
contains priority and token status (free/busy) information. The third byte contains packet
control information. The priority field can be used to implement a variety of methods for
sharing the channel capacity among the sites on the network.
In addition to the token, a packet in the IEEE Token Ring has fields for source
and destination addresses (each 6 bytes long), message data (length ~5000bytes),
checksum (4 bytes), end delimiter (1 byte), and packet status (1 byte). The source
address and destination address fields respectively contain the addresses of the
sending and receiving sites. The message data field contains the data to be
transmitted. This field is of variable length and allows packets to be of almost any
length. The upper bound of 5000 bytes for the length of this field is a default value
for aparameter that can be configured on a per-installation basis. The checksum
field contains a checksum generated by the sender and used by the receiver to check
the validity of the received packet. The end-delimiter field contains a fixed bit
pattern that enables sites to recognize the end of a packet. Finally, the packet status
field specifies whether the packet was successfully received by the receiving site.
This field helps the sending site in knowing whether its packet was received by the
receiver. The sending site is responsible for removing its packet from the ring when
it returns after one rotation.Sec.2.4 • WANTechnologies
2.4WANTECHNOLOGIESS9
A WAN of computers isconstructed byinterconnecting computers that areseparated by
large distances; they may be located in different cities or even in different countries. In
general, no fixed regularnetwork topology is used for interconnecting thecomputers of
a WAN. Moreover, different communication media may be used for different links of a
WAN. For example, in a WAN, computers located in the same country may be
interconnected bycoaxialcables(telephone lines), but communications satellites may be
used tointerconnect twocomputers that are located in different countries.
Thecomputers of a WAN are not connected directly to the communication channels
but areconnected tohardware devicescanedpacket-switching exchanges (PSEs), which
arespecial-purpose computers dedicated to the task ofdatacommunication. Therefore, the
communication channels of the network interconnect the PSEs, which actually perform
the task of data communication across the network (Fig. 2.6). A computer of a WANonly
interacts with the PSE of the WAN to which it is connected for sending and receiving
messages from other computers on the WAN.
•"ig.2.6 A WAN of computers.
To send a message packetto another computer on the network, a computer sends the
packetto the PSE to which it is connected. Thepacketistransmitted from the sending
computer's PSE to the receiving computer's PSE, possibly via other PSEs. The actual
mode of packet transmission and the route used for forwarding a packet from its sending
computer's PSE to its receiving computer's PSE depend on the switching and routing60 Chap.2 • Computer Networks
techniques used bythe PSEs of the network. Variouspossible options for these techniques
are described next. When the packet reaches its receiving computer's PSE, it is delivered
to the receiving computer.
1.4.1 Switching T.chnlqu8s
We saw that in a WAN communication is achieved by transmitting a packet from its
sourcecomputer to its destination computer through two or more PSEs. The PSEs provide
switching facility to move a packet from one PSE to another until the packet reaches its
destination. That is, a PSE removes a packet from an input channel and places it on an
output channel. Network latency is highly dependent on the switching technique used by
the PSEs of the WAN.The two most commonly used schemes are circuit switching and
packet switching. They are described next.
CircuitSwitching
In this method, before data transmission starts,a physical circuit is constructed between
the sender and receiver computers during the circuit establishment phase. During this
phase, the channels constituting the circuit are reserved exclusively for the circuit; hence
there is no need for buffers at the intermediate PSEs. Once the circuit is established, all
packetsofthe data are transferred in the data transfer phase. Since all the packets of a
message data are transmitted one after another through the dedicated circuit without being
buffered at intermediate sites, the packets appear to form a continuous data stream.
Finally, in the circuit termination phase, the circuit is tom down as the last packet of the
data is transmitted. As soon as the circuit is torn down, the channels that were reserved for
the circuit become available for use by others. If a circuit cannot be established because
a desired channel is busy (being used), the circuit is said to be blocked. Depending on the
way blocked circuits are handled, the partial circuit may be tom down, with establishment
to be attempted later.
This scheme is similar to that·used in the public telephone system. In this system,
when a telephone call is made, a dedicated circuit is established by the telephone
switching office from the caller'stelephone to the callee'stelephone. Once this circuit is
established, the only delay involved in the communication is the time required for the
propagation of theelectromagnetic signal through all the wires and switches. While it
might be hard to obtain a circuit sometimes (such as calling long distance on Christmas
Day), once the circuit is established, exclusive access to it isguaranteed until the call is
terminated.
The main advantage of a circuit-switching technique is that once the circuit is
established, data is transmitted with no delay other than the propagation delay, which is
negligible. Furthermore, since the full capacity of the circuit is available for exclusive use
by theconnected pair of computers, the transmission time required to send a message can
beknown and guaranteed after the circuit has been successfully established. However, the
method requires additional overhead during circuit establishment and circuit disconnec­
tion phases, and channel bandwidths may be wasted if the channel capacities of the path
forming the circuit are not utilized efficiently by the connected pair of computers.Sec.2.4 • WANTechnologies 61
Therefore, the method is considered suitable only for long continuous transmissions or for
transmissions that require guaranteed maximum transmission delay. It is the preferred
method for transmission of voice and real-time data in distributed applications.
Circuit switching is used in the Public Switched Telephone Network (PSTN).
PacketSwitching
In this method, instead of establishing a dedicated communication path between a sender
and receiver pair (of computers), the channels are shared for transmitting packets of
different sender-receiver pairs. That is, a channel is occupied by a sender-receiver pair
only while transmitting a single packet of the message of that pair; the channel may then
be used for transmitting either another packet of the same sender-receiver pair or a packet
of some other sender-receiver pair.
In this method, each packet of a message contains the address of the destination
computer, so that itcan be sent to its destination independently of all other packets. Notice
that different packets of the same message may take a different path through the network
and, at the destination computer, the receiver may get the packets in an order different
from the order in which they were sent. Therefore, at the destination computer, the packets
have to be properly reassembled into a message. When a packet reaches a PSE, the packet
is temporarily stored there in a packet buffer. The packet is then forwarded to a selected
neighboring PSE when the next channel becomes available and the neighboring PSE has
an available packet buffer. Hence the actual path taken by a packet to its destination is
dynamic because the path is established as the packet travels along. Packet-switching
technique is also known as store-and-forward communication because every packet is
temporarily stored by each PSE along its route before it is forwarded to another PSE.
Ascompared to circuit switching, packet switching is suitable for transmitting small
amounts of data that are bursty in nature. The method allows efficient usage of channels
because the communication bandwidth of a channel is shared for transmitting several
messages. Furthermore, the dynamic selection of the actual path to be taken by a packet
gives the network considerable reliability because failed PSEs or channels can beignored
and alternate paths may be used. For example, inthe WANof Figure 2.6, ifchannel 2fails,
a message from computer A to D can still be sent by using the path 1-3.However, due
to the need to buffer each packet at every PSE and to reassemble the packets at the
destination computer, the overhead incurred per packet is large. Therefore, the method is
inefficient for transmitting large messages. Anotherdrawback of the method is that there
is no guarantee of how long it takes a message to go from its source computer to its
destination computer because the time taken for each packet depends on the route chosen
for that packet, along with the volume of data being transferred along that route.
Packet switching is used in the X.25 public packet network and the Internet.
2.4.2RoutingTechniques
In a WAN, when multiple paths exist between the source and destination computers
of a packet, anyone of the paths may be used to transferthe packet. For example,
in the WAN of Figure 2.6, there arc two paths between computers E and F: 3-4and62 Chao.2 •Computer Networks
1-2-4-and anyone of the two may be used to transmit a packet from computer E
to F. The selection of the actual path to be used for transmitting a packet is
determined by the routing technique used. An efficient routing technique is crucial to
the overall performance of the network. This requires that the routing decision
process must be as fast as possible to reduce the network latency. A good routing
algorithm should be easilyimplementable in hardware. Furthermore, the decision
process usually should"not require global state information of the network because
such information gathering is a difficult task and creates additional traffic in the
network. Routing algorithms are usually classified based on the following three
attributes:
• Place where routing decisions are made
• Time constant ofthe information upon which the routing decisions are based
• Control mechanism used for dynamic routing
Note that routing techniques are not needed in LANs because the sender of a message
simply puts the message on the communication channel and the receiver takes it off from
the channel. There is no need to decide the path to be used for transmitting the message
from the sender to the receiver.
PlaceWhereRoutingDecisionsAre Made
Based on this attribute, routing algorithms may be classified into the following three
types:
1. Source routing. In this method, the source computer's PSE selects the entire
path before sending the packet. That is, all intermediate PSEs via which the packet
will be transferred to its destination are decided at the source computer's PSE of
the packet, and this routing information is included along with the packet. The
method requires that the source computer's PSE must have fairly comprehensive
information about the network environment. However, the routing decision process
is efficient because the intermediate PSEs need not make any routing decision. A
drawback of the method is that the path cannot be changed after the packet has
left the source computer's PSE, rendering the method susceptible to component
failures.
2. Hop-by-hop routing. In this method, each PSE along the path decides only the
next PSE for the path. That is, each PSE maintains information about the status of all its
outgoing channels and the adjacent PSEs and then selects a suitable adjacent PSE for the
packet and transmits it to that PSE. The routing decisions are typically based on the
channel availability andthe readiness of the adjacent PSEs to receive andrelay the packet.
The method requires that each PSE must maintain a routing table of some sort. However,
ascompared to thestaticrouting method, thismethod makes moreefficient useofnetwork
bandwidth and provides resilience to failures because alternative paths can be used for
packet transmissions.Sec.2.4 • WANTechnologies 63
3.Hybridrouting.Thismethodcombines the first two methods in the sense that the
sourcecomputer's PSEspecifies onlycertainmajorintermediate PSEsofthecomplete
path, and the subpaths between any two of the specified PSEs are decidedby themethod
ofhop-by-hop routing.
Static and Dynamic Routing
Depending on when the information used for making routing decisions isspecified and
howfrequently it ismodified, routingalgorithms areclassified into thefollowing two
types:
1.Static routing. In this method, routingtables(storedatPSEs)are set once and do
notchangefor very long periods oftime. They are changed only when the network
undergoes majormodifications. Static routing is also known as fixedordeterministic
routing.Staticroutingissimpleand easy to implement. However, it makes poor use of
network bandwidth andcausesblocking ofapacketeven when alternative paths are
available for itstransmission. Hence, static routingschemes aresusceptible tocomponent
failures.
2.Dynamic routing.In this method, routing tables are updated relatively frequently,
reflecting shortertermchanges in the network environment. Dynamic routingstrategyis
also known as adaptive routingbecause it has atendency to adapt to the dynamically
changing stateofthenetwork, such as the presence of faulty or congested channels.
Dynamic routingschemes can usealternative paths for packet transmissions, making more
efficient useofnetwork bandwidth andproviding resilience to failures. The latter property
isparticularly important forlarge-scale architectures, sinceexpanding network size can
increasetheprobability ofencountering a faultynetworkcomponent. Indynamic routing,
however, packetsofamessage mayarrive out of orderat thedestination computer. This
problem can besolvedbyappending asequence numberto eachpacketandproperly
reassembling thepacketsat thedestination computer.
The path selection policy for dynamic routing may eitherbeminimal or
nonminimal. In theminimal policy, the selectedpath is one of the shortestpathsbetween
the source and destination pairofcomputers. Therefore, everychannelvisited will bring
the packet closerto thedestination. On theotherhand, in the nonminimal policy, a packet
may follow a longerpath, usually in response tocurrentnetwork conditions. If the
nonminirnal policyis used, care must be taken to avoid a situationinwhich the packetwill
continue to beroutedthroughthenetwork but never reach the destination.
ControlMechanisms for Dynamic Routing
In thedynamic routingstrategy, routing tables are constantly updated. One ofthe
following threeapproaches may be used for controlling the update action:
1.Isolatedmanner.In thisapproach, individual PSEs update the information in their
local routing table in an isolatedmanner,perhapsbyperiodically trying various routes and
observing performance.64 Chap.2 •Computer Networks
2. Centralized manner. In this method, changes in the network environment,
connectivity, orperformance areconstantly reported to one centralized PSE. Based on the
information received, the global routing table maintained at thecentralized PSE is
constantly. updated. The updated routing table information isperiodically sent from the
centralized PSE to the source PSEs (in the source-routing strategy) or to all PSEs (in the
hop-by-hop routing strategy).
The main advantages of the centralized approach are that the routes are globally
optimalandotherPSEs are not involved in the information gathering ofthe global
network status. However, the centralized approach suffers from poor performance in
situations where the system is large or where traffic changes are frequent. Also, it has poor
reliability since the table construction isperformed at a single PSE.
3. Decentralized manner. Toovercome theshortcomings of thecentralized
approach, several systems use the distributed control mechanism. In this method, each
PSEmaintains a routing table and the routing table updates are performed by mutual
interaction among the PSEs. Often a PSE piggybacks the routing table update information
along with some other message being sent to another PSE.
2.5COMMUNICATION PROTOCOLS
In the last several sections of this chapterwe saw that several types of agreements are
neededbetween thecommunicating parties in a computer network. For example, it is
important that the sender and receiver of a packet agree upon the positions and sizes of the
various fields in the packet header, the position and size of actual data in the packet, the
position and size of the checksum field, the method to calculate the checksum for error
detection and so on. For transmission of message data comprised of multiple packets, the
sender and receivermust also agree upon the method used for identifying the first packet
and the last packet of the message, and since the last packet may only be partially filled,
amethodis needed to identify the last bit of the message in this packet. Moreover,
agreement is also needed for handling duplicate messages, avoiding buffer overflows, and
assuring proper message sequencing. All such agreements, needed for communication
between thecommunicating parties, are defined in terms of rules and conventions by
network designers. The term protocol is used to refer to a set of such rules and
conventions.
Computer networks are implemented using the concept of layered protocols.
According tothis concept, the protocols ofa network are organized into a series of layers in
suchawaythateachlayercontains protocols for exchanging dataandproviding functions in
a logical sense with peer entities at other sites in the network. Entities in adjacent layers
interactinaphysicalsensethrough the common interface defined between thetwolayersby
passingparameters such as headers, trailers, and data parameters. The main reasons for
using the conceptof layered protocols in network design are as follows:
• The protocols of a network are fairly complex. Designing them in layers makes
theirimplementation more manageable.Sec.2.5 • Communication Protocols 6S
•Layering ofprotocols provides well-defined interfaces between thelayers,so that
achangein onelayerdoes not affectanadjacent layer.Thatis, thevarious
functionalities canbepartitioned andimplemented independently so that each one
can bechanged astechnology improves withouttheotheronesbeingaffected. For
example, achangeto aroutingalgorithm in anetwork controlprogram shouldnot
affectthefunctions ofmessage sequencing, whichislocatedinanotherlayerofthe
network architecture.
•Layering ofprotocols alsoallowsinteraction between functionally pairedlayersin
different locations. Thisconceptaids inpermitting thedistribution offunctions to
remotesites.
Thetermsprotocol suite,protocol family,orprotocol stackare used to referto the
collection ofprotocols (ofalllayers)ofaparticular network system.
2.5.1 Protocols forNetwork Systems
InChapter1we sawthatdistributed systemsarebasically different fromnetwork systems.
Therefore, therequirements ofcommunication protocols ofthese two types ofsystemsare
alsodifferent. Thebasicgoalofcommunication protocols fornetwork systemsis toallow
remotecomputers tocommunicate with each otherand toallowusers to accessremote
resources. On theotherhand, the basic goal ofcommunication protocols fordistributed
systemsis not only to allowusers toaccessremoteresources but to do so in a transparent
manner.
Severalstandards andprotocols for network systemsarealreadyavailable. However,
protocols fordistributed systems are still in theirinfancyand no standards are yet
available. Somestandard network protocol modelsaredescribed next. The protocols for
distributed systemsarcpresented in the next section.
TheISO/OSI Reference Model
Thenumberoflayers,thenameofeach layer, and the functions ofeachlayermay be
different fordifferent networks. However, tomakethejobofthenetwork communication
protocol designers easier, the International Standardization Organization (ISO)has
developed areference model that identifies sevenstandard layersanddefinesthejobsto
beperformed ateachlayer.Thismodel is calledtheOpenSystemInternational Reference
Model(abbreviated OSlmodel)[DePrycker etaJ. 1993, Larmouth 1993,Stallings 1993c].
It is aguide,not aspecification. Itprovides aframework in which standards can be
developed for theservices andprotocols at each layer. Note that adherence tostandard
protocols isimportant fordesigning opendistributed systems. This isbecauseifstandard
protocols are used, separate software components ofdistributed systemscan bedeveloped
independently oncomputers havingdifferent architectures (different codeordering and
datarepresentations). Toprovide anunderstanding ofthestructure andfunctioning of
layerednetwork protocols, abriefdescription ofthe OSImodelispresented next.There
are many sources for more detail on this model [Tanenbaum 1988,Stallings 1993c,
Larmouth 1993J.66 Chap. 2 • Computer Networks
The architecture of the OSI model is shown in Figure 2.7. Itis a seven-layer
architecture in which a separate set of protocols is defined for each layer.Thus each layer
has an independent function and deals with one or more specific aspects of the
communication. The roles of the seven layers are briefly described below.
Site1
Application protocol-_.._--~.-_.~-~ _..........
t--__P_re_s_e~~,protocol
Data-link protocol
Physical protocol .
14-+- ~'--- '-- -'._.--- -I'"
NetworkSite2
Fig. 2.7 Layers. interfaces,and protocolsin the OSI model.
PhysicalLayer: The physical layer isresponsible fortransmitting raw bit streams
between two sites. That is, it may convert the sequence of binary digits into electric
signals, light signals, orelectromagnetic signals depending on whetherthe twosites areon
a cable circuit, fiber-optic circuit, or microwave/radio circuit, respectively. Electrical
details such as how many volts to use for 0 and 1,how many bitscan be sent per second,
and whether transmission can take place only in one direction or in both directionsSec.2.5 • Communication Protocols 67
simultaneously are also decided by the physical layer protocols. In addition, the physical
layerprotocols also deal with the mechanical details such as the size and shape of the
connecting plugs, the numberof pins in the plugs, and the function ofeach pin. In short,
the physical layer protocols deal with the mechanical, electrical, procedural, and
functional characteristics oftransmission of raw bit streams between two sites. RS232-C
is apopularphysical layer standard for serial communication lines.
Data-Link Layer. The physical layer simply transmits the data from the sender's
site to the receiver's site as raw bits. It is the responsibility of the data..link layer to
detect and correct any errors in the transmitted data. Since the physical layer is only
concerned with a raw bit stream, the data-link layer partitions it into frames so that
error detection and correction can beperformed independently for each frame. The data­
link layer also performs flow control of frames between two sites to ensure that a
sender does not overwhelm areceiver by sending frames at a rate faster than the
receiver can process. Therefore, the error control and flow control mechanisms of a
network form the data-link layerprotocols in the OSI model. Notice that the data-link
layer and physical layer protocols establish an error-free communication of raw bits
between two sites.
Network Layer. The network layer is responsible for setting up a logical path
between two sites for communication to take place. It encapsulates frames into packets
that can be transmitted from one site to another using a high-level addressing and routing
scheme. That is, routing is the primary jobof the network layer and the routing algorithm
forms the main part of the network layer protocols of the network.
Twopopularnetworklayer protocols are the X.25 Protocol and theInternet Protocol
(calledIP).The X.25 is a connection-oriented protocol that is based on the conceptof
establishing a virtual circuitbetween the senderandreceiver before the actual
communication starts between them. In this protocol, a request for connection is first sent
to thedestination, which can eitherbe accepted or rejected. If the connection isaccepted,
therequesting party is given a connection identifier to use in subsequent requests. During
theconnection establishment phase, a route between the two parties is also decidedthat
is used for the transmission ofsubsequent traffic.
On the other hand, IP is a connection lessprotocol in which no connection is
established between the senderandreceiver before sending a message. Therefore, each
packet of the message is transmitted independently and may take a different route. IP is
partoftheDoD(U.S.Department ofDefense) protocol suite.
Notice that the functions performed at the network layer are primarily required in
WANs. In a single LAN, the network layer is largely redundant because packets can be
transmitted directly from any site on the networkto any other site. Therefore thenetwork
layer, if present, has little work to do.
Transport Layer. The job of the transport layer is to provide site-to-site
communication and to hide all the details ofthecommunication subnet from the session
layer by providing anetwork-independent transport service. Using this service, all the
details of the communication subnetare sealed and one subnet can be replaced with
anotherwithoutdisturbing the layers above the transport layer.68 Chap.2 •Computer Networks
Inparticular, thetransport layeracceptsmessages ofarbitrary length from the session
layer,segments them into packets,submitsthem to the networklayer for transmission, and
finallyreassembles thepacketsat thedestination. Some packets may be lost on the way
from the senderto thereceiver, anddepending on the routing algorithms used in the
networklayer,packetsmayarriveat thedestination in asequence that isdifferent from the
orderinwhichthey are sent. .Thetransport layerprotocols includemechanisms for
handling lost andout-of-sequence packets.Forthis, thetransport layerrecordsasequence
numberin eachpacketand uses the sequence numbers fordetecting lostpacketsand for
ensuring thatmessages arereconstructed in thecorrectsequence.
TheISO model provides fiveclassesoftransport protocols (known as TPOthrough
TP4)whichbasically differintheirabilityto handle errors. TPOis the least powerful one
andTP4is the most powerful one. The choiceofwhich one to use depends on the
properties ofthe .underlying network layer.
The two mostpopulartransport layerprotocols are theTransport Control Protocol
(TCP) and the UserDatagram Protocol (UDP). Both are implemented in the DARPA
protocol suiteofDARPA Internet. TCPis aconnection-oriented transport protocol that
provides the same servicesas TP4ofthe ISO model. It uses end-to-end mechanisms to
ensurereliable, ordereddelivery ofdataoveralogicalconnection. Thesegoals are
basically achieved by using packetsequence numbers andpositiveacknowledgments with
timeoutandretransmission.
TheUDPis aconnectionless transport protocol. It is anunreliable protocol because,
when it is used, message packetscan be lost, duplicated, or arrive out oforder.Therefore,
only those applications that do not need reliablecommunication should use UDP.
Session Layer. Thepurposeofthesessionlayer is to providethe means by which
presentation entitiescanorganize andsynchronize theirdialogandmanagetheir data
exchange. Itallowsthe twopartiestoauthenticate eachotherbeforeestablishing a dialog
sessionbetween them. It also specifies dialogtype-one way, two way alternate, or two
waysimultaneous-and initiatesadialogsessionif themessage is aconnection request
message. Theotherservicesofthesessionlayerincludequarantine service,dialogcontrol,
andprioritymanagement. Thequarantine servicebuffersa groupofmessages on the
receiving side until the sessionlayeron thesendingsideexplicitly releasesthem. This is
useful in database applications where a transaction (consisting ofa groupofmessages)
needs to be an atomicunit. The dialogcontrolis useful for dialogsessions in which the
userprimitives used for sendingandreceiving messages are of the nonblocking type. In
thiscase,the user may have multiple requestsoutstanding on the same session,and replies
maycomeback in an orderdifferent from that in which the requestswere sent. The dialog
controlreorders repliesaccording to theorderofrequests. The priority management
serviceis useful for givingprioritytoimportant andtime-bound messages overnormal,
less-important messages. Thesession layer is not required forconnectionless
communication.
Presentation Layer. Thepurpose ofthislayeris torepresent message
information tocommunicating application layerentitiesin a way that preserves meaning
whileresolving syntaxdifferences. For this, the presentation layermayperformone or
moreofthefollowing typesoftransformations onmessage data:Sec. 2.5 • Communication Protocols 69
• A message usually contains structured information that may include any of the
data types used in programming languages-integers, characters, arrays, records,
and so on, including user-defined data types. Translation is therefore required
wherelanguage systems or application programs int.hesource and destination
computers usedifferent representations for these data types.
• Data format conversions are also needed to transfer data between computers when
thehardware of the sending and receiving computers uses different data
representations. In this case, the presentation layer software in the sending
computer transforms message data from the formats used in its own computer to
a set of standard network representations calledeXternal Data Representation
(XDR)beforetransmission. Thepresentation layer software in the receiving
computer transforms the message data from the network representations to the
formats used in its own computer.
• Forapplications dealing with confidential or secret data, the presentation layer
software in the sending computer encrypts message data before passing it to the
session layer. On the receiver side, the encrypted message data is decrypted by the
presentation layer before being passed on to the application layer.
• In a similar manner, when message data is large in volume (such as multimedia
data) or with networks that are slow or heavily loaded, message data may be
compressed anddecompressed by thepresentation layer software in the sending
and receiving computers, respectively.
Application Layer. Theapplication layer provides services that directly support
the end users of the network. Obviously, the functionality implemented at this layer of the
architecture isapplication-specific. Since each application has different communication
needs, no fixed or standard set ofapplication layer protocols can meet the needs of all
applications. Therefore, theapplication layer isbasically acollection ofmiscellaneous
protocols for various commonly usedapplications such as electronic mail, file transfer,
remote login, remote jobentry, and schemas for distributed databases. Some popular
application layer protocols are X.400 (Electronic Mail Protocol), X.SOD(Directory Server
Protocol), FTP (File Transfer Protocol), and rlogin (Remote Login Protocol).
In actual implementation, ofthe seven layers, the first three layers are likely to be in
hardware, the next two layers in the operating system, the presentation layer in library
subroutines in the user'saddress space, and the application layer in the user'sprogram.
ExampleofMessage Transfer in the OSIModel. To illustrate the functions
of the various layers ofthe OSI model, let us consider a simple example ofmessage
transmission. With reference to Figure 2.8, let us assume that a process at the sending
site wants to send a message Mto a process at the receiving site. The sending site's
process builds the message Mand passes itto theapplication layer (layer 7) on its
machine. The application layersoftware adds a header (H7)toMand passes the
resulting message to the presentation layer (6) via the interface between layers 7 and
6. Thepresentation layersoftware performs text compression, codeconversion, security
encryption, and so 011,on the received message, and after adding a header (H6)toit,70
SendingsiteChap.2 •Computer Networks
Receiving site
Network
Fig.2.8 An example illustrating transfer of message M from sending site to receiving
site in the OSI model: H",header added by layer n;T",trailer added by
layern.
it passes the resulting message on to the session layer (5). Depending on the type of
dialog, the session layer software establishes a dialog between the sender and the
receiver processes. It also regulates the direction of message flow. A header (H5)is
added to the message at this layer, and the resulting message is passed on to the
transport layer (4). The transport layer software now splits the message into smaller
units(M.andM2)called packets and adds a header (H4)to each packet. These headers
contain the sequence numbers of the message packets. The packets are then passed on
to the network layer (3). The network layer software makes routing decisions for the
received packets and sets up a logical path between the sending and receiving sites for
transmission of the packets. It then adds a header (H3)to each packet and passes them
on to the data-link layer (2). The data-link layer software adds a header (Hz)and a
trailer(T2)to each of these packets. The trailers contain the checksum of the data in
the corresponding packets. The resulting message units are called frames, which are
passed on to the physical layer (1). The physical layer software simply transmits the
raw bits from the sender's machine to the receiver's machine using the physical
connection between the two machines.Sec.2.5 • Communication Protocols 71
On thereceiver's machine, themessage datatraverses up from the physical layer to
theapplication layer. As the message datatraverses tohigherlevel layers, each layer
performs the funct.ions assigned toitand strips offtheheadersortrailersaddedby itspeer
layerat thesending site. For example, thedata-link layerat thereceiving machine
performs errordetection byrecalculating thechecksum for each frame and comparing it
with the checksum in thetrailerof the frame. It strips off the header(H2)and thetrailer
(T2)from the frames beforepassingthem on to the network layer. The application layer
of thereceiver's machine finallypasseson themessage in itsoriginal form to the
communicating processon thereceiver's site.Noticethat thesoftware of aparticular layer
on thesending machine conceptually communicates only with its peerlayeron the
receiving machine, although physically itcommunicates only with the adjacent layers on
thesendingmachine. Thisabstraction iscrucialtonetwork design.
The IEEE 802 LAN Reference Model
The ISO model is oriented towardWANsratherthanLANsbecauseit wasconceived as
a model for computer networking primarily in thepoint-to-point packet-switching
environment. In aLAN,the hostcomputers areconnected directlyto anetworkcircuitby
relatively simpleinterface hardware. Theinterface hardware andnetworkdriversoftware
in each site can send and receivedata at high speedswith low errorrates and without
switching delays.Theseimportant characteristics ofLANs give considerable advantages
in cost, speed, and reliability incomparison to WANs. Due to these differences in
characteristics between LANs and WANs, and also becauseofthefollowing differences
between theOSImodel and LAN concepts, the OSImodelisgenerally considered to be
unsuitable for LAN environments:
• In the OSI model, information isexchanged between twocommunicating entities
only after they have enteredinto anagreement aboutexchanging information. But
in a LAN, no such prior agreement isneededforcommunication to take place, and
information may bedelivered to adestination from anumberofdifferent sources
withinashorttimeinterval.
• In the OSImodel,the model ofcommunication isgenerally one to one and/orone
to many. But in aLAN,themodelofcommunication isgenerally many to
many.
• The OSI model is oftensaid to be connection oriented. Butcommunications in a
LAN is mostly connectionless.
Thisimpliesthat amodified reference modelparticularly suited to LANsis needed.
Thisproblem wasrealizedlong ago, and a reference modelsuitableforLANswas built
byIEEEin 1983, the IEEE 802 LANReference Model(abbreviated IEEE802 LAN)
[IEEE 1990]. The IEEE802I../ANmodel was builtwith an aim to use as much as possible
of the OSI model while providing compatibility between LANequipments made by
different manufacturers such that data communication can take place between these
equipments with the minimum efforton the part of the users or builders ofLANs.
Therefore, theIEEE 802 LAN model modifies only the lowesttwo layers ofthe OSI72 Chap.2 •Computer Networks
model and does not include specifications for higher layers, suggesting the use of the OSI
model protocols at higher layers. The modifications of the lowest two layers are mainly
concerned with the most important features of LANs that result from the fact that the
physical medium isaresource shared by all sites connected to it.The relationship between
the IEEE 802 LAN model and the OSI model is shown in Figure 2.9.
The OSImodel
elLayer7
(application)
Layer6
(presentation)
Layer5
(session)
Layer4
(transport)
Layer3 Thelowestthree layers
(network) ofthe IEEE802 LAN mod
Layer 2Layer3
(data link)(logical-link control)
Layer 2
Layer 1(medium-access control)
(physical)Layer 1
(physical)
Fig. 2.9 Relationship between the IEEE 802 LAN model and the OSI model.
As shown in the figure, the lowest three layers of the IEEE 802 LAN model are the
physical layer, the medium-access-control layer, and the logical-link-control layer. The
physical layer defines interface protocols for the following four types of media that are
commonly used inLANs: baseband, broadband, fiber optics, and twisted pair.Asthe name
implies, the medium-access-control layer deals with the medium-access-control protocols
for LANs. This layer includes functions associated with both the physical and data-link
layers of the OSI model. It includes the following four standards:
1. The IEEE 802.3 standard, which defines protocols for aLAN having bus topology
that uses the CSMNCD method for medium-access control.
2. The IEEE 802.4 standard, which defines protocols foraLAN having bus topology
that uses the token-passing method for medium-access control. The sites
connected to the bus are arranged in a logical ring to use the token-passing
method.Sec.2.5 • Communication Protocols 73
3. The IEEE 802.5 standard, which defines protocols for a LAN having ring
topology that uses the token-passing method for medium-access control.
4. The IEEE 802.6 standard, which defines protocols for a MAN.
The thirdlayer,thatis,the logical-link-controllayer, contains theIEEE802.2standard.
This standard basically defines acommon logical-link-control protocol that can be used in
conjunction with each of the four standards defined at the media-access-controllayer.
Finally, the relationship between the protocols defined in the OSI model and the
standards defined in the IEEE 802 LAN model is described in the IEEE 802.1 standard.
Further details on the IEEE 802 LAN model can be found in [IEEE 1990, 1985a,b,c].
Network Communication Protocol Case Study:
TheInternetProtocol Suite
Several protocol suites for network systems, such as the IP suite of the U.S. Department
of Defense, Xerox Networking System (XNS) of Xerox, System Network Architecture
(SNA) of IBM, Advanced Peer-to-Peer Networking (APPN) of IBM, and NetBIOS of
IBM, are available today. Of the available protocol suites for network systems, IP is the
most popular and widely used one because it has several attractive features. For instance,
it is suitable for both LANs and WANs; itcan beimplemented on all types of computers,
from personal computers to the larger supercomputers; anditis not vendor specific. It is
an open standard governed by the nonaligned (vendor-independent) InternetEngineering
Task Force (IETF). Every major vendor supports IP, making it the lingua franca on
networking. Moreover, IP is such a dominant networking standard that companies in a
position to use itas their backbone protocol will be able to move quickly to high-speed
internetworking technologies like ATM,FDDI, switched Ethernet and Token Ring, or
IOO-Mbps Ethernet. Owing to itsimportance and wide popularity, IP is described below
as a case study of protocol suites for network systems.
Figure 2.10 shows the structure of the IP suite. It consists of five layers and several
protocols at each layer. The existence of multiple protocols in one layer allows greater
flexibility to the users due to different protocols for different applications having different
communication requirements. The protocols of each layer are briefly described next.
Layers Protocols at each layer
Fig.2.10 The Internet Protocolsuite
structure.I
FTP, TFTP, TELNET,ApplicationSMTP, DNS, others
I
Transport TCP,UDP
I
Network IP,ICMP
Data link ARP, RARP, others
PhysicalSLIP, Ethernet, Token Ring,
others74 Chap.2 •Computer Networks
Physical Layer Protocols. Most systems using the IP suite for a LAN use the
Ethernet protocol at the physical layer. However, LAN products using the IP suite with the
Token Ring protocol used at the physical layer are also available. Moreover,
implementations using the SLIP (Serial Line Internet Protocol), which uses an RS-232
serial line protocol (having speeds from 1200 bits per second to 19.2Kbps), also exist.
Networks using the IP suite with physical layer protocols forsatelliteandmicrowave links
also exist.
Data-link Layer Protocols. Everyprotocol suitedefines some type of
addressing for uniquely identifying eachcomputer on a network. In the IP suite, a
computer's address (called Internet address orIP address) consistsofthe following
information:
1. Net number. Each network using the Internetprotocol suite has a unique net
numberthat is assigned by a central authority-the Network Information Center
(NIC) located at SRI International.
2. Subnet number. This is an optional numberrepresenting the subnet to which the
computer beingaddressed is attached. This numberisassigned by a user to the
subnet when the subnet is being set up. The subnetnumberis stated in the IP
addressofacomputer only when the computer is on a subnet.
3. Host number. Thisnumberuniquely identifies thecomputer beingaddressed on
the network identified by a net number.
All thisinformation isrepresented by a 32-bit address divided into four 8-bit fields.
Each field is calledanoctet.Each octet is separated from the next octet by a period. The
decimalnumberrepresents 1 byteofthe IP address, which can have a value of 0-255.
Therefore, a typical IP address is 190.40.232.12.
There are three classes of Internet address-A, B, andC-plus aprovision for
Internet multicast communication that is useful for applications that need multicast
facility. The format and the permissible values for each octet for each class of Internet
address are shown in Figure 2.11. Due to the increasing importance ofmulticast-based
applications, a groupofuserorganizations hasestablished amulticast network called
MBone (Multicast Backbone) that is a virtual networkin theInternetthatmulticasts audio,
video,white-board, and other streams that need to be distributed to large groups
simultaneously [Macedonia andBrutzman 1994].MBoneaddresses suchnetworkissues
asbandwidth constraints, routingprotocols, datacompression, and network topology.
Manyapplication tools are available freeofcost for a wide variety ofhost platforms.
Today,hundreds ofresearchers useMBonetodevelop protocols andapplications for
groupcommunication.
The three classesof Internet addresses aredesigned to meet the requirements of
different typesoforganizations. Thus class A addresses are used for those networks that
need toaccommodate a largenumberofcomputers (hosts) on a single network, while
class Caddresses allow for more networks but fewer hosts per network, and class B
addresses providea median distribution betweennumberofnetworks and numberof hosts
per network. Notice from Figure 2.11 that there can be only 127class A networks, and theSec.2.5 • Communication Protocols 75
1f--7bits--+I4 24bits ~IGNetnumberI Hostnumber
t+--Octet1---+t+-- Octet2---+t+--Octet 3--.t+-- Octet4----.'
(0- 127) (0- 255) (0- 255) (0- 255)
AnexampleIPaddressis 78.3.50.8
(a)
~"Octet2--+t4---0ctet 3-- ....'41----0ctet 4--t-t
(0- 255) (0- 255) (0- 255)
Anexample IPaddressis130.150.10.28
(b)tB__---:--- 1
~Octet1
(128-191)
HostnumberI
Octet4~
(1- 254)Netnumber
~14Octet2_'4Octet3-14
(0--255) (0- 255)
AnexampleIPaddressis221 .198.141.233
(c)8TJ.... --=- _
t+--Octet1
(192- 233)
Multicastaddress
-ItOctet3----+~ Octet4~
(0·-255) (1- 254)rnE_o _
t+--Octet1-14Octet2
(234- 255) (0 _.255)
Anexample IPaddress is 236.8.26.54
(cf)
Fig. 2.11 Internet address formats: Internet address for (0)class A, (b)class B~
(c)class C networks, and (d)multicastcommunication facility.
highesthostaddress'in a class A network can be255.255.254, thusaccommodating a
possible 16,777,214 hosts. On the otherhand, aclassCnetwork canaccommodate only
254 hosts.
Values from 0 to 255 can be assigned to each octet for the host numberpart of
anaddress, with the restriction that the host numberpartcannotbe all O's or all 1 'so
That is, for example, on anetwork having a net addressof78, a host could have the76 Chap.2 • Computer Networks
address 78.15.0.105 or 78.1.1.255 but it could not have the address 78.0.0.0 or
78.255.255.255. This is because Internet addresses with a host number part that is all
O'sor all 1's are used for special purposes. Addresses with host numberpart set to all
O'sare used to refer to "this host," and a host numberset to all 1'sis used to address
abroadcast message to all of the hosts connected to thenetwork specified in the net
numberpartofthe address.
Amultihomed hostis one that is connected to two or more networks. This implies
that it must have two or more Internet addresses, one for each network to which it is
connected. This means that every Internet address specifies a unique host but each host
does not have a unique address.
Eachpacketreceived by the data-link layer from the network layercontains the
IPaddresses ofthesenderandreceiver hosts.TheseIPaddresses must be converted
tophysical network addresses for transmission across the network. Similarly, physical
network addresses embedded inpackets received from other networks must be
converted to IPaddresses before being passed on to the network layer. The jobof
translating IP addresses to physical network addresses andphysical network addres­
ses to IP addresses isperformed by thedata-link layer. Two important protocols that
belong to this layer are ARP and RARP. ARP(Address Resolution Protocol)
[Plummer 1982] is the Ethernet address resolution protocol that maps known IP
addresses (32 bits long) to Ethernet addresses (48 bits long). On the other hand,
RARP (Reverse ARP)[Finlayson et al. 1984] is the IP address resolution protocol
that maps known Ethernet addresses (48 bits) to IP addresses (32bits), the reverse
ofAR~
Network Layer Protocols. The two network layer protocols are IP [Postel
1981a] and ICMP (Internet Control Message Protocol) [Postel 1981b]. IP performs the
transmission ofdatagrams from one host to another. A datagram is a group of information
transmitted as a unit to and from the upper layer protocols onsendingandreceiving hosts.
Itcontains the IPaddresses ofsending and receiving hosts. For datagram transmission, the
two main jobsofIP arefragmentation andreassembly ofdatagrams into IP packets and
routingofIPpacketsbydetermining the actual path to be taken by each packet from its
source to the destination. For packet routing, a dynamic routingalgorithm that uses a
minimal path selection policy is used.
On thesendinghost, when a datagram isreceived at the network layer from the
transport layer, the IP attaches a 20-byte header. This headercontains a number of
parameters, mostsignificantly the IPaddresses ofthe sending and receiving hosts. Other
parameters includedatagram length and identify information if thedatagram exceeds the
allowable byte size for network packets [called MTU (maximum transferunit)of the
network] and must be fragmented. If a datagram is found to be larger than the allowable
byte size for network packets, the IP breaks up the datagram into fragments and sends
eachfragment as an IP packet. When fragmentation does occur, the IP duplicates the
sourceaddressanddestination address into each IP packet, so that the resulting IP packets
can bedelivered independently ofeach other. The fragments are reassembled into the
originaldatagram by the IP on the receiving host and then passedon to the higher protocol
layers.Sec.2.5 • Communication Protocols 77
Thedatatransmission serviceoftheIPhasbest-effort delivery semantics. Thatis, a
besteffortismadetodeliverthepacketsbutdeliveryisnotguaranteed. TheIPcomputes
andverifiesachecksum thatcoversits ownheader,whichisinexpensive tocalculate.
Thereis no data checksum, whichavoidsoverheads whencrossing routers,butleavesthe
higherlevelprotocols toprovide theirownchecksums. On thereceiving host,ifthe
checksum oftheheaderisfoundto be in error, the packetisdiscarded, with the
assumption that ahigherlayerprotocol willretransmit thepacket.Hence,thedata
transmission serviceofthe IP is unreliable.
TheICMPofthenetwork layerprovides anelementary formofflowcontrol.When
IPpacketsarrive at a host or routerso fast that they are discarded, theICMPsendsa
message to theoriginalsourceinforming it that the data is arriving too fast, which then
decreases theamountofdatabeingsent on that connection link.
Transport LayerProtocols. Transport layerprotocols enablecommunications
between processes runningonseparatecomputers ofanetwork. The two main protocols
ofthislayerareTCP(Transport ControlProtocol) [Postel1981c] and UDP (User
Datagram Protocol) [Postel1980].Thesetwoprotocols aresometimes referredto asTCPI
II)andUDPIIP, respectively, toindicatethat they use the IPat thenetwork layer.
TheTCPprovides aconnection-oriented, reliable, byte-stream serviceto an
application program. It isareliableprotocol becauseany data writtentoaTCPconnection
will bereceivedbyitspeeror anerrorindication will be given. SincetheIPofthenetwork
layerprovides anunreliable, connectionless delivery service,it is theTCPthatcontains
the logic necessary toprovideareliable, virtualcircuitforauserprocess.Therefore, TCP
handles theestablishment andtermination ofconnections between processes, the
sequencing ofdatathatmightbereceived outoforder, the end-to-end reliability
(checksum, positiveacknowledgments, timeouts), and theend-to-end flowcontrol.Note
that the ICMPofthenetwork layerdoes not provide end-to-end flowcontrolservice
between twocommunicating processes. TCPis used in most ofthewell-known Internet
services that aredefinedat theapplication layer.
On theotherhand,UDPprovides aconnectionless, unreliable datagram service.It is
anunreliable protocol becausenoattemptismadetorecoverfromfailureor loss;packets
may be lost, with no errorindication given.Therefore, UDP is very similarto IP with two
additional features that are not provided by IP:process addressing and anoptional
checksum to verify the contents oftheUDPdatagram. Thesetwoadditional featuresare
enoughreasonfor a user processto useUDPinsteadoftryingto use IP directlywhena
connectionless datagram protocol isrequired. UDPisoftenused for experimental or
small-scale distributed applications inwhicheitherreliability ofcommunication is not
important orreliability ofcommunication istakencareofat theapplication level. For
example, rwhoservice,network monitoring, timeservice,TrivialFileTransfer Protocol
(TFTP),and soon,useUDP.
TheIPlayerprovides host-to-host communication service,but thetransport layer
provides process-to-process communication service.Forprocessaddressing, bothTCP
andUDPuse 16-bit integerportnumbers. Thatis, bothTCPandUDP attachaheaderto
the data to be transmitted. Amongotherparameters, thisheadercontains portnumbers to
specifysending andreceiving processes. A portnumberuniquely identifies aprocess78 Chap.2 • Computer Networks
within aparticular computer and is valid only within that computer. Once an IP packethas
beendelivered to thedestination computer, the transport layerprotocols dispatch it to the
specified portnumberat that computer. The process identified by the port numberpicks
up thepacketfrom the port. Furtherdetailsoftheport-based process-addressing
mechanism is given in Chapter3.
Application Layer Protocols. Avarietyofprotocols exist at the application
layer in the IP suite. Thesestandard application protocols areavailable at almost all
implementations ofthe IP suite. Some ofthe most widely used ones are briefly described
next.Additional details of these protocols can be found in [Stallings 1992b]:
1. File TransferProtocol(FTP). This protocol is used to transferfiles to and from
aremotehost in a network. Afiletransfertakes place in the following manner:
• Auserexecutes theftpcommand on its local host, specifying the remote host as
a parameter.
• TheFrPclient process of the user'smachineestablishes aconnection with anFrP
serverprocesson the remote host using TC~
• The user is then prompted for login name and password toensurethat the user is
allowedto access the remote host.
•Aftersuccessful login, the desired file(s) may be transferred ineitherdirection by
usingget(fortransferfrom remote to local machine) andput(fortransferfrom
local to remote machine) commands. Both binary and text files can be transferred.
The user can also listdirectories or move between directories ofthe remote
machine.
2. TrivialFileTransferProtocol(TFTP). This protocol also enablesusers totransfer
files to and from a remote host in a network. However, unlike FfP,it uses UDP (not TCP),
itcannotchecktheauthenticity of the user, and it does not provide the facilities oflisting
directories and moving between directories.
3.TELNET. This protocol enables terminals andterminal-oriented processes to
communicate withanotherhost on the network. That is, a user can executethetelnet
command on its local host to start a login session on a remotehost. Once a login
session is established, telnet enters the input mode. In this mode, anything typed on the
keyboard by the user is sent to the remote host. The input mode enteredwill beeither
character or line mode depending on what the remotesystem supports. In the character
mode,everycharacter typed on the keyboard isimmediately sent to the remote host
forprocessing. On the other hand, in the line mode, alltyped material is echoedlocally,
and(normally) onlycompleted Jines are sent to the remote host for processing. Like
FTP,TELNET uses TCP.
4.SimpleMail TransferProtocol(SMTP). This protocol enablestwo user processes
on anetwork toexchange electronic mail using a TCP connection between them.
5. DomainNameService(DNS). Theclientprocesses ofapplication protocols, such
asFT~TFT~TELNET, SMTP, can be designed to accept Internetaddresses (in theirSec.2.5 • Communication Protocols 79
decimal form) from a user to identify the remote host with which the user wants to
interact. However, as compared to numeric identifiers, symbolic names are easierfor
human beings to remember and usc. Therefore, theInternetsupports a scheme for the
allocation and use of symbolic names for hosts and networks, such asasuvax.eas.asu.edu
oreas.asu.edu. The named entities are called domains and the symbolic names are called
domain names. The domain name space has a hierarchical structure that is entirely
independent of the physical structure of the networks that constitute the Internet. A
hierarchical naming scheme provides greaterflexibility ofname space management
(described in detail in Chapter10).
When domain names are accepted asparameters byapplication protocols such as
FfP, "fFfP, TELNET, SMTP, and so on, they must be translated to Internet addresses
before making communication operation requests to lower level protocols. This jobof
mapping domain names to Internet addresses isperformed by DNS. Furtherdetails of
DNS are given in Chapter10.
2.5.2Protocols forDistributad Systams
Although the protocols mentioned previously provide adequate support for traditional net­
work applications such as file transfer and remote login, they are not suitable fordistributed
systems and applications. This is mainly because of the following special requirements of
distributed systems as compared tonetwork systems [Kaashoek et a1.1993]:
• Transparency. Communication protocols for network systems use location­
dependent processidentifiers (such as port addresses that are unique only within
a node). However, for efficient utilization ofresources, distributed systems
normally support process migration facility. With communication protocols for
network systems, supporting process migration facility is difficult because when a
process migrates, its identifier changes. Therefore, communication protocols for
distributed systems must use location-independent processidentifiers that do not
changeeven when a process migrates from one node to another.
•Client-server-based communication. Thecommunication protocols for network
systems treat communication as aninput/output device that is used to transport
data between two nodes of a network. However, most communications in
distributed systems are based on the client-server model in which a client requests
a server to perform some work for itby sending the server a message and then
waiting until the server sends back a reply. Therefore, communication protocols
fordistributed systems must have a simple, connectionless protocol having
features to supportrequest/response behavior.
• Group communication. Several distributed applications benefit from group
communication facility that allows a message to be sent reliably from one sender
tonreceivers. Although many network systems providemechanisms to do
broadcast or multicast at the data-linklayer,theircommunication protocols often
hide these useful capabilities from the applications. Furthermore, although
broadcast can be done by sending npoint-to-point messages and waiting for n
acknowledgments, thisalgorithm isinefficient and wastes bandwidth. Therefore,80 Chap.2 •Computer Networks
communication protocols for distributed systems must support more flexible and
efficient group communication facility inwhich agroup address can be mapped on
one or more data-link addresses and the routing protocol can use a data-link
multicast address to send a message to all the receivers belonging to the group
defined by the multicast address.
• Security. Security is a critical issue in networks, and encryption is the commonly
used method to ensure security of message data transmitted across a network.
However, encryption is expensive to use, and all nodes and all communication
channels of a network are not untrustworthy for a particular user. Therefore,
encryption should be used only when there is a possibility of a critical message to
travel via an untrustworthy node/channel from its source node to the destination
node. Hence a communication protocol is needed that can support a flexible and
efficient encryption mechanism in which a message is encrypted onlyifthe path
it takes across the network cannot be trusted. Existing communication protocols
for network systems do not provide such flexibility.
•Network management. Network management activities, such as adding/removing
a node from a network, usually require manual intervention by a system
administrator to update theconfiguration files that reflect thecurrent configuration
of the network. For example, the allocation of new addresses is often done
manually. Ideally, network protocols should automatically handle network
management activities to reflect dynamic changes in network configuration.
• Scalability. A communication protocol for distributed systems must scale well and
allow efficient communication totake place in both LAN and WANenvironments.
A single communication protocol must be usable on both types of networks.
Twocommunication protocols that have been designed to achieve higher throughput
and/or fast response in distributed systems and to address one or more of the issues stated
above are VMTP (Versatile Message Transport Protocol) andFLIP (Fast Local Internet
Protocol). VMPT provides group communication facility and implements a secure and
efficientclient-server-based communication protocol [Cheriton and Williamson 1989].On
the other hand, FLIP is designed to support transparency, efficient client-server-based
communication, group communication, secure communication, and easy network
management [Kaashoek et al. 1993]. These protocols are briefly described next.
The Versatile Message Transport Protocol
This is a transport protocol that has been especially designed for distributed operating
systems and has been used in the V-System [Cheriton 1988]. It is a connectionless
protocol that has special features to support request/response behavior between a client
and one or more server processes. It is based on the concept of a message transaction
that consists of a request message sent by a client to one or more servers followed by
zero or more response messages sent back to the client by the servers, at most one per
server. Most message transactions involve a single request message and a single
response message.Sec.2.5 • Communication Protocols 81
Forbetterperformance. aresponse is used to serve as an acknowledgment for the
corresponding request, and a response is usually acknowledged by the next requestfrom
the same client. Using special facilities, a clientcanrequestfor animmediate
acknowledgment for itsrequestor aservercanexplicitly requestanacknowledgment for
itsresponse.
Tosupporttransparency and toprovidegroupcommunication facility,entitiesin
VMTPareidentified by64-bitidentifiers that are unique, stable, and independent ofthe
host address. The latter property allowsentitiesto bemigrated andhandledindependent
ofnetwork layeraddressing. A portion of the entity identifier space isreserved for entity
groupidentifiers that identify a group ofzero or more entities. For example, each file
server, as a separateentity, may belong to the group offileservers,identified by a single
entity group identifier. To find out the locationof aparticular file directory, a clientcan
send a request for this information to the entity group of file serversand receive a response
from the server containing the directory. A group management protocol has been provided
forcreating newgroups,adding new members ordeleting members from an existing
group, and querying information aboutexistinggroups.
Again for betterperformance, VMPTprovides aselective retransmission mechanism.
The packets ofamessage aredividedintopacketgroups that containup to amaximum
of16kilobytes ofsegment data. The data segment is viewed as a sequence ofsegment
blocks, each of 512 bytes (exceptfor the last, which may be only partly full), allowing the
portions of thesegment in apacketgroupto bespecified by a32-bitmask. Each packet
contains adelivery mask field that indicates theportionsofthe datasegment thepacket
contains. Themaximum numberofblocksper packet is determined by thenetwork
maximum packetsize. When a packetgroup is received, the delivery masks for the
individual packetsare ORed togetherto obtain a bitmapindicating whichsegment blocks
are still outstanding. Anacknowledgment packetcontains this bitmap, and the sender
selectively retransmits only the missing segment blocks.
TheVMTPuses arate-based flow control mechanism. In thismechanism, packetsin
apacketgroupare spaced out with interpacket gaps to reduce the arrival rate at the
receiver. The mechanism allowsclientsand servers to explicitly communicate their
desiredinterpacket gap times and to make adjustments based on selective retransmission
requests described previously. For example, if thebitmapreturned by thereceiver
indicates that every otherpacketneeds to be retransmitted, thesenderreasonably increases
theinterpacket gap. If the next acknowledgment bitmapindicates that every fourth packet
is missing, the senderagainincreases theinterpacket gap. When no packetlossoccurs,the
senderperiodically reducestheinterpacket gap to ensure that it is transmitting at the
maximum rate thereceivercan handle. Thus, selective retransmission provides feedback
toindicatethat the rate of transmission is too high and also minimizes theperformance
penaltyarisingfromoverflooding of packets from a fast senderto a slow receiver.
Anoptimization used in VMTPis todifferentiate between idempotent and
nonidempotent operations. Anidempotent operation is one whose execution can be
repeated anynumberoftimeswithout there being any side effects. For example,
requesting the time ofday is a typicalidempotent operation, buttransferring money
from one bank accounttoanotheris anonidempotent operation. In VMTP, a servercan
label aresponse toindicate that amessage transaction wasidempotent. By doing so,82 Chap.2 • Computer Networks
arrangements need not be made for retransmitting the response when it is lost because
theservercanreproduce the response when the requestisretransmitted. However, when
aresponse isnonidempotent, VMPTprevents the server from executing a request more
than once.
In addition to the aforementioned features, VMTP provides a richcollection of
optional facilities that expanditsfunctionality andefficiency in various situations. One
such facility that is particularly useful for real-time communication is the facility of
conditional message delivery. With this facility, a clientcan specify that its message
should only be delivered if theserveris able to process it immediately. Theoptional
facilities arecarefully designed to provide critical extensions to the basic facilities without
imposing asignificant performance penalty,especially oncommon-case processing.
Furtherdetailsofthe VMTP protocol can be found in [Cheriton 1986,Cheriton and
Williamson 1989].
The Fast Local InternetProtocol
This is a connectionless protocol for distributed operating systems. It has been used in
theAmoeba distributed system[Mullender eta1.1990]. Its main features include
transparency, security, easy network management, groupcommunication facility, and
efficientclient-server-based communication facility.The following description is based on
the material presented in(Kaashoek et al. 1993].
For transparency, FLIP identifies entities, called network service access points
(NSAPs), withlocation-independent 64-bit identifiers. Sites on an internetwork can have
more than one NSAP, typically one or more for each entity (e.g., process). Each site is
connected to theinternetwork by aFLIP box thateithercan be a software layer in the
operating systemofthecorresponding site or can be run on a separate communications
processor. Each FLIP box maintains a routing table that is basically adynamic hint cache
mapping NSAPaddresses on data-link addresses. Special primitives areprovided to
dynamically registerandunregister NSAPaddresses into the routing table ofaFLIPbox.
An entity can registermore than one address in a FLIPbox (e.g., its own address to
receivemessages directed to the entity itselfand the null address to receive broadcast
messages). FLIPuses aone-way mapping between the private addressused toregisteran
entity and the public address used to advertise the entity. A one-way encryption function
is used to ensurethat one cannotdeduce the private address from the public address.
Therefore, entitiesthat know the (public) address ofan NSAP (because they have
communicated with it) are not able to receive messages on that address, becausethey do
not know the corresponding private address.
The FLIP messages aretransmitted unreliably betweenNSAPs. A FLIP message may
beofany size less than 232-1bytesIf a message is too large for a particular network,
it isfragmented intosmallerchunks,calledfragments. Afragment typically fits in a single
networkpacket. The basic function ofFLIP is to route an arbitrary-length message from
thesourceNSAPto thedestination NSAP. The path selection policy is based on the
information stored in the routing tables ofeach FLIP box about the networks to which it
isconnected. The two main parameters used for this purposeare thenetworkweightand
asecurity bit. A lownetwork weight means that the network is desirable on which toSec.2.6 • Internetworking 83
forwardamessage. Thenetwork weightcan be based, for example, onphysical properties
ofthenetwork, such asbandwidth and delay. On the otherhand, the securebitindicates
whether sensitive datacan be sent unencrypted overthenetwork or not.
The three types ofcallsprovided inFlJPforsendingamessage to apublicaddress
areflip_unicast, flip_multicast, andflip_broadcast. Thesecallsprovide bothpoint-to­
point and groupcommunication facilities. Thegroupcommunication protocols make
heavy use of flip_multicast. Thishas theadvantage that a group ofnprocesses can be
addressed using one FLIPaddress, evenifthey are locatedonmultiple networks.
Although FLIPdoes not encryptmessages itself, it provides thefollowing two
mechanisms forsecuredeliveryofmessages. In the first mechanism, asendercan mark
itsmessage sensitive by using the securitybit. Such messages are routed only overtrusted
networks. In thesecondmechanism, messages routedoveranuntrustcd networkby aFLIP
aremarkedunsafebysettingtheunsafebit.Whenthereceiverreceives themessage, by
checking theunsafebit, it can tell the senderwhetheror not there is a safe route between
them. If a safe route exists,thesendertries to send sensitive messages inunencrypted form
but with the securitybit set. If at some stage duringroutingno further trustedpath is found
for themessage (whichcan only happendue tonetwork configuration changes), it is
returned to thesenderwith theunreachable bit set. If this happens, thesenderencrypts the
message andretransmits it with the securitybitcleared.Therefore, message encryption is
done only when required.
The FLIP supports easynetwork management becausedynamic changesinnetwork
configuration areautomatically handled. The only network management jobthatrequires
humanintervention is thespecification oftrustedanduntrusted networks. Thatis,FLIP
relies on the systemadministrator to mark a network interface astrustedoruntrusted,
becauseFLIPitselfcannotdetermine if anetwork can beconsidered trusted.
Onerequirement for which FLIPdoes not provide fullsupport iswide-area
networking. Although FIJPhas been used successfully in small WANs, itdoes not scale
wellenoughto be used as the WAN communication protocol in a large WAN. FLIP
designers tradedscalability forfunctionality becausethey felt that wide-area communica­
tionshouldnotbedone at the network layer, but in higherlayers.
Furtherdetailsof theFLIPprotocol can be found in (Kaashoek eta1.1993].
2.6INTERNETWORKING
We saw in Chapter 1 that two desirable featuresofdistributed systemsareextensibility
andopenness. Both these features call for a need to integrate two or more networks
(possibly supplied bydifferent vendors and based on different networking standards) to
form a single network so thatcomputers thatcouldnotcornmunicate becausethey were
ondifferent networks beforeinterconnection can now communicate with each other.
Interconnecting of two or more networks to form a single network iscalled
internetworking, and theresulting networkiscalledaninternetwork. Therefore, aWANof
multiple LANsis aninternetwork.
Internetworks areoftenheterogeneous networks composed ofseveralnetwork
segments that may differ in topology andprotocol. Forexample, aninternetwork may84 Chap.2 • Computer Networks
have multiple LANs, someof whichmay havemultiaccess bustopology whileothers may
have ring topology; some of these LANs may be using Ethernet technology while others
maybeusing Token Ring technology; and some segments of the network may be using
the IP suite while others may be using IBM's SNA (System Network Architecture)
protocol suite. Internetworking allows these relatively unrelated networks to evolve into
a single working system. That is, the goal of internetworking is to hide the details of
different physical networks, so that the resulting internetwork functions as a single
coordinated unit.
The three important internetworking issues are how to interconnect multiple
(possibly heterogeneous) networks into a single network, which communication
medium to use for connecting two networks, and how to manage the resulting
internetwork. Some commonly used technologies to handle these issues are described
below. An important point to remember here is that handling of intemetworking issues
becomes much easier if the network segments of the resulting internetwork were
designed using widely accepted standards instead of proprietary topologies and
protocols. If an organization has designed its networks using nonstandard technologies,
interconnection to global networks may require tearing of the existing networks and
starting over again. Therefore, adherence to standards is very important from an
internetworking point of view.
1.6.1Interconnection Technologies
Interconnection technologies enable interconnection of networks that may possibly
have different topologies and protocols. Interconnecting two networks having the
same topology and protocol is simple because the two networks can easily commu­
nicate with each other. However, interconnecting two dissimilar networks that have
different topologies and protocols requires an internetworking scheme that provides
some common point of reference for the two networks to communicate with each
other. That point of reference might be a high-level protocol common to the two
networks, a device that allows interconnection of different topologies with different
physical and electrical characteristics, or a protocol that allows operating environment
differences to be ignored. The most commonly used approach is to make use of
common high-level protocols for moving data between common layers on a commu­
nications model such as the OSI or the IP suites. Internetworking tools, such as
bridges, routers, brouters, and gateways, make extensive use of this approach. As
described next, each of these tools has strengths, weaknesses, and specific applica­
tions in internetworking. These tools are "blackbox" intemetworking technologies that
enable interconnection of similar or dissimilar networks to form a single network
system.
Bridges
Bridges operate at the bottom two layers of the OSI model (physical and data link).
Therefore, they are used to connect networks that use the same communication
protocols above the data-link layer but mayormay not use the same protocols at theSec.2.6 • Internetworking 85
physical anddata-link layers. For example, bridgesmay be used to connect two
networks, oneofwhich uses fiber-optic communication medium and the otheruses
coaxialcable; or one of which uses Ethernet technology and theotheruses Token Ring
technology. But both networks must use the same high-level protocols (e.g.,TCP/IPor
XNS) to communicate.
Thesimilarity ofhigherlevelprotocols impliesthatbridgesdo notmodifyeitherthe
format or the contentsofthe frames when they transferthem from one network segment
toanother(theysimplycopy the frames). Hencebridges feature high-level protocol
transparency. Theycantransferdatabetween twonetworksegments over a third segment
in themiddlethatcannotunderstand the data passingthroughit. As far as the bridgeis
concerned, theintermediate segment existsforroutingpurposes only.
Bridges areintelligent devicesin the sense that they use a processoflearning
and filtering in data forwarding to keep network traffic within the segment ofthe
network to which it belongs. Therefore, bridgesare also useful in network partitioning.
When the performance of anetwork segment degrades due toexcessive network
traffic, it can be brokeninto two network segments with a bridge interconnecting the
twosegments.
Routers
Routersoperateat thenetworklayerofthe OSI model. Therefore, routersdo notcarewhat
topologies oraccess-level protocols theinterconnected network segments use.Since
routersuse thebottomthreelayersof the OSI model,they areusuallyused tointerconnect
thosenetworks that use the same high-level protocols above the network layer. Note that
theprotocols ofdata-link andphysical layersaretransparent to routers. Therefore, iftwo
network segments usedifferent protocols at these two layers, a bridgemust be used to
connectthem.
Unlikebridges, routersdo not view an internetwork from end to end. That is,
bridgesknow the ultimate destination ofa data, but routers only know which is the
nextrouterfor the data being transferred acrossthenetwork. However, routersare
smarterthanbridgesin the sense that they not only copy a"data from one network
segment to another, but theyalsochoosethe best route for the data by using
information in arouting table to make this decision. Thatis,managing traffic
congestion is a big plus of routers; they employa flowcontrolmechanism todirect
traffic on to alternative, lesscongested paths.
Routers arecommonly used to interconnect thosenetwork segments oflarge
intemetworks that use the same communication protocol. They are particularly useful in
controlling traffic flow by makingintelligent routingdecisions.
Aninternetwork often uses both bridgesand routers to handle both routingand
multiprotocol issues. This requirement hasresulted in thedesignofdevices called
brouters, which are a kind ofhybridofbridgesand routers. They providemanyofthe
advantages ofbothbridgesandrouters.They are complex, expensive, anddifficult to
install, but for very complex heterogeneous intemetworks in which the networksegments
use the same high-level communication protocols, they often provide the best
internetworking solution.86 Chap.2 •Computer Networks
Gateways
Gateways operateat the top three layersofthe OSI model (session, presentation, and
application). Theyare the most sophisticated internetworking tools and are used for
interconnecting dissimilar networks that usedifferent communication protocols. Thatis,
gateways are used to interconnect networks that are builton totally different
communications architectures. Forinstance, agateway may be used to interconnect two
networks, oneofwhichuses the IP suite and the otheruses the SNA protocol suite.
Sincenetworks interconnected by agateway usedissimilar protocols, protocol
conversion is themajorjobperformed bygateways. Additionally, gateways sometimes
alsoperform routingfunctions.
2.6.2WhichCommunication M.dlum toUs.?
Another important issue ininternetworking is todecidethecommunication medium that
shouldbe used to connecttwonetworks. This largely dependson thelocations ofthe two
networks and the throughput desired. Forexample, FDDI (Fiber Distributed Data
Interface), specified by theAmerican National Standards Institute (ANSI), operates at a
speedofl00Mbps and is an ideal high-bandwidth backbone forinterconnecting LANs
that arelocatedwithinamultistory building orhousedinseveralbuildings in acampusJike
environment.
Ifthe twonetworks arelocateda little far from each other(such as on opposite sides
ofa town or in nearbycities),then they may be connected byleasedtelephone lines if the
data traffic between the twonetworks is not heavy. If the datatrafficbetween the two
networks is heavy, dedicated lines may be used to interconnect the twonetworks. Use of
dedicated lines is also suggested forsecurity reasonswhen the data exchanged between
the twonetworks oftencontains sensitive information.
Finally, if the two networks arelocatedvery far from each other(such as in different
countries or in two distantly locatedcitiesofacountry), thencommunication channels of
public data networks, such astelephone lines orcommunication satellites, may be used to
interconnect them.Long-haul communication channels areexpensive. Moreover, if
communication channels ofa public data network are used to interconnect the two
networks, inconsistencies oftraffic and systemreliability influence the data throughput
between the twonetworks. Security is also a problem in this case. The data throughput
problem may besolvedto someextentby using one'sownmethodoftrafficrouting.For
example, ifthe twonetworks arelocatedin New York and Los Angeles, the total traffic
between the two networks may be routedthrough bothDenverandDallasforbetter
throughput. Methods tohandlethesecurityproblem aredescribed inChapter 11.
1.6.3NetworkManagement Technologies
Network management deals with the monitoring andanalysis ofnetwork statusand
activities. Network monitoring tools watch network segments andprovideinformation on
datathroughput, node and link failures, and otherglobaloccurrences on thenetwork that
may beusefulinsomemannertonetwork managers. Simplenetwork monitoring toolsSec.2.6 • Internetworking 87
reporttheexistence, ifnot thecause,ofaproblem in any part ofthenetwork. On theother
hand,network analysis toolsanalyzenetwork activities from a wide varietyofangles at
adepththatincludes packet..levelprotocol analysis. They add quantitative information to
themonitor's qualitative databyproviding a wide array ofcomplete information aboutthe
operation of anetwork.
Management of aninternetwork is more complex thanmanagement ofasimple
independent LANbecause localproblems becomeglobalproblems when several LANs
areinterconnected to form an internetwork. Pinpointing thelocationofaproblem in an
internetwork is tricky becausetheproblem maybeon a local or remote LAN. Therefore,
the tools available formanaging asingleindependent LANeitherwork poorly or do not
work at all when appliedtointemetworks. Theheterogeneous natureofinternetworks is
also amajorobstacle in thedesignofwidelyacceptable management tools for
internetworks. Everymanager ofaninternetwork dreamsofa single tool that has the
following features:
1. It can enfoldall theprotocols anddevicesfound on a typical heterogeneous
internetwork.
2. Itshouldbe easy to usc. Highly graphical userinterface that allows rapid user
interaction andreducesthe need for highlyskillednetworkanalystsat most levels
isdesirable.
3. Itshouldbeintelligent in the sense that it can learn and reasonas itisolates
network faults.
4.Itshouldhave no preferences regarding adevice's vendor or protocol.
Unfortunately, no such tool existsatpresent.However, the future looks encouraging,
asseveralnetwork management frameworks andnetwork management profilesare on the
way. Toprovideformanagement of future interoperable multivendornetworks, the ISO,
the IETF, the OSf~andotherorganizations arecurrently developing management
standards forcommunications networks based on severalreference modelsandnetwork
management frameworks. Ofthe various emerging standards, threestandards seem to be
promising for future network management tools.TheseareSimpleNetwork Management
Protocol (SNMP), Common Management Information Protocol (CMIP), andDistributed
Management Environment (DME).
TheSNMPis aclient-server protocol suitableforapplications thatoperatein the
client-server mode and do not requirereal-time notification of faults. It was introduced in
the late 1980s to controlandmonitor networks that use the IP suite. Because ofits
simplicity forimplementation andlowercosts,SNMP-based tools are being implemented
by most of the network management element vendors.10address speed, security, and
manager-to-manager communication capability, IETFisworking on version 2 ofSNMP
protocols. FurtherdetailsofSNMPmay be found in [DataproI990, Shevenell 1994,Janet
1993].
TheeMIPis anetwork management standard developed by OSI(ISO/CCITT). It is
designed tofacilitate interoperability and true integration between largenumbers of
separate, isolated network management products andservices in a multi vendor88 Chap.2 •Computer Networks
environment. It is based on a manager-agent model. The managing system invokes the
management operations, and the managed system forwards the notifications to the
manager. Communications between managing systems is also facilitated by the agent­
manager role. Further details of CMIP may befound in [IT 1990, Janet 1993].
There are a lot more SNMP-based products available as network management tools
as compared to CMIP-based products. In spite of providing richer functionality and more
sophisticated features than SNMP-based products, CMIP-based products are not enjoying
rapid growth because they are more expensive, more complex, and require more
processing power to implement.
The OSF's DME is a set of specifications for distributed network management
products. Its goal is to provide a framework to enable a consistent system and network
management scheme across a global, multivendor distributed environment. To achieve
this goal, the design of DME has been based on SNMP, CMIP, and other de facto
standards. DME-based products are not yet available in the market. Further details of
DME may be found in [Datapro 1993].
1.6.4Internetwork (aseStudy: The Internet
The Internet is the best example of an internetwork. It is a single worldwide collection
of interconnected heterogeneous networks that share a uniform scheme for addressing
host computers and a suite of agreed protocols. Hosts and other resources on the
Internet are named by using the DNS (Domain Name System) naming scheme
described in Chapter 10.
The Internet has its roots in the ARPANET system of the Advanced Research
Projects Agency of the U.S. Department of Defense. ARPANET was the first WANand
had only four sites in 1969.The Internet evolved from the basic ideas of ARPANETand
was initially used by research organizations and universities to share and exchange
information. Since restrictions for commercial use were lifted in 1989, the Internet has
rapidly grown into an internetwork that now interconnects more than 10,000 networks,
allowing more than 3million computers and morethan40 millioncomputer users inmore
than 150 countries around the world to communicate with each other. The Internet
continues to grow at a rapid pace.
The Internet is a vast ocean of information that is of interest to a wide variety of
users.Several user-friendlytools areavailable thatallow users tosuccessfully navigatethe
Internet and find useful information for one's own purposes. A few of the most popular
of these tools are Gopher, Archie, WAIS (Wide-Area Information Servers), WWW
(World-WideWeb), and Mosaic.
Gopher[Martin 1993] is a text-based tool that provides hierarchical collections of
information of all sorts across the Internet. It is a seemingly endless maze of directory
menus. Developed at the University of Minnesota in 1991, Gopher is currently the most
commonly used tool to locate information on the Internet. For further details, ftp to
boombox.micro.umn.edu and look in the directory /pub/gopher/docs.
Archieis a collection of tools that allows searching of indexes of files available on
public servers by anonymous IIpon the Internet. For further details, gopher to
gopher.gmu.edu.Sec.2.6 •Internetworking 89
Wide-Area Information Servers (WAfS) is a group of freeware, shareware, and
commercial software programs that help users locate information on the Internet. For
further details, gopher to gopher.gmu.edu.
TheWorld-WideWeb(WWW) is ahypermedia distribution system that uses
hypertext links to other textual documents or files. With this facility, users can click
on a highlighted word or words in a document to provide additional information about
the selected word(s). With WWW, users can also access graphic pictures, images,
audio clips, or even full-motion video that is set up at sites all over the world to
provide a wealth of useful information. WWW was invented by the European Centre
for Nuclear Research (CERN) in 1992 in an attempt to build a distributed hypermedia
system. WWW traffic is the fastest growing part of the Internet and it is today's
preferred vehicle for the Internet commerce. For further details, refer to [Vetter et al.
1994] or gopher to info.cern.ch.
Mosaicis ahypermedia-based browsing tool for finding and retrieving infor­
mation from the Internet. Mosaic browsers are currently available for UNIX work­
stations running X Windows, pesrunning Microsoft Windows, and the Apple
Macintosh computers. Mosaic can access data in WWW servers, WAIS, Gopher
servers, Archie servers, and several others. Its popularity is rapidly increasing
because of its many useful features and capabilities. For further details, refer to
[Vetter et al. 1994] or anonymous ftp to ftp.NCSA.uiuc.edu and look in the
directory IPC/Mosaic.
The worldwide scope of the Internet makes it perhaps the single most valuable tool
for use in many significant ways by both non-profit and commercial organizations. Some
of the important current strategic uses of the Internet are listed here. The following
description is based on the material presented in [Nejrneh 1994]:
1. On-line communication. The electronic mail service (known as e-mail)on the
Internet is extensively used today by computer users around the world to communicate
with each other. With this facility, the Internet has proved to be a rapid and productive
communication tool for millions of users. As compared to paper mail, telephone, and
fax, e-mail is preferred bymany because (a) itis faster than paper mail; (b) unlike the
telephone, the persons communicating with each other need not be available at the
same time; and (c) unlike fax documents, e-mail documents can be stored in a
computer and be easily manipulated using editing programs.
2.Software sharing. The Internet provides access to a large number of shareware
software development tools and utilities. A few examples of such available shareware
tools are C++ compilers, code libraries, mail servers, and operating systems (all available
viajipfromsunsite.unc.edu). The Free Software Foundation also provides a wealth of
GNU software (for details anonymous ftp to prep.ai.mit.edu and look in the directory
IpubIGNU).
3. Exchange ofviews on topics ofcommon interest. The Internet has a number of
news groups. Each news group allows a group of users to exchange their views on some
topic of common interest. For example, the news group comp.os.os'l.advocacy contains
candid dialog about the OS/2operating system.90 Chap.2 •Computer Networks
4. Posting ofinformation ofgeneral interest. The Internet is also being extensively
used as a large electronic bulletin board on which information of general interest can be
posted to bring it to the attention of interested users around the world. Some commonly
postedinformation includecareeropportunities, conference and event announcements,
and calls for papers for conferences andjournals.
5. Product promotion. Severalcommercial organizations are effectively using the
Internet services for promoting their products. These organizations make use of corporate
ftp,Gopher, or WWW server sites focused on disseminating timelyinformation about
corporate happenings, productannouncements, recent strategic alliances, press releases,
andotherinformation ofpotential interest to existing and prospective customers. For
example, comp.sys.sun.announce news group contains information about Sun Micro­
system's latest product announcements.
6.Feedback about products. In addition to product promotion, commercial
organizations are also using the Internet to gather information about user satisfaction of
existing products, market opportunities of new products, and ideas for potential new
products. This is usually accomplished by putting up an interactive survey application by
theorganization on a WWW or Gophersite on the Internet.
7.Customer support service. Many software organizations are also using theInternet
toprovideunprecedented levels of timely customer support. The combined electronic
mail,ftp,andotherservices on the Internet provide all of the enabling tools necessary to
provide such first-rate customer support. For example, bugs in fielded software products
can bereportedto anorganization viaelectronic mail, and bug fixes, minor releases, work­
arounds, known problems and limitations, and general advice about a product can bemade
available by an organization to itscustomers via anftpserver.
8.On-linejournals and magazines. The Internet now has literally hundreds of
electronic subscriptions that can be found both for free and low cost. There are many
Gopher and WWW sites on the Internet that deal with electronic versions of many journals
and magazines. For example, Dow Jones NewslRetrieval provides fee-based access to the
electronic version of the WallStreet Journal on the Internet. Researchers are working in
thedirection toextendthis idea to support full-fledged electronic libraries on the
Internet.
9.On-line shopping. The Internet has also facilitated the introduction of a new
marketconceptthat consists of virtual shops. These shops remain open 24 hours all the
year round and are accessible to purchasers all around the world. They provide
information about products or services for sale through ftp,Gopher, or WWW servers.
Using the Internet services, customers submit specific product queries and request specific
sales quotes. Through a well-defined authorization andauthentication scheme, the Internet
services are then used to accept orders placed by the customers, to handle order payments,
and to track orders to fulfillment. For example, the Internet Mall is a collection of shops,
eachproviding several products or services for sale. For a list of the available products or
services at the Internet Mall, ftp to ftp.netcom.com and look in the directory /pubs/
Guides.Sec.2.7 • ATMTechnology 91
10.Worldwide videoconferencing. Worldwide video conferencing is an emerging
service on the Internet that allows a group of users located around the globe to talk and
interact with each other as if they were sitting and discussing in a single room. The ·CU­
SeeMe system developed at CornelllJniversity is an example of an Internet-based video­
conferencing system. For information on CU-SeeMe, ftp to gated.comell.edu and look in
the directory /pub/videoICU-SeeMe.FAQ.7-6.txt.
2.7ATMTECHNOLOGY
Asynchronous Transfer Mode (ATM) is often described as the future computer networking
paradigm. Itis a high-speed, connection-oriented switching and multiplexing technology
that uses short, fixed-length packets (called cells)to transmit different types of traffic
simultaneously, including voice, video, and data. Itisasynchronous in that information
streams can be sent independently without a common clock. This emerging technology is
briefly described next. For a more complete treatment of the state of the art in ATM
technology,see [DePrycker 1993,Newman 1994,Fischer et a1.1994,Haendel et al. 1994,
Vetter1995,Kim and Wang 1995].
2.7.1 Main FeaturesofATMTechnology
ATM technology is expected to have an enormous impact on future distributed systems
because of its following attractive features:
1. It enables high-bandwidth distributed applications by providing data transmission
speeds of 155Mbps, 622Mbps, and potentially 2.5Gbps. This feature will make possible
several new distributed applications, suchasapplications based on video-on-demand
technique, video-conferencing applications, and applications that need to access remote
databases of multimedia data.
2. It provides high transmission speeds for both local and wide-area networks and
services, enabling high-powered distributed applications that previously had little hope of
extending beyond LAN environments to be used in WAN environments as well.
3.Itsupports both the fundamental approaches to switching (circuit switching and
packet switching) within a single integrated switching mechanism (called cellswitching).
This feature makes itsuitable both for distributed applications that generate constant-bit­
rate(eBR)traffic and distributed applications that generate variable-bit-rate (VBR)
traffic. For instance, applications dealing with video and digitized voice generate CBR
traffic.Constant-bit-rate traffic requires guaranteed throughput rates and service levels.
On the other hand, most data applications generate VBR traffic. Variable-bit-rate traffic
can tolerate delays and fluctuating throughput rates.
4. It uses the concept of virtual networking to pass traffic between two locations.
This concept allows the available bandwidth of a physical channel to be shared by
multiple applications, enabling multiple applications to simultaneously communicate at92 Chap. 2 • Computer Networks
different rates over the same path between two end points. That is, it allows the total
bandwidth available to be dynamically distributed among a variety of user applications.
5. In addition to point-to-point communication in which there is a single sender and
a single receiver, itcan easily support multicasting facility inwhich there isa single sender
but multiple receivers. Such a facility is needed for transmitting broadcast television to
many houses at the same time. Many collaborative distributed applications also require
frequent use of this kind of facility.
6. It enables the use of a single network to efficiently transport a wide range of
multimedia data such as text, voice, video, broadcast television, and so on. Therefore, the
use of separate networks such as a telephone network for voice, an X.25 network for data,
and a cable television network for video can now bereplaced by a single ATM network
thatprovides a means for integrating voice, video, data, and other information. This
integration will in tum lead to substantial cost savingsandsimplification in the design of
communication networks.
7. It is flexible in the way it grants access to bandwidth. That is, it enables supply
of bandwidth on demand and allows billing network users on a per-cell basis (more
probably on a .giga-cellbasis, given the speed and transfer capabilities ofATM).A user
can grab as big or as small a chunk of network bandwidth as he or she needs and pay only
for as much as he or she uses.
8. It is a scalable technology. It enables increase or decrease of such things as
bandwidths and data rates and still maintains the architecture of the signaling process.
Moreover, the same switching technology (cell switching) and the same cell formatis used
for the transport of all types of information (voice, video, and data) inboth LANandWAN
environments.
9. It has a fairly solid base of standards. It has been adopted by the International
Telecommunications Union (lTV) (formerly CCITT) and internationally standardized as
the basis for the Broadband Integrated Services Digital Network (B-ISDN).
2.7.2 laslc Cone.ptsofATMTachnology
There are two fundamental types of network traffic-CBR and VBR. The CBR traffic
(comprising of video and digitized voice information) is smooth, whereas VBR traffic
(comprising of datainformation) is bursty. The CBR traffic requires a low but constant
bandwidth and guaranteed throughput rates and service levels. On the other hand, VBR
traffic requires large bandwidth for very short periods of time at random intervals and can
tolerate delays and fluctuating throughput rates. Due to this basic difference in
characteristics of the two types of traffic, circuit switching is the most suitable networking
technology for handling CBR traffic, whereas packet switching is the most suitable
networking technology for handling VBR traffic. However, neither circuit switching nor
packet switching is suitable for handling both classes of network traffic. Therefore, when
the standards bodies of the lTV were working on a universal multiplexing and switching
mechanism that could support integrated transport of multiple-bit-rate traffic in anSec.2.7 • ATMTechnology 93
efficientand cost-effective way,theycameupwiththeideaofahybridformofswitching
technique called cell switching. ATMtechnology is based on this cell-switching
technique.
Cell-switching technology isbasedon thedigitalpacket-switching technology, which
relaysandroutestrafficovervirtualpathsbymeansofanaddresscontained withinthe
packet(this isdifferent fromcircuit-switching technology, whichroutestraffic not by
address butoverdedicated physical pathsestablished beforecommunication starts).
However, unlikemorefamiliar packet-switching technologies, such asX.25orframe
relay,cell-switching technology uses very short,fixed-length packets, calledcells.In
ATM, cells are 53 byteslong.Theyconsistofa5-byteheader(containing theaddress) and
a48-byteinformation field.
The cell size of53byteswaschosentomakeATM useful for data as well as voice,
video,andotherreal-time trafficthatcannottoleraterandomly varying transmission
intervals anddelays.Puredatasourcescanproduce very long messages-up to 64
kilobytes in manycases.Bysegmenting suchmessages intoshortcells,ATMensuresthat
CBRtraffic such as voiceandvideocan begivenpriorityandneedneverwaitmorethan
one53-bytecelltransmission time(3f.Lsata155-Mbps transmission rate)beforeit can
gainaccessto acommunication channel. Withframe-based packet-switching technology,
thewaitingtimewouldberandom, possibly severalmilliseconds inlength.Theuseof
short,fixed-size cells also eliminates thedangerofa smaJIpacketbeingdelayedbecause
a big one is hogging aneededline. Incaseofcellswitching, aftereach cell is transmitted,
a new one (even one belonging to adifferent message) can be sent.
Thepropersizeofa cellinATMwas thesubjectofmuchdebatewiththestandards
committees. This isbecausetelephony peoplewereinfavorofasmall cell to reducedelay
for voice packets, whereas datacommunications peoplewere in favor ofa large cell to
minimize theoverhead involved in thesegmentation andreassembly ofmessage data.
Aftermuchdiscussion, the cell size debatewasnarrowed into twochoices-32-byte cells
or64-byte cells. As a compromise, thelTVset the cell size at 48 bytes plus the
header.
Noticethatwith a fixed cell size of53bytes,ATMtechnology is not an ideal choice
eitherforapplications dealingwithCBRtrafficsuch as voice and video or for applications
dealingwith VBR traffic such as file transfers. It is,however, the besttechnology on the
horizonforhandling bothtypesoftrafficonasingleintegrated network. Becauseofits
fast,hardware-based switching, it canemulate thededicated circuitsusuallyrequired for
handlingCBRtraffic. And becauseit ispacketbased,itcanefficiently handleVBRtraffic
as well.
The ATM is a connection-oriented technology because asenderfirstestablishes a
connection with the receiver. However, unlikecircuitswitching, in which a physical
circuitisestablished between thesenderand thereceiver andreserved forthemfor the
entireduration oftheircommunication session, in ATM technology, avirtualcircuitis
established between thesenderand the receiver. Thatis, ATM does not reservethe path
for oneuserexclusively. Any time a givenuseris notoccupying achannel, anotheruser
is free to use it. Connection establishment in ATMmeansthat a route is determined from
thesenderto thereceiver androutinginformation isstoredin theswitches alongtheroute
duringconnection establishment. Allcellsofmessages from the senderto the receiver94 Chap.2 •Computer Networks
follow this virtual path stored in the switches. When the connection is nolongerneeded,
it isreleased and the routing information for this connection is purged from the
switches.
The address information in theheaderofeach cell is used by the routingprotocol to
determine the virtual path that the cell will traverse. Addresses in ATM are only oflocal
significance, in that they matteronlybetween twoadjacent piecesofATMequipment.
When a virtual path is established, each switch is provided with a set oflookuptables that
identifyanincoming cell byheaderaddress, route itthroughthe switch to the proper
outputport, and overwrite theincoming addresswith a new one that the next switch along
the route will recognize as an entry in its routingtable. Amessage is thuspassedfrom
switch to switch over a prescribed route, but the route is virtual since the facility carrying
themessage isdedicated to it only while a cell ofthe message traverses it.
In ATM, a virtual path is essentially abundleofvirtualchannels that can be
multiplexed together. Therefore, overa single virtual path, two hosts may multiplex cells
ofmanyindividual applications. Cells are statistically multiplexed, allowing the total
available bandwidth to bedynamically distributed among a variety ofdistributed
applications. This is achieved byselecting virtualchannel pathsaccording to the
anticipated traffic and allocating thenetworkresources needed.Forguaranteed bandwidth
applications, users are required to specify the amountofbandwidth required. It is the
virtual nature ofATMservicesthatprovides greaternetwork efficiencies.
1.7.3 ArM Protocol"-f.rence Mod.1
Theprotocol reference model in ATM is dividedinto three layers-physical layer, ATM
layer, and ATM adaptation layer (AAL) (Fig. 2.12). Applications involving data, voice,
and video are built on top ofthese three layers. The functionalities ofthe three layers are
described next.
Fig. 2.12 ATMprotocol reference model.1ld' Oth I-er ayersno speeIe In,..
ATMprotocolreference model
ATMAdaptation layer(AAL)
ATMlayer
PhysicallayerI
Physical Layer
Thephysical layeris thebottom-most layeroftheATM protocolsuite. It is concerned with
puttingbits on the wire and taking them off again. It has two sublayers: the physical
mediumdependent (PMD)sublayer and thetransmission convergence (TC) sublayer. TheSec.2.7 • ATMTechnology 95
PMDsublayer defines the actual speed for traffic transmission on thephysical
communication medium (electrical/optical) used. On the otherhand, the TC sublayer
definesaprotocolfor theencoding anddecoding of cell data into suitableelectrical/optical
waveforms fortransmission andreception on the physical communication medium
definedby the PMD sublayer. The protocol of the TC sublayer differsaccording to the
physical communication medium used.
Thephysical layer can transfercells from one user to anotherin one of the following
two ways:
1. Bycarrying cells as a synchronous data stream. In this case, the user-network
interface (UNI), which takes the form of an ATM adaptorboardpluggedinto acomputer,
puts out a stream of cells on to a wire or fiber. The transmission stream must be
continuous, and when there is no data to be sent, empty cells are transmitted.
2. Bycarrying cells in the payload portionofanexternally framedtransmission
structure. In this case, theUNIuses some standard transmission structure for framing and
synchronization at the physical layer. SONET(Synchronous Optical NETwork) [Omidyar
andAldridge 1993], the most commonly usedstandard for this purpose, is briefly
described next. The SONET format is currently supported bysingle-mode fiber,
multimode fiber, and twisted pair.
SONETis aninternational suite ofstandards fortransmitting digitalinformation over
optical interfaces. In SONET, the basic unit ofdatatransmission is a frame whose
structure is shown in Figure 2.13. As shown in the figure, a SONETframeconsistsofa
total of810bytes (9 X90),out of which 27 bytes (9 X3) areoverhead and theremaining
783 bytes (9 X87) are payload. The overhead bytes are used for error monitoring, system
maintenance functions, synchronization, andidentification ofpayloadtype.Thepayload
area can carry a variety of signals, such as several T1 signals, or a TJsignal, or several
ATM virtual circuits. Tlis a digital transmission servicewith a basic data rate of
1.544Mbps, and T3is a digital transmission servicewith a basic data rate of 44.736Mbps
fortransport of 28Tlcircuits.
The order of transmission of bytes is row by row, from left to right, with one
entire frame transmitted every125us.The basic time unit of one frame every 125 J.1s
matches with the telephone system's standard sampling rate of 800 samples per
second.Therefore, for theSONET frame format, the gross data rate is 51.840Mbps
(with the overhead bytes included), and the net data rate is 49.920Mbps (with the
overhead bytesexcluded).
The basic unit of SONET with a bit rate of51.840Mbps is calledSTS-l
(Synchronous Transport Signal Levell). HigherrateSONETsignals are obtained by byte­
interleaving nframe-aligned STS-l's to form an STS-nsignal [Vetter 1995].
STS uses an electrical ratherthan anopticalsignal.OpticalCarrier (OC) levels
areobtained from STS levels after scrambling (to avoid long strings of 1's and O'sand
allow clock recovery at the receivers) andperforming electrical-to-optical conversion
[Vetter 1995]. Thus, OC-nlevelsignalsareobtained byscrambling andconverting STS­
nlevel signals. The most commonly used values ofnare 1, 3, and 12, giving OC-I,Chap.2 •Computer Networks
f4--3bytes- ....~..,~----- 87bytes------.
Byte Byte Byte ByteByte... Byte
9bytes
~I
~I
Fig. 2.13 SONET frame format.
OC-3, and OC-12 signal levels having data rates of 51.84, 155.52, and 622.08Mbps,
respectively.
In Europe, another standard for frame formatting called SDH(Synchronous Digital
Hierarchy) [Omidyar andAldridge 1993] isalso available. For the SOH frame format, the
gross data rate for the basic unit is155.52Mbps, instead of the 51.84 Mbps for
SONET.
ATMLayer
The ATM layer handles most of the cell processing and routing activities. These
include building the cell header, cell multiplexing ofindividual connections into
composite flows of cells, cell demultiplexing ofcomposite flows into individual
connections, cell routing, cell payload type marking and differentiation, cell loss
priority marking and reduction, cell reception and headervalidation, and generic flow
control of cells. These functions are designed to be carried out in hardware at very
high data rates. The ATM layer is independent of the physical medium used to
transport the cells.
The functionality of the ATM layer is defined by the fields present in the ATM
cell header (Fig. 2.14). These fields and their functions are as follows:Sec.2.7 • ATMTechnology
4bits 8bits 16bits 3bits 1bit 8bits 48bits97
~~»
GFCVPI VCI PTICLPHEC Payload
{{
~
---------1.WlI4----- Payloadarea--+I
Fig.2.14 ATMcell format: GFC, Generic Flow Control; VPI, Virtual Path Identifier;
VCI, Virtual Channel Identifier; PTI, Payload Type Identifier; CLP,Cell
Loss Priority; HEC, Header Error Control.
•Genericjlow control(GFC)field. This field occupies 4 bits in anATMcell header.
ThedefaultsettingoffourD'sindicates that thecell is uncontrolled. Anuncontrolled
cell does not take precedence overanothercell when contending foravirtual circuit.
The bits in the GFC field can be suitably set to implement some form ofprioritized
congestion control. For example, the bits inthe GFC field could beusedto prioritize
voiceovervideo or to indicatethat both voice and video take precedence overother
typesofdata. The GFC field isalso used by the UNI to control the amount oftraffic
entering thenetwork, allowing the UNI to limit the amount ofdataentering the
network during periodsofcongestion [Vetter 1995].
• Virtual path identifier (VPJ)andvirtualchannelidentifier (VCI) fields. TheVPI
fieldoccupies 8 bits and theVCI fieldoccupies 16 bits in an ATM cell header.
These two fields are used by the routing protocol todetermine the path( s)and
channel(s) the cell will traverse. Thesefields are modified at each hop along the
path. That is, when acell arrives at an ATM switch, its VPIandvelvalues are
used todetermine the new virtual identifier to be placed inthe cellheaderand the
outgoing link over which to transmitthe cell. As impliedby its name, the VPIfield
is used to establish virtual paths between networkend-points. Recall that in ATM
two hosts may multiplex cells of many individualapplications over a single virtual
pathconnection. This isachieved by thevelfields of the cells that distinguish
among cells ofdifferent applications andthusestablish virtual links overagiven
virtual path.
•Payload-type identifier (PTJ) field. This field occupies 3bits in an ATM cell
header. It is used to distinguish data cells from control cells so that user data and
control data can be transmitted ondifferent subchannels.
• Cell loss priority(CLP) field. This field occupies 1 bit in an ATM cell header.
When set, it indicates that the cell can be discarded, if necessary, during periods
ofnetwork congestion. Forexample, voice data may be able to suffer lost cells
without the need for retransmission, whereas text data cannot. In this case, an
application may set the CLP field of the cells for voice traffic.
•Headererror control (HEC)field. This field occupies 8 bits in anATMcell header.
Itis used to protecttheheaderfield from transmission errors. It contains a
checksum of only the header (not the payload).98 Chap.2 •Computer Networks
ATMAdaptation Layer
The functionality of the physical and the ATM layers of the ATM protocol suite is not
tailored to anyapplication. We saw that ATM can support various types of traffic,
including voice, video, and data. The AAL is responsible forproviding different types of
services to different types of traffic according to their specific requirements. It packages
various kinds of user traffic into 48-byte cells, togetherwith theoverhead needed to meet
specific quality-of-service requirements of different types of traffic. To reflect the
spectrum of applications, four service classes were defined by the lTV (Fig. 2.15):
1. ClassA. Applications having delay-sensitive CBR traffic that require connection..
oriented service belong to this class. Video and voice applications normally
belong to this class.
2. ClassB. Applications having delay-sensitive VBR traffic that require connection­
oriented service belong to this class. Some video and audio applications belong to
this class.
3. Class C. Applications having VBR traffic that are not delay-sensitive but that
requireconnection-oriented service belong to this class. Connection-oriented file
transfer is a typical example of an application that belongs to this class.
4. ClassD. Applications having VBR traffic that are not delay-sensitive anddoes not
requireconnection-oriented service belong to this class. LAN interconnection and
electronic mail are typical examples of applications that belong to this class.
ServiceClassA ClassB ClassC Class0class
BitratetypeCBR VBR VBR VBR
DelayYes Yes No Nosensitive?
ConnectionYes Yes Yes Nooriented?
AALprotocolAAL1 AAL2AAL3/4 AAL3/4
tobeused orAAL5 orAAL5
Fig.2.15 Service classes for the ATMAdaptation Layer (AAL).
Tosupport the four service classes, initially the lTV recommended four types ofAAL
protocols, called AALI,AAL2, AAL3, and AAL4. It was soon discovered that the
differences between AAL3 and AAL4 protocols are minor. Therefore, they were later
merged into a single protocol, called AAL3/4.
It was.laterdiscovered that the mechanisms of the AAL3/4 protocol were fairly
complex for computer data traffic. Therefore, a new protocol called AAL5 was later addedSec.2.7 •ATMTechnology 99
to the AAL layer for handling computer data traffic [Suzuki 1994].The AAL5 protocol is
also called SEAL (Simple and Efficient Adaptation Layer).
As shown in Figure 2.15, class A traffic will use the AALIprotocol, class B traffic
the AAL2 protocol, and class C and 0 traffic either AAL3/4 orAAL5. Since both AAL3/4
and AAL5 protocols are meant for use by class C and 0 traffic, it is important to know
the basic differences between the two protocols. AAL3/4 performs error detection on each
cell and uses a sophisticated error-checking mechanism thatconsumes 4 bytes of each
48-byte payload. AAL3/4 allows ATM cells to be multiplexed. On the other hand, AAL5
uses a convent.ional 5-byte header(no extra byte from the payload of a cell) and it does
not support cell multiplexing.
2.7.4ATMNetworks
In its.simplest form, an ATMnetwork has a mesh-star architecture with two or more ATM
switches interconnected with copper or optical cables and the host computers connected
to the ATMswitches. Figure 2.16 shows such an ATM network with three ATMswitches
and nine host computers. Cellsoriginating at any of the nine host computers can be
switched to any of the other host computers attached to the system by traversing through
one or more ATM switches. This simple form is normally suitable for local area ATM
networks. In addition to ATM switches and host computers, a wide-area ATM network
also contains intemetworking devices, such as routers, gateways, and interfaces, to the
public network.
Hostcomputers/\
Fig. 2.16 AnATMnetwork.100 Chap.2 • Computer Networks
An ATMswitch has several input and output ports. Each input port has an input port
controller, and each output port has an output port controller. Each input port controller
consistsofa table, referred to as the VCI table, which maps the VPI and VCI of an
incoming cell to an output VCI and an output port address. Before an incoming cell is
released by an input port controller to the switching fabric of the switch, the VCI of the
cell isreplaced by theoutput VCI, and theoutput port address isappended for self-routing.
Each ATMswitch also has a switch controller that performs different switch management
functions, including updating the tables of the input port controllers. Moreover, eachATM
switch usually also has buffers to temporarily store data when cells arriving at different
input ports contend for the same output port. Separate buffers may be associated either
with the input ports or with the output ports, or the switch may have a pool of buffers that
can be used for both input and output buffering.
The ATMswitches that contain only a few ports are cheaperandeasierto build than
switches containing many ports. Local area ATM networks normally contain a small
numberofATM switches with only a few ports per switch, whereas wide-area ATM
networks normally contain a large number of ATM switches with many ports per
switch.
Each host computer in an ATM network is assigned an ATM address that could be
basedeitheron a hierarchical 8-byte-long ISDN telephone numberschemeE.l64or a
20-byte address proposed by the ATM Forum [ATMForum 1993]. The latter is modeled
after the address format of an OSI network service access point.
The ATMnetworks having protocol support for a mixture of high-level communica­
tion services (e.g., TCPII~UDPIIP, Berkeley Software Distributor [BSD] sockets, and
RPC) may also be used as backbone networks to interconnect existing networks.
As anetworking technology, ATM possesses many attractive features, including
enormously high bandwidth, scalability, traffic integration, statistical multiplexing, and
network simplicity. With these features, ATM technology is certainly going to have a
significant impact on the design of future distributed systems. However, for the success of
ATMas a networking technology forfuture distributed systems, several problems have yet
to be solved. These problems offer a new set of challenges to network designers and users.
Some of the most important of these problems that are currently under investigation by
researchers working in the area of ATM technology are briefly described next.
Ioteroperability
IfATMis to succeed as a networking technology, it must interwork with existing installed
bases. This property is important to the acceptance of ATM since it will allow a huge
number ofexisting distributed applications to berun overATMnetworks. Tworemarkable
efforts being made in this direction are LANemulation overATMby the ATMForum (the
primaryorganization developing and defining ATMstandards) [ATMForum 1994]and IP
overATMby the IETF (Internet Engineering Task Force) [Chao et al. 1994, Laubach
1994,Brazdziunas 1994]. They are described next.Sec.2.7 • ATMTechnology 101
LANEmulation over ATM. 'TheLAN emulation over ATM(calledIAN
emulation) dealswithenablingexistingLAN-based distributed applicationstoberunover
ATMnetworks. It alsoenables interconnection ofATMnetworks withtraditional
LANs.
MostexistingLANsarebasedonshared-media interconnects andemploytheIEEE
802 family ofLANprotocols, whichincludes theEthernet (802.3),theTokenBus(802.4),
and the Token Ring (802.5)(seeSection2.5.1).RecallfromFigure2.9 that in the IEEE
802 model the data-link layerprotocol ofthe ISO reference modelisdividedinto two
layers-the medium-access-control (MAC)layer, which definesthemechanisms that are
used to access, share, and manage thecommunication medium, and the logical-link­
control(IJLC) layer, whichdefinesacommon interface fordifferent network layer
protocols tointerwork withdifferent MACprotocols. Each host attached to a LAN has a
globally uniqueMACaddress. MACaddresses are 48 bits long and form a flat address
space. A host can send data to anotherhost only if it knowsthe MAC addressofthe
receiving host(ifboth the hosts are in the same LAN)or the MAC addressofthe next hop
router(ifboth the hosts are in different LANs).
The key idea behindLANemulation is todesignaseparate protocol layer,referred
to as the ATM-MAC layer,abovethe AAL and belowthe LLC layer. Two key functions
that must be supported bytheATM-MAC layerare as follows:
1.Emulation ofthephysical, broadcast, sharedmediumofI.lANs for supporting
broadcast communication facility
2.Resolution ofMACaddresses to ATM addresses forsupporting point-to-point
communication facility
The ATM emulates thephysical, broadcast, sharedmediumofaconventional LAN
byestablishing anATMmulticast virtualconnection between allofthe hosts that are
directlyconnected to the ATM network, referredto as the LAN emulation clients(LECs).
Thismulticast connection is thebroadcast channeloftheATMLANsegment. Any LEC
maybroadcast toallothersontheATML.ANsegment bytransmitting on themulticast
virtualconnection.
For point -to-point communication, anaddress resolution protocol isrequired to
translate the48-bitMACaddressto an A'TM address.Translating MACaddresses to ATM
addresses can be done using eitherabroadcast-based approach or aserver-based approach.
Thebroadcast-based approach relies on the switchbroadcast capability. On theotherhand,
in theserver-based approach, aLANemulation server(LES) is placedon aglobally
knownvirtualchannel, and a set ofquery/response messages isimplemented for
interaction between theI.JESand theLEes.AllMAC-to-ATM address resolution requests
are sent to the LES, which responds totherequester using a predetermined virtual
channel.
Oncethe ATM addressofthereceiving host has been obtained, apoint-to-point ATM
virtualconnection maybeestablished between thesendingandreceiving hostsbyusingthe
ATMsignaling protocol. Theresultoftheaddressresolution and theVeloftheestablished
connection arecachedin a table in the sending hoston theassumption thatfurther
communication with the receiving host is likely. Thismechanism operates entirelywithin102 Chap.2 • Computer Networks
theATM-MAClayer and is totally transparent tothe LLC and higher layer protocols in the
hosts. Further details ofLAN emulation can befound in [Newman 1994].
IPoverATM. The IP over ATM deals with enabling existing distributed
applications that have been designed for the IP suite to be run over ATM networks. Two
cases that need to be considered for supporting IP over ATM are as follows:
1. Supporting IP over an ATM network that has LAN emulation functionality
implemented over it
2.Supporting IP over a pure ATM network that consists of only ATM switches
Since LAN emulation defines the ATM-MAC layer above the AAL and below the
LLC~supporting IP over an emulated LAN is the same as supporting IP over any IEEE
802 LAN. However, when IP is to be supported over a pure ATM network, it is possible
to simplify the protocol stack and run IP directly over ATM.For implementing IP directly
over ATM,an address resolution protocol is required to translate an IP address to anATM
address. Once again the server-based approach (as described for LAN emulation) can be
used for this purpose. With IP over ATM,the address resolution server, referred to as the
IP-ATM-ARP server, maintains tables that contain mapping information to map IP
addresses to ATM addresses.
When a new host is added to the ATM network, itfirst goes through a registration
process and obtains an ATM address for itself. It then sends a message to the IP-ATM­
ARP server, requesting it to add its address resolution information in the mapping table.
The message contains the IPand ATM addresses of the newly added host. The server
updates the mapping table, allocates a new reserved VCI to the host, and returns the VCI
to the host. The host uses this VCI to discriminate between messages received from the
server and other hosts. The above process can also be adopted to allow port mobility of
hosts. Further details of IP over ATM can be found in [Chao et al. 1994].
Bandwidth Management
The ATM networks are meant for carrying a mix of synchronous, asynchronous, and
isochronous traffic. To achieve the desired quality of service, users are often required to
specify the bandwidth requirement for their applications. Two important issues that need
to be resolved in this connection are how users estimate and indicate the bandwidth
requirements of their applications to the network and how the network allocates the
bandwidth to the applications tomake best use of the available bandwidth while satisfying
the requests of the applications. Some proposals made by researchers working in this area
are as follows [Turner 1992, Vetter 1995]:
1. Peak-rate allocation method. In this method, users only specify the maximum
traffic rate for their applications. Based on user'srequests, the network assigns virtual
channels to the applications in such a manner that on every link of the network the sum
of the rates on the virtual channels is no more than the link'smaximum cell rate. If an
application '8traffic exceeds its specified peak rate, its cells are simply discarded.Sec.2.7 • ATMTechnology 103
2.Minimum-throughput allocation method. In thismethod, usersspecifythedesired
minimum throughputs fortheirapplications, and the network guarantees thespecified
throughputs to theapplications on abest-effortbasis.
3.Bursty-traffic specification method. In thismethod, usersspecifythemaximum
andaverage trafficratesplusthemaximum burstsizefortheirapplications. These
parameters areusedtoproperly configure thenetwork toallocatetheavailable bandwidth
to theapplications tomeettheirspecified requirements.
Noneofthesemethods hasbeenfoundto besatisfactory. Forinstance, Vetter[1995]
pointsoutthatthe first methodoffersastrongperformance guarantee and iseasyto
implement, but it may makepooruseoftheavailable network bandwidth incaseofbursty
traffic;thesecondmethodcanprovidehighefficiency, but itsperformance guarantee is
weak;and thethirdmethodinvolves largecomputation overhead incomputing whena
newvirtualchannelcanbesafelymultiplexed withothervirtualchannels. Moreover, all
threemethods sufferfrom two additional drawbacks. First,sinceend-to-end protocols
normally operateondataunitscomprising severalcells,for anapplication needingreliable
transport service,the loss or discardofasinglecellforcesretransmission oftheentire
data,resulting inlowerprotocol throughput [Vetter 1995]. Theproblem becomes more
acutein awide-area ATMnetwork because theretransmission mayalsoresultin
discarding alargeamountofdataalreadyin theconnection pipe.Thiscanhave aserious
performance implication. Theseconddrawback isthatnoneofthethreemethods
adequately handles multicast virtualcircuits[Vetter1995].Therefore, newbandwidth
management mechanisms thatcanovercome theproblems mentioned previously are
needed.
LatencylBandwidth Trade-off
Kleinrock [1992]pointedoutthatthelatency/bandwidth trade-off inhigh-speed wide-area
ATMnetworks willposenewchallenges to thedesigners ofthesenetworks. Thisis
primarily due to the fact that the propagation delayorspeedoflightoverawideareais
severalmagnitudes greaterthan the timeittakestotransmit an ATM cell. Forinstance, it
takesroughly 15ms for a bit to travelacrosstheUnitedStatesoneway. At 1 Gbps,this
timeismorethan35,000timesgreaterthan thetimerequired totransmit asingleATM cell
intothe link [Vetter 1995]. Thislatencylbandwidth trade-off posesthefollowing twomain
problems. Theseare thesameproblems described in[Tanenbaum 1995]:
1.Consider a WANspanning acrosstheUnitedStates.Theround-trip propagation
delaybetween twoend sites ofthe WAN may be approximately 30ms.Suppose thetwo
sitesare on a 622-Mbps ATMnetwork. At 622Mbps,ittakesonlyabout1.6ms(1/622
second)topumpall bitsofa fileofsize 1megabits on to the network. Sincetheround-trip
propagation delaybetween the twositesis 30 ms, the receiver's replycan bereceived by
thesenderonlyafter31.6ms.Therefore in thisexample, outoftotal31.6ms, the link was
idle for 30ms, or 95% ofthe total. Thesituation will beworsewithhigherspeednetworks
andshortermessages. Athigherspeeds,thefraction oftheavailable virtualcircuit104 Chap.2 • Computer Networks
bandwidth thatcan beeffectively used will tend to zero. Hence, new protocols and system
architectures are needed to deal with the latency problem in high-speed wide-area ATM
networks.
2. Since the propagation delay is several magnitudes greater than the time it takes to
transmit an ATM cell, a sender can send thousands of cells over the network before the
first bit even arrives at the receiver's site. If the receiver does not possess a large amount
of buffering capacity, mostof thecells will belostdue to inadequate buffer space, and they
will have to be retransmitted. This can have a serious performance implication. The use
oftheconventional sliding-window protocol for flow control to solve this problem does
not work well in this case. This is because if it is decided that the sender must wait for an
acknowledgment after sending every megabit of data, due to the latency problem already
described above, the virtual circuit will be 95% idle. To solve this problem, areas that
requireparticular attention include flow control, buffering, and congestion control. Some
work performed in these areas may be found in [Hong and Suda 1991, Trajkovic and
Golestani 1992, Eckberg 1992, Yazid and Mouftah 1992].
1.8SUMMARY
A distributed system relies entirely on the underlying computer network for the
communication of data and control information between the nodes of which they are
composed. A computer network is a communication system that links the nodes by
communication lines and software protocols to exchange data between two processes
running on different nodes of the network.
Based on characteristics such as geographic distribution of nodes, data rate, error
rate, and communication cost, networks are broadly classified into two types: LAN and
WAN. Networks that share some of the characteristics of both LANs and WANs are
sometimes referred to as MANs.
The two commonly used network topologies for constructing LANs are the
multiaccess bus and ring. For both multiaccess bus and ring networks, a single channel is
shared by all the sites of a network. Therefore, medium-access control protocols are
needed to provide controJled access to the shared channel by all sites. Of many medium
access control protocols, the CSMAlCD protocol is most commonly used for multiaccess
bus networks, and the token ring and slotted ring protocols are used for ring networks.
A wide-area network of computers is constructed byinterconnecting computers that
are separated by large distances. Special hardware devices called packet-switching
exchanges (PSEs) are used to connect the computers to the communication channels. The
PSEs perform switching and routing activities to transmit data across the network. The
twocommonly used switching techniques are circuit switching and packet switching.
The selection of the actual path to be used to transmit a packet in a WAN is
determined by the routing strategy used. The path used to transmit a packet from one site
to another eithermaybefixed or may dynamically change based on network conditions.
This depends on whether a static or a dynamic routing strategy is being used. Moreover,
either the whole path may be decided at the source site or the subpath for each hop of theChap. 2 • Exercises 105
path may be decidedby each site along the path. Furthermore, with adynamic routing
strategy, routingtables may be updated in an isolated, centralized, ordecentralized
manner.
Computer networks areimplemented using the conceptoflayeredprotocols. The OSI
modelprovides astandard forlayeredprotocols for WANs, and the IEEE802 LAN model
defines a standard for LANs. The seven layers of the OSI model are physical, data link,
network, transport, session,presentation, andapplication. Ontheotherhand, the lowest
three layers of theIEEE802 lJAN model are physical, medium-access control, and
logical-link control. The IEEE802 LAN model does not includespecifications for higher
layers. Of the available protocol suites for network systems, the InternetProtocol (IP)
suite is the most popularand widely used.
Thecommunication protocols designed for network systemsare usually unsuitable
fordistributed systems becauseofthe special requirements ofdistributed systems as
compared tonetwork systems. Several communication protocols have been designed to
achievehigherthroughput and/orfastresponse indistributed systemsand to address one
or more of the special requirements ofdistributed systems. Two such protocols whose
characteristic features were described inthischapterareVMTPand FLIP.
Interconnecting two or more networks to form a single network is called
internetworking, and the resulting network is called an internetwork. The goal of
internetworking istohide the details of different physical networks so that the resulting
internetwork functions as asinglecoordinated unit. Tools such as bridges, routers,
brouters, andgateways are used for internetworking. TheInternetis the best example of
aninternetwork.
TheATMis ahigh-speed, connection-oriented switching andmultiplexing
technology that uses short, fixed-length packets (called cells) to transmit different types of
trafficsirnultaneously, including voice, video, and data. Due to its many attractive
features, ATM technology is often described as the future computer networking
paradigm.
EXERCISES
2.1. What are the main differences between a LAN and a \VAN?
2.2. Why are medium-access control protocols needed? What properties must a good medium­
access-control protocol have?
2.3. The CSMA/CD scheme for medium-access control allows random access to the shared
medium, detects collisions, and takes necessary steps to retransmit ifa collision is detected. Is
it possible to devise a random-access scheme for medium-access control in which collisions
never occur (collisions are totally avoided)? If no, explain why. If yes, describe a possible
scheme of this type along with its advantages and disadvantages.
2.4.Answer the following questions for Ethernet:
(a) How does a site acquire the shared channel for transmitting its packets?
(b) How is a collision detected?
(c) How is a collision resolved after detection?
(d) How is the possibility of repeated collisions minimized?106 Chap. 2 • Computer Networks
2.5.In Ethernet, collisioninterval is the time required for a signal to propagate from one end of
the medium to the other and back again, and retransmission slottime is set to be a little longer
than the collision interval. Prove that no collisions will occur if every site transmits its packet
only after it listens tothe shared medium and finds it free for atime period that isat least equal
to theretransmission slot time.
2.6.The token ring and the slotted-ring protocols formedium-access controlorganize the sites of
a network in a logical ring structure. Present an algorithm for detecting the failure of a site in
the ring and reconstructing the logical ring when the failure of a site is detected.
2.7.Presentan algorithm to detect the loss of a token in the token ring scheme for medium-access
control.
2.8.Suggestapriority-based token ring scheme for medium-access control that does not lead to
thestarvation of a low-priority site when higher priority sites always have something to
transmit.
2.9. In a high-speed LAN, suppose the term high speed means a data transferrate that is high
enoughto make the mean packet transmission time become less than the mediumpropagation
delay.Consider a bus LAN that spans 6000 meters, uses a mean packet length of 1400 bits,
and has a data transmission rate of 50 X106bits per second. If the communication medium
used for this LAN has a propagation speed of 2 X108mis, would the LAN be considered a
high-speed LAN?
2.10.It has been shown that the performance of theCSMA/CD schemedegrades significantly as the
ratioa:::(TW)/Bincreases, where 'Tis theend-to-end propagation delayofthe signal across
the network, Wis the channel bandwidth, andBis the number of bits per packet. One finds
that a good estimateofris 10f.LSfor eachkilometer of cable(assuming onerepeaterfor each
500 meters of cable). Experimental results have shown that, for a:::0.1,CSMAlCD provides
adequate channel capacity, 0.65 or higher. For the definition ofhigh-speed LAN given in
Exercise 2.9, show that CSMA/CD scheme is unsuitable for high-speed LANs.
2.11.What is meant by internetworking'l What are the main issues in intemetworking? Explain the
difference among the following terms:
(a) Bridge
(b) Router
(c)Gateway
2.12.Suppose that the following sequence of message exchanges are involved in transmitting a
pieceofdata when circuit-switching technique is used:
(a)connect_request (from sender to receiver)
(b)connectionjacknowledgment (fromreceiverto sender)
(c)send_data (data transfer from sender to receiver)
(d)dataacknowledgment (fromreceiverto sender)
(e)disconnectrequest (from sender to receiver)
(t)disconnection ocknowledgment (from receiver to sender)
Suppose that the time to transfer each of the above message is t,exceptfor thesend_data
message, for which the time taken is t+ds,wheredis aconstant andsis the size of the
data in bytes. Now suppose that on the same network tis also the time to transfera packet
of100 bytes and a packet-switching technique used returns an acknowledgment from
receiverto sender for every npackets received. Compute the threshold value of sat which
both the circuit-switching andpacket-switching techniques perform at the same data
transmission rate.Chap. 2 • Exercises 107
2.13.Suggest threedifferent routingstrategies for use in computer networks. List the relative
advantages anddisadvantages of thestrategies suggested byyou.
2.14. A network systemuses the dynamic routingstrategy and thenon-minimal-path selection
policy. In this system,apacket may continue to be routed throughthenetwork butneverreach
itsdestination. Deviseamechanism that avoids the occurrence ofthissituation in the
system.
2.15.Why are communication protocols needed in a network system?Whatare the main reasons
for using the layeredapproach tocommunication protocol specification anddesign?
2.16.Draw adiagram showing thearchitecture of theOSImodel.Brieflydescribe thefunctions of
each layer of this architecture.
2.17.In Figure 2.8, we see that each layer adds itsownheaderto themessage beingtransmitted
across the network. Insteadofaddingaseparateheaderat each layer, it would have been more
efficient to add a single headercontaining the control information in all these headersto the
message before its transmission across the network. Explainwhy this is not done.
2.18.Mostcomputer networks use fewer layers than those specified in theOSImodel.Explainwhat
might be the reason for this. What problems, ifany,couldthis lead to?
2.19. What are the main differences between connection-oriented andconnectionless communica­
tionprotocols? Indicate which of the two protocols ispreferable for thetransmission of the
following types of information:
(a) Voice
(b)Video
(c) Bursty data
2.20.Thepacketsof amessage may arrive at their destination in an order different from the order
in which they were sent. Indicate for which of the following types of networks is this
statement true:
(a)Ethernet LAN
(b) WAN
(c)ATMLAN
(d) ATM WAN
Givereasonsfor your answers.
2.21.Why is the OSI model considered to beunsuitable for use in a LAN environment? Give the
architecture ofacommunication protocol modelsuitable for LANs. Brieflydescribe the
functions of each layer of this architecture.
2.22.Why are conventional communication protocols fornetwork systemsgenerally considered to
beunsuitable fordistributed systems?
2.23.Explainthemechanism used in the VMTPprotocol for eachofthe following:
(a)Handling of lostmessages
(b)Groupcommunication
(c) Flow control
(d)Transparent communication.
2.24.Explainthemechanism used in the FLIPprotocol for each of the following:
(a)Transparent communication
(b)Groupcommunication
(c)Securecommunication
(d) Easy network management.108 Chap. 2 • Computer Networks
2.25.What are the main attractive features of ATM technology? What type of impact will each of
these features have on future distributed systems?
2.26.Describe the functionalities of the different layers of the ATM protocol reference model.
2.27.Explain how the following can be achieved:
(a) LAN emulation over ATM
(b)IP over ATM
2.28.Give three different methods that may be used in ATM networks to allocate bandwidth to
applications to make best use of the available bandwidth while satisfying the requests of the
applications. Also give the relative advantages and limitations of the three methods.
2.29.Give examples to illustrate the problems that occur due to the latencylbandwidth trade-off in
high-speed, wide-area ATM networks.
BIBLIOGRAPHY
[Abeysundara andKamal1991]Abeysundara, B. W.,and Kamal, A. E., "High-Speed Local Area
Networks and Their Performance: A Survey," ACMComputing Surveys, Vol. 23,No.2,pp.
221-264 (1991).
[ATMForum1993]ATMUser-Network Interface Specification Version3.0,Prentice-Hall,
Englewood Cliffs, NJ (1993).
[ATMForum1994]"LAN Emulation Over ATM," Draft Specification-Revision 5 (ATM
FORUM 94-0035R5), LAN Emulation Sub-Working Group of the ATM Forum Technical
Committee (August 1994).
[Black1993]Black,V.,Computer Networks: Protocols. Standards, andInterface, 2nded., Prentice­
Hall, Englewood Cliffs, NJ (1993).
[Black1995a]Black,V.,ATM: Foundation forBroadband Networks, Prentice-Hall, Englewood
Cliffs, NJ (1995).
[Black1995b]Black,V.,TCPIIPandRelatedProtocols, 2nd ed., IEEE Computer Society Press,
Los Alamitos, CA (1995).
[Brazdziunas 1994]Brazdziunas, C., "IPing Support for ATM Services," Internet RFC No. 1680
(1994).
[Chaoet al, 1994] Chao, H.1,Ghosal, D., Saha, D., and Tripathi, S. K., "IP on ATM Local Area
Networks," IEEECommunications Magazine, pp.52-59,New York, NY (August 1994).
[Cheriton 1986JCheriton, D. R., "VMTP: A Transport Protocol for the Next Generation of
Communication Systems," In: Proceedings oftheSIGCOMM'86, pp.406-415 (August 1986).
[Cheriton 1988]Cheriton, D. R., "The V Distributed System," Communications ofthe ACM, Vol.
31,No.3,pp.314-333, ACM, New York, NY (1988).
[Cheriton. andWilliamson 1989]Cheriton, D. R., and Williamson, C. L., "VMTPAs theTransport
Layer for High-Performance Distributed Systems," IEEECommunications Magazine, Vol. 27,
No.6,pp.37-44,New York, NY (1989).
[Comer1995]Comer, D. E., Intemetworking with TCPI/P: Volume l-s-Principles, Protocols. and
Architectures, 3rd ed., Prentice-Hall, Englewood Cliffs, NJ (1995).
[ComerandStevens1993]Comer, D.E., and Stevens, D. L., lntemetworking with TCPIIP: Volume
III-Client-Server Programming andApplications: BSDSocketVersion,Prentice-Hall, Engle­
wood Cliffs, NJ (1993).Chap. 2 • Bibliography 109
[ComerandStevens1994] Comer, D.E., andStevens, D. L., Internetworking with TCPIIP: Volume
II-Design, Implementation, and Internals, 2nd ed., Prentice-Hall, Englewood Cliffs, NJ
(1994).
[Datapro 1990] Datapro, "An Overview of Simple Network Management Protocol," Datapro
Network Management, NM40-300-201 (February 1990).
[Datapro 1993] Open Software Foundation (OSF) Distributed Management Environment (DME),
A Datapro Report, Datapro Network Management, NM40-684-07 (April 1993).
[DePrycker 1993] DePrycker, M.,Asynchronous Transfer Mode: Solution forBroadband ISDN,
2nded.,Ellis Horwood (1993).
[DePrycker et al.1993] DePrycker, M.,Peschi, R., and Landegem, T.,"B-ISDN and the OSI
Protocol Reference Model," IEEE Network, Vol. 7,No.2,pp.10-18,New York, NY (March
1993).
[DuttonandLenhard 1995] Dutton, Jr., H.,and Lenhard, P., High-Speed Networking Technology:
An Introductory Survey, Prentice-Hall, Englewood Cliffs, NJ (1995).
[Eckberg 1992] Eckberg, A., "B-ISDN/ATM Traffic and Congestion Control," IEEE Network, Vol.
6,No.5,pp.28-37,New York, NY (1992).
[Finlayson etal.1984] Finlayson, R., Mann, T.,Mogul,1.,and Theimer, M.,"A Reverse Address
Resolution Protocol," RFC No. 903 (June 1984).
[.~ischer et al. 1994] Fischer, W.,WalJmeier, E.,Worster, T., Davis, S. P., and Hayter, A., "Data
Communications UsingATl\1:Architectures, Protocols, and Resource Management," IEEE
Communications Magazine, pp.24-33,New York, NY (August 1994).
[FurhtandMilenkovic 1995] Furht, B., and Milenkovic, M., GuidedTourofMultimedia Systems
andApplications, IEEEComputer Society Press, Los Alamitos, CA (1995).
[Haendel etal,1994] Haendel, R., Huber, M. N., and Schroeder, S., ATM Networks: Concepts,
Protocols, Applications, Addison-Wesley, Reading, MA (1994).
[Helgert 1991] Helgert, H. J.,Integrated Services Digital Networks.' Architectures, Protocols,
Standards, Addison-Wesley, Reading, MA (1991).
(HongandSuda1991] Hong, D., and Suda, T., "Congestion Control and Prevention in ATM
Networks," IEEE Network, Vol.5,No.4,pp.10-16,New York, NY (1991).
[Hughes 1994] Hughes, K., "Entering the World-Wide Web: A Guide to Cyberspace," ftp:/
taurus.cs.nps.navy.mil:/pub/mbmy/world-wide-web-guide.ps.Z (1994).
[IEEE1985a]CarrierSense Multiple Access with Collision Detect (("'SMA/CD) AccessMethodand
Physical Layer Specifications, ANSI/IEEE 802.3 (lSOIDIS 8802/3), IEEE, New York (1985).
[IEEE1985b]Token-Passing Bus AccessMethodand Physical Layer Specifications, ANSI/IEEE
802.4 (ISO/DIS 8802/4), IEEE, New York(1985).
[IEEE1985c]T()kenRingAccessMethodandPhysical LayerSpecifications, ANSIIIEEE 802.5
(lSOIDIS 8802/5), IEEE, New York (1985).
[IEEE1990]IEEEStandard 802: Overview and Architecture, American National Standard ANSI/
IEEE 802, IEEE Computer Society Press, Los Alamitos, CA (1990).
[IT1990] Information Technology-Open Systems Interconnection-Management Information
ProtocolSpecification-Common Management Information Protocol, ISOIIEC 9596-1, ISOIIEC
JTC1/SC21 N5303 (November 1990).110 Chap. 2 • Computer Networks
[Janet1993]Janet, E. L., "Selecting a Network Management Protocol, Functional Superiority vs.
PopularAppeal:' Telephony (November 1993).
(Kaashoek et al,1993]Kaashoek, M.F., Van Renesse, R., Staveren, H., and Tanenbaum, A. S.,
"FLIP:AnInternetwork Protocol for Supporting Distributed Systems," ACMTransactions on
Computer Systems, Vol. 11,No.1,pp.73-106(1993). © ACM, Inc., 1993.
[Kawarasaki andJabbari1991]Kawarasaki, M., and Jabbari, B.,"B-ISDN Architecture and
Protocol," IEEEJournalofSelected Areas on Communications, Vol.SAC-9,No.9,pp.
1405-1415, New York, NY (1991).
[Kimand Wang 1995] Kim, B. G., and Wang, P., "ATM Network: Goals and Challenges,"
Communications ofthe ACM, Vol. 38,No.2,pp.39-44(1995).
[King and Mitrani1987]King,P1. B., and Mitrani, I., "Modeling aSlottedRing Local Area
Network:' IEEE Transactions on Computers, Vol. C-36, No.5,pp.554-561, Piscataway, NJ
(1987).
[Kleinrock 1992] Kleinrock, L., "TheLatency/Bandwidth Tradeoff inGigabitNetworks," IEEE
Communications Magazine, Vol. 30,No.4,pp.36-40,New York, NY (1992).
[Kroll994] Krol, E., The Whole Internet: User's Guide and Catalog, 2nd ed.,O'Reilly, Sebastopol,
CA (1994).
[Kung 1992) Kung, H. T., "Gigabit Local Area Networks: A Systems Perspective," IEE'E
Communications Magazine, Vol. 30,No.4,pp.79-89,New York, NY (1992).
[Larmouth 1993]Larmouth, J.,Understanding OSI, Prentice-Hall, London, UK (1993).
[Laubach 1994] Laubach, M.,"Classical IPand ARP over ATM," RFC No. 1577 (January
1994).
[Leinwandand Conroy1996] Leinwand, A., and Conroy, K. F., Network Management: APractical
Perspective, 2nd ed.,Addison-Wesley, Reading, MA (1996).
[Macedonia and Brutzman 1994]Macedonia, M. R., and Brotzman, D. P.,"MBone Provides
Audioand Video Across the Internet," IEEE Computer, pp.30-36(April 1994).
[Malamud 1992] Malamud, C.,STACKS: lnteroperability in Today's Computer Networks, Prentice­
Hall,Englewood Cliffs, NJ (1992).
[Malamud 1993] Malamud, C.,Exploring the Internet: ATechnical Travelogue, Prentice-Hall,
Englewood Cliffs, NJ (1993)."
[Martin1993]Martin, 1. L., "Travels withGopher," IEEE Computer, Vol 26.,No.5,pp.84-87
(1993).
[Miller 1995] Miller, M. A., Inter Networking: AGuide to Network Communications LAN to LAN;
LANtoWAN,2nd ed., M&T Books, New York, NY (1995).
[Mosaic1994] "What'sNew with NCSA Mosaic," http:www.ncsa.uiuc.edu/SDG/SoftwarelMosaic/
Docs/whatsnew.html (June 1994).
[Mullender et al. 1990] Mullender, S. 1.,VanRossum, G., Tanenbaum, A. S., VanRenesse, R., and
VanStaverene, H.,"Amoeba: ADistributed Operating System for the 1990s," IEEE Computer,
Vol. 23., No.5,pp.44-53(1990).
[Nejmeh 1994] Nejmeh, B. A., "Internet: AStrategic Tool for the Software Enterprise,"
Communications ofthe ACM, Vol. 37, No. 11, pp. 23-27(1994). © ACM, Inc., 1994.
[Newman1994] Newman, P, "ATM Local Area Networks," IEEECommunications Magazine, Vol.
32,No.3,pp.86-98(1994).Chap.2 • Bibliography 111
[Omidyar and Aldridge 1993] Omidyar, C., andAldridge, A.,"Introduction toSDH/SONET,"
IEEECommunications Magazine, Vol. 31,No.9,pp,30-33(1993).
[Partridge 1994]Partridge, C.,Gigabit Networking, Addison-Wesley, Reading, MA(1994).
[Perlman 1992]Perlman, R.,Interconnections: Bridges and Routers, .Addison-Wesley, Reading,
MA (1992).
[Plummer 1982]Plummer, D.C., "An Ethernet Address Resolution Protocol," RFC No. 826
(November 1982).
[Postel 1980] Postel,J.,"UserDatagram Protocol," RFC No. 768, USC Information Sciences
Institute (August 1980).
[Postel 1981a] Postel,J.,"Internet Protocol: DARPA Internet Program Protocol Specification,"
RFC No. 791 (September 1981).
[Postel 1981b] Postel,1.,"Internet ControlMessage Protocol," RFC No. 792 (September 1981).
[Postel 1981c] Postel,1.,"Transmission Control Protocol: DARPA Internet Program Protocol
Specification," RFCNo. 793 (September 1981).
[Press 1994] Press,L.,"Commercialization oftheInternet," Communications ofthe ACM, Vol. 37,
No.11,pp. 17-21(1994).
[Ramos et al.1996JRamos,E.,Schroeder, A., andBeheler, A.,Computer Networking Concepts,
Prentice-Hall, Englewood Cliffs,NJ(1996).
[Rooholamini 19951Rooholamini, R.,"ATM-Based Multimedia Servers," IEEE Multimedia, pp.
39-52(Spring1995).
[Santifaller 1994]Santifaller, M.,TCPIIP and ONC/NFS, Internetworking in a UNIX Environment,
2nd ed., Addison-Wesley, Reading, MA (1994).
[Shevenell 1994J ShevenelJ, M.,"NMPv2 NeedsReworking toEmerge as a Viable Net
Management Platfornl," Network World (March7, 1994).
[Smythe 1995] Smythe, C.,lnternetworking: Designing the Right Architectures, Addison-Wesley,
Reading, MA(1995).
[Stallings 1992a] Stallings, W. (Ed.), Advances in ISDN and Broadband ISDN,IEEEComputer
SocietyPress, Los Alamitos, CA(1992).
[Stallings 1992b] Stallings, W.,Computer Communications: Architectures, Protocols and
Standards, 3rd ed.,IEEEComputer SocietyPress, Los Alamitos, CA(1992).
[Stallings 1993a] Stallings, W. (Ed.), Advances in Local and Metropolitan Area Networks, IEEE
Computer SocietyPress,LosAlamitos, CA(1993).
[Stallings 1993b] Stallings, W. (Ed.), Network Management, IEEEComputer SocietyPress, Los
Alamitos, CA(1993).
[Stallings 1993c] Stallings, W.,Networking Standards: A Guide to OSI, ISDN, LAN, and MAN
Standards, Addison-Wesley, Reading, MA (1993).
[Stallings 1995] Stallings, W.,ISDN and Broadband ISDN with Frame Relay and ATM, 3rd ed.,
Prentice-Hall, Englewood Cliffs,NJ(1995).112 Chap. 2 • Computer Networks
[Suzuki1994JSuzuki, T., "ATM Adaptation LayerProtocol," IEEECommunications Magazine,
Vol. 32,No.4,pp.80-83(1994).
[Tanenbaum 1988]Tanenbaum, A. S.,Computer Networks, 2nd ed., Prentice-Hall, Englewood
Cliffs, NJ (1988).
[18nenbaum 1995JTanenbaum, A. S.,Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs, NJ (1995).
[Tittel and James 1996] Tittel, E., and James, S., ISDN Networking Essentials, Academic Press,
SanDiego,CA (1996).
[Trajkovic and Golestani 1992]Trajkovic, L., andGolestani, S. J.,"Congestion Control for
Multimedia Services," IEEE Network, Vol. 6,No.5,pp.20-26(1992).
[Thrner 1992] Turner, J., "Managing Bandwidth in ATM Networks with Bursty Traffic," IEEE
Network, Vol. 6,No.5,pp.50-58(1992).
[Umar1993] Umar, A., Distributed Computing: A Practical Approach, Prentice-Hall, Englewood
Cliffs, NJ (1993).
[Verma1990] Verma, P.K., ISDN Systems: Architecture, Technology &Applications, Prentice-Hall,
Englewood Cliffs, NJ (1990).
[Vetter1995J Vetter, R. J., "ATM Concepts: Architectures, andProtocols," Communications ofthe
ACM,Vol. 38,No.2,pp.31-38(1995).
[Vetter and Du 1993] Vetter, R. J., and Du, D. H. C., "Distributed Computing withHigh-Speed
OpticalNetworks," IEEE Computer, Vol. 26,No.2,pp.8-18(1993).
[Vetteret al, 1994] Vetter,R. J., Spell, C., and Ward, C., "Mosaic and the World-Wide Web," IEEE
Computer, pp.49-56(October 1994).
[Vickers and Suda 1994] Vickers, B. J., and Suda, T., "Connection lessServicefor Public ATM
Networks," IEEECommunications Magazine, pp.34-42(August 1994).
[Voruganti 1994] Voruganti, R. R., "A Global Network Management Framework for the '90s,"
IEEECommunications Magazine, pp.74-83(August 1994).
[Wilkes and Wheeler 1979] Wilkes, M. V., and Wheeler, D. J., "TheCambridge Digital
Communication Ring,"In:Proceedings ofthe Local Area Communications Network Symposium,
Boston,pp.47-61(May 1979).
[Wittie1991] Wittie, L. D., "Computer Networks andDistributed Systems," IEEE Computer, Vol.
24,No.9,pp.67-75(1991).
[WWW1994&]"World-Wide WebGrowth," ftp:nic.merit.edu (1994).
[WWW 1994b]"TheWWW Virtual Library," http:info.cern.chlhypertextlDataSourceslbySubjectl
Overview.html (June 1994).
(Yazid and Mouftah 1992] Yazid, S.,.andMouftah, H. T.,"Congestion Control Methods for
B-ISDN," IEEECommunications Magazine, Vol. 30,No.7,pp.42-47(1992).
POINTERS TO818UOGRAPHIES ONTHEINTERNET
Bibliographies containing references onComputer Networking can be found at:
ftp:ftp.cs.umanitoba.ca/publbibliographieslDistributedlnetwork.html
ftp:ftp.cs.umanitoba.ca/publbibliographieslDistributedlCCR.htmlChap.2 •PointerstoBibliographies on the Internet 113
Bibliography containing references onCommunication and Routing in Interconnection
Networks can be found at:
ftp:ftp.cs.umanitoba.calpub/bibliographieslParallel/par.comm.html
Bibliography containing references on theInternetcan be found at:
ftp:ftp.cs.umanitoba.ca/pub/bibliographieslMisc/internet.html
Bibliography containing references onGigabitorHigh-Speed Networks canbefound
at:
ftp:ftp.cs.umanitoba.ca/pub/bibliographies/Distributed/gigabit.html
Bibliography containing references onATMNetworks can be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslDislributed/ATM. htmlCHAPTER3
MessQge Passing
3.1INTRODumON
Aprocessis a program in execution. When we say that two computers of a distributed
system are communicating with each other, we mean that two processes, one running on
each computer, are in communication with each other. In a distributed system, processes
executing on different computers often need to communicate with each other to achieve
some common goal. For example, each computer of a distributed system may have a
resourcemanager process to monitor thecurrent statusof usage of its local resources, and
theresource managers of all the computers might communicate witheach other fromtime
to time to dynamically balance the system load among all the computers. Therefore, a
distributed operating system needs to provide interprocess communication (lPC)
mechanisms to facilitate such communication activities.
Interprocess communication basically requires information sharing among two or
more processes. The two basic methods for information sharing are as follows:
1. Original sharing, or shared-data approach
2. Copy sharing, or message-passing approach
In the shared-data approach, the information to be shared is placed in a common
memory area that is accessible to all the processes involved in an IPC. The shared-data
114Sec.3.2 • Desirable Featuresof a Good Message-Passing System 115
paradigm gives the conceptual communication pattern illustrated in Figure 3.1 (a).On the
other hand, in the message-passing approach, the information to be shared is physically
copied from the senderprocess's address space to the address spaces of all the receiver
processes, and this is done by transmitting the data to be copied in the form of messages
(amessage isa block ofinformation). The message-passing paradigm gives the conceptual
communication pattern illustrated in Figure 3.1 (b).That is, the communicating processes
interact directly with each other.
Sharedcommon
memoryarea
(a)
(b)
Fig. 3.1 The two basic interprocess communication paradigms: (a)Theshared-data
approach. (b)Themessage-passing approach.
Sincecomputers in a network do not share memory, processes in adistributed system
normally communicate byexchanging messages rather than through shared data.
Therefore, message passing is the basic IPemechanism in distributed systems.
Amessage-passing systemis a subsystem of a distributed operating system that
provides a set of message-based IPeprotocols and does so byshielding the details of
complex network protocols and multiple heterogeneous platforms from programmers. It
enablesprocesses tocommunicate byexchanging messages and allows programs to be
written by using simple communication primitives, such as sendandreceive.It serves as a
suitableinfrastructure forbuilding other higher levellPC systems, suchasremote procedure
call (RPC; see Chapter4) and distributed shared memory (DSM; see Chapter5).
3.2DESIRABlE FEATURES OFAGOODMESSAGE·PASSING
SYSTEM
3.2.1Simplicity
Amessage-passing system should be sitnple and easy to use. It must be straightforward
toconstruct newapplications and tocommunicate with existing ones by using the
primitives provided by themessage-passing system. It should alsobe possible for a116 Chap.3 •MessagePassing
programmer todesignate thedifferent modulesofadistributed application and to send and
receivemessages between them in a way as simpleaspossiblewithoutthe need to worry
aboutthesystemand/ornetwork aspectsthat are not relevant for theapplication level.
Cleanandsimplesemantics oftheIPeprotocols ofamessage-passing systemmake it
easiertobuilddistributed applications and to get them right.
3.2.1UnlrormSemantics
In adistributed system, a message-passing systemmaybeused for the following two
typesofinterprocess communication:
1. Local communication, in which the communicating processes are on the same
node
2. Remote communication, in which the communicating processes are ondifferent
nodes
Animportant issue in the designofamessage-passing systemis that the semantics
ofremotecommunications shouldbe ascloseaspossible to thoseoflocalcommunica­
tions. This is an important requirement forensuring that themessage-passing systemis
easy to use.
3.2.3Efficiency
Efficiency is.normally acriticalissue for a message-passing systemto beacceptable by
the users. Ifthemessage-passing systemis notefficient, interprocess communication may
becomesoexpensive thatapplication designers willstrenuously trytoavoidits use in their
applications. As a result, the developed application programs would be distorted. AnIPe
protocolofamessage-passing systemcan be made efficient byreducing thenumberof
message exchanges, as far as practicable, duringthecommunication process. Some
optimizations normally adoptedforefficiency includethefollowing:
• Avoiding the costs ofestablishing andterminating connections between the same
pairofprocesses for each and everymessage exchange between them
•Minimizing the costs ofmaintaining theconnections
•Piggybacking ofacknowledgment ofprevious messages with the next message
duringaconnection between asenderand areceiverthatinvolves severalmessage
exchanges
3.1.4Reliability
Distributed systems arepronetodifferent catastrophic eventssuch as node crashesor
communication link failures.. Such eventsmayinterrupt acommunication that was in
progress between twoprocesses, resulting in the loss ofa message. A reliableIPeprotocol
cancopewithfailureproblems andguarantees thedeliveryofamessage. Handling oflostSec. 3.2 • Desirable Features of a Good Message-Passing System 117
messages usually involves acknowledgments and retransmissions on the basis of
timeouts.
Another issue related to reliability is that of duplicate messages. Duplicate messages
may be sent in the event of failures or because of timeouts. A reliable fPCprotocol is also
capable of detecting and handling duplicates. Duplicate handling usually involves
generating and assigning appropriate sequence numbers to messages.
A goodmessage-passing system must have IPC protocols to support these reliability
features.
3.2.5Correctness
A message-passing system often has IPC protocols for group communication that allow a
sender to send a message to a group of receivers and a receiver to receive messages from
several senders. Correctness is a feature related to IPC protocols for group communica­
tion. Although not always required, correctness may be useful for some applications.
Issues related to correctness are as follows [Navratnam et al. 1988]:
• Atomicity
• Ordered delivery
• Survivability
Atomicity ensures that every message sent to a group of receivers will be delivered
to either all of them or none of them. Ordered delivery ensures that messages arrive at all
receivers in an order acceptable to the application. Survivability guarantees that messages
will be delivered correctly despite partial failures of processes, machines, or communica­
tion links. Survivability is a difficult property to achieve.
3.2.6Flexibility
Not all applications require the same degree of reliability and correctness of the fPC
protocols. For example, in adaptive routing, it may be necessary to distribute the
information regarding queuing delays in different parts of the network. A broadcast
protocol could be usedfor this purpose. However, ifa broadcast message is late incoming,
due tocommunication failures, it might justas well not arrive at all as it will soon be
outdated by a more recent one anyway. Similarly, many applications do not require
atomicity or ordered delivery of messages. For example, a client maymulticast a request
message to a group of servers and offer the job to the first server that replies. Obviously,
atomicity of message delivery is not required in this case. Thus the IPC protocols of a
message-passing system must be flexible enough to cater to the various needs of different
applications. That is, the IPC primitives should be such that the users have the flexibility
to choose and specify the types and levels of reliability and correctness requirements of
their applications. Moreover, IPC primitives must also have the flexibility to permit any
kind of control flow between the cooperating processes, including synchronous and
asynchronous send/receive.118 Chap.3 •MessagePassing
A good message-passing system must also be capable of providing a secure end-to-end
communication. That is, a message in transit on the network should not be accessible to
any user other than those to whom it is addressed and the sender. Steps necessary for
secure communication include the following:
• Authentication of the receiver(s) of a message by the sender
• Authentication of the sender of a message by its receiver(s)
• Encryption of a message before sending it over the network
These issues will bedescribed in detail in Chapter 11.
3.1.8Portability
There are two different aspects of portability in a message-passing system:
1. The message-passing system should itself be portable. That is, it should be
possible to easily construct a new IPC facility on another system by reusing the basic
design of the existing message-passing system.
2. The applications written by using the primitives of the IPC protocols of the
message-passing system should be portable. This requires that heterogeneity must be
considered while designing a message-passing system. This may require the use of an
external data representation format for the communications taking place between two or
more processes running on computers of different architectures. The design of high-level
primitives for the IPC protocols of a message-passing system should bedone so as to hide
the heterogeneous nature of the network.
3.3ISSUESINIPCBYMESSAGE PASSING
A message is a block of information formatted by a sending process in such a manner that
it is meaningful to the receiving process. It consists of a fixed-length header and a
variable-size collection of typed data objects. As shown in Figure 3.2, the header usually
consists of the following elements:
• Address. It contains characters that uniquely identify the sending and receiv­
ing processes in the network. Thus, this element has two parts-one part is
the sending process address and the other part is the receiving process
address.
• Sequence number. This is the message identifier (ID), which is very useful
for identifying lost messages and duplicate messages in case of system
failures.Sec.3.3 • Issuesin IPCbyMessagePassing 119
Structural information Addresses
Actual dataNumberof TypeSequenceReceiving Sendingorpointer number
tothe data bytes/or message 10process process
elements address address
..I ~Variable- -4.....141-------- Fixed-length header-----­
sizecollection
oftyped data
Fig.3.2 Atypical message structure.
• Structural information. This element also has two parts. The typepart specifies
whether the data to be passed on to the receiver is included within the message or
the message only contains a pointer tothedata, which is stored somewhere outside
the contiguous portion of the message. The second part of this element specifies
the length of the variable-size message data.
In amessage-oriented IPC protocol, the sending process determines the actual
contents of a message and the receiving process is aware of how to interpret the
contents. Special primitives are explicitly used for sending and receiving the mes­
sages. Therefore, in this method, the users are fullyaware of the message formats
used in the communication process and the mechanisms used to send and receive
messages.
In the design of an IPeprotocol for a message-passing system, the following
important issues need to be considered:
• Who is the sender?
• Who is the receiver?
• Is there one receiver or many receivers?
• Is the message guaranteed to have been accepted byits receiver(s)?
• Does the sender need to wait for a reply?
• What should be done if a catastrophic event such as a node crash or a
communication link failure occurs during the course of communication?
• What should be done if the receiver is not ready to accept the message: Will the
message be discarded or stored in a buffer? In the case of buffering, what should
be done if the buffer is full?
• If there are several outstanding messages for a receiver, can it choose the order in
which to service the outstanding messages?
These issues are addressed bythe semantics of the set of communication primitives
provided bythefPCprotocol. A general description of the various ways in which these
issues are addressed bymessage-oriented IPC protocols is presented below.120
3.4SYNCHRONIZATIONChap.3 • MessagePassing
A central issue in the communication structure is the synchronization imposed on the
communicating processes by the communication primitives. The semantics used for
synchronization may be broadly classified as blocking andnonblocking types. A primitive
is said to have nonblocking semantics if its invocation does not block the execution of its
invoker (the control returns almost immediately to the invoker); otherwise a primitive is
said to be of the blocking type. The synchronization imposed on the communicating
processes basically depends on one of the two types of semantics used for the sendand
receiveprimitives.
In case of a blocking sendprimitive, after execution of the sendstatement, the
sending process is blocked until it receives an acknowledgment from the receiver that the
message has been received. On the other hand, for nonblocking sendprimitive, after
execution of thesendstatement, the sending process is allowed to proceed with its
execution as soon as the message has been copied to a buffer.
In the case of a blocking receiveprimitive, after execution of the receivestatement,
the receiving process is blocked until it receives a message. On the other hand, for a
nonblocking receiveprimitive, the receiving process proceeds with its execution after
execution ofthereceivestatement, which returns control almost immediately justafter
telling the kernel where the message buffer is.
An important issue in a nonblocking receiveprimitive is how the receiving process
knows that the message has arrived in the message buffer. One of the following two
methods is commonly used for this purpose:
1. Polling. In this method, a testprimitive is provided to allow the receiver tocheck
the buffer status. The receiver uses this primitive to periodically poll the kernel to check
if the message is already available in the buffer.
2.Interrupt. In this method, when the message has been filled in the buffer and is
ready for use by the receiver, a software interrupt is used to notify the receiving process.
This method permits the receiving process to continue with its execution without having
to issue unsuccessful testrequests. Although this method is highly efficient and allows
maximum parallelism, its main drawback is that user-level interrupts make programming
difficult [Tanenbaum 1995].
A variant of the nonblocking receiveprimitive is the conditional receiveprimitive,
which also returns control to the invoking process almost immediately, either with a
message or with an indicator that no message is available.
In a blocking sendprimitive, the sending process could get blocked forever in
situations where the potential receiving process has crashed or the sent message has been
lost on the network due to communication failure. Toprevent this situation, blocking send
primitives often use a timeout value that specifies an interval of time after which the send
operation is terminated with an error status. Either the timeout value may be a default
value or the users may be provided with the flexibility to specify it as a parameter of the
sendprimitive.Sec.3.4 • Synchronization 121
A timeout value may also be associated with a blocking receiveprimitive to prevent
the receiving process from getting blocked indefinitely in situations where the potential
sending process has crashed or the expected message has been lost on the network due to
communication failure.
When both the sendandreceiveprimitives of a communication between two
processes useblocking semantics, the communication is said to be synchronous; otherwise
it isasynchronous. That is, for synchronous communication, the sender and the receiver
must be synchronized to exchange a message. This is illustrated in Figure 3.3.
Conceptually, the sending process sends a message to the receiving process, then waits for
anacknowledgment. After executing the receivestatement, the receiver remains blocked
until it receives the message sent by the sender. On receiving the message, the receiver
sends anacknowledgment message to the sender.The sender resumes execution only after
receiving this acknowledgment message.
Sender's
executionReceiver's
execution
Receive(message);
Iexecution suspended
I
I
I
I
I
I
I
Execution resumedSend(message);
execution suspended
I
III
I
I
I
I
Execution resumed ISend(acknowledgment)
Blockedstate
Executing state
Fig.3.3 Synchronous mode of communication with both sendandreceiveprimitives
havingblocking-type semantics.
Ascompared to asynchronous communication, synchronous communication issimple
and easy to implement. It also contributes to reliability because it assures the sending
process that its message has been accepted before the sending process resumes execution.
As a result, if the message gets lost or is undelivered, no backward error recovery is122 Chap.3 •MessagePassing
necessary forthesendingprocess toestablish a consistent stateandresume execution [Shatz
1984]. However, the main drawback ofsynchronous communication is that it limits
concurrency and is subject to communication deadlocks (communication deadlock is
described inChapter6). It is less flexible than asynchronous communication because the
sendingprocessalways hastowaitforan acknowledgment from thereceiving process even
when thisisnotnecessary. Inasystem thatsupports multiplethreads inasingle process (see
Chapter 8), the blocking primitives can be used without the disadvantage oflimited
concurrency. How this ismade possible is explained inChapter8.
A flexible message-passing system usually provides both blocking and nonblocking
primitives forsendandreceiveso that users can choose the most suitable one to match the
specificneeds of their applications.
3.5BUFFERING
Messages canbetransmitted from one process to another by copying the body of the
message from the address space ofthe sending process totheaddress space ofthe receiving
process (possibly via the address spaces of the kernels of the sending and receiving
computers). In some cases, the receiving process may not be ready to receivea message
transmitted to itbutitwantstheoperating system tosavethat message forlaterreception. In
these cases, theoperating system willrelyonthereceiver having abuffer inwhich messages
can be stored prior to the receiving process executing specific code toreceive the message.
Ininterprocess communication, themessage-buffering strategy is strongly related to
synchronization strategy. The synchronous and asynchronous modes of communication
correspond respectively to the two extremes of buffering: a null buffer, ornobuffering,
and abufferwithunbounded capacity. Other two commonly used buffering strategies are
single-message andfinite-bound, ormultiple-message, buffers. These four types of
buffering strategies are described below.
3.5.1Nullluff.r(orNoluff.rlng)
In case of no buffering, there is no place to temporarily store the message. Hence one of
the following implementation strategies may be used:
1. The message remains in the sender process's address space and the execution of
thesendis delayed until the. receiverexecutes the corresponding receive.To do this, the
senderprocessis backed up and suspended in such a way that when itis unblocked, it
starts by reexecuting thesendstatement. When the receiver executes receive, an
acknowledgment is sent to the sender'skernel saying that the sendercan now send the
message. On receiving the acknowledgment message, the sender is unblocked, causing the
sendto beexecuted once again. This time, the message is successfully transferred from the
sender's address space to the receiver's address space because the receiveris waiting to
receive the message.
2. The message is simply discarded and the timeout mechanism is used to resend the
message after a timeout period. That is, after executing send,the sender process waits forSec.3.5 • Buffering 123
anacknowledgment from the receiver process. If noacknowledgment isreceived within
thetimeoutperiod,itassumes that itsmessage wasdiscarded and tries againhopingthat
this time the receiver has already executedreceive.Thesendermay have to try several
timesbeforesucceeding. Thesendergives up afterretryingfor apredecided numberof
times.
Asshownin Figure 3.4(a),in the case of no buffering, thelogicalpathofmessage
transfer isdirectly from the sender's addressspace to the receiver's addressspace,
involving a single copy operation.
Sending Receiving
~~------------~@
(a)
Sending
processReceiving
process
Node
boundary
(b)
Sending
process
IMessage21
IMessage31
Multiple·message
buffer/mailbox/port
(c)
Fig. 3.4 The three types of buffering strategies used in interprocess comunication
mechanisms: (a)Message transfer in synchronous sendwithno buffering
strategy (only one copy operation is needed). (b)Message transfer in
synchronous send with single-message buffering strategy (two copy
operations are needed). (c)Message transfer in asynchronous send with
multiple-message buffering strategy (two copy operations are needed).124 Chap.3 •MessagePassing
3.5.1Single-Messap luff.r
The null bufferstrategy is generally notsuitableforsynchronous communication between
twoprocesses in adistributed systembecauseif thereceiveris not ready, a message has
to betransferred two or more times, and the receiverofthemessage has to wait for the
entire time taken to transferthe message across the network. In a distributed system,
message transfer across the network may require significant time in some cases.
Therefore, insteadof using the null buffer strategy, synchronous communication
mechanisms innetwork/distributed systemsuse asingle-message bufferstrategy. In this
strategy, a buffer having a capacity to store a single message is used on the receiver's
node. This is becausein systems based on synchronous communication, anapplication
modulemay have at most one message outstanding at a time. The main idea behind the
single-message buffer strategy is to keep the message ready for use at the locationof the
receiver. Therefore, in this method, the request message is buffered on the receiver's node
if thereceiver is not ready to receive the message. The message buffermayeitherbe
located in the kernel'saddress space or in the receiverprocess's addressspace. As shown
inFigure3.4(b),in this case the logical path ofmessage transferinvolves two copy
operations.
3.5.3Unbounded-Capacity luffe,
In theasynchronous modeofcommunication, since asenderdoes not wait for the receiver
to be ready, there may be several pendingmessages that have not yet been accepted by the
receiver. Therefore, anunbounded-capacity message buffer that can store all unreceived
messages is needed to supportasynchronous communication with the assurance that all
themessages sent to the receiverwill be delivered.
3.5.4Flnlte-80und (orMultlpl.-MuSQge) lu".r
Unbounded capacityofa buffer is practically impossible. Therefore, inpractice, systems
usingasynchronous modeofcommunication usefinite-bound buffers, also known as
multiple-message buffers. When the buffer has finite bounds, a strategy is also needed for
handling theproblem of apossiblebufferoverflow. The buffer overflow problem can be
dealt with in one ofthe following two ways:
1. Unsuccessful communication. In this method, message transfers simply fail
whenever there is no more buffer space. The sendnormally returns an errormessage to the
sendingprocess,indicating that themessagecould not be delivered to thereceiverbecause
thebufferis full.Unfortunately, the useofthis method makes message passingless
reliable.
2. Flow-controlled communication. The second method is to use flow control,which
means that the senderisblockeduntil the receiveraccepts some messages, thus creatingSec.3.6 • Multidatagram Messages 125
space in the buffer for new messages. This method introduces a synchronization between
the sender and the receiver and mayresult in unexpected deadlocks. Moreover, due to the
synchronization imposed, the asynchronous send does not operate in the truly
asynchronous mode for all sendcommands.
The amount of buffer space to be allocated in the bounded-buffer strategy is a
matter of implementation. In the most often used approach, a create_buffer system
call is provided to the users. This system call, when executed by a receiver process,
creates a buffer (sometimes called a mailbox orport)of a size specified by the
receiver. The receiver's mailbox may be located either in the kernel's address space
or in the receiver process's address space. If it is located in the kernel's address
space, mailboxes are a system resource that must be allocated to processes as and
when required. This will tend to limit the number of messages that an individual
process may keep in its mailbox. On the other hand, ifthe mailbox is located in the
receiver process's address space, the operating system will have to rely on the
process allocating an appropriate amount of memory, protecting the mailbox from
mishaps, and so on.
As shown in Figure 3.4(c),in the case of asynchronous sendwithbounded-buffer
strategy, the message is first copied from the sending process's memory into the receiving
process's mailbox and then copied from the mailbox to the receiver's memory when the
receiver calls for the message. Therefore, in this case also, the logical path of message
transfer involves two copy operations.
Although message communication based on multiple-message-buffering capability
provides better concurrency and flexibility as compared to no buffering or single-message
buffering, it is more complex to design and use. This is because of the extra work and
overhead involved in the mechanisms needed for the creation, deletion, protection, and
other issues involved in buffer management.
3.6MUlTIDATAGRAM MESSAGES
Almost all networks have an upper bound on the size of data that can be transmitted at a
time. This size is known as the maximum transferunit (MTU) of a network. A message
whose size is greater than the MTU has to be fragmented into multiples of the MTU,and
then each fragment has to be sent separately. Each fragment is sent in a packet that has
some control information in addition to the message data. Each packet is known as a
datagram. Messages smaller than the Ml'Uof the network can be sent in a single packet
and are known as single-datagram messages. On the other hand, messages larger than the
MTU of the network have to be fragmented and sent in multiple packets. Such messages
are known as multidatagram messages. Obviously, different packets of a multidatagram
message bear a sequential relationship to one another. The disassembling of a
multidatagram message into multiple packets on the sender side and the reassembling ofthe packets on the receiver side is usually the responsibility of the message-passing
system.126
3.7ENCODING ANDDECODING OFMESSAGE DATAChap.3 •MessagePassing
A message data should be meaningful to the receiving process. This implies that, ideally,
the structure of program objects should be preserved while theyare being transmitted from
the address space of the sending process to the address space of the receiving process. This
obviously is not possible in a heterogeneous system in which the sending and receiving
processes are on computers ofdifferent architectures. However, even in homogeneous
systems,itis very difficult to achieve this goal mainly because oftwo reasons:
1. An absolute pointer value loses its meaning when transferred from one process
address space to another. Therefore, such program objects that use absolute pointervalues
cannotbe transferred in their original form, and some other form of representation must
be used to transfer them. For example, to transmit a tree object, each elementof the tree
must be copied in a leaf record and properly aligned in some fixed order in a buffer before
it can be sent to another process. The leaf records themselves have no meaning in the
address space of the receiving process, but the tree can be regenerated easily from them.
To facilitate such regeneration, object-type information must be passed between the
senderand receiver, indicating not only that a tree object isbeing passed but also the order
in which the leafrecords are aligned. This process of flattening and shaping of tree objects
also extends to other structured program objects, such as linked lists.
2. Different program objects occupy varying amount of storage space. To be
meaningful, a message must normally contain several types of program objects, such as
long integers, short integers, variable-length character strings, and so on. In this.case, to
make the message meaningful to the receiver, there must be some way for the receiverto
identify which program object is stored where in the message buffer and how much space
each program object occupies.
Due to the problems mentioned above in transferring program objects in their
original form, they are first converted toa stream form that issuitable for transmission and
placed into a message buffer. This conversion process takes place on the sender side and
is known as encoding ofa message data. The encoded message, when received by the
receiver, must be converted back from the stream form to the original program objects
before it can be used.The process of reconstruction of program objects from message data
on thereceiverside is known as decoding of the message data.
One of the following two representations may be used for the encoding and'decoding
of a message data:
1. In tagged representation the type of each program object along with its value is
encoded in the message. In this method, it is a simple matter for the receiving process to
check the type ofeach program object in the message because of the self-describing nature
of the coded data format.
2. Inuntagged representation the message data only contains program objects. No
information is included in the message data to specify the type of each program object. InSec.3.8 • ProcessAddressing 127
this method, the receiving process must have a prior knowledge ofhow to decode the
received data because the coded data format is not self-describing.
The untagged representation is used in Sun XDR (eXternal Data Representation)
[Sun 1990] and Courier[Xerox 1981], whereas the tagged representation is used in the
ASN.1 (Abstract Syntax Notation) standard [CCITf 1985] and the Mach distributed
operating system[Fitzgerald and Rashid 1986].
In general, tagged representation is more expensive than untagged representation,
both in terms of the quantity of data transferred and the processing time needed at each
side to encode and decode the message data. No matter which representation is used, both
the sender and the receiver must be fully aware of the format ofdata coded inthe message.
The sender possesses the encoding routine for the coded data format and the receiver
possesses the corresponding decoding routine. The encoding and decoding operations are
perfectly symmetrical in the sense that decoding exactly reproduces the data that was
encoded, allowing for differences in local representations. Sometimes, a receiver may
receive a badly encoded data, such as encoded data that exceeds a maximum-length
argument. In such a situation, the receiver cannot successfully decode the received data
and normally returns an error message to the sender indicating that the data is not
intelligible.
3.8PROCESS ADDRESSING
Another important issue in message-based communication is addressing (or naming) of
the parties involved in an interaction: To whom does the sender wish to send itsmessage and, conversely, from whom does the receiver wish to accept a message? For
greater flexibility, a message-passing system usually supports two types of process
addressing:
1.Explicit addressing. The process with which communication is desired is
explicitly named as a parameter in thecommunication primitive used. Primitives (a)
and(b)of Figure 3.5 require explicit process addressing.
2.Implicit addressing. A process willing to communicate does not explicitly name
a process for communication. Primitives (c)and(d)of Figure 3.5 support implicit
process addressing. In primitive (c),the sender names a service instead of a process.
This type of primitive is useful in client-server communications when the client is not
concerned with which particular server out of a set of servers providing the service
desired by the client actually services its request. This type of process addressing is also
known as functional addressing because the address used in the communication
primitive identifies a service rather than a process.
On the other hand, in primitive (d),the receiver is willing to accept a message
from any sender. This type of primitive is again useful in client-server communications
when the server is meant to service requests of all clients that are authorized to use its
service.128 Chap.3 •MessagePassing
(a)send(process_id, message)
Sendamessagetotheprocessidentifiedby"process_id".
(b)receive(process_id, message)
Receiveamessagefromtheprocess identifiedby"process_id".
(c)send_any (service_id, message)
Sendamessagetoanyprocessthat providestheserviceoftype
"service_ief'.
(d)receive_any (process_id, message)
Receiveamessagefromanyprocessand returntheprocess
identifier("process_id") oftheprocessfromwhichthe message
wasreceived.
Fig.3.5 Primitives for explicit and implicit addressing of processes.
With the two basic types ofprocess addressing usedin communication primitives, we
now look at the commonly used methods for process addressing.
A simple method to identify a process is by a combination of machine_id andlocal_
id,such asmachine_id@local_id. Thelocal_id part is a process identifier, or a port
identifier of a receiving process, or something else that can be used to uniquely identify
a process on a machine. A process willing to send a message to another process specifies
thereceiving process's address in the form machine_id@local_id. Themachine_id part of
the address is used by the sending machine's kernel to send the message to the receiving
process's machine, and the local_idpart of the address is then used by the kernel of the
receiving process's machine to forward the message totheprocess for which itisintended.
This method of process addressing is used in Berkeley UNIX with 32-bit Internet
addresses for machine_id and 16-bit numbers for local_id.
An attractive feature of this method is that no global coordination is needed to
generate systemwide unique process identifiers because local_ids need tobeunique only
for one machine and can be generated locally without consultation with other machines.
However, a drawback of this method is that it does not allow a process to migrate from
one machine to'another if such a need arises. For instance, one or more processes of a
heavily loaded machine may be migrated to a lightly loaded machine to balance the
overall system load.
To overcome the limitation of the above method, processes can be identified by a
combination of the following three fields: machineld,local_id, andmachineid.
1. The first field identifies the node on which the process is created
2. The second field is a local indentifier generated by the node on which the process
is created
3. The third field identifies the last known location (node) of the process.
During the lifetime of a process, the values of the first two fields of its identifier
never change; the third field, however, may.This method of process addressing is known
aslink-based processaddressing. For this method to work properly, when a process isSec.3.8 • ProcessAddressing 129
migrated from its current node to a new node, a linkinformation (process identifier with
the value of its third field equal to the machineid of theprocess's new node) is left on
its previous node, and on the new node, a new local_idis assigned to the process, and its
process identifier and the new local_idis entered in a mapping table maintained by the
kernelofthe new node for all processes created on another node but running on this node.
Note that the value of the third field of a process identifier is set equal to its first field
when the process is created.
A process willing to send a message to another process specifies the receiving
process's address in the form, say, machine_id@local_id@machine_id. The kernel of
the sending machine delivers the message to the machine whose machine_id is specified
in the third field of the receiving process's address. If the value of the third field is
equal to the first field, the message will be sent to the node on which the process was
created. If the receiving process was not migrated, the message is delivered to it by
using the local_id information in the process identifier. On the other hand, if the
receiving process was migrated, the link information left for it on that node is used to
forward the message to the node to which the receiving process was migrated from this
node. In this manner, the message may get forwarded from one node to another several
times before it reaches the current node of the receiving process. When the message
reaches the current node of the receiving process, the kernel of that node extracts the
process identifiers of the sending and receiving processes from the message. The first
two fields of the process identifier of the receiving process are used as its unique
identifier to extract its localidfrom the mapping table and then to deliver the message
to the proper process. On the other hand, the process identifier of the sending process is
used to return to it the current location of the receiving process. The sending process
uses this information to update the value of the third field of the receiving process's
identifier, which it caches in a local cache, so that from the next time the sending
process can directly send a message for the receiving process to this location of the
receiving process instead of sending it via the node on which the receiving process was
created. A variant of this method of process addressing is used in DEMOSIMP [Miller
eta1.1987] and Charlotte [Artsyet al. 1987]. Although this method of process
addressing supports the process migration facility, it suffers from two main drawbacks:
1. The overload of locating a process may be large if the process has migrated
several times during its lifetime.
2. Itmaynot be possible to locate a process if an intermediate node on which the
process once resided during its lifetime is down.
Bothprocess-addressing methods previously described are nontransparent due to the
need tospecify the machine identifier.The useris wellawareof thelocation of the process
(or at least the location on which the process was created). However, we saw in Chapter
1 that location transparency is one of the main goals of a distributed operating system.
Hence a location-transparent process-addressing mechanism is more desirable for a
message-passing system. A simple method to achieve this goal is to ensure that the
systemwide unique identifier of a process does not contain an embedded machine
identifier. A centralized process identifier allocator that maintains a counter can be used130 Chap.3 •MessagePassing
for this purpose. When it receives a request for an identifier, it simply returns the current
valueofthe counter and then increments it by 1.This scheme, however, suffers from the
problems of poor reliability and poor scalability.
Another method to achieve the goal of location transparency in process addressing is
to use a two-level naming scheme for processes. In this method, each process has two
identifiers: a high-level name that is machine independent (an ASCII string) and a low­
level name that is machine dependent (such as machine_id@local_id). Aname server is
used to maintain a mapping table that maps high-level names ofprocesses to their low­
level names. When this method of process addressing is used, a process that wants to send
a message to another process specifies the high-level name of the receiving process in the
communication primitive. The kernel of the sending machine first contacts the name
server (whose address is well known to all machines) to get the low-level name of the
receiving process from itshigh-level name. Usingthelow-level name, the kernel sends the
message to the proper machine, where the receiving kernel delivers the message to the
receiving process. The sending kernel also caches the high-level name to low-level name­
mapping information ofthe receiving process in a local cache for future use, so that the
name server need not be contacted when a message has to be sent again to the receiving
process.
Notice that the name server approach allows a process to be migrated from one node
to another without the need to change the code in the program of any process that wants
tocommunicate with it. This is because when a process migrates its low-level identifier
changes, and this change isincorporated inthe name server'smapping table. However, the
high-level name of the process remains unchanged.
The name server approach is also suitable for functional addressing. In this case, a
high-level name identifies a service instead of a process, and the name server maps a
serviceidentifier to one or more processes that provide that service.
The name server approach also suffers from the problems of poor reliability and poor
scalability because the name server is a centralized component of the system. One way to
overcome these problems is to replicate the name server. However, this leads to extra
overhead needed in keeping the replicas consistent.
3.9FAilUREHANDLING
While a distributed system may offer potential for parallelism, itis also prone to partial
failures such as a nodecrash or a communication link failure. As shown in Figure 3.6,
during interprocess communication, such failures may lead to the following problems:
1. Lossofrequest message. This may happen either due to the failure of
communication link between the sender and receiver or because the receiver's node is
down at the time the request message reaches there.
2. Lossofresponse message. This may happen either due to the failure of
communication link between the sender and receiver or because the sender'snode isdown
at the time the response message reaches there.Sec.3.9 •FailureHandling
Sender Receiver131
Sendrequest
Lost
(a)
Sender
Sendrequest
Successful request
execution
Send response
Sender
SendrequestLost
(b)
(c)Receiver
\Restarted
Fig.3.6 Possible problems in IPedue to different types of system failures. (a)
Request message is lost. (b)Response message is lost. (c)Receiver's
computer crashed.
3. Unsuccessful execution ofthe request. This happens due to the receiver's node
crashing while the request is being processed.
To cope with these problems, a reliable IPC protocol of a message-passing system is
normallydesigned based on the idea of internal retransmissions of messages after timeouts
and the return of an acknowledgment message to the sending machine's kernel by the
receiving machine's kernel. That is, the kernel of the sending machine is responsible for
retransmitting the message after waiting for a timeout period ifnoacknowledgment is
received from the receiver's machine within this time. The kernel of the sending machine
frees the sending process onlywhen the acknowledgment is received. The time duration132 Chap.3 •MessagePassing
for whichthesender waitsbefore retransmitting therequest isnormally slightly more than
the approximate round-trip timebetween the sender and the receiver nodes plus the
average time required for executing the request.
Based on the above idea, a four-message reliable IPC protocol for client-server
communication between two processes works as follows (see Fig. 3.7):
Client
- - - -Blockedstate-.-Executing stateFig. 3.7 The four-message reliable IPC
protocol for client-server
communication between two
processes.
1. The client sends a request message to the server.
2. When the request message is received at the server'smachine, the kernel of that
machine returns an acknowledgment message to the kernel of the client machine. If the
acknowledgment isnot received within the timeout period, the kernel ofthe client
machine retransmits the request message.
3. Whenthe server finishes processing theclient's request,itreturns areply message
(containing the result of processing) to the client.
4. When the reply message is received at the client'smachine, the kernel of that
machine returns an acknowledgment message to the kernel of the server machine. If the
acknowledgment message is not received within the timeout period, the kernel of the
server machine retransmits the reply message.Sec.3.9 • FailureHandling 133
Inclient-server communication, theresultoftheprocessed requestissufficient
acknowledgment thattherequestmessage wasreceivedbythe server. Basedon this idea,
athree-message reliable IPCprotocol forclient-server communication between two
processes worksasfollows(see Fig. 3.8):
Fig.3.8 Thethree-message reliableIPC
protocol for client-server
communication between two
processes.----- Blocked state--Executing state
1. Theclientsendsarequestmessage to the server.
2.Whentheserverfinishesprocessing theclient'srequest,itreturnsareplymessage
(containing theresultofprocessing) to theclient.Theclientremains blocked until the
reply isreceived. If the reply is not received withinthetimeoutperiod,thekernelofthe
clientmachine retransmits therequestmessage.
3.Whenthereplymessage isreceived at theclient'smachine, thekernelofthat
machine returnsanacknowledgment message to thekerneloftheservermachine. If the
acknowledgment message is notreceived withinthetimeoutperiod,thekernelofthe
servermachine retransmits thereplymessage.
In theprotocol ofFigure3.8, aproblem occursif arequestprocessing takesa long
time. If the requestmessage is lost, it will be retransmitted onlyafterthetimeoutperiod,
which has beenset to a large valuetoavoidunnecessary retransmissions oftherequest
message. On the otherhand, if the timeout valueis not set properly takinginto
consideration the long time neededforrequestprocessing, unnecessary retransmissions of134 Chap.3 •MessagePassing
the request message will take place. The following protocol may be used to handle this
problem:
1. The client sends a request message to the server.
2. When the request message is received at the server'smachine, the kernel of that
machine starts a timer.If the server finishes processing the client'srequest and returns the
reply message totheclient beforethetimerexpires, thereplyservesasthe acknowledgment
ofthe request message. Otherwise, a separate acknowledgment is sent by the kernel of the
server machine toacknowledge therequest message. Ifan acknowledgment isnotreceived
within the timeout period, the kernel of the client machine retransmits the request
message.
3. When the reply message is received at the client'smachine, the kernel of that
machine returns an acknowledgment message to the kernel of the server machine. If the
acknowledgment message is not received within the timeout period, the kernel of the
server machine retransmits the reply message.
Notice that the acknowledgment message from client to server machine in the
protocol of Figure 3.8 is convenient but not a necessity. This is because if the reply
message is lost, the request message will be retransmitted after timeout. The server can
process the request once again and return the reply to the client. Therefore, a message­
passing system maybedesigned to usethe following two-message IPC protocol forclient­
server communication between two processes (see Fig. 3.9):
- - -Blockedstate--Executing stateFig.3.9 Thetwo-message IPCprotocol used
in many systems for client-server
communication between two
processes.Sec.3.9 • FailureHandling 135
1. The client sends a request message to the server and remains blocked until a reply
is received from the server.
2. When the server finishes processing the client'srequest, it returns areply message
(containing the result of processing) to the client. If the reply is not received
within the timeout period, the kernel of the client machine retransmits the request
message.
Based on the protocol of Figure 3.9, an example of failure handling during
communication between two processes is shown in Figure 3.10. The protocol of Figure
3.9is said to obey at-Least-once semantics, which ensures that at least one execution of the
receiver's operation has been performed (but possibly more). It is more appropriate to call
TimeoutTClient
Send
requestServer
Lost
Send
request
Timeout
Timeout1Send
requestCrashUnsuccessful
request execution
Restarted
Successful
request execution
'\Send response
)These two successful
executions of the same
request may produce
different results.
Successful
request execution
Send response
Fig.3.10 An example of fault-tolerant communication between a client and a server.136 Chap. 3 • Message Passing
this semantics the last-one semantics because the results of the last execution of the
request are used by the sender, although earlier(abandoned) executions of the request may
have had side effects that survived the failure. As explained later, this semantics may not
beacceptable to several applications.
3.9.1Idempotency andHandlingorDuplicate Request
Messages
Idempotency basically means "repeatability." That is,an idempotent operation produces the
same results without any side effects no matter how many.times it is performed with the
same arguments. An example of anidempotent routine is a simple GetSqrtprocedure for
calculating the square root ofagiven number. For example, GetSqrt(64) always returns 8.
On the other hand, operations that do not necessarily produce the same results when
executed repeatedly with the same arguments are said to be nonidempotent. For example,
consider the following routine ofa server process that debits a specified amount from a
bank account and returns the balance amount to a requesting client:
debit(amount)
if(balance ~amount)
{balance=balance-amount;
return ("success", balance);}
else return ("failure", balance);
end;
Figure 3.11 shows a sequence ofdebitiI00) requests made by a client for processing
thedebitroutine. The first request asks the server to debit an amount of 100 from the
balance. The server receives the request and processes it. Suppose the initial balance was
1000, so the server sends a reply ("success," 900) to the client indicating that the balance
remaining is 900. This reply, for some reason, could not be delivered to the client. The
client then times out waiting for the response of its request and retransmits thedebiti100)
request. The server processes the debit(100) request once again and sends a reply
("success," 8(0)to the client indicating that the remaining balance is 800, which is not
correct.Therefore, we see from this example that multiple executions ofnonidempotent
routines produce undesirable results.
Clearly, when no response is received by the client, it is impossible to determine
whether the failure wasdue to a server crash.or the loss of the request or response message.
Therefore, as can be seen in Figure 3.10, due to the use of timeout-based retransmission of
requests, the server may execute (either partially or fully) the same request message more
than once. This behavior mayormay not be tolerable depending on whether multiple
executions of the request have the same effect as a single execution (as in idempotent
routines). If the execution of the request is nonidempotent, then its repeated execution will
destroytheconsistency ofinformation. Therefore such "orphan" executions must,ingeneral,
beavoided. The orphan phenomenon has led to the identification and use of exactly-once
semantics, which ensures that only one execution of the server'soperation is performed.
Primitives based on exactly-once semantics are mostdesired butdifficult to implement.Sec.3.9 • FailureHandling
ClientServer
(balance=1000)137
SendTrequest
Timeout
_1~nd
requestProcessdebitroutine
balance=1000- 100=900
Return(success, 900)
Processdebit routine
balance=900- 100 =800
Receive
balance=800Return(success,800)
(success, 800)
debit (amount)
{
if(balance >=amount)
{ balance =balance -amount;
retum("success", balance);
}
elsereturn(Ufailure",balance);
Fig. 3.11 A nonidempotent routine.
One way to implement exactly-once semantics is to use a unique identifier for every
request that the client makes and toset up areply cache inthe kernel'saddress space on the
server machine to cache replies. In this case, before forwarding a request to a server for
processing, the kernel oftheservermachine checks to see if a reply already exists in the
reply cache for therequest. Ifyes, this means that this isa duplicate request that has already
been processed. Therefore, thepreviously computed result isextracted from thereply cache
and anew response message issent totheclient. Otherwise, the request isanewone. Inthis
case, the kernel forwards the requestto theappropriate server for processing, and when the
processing isover, it caches the request identifier along with the result of processing in the
reply cache before sending a response message tothe client.
Anexample ofimplementing exactly-once semantics is shown in Figure 3.12. This
figure is similarto Figure 3.11 exceptthat requests are now numbered, and a reply cache
has been added to the server machine. The client makes request-I ;the server machine's
kernel receives request-l and then checks the reply cache to see ifthere is a cachedreply138 Chap.3 • MessagePassing
ClientServer
(balance=1000)Request Replyto
identifier besent
...request-1 success,900)-10----- ~----_.
Replycache
SendIrequest-1
Timeout
Checkreplycacheforrequest ...1
Matchfound I
Extractreply..-----J
Return(success. 900)Checkreplycacheforrequest ...1
Nomatch found,soprocessrequest ...1
Savereply---.J
Return(success, 900)
Send
request ...1
Receive
balance=900
Fig.3.12 An example of exactly-once semantics using request identifiers and reply cache.
forrequest-I, There is no match, so it forwards the request to the appropriate server.The
server processes the request and returns the result to the kernel. The kernel copies the
requestidentifier and the result of execution to the reply cache and then sends the result
in the form of a response message to the client. "Thisreply is lost, and the client times out
onrequest ...land retransmits request-I, The server machine's kernel receives request-I
once again and checks the reply cache to see if there is a cached reply for request-I, This
time a match is found so it extracts the result corresponding torequest-Jfrom the reply
cache and once again sends it to the client as a response message. Thus the reprocessing
of a duplicate request is avoided. Note that the range of the request identifiers should be
much larger than the number of entries in the cache.Sec.3.10 •GroupCommunication 139
Itisimportant toremember that the use of a reply cachedoes not make a
nonidempotent routineidempotent. Thecacheis simply one possible way toimplement
nonidempotent routines withexactly-once semantics.
3.9.2 K••plngTrackof lostQndOut-of-Sequence Packets
inMultldGtGgram MessGges
Inthecase of multidatagram messages, thelogical transferofamessageconsistsofphysical
transferof several packets. Therefore, amessage t.ransmission can be considered to be
complete only when all the packets of the message have been received by the process to
which it is sent. For successful completion ofamultidatagram message transfer, reliable
delivery of every packetisimportant. Asimpleway toensurethis is to acknowledge each
packetseparately (calledstop-and-wait protocol). But aseparateacknowledgment packet
for each requestpacketleads to a communication overhead. Therefore, toimprove
communication performance, a betterapproach is to use a single acknowledgment packet
for all the packets ofamultidatagram message (calledblastprotocol). However, when this
approach is used, a node crash or a communication link failure may lead to the following
problems:
• One or more packets of the multidatagram message are lost in communication.
• The packets arc received out ofsequence by the receiver.
Anefficient mechanism to cope with these problems is to use a bitmapto identify the
packetsofamessage. Inthis mechanism, theheaderpart ofeach packetconsistsoftwo extra
fields, one of which specifies the totalnumberofpacketsinthemultidatagram messageand
the other is the bitmapfield that specifies theposition of this packet in the complete
message. The first field helps the receiving processto set aside a suitably sized bufferarea
for themessage and the second field helps in deciding thepositionof this packet in that
buffer. Since all packetshaveinformation about the total numberof packets in the message,
so even in the case of out-of-sequence receipt of the packets,that is, even when the first
packetisnotreceivedfirst, asuitably sized bufferarea can besetaside bythe receiverforthe
entire message and the received packetcan beplacedin itsproperpositioninside the buffer
area. After timeout, if all packets have not yet been received, a bitmap indicating the
unreceived packetsis sent to the sender. Using the bitmapinformation, thesender
retransmits only those packets that have not been received by the receiver. This technique is
calledselective repeat. When all the packetsofamultidatagram message are received, the
message transferiscomplete, and thereceiversends an acknowledgment message to the
sending process. This method of multidatagram messagecommunication isillustrated with
anexample inFigure3.13 in which the multidatagram message consistsof five packets.
3.10GROUPCOMMUNICATION
The most elementary form of message-based interaction isone-to-one communication
(also known as point-to-point, orunicast, communication) in which a single-sender
process sends a message to asingle-receiver process.However, forperformance and ease140 Chap.3 •MessagePassing
Missingpackets information(5,0100 1~)__42
3
51Bufferfor5packets
erfor5~
dplace
in..
acket
3..
.....H
I~~
acket
5---1
quest
cket--
cketPlacethis p
inpositionCreate buff
packetsan
thispacket
position2
Placethisp
inpositionTimeoutTSendrequestmessage
LostReceiverofthe
multidatagram
message
Fourthof5packetsSenderofa
multidatagram
messagethat
consistsof
fivepackets
Packets
ofthe
responseI
---r
Resend missing
packets
---L
Sendacknowledgment
Acknowledgment
Fig.3.13 Anexampleoftheuseofabitmaptokeeptrackoflostandoutofsequence
packetsina multidatagram messagetransmission.
of programming, several highly parallel distributed applications require that a message­
passing system should also provide group communication facility.Depending on singleor
multiple senders and receivers, the following three types of group communication are
possible:
1. One to many (single sender and multiple receivers)
2. Many to one (multiple senders and single receiver)Sec.3.10 •GroupCommunication
3. Many to many (multiple senders and multiple receivers)
The issues related to these communication schemes are described below.
3.10.1On8-to-Many Communication141
In this scheme, there are multiple receivers for a message sent by a single sender. One-to­
many scheme is also known as multicast communication. A special case ofmulticast
communication isbroadcast communication, in which the message is sent to all
processors connected to a network.
Multicastlbroadcast communication is very useful for several practical applications.
For example, consider a server manager managing a group of server processes all
providing the same type of service. The server manager can multicast a message to all the
server processes, requesting that afree server volunteer toserve thecurrent request. It then
selects the first server that responds. The server manager does not have to keep track of
the free servers. Similarly, to locate a processor providing a specific service, an inquiry
message may be broadcast. Inthiscase, it isnot necessary to receive ananswer from every
processor; justfinding one instance of the desired service is sufficient.
GroupManagement
In case of one-to-many communication, receiver processes of a message form a group.
Such groups are of two types--closed and open. A closedgroupis one in which only the
members of the group can send a message to the group. An outside process cannot send
a message to the group as a whole, although it may send a message to an individual
memberof the group. On the other hand, an open group is one in which any process in
the system can send a message to the group as a whole.
Whether to use a closed group or an open group is application dependent. For
example, agroup of processes working on acommon problem need not communicate with
outside processes and can form a closed group. On the other hand, a group of replicated
servers meant for distributed processing ofclient requests must form anopen group so that
client processes can send their requests to them. Therefore, a flexible message-passing
system with group communication facility should support both types of groups.
Amessage-passing system with group communication facility provides the flexibility
to create and delete groups dynamically and to allow a process tojoin or leave a group at
any time. Obviously, the message-passing system must have a mechanism to manage the
groups and their membership information. A simple mechanism for this is to use a
centralized groupserverprocess. All requests to create a group, to delete a group, to add
a member to a group, or to remove a member from a group are sent to this process.
Therefore, it is easy for the group server to maintain up-to-date information of all existing
groups and their exact membership. This approach, however, suffers from the problems of
poor reliability and poor scalability common to all centralized techniques. Replication of
the group server may be done to solve these problems to some extent. However,
replication leads to the extra overhead involved in keeping the group information of all
group servers consistent.142 Chap.3 •MessagePassing
GroupAddressing
A two-level naming scheme is normally used for group addressing. The high-level group
name is an ASCII string that is independent of the location information of the processes
in the group. On the other hand, the low-level group name depends to a large extent on
the underlying hardware. For example, on some networks it is possible to create a special
network address to which multiple machines can listen. Such a network address is called
amulticast address.A packet sent to a multicast address is automatically delivered to all
machines listening to the address. Therefore, in such systems a multicast address is used
as a low-level name for a group.
Some networks that do not have the facility to create multicast addresses may have
broadcasting facility. Networks with broadcasting facility declare a certain address, such
as zero, as a broadcast address. A packet sent to a broadcast address is automatically
delivered to all machines on the network. Therefore, the broadcast address of a network
may be used as a low-level name for a group. In this case, the software of each machine
must check to see if the packet is intended for it. If not, the packet is simply discarded.
Since all machines receiveevery broadcast packetand mustcheck ifthe packet isintended
for it, the use of a broadcast address is lessefficient than the use of a multicast address for
group addressing. Also notice that in a system that uses a broadcast address for group
addressing, aUgroups have the same low-level name, the broadcast address.
If a network does not support either the facility to create multicast addresses or the
broadcasting facility, a one-to-one communication mechanism has to be used to
implement the group communication facility. That is, the kernel of the sending machine
sends the message packet separately to each machine that has a process belonging to the
group. Therefore, in this case, the low-level name of a group contains a list of machine
identifiers of an machines that have a process belonging to the group.
Notice that in the first two methods a single message packet is sent over the network,
whereas in the third method the number of packets sent over the network depends on the
number of machines that have one or more processes belonging to the group. Therefore
the third method generates more network traffic than the other two methods and is in
general less efficient. However, it is better than the broadcasting method in systems in
which most groups involve only a few out of many machines on the network. Moreover
the first two methods are suitable for use only on a single LAN. If the network contains
multiple LANs interconnected by gateways and the processes of a group are spread overmultiple LANs, the third method is simpler and easier to implement than the other two
methods.
Message Delivery to Receiver Processes
Userapplications use high-level group names in programs. The centralized group server
maintains a mapping of high-level group names to their low-level names. The group
server also maintains a list of the process identifiers of all the processes for each
group.
When a sender sends a message to a group specifying its high ..level name, the kernel
of the sending machinecontacts thegroup server toobtain the low-level name of thegroupSec. 3.10 • Group Communication 143
and the list of process identifiers of the processes belonging to the group. The list of
processidentifiers is inserted in the message packet. If the low-level group name is either
amulticast addressor abroadcast address, the kernel simply sends the packetto the
multicastlbroadcast address. On the other hand, if the low-level group name is a list of
machine identifiers, the kernel sends a copy of the packet separately to each machine in
the list.
When the packet reaches a machine, the kernel of that machine extracts the list of
processidentifiers from the packet and forwards the message in the packet to those
processes in the list that belong to its own machine. Note that when the broadcast address
is used as a low-level group name, the kernel of a machine may find that none of the
processes in the list belongs to its own machine. In this case, the kernel simply discards
the packet.
Notice that a sender is not at all aware of either the size of the group or the actual
mechanism used for group addressing. The sender simply sends a message to a group
specifying itshigh-level name, and the operating system takes the responsibility to deliver
the message to all the group members.
Buffered andUnbuffered Multicast
Multicasting is anasynchronous communication mechanism. This is because multicast
sendcannot be synchronous due to the following reasons [Gehani 1984]:
1. It isunrealistic to expect a sending process to wait until all the receiving processes
that belong to the multicast group are ready to receive the multicast message.
2. The sending process maynot be aware of all the receiving processes that belong
to themulticast group.
How amulticast message is treated on a receiving process side depends on whether
themulticast mechanism is buffered or unbuffered. For an unbuffered multicast, the
message is not buffered for the receiving process and is lost if the receiving process is not
in a state ready to receive it. Therefore, the message is received only bythoseprocesses
of themulticast group that are ready to receive it. On the other hand, for a buffered
multicast, the message is buffered for the receiving processes, so each process ofthe
multicast group will eventually receive the message.
Send-to-All andBulletin-Board Semantics
Ahamad and Bernstein [1985] described the following two types of semantics for one-to­
manycommunications:
1.Send-to-all semantics. A copy of the message is sent to each process of the
multicast group and the message is buffered until itis accepted by the process.
2.Bulletin-board semantics. A message to be multicast is addressed to a channel
instead of being sent to every individual process of the multicast group. From a logical144 Chap.3 •MessagePassing
pointofview, the channel plays the role of a bulletin board. A receiving process copies
the message from the channel instead of removing it when it makes a receiverequest on
the channel. Thus a multicast message remains available to other processes as if it has
been posted on the bulletin board. The processes that have receiveaccess right on the
channel constitute the multicast group.
Bulletin-board semantics is more flexible than send-to-all semantics because it takes
care of the following two factors that are ignored by send-to-all semantics [Ahamad and
Bernstein 1985]:
1. The relevance of a message to a particular receiver may depend on the receiver's
state.
2. Messages not accepted within a certain time after transmission may no longer be
useful; their value may depend on the sender'sstate.
To illustrate this, let us once again consider the example of a server manager
multicasting a message to all theserver processes to volunteer to serve thecurrent request.
Using send-to-all semantics, it would be necessary to multicast to all the servers, causing
many contractors to process extraneous messages. Using bulletin-board semantics, only
those contractors that are idle and in a state suitable for serving requests will make a
receiverequest on the concerned channel, and thus.only contractors in the correct state
will process such messages [Ahamad and Bernstein 1985]. Furthermore, the message is
withdrawn from the channel by the server manager as soon as the bid period is over; that
is, the first bidder is selected (in this case). Therefore, the message remains available for
being received only as long as the server manager is in a state in which bids are
acceptable. While this does not completely eliminate extraneous messages (contractors
may still reply after the bid period is over), it does help in reducing them.
Flexible Reliability in Multicast Communication
Different applications require different degrees of reliability. Therefore multicast
primitives normally provide the flexibility for user-definable reliability. Thus, the sender
of a multicast message can specify the number of receivers from which a response
message is expected. In one-to-many communication, thedegree of reliability is normally
expressed in the following forms:
1. TheO-reliable. No response is expected by the sender from any of the receivers.
This is useful for applications using asynchronous multicast in which the sender does not
wait for any response after multicasting the message. An example of this type of
application is a time signal generator.
2. Thel-reliable. The sender expects a response from any of the receivers. The
already described application in which a server manager multicasts a message to all the
servers to volunteer to serve the current request and selects the first server that responds
is an example of l-reliable multicast communication.Sec.3.10 • Group Communication 145
3. Them-out-of-n-reliable. The multicast group consists of nreceivers and the
sender expects a response from m(1<m <n) of thenreceivers. Majority consensus
algorithms (described in Chapter 9) used for the consistency control of replicated
information use this form of reliability, with the value m=n/2.
4. All-reliable. The sender expects a response message from all the receivers of the
multicast group. For example, suppose a message for updating the replicas of a file is
multicast to all the file servers having a replica of the file. Naturally, such a sender process
will expect a response from all the concerned file servers.
AtomicMulticast
Atomic multicast has an all-or-nothing property.That is, when a message is sent to a group
by atomic multicast, itiseither received by all theprocesses that are members ofthe group
or else it is not received by any of them. Animplicit assumption usually made in atomic
multicast is that when a process fails, it is no longer a member of the multicast group.
When the process comes up after failure, it must join the group afresh.
Atomic multicast is not always necessary. For example, applications for which the
degree of reliability requirement isO-reliable., l-reliable, orm-out-of-n-reliable do not
need atomic multicast facility. On the other hand, applications for which the degree of
reliability requirement is all-reliable need atomic multicast facility. Therefore, a flexible
message-passing system should support both atomic and nonatomic multicast facilities
and should provide the flexibility to the sender of a multicast message to specify in the
sendprimitive whether atomicity property is required or not for the message being
multicast.
A simple method to implement atomic multicast is to multicast a message, with the
degree of reliability requirement being all-reliable. In this case, the kernel of the sending
machine sends the message to all members of the group and waits for an acknowledgment
from each member (we assume that a one-to-one communication mechanism is used to
implement the multicast facility). After a timeout period, the kernel retransmits the
message to all those members from whom an acknowledgment message has not yet been
received. The timeout-based retransmission of the message is repeated until an
acknowledgment is received from all members of the group. When all acknowledgments
have been received, the kernel confirms to the sender that the atomic multicast process is
complete.
The above method works fine only as long as the machines of the sender process and
the receiver processes do not fail during an atomic multicast operation. This is because if
the machine of the sender process fails, the message cannot be retransmitted ifone or
more members did not receive the message due to packet loss or some other reason.
Similarly, if the machine of a receiver process fails and remains down for some time, the
message cannot be delivered to that process because retransmissions of the message
cannot be continued indefinitely and have to be aborted after some predetermined time.
Therefore, a fault-tolerant atomic multicast protocol must ensure that a multicast will be
delivered to all members of the multicast group even inthe event of failure of the sender's
machine or a receiver's machine. One method to implement such a protocol is described
next [Tanenbaum 1995}.146 Chap.3 •MessagePassing
In this method, each message has a message identifier field to distinguish it from all
other messages and a field to indicate that it is an atomic multicast message. The sender
sends the message to a multicast group. The kernel of the sending machine sends the
message to all members of the group and uses timeout-based retransmissions as in the
previous method. A process that receives the message checks its message identifier field
to see if it is a new message. If not, it is simply discarded. Otherwise, the receiver checks
to see.if it is an atomic multicast message. If so, the receiver also performs an atomic
multicast of the same message, sending it to the same multicast group. The kernel of this
machine treats this message as an ordinary atomic multicast message and uses timeout­
based retransmissions when needed. In this way, each receiver of an atomic multicast
message willperform an atomic multicast of the message tothe same multicast group. The
method ensures that eventually all the surviving processes of the multicast group will
receive the message even if the sender machine fails after sending the message or a
receivermachine fails after receiving the message.
Notice that an atomic multicast is in general veryexpensive as compared to a normal
multicast due to the large number of messages involved in its implementation. Therefore,
amessage-passing system should not use the atomicity property as a default property of
multicast messages but should provide this facility as an option.
GroupCommunication Primitives
In both one-to-one communication and one-to-many communication, the sender of a
process basically has to specify two parameters: destination address and a pointer to the
message data. Therefore ideally the same sendprimitive can be used for both one-to-one
communication and one-to-many communication. If the destination address specified in
thesendprimitive is that of a single process, the message is sent to that one process. On
the other hand, if the destination address is a group address, the message is sent to all
processes that belong to that group.
However, most systems having a group communication facility provide a different
primitive (such as sendgroup) for sending a message to a group. There are two main
reasons for this. First, it simplifies the design and implementation of a group
communication facility. For example, suppose the two-level naming mechanism is
used for both process addressing and group addressing. The high-level to low-level
name mapping for processes is done by the name server, and for groups it is done by
the group server. With this design, if a single sendprimitive is used for both one-to­
onecommunication and one-to-many communication, the kernel of the sending
machine cannot know whether the destination address specified by a user is a single
process address or a group address. Consequently, it does not know whether the name
server or the group server should be contacted for obtaining the low-level name of the
specified destination address. Implementation methods to solve this problem are
possible theoretically, but the design will become complicated. On the other hand, if
separate primitives such as sendandsendgroupare used, the kernel can easily make
out whether the specified destination address is a single process address or a group
address and can contact the appropriate server to obtain the corresponding low-level
name.Sec.3.10 • Group Communication 147
Second, it helps in providing greater flexibility to the users. For instance»a separate
parameter may be used in the sendgroupprimitive to allow users to specify the degree
of reliability desired(number of receivers from which a response message isexpected),
andanotherparameter may be used to specify whether the atomicity property isrequired
or not.
3.10.2Many-to-One Communication
In this scheme, multiple senders send messages to a single receiver. The single receiver
may beselective ornonselective. Aselective receiver specifies a unique sender; a message
exchange takes place only ifthat sender sends a message. On the other hand, a
nonselective receiverspecifies a set of senders, and ifanyonesender in the set sends a
message to this receiver, a message exchange takes place.
Thus we see that an important issue related to the many-to-one communication
scheme is nondeterminism. The receiver may want to wait for information from any ofa
groupofsenders, ratherthan from one specific sender. As itis not known in advance
which member (or members) of the group will have its information available first, such
behavior isnondeterministic. In some cases itis useful to dynamicalJy control the group
of senders from whom to accept message. For example, a buffer process may accept a
request from a producer process to store an item in the buffer whenever the buffer is not
full; it may accept a request from a consumer process to get an item from the buffer
whenever the buffer is not empty. To program such behavior, a notation is needed to
express and control nondeterminism. One such construct is the"guarded command"
statement introduced by Dijkstra l19751.Since this issue is related to programming
languages rather than operating systems, we will not discuss it any further.
3.10.3Many-to-Many Communication
In this scheme, multiple senders send messages to multiple receivers. The one-to-many
andmany-to-one schemes are implicit in this scheme. Hence the issues related to one-to­
many and many-to-one schemes, which have already been described above, also apply to
themany-to-many communication scheme. In addition, an important issue related to
many-to-many communication scheme is that of ordered message delivery.
Ordered message delivery ensures that all messages are delivered to all receivers in
an order acceptable to the application. This property is needed by many applications for
theircorrectfunctioning. For example, suppose two senders send messages to update the
same record of a database to two server processes having a replica of the database. If the
messages of the two senders are received by the two servers in different orders, then the
final values of the updatedrecord of the database may be different in its two replicas.
Therefore, thisapplication requires that all messages be delivered in the same order to all
receivers.
Ordered message delivery requires message sequencing. In a system with a single
senderand multiple receivers (one-to-many communication), sequencing messages to all
thereceivers is trivial. If the sender initiates the next multicast transmission only after
confirming that the previous multicast message has been received by all the members, the148 Chap.3 • MessagePassing
messages winbedelivered in the same order. On the other hand. in a system with multiple
senders and a single receiver (many-to-one communication), the messages will be
delivered to the receiver in the order in which they arrive at the receiver's machine.
Ordering in this case is simply handled by the receiver. Thus we see that it is not difficult
to ensure ordered delivery of messages in many-to-one 'or one-to-many communication
schemes.
However, in many-to-many communication, a message sent from a sender may
arrive at a receiver's destination before the arrival of a message from another sender;
but this order may be reversed at another receiver's destination (see Fig. 3.14). The
reason why messages of different senders may arrive at the machines of different
receivers in different orders is that when two processes are contending for access to a
LAN, the order in which messages of the two processes are sent over the LAN is
nondeterministic. Moreover, in a WAN environment, the messages of different senders
may be routed to the same destination using different routes that take different amounts
of time (which cannot be correctly predicted) to the destination. Therefore, ensuring
ordered message delivery requires a special message-handling mechanism in many-to­
manycommunication scheme.
The commonly used semantics for ordered delivery of multicast messages are
absolute ordering, consistent ordering, and causal ordering. These are described
below.
Time
1
Fig. 3.14 No ordering constraint for
message delivery.
Absolute Ordering
This semantics ensures thatall messages aredelivered toallreceiver processes intheexact
order in which they were sent (see Fig. 3.15). One method to implement this semantics is
to use global timestamps as message identifiers. That is, the system is assumed to have a
clock at each machine and all clocks are synchronized with each other, and when a sender
sends a message, the clock value(timestamp) istaken as the identifier of that message and
embedded in the message.
The kernel of each receiver's machine saves all incoming messages meant for a
receiver in a separate queue. A sliding-window mechanism is used to periodicallySec.3.10 • Group Communication
Time
1t1<~149
Fig.3.]5 Absoluteorderingof messages.
deliver the message from the queue to the receiver. That is, a fixed time interval is
selected as the window size, and periodically all messages whose timestamp values
fall within the current window are delivered to the receiver. Messages whose
timestamp values fall outside the window are left in the queue because of the
possibility that a tardy message having a timestamp value lower than that of any of
the messages in the queue might still arrive. The window size is properly chosen
taking into consideration the maximum possible time that may be required by a
message to go from one machine to any other machine in the network.
Consistent Ordering
Absolute-ordering semantics requires globally synchronized clocks, which are not easy
to implement. Moreover, absolute ordering is not really what many applications need
to function correctly. For instance, in the replicated database updation example, it is
sufficient to ensure that both servers receive the update messages of the two senders
in the same order even ifthis order is not the real order in which the two messages
were sent. Therefore, instead of supporting absolute-ordering semantics, most systems
supportconsistent-ordering semantics. This semantics ensures that all messages are
delivered to all receiver processes in the same order. However, this order may be
different from the order in which messages were sent (see Fig. 3.16).
One method to implement consistent-ordering semantics is to make the many-to­
many scheme appear as a combination of many-to-one and one-to-many schemes
[Chang and Maxemchuk 1985]. That is, the kernels of the sending machines send
messages to a single receiver (known as a sequencer) that assigns a sequence number
to each message and then multicasts it.The kernel of each receiver's machine saves
all incoming messages meant for a receiver in a separate queue. Messages in a queue
are delivered immediately to the receiver unless there is a gap in the message
identifiers, in which case messages after the gap are not delivered until the ones in thegap have arrived.150 Chap.3 •MessagePassing
Time1tl<~
Fig.3.16 Consistent ordering of messages.
Thesequencer-based method forimplementing consistent-ordering semantics is
subjecttosinglepointoffailureandhencehaspoorreliability. A distributed algorithm for
implementing consistent-ordering semantics that does not suffer from this problem is the
ABCAST protocol ofthe ISIS system[Birman and Van Renesse 1994,Birman1993,
Birmanet al.1991,BirmanandJoseph1987].Itassignsasequence numberto amessage
bydistributed agreement amongthegroupmembers and the senderand works as
follows:
1.Thesenderassignsatemporary sequence numberto themessage andsendsit
to all the members ofthemulticast group.Thesequence number assigned by the
sendermust be largerthan any previous sequence number used by the sender.
Therefore, asimplecountercan be used by the sendertoassignsequence numbers to
itsmessages.
2. Onreceiving themessage, eachmember ofthegroupreturnsaproposed
sequence numberto the sender. Amember(i)calculates itsproposed sequencenumber
byusingthefunction
max(Fmax'Pmax)+1+ilN
whereFmaxis thelargestfinalsequence numberagreedupon so far for a message received
by thegroup(eachmembermakesarecordofthis when a final sequence numberisagreed
upon),Pmaxis thelargestproposed sequence numberby thismember, andNis the total
numberofmembers in themulticast group.
3.Whenthesenderhasreceived theproposed sequence numbers from all the
members, itselectsthelargestone as the final sequence numberfor themessage and sends
it to allmembers in acommitmessage. Thechosenfinalsequence numberisguaranteed
to beuniquebecauseofthe termUNin thefunction used for the calculation ofaproposed
sequence number.
4. Onreceiving thecommitmessage, eachmember attaches the final sequence
numberto themessage.Sec. 3.10 • Group Communication 151
5.Committed messages with final sequence numbers are delivered to the application
programs in order of their final sequence numbers. Note that the algorithm for sequence
number assignment to a message is a part of the runtime system, not the user
processes.
It can be shown that this protocol ensures consistent ordering semantics.
CausalOrdering
For some applications consistent-ordering semantics is not necessary and even weaker
semantics is acceptable. Therefore, an application can have better performance if the
message-passing system used supports a weaker ordering semantics that is acceptable to
the application. .One such weaker ordering semantics that is acceptable to many
applications is the causal-ordering semantics. This semantics ensures that ifthe event of
sending one message is causally related to the event of sending another message, the twomessages are delivered to all receivers in the correct order. However, if two message­
sending events are not causally related, the two messages may be delivered to the
receivers in any order. Two message-sending events are said to becausally related if they
arecorelated by the
happened-before relation (for adefinition of happened-before relation
seeChapter6). That is, two message-sending events are causally related if there is any
possibility of the second one being influenced in any way bythe first one. The basic idea
behindcausal-ordering semantics is that when it matters, messages are always delivered
in the proper order, but when it does not matter, they may be delivered in any arbitrary
order.
An example of causal ordering of messages is given in Figure 3.17. In this example,
senderSIsends message mJ to receivers R], R2,andR3and sender S2sends message m2
to receivers R2,andR3.On receiving nu ,receiverR]inspects it, creates a new message
ms,and sends m-;toR2andR3.Note that the event of sending m3is causally related to
the event of sending m,because the contents of m-;might have been derived in part from
ml;hence the two messages must be delivered to both R2andR3in the proper order, m,
Time
1
F'ig.3.17 Causal ordering of messages.152 Chap.3 •MessagePassing
beforem3'Also note that since m2is not causally related to either m,orm3' m2can be
delivered at any time to R2andR3irrespective of m,orm-,This is exactly what the
exampleofFigure 3.17 shows.
One method for implementing causal-ordering semantics is the CBCASTprotocol of
the ISIS system [Birman et al. 1991]. It works as follows:
1. Each member process of a group maintains a vector of ncomponents, where nis
the total number of members in the group. Each member is assigned a sequence number
from 0 to n,and theithcomponent of the vectors corresponds to the member with
sequence number i.In particular, the value of the ithcomponent of a member's vector is
equal to the number of the last message received in sequence by this member from
memberi.
2. To send a message, a process increments the value of its own component in its
own vector and sends the vector as part of the message.
3. When the message arrives at a receiver process's site,it isbuffered bytheruntime
system. The runtime system tests the two conditions given below to decide whether the
message can be delivered to the user process or its delivery must be delayed to ensure
causaJ. ..ordering semantics. Let Sbe the vectorof the sender process that is attached to the
message and Rbethe vector of the receiver process. Also let ibe the sequence numberof
the sender process. Then the two conditions to be tested are
S[i]=R[i]+1 andSUl::;RUJfor allj~i
The first condition ensures that the receiver has not missed any message from the
sender. This test is needed because two messages from the same sender are always
causally related. The second condition ensures that the sender has not received any
message that the receiver has not yet received. This test is needed to make sure that the
sender'smessage is not causally related to a message missed by the receiver.
If the message passes these two tests, the runtime system delivers it to the user
process. Otherwise, the message is left in the buffer and the test is carried out again for
it when a new message arrives.
A simple example to illustrate the algorithm is given in Figure 3.18. In this
example, there'are four processes A, B,C, andD.The status of their vectors at some
instance of time is (3, 2, 5, I), (3, 2, 5, 1), (2, 2, 5, 1), and (3, 2, 4, 1), respectively.
This means that, until now, Ahas sent three messages, Bhas sent two messages, C
has sent five messages, and Dhas sent one message to other processes. Now Asends
a new message to other processes. Therefore, the vector attached to the message will
be (4, 2, 5, 1). The message can be delivered to Bbecause it passes both tests.
However, the message has to be delayed by the runtime systems of sites of processes
C andDbecause the first test fails at the site of process C and the second test fails
at the site of process D.
A good message-passing system should support at least consistent- and causal­
ordering semantics and should provide the flexibility to the users to choose one of these
in their applications.Sec.3.11• CaseStudy:4.3BSDUNIXIPCMechanism
Statusofvectorsatsomeinstanceoftime
I
Vectorof Vectorof Vectorof : Vectorof
processAIprocessBprocessC:processD~l~ [iliIili]:~
I
I
ProcessAsendsanew :
messagetootherprocesses:
CiliTI:E!M=gel!
I
I
I-----_:~ Deliver
I
I
:Delay
:becausethe
:condition
I
:A[1]=C[1]+1
Idoesnothold
I
I
I
I
I
I
I
I
I
I
Fig. 3.18 An example toillustrate theCBCAST protocol for implementing causal
ordering semantics.
3.11CASESTUDY:4.38SDUNIXIPCMECHANISM153
The socket-based IPC of the 4.3BSD UNIX system illustrates how a message-passing
systemcanbedesignedusing theconceptsandmechanismspresentedinthischapter.The
system was produced by the Computer Systems Research Group (CSRG) of the
Universityof California at Berkeley and is the most widely used and well documented
message-passingsystem.
3.11.1 8aslc Concepts andMainFeatures
TheIPemechanism of the 4.3BSD UNIX provides a general interface for constructing
network-based applications. Its basic concepts and main features are as follows:
1. Itisnetworkindependentinthesensethatitcansupportcommunicationnetworks
that usedifferentsetsof protocols,differentnamingconventions,differenthardware,and
soon.Forthis,it usesthenotionof communication domain,whichreferstoastandardset
ofcommunicationproperties.Inthischapterwehaveseenthattherearedifferentmethods
of namingacommunicationendpoint.Wealsohaveseenthattherearedifferentsemantics
of communication related to synchronization, reliability, ordering, and so on. Different
networks often use different naming conventions for naming communicationendpoints154 Chap.3 •MessagePassing
and possess different semantics of communication. These properties of a network are
known as its communication properties. Networks with the same communication
properties belong toacommon communication domain (orprotocol family). By providing
the flexibility to specify a communication domain as a parameter of thecommunication
primitive used, the IPC mechanism of the4.3B5DUNIX allows the users to select a
domainappropriate to their applications.
2. Ituses aunified abstraction, called socket,foranendpoint of communication. That
is, a socket is an abstract object from which messages are sent and received. The IPC
operations are based on socket pairs, one belonging to each of a pair ofcommunicating
processes that may beonthesame ordifferent computers. Apairof sockets may beused for
unidirectional orbidirectional communication between two processes. A message sentby a
sending process isqueuedinitssocket untilithasbeentransmitted across thenetwork bythe
networking protocol and an acknowledgment has been received (only if the protocol
requires one). On thereceiver side, the message isqueued in the receiving process's socket
until the receiving process makes an appropriate system call toreceive it.
Any process can create a socket for use in communication with another process.
Sockets are created within a communication domain. A created socket exists until it is
explicitly closed or until every process having a reference to it exits.
3. For location transparency, it uses a two-level naming scheme for naming
communication endpoints. That is, a socket can be assigned a high-level name that is a
human-readable string. The low-level name of a socket is communication-domain
dependent. For example, it may consist of a local port number and an Internet address. For
translation ofhigh-level socket names to their low-level names, 4.3B50 provides
functions for application programs rather than placing the translation functions in the
kernel. Note that a socket'shigh-level name is meaningful only within the context of the
communication domain in which the socket is created.
4. It is highly flexible in the sense that it uses a typing mechanism for sockets to
provide the semantic aspects of communication toapplications ina controlled and uniform
manner. That is, all sockets are typed according to theircommunication semantics, such
as ordered delivery, unduplicated delivery, reliable delivery, connectionless communica­
tion,connection-oriented communication, and so on. The system defines some standard
socket types and provides the flexibility to the users to define and use their own socket
types when needed. For example, a socket oftypedatagram modelspotentially unreliable,
connectionless packetcommunication, and a socket of type streammodels a reliable
connection-based byte stream.
5. Messages can be broadcast if the underlying network provides broadcast
facility.
3.11.2 TM IPCPrlmltlv.s
Theprimitives of the 4.3BSD UNIXIPC mechanism are provided as system calls
implemented as a layer on top of network communication protocols such as TCP, UDP,
and so on. Layering the IPC mechanism directly on top of network communicationSec.3.11• CaseStudy:4.3BSDUNIX IPeMechanism 155
protocols helps in making it efficient. The most important available IPC primitives are
brieflydescribed below.
s=socket(domain, type, protocol)
When a process wants to communicate with another process, it must first create a socket
by using the socketsystem call. The first parameter of this call specifies the
communication domain. The most commonly used domain is the Internet communication
domain because a large number of hosts in the world support the Internet communication
protocols. The second parameter specifies the socket type that is selected according to the
communication semantics requirements of the application. The third parameter specifies
thecommunication protocol (e.g., TCP/IPor UDPIIP) to be used for the socket's
operation. If the value of this parameter is specified as zero, the system chooses an
appropriate protocol. The socketcall returns a descriptor by which the socket may be
referenced in subsequent system calls. Acreated socket is discarded with the normal close
system call.
bind (s,addr,addrlen)
After creating a socket, the receiver must bind it to a socket address. Note that if two-way
communication is desired between two processes, both processes have to receive
messages, and hence both must separately bind their sockets to a socket address. The bind
system call is used for this purpose. The three parameters of this call are the descriptor of
the created socket, a reference to a structure containing the socket address to which the
socket is to be bound, and the number of bytes in the socket address. Once a socket has
been bound, its address cannot be changed.
It might seem more reasonable to combine the system calls for socket creation and
binding a socket to a socket address (name) in a single system call. There are two main
reasons for separating these two operations in different system calls. First, with this
approach a socket can be useful without names. Forcing users to name every socket that
is created causes extra burden on users and maylead to the assignment of meaningless
names. Second, some communication domains might require additional, nonstandard
information (such as type of service) for binding ofa name toa socket. The need to supply
this information at socket creation time will further complicate the interface.
connect(s,server_addr,server_addrlen)
The two most commonly used communication types in the 4.3BSDUNIXIPC mechanism
areconnection-based (stream) communication andconnectionless (datagram) commu­
nication. In connection-based communication, two processes first establish a connection
between their pairs of sockets. The connection establishment process is asymmetric
because one of the processes keeps waiting for a request for a connection and the other
makes a request for a connection. Onceconnection has been established, data can be
transmitted between the two processes in either direction. This type of communication is
useful for implementing client-server applications. Aserver creates a socket, binds a name156 Chap.3 •MessagePassing
to it, and makes the name publicly known. It then waits for a connection request from
client processes. Clients send connection requests to the server. Once the connection is
established, they can exchange request and reply messages. Connection-based commu­
nication supports reliable exchange of messages.
In connectionless communication, a socket pair is identified each time a
communication is made. For this, the sending process specifies its local socket descriptor
and the socket address of the receiving process's socket each time it sends a message.
Connectionless communication is potentially unreliable.
Theconnectsystem call is used in connection-based communication by a client
process torequest aconnectionestablishment betweenitsownsocket and thesocketofthe
server process with which it wants to communicate. The three parameters ofthis call are
thedescriptor oftheclient's socket,areference toastructurecontaining thesocket address
of theserver'ssocket, and the number of bytes in the socket address. The connectcall
automatically binds a socket address (name) to the client'ssocket. Hence prior binding is
not needed.
listen (s, backlog)
Thelistensystem call is used in case of connection-based communication by a server
process to listen on its socket for client requests for connections. The two parameters of
this call are the descriptor of the server'ssocket and the maximum number ofpending
connections that should be queued for acceptance.
snew=accept(s,client_addr, client_addrlen)
Theacceptsystem can is used in a connection-based communication by a server process
to accept a request for a connection establishment made by a client and to obtain a new
socket for communication with that client. The three parameters of this call are the
descriptor of the server'ssocket, a reference to a structure containing the socket address
of theclient'ssocket, and the number of bytes in the socket address. Note that the call
returns a descriptor (snew)that is the descriptor of a new socket that is automatically
created upon execution of the acceptcall. This new socket is paired with the client's
socket so that the server can continue to use the original socket with descriptor sfor
accepting further connection requests from other clients.
Primitives for Sending and Receiving Data
A variety of system calls are available for sending and receiving data. The four most
commonly used are:
nbytes=read(sneMl,buffer, amount)
write(s,"message," msg_length)
amount=recvfrom (s, buffer, sender_address)
sendtots, "message," receiver_address)Sec.3.12•Summary 157
Thereadandwritesystem calls are most suitable for use in connection-based
communication. Thewriteoperation is used bya client to send a message to a server.The
socket to be used for sending the message, the message, and the length of the message are
specified as parameters to the call. The readoperation is used by the server process to
receive the message sent by the client. The socket of the server to which the client'ssocket
isconnected and the buffer for storing the received message are specified as parameters
to the call. The call returns the actual number of characters received. The socket
connection establishment between the client and the server behaves like a channel of
stream data that does not contain any message boundary indications. That is, the sender
pumps data into the channel and the receiver reads them in the same sequence as written
by thecorresponding write operations. The channel size is limited by a bounded queue at
the receiving socket. The sender blocks if the queue is full and the receiver blocks if the
queue is empty.
On the other hand, the recvfrom andsendtosystem calls are most suitable for use in
case ofconnectionless communication. Thesendtooperation is used by a sender to send
a message to a particular receiver. The socket through which the message is to besent, the
message, and a reference to a structure containing the socket address of the receiver to
which the message is to be sent are specified as parameters to this call. The reevfrom
operation is used by a receiver to receive a message from a particular sender. The socket
through which the message is to be received, the buffer where the message is to be stored,
and a reference to a structure containing the socket address of the sender from which the
message is to be received are specified as parameters to this call. The recvfrom call
collects the first message in the queue at the socket. However, ifthe queue is empty, it
blocks until a message arrives.
Figure 3.19 illustrates the use of sockets for connectionless communication between
two processes. In the socketcall, the specification ofAF_INET as the first parameter
indicates that the communication domain is the Internet communication domain, and the
specification of SOCK_DGRAM as the second parameter indicates that the socket isof the
datagram type (used for unreliable, connectionless communication).
Alternatively, Figure 3.20 illustrates the use of sockets for connection-based
communication between aclient process and a server process. The specification of SOCK_
STREAM as the second parameter of thesocketcall indicates that the socket is of the
stream type (used for reliable, connection-based communication).
3.12SUMMARY
Interprocess communication (IPC) requires information sharing among two or more
processes. The two basic methods for information sharing are original sharing (shared­
data approach) and copy sharing (message-passing approach). Since computers in a
network do not share memory, the message-passing approach is most commonly used in
distributed systems.
Amessage-passing system is a subsystem of a distributed operating system that
provides a set of message-based protocols, and it does so by shielding the details of
complex network protocols and multiple heterogeneous platforms from programmers,158 Chap.3 •MessagePassing
s=socket(AF_'NET, SOCK_DGRAM, 0);
bind(s,sender_address, server_address_length);
sendto(s,"message", receiver_address);
close(s);
(a)
s=socket(AF _INET,SOCK_DGRAM, 0);
bind(s,receiver_address, receiver_address_length)
amount=recvfrom(s,buffer,sender_address);
close(8);
(b)Fig. 3.19 Use of sockets for connectionless
communication between two
processes. (a)Socket-related
system calls in sender'sprogram.
(b)Socket-related system calls in
receiver's program.
Someofthe desirable features of a good message-passing system are simplicity,
uniform semantics, efficiency, reliability, correctness, flexibility, security, and port­
ability.
The sender and receiver of a message may communicate either in the synchronous or
asynchronous mode. As compared to the synchronous mode of communication, the
asynchronous mode provides better concurrency, reduced message traffic, and better
flexibility. However, the asynchronous communication mode is more complicated to
implement, needs message buffering, and requires programmers to deviate from the
traditional centralized programming paradigm.
The four types of buffering strategies that may be used in the design of IPC
mechanisms are a null buffer, or no buffering; a simple-message buffer; an unbounded­
capacity buffer; and a finite-bound, or multiple-message, buffer.
Messages are transmitted over a transmission channel in the form of packets.
Therefore, for transmitting a message that is greater than the maximum size of a packet,
the logical message has to be separated (disassembled) and transmitted in multiple
packets. Such a message is called a multipacket or a multidatagram message.
Encoding is the process of converting the program objects of a message to a
stream form that is suitable for transmission over a transmission channel. This process
takes place on the sender side of the message. The reverse process of reconstructing
program objects from message data on the receiver side is known as decoding of the
message data.Sec.3.12 •Summary
Fig. 3.20 Use of sockets for
connection-based communication
between a client and a server.
(a)Socket-related system calls in
client'sprogram. (b)Socket-related
system calls in server'sprogram.159
5=socket(AF_INET,SOCK_STREAM, 0);
connect(s, server_address, server_address_length);
write(s,"message", mSQ_length);
close(s):
(a)
s=socket(AF_INET,SOCK __STREAM,0);
bind(5,server_address, server_address_length);
listen(s,backlog);
snew=accept(s, client_address, client_address_length);
nbytes=read(snew,buffer, amount);
close(snew);
close(s);
(b)
Another major issue in message passing is addressing (or naming) ofthe parties
involved inan interaction. Aprocess mayormay notexplicitly name aprocess with which
it wants to communicate depending uponwhetherit wants to communicate only with a
specific process or with any process of a particular type. An important goal in process
addressing is to provide location transparency. The most commonly used method to
achieve this goal is to usc a two-level naming schemeforprocesses and a name server to
map high-level, machine-independent process names to their low-level, machine­
dependent names.
Failurehandling is another important issue in the design of an IPemechanism. The
two commonly used methods in the design ofa reliableIPeprotocolare the use ofinternal
retransmissions based on timeouts and the use of explicit acknowledgment packets. Two
important issues related to failure handling in IPC mechanisms areidempotency and
handling of duplicate request messages and keeping track of lost and out-of-sequence
packets in multidatagram messages.
The most elementary form ofmessage-based interaction isone-to-one communication
in which a single sending process sends a message to a single receiving process. However,
for better performance and flexibility, several distributed systems provide group com-160 Chap. 3 • Message Passing
munication facilitiesthatmayallow one-to-many, many-to-one, andmany-to-many typesof
interactions betweenthesendersandreceivers. Someissuesrelatedtogroup communica­
tionaregroup management, groupaddressing, atomicity, andordered messagedelivery.
EXERCISES
3.1. What are the.main reliability issues in designing a message-passing system? Describe a
suitable mechanism for handling each of these issues.
3.2.What are the main issues related to the correctness of the IPC protocols of a message-passing
system? Describe a suitable mechanism for handling each of these issues.
3.3. Describe some flexibility features that a message-passing system should provide to its users.
Write suitable IPC primitives that will allow the users to take advantage of these flexibility
features.
3.4.Describe blocking and nonblocking types of fPC.Which is easier to implement and why?
Discuss their relative advantages and disadvantages.
3.5. Write the code for implementing aproducer-consumer pair of processes for the following two
cases:
(a) They use a single-message buffer.
(b) They use a buffer that can accommodate up to nmessages.
The producer produces messages and puts them in the message buffer, and the consumer
consumes messages from the message buffer.Assume that all messages are of fixed size.
3.6.What isadatagram?Whyaremultidatagram messages usedinIPC?Whatarethemainissuesin
IPCofmultidatagram messages? Describe amechanism forhandling each of these issues.
3.7. In a multidatagram communication, explain how the recipient can properly recognize and
arrange the datagrams of the same message and how can it recognize the Jastdatagram of a
message.
3.8. A linked list ofcharacters isto be sent across a network in the form of a stream of bytes. Write
the code in any suitable programming language for encoding the data structure on the sender
side and decoding it on the receiver side.
3.9. Write the code for implementing the bulletin-board semantics for one-to-many communica­
tion for the following cases:
(a) A message posted on the bulletin board is automatically removed after nreceivers have
read it.
(b) A message posted on the bulletin board is automatically removed after the lapse of time
t.Timetis a parameter specified by the sender of a message.
Assume that only one message can beposted on the bulletin board at a time. If the bulletin
board is not empty at the time a sender wants to post a message, a "not empty, try again"
message is returned to the sender. You may make any other assumptions that you feel
necessary, but clearly state your assumptions.
3.10. Give two examples of applications for which each of the following types of multicast
communication is most suitable:
(a) The O-reliable
(b) Thel-reliable
(c) The m-out-of-n reliable (1 <m<n)
(d) All-reliableChap. 3 • Exercises 161
3.11.What is meant by"ordered message delivery"? Do allapplications need the same semantics
for this property? If yes, explain why. If no, give examples of two applications that need
different semantics for this property.
3.12. Explain what is meant by absolute ordering, consistent ordering, and causal ordering of
messages. Give a mechanism to implement each one.
3.13.Describe a mechanism forimplementing consistent ordering of messages in each of the
following cases:
(a)One-to-many communication
(b)Many-to-one communication
(c)Many-to-many communication
3.14.Describe three different process-addressing mechanisms. Discuss their relative advantages
and disadvantages. Which of the mechanisms described by you is most suitable for each of the
following cases (give reasons for your answer):
(a) Forcommunication between a server process and several client processes. The client
processes send request messages to the server process and the server process returns a
reply for each client request.
(b) For allowing a sender process to send messages to a group of processes.
(c) For allowing a sender process to send messages to a receiver process that is allowed to
migrate from one node to another.
(d) For allowing a sender process to send messages to a receiver process that is allowed to
migrate from one node to another and to allow the receiver process to return areply to the
sender process.
(e) For allowing a client process to receive service from anyone of the several server
processes providing that service.
3.15.What is an idempotent operation? Which of the following operations are idempotent:
(a)read_next_record (filename)
(b)readrecord (filename, recordnumber)
(c)append_record (filename, record)
(d)writerecord (filename, after_record_n, record)
(e)seek(filename, position)
(f)add(integer_I, integer_2)
(g)increment (variable_name)
3.16.Suggest a suitable mechanism for implementing each of the following types of IPe
semantics:
(a) Last one
(b) At least once(c) Exactly once
3.17.Theoperations performed by a server are nonidempotent. Describe a mechanism for
implementing exactly-once IPesemantics in this case.
3.18.Suggest whether at-least-once or exactly-once semantics should be used for each of the
following applications (give reasons for your answer):
(a) For making a request to a file server to read a file
(b) For making a request to a file server to append some data to an existing file
(c) For making a request to a compilation server to compile a file
(d) For making a request to a database server to update a bank account
(e) For making a request to a database server to get the current balance of a bank account
(f)For making a request to a booking server to cancel an already booked seat162 Chap. 3 • Message Passing
3.19.Suggestasuitablemechanismfor implementingreliable IPCwithexactly-oncesemanticsin
each of the followingcases:
(a) The computersof the sender and receiver processesare reliable but the communication
links connectingthem are unreliable.
(b)Thecomputersof thesenderandreceiverprocessesareunreliablebutthecommunication
links connectingthem are reliable.
(c) The computer of the sender process and the communication links connecting the
computers of the sender and receiver processes are reliable but the computer of the
receiver processis unreliable.
(d)The computer of the receiver process and the communication links connecting the
computersofthesenderandreceiverprocessesarereliablebutthecomputerof thesender
process is unreliable.
3.20.Is it always necessaryforthe senderof a messageto knowthat the messagearrivedsafelyat
its destination? If yes, explain why.If no, give twoexamplesin support of your answer.
3.21.What is the main purpose of using an acknowledgmentmessage in an IPC protocol? Are
acknowledgmentmessagesalwaysneededforreliablecommunication?Givereasonsforyour
answer.
3.22.What is "piggybacking"of a message? How does ithelp in reducing network traffic?Give
some examplesof wherethe piggybackingscheme may be used to improve performancein
distributed systems.
3.23.Inmanyclient-serversystems,thetimeoutmechanismisusedtoguardagainstthehangingof
a client forever if the server crashes. That is, in these systems, if after sending a request
message to a server a client does not receive a replyfrom the server within a fixed timeout
interval, the client assumes that the server has crashed and can take necessary corrective
actions. What should be the ideal length ofthe timeout period in these systems? If the server
computer is fully reliable, is it still useful to use the timeout mechanism?Give reasons for
your answer.
3.24. A file server services file read/write requests of multiple clients. Clients can directly
communicate with the file server by sending messages to it and receiving messages from
it.
(a) Describethecontentsof themessagethata clientmustsendto the fileserverforreading
a portion of a file.
(b) Describethe contentsof the messagethat the server must returnto theclient in reply to
part(a).
(c) Describethecontents ofthemessagethata client mustsendto the fileserver for writing
some data to an existingfile.
(d)Describe thecontentsof the messagethat the server mustreturnto the client in reply to
part (c).
(e) Describe a mechanism by which the file server can cope with multiple client requests
arriving almost simultaneously.
3.25.In a client-serverIPC,a client sendsa request messageto a server,and the server processes
the request and returns the result of the request processing to the client. Is it useful for a
process to behave bothas a client and a server?If no, explain why.If yes, give an example
in support of your answer.
3.26. Afile storageandretrievalsystemconsistsof thefollowingtypesofprocesses:severalclient
processes, a file manager process, a cache manager process, and several disk manager
processes.These processesperform the followingjobs:Chap. 3 • Bibliography 163
(a)Aclientprocesssendsfileaccessrequests tothefilemanager process.
(b) The file manager process, onreceivingaclientrequest, sendstherequestto thecache
manager.
(c) If the data is available in thecache,thecachemanager extractsthedatafrom the cache
andsendsit in a reply message to the file manager. Otherwise, thecachemanager sends
arequestfor thedatato all the diskmanagers.
(d) Onreceiving arequestfrom the cachemanager, a diskmanager searches for thedatain
its own disk and returnsasuitablereplyto thecachemanager. Thatis, if the datais not
found, a "notfound"message isreturned; otherwise therequested data isreturned in a
message.
(e) Upon receiptofthe data, the cachemanager cachesthedatain thecacheand also sends
it to the file manager.
(0The file manager performs therequested operation on the data and finally returnsa
suitablereply to the clientprocess.
WhatformofIPC do the different typesofprocesses ofthisapplication use forinteraction
amongthem?WriteproperIPCprimitives todefinetheinterface between theseprocesses.
3.27.Write the skeleton oftheprocesses ofthe filestorageandretrieval systemofExercise 3.26
using the primitives ofthe4.3BSDUNIX IPC mechanism to show how they will
communicate witheachother. Use connection-based communication.
BIBLIOGRAPHY
[Ahamad and Bernstein 1985]Ahamad,M.,andBernstein, A. J.,"AnApplication ofNameBased
Addressing to LowLevelDistributed Algorithms," IEEE Transactions on Software Engineering,
Vol.SE-l1,No.1,pp.59-67(1985).
[Andrews 1991]Andrews, G.,"Paradigms forProcessInteraction inDistributed Programs," ACM
Computing Surveys, Vol. 23, No. r,pp.49-90(1991).
[Artsyetale1987]Artsy,Y.,Chang,H.,andFinkel,R.,"Interprocess Communication inCharlotte,"
IEEE Software, pp. 22--28 (1987).
[Bal and Tanenbaum 1989]Bal,H. E.,andTanenbaum, A. S.,"Programming Languages for
Distributed Computing Systems," ACMComputing Surveys, Vol. 21, No.3,pp.261-322
(1989).
[Birman 1993]Birman,K. P.,"TheProcessGroupApproach toReliable Distributed Computing,"
Communications ofthe ACM, Vol. 36, pp. 36-53(1993).
[Birman andJoseph1987]Birman, K. P., and Joseph,T. A.,"Reliable Communication in the
Presence ofFailures," ACMTransactions on Computer Systems, Vol. 5,No.1,pp.47-76
(1987).
[Birman and Van Renesse 1994]Birman, K. P., and Van Renesse, R.,Reliable Distributed
Computing with the ISIS Toolkit, IEEEComputer SocietyPress,LosAlamitos, CA(1994).
[Birman etale 1991] Birman, K. P.,Schiper, A., and Stephenson, P.,"Lightweight Causaland
AtomicGroupMulticast," ACM Transactions on Computer Systems, Vol. 9,No.3,pp.272-314
(1991).
[CCITT1985]Recommendation X.409:Presentation Transfer SyntaxandNotation. RedBook,Vol.
VIII,International Telecommunications Union,Geneva, Switzerland (1985).164 Chap.3 • MessagePassing
[Changand Maxemehuk 1984] Chang, J. M.,andMaxemchuk, N.F.,"Reliable Broadcast
Protocols," ACM Transactions on Computer Systems, Vol. 2, pp. 39-59(1984).
[ChangandMaxemchuk 1985] Chang,J.M.,andMaxemchuk, N.F.,"ABroadcast Protocol for
Broadcast Networks," ACM Transactionson Computer Systems, Vol. 3,No.1(1985).
[Dijkstra 1975] Dijkstra, E. W., "Guarded Commands, Nondeterminacy, and Formal Derivation of
Programs," Communications ofthe ACM, Vol.18,No.8,pp.453-457 (1975).
[Draves1990]Draves,R. P.,"The RevisedIPCInterface," In:Proceedings oftheFirstUSENIX
Mach Symposium, USENIX, Berkeley, CA, pp. 101-121, (1990).
[Ezhilcbelvan et al, 1995] Ezhilchelvan, P.D.,Macedo, R. A.,andShrivastava, S.K.,"Newtop: A
Fault-Tolerant GroupCommunication Protocol," In:Proceedings ofthe 15th International
Conference on Distributed Computing Systems, IEEE (1995).
[Fitzgerald and Rashid 1986]Fitzgerald, R., and Rashid, R. F.,"TheIntegration of Virtual
Memory Management andInterprocess Communication inAccent," ACM Transactions on
Computer Systems, Vol.4,No.2,pp.147-177 (1986).
[Franketal, 1985] Frank, A. J., Wittie, L. D.,andBernstein, A. J.,"Multicast Communication on
Network Computers," IEEESoftware, Vol.2,No.3,pp.49-61(1985).
[Gammage and Casey1985]Gammage, N., and Casey, L., "XMS: A Rendezvous Based
Distributed System Software Architecture," IEEE Software, Vol. 2,No.3, pp.9-19
(1985).
[Gammage et al. 1987] Gammage, N. D.,Kamel, R. F.,and Casey, L.,"Remote Rendezvous,"
Software-Practice and Experience, Vol. 17, No. 10,pp.741-755 (1987).
[Garcia-Molina andSpauster 1991]Garcia-Molina, H.,and Spauster, A.,"Ordered andReliable
Multicast Communication," ACMTransactions on Computer Systems,Vol.9,No.3,pp.242-271
(1991).
[Garg1996]Garg, V. K.,Principles ofDistributed Systems, KluwerAcademic, Norwell, MA
(1996).
[Gehani 1984] Gehani,N. H.,"Broadcast Sequential Processes (BSP),"IEEE Transactions on
Software Engineering, Vol. SE-IO, No.4,pp.343-351 (1984).
[Gehani 1987]Gehani,N. H.,"Message Passing: Synchronous versusAsynchronous," AT&T Bell
Laboratories, Murray Hill, NJ (1987).
[Islam and Roy1995]Islam, N., and Roy, H., "Techniques for Global Optimization ofMessage
PassingCommunication on Unreliable Networks," In:Proceedings ofthe 15th International
Conference on Distributed Computing Systems, IEEE, Piscataway, NJ (1995).
[Jalote1994]Jalote, P.,Fault Tolerancein Distributed Systems, Prentice-Hall, Englewood Cliffs,
NJ(1994).
[Jia1995] Jia, X.,"A Total Ordering Multicast Protocol Using Propagation Trees,"IEEE
Transactions on Parallel and Distributed Systems, Vol.6,No.6,pp.617-627 (1995).
[Kaashoek andTanenbaum 1991JKaashoek, M.F.,andTanenbaum, A.S.,"GroupCommunica­
tion in the Amoeba Distributed Operating System," In:Proceedings ofthe 11th International
Conference on Distributed Computing Systems, IEEE Press, Piscataway, NJ,pp.222-230
(1991).
[Kaashoek et al.1989]Kaashoek, M. F.,Tanenbaum, A. S., Hummel, S., and Bal, H. E.,"An
Efficient Reliable Broadcast Protocol," Operating Systems Review, Vol. 23, pp. 5-19
(1989).Chap. 3 • Bibliography 165
[Kranzet al, 1993] Kranz,D.,Johnson,K.,Agarwal, A.,Kubiatowicz, 1. 1., and Lim, B.,
"Integrating Message Passing and Shared Memory: Early Experiences," In: Proceedings ofthe
4th Symposium onPrinciples and Practice ofParallel Programming, AssociationforComputing
Machinery,New York, NY,pp.54-63(1993).
[Liang et al, 1990] Liang,L.,Chanson, S. T.,and Neufeld, W.,"Process Groups and Group
Communications: Classifications and Requirements," IEEE Computer, Vol.23, pp.56-66
(1990).
[Luanand Gligor 1990] Luan, S. W.,and Gligor, V.D., "A Fault-TolerantProtocol for Atomic
Broadcast," JEEE Transactions on Parallel and Distributed Systems, Vol.I,pp.271-285
(1990).
[Meliar-Smith etal, 1990] Meliar-Smith, P. M., Moser, L. E., and Agrawala, V., "Broadcast
ProtocolsforDistributedSystems," IEEE Transactions on Parallel and Distributed Systems,Vol.
1,pp. 17-25 (1990).
[Milenkovic 1992] Milenkovic, M., Operating Systems: Concepts and Design, 2nd ed., McGraw­
Hill,NewYork,NY(1992).
[Miller et ale 1987] Miller,B. P,Presotto, D. L.,and Powell, M. L.,"DEMOSIMP: The
Developmentof a Distributed OperatingSystem," Software-Practice and Experience, Vol.17,
No.4,pp.277-290 (1987).
[Mullender 1993]"Interprocess Communication," In: S. Mullender (Eds.), Distributed Systems,
2nded.,Association for Computing Machinery,New York,NY,pp. 217-250 (1993).
[Natrajan 1985] Natrajan, N.,"Communication and Synchronization Primitives for Distributed
Programs," IEEE Transactions on Software Engineering, Vol.SE-l1,No.4,pp.396-416
(1985).
[Navratnam et al,1988]Navratnarn, S.,Chanson, S:, and Neufeld, G., "Reliable Group
Communication inDistributedSystems,"In: Proceedings ofthe 8th International Conference on
Distributed Computing Systems, IEEE Press, Piscataway,NJ, pp. 439-446 (1988).
[Ramanathan and Shin 1992] Ramanathan, P., and Shin, K. G., "Delivery of Time-Critical
Messages Using aMultiple CopyApproach," ACMTransactions onComputer Systems, Vol.10,
pp.144-166 (1992).
[Shatz1984]Shatz,S.M., "Communication Mechanismsfor ProgrammingDistributedSystems,"
IEE~EComputer, pp.21-28(June1984).
[Stemple et al. 1986] Stemple, D. W.,VinterS. T.,and Ramamritham, K.,"FunctionalAddressing
in Gutenberg: InterprocessCommunication without Process Identifiers," IEEE Transactions on
Software Engineering, Vol.SE-12, No. 11, pp.1056-1066 (1986).
[Sun1990]SunMicrosystemsInc., Network Programming, SunMicrosystems,MountainView, CA
(March 1990).
[Tanenbaum 1995]Tanenbaum,A. S.,Distributed Operating Systems, Prentice-Hall,Englewood
Cliffs, NJ (1995).
[Tanenbaum et al,1992] Tanenbaum, A. S., Kaashoek, M. F., and Bal, H. E., "Parallel
Programming Using Shared Objects and Broadcasting," JEEE~Computer, pp.10-19(August
1992).
[Xerox 1981] Xerox Corporation, Courier: The Remote Procedure Call Protocol. Xerox Systems
Integration Standards, Xerox Corporation, Standard, CT (1981).
[YeungandYum 1995] Yeung,K. H.,and Yum,T. S., "Selective Broadcast Data Distribution
Systems," In: Proceedings ofthe 15th International Conference on Distributed Computing
Systems,IEEE Press, Piscataway,NJ (1995).166 Chap.3 •MessagePassing
POINTERS TO818ll0GRAPHIES ONTHEINTERNET
Icouldnotfinda bibliography dedicatedonlytomessage passing.However, thefollowing
bibliographies containreferences on the topicscoveredin thischapter:
ftp:ftp.cs.umanitoba.calpublbibliographiesIOsIlMMD_IV.html
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/os.html
ftp:ftp.cs.umanitoba.calpublbibliographieslParalleUJPDC.html
ftp:ftp.cs.umanitoba.calpublbibliographieslParalleUpvrn.htrnlCHAPTER4
RemoteProcedure
Calls
4.1 INTRODUOION
The general message-passing model of interprocess communication (IPC) was pre­
sented in the previous chapter. The IPepart of a distributed application can often
be adequately and efficiently handled by using an IPeprotocol based on the
message-passing model. However, an independently developed IPC protocol is tai­
lored specifically to one application and does not provide a foundation on which to
build a variety of distributed applications. Therefore, a need was felt for a general
IPeprotocol that can be used for designing several distributed applications. The
Remote Procedure Call (RPC) facility emerged out of this need. Itis a special case
of the general message-passing model of IPC. Providing the programmers with a
familiar mechanism for building distributed systems is one of the primary motiva­
tions for developing the RPC facility. While the RPefacility is not a universal
panacea for all types of distributed applications, it does provide a valuable commu­
nication mechanism that is suitable for building a fairly large number of distributed
applications.
167168 Chap.4 •RemoteProcedure Calls
The RPC has become a widely accepted IPCmechanism indistributed systems. The
popularity ofRPC as the primary communication mechanism fordistributed applications
is due to its following features:
1.Simplecall syntax.
2.Familiar semantics (because ofitssimilarity to localprocedure calls).
3. Itsspecification ofawell-defined interface. This property is used to support
compile-time typechecking andautomated interface generation.
4. Its ease of use. The clean and simple semantics ofaprocedure call makes it easier
to builddistributed computations and to get them right.
5. Its generality. This feature is owing to the fact that in single-machine
computations procedure calls are often the most important mechanism for
communication between parts ofthealgorithm [Birrell and Nelson 1984].
6. Its efficiency. Procedure calls are simpleenoughforcommunication to be quite
rapid.
7. It can be used as an IPC mechanism tocommunicate between processes on
different machines as well as between different processes on the same
machine.
4.1THERPeMODEL
The RPC model is similarto thewell-known andwell-understood procedure call model
used for the transferofcontrol and data within a program in thefollowing manner:
1. For making a procedure call, thecallerplacesarguments to theprocedure in some
well-specified location.
2.Controlis thentransferred to thesequence ofinstructions thatconstitutes the body
oftheprocedure.
3. Theprocedure body isexecuted in a newly createdexecution environment that
includes copiesofthearguments given in the callinginstruction.
4. After the procedure's execution is over, controlreturns to the callingpoint,
possibly returning a result.
The RPC mechanism is anextension oftheprocedure callmechanism in the sense
that itenablesa call tobemade to a procedure that does not reside in theaddress space
ofthecallingprocess. The calledprocedure (commonly calledremoteprocedure) may be
on the same computer as thecallingprocessor on adifferent computer.
In caseofRPC, since the callerand thecalleeprocesses havedisjointaddress spaces
(possibly ondifferent computers), theremoteprocedure has no access to data and
variables ofthecaller'senvironment. Therefore the RPC facility uses a message-passing
scheme for information exchange between thecallerand the callee processes. As shown
inFigure4.1, when a remote procedure call is made, the callerand thecalleeprocesses
interactin thefollowing manner:Sec. 4.2 • The RPC Model 169
Caller
(clientprocess)
Callprocedure and
waitforreplyCallee
(serverprocess)
I
I
I,
Requestmessage f
(containsremoteprocedure's parameters~
I
IReceiverequestand
startprocedure
execution
Procedure
executes
ResumeexecutionSendreplyandwait
fornextrequest
Fig. 4.1 A typical model of Remote Procedure Call.
1. The caller (commonly known as clientprocess) sends a call (request) message to
the callee (commonly known as serverprocess) and waits (blocks) for a reply
message. The request message contains the remote procedure's parameters,
among other things.
2. The server process executes the procedure and then returns theresult ofprocedure
execution inareply message to the client process.
3. Once the reply message is received, the result of procedure execution isextracted,
and thecaller'sexecution is resumed.
The server process is normally dormant, awaiting the arrival of a request message.
When one arrives, the server process extracts the procedure's parameters, computes the
result, sends a reply message, and then awaits the next call message.
Note that in this model of RPC, only one of the two processes is active at any
given time. However, in general, the RPC protocol makes no restrictions on the
concurrency model implemented, and other models of RPC are possible depending on
the details of the parallelism of the caller'sandcallee'senvironments and the RPC
implementation. For example, an implementation may choose to have RPC calls to be
asynchronous, so that the client may do useful work while waiting for the reply from
the server. Another possibility is to have the server create a thread (threads are
described in Chapter 8) to process an incoming request, so that the server can be free
to receive other requests.170
4.3TRANSPARENCY OFRPCChap.4 • RemoteProcedure Calls
Amajorissue in the design ofan RPC facility is its transparency property. A transparent
RPCmechanism is one in which local procedures andremoteprocedures are(effectively)
indistinguishable toprogrammers. Thisrequiresthefollowing two types oftransparencies
[WilburandBacarisse 1987]:
I. Syntactic transparency means that a remoteprocedure callshouldhaveexactlythe
same syntax as a local procedure call.
2. Semantic transparency meansthat thesemantics ofaremoteprocedure call are
identical to thoseofa localprocedure call.
It is not very difficulttoachievesyntactic transparency ofan RPCmechanism, and
we have seen that the semantics ofremoteprocedure calls are also analogous to thatof
localprocedure calls for most parts:
• Thecallingprocessissuspended until the calledprocedure returns.
• Thecallercan pass arguments to thecalledprocedure (remoteprocedure).
• Thecalledprocedure (remoteprocedure) can return results to the caller.
Unfortunately, achieving exactlythe same semantics forremoteprocedure calls as
for local procedure calls is close to impossible [Tanenbaum and VanRenesse 1988]. This
ismainlybecauseofthefollowing differences between remoteprocedure calls and local
procedure calls:
1.Unlikelocalprocedure calls, with remoteprocedure calls, the calledprocedure is
executed in anaddressspace that is disjointfrom the callingprogram's addressspace. Due
to this reason, the called(remote) procedure cannothave access to any variables or data
values in the callingprogram's environment. Thus in the absenceofsharedmemory, it is
meaningless to passaddresses inarguments, makingcall-by..reference pointers highly
unattractive. Similarly, it is meaningless to passargument valuescontaining pointer
structures (e.g.,linkedlists), since pointers arenormally represented bymemory
addresses. According to Bal et al. [1989], dereferencing apointerpassedby thecallerhas
to be done at the caller'sside, which impliesextracommunication. Analternative
implementation is to send a copy ofthe value pointedat thereceiver, but this has subtly
different semantics and may be difficulttoimplement ifthepointerpointsinto themiddle
ofacomplex datastructure, such as a directedgraph. Similarly, call by reference can be
replaced by copy in/copyout, but at the costofslightlydifferent semantics.
2.Remoteprocedure calls are more vulnerable to failure than local procedure calls,
since they involvetwodifferent processes andpossibly anetwork and two different
computers. Therefore programs that make use ofremoteprocedure calls must have the
capability ofhandling even those errorsthatcannotoccurin localprocedure calls. The
need for the abilityto take care ofthepossibility ofprocessor crashesandcommunicationSec.4.4 • Implementing RPCMechanism 171
problems ofanetwork makesitevenmoredifficult toobtainthesamesemantics for
remoteprocedure callsas for local procedure calls.
3.Remoteprocedure callsconsume muchmoretime(100-1000 timesmore)than
localprocedure calls.Thisismainlydue to the involvement ofacommunication network
inRPCs.Therefore applications usingRPCsmustalso have the capability tohandlethe
longdelaysthat may possibly occurdue tonetwork congestion.
Becauseofthesedifficulties inachieving normalcallsemantics forremoteprocedure
calls, some researchers feel that the RPCfacilityshouldbenontransparent. Forexample,
Hamilton [1984]arguesthatremoteprocedures shouldbetreateddifferently fromlocal
procedures from the start, resulting inanontransparent RPCmechanism. Similarly, the
designers ofRPC inArgus[LiskovandScheifler 1983]wereoftheopinionthatalthough
the RPC systemshouldhidelow-level detailsofmessage passingfrom the users, failures
and long delaysshouldnot behiddenfrom the caller. Thatis, thecallershouldhave the
flexibility ofhandling failuresand long delaysin anapplication-dependent manner. In
conclusion, although in most environments totalsemantic transparency isimpossible,
enough can be donetoensurethatdistributed application programmers feel
comfortable.
4.4IMPLEMENTING RPCMECHANISM
Toachievethe goalofsemantic transparency, theimplementation ofanRPCmechanism
isbasedon theconceptofstubs,whichprovideaperfectly normal(local)procedure call
abstraction byconcealing fromprograms theinterface to theunderlying RPCsystem.We
saw that an RPC involves aclientprocessand aserverprocess.Therefore, toconcealthe
interface oftheunderlying RPCsystemfrom both the clientandserverprocesses, a
separate stubprocedure isassociated witheachofthe twoprocesses. Moreover, to hide the
existence andfunctional detailsoftheunderlying network, an RPC communication
package (known asRPCRuntime) isused on both the clientandserversides.Thus,
implementation ofanRP(~mechanism usuallyinvolves thefollowing fiveelements of
program [BirrellandNelson1984]:
1.Theclient
2. Theclientstub
3. TheRPCRuntime
4. Theserverstub
5. Theserver
Theinteraction between themisshowninFigure4.2.Theclient,theclientstub, and
oneinstanceofRPCRuntime executeon theclientmachine, while the server, the server
stub, and anotherinstanceofRPCRuntime executeon theservermachine. Thejobofeach
oftheseelements isdescribed below.172
Clientmachine
ClientChap.4 •RemoteProcedure Calls
Servermachine
Server
Call
Clientstub Serverstub
Pack
APCRuntime
Call packet
ResultpacketRPCRuntime
Send
Fig. 4.2 Implementation ofRPCmechanism.
4.4.1Client
The client is a user process that initiates a remote procedure call. To make a remote
procedure call, the client makes a perfectly normal local call that invokes a corresponding
procedure in the client stub.
4.4.1ClientStub
The client stub is responsible for carrying out the following two tasks:
• On receipt of a call request from the client, it packs a specification of the target
procedure and the arguments into a message and then asks the local RPCRuntime
to senditto the server stub.Sec.4.4 •Implementing RPCMechanism 173
• Onreceiptofthe result of procedure execution, itunpacks theresultandpassesit
to theclient.
4.4.3RPCRuntlme
TheRPCRuntime handlestransmission ofmessages acrossthenetwork between client
andservermachines. It isresponsible forretransmissions, acknowledgments, packet
routing,andencryption. TheRPCRuntime on theclientmachine receives the callrequest
message from the clientstub and sends it to the servermachine. It alsoreceives the
message containing theresultofprocedure execution from the servermachine andpasses
it to theclientstub.
On theotherhand,theRPCRuntime on theservermachine receives themessage
containing theresultofprocedure execution from the serverstub and sends it to the client
machine. It alsoreceives the callrequestmessage from the clientmachine andpassesit
to theserverstub.
4.4.4ServerStub
Thejoboftheserverstub is very similarto thatoftheclientstub. Itperforms the
following two tasks:
• Onreceiptofthe callrequestmessage from the local RPCRuntime, theserverstub
unpacks it andmakesaperfectly normalcall toinvoketheappropriate procedure
in the server.
• Onreceiptofthe result ofprocedure execution from the server, the serverstub
packstheresultinto amessage and then asks the local RPCRuntime to send it to
theclientstub.
4.4.5Server
Onreceiving a callrequestfrom the serverstub, the serverexecutes theappropriate
procedure andreturnstheresultofprocedure execution to theserverstub.
Note here that the beautyofthewholeschemeis the total ignorance on the part ofthe
clientthat the work was done remotely insteadofby the local kernel.Whentheclientgets
controlfollowing theprocedure call that itmade, all it knowsis that the resultsofthe
procedure execution areavailable toit.Therefore, as far as the clientisconcerned, remote
services areaccessed bymakingordinary (local)procedure calls, not by using the send
andreceiveprimitives ofChapter3. All the detailsofthemessage passingarehiddenin
theclientandserverstubs,makingthe steps involved inmessage passinginvisible to both
theclientand the server.174
4.5STU8GENERATIONChap.4 •RemoteProcedure Calls
Stubs can begenerated in one of the following two ways:
1. Manually. In this method, the RPC implementor provides a set of translation
functions from which a user can construct his or her own stubs. This method is simple to
implement andcan handle very complex parameter types.
2. Automatically. This is the more commonly used method for stub generation. It
usesInterface Definition Language (JDL) that is used to define the interface between a
clientand a server. An interface definition is mainly a list of procedure names supported
by the interface, together with the types of their arguments and results. This is sufficient
information for the client and server to independently perform compile-time type­
checking and to generate appropriate calling sequences. However, an interface definition
alsocontainsother information that helps RPC reduce data storage and the amount ofdata
transferred over the network. For example, an interface definition has information to
indicatewhethereach argument is input, output, or both-only input arguments need be
copiedfrom client to server and only output arguments need be copied from server to
client. Similarly, an interface definition also has information about type definitions,
enumerated types, and defined constants that each side uses to manipulate data from RPC
calls, making itunnecessary for both the client and the server to store this information
separately. (See Figure 4.21 for an example of an interface definition.)
Aserverprogram that implements procedures in an interface is said to exportthe
interface, and aclient program that calls procedures fromaninterface is said to importthe
interface. When writing a distributed application, a programmer first writes an interface
definition using the IDL. He or she can then write the client program that imports the
interface and the server program that exports the interface. The interface definition is
processed using an IDL compiler togenerate components that can be combined with client
and server programs, without making any changes to the existing compilers. In particular,
from aninterface definition, an IDL compiler generates aclient stub procedure and aserver
stubprocedure for each procedure in the interface, the appropriate marshaling and
unmarshaling operations (described later in this chapter) in each stub procedure, and a
header file that supports thedata types intheinterface definition. The headerfileisincluded
in the source files ofboth the client and server programs, the client stub procedures are
compiled and linked with the client program, and the server stub procedures arecompiled
and linked with the server program. An IDL compiler can be designed to process interface
definitions foruse withdifferent languages, enabling clients and servers written indifferent
languages, tocommunicate byusing remote procedure calls.
4.6RPeMESSAGES
Any remote procedure call involves a client process and a server process that are possibly
located on different computers. The mode ofinteraction between the client and server is
that theclientasks the server to execute a remote procedure and the server returns theSec.4.6 • RPC Messages 175
result of execution of theconcerned procedure to the client. Based on this mode of
interaction, the two types of messages involved in theimplementation of an RPC system
are as follows:
1. Callmessages that are sent by the client to the serverforrequesting execution of
aparticular remoteprocedure
2.Replymessages that are sent by the server to the clientforreturning the result of
remoteprocedure execution
The protocol of the concerned RPC system defines the format of these two types of
messages. Normally, an RPC protocol is independent oftransport protocols. That is, RPC
does not care how a message is passed from one process to another. Therefore an RPC
protocol deals only with the specification andinterpretation of these two types of
messages.
4.6.1CallM.ssag.s
Since a call message is used to request execution of aparticular remoteprocedure, the two
basiccomponents necessary in a call message are as follows:
1. Theidentification information of the remote procedure to beexecuted
2. Thearguments necessary for the execution of theprocedure
In addition to these two fields, a call message normally has the following fields:
3. A message identification field that consistsof a sequence number. This field is
useful in two ways-for identifying lost messages and duplicate messages in case
of system failures and for properly matching reply messages to outstanding call
messages, especially in those cases where the replies of several outstanding call
messages arrive out of order.
4. Amessage type field that is used to distinguish callmessages from reply
messages. For example, in an RPC system, this field may be set to 0 for all call
messages and set to 1 for all reply messages.
5.Aclientidentification field that may be used for two purposes-to allow the
server of the RPC to identify the client to whom the reply message has to be
returned and to allow the server to check the authentication of the client process
forexecuting theconcerned procedure.
Thus, a typical RPC call message format may be of the form shown in Figure 4.3.
4.6.2R.plyMessages
When the serverof an RPC receives a call message from a client, itcouldbefaced with
one of the following conditions. In the list below, it is assumed for aparticular condition
that no problem was detected by the server for any of the previously listedconditions:176 Chap.4 •RemoteProcedure Calls
ments(
Remoteprocedure identifier)
Message Message Client
identifier typeidentifier ProgramVersion ProcedureArgu
number number number
(
.)
Fig.4.3 A typical RPC call message format.
1. The server finds that the call message is not intelligible to it. This may happen
when a call message violates the RPC protocol. Obviously the server will reject
such calls.
2. The server detects by scanning the client'sidentifier field that the client is not
authorized to use the service. The server will return an unsuccessful reply without
bothering to make an attempt to execute the procedure.
3. The server finds that the remote program, version, or procedure number specified
in the remote procedure identifier field of the call message is not available with
it.Again the server will return an unsuccessful reply without bothering to make an
attempt to execute the procedure.
4. If this stage is reached, an attempt will be made to execute the remote procedure
specified in the call message. Therefore itmay happen that the remote procedure
is not able to decode the supplied arguments. This may happen due to an
incompatible RPC interface being used by the client and server.
5. An exception condition (such as division by zero) occurs while executing the
specified remote procedure.
6. The specified remote procedure is executed successfully.
Obviously, in the first five cases, an unsuccessful reply has to besent to the client
with the reason for failure in processing the request and a successful reply has to be sent
in the sixth case with the result of procedure execution. Therefore the format of a
successful reply message and an unsuccessful reply message is normally slightly different.
A typical RPC reply message format for successful and unsuccessful replies may beof the
form shown in Figure 4.4.
The message identifier field of a reply message is the same as that of its
corresponding call message so that a reply message can be properly matched with its call
message. The message type field is properly set to indicate that it is a reply message. For
a successful reply, the reply status field is normally set to zero and is followed by the field
containing the result of procedure execution. For an unsuccessful reply, the reply status
field is either set to 1or to a nonzero value to indicate failure. In the latter case, the value
of the reply status field indicates the type of error. However, in either case, normally a
shortstatement describing the reason for failure is placed in a separate field following the
reply status field.
Since RPC protocols are generally independent of transport protocols, it is not
possible for an RPC protocol designer to fix the maximum length of call and replySec.4.7 • Marshaling Arguments andResults 177
suitc
)
Message Message Reply
identifier type status Re
(successful)
(
.,J
(a)
Fig. 4.4 A typical RPC reply message
format:(a)a successful reply
message format; (b)an unsuccessful
reply message format.Message Message Reply Reasonfor
identifier type status failure
(unsuccessful)
(b)
messages. Therefore, for a distributed application to work for a group of transports, itis
important for the distributed application developers to ensure that their RPC call and reply
messages do not exceed the maximum length specified by any of the transports of the
concerned group.
4.7MARSHALING ARGUMENTS ANDRESULTS
Implementation of remote procedure calls involves the transferof arguments from the
client process to the server process and the transfer of results from the server process to
the client process. These arguments and results are basicaIJy language-level data structures
(program objects), which are transferred in the form of message data between the two
computers involved in the call. We have seen in the previous chapter that transfer of
message data between two computers requiresencoding and decoding of the message
data. For RPCs this operation isknownasmarshaling and basically involves the following
actions:
1. Taking the arguments (of a client process) or the result (of a server process) that
will form the message data to be sent to the remote process.
2. Encoding the message data of step 1 above on the sender's computer. This
encoding process involves the conversion of program objects into a stream form
that is suitable for transmission and placing them into a message buffer.
3. Decoding of the message data on the receiver's computer. This decoding process
involves the reconstruction of program objects from the message data that was
receivedinstream form.
In order that encoding and decoding of an RPC message can be performed
successfully, the order and the representation method (tagged or untagged) used to178 Chap.4 •RemoteProcedure Calls
marshalarguments andresultsmustbeknownto both the clientand theserverofthe RPC.
Thisprovides adegreeof typesafetybetween aclientand aserverbecausetheserverwill
notaccepta call from a clientuntil the clientuses the sameinterface definition as the
server. Type safety is ofparticular importance toserverssince itallowsthemtosurvive
againstcorruptcallrequests.
Themarshaling processmustreflectthestructure ofall typesofprogram objectsused
in theconcerned language. Theseincludeprimitive types,structured types,and user­
definedtypes.Marshaling procedures may beclassified into two groups:
1.Thoseprovided as a part ofthe RPC software. Normally marshaling procedures
forscalardatatypes, together withprocedures tomarshalcompound typesbuilt from the
scalarones,fall in this group.
2.Thosethat are definedby the users ofthe RPC system.Thisgroupcontains
marshaling procedures foruser-defined data types and data types that includepointers. For
example, inConcurrent CLU,developed for use in the Cambridge Distributed Computer
System[BaconandHamilton 1987], for user-defined types, the type definition must
containprocedures formarshaling.
AgoodRPCsystemshouldalwaysgenerate in-linemarshaling codeforeveryremote
call so that the users are relieved oftheburdenofwritingtheirownmarshaling
procedures. However, practically itisdifficult toachieve this goal because ofthe
unacceptable largeamounts of.code that may have to be generated forhandling all
possible datatypes.
4.8SERVERMANAGEMENT
InRPC-based applications, twoimportant issuesthat need to be considered forserver
management areserverimplementation andservercreation.
4.8.1 ServerImplementation
Basedon the style ofimplementation used,serversmay beoftwo types: statefuland
stateless.
Stateful Servers
Astatefulservermaintains clients'stateinformation from one remoteprocedure call to the
next.Thatis, incaseoftwosubsequent calls by a clientto astatefulserver,somestate
information pertaining to theserviceperformed for theclientas aresultofthe first call
execution isstoredby theserverprocess.Theseclients'stateinformation issubsequently
used at the timeofexecuting thesecondcall.
Forexample, let usconsider aserverforbyte-stream files that allowsthefollowing
operations on files:Sec.4.8 • Server Management 179
Open(filename, mode):Thisoperation is used to open a file identified byfilename
in thespecified mode.When the server executes thisoperation, itcreatesan entry for
this file in afile-table that it uses for maintaining the file state information of all the
open files. The file state information normally consistsof theidentifier of the file, the
open mode, and the currentpositionof anonnegative integerpointer, called the read­
writepointer.When a file is opened, its read-write pointeris set to zero and the
server returns to the client afileidentifier (jid),which is used by the client for
subsequent accesses to that file.
Readtfid,n,buffer):Thisoperation is used to get nbytes of data from the file
identified bY.tidinto the buffer named buffer.When the serverexecutes thisoperation,
it returns to the client nbytes of file data starting from the byte currently addressed by
theread-write pointerand then increments theread-write pointerbyn.
Write(fid,n,buffer):Onexecution ofthisoperation, theservertakesnbytes of data
from the specified buffer,writes it into the file identified byfidat the byte position
currently addressed by theread-write pointer,and then increments theread-write
pointerbyn.
Seektfid,position): Thisoperation causes the server to changethe value of the read­
writepointerof the file identified bylidto the new value specified asposition.
Close(fid):Thisstatement causes the server to delete from its file-table the file state
information of the file identified byfide
The file server mentioned above is stateful because it maintains the currentstate
information for a file that has been openedfor use by a client. Therefore, as shown in
Figure 4.5, after opening a file, if a client makes two subsequent Readtfid,100,buJ)
calls, the first call will return the first 100 bytes (bytes 0-99)and the second call will
return the next 100 bytes (bytes 100-199).
Clientprocess Server process
Open (filename. mode)
File table
fid ModeRIW
Return (tid) pointer
Read (tid, 100, buf)
Return (bytes 0 to 99)
Read (fid, 100, buf)
Return (bytes 100to 199)
Fig. 4.5 An example of a stateful file server.180 Chap.4 •RemoteProcedure Calls
Stateless Servers
A stateless server does not maintain any client state information. Therefore every request
from a client must be accompanied with all the necessary parameters tosuccessfully carry
out the desired operation. For example, a server for byte stream files that allows the
following operations on files is stateless.
Read(filename, position, n, buffer):Onexecution of thisoperation, the server
returns to the client nbytes of data ofthe file identified by filename. The returned
data is placed in the buffer named buffer.The value of actual numberof bytes read
isalso returned to the client. The position within the file from where to begin reading
isspecified as thepositionparameter.
Write(filename, position, n, buffer): When the server executes this operation, it
takesnbytes of data from the specified bufferand writes it into the file identified by
filename. Theposition parameter specifies the byte position within the file from
where to start writing. The server returns to the client the actual numberof bytes
written.
As shown in Figure 4.6, this file server does not keep track of any file state
information resulting from aprevious operation. Therefore if a client wishes to have
similareffectas thatin Figure 4.5,the foJJowing two Readoperations must be carried
out:
Read(filename, 0, 100, buf)
Read(filename, 100,100,buf)
Notice that in this case the client has to keep track of the file state information.
Clientprocess Serverprocess
Filestateinformation
File-ModeRIW Read(filename, 0,100,bUf)
name pointer ...
Return(0to99bytes)
"'
Read(filename, 100,100,buf)
...
....Return(100to 199bytes)
Fig. 4.6 An exampleofa stateless file server.Sec.4.8 •ServerManagement 181
WhyStateless Servers?
Fromthedescription ofstatefulandstateless servers,readersmighthaveobserved that
statefulserversprovideaneasierprogramming paradigm becausetheyrelievetheclients
from the task ofkeeping trackofstateinformation. Inaddition, statefulserversare
typically moreefficient thanstateless servers.Therefore, theobviousquestion thatarises
is whyshouldstateless serversbe used at all.
The useofstateless serversin many distributed applications isjustified by the fact
thatstateless servershave adistinctadvantage overstatefulserversin theeventofa
failure.Forexample, withstatefulservers,if aservercrashesand then restarts,thestate
information that it was holdingmay be lost and the clientprocessmightcontinue its task
unaware of thecrash,producing inconsistent results.Similarly, whenaclientprocess
crashesand then restartsits task, the serveris leftholdingstateinformation that is no
longervalid but cannoteasilybewithdrawn. Therefore, theclientofastatefulservermust
beproperly designed todetectservercrashesso thatitcanperform necessary error­
handling activities. On theotherhand, with stateless servers,aclienthas toonlyretry a
requestuntil the serverresponds; it does not need to know that the serverhascrashedor
that the network temporarily wentdown.Therefore, stateless servers, whichcan be
constructed aroundrepeatable operations, makecrashrecovery very easy.
Bothstateless andstatefulservershavetheirownadvantages anddisadvantages. The
choiceofusingastateless or astatefulserverispurelyapplication dependent. Therefore,
distributed application systemdesigners mustcarefully examine thepositiveandnegative
aspectsofbothapproaches fortheirapplications beforemakingachoice.
4.8.2 Server Creation Semantics
In RPC, the remoteprocedure to beexecuted as aresultofaremoteprocedure callmade
byaclientprocesslies in aserverprocessthat istotallyindependent oftheclientprocess.
Independence heremeansthat theclientandserverprocesses haveseparate lifetimes, they
normally run onseparate machines, and they havetheirownaddressspaces.Sinceaserver
processisindependent ofaclientprocessthatmakesaremoteprocedure call to it, server
processes mayeitherbecreatedandinstalled beforetheirclientprocesses or becreatedon
ademand basis.Basedon the time duration for which RPCserverssurvive, they may be
classified asinstance-per-calJ servers,instance-per-transactionlsession servers,orpersist­
entservers.
Instance-per-Call Servers
Serversbelonging to thiscategory existonly for the durationofasinglecall. Aserverof
this type is createdbyRPCRuntime on theservermachine onlywhena callmessage
arrives.Theserverisdeletedafterthe call has beenexecuted.
Thisapproach forservercreation is notcommonly usedbecauseofthefollowing
problems associated withit:
•Theserversofthis type are stateless becausethey are killedassoonas theyhave
serviced the call for whichthey were created.Therefore, anystatethat has to be182 Chap.4 •RemoteProcedure Calls
preserved across server calls must be taken care of by either the client process or
the supporting operating system. The involvement of the operating system in
maintaining intercall state information will make the remote procedure calls
expensive. On theother hand, if the intercall state information is maintained bythe
client process, the state information must be passed to and from the server with
each call. This will lead to the loss of data abstraction across the client-server
interface, which will ultimately result in loss of attractiveness of the RPC
mechanism to the programmers.
• When a distributed application needs to successively invoke the same type of
server several times, this approach appears more expensive, since resource
(memory space to provide buffer space and control structures) allocation and
deallocation has to be done many times. Therefore, the overhead involved in
server creation and destruction dominates the cost of remote procedure calls.
Instance-per-Session Servers
Servers belonging to this category exist for the entire session for which a client and a
server interact. Since a server of this type exists for the entire session, it can maintain
intercall state information, and the overhead involved in server creation and destruction
for aclient-server session that involves a large number of calls is also minimized.
In this method, normally there is a server manager for each type of service. All these
server managers are registered with the binding agent (binding agent mechanism for
binding a client and a server is described later in this chapter). When a client contacts the
binding agent, it specifies the type of service needed and the binding agent returns the
address of the server manager of the desired type tothe client. The client then contacts the
concerned server manager, requesting it to create a server for it. The server manager then
spawns a new server and passes back its address to the client. The client now directly
interacts with this server for theentire session. This server isexclusively used bythe client
for which it was created and is destroyed when the client informs back to the server
manager of thecorresponding type that it no longer needs that server.
Aserverof this type can retain useful state information between calls and so can
present a cleaner, more abstract interface to its clients. Note that a server of this type only
services a single client and hence only has to manage a single set of state information.
Persistent Servers
Apersistent server generally remains in existence indefinitely. Moreover, we saw that the
servers of the previous two types cannot be shared by two or more clients because they
areexclusively created for a particular client on demand. Unlike them, a persistent server
is usually shared by many clients.
Servers of this type are usually created and installed before the clients that use them.
Each server independently exports its service by registering itselfwith the binding agent.
When a client contacts the binding agent for a particular type of service, the binding agent
selects a server ofthat type either arbitrarily or based on some in-built policy (such as theSec.4.9 • Parameter-Passing Semantics 183
minimum numberofclients currentlyboundto it)andreturnstheaddressoftheselected
serverto theclient.Theclientthen directlyinteractswiththatserver.
Notethatapersistent servermaybe simultaneously boundto severalclients. Inthis
case, the serverinterleaves requests from anumberofclientsand thus has to concurrently
manage severalsets ofstateinformation. Ifapersistent serverissharedbymultiple
clients,theremoteprocedure thatitoffersmust be designed so thatinterleaved or
concurrent requests fromdifferent clientsdo notinterfere witheachother.
Persistent serversmayalso be used for improving the overall performance and
reliability of thesystem.For this, severalpersistent serversthatprovidethesametypeof
servicemay beinstalled ondifferent machines toprovideeitherloadbalancing or some
measure ofresilience to failure.
4.9PARRMETER·PASSING SEMANTICS
Thechoiceofparameter-passing semantics iscrucialto thedesignof an RPC mechanism.
The two choicesarecall-by-value andcall-by-reference.
4.9.1(all-by-Value
In theeall-by-valuemethod, allparameters arecopiedinto amessage that istransmitted
from the clientto theserverthroughtheintervening network. Thisposes no problems for
simplecompact typessuch as integers, counters, small arrays, and so on. However,
passinglargerdata types such as multidimensional arrays, trees, and so on, can consume
much time for transmission ofdata that may not be used. Therefore thismethodis not
suitableforpassingparameters involving voluminous data.
Anargument in favor of the high cost incurred inpassinglargeparameters by value
is that it forces the users to be aware oftheexpenseofremoteprocedure calls for large­
parameter lists. In turn, the users are forced to carefully consider theirdesignofthe
interface neededbetween clientandservertominimize thepassingofunnecessary data.
Therefore, beforechoosing RPCparameter-passing semantics, it isimportant tocarefully
reviewandproperly designtheclient-server interfaces so thatparameters becomemore
specificwithminimal data being transmitted.
4.9.2(all-by-Reference
MostRPCmechanisms use thecall-by-value semantics forparameter passingbecausethe
clientand theserverexistindifferent addressspaces,possibly even ondifferent typesof
machines, so thatpassingpointers orpassingparameters byretereneeismeaningless.
However, a few RPC mechanisms do allow passingofparameters byreference inwhich
pointersto theparameters arepassedfrom the clientto the server. Theseareusuallyclosed
systems, where a singleaddressspace is sharedby allprocesses in thesystem.For
example, distributed systems havingdistributed shared-memory mechanisms (described
inChapter 5) can allow passingofparameters byreference.184 Chap.4 •RemoteProcedure Calls
In an object-based system that uses the RPC mechanism for object invocation, the
call-by-reference semantics is known as call-by-object-reference. This is because in an
object-based system, the value of a variable is a reference to an object, so it is this
reference (the object name) that is passed in an invocation.
Emerald [Black et al. 1986, 1987] designers observed that the use of a call-by­
object-reference mechanism in distributed systems presents a potentially serious
performance problem because on a remote invocation access by the remote operation
to an argument is likely to cause an additional remote invocation. Therefore to avoid
many remote references, Emerald supports a new parameter-passing mode that is known
ascall-by-move. In call ...by-move, a parameter is passed by reference, as in the method
ofcall-by-object-reference, but at the time of the call, the parameter object is moved
to the destination node (site of the callee). Following the call, the argument object may
either return to the caller'snode or remain at the callee's node (these two modes are
known as call-by-visit andcall-by-move, respectively).
Obviously, the use of the call-by-move mode for parameter passing requires that the
underlying system supports mobile objects that can be moved from one node to another.
Emerald objects are mobile ..
Notice that call-by-move does not change the parameter-passing semantics, which is
still call-by-object-reference. Therefore call-by-move is basically convenient and
optimizes performance. This is because call-by-move could be emulated as a two-step
operation:
• First move each call-by-move parameter object to the invokee's node.
• Then invoke the object.
However, performing themoves separately wouldcause multiple messages to besent
across the network. Thus, providing call-by-move as a parameter-passing mode allows
packaging of the argument objects in the same network packet as the invocation message,
thereby reducing the network traffic and message count.
Although call-by-move reduces the cost of references made by the invokee, it
increases the cost of the invocation itself. If the parameter object is mutable and shared,
it also increases the cost of references by the invoker [Black et al. 1987].
4.10 CAll SEMANTICS
In RPC, the caller and the callee processes are possibly located on different nodes. Thus
it is possible for either the caller or the callee node to fail independently and later to be
restarted. In addition, failure of communication links between the caller and the callee
nodes isalso possible. Therefore, the normal functioning ofanRPC mayget disrupted due
to one or more of the following reasons:
• The call message gets lost.
• The response message gets lost.Sec. 4.10 • Call Semantics
• The callee node crashes and is restarted.
• The caller node crashes and is restarted.185
Someelementof acaller'snode that is involved in the RPC must contain necessary
code to handle these failures. Obviously, the code for the caller'sprocedure should not be
forced to deal with these failures. Therefore, thefailure-handling code is generally a part
ofRPCRuntime. The call semantics of an RPC system that determines how often the
remoteprocedure may beexecuted under fault conditions depends on this part of the
RPCRuntime code. This part of the code may be designed to provide the flexibility to the
application programmers to select from different possible call semantics supported by an
RPC system. The different types of call semantics used in RPC systems are described
below.
4.10.1 Possibly or May-Ie CallSemantics
This is the weakest semantics and is not really appropriate to RPC but is mentioned here
forcompleteness. Inthismethod, to prevent the caller from waiting indefinitely for a
response from thecallee, a timeout mechanism is used. That is, the caller waits until a pre­
determined timeout period and then continues with its execution. Therefore the semantics
does not guarantee anything about the receipt of the call message or the procedure
execution by the caller. This semantics may be adequate for some applications in which
the response message is not important for the caller and where the application operates
within a local area network having a high probability of successful transmission of
messages.
4.10.2last-One CallSemantics
This call semantics is similar to the one described in Section 3.9 and illustrated with an
example in Figure 3.10. It uses the idea of retransmitting the call message based on
timeouts until a response is received by the caller. That is, the calling of the remote
procedure by the caller, the execution of the procedure by the callee, and the return of the
result to the caller will eventually be repeated until the result of procedure execution is
received by the caller. Clearly, the results of the last executed call are used by the caller,
although earlier (abandoned) calls may have had side effects that survived the crash.
Hence this semantics is called last-one semantics.
Last-one semantics can beeasily achieved in the way described above when only two
processors (nodes) are involved in the RPC. However, achieving last-one semantics in the
presence of crashes turns out to be tricky for nested RPCs that involve more than two
processors (nodes) [Bal et a1.1989J. For example, suppose process PIof nodeNIcalls
procedure Flon nodeN2,which in turn calls procedure F2on nodeN3.While the process
onN3is working on F2,nodeN)crashes. Node NI's processes will be restarted, and PI's
call toF)willberepeated. The second invocation of f"I will again call procedure F2on
nodeN3.Unfortunately, node N3is totally unaware of node Nt'8crash.Therefore
procedure F2will beexecuted twice on node N3andN3may return the results of the two
executions ofF2in any order, possibly violating last-one semantics.186 Chap.4 • RemoteProcedure Calls
The basic difficulty in achieving last-one semantics in such cases iscaused by orphan
calls. An orphan call is one whose parent(caller) has expired due to a node crash. To
achieve last-one semantics, these orphan calls must be terminated before restarting the
crashedprocesses. This is normally done either by waiting for them to finish or by
tracking them down and killing them ("orphan extermination"). As this is not an easy job,
otherweakersemantics have been proposed for RPC.
4.10.3last-of-Many CallS....antlcs
This issimilarto the last-one semantics exceptthat the orphan calls are neglected [Bal et
aI. 1989]. A simple way to neglect orphan calls is to use call identifiers to uniquely
identify each call. When a call is repeated, it is assigned a new call identifier. Each
response message has the corresponding callidentifier associated with it. A caller accepts
aresponse only if the call identifier associated with it matches with the identifier of the
most recently repeated call; otherwise it ignores the response message.
4.10.4At-least-Once CallSemantics
This is an even weaker call semantics than the last-of-many call semantics. Itjust
guarantees that the call is executed one or more times but does not specify which results
arereturned to the caller. Itcan beimplemented simply by using timeout-based
retransmissions without caring for the orphan calls. That is, for nested calls, if there are
any orphan calls, it takes the result ofthe first response message and ignores the others,
whetheror not the accepted response is from an orphan.
4.10.5Exactly-Once CallSemantics
This is the strongest and the most desirable call semantics because it eliminates the
possibility of aprocedure being executed more than once no matter how many times
a call is retransmitted. The last-one, last-of-many, and at-least-once call semantics
cannotguarantee this. The main disadvantage of these cheap semantics is that they
force the application programmer to design idempotent interfaces that guarantee that if
aprocedure isexecuted more than once with the same parameters, the same results
and side effects will be produced. For example, let us consider the example given in
[Wilbur and Bacarisse 1987] for reading and writing a record in a sequential file of
fixed-length records. For reading successive records from such a file, a suitable
procedure is
ReadNextRecord(Filename)
Ignoring initialization and end-of-file effects, each execution of thisprocedure will return
the next recordfrom the specified file. Obviously, this procedure is not idempotent
becausemultiple execution ofthisprocedure will return the successive records, which is
notdesirable forduplicate calls that are retransmitted due to the loss of response
messages. This happens because in the implementation ofthis procedure, the server needsSec. 4.11 • Communication Protocols for RPCs 187
to keep track ofthecurrentrecordposition for each clientthat hasopenedthe file for
accessing. Therefore to design an idempotent interface forreadingthenextrecord from
the file,itisimportant that each client keeps track of its own currentrecordpositionand
theserverismadestateless, that is, no clientstateshouldbemaintained on theserverside.
Basedon this idea, an idempotent procedure forreadingthenextrecordfrom asequential
file is
ReadRecordN(Filename, N)
whichreturnstheNthrecordfrom the specified file. In this case,theclienthas tocorrectly
specifythe value ofNtoget thedesiredrecordfrom the file.
However, not allnonidempotent interfaces can be so easilytransformed to an
idempotent form.Forexample, consider thefollowing procedure forappending a new
recordto thesamesequential file:
AppendRecord(Filename, Record)
It isclearlynotidempotent sincerepeated execution will add furthercopiesofthesame
recordto the file. This interface may beconverted into anidempotent interface byusing
thefollowing twoprocedures insteadof the one definedabove:
GetLastRecordNo(Filename)
WriteRecordN(FiJename, Record, N)
The first procedure returnstherecordnumberofthelastrecordcurrently in the file, and
thesecondprocedure writesarecordat aspecified positionin the file. Now, for appending
arecord,theclientwin have to use thefollowing twoprocedures:
Last=GetLastRecordNo(Filename)
WriteRecordN(Filename, Record,Last)
Forexactly-once semantics, theprogrammer isrelieved oftheburdenof
implementing theserverprocedure inanidempotent mannerbecause the callsemantics
itselftakescareofexecuting theprocedure onlyonce.Asalreadydescribed inSection3.9
andillustrated with anexample inFigure3.12,theimplementation ofexactly-once call
semantics isbasedon the use oftimeouts, retransmissions, callidentifiers with the same
identifier forrepeated calls,andareplycacheassociated with the callee.
4.11COMMUNICATION PROTOCOLS FORRPCs
Different systems, developed on thebasisofremoteprocedure calls,havedifferent IPe
requirements. Basedon theneedsofdifferent systems, severalcommunication protocols
havebeenproposed for use in RPCs. Abriefdescription oftheseprotocols isgiven
below.188 Chap.4 •RemoteProcedure Calls
4.11.1 The hqu8stProtocol
This protocol is also known as the R(request) protocol [Spector 1982].It is used in RPCs
in which the called procedure has nothing to return as the result of procedure execution
and the client requires no confirmation that the procedure has been executed. Since no
acknowledgment or reply message is involved in this protocol, only one message per call
is transmitted (from client to server) (Fig. 4.7). The client normally proceeds immediately
after sending the request message as there is no need to wait for a reply message. The
protocol provides may-be call semantics and requires no retransmission of request
messages.
Client Server
I
--~-----------------~-----• • •I Requestmessage I •
• .. I
• Procedure I
FirstRPC I execution I
• I I I
I • I
I I I-----------------.-----
I
--------------------~-----I • I
I Requestmessage I I
I I.....
• • NextRPe. Procequre I
I execution I
• I
• I I I I
-----------------~-----I
I
Fig.4.7 The request(R) protocol.
An RPC that usesthe Rprotocol iscalled asynchronous RPC.An asynchronous RPC
helps in improving the combined performance of both the client and the server in those
distributed applications in which the client does not need a reply to each request. Client
performance is improved because the client is not blocked and can immediately continue
to doother work after making thecall. On the other hand, server performance is improved
because the server need not generate and send any reply for the request. One such
application is a distributed window system. A distributed window system, such as X-11
[Davison et aI. 1992], is programmed as a server, and application programs wishing to
display items in windowson adisplay screen are its clients. Todisplay items ina window,
a client normally sends many requests (each request containing a relatively small amountSec.4.11•Communication Protocols forRPCs 189
of information for a small change in the displayed information) to the server one after
another without waiting for a reply for each of these requests because it does not need
replies for the requests.
Notice that for an asynchronous RPC, the RPCRuntime does not take responsibility
for retrying a request in case of communication failure. This means that ifan unreliable
datagram transport protocol such as UDP is used for the RPC, the request message could
be lost without the client'sknowledge. Applications usingasynchronous RPC with
unreliable transport protocol must be prepared to handle this situation. However, if a
reliable,connection-oriented transport protocol such as TCP is used for the RPC, there is
no need to worry about retransmitting the request message because itis delivered reliably
in this case.
Asynchronous RPCs with unreliable transport protocol are generally useful for
implementing periodic update services. For example, a time server node in a distributed
system may send time synchronization messages every Tseconds to other nodes using the
asynchronous RPC facility. In this case, even ifa message is lost, the correct time is
transmitted in the next message. Each node can keep track of the last time it received an
update message to prevent it from missing too many update messages. A node that misses
too many update messages can send a special request message to the time server node to
get a reliable update after some maximum amount of time.
4.11.2 The Request/Reply Protocol
This protocol is also known as the RR(request/reply) protocol [Spector 1982].It is useful
for the design of systems involving simple RPCs. A simpleRPCis one in which all the
arguments as well as all the results fit in a single packet buffer and the duration of a call
and the interval between calls arc both short (less than the transmission time for a packet
between the client and server) [Birrell and Nelson 1984].The protocol is based on the idea
of using implicit acknowledgment toeliminate explicitacknowledgment messages.
Therefore in this protocol:
• Aserver'sreply message is regarded as an acknowledgment of theclient'srequest
message.
• Asubsequent call packet from a client is regarded as an acknowledgment of the
server'sreply message of the previous call made by that client.
Theexchange of messages between a client and a server in the RR protocol is shown
in Figure 4.8. Notice from the figure that the protocol involves thetransmission of only
two packets per call (one in each direction).
The RR protocol in its basic form does not possess failure-handling capabilities.
Therefore to take care of lost messages, the timeouts-and-retries technique is normally
used along with the RR protocol. In t.histechnique, a client retransmits its request
message if it does not receive the response message. before a predetermined timeout
period elapses. Obviously, ifduplicate request messages are not filtered out, the RR
protocol, compounded with this technique, provides at-least-once call semantics.190 Chap.4 •RemoteProcedure Calls
Client Server
:-t-----~~~~~~a~-----~----:
I I -.. I
I , Procedure I
FirstRPC I I execution I
I I Replymessage I
I I
I ["II'"Alsoservesasacknowledgment I
I forthe requestmessage I I
--~-----------------I-----
I
~-------------------~-----I I
I Requestmessage I
I I
I Alsoservesas acknowledgment'" I
NextRPC I forthe replyofthepreviousRPC Procedure I
executionI I
I Replymessage , I
I .... I
I Alsoservesasacknowledgment I I_ _ __ _ _ JO.!.t'ler.e<1.U~t E1~s.!g! _ _ _ _ L- _ _ _ _ _
I
I
}'ig.4.8The request/reply (RR) protocol.
However, servers can support exactly-once callsemantics bykeeping recordsofthe
replies in a reply cache that enablesthem to filter out duplicate requestmessages and
toretransmit replymessages without the need to reprocess a request. The details of this
technique were given in Section3.9.
4.11.3 The R8quest/Reply/Acknowledge.R.ply Protocol
Thisprotocol is also known as the RRA(requestJreply/acknowledge-reply) protocol
[Spector 1982]. The implementation ofexactly-once callsemantics with RR protocol
requires the server to maintain a record of the replies in its reply cache. In situations
where a serverhas a large numberofclients,this may result in servers needing to
store large quantities ofinformation. In some implementations, serversrestrictthe
quantity ofsuch data by discarding it after a limited period oftime. However, this
approach is not fully reliable because sometimes itmay lead to the loss ofthose
replies that have not yet been successfully delivered to their clients. To overcome
thislimitation of the RR protocol, the RRA protocol is used, which requires clients
toacknowledge the receipt ofreply messages. The serverdeletes an information
from its reply cache only after receiving anacknowledgment for it from the client.
As shown in Figure 4.9, the RRA protocol involves thetransmission of three
messages percall (two from the clientto theserverand one from the serverto the
client).Sec.4.12 • Complicated RPCs 191
Client Server
Procedure
execution....-----
I
I
I
Procedure I
execution I
II
I
II
----~~~---~-----~
RequestmessageI
I
I ..
I
I
I Replymessage...,...
Replyacknowledgment message I
.......,
~----------------- I
I
~-----------------I
I
l-.. Requestmessage I
I-.r
I
I
I Replymessage -
~Replyacknowledgment message I
........
~----------------- I
I,...-
r--
I
I
I
NextAPC I
I
I
I
I
II
I
I
I
FirstAPeI
I
I
I
I
Fig. 4.9 The request/reply/acknowledge-reply (RRA) protocol.
In the RRA protocol, there is a possibility that the acknowledgment message may
itself get lost. Therefore implementation of the RRA protocol requires that the unique
message identifiers associated with request messages must be ordered. Each reply
message contains the message identifier of the corresponding request message, and each
acknowledgment message also contains the same message identifier. This helps in
matching a reply with its corresponding request and an acknowledgment with its
corresponding reply. A client acknowledges a reply message only if it has received the
replies to all the requests previous to the request corresponding to this reply. Thus an
acknowledgment message is interpreted as acknowledging the receipt of all reply
messages corresponding to the request messages with lower message identifiers.
Therefore the loss of an acknowledgment message is harmless.
4.12COMPLICATED RPCs
Birrell and Nelson [1984] categorized the following two types of RPCs as complicated:
1.RPCs involving long-duration calls or large gaps between calls
2. RPCs involving arguments and/or results that are too large to fit in a single­
datagram packet
Different protocols are used for handling these two types of complicated RPCs.192 Chap.4 •RemoteProcedure Calls
4.11.1APCsInvolving Long-Duration Callsor Larg.Gaps
ktw••nCalls
Oneofthefollowing twomethods.may be used to handlecomplicated RPCsthatbelong
to thiscategory [Birrell and Nelson1984]:
1. Periodic probing ofthe server by the client. In thismethod,afteraclientsends a
requestmessage to a server, it periodically sends aprobepacketto the server, which the
serverisexpected toacknowledge. This allows the clienttodetectaserver'scrash or
communication link failures and to notify the corresponding userofanexception
condition. Themessage identifier oftheoriginalrequestmessage isincluded in each probe
packet.Therefore, if theoriginalrequestis lost, in reply to a probepacketcorresponding
to thatrequestmessage, theserverintimates theclientthat the requestmessage
corresponding to the probe packethas not been received. Uponreceiptofsuch a reply
from the server, the clientretransmits theoriginalrequest.
2. Periodic generation ofanacknowledgment by the server. In this method, if a
serveris not able to generate the next packetsignificantly soonerthan the expected
retransmission interval, itspontaneously generates anacknowledgment. Therefore for a
long-duration call, theservermay have to generate severalacknowledgments, thenumber
ofacknowledgments beingdirectlyproportional to theduration ofthe call. If the client
does not receiveeitherthe reply for its requestor anacknowledgment from the server
withinapredetermined timeoutperiod,itassumes thateithertheserverhascrashedor
communication link failure has occurred. In this case, it notifiestheconcerned userofan
exception condition.
4.11.1RPCsInvolving LongM.ssages
In some RPCs, the. arguments and/orresultsare too large to fit in a single-datagram
packet. For example, in a file server, quitelargequantities ofdatamaybetransferred as
inputarguments to thewriteoperation or as results to the readoperation. Asimpleway
tohandlesuch an RPC is to use severalphysical RPCs for one logical RPC. Each physical
RPCtransfers anamountofdata that fits in a single-datagram packet.Thissolution is
inefficient due to a fixed amountofoverhead involved with each RPC independent ofthe
amountofdata sent.
Another methodofhandling complicated RPCsofthiscategory is to use
multidatagram messages. In thismethod,a long RPC argument or result is fragmented and
transmitted inmultiple packets. Toimprove communication performance, a single
acknowledgment packetis used for all the packetsofamultidatagram message. In this
case, the same approach that wasdescribed inSection3.9 is used to keep track oflost and
out-of-sequence packetsofamultidatagram RPCmessage.
SomeRPCsystemsarelimitedto small sizes. For example, theSunMicrosystem's
RPC islimitedto 8kilobytes. Therefore, in thesesystems, an RPCinvolving messages
largerthan the allowed limit must behandled bybreaking it up into severalphysical
RPCs.Sec.4.13 • Client-Server Binding
4.13CLIENT-SERVER BINDING193
It isnecessary for aclient(actually a clientstub) to know the locationof aserverbefore
aremoteprocedure call can take place between them. The processby which a client
becomes associated with a server so that calls can take place is knownasbinding. From
theapplication level'spoint of view, the model ofbinding is thatservers"export"
operations toregistertheirwillingness toprovideserviceandclients'"import" operations,
asking the RPCRuntime systemto locate a serverandestablish any state that may be
needed at each end [Bershad eta1.1987]. The client-server bindingprocessinvolves
properhandling ofseveralissues:
1. How does a clientspecify a serverto which it wants to get bound?
2. How does the bindingprocesslocate the specified server?
3. When is it properto bind a clientto aserver?
4. Is itpossible for aclienttochangeabindingduringexecution?
5. Can a clientbesimultaneously bound to multiple serversthatprovidethe same.()service
Thesebindingissues are described below.
4.13.1SarverNaming
Thespecification by aclientof aserverwith which it wants to communicate isprimarily
a naming issue. For RPC, Birrell and Nelson [1984] proposed the use of interface names
for this purpose. An interface name has twopal1s-a typeand aninstance. Typespecifies
theinterface itselfandinstance specifies aserverproviding theservices within that
interface. Forexample, there may be an interface of typefile_server, and there may be
severalinstances ofserversproviding file service. When a clientis notconcerned with
whichparticular serverofaninterface servicesitsrequest,it need not specify the instance
part of the interface name.
The type part of an interface usually also has a version numberfield todistinguish
between old and new versions of theinterface that may have different setsofprocedures
or the same set of procedures withdifferent parameters. It isinevitable in thecourseof
distributed application programming that anapplication needs to be updatedafteragiven
version has been released. The use of a versionnumberfield allows old and new versions
ofadistributed application to coexist. One would hope that the new version ofaninterface
wouldeventually replace all the old versions of the interface. However, experience has
shownthatitisalwaysbetter tomaintain backward compatibility with old versionsofthe
software becausesomeone might still be using one ofthe old versions.
According toBirrelland Nelson [1984], the interface namesemantics arebased
on anarrangement between theexporter and the importer. Therefore, interface names
arecreatedby the users. They are not dictatedby the RPC package. The RPC package
onlydictatesthe means by which an importer uses the interface name to locatean
exporter.194 Chap.4 •RemoteProcedure Calls
4.13.2ServerLocQtlng
The interface name of a server is its unique identifier. Thus when a client specifies the
interface nameofa server for making a remote procedure call, the server must be located
before the client'srequest message can be sent to it.This is primarily a locating issue and
any locating mechanism (locating mechanisms are described in Chapter10) can be used
for this purpose. The two most commonly used methods are as follows:
1.Broadcasting. In this method, a message to locate the desired server is broadcast
to all the nodes from the client node. The nodes on which the desired server is located
return a response message. Note that the desired server may bereplicated on several nodes
sothe client node willreceive aresponse from all these nodes. Normally, the first response
that is received at the client'snode is given to the client process and all subsequent
responses are discarded.
This method is easy to implement and is suitable for use for small networks.
However, the method is expensive for large networks because of the increase in message
traffic due to the involvement of all the nodes in broadcast processing. Therefore the
second method, which is based on the idea ofusing a name server, is generally used for
large networks.
2.Bindingagent.A binding agent is basically a name server used to bind a client to
a server by providing the client with the location information of the desired server. In this
method, a binding agent maintains a binding table, which is a mapping of a server's
interface name to its locations. All servers register themselves with the binding agent as
a part of their initialization process. Toregister with the bindingagent, a server gives the
binder its identification information and a handle used to locate it. The handle is system
dependent and might be an Ethernet address, an IP address, an X.500 address, a process
identifier containing a node number and port number, or something else. A server can also
deregister with the binding agent when it is no longer prepared to offer service. The
binding agent can also poll the servers periodically, automatically deregistering any server
that fails to respond.
To locate a server, a client contacts the binding agent. If the server is registered with
the binding agent, it returns the handle (location information) of the server to the client.
The method is illustrated in Figure 4.10.
The binding agent'slocation is known to all nodes. This is accomplished by using
either a fixed address for the binding agent that is known to all nodes or a broadcast
message to locate the binding agent when a node is booted. In either case, when the
binding agent is relocated, a message is sent toall nodes informing the new location ofthe
binding agent.
A binding agent interface usually has three primitives: (a) registeris usedbya server
to register itselfwith the binding agent, (b) deregister is'used by a server to deregister
itselfwith the binding agent, and (c) lookupis used by a client to locate a server.
The binding agent mechanism for locating servers has several advantages. First, the
method can support multiple servers having the same interface type so that any of the
available servers may be used to service a client'srequest. This helps to achieve a degree
of fault tolerance. Second, since all bindings are done by the binding agent, when multipleSec. 4.13 • Client-Server Binding
CDTheserverregisters itselfwith the bindingagent.
®Theclientrequests the bindingagentforthe server's location.
®Thebindingagentreturns the server'slocationinformation tothe client.
@Theclientcalls the server.
Fig. 4.10 The binding agent mechanism for locating a server in case of RPC.195
serversprovidethesameservice, theclientscan bespreadevenlyovertheserversto
balance the load. Third,thebinding mechanism can beextended to allow serversto
specifya listofusers who may use its service,inwhichcasethebindingagentwould
refuseto bindthoseclientsto theserverswho are not authorized to use its service.
However, thebindingagentmechanism hasdrawbacks. Theoverhead involved in
bindingclientstoserversis large and becomes significant when many clientprocesses are
shortlived.Moreover, inaddition to anyfunctional requirements, abindingagentmustbe
robustagainstfailuresandshouldnotbecomeaperformance bottleneck. Distributing the
bindingfunction amongseveralbindingagentsandreplicating information amongthem
cansatisfyboththesecriteria.Unfortunately, replication ofteninvolves extraoverhead of
keeping themultiple replicas consistent. Therefore, thefunctionality offeredbymany
bindingagentsislowerthanmightbehopedfor.
4.13.3BindingTime
Aclientmay beboundto aserveratcompile time, at link time, or at call time [Goscinski
1991].
Binding at Compile Time
Inthismethod, theclientandservermodules areprogrammed asifthey were intended to
belinkedtogether. Forexample, theserver'snetwork addresscan becompiled into the
clientcodeby theprogrammer and then it can be foundbylookinguptheserver'sname
inafile.196 Chap.4 •RemoteProcedure Calls
Themethodisextremely inflexible in the sense that iftheservermoves or the server
isreplicated or theinterface changes, allclientprograms using the serverwill have to be
found and recompiled. However, themethodis useful in certainlimitedcases. For
example, it may be used in an application whoseconfiguration isexpected toremainstatic
for a fairly long time.
Binding at Link Time
In thismethod, aserverprocess exportsitsservicebyregistering itselfwith the
binding agentas partofitsinitialization process. A client then makesanimport
requestto thebindingagent for the servicebeforemakinga call. The bindingagent
binds the clientand the serverbyreturning to theclienttheserver's handle(details
that are necessary formakinga call to the server). Calls can take placeonce the
clienthasreceived theserver'shandle. The server'shandleiscachedby theclientto
avoidcontacting thebinding agentforsubsequent calls to be made to the same
server. Due to the overhead involved incontacting thebindingagent, this methodis
suitable for those situations in which a client calls a serverseveral times once it is
boundto it.
Binding at Call Time
In thismethod,aclientisboundto aserverat the time when it calls the serverfor the first
timeduringitsexecution. Acommonly usedapproach forbindingat call time is the
indirect call method,As shown in Figure4.11,in this method, when a clientcalls aserver
for the first time, it passestheserver'sinterface name and the arguments ofthe RPC call
to thebindingagent. The bindingagent looks up the locationofthe target serverin its
bindingtable, and on behalfoftheclientit sends an RPC call message to the target server,
including in it thearguments received from the client. When the target serverreturnsthe
resultsto thebindingagent, the bindingagentreturnsthis result to the clientalong with
thetargetserver's handleso that the clientcansubsequently call the target server
directly.
4.13.4ChangingIIndlngs
Theflexibility provided by asystemtochangebindings dynamically is very useful
from areliability pointofview.Binding is aconnection establishment between a
clientand a server. The clientorserverofaconnection may wish to changethe
binding at some instance oftime due to some changein thesystemstate. For
example, aclientwillingto get a requestserviced byanyone ofthemultiple servers
for thatservicemaybeprogrammed tochangeabindingtoanotherserverofthe same
type when a call to the alreadyconnected serverfails. Similarly, the serverofa
binding may want to alter the binding andconnect the client to anotherserverin
situations such as when the serviceneeds to move to anothernode or a new version
oftheserverisinstalled. When a binding is altered by the concerned server, it isSec.4.13 •Client-Server Binding
CDTheclientprocess passes the server's interface name and
thearguments oftheAPecall tothe bindingagent.
®Thebindingagentsends an RPecallmessage to the server,
including in itthearguments received from the client.
®The server returns the result of request processing tothe
bindingagent.oThebinding a~entreturns this result tothe clientalong
with theservershandle.
®Subsequent calls are sent directly from the clientprocess
tothe server process.
Fig. 4.11 Illustrating binding at call time bythe method of indirect call.197
important to ensure that any state data held by the server is no longer needed or can
be duplicated in the replacement server. For example, when a file server has to be
replaced with a new one, either it must be replaced when no files are open or the state
of all the open files must be transferred from the old server to the new one as a part
of the.replacement process.
4.13.5Multlpl.Simultan80uS Ilndlngs
In a system, a service may be provided by multiple servers. We have seen that, in
general, a client is bound to a single server of the several servers of the same type.
However, there may be situations when itis advantageous for a client to be bound
simultaneously to all or multiple servers of the same type. Logically, a binding of this
sort gives rise to multicast communication because when a call is made, all the servers
bound to the client for that service will receiveand process the call. For example, a
client may wish to update multiple copies of a file that is replicated at several nodes.
For this, the client can be bound simultaneously to file servers of all those nodes where
a replica of the file is located.198
4.14EXCEPTION HANDUNGChap.4 •RemoteProcedure Calls
We saw in Figure4.4 that when a remote procedure cannot be executed successfully,
theserverreports an error in the reply message. An RPC also fails when a client
cannotcontactthe server of the RPC. An RPC system must have an effective
exception-handling mechanism forreporting such failures to clients. One approach to
do this is to define an exception condition for each possible errortype and have the
corresponding exception raised when an errorof that type occurs, causing the
exception-handling procedure to be called and automatically executed in theclient's
environment. Thisapproach can be used with those programming languages that
provide language constructs forexception handling. Some such programming lan­
guagesare ADA, CLU [Liskov et al. 1981], and Modula-3 [Nelson 1991, Harbinson
1992]. In C language, signal handlers can be used for the purpose ofexception
handling.
However, not every language has anexception-handling mechanism. For exam­
ple, Pascal does not have such a mechanism. RPCsystems designed for use with
suchlanguages generalJy use the method provided inconventional operating systems
forexception handling. One such method is to return a well-known value to the
process, makinga system call to indicate failure and to report the type oferrorby
storingasuitablevalue in a variable in the environment ofthecallingprogram. For
example, in UNIX the value -1is used to indicate failure, and the type oferror is
reported in the global variable errno.In an RPC, a return value indicating anerroris
used both for errors due to failure to communicate with the serverand errors
reported in the reply message from the server. The details of the type oferroris
reported bystoringasuitablevalue in a global variable in the clientprogram. This
approach suffers from two main drawbacks. First, it requires the clientto test every
return value. Second, it is not general enoughbecausea return value used to indicate
failure may be a perfectly legal value to be returned by a procedure. Forexample, if
the value -1is used to indicate failure, this value is also the return value of a
procedure call with arguments -5and 4 to a procedure forgettingthe sum oftwo
numbers.
4.15SECURITY
Someimplementations ofRPCincludefacilities for client and serverauthentication as
well as for providing encryption-based security for calls. For example, in [Birrell and
Nelson 1984], callersare given a guarantee ofthe identity of the callee, and vice versa,
by using the authentication service of Grapevine [Birrell et al. 1982]. For full end-to­
endencryption ofcalls and results, the federal data encryption standard [DES 1977] is
used in [Birrell and Nelson 1984]. The encryption techniques provideprotection from
eavesdropping (andconcealpatternsofdata) and detect attempts atmodification, replay,
orcreationofcalls.Sec.4.16 • Some SpecialTypesofRPCs 199
Inotherimplementations of RPC that do not includesecurityfacilities, thearguments
and results ofRPC are readable byanyonemonitoring communications betweenthecaller
and thecallee.Therefore in this case, ifsecurityisdesired,the user must implement his
or her own authentication and data encryption mechanisms. Whendesigning an
application, the user shouldconsider thefollowing security issues related with the
communication ofmessages:
• Is the authentication of theserverby theclientrequired?
• Is the authentication of theclientby theserverrequired when the resultis
returned?
• Is it all right if the arguments and results of the RPC are accessible to usersother
than the callerand thecallee?
Theseandothersecurity issues are described in detail in Chapter 11.
4.16SOMESPECIALTYPESOFRPCs
4.16.1Callback RPC
In the usual RPC protocol, thecallerandcalleeprocesses have aclient-server relationship.
Unlikethis, thecallback RPCfacilitates apeer-to-peer paradigm among the participating
processes. Itallowsaprocessto be both a clientand a server.
Callback RPC facility is very useful in certaindistributed applications. For
example, remotely processed interactive applications that need user input from time to
time or under specialconditions for further processing requirethis type offacility. As
shown in Figure4.12, in such applications, theclientprocessmakes an RPC to the
concerned serverprocess, andduringprocedure execution for the client, the server
processmakes a callback RPC to the clientprocess. The clientprocess takes necessary
actionbasedon theserver's requestand returns a reply for the callback RPC to the
serverprocess. On receiving this reply, the serverresumes theexecution ofthe
procedure and finally returns the result ofthe initial call to the client. Note that the
servermay make severalcallbacks to theclientbeforereturning the result ofthe
initial call to the clientprocess.
The ability for a serverto call its clientback is very important, and care is neededin
the design ofRPCprotocols toensurethat it ispossible. Inparticular, toprovidecallback
RPC facility, the following arenecessary:
•Providing theserverwith the client'shandle
•Makingtheclientprocesswait for the callback RPC
•Handling callback deadlocks
Commonly usedmethods tohandlethese issues are described below.200
Client
Processcallback
requestandsend
replyChap.4 •RemoteProcedure Calls
Server
I
I
I
I
I
I
I
I
I
I
IStartprocedure
execution
Stopprocedure
execution temporarily
Resumeprocedure
execution
Procedure execution
ends
Fig.4.12 Thecallback RPC.
Providing the Serverwith the Client's Handle
The server must have the client'shandle to call the client back. The client'shandle
uniquely identifies the client process and provides enough information to the server
for making a call to it. Typically, the client process uses a transient program number
for the callback service and exports the callback service byregistering its program
number with the binding agent. The program number is then sent as a part of the RPC
request to the server. To make a callback RPC, the server initiates a normal RPC
request to the client using the given program number. Instead of having the client just
send the server the program number, it could also send its handle, such as the port
number. The client'shandle could then be used by the server to directly communicateSec.4.16 • SomeSpecialTypesofRPCs 201
with the client and would savean RPC to the binding agent to get the client's
handle.
Making the Client Process Wait for the Callback RPC
Theclientprocessmustbewaitingfor thecallback so that it can process the incoming
RPC request from the serverand also to ensurethat acallback RPC from the serveris not
mistaken to be the reply of the RPC call made by the clientprocess. To wait for the
callback, aclientprocessnormally makes a call to a svc-routine. Thesvc-routine waits
untilitreceives arequestand then dispatches therequestto theappropriate procedure.
Handling Callback Deadlocks
Incallback RPC, since a processmay play the role ofeitheraclientor a server, callback
deadlocks can occur. For example, consider the most simplecase in which a processPI
makes an RPC call to a processP2and waits for a reply from Pz-In themeantime, process
Pzmakes an RPC call to anotherprocessP3and waits for a reply from P3•In the mean­
time, process P3makesan RPC call to processPJand waits for a reply from Pl'ButPI
cannotprocess P3'Srequestuntil itsrequesttoPzhas been satisfied, andP2cannotprocess
PI'Srequest until its requesttoP3has been satisfied, andP3cannotprocessP2'srequest
until itsrequesttoPIhas been satisfied. As shown in Figure4.13, asituation nowexists
wherePIis waiting for a reply from P2'which is waiting for a reply from P3,which is
waiting for a reply from PI.The result is that none of the three processes can have their
requestsatisfied, and hence all three will continue to waitindefinitely. In effect, a callback
deadlock hasoccurred due to the interdependencies ofthe three processes.
While using a callback RPC, care must be taken to handle callback deadlock
situations. Variousmethods forhandling deadlocks aredescribed inChapter6.
Fig. 4.13 An example of a callback deadlock
incase of callback RPC
mechanism.P1is waiting for R21(replyfrom P2toPt)
P2is waiting for R32(reply from P3toP2)
P3is waiting for R13(reply from P1toP3)202 Chap.4 •RemoteProcedure Calls
4.16.1Broadcast RPC
The RPC ...based IPC is normally of the one-to-one type, involving a single client process
and a single server process. However, we have seen in the previous chapter that for
performance reasons several highly parallel distributed applications require the commu­
nication system to provide the facility of broadcast and multicast communication. The
RPC-based IPC mechanisms normally support broadcast RPC facility for such
applications. In broadcast RPC, a client'srequest is broadcast on the network and is
processed by all the servers that have the concerned procedure for processing that request.
The client waits for and receives numerous replies.
A broadcast RPC mechanism may use one of the following two methods for
broadcasting a client'srequest:
1. The client has to use a special broadcast primitive to indicate that the request
message has to be broadcasted. The request is sent to the binding agent, which forwards
the request to all the servers registered with it. Note that inthis method, since all broadcast
RPC messages are sent to the binding agent, only services that register themselves with
their binding agent are accessible via the broadcast RPC mechanism.
2. The second method is to declare broadcast ports. A network port of each node is
connected to a broadcast port. A network port of a node is a queuing point on that node
for broadcast messages. The client of the broadcast RPC first obtains a binding for a
broadcast port and then broadcasts the RPC message by sending the message to this port.
Note that the same primitive may be used for both unicast and broadcast RPCs. Moreover,
unlike the first method, this method also has the flexibility of being used for multicast
RPC in which the RPC message is sent only to a subset of the available servers. For this,
the port declaration mechanism should have the flexibility toassociate only a subset of the
available servers to a newly declared multicast port.
Since a broadcast RPC message is sent to all the nodes of a network, a reply is
expected from each node. As already described in the previous chapter, depending on the
degree of reliability desired, the client process may wait for zero, one, m-out-of-n, or all
the replies. In some implementations, servers that support broadcast RPC typically
respond only when the request issuccessfully processed and are silent in the faceoferrors.
Such systems normally use some type of timeout-based retransmission mechanism for
improving the reliability of the broadcast RPC protocol. For example, in SunOS, the
broadcast RPC protocol transmits the broadcast and waits for 4 seconds before
retransmitting the request. Itthen waits for 6 seconds before retransmitting the request and
continues to increment the amount of time to wait by 2 seconds until the timeout period
becomes greater than 14seconds. Therefore, in the worst case, the request is broadcast six
times and the total wait time is 54 seconds (4+6+8+ 10+12+ 14). In SunOS, the
broadcast RPC uses unreliable, packet-based protocol for broadcasting the request, and so
the routine retransmits the broadcast requests by default. Increasing the amount of time
betweenretransmissions isknown asa back-offalgorithm. The useof a back-offalgorithm
for timeout-based retransmissions helps in reducing the load on the physical network and
computers involved.Sec.4.17 • RPCin Heterogeneous Environments
4.16.3 latch-Mode RPe203
Batch-mode RPCis usedtoqueueseparateRPC requestsinatransmission bufferonthe
clientside and then sendthemoverthenetwork in onebatchto the server. Thishelpsin
thefollowing twoways:
1.Itreducestheoverhead involved insendingeachRPCrequestindependently to
theserverandwaitingfor aresponse foreachrequest.
2.Applications requiring highercall rates (50-100 remotecallspersecond)may not
befeasible withmostRPCimplementations. Suchapplications can be
accommodated with the use ofbatch-mode RPC.
However, batch-mode RPC can be usedonly with thoseapplications in which a client
has many RPCrequests to send to aserverand theclientdoes not need any reply for a
sequence ofrequests. Therefore, therequests arequeuedon theclientside, and the entire
queueofrequests isflushedtotheserverwhen one ofthefollowing conditions becomes
true:
1. Apredetermined intervalelapses.
2. Apredetermined numberofrequests have been queued.
3.Theamountofbatcheddataexceeds thebuffersize.
4. A call is madeto oneoftheserver's procedures forwhicharesultisexpected.
Fromaprogramming standpoint, thesemantics ofsuchacall(nonqueueing RPC
request)shouldbe such that the servercandistinguish it from the queuedrequests
and send a replyforitto theclient.
Theflushing outofqueuedrequests incases1, 2, and 3 happens independent ofa
nonqueuing RPCrequestand is not noticeable by theclient.
Obviously, thequeuedmessages shouldbe sent reliably. Hence,abatch-mode RPC
mechanism requires reliabletransports such as TCP. Moreover, although thebatch-mode
optimization retainssyntactic transparency, itmayproduce obscuretiming-related effects
whereotherclientsareaccessing theserversimultaneously.
4.17RPeINHETEROGENEOUS ENVIRONMENTS
Heterogeneity is animportant issuein thedesignofanydistributed application because
typically the more portable anapplication, the better. Whendesigning an RPCsystemfor
aheterogeneous environment, thethreecommon typesofheterogeneity that need to be
considered are asfollows:
1. Data representation. Machines havingdifferent architectures may use different
datarepresentations. Forexample, integersmay berepresented with the mostsignificant
byte at the low-byte addressin onemachine architecture and at the high-byte addressin
anothermachine architecture. Similarly, integers may berepresented inI'scomplement204 Chap.4 • RemoteProcedure Calls
notationin one machine architecture and in 2's complement notationinanothermachine
architecture. Floating-point representations may also vary between twodifferent machine
architectures. Therefore, an RPC system for a heterogeneous environment must be
designed to take care ofsuchdifferences in datarepresentations betweenthearchitectures
ofclientand server machines ofaprocedure call.
2. Transport protocol. Forbetterportability ofapplications, an RPC system must be
independent of theunderlying network transport protocol. This will allow distributed
applications using the RPC system to berun ondifferent networks that use different
transport protocols.
3. Control protocol. Forbetterportability ofapplications, an RPCsystemmust also
beindependent oftheunderlying network controlprotocol that defines control
information in eachtransport packetto track the state ofa call.
The most commonly usedapproach to deal with these types ofheterogeneity while
designing an RPC system for a heterogeneous environment is to delay the choicesofdata
representation, transport protocol, and control protocol until bind time. In conventional
RPCsystems, all thesedecisions are made when the RPC system is designed. That is, the
bindingmechanism of an RPC system for a heterogeneous environment isconsiderably
richerininformation than thebindingmechanism used by a conventional RPC system. It
includes mechanisms fordetermining which data conversion software (if anyconversion
isneeded), whichtransport protocol, and which controlprotocol should be used between
aspecificclientand server and returns the correctprocedures to the stubs as result
parameters of the binding call. These binding mechanism details are transparent to the
users. That is, application programs neverdirectlyaccess the component structures of the
bindingmechanism; they deal with bindings only as atomic types and acquireand discard
them via the calls ofthe RPC system.
SomeRPC systems designed forheterogeneous environments are the HCS
(Heterogeneous Computer Systems) RPC (called HRPC) [Bershad et al. 1987], the DeE
SRC(SystemResearch Center)Firefly RPC [Schroeder andBurrows 1990],Matchmaker
[Jones et aI. 1985], and Horus [Gibbons 1987].
4.18UGHTWEIGHT RPe
TheLightweight Remote Procedure Call (LRPC)wasintroduced byBershadet aI. [1990]
andintegrated into the Taos operating systemofthe DEC SRC Fireflymicroprocessor
workstation. Thedescription below is based on the materialin theirpaper[Bershad et al.
1990J.
Asmentioned inChapter1, based on the size of the kernel, operating systems may
bebroadly classified into two categories-e-monolithic-kemel operating systems and
microkernel operating systems. Monolithic-kernel operating systems have a large,
monolithic kernel that is insulated from user programs by simple hardware boundaries. On
theotherhand, in microkernel operating systems, a small kernel provides only primitive
operations and most oftheservicesareprovided by user-level servers. The servers areSec.4.18 • Lightweight RPC 205
usuallyimplemented asprocesses and can be programmed separately. Each server forms
acomponent of theoperating system and usually has its own address space. As compared
to themonolithic-kernel approach, in this approach services are provided less efficiently
because the various components of theoperating system have to use some form of IPC to
communicate with each other. The advantages of this approach include simplicity and
flexibility. Due to modular structure, microkemel operating systems are simple and easy
to design, implement, and maintain.
In themicrokemel approach, when different components of theoperating system
have their own address spaces, the address space of each component is said to form a
domain, and messages are used for all interdomain communication. In this case, the
communication traffic in operating systems are of two types [Bershad et al. 1990]:
1. Cross-domain, which involves communication between domains on the same
machine
2. Cross-machine, which involves communication between domains located on
separate machines
The LRPC is a communication facility designed and optimized forcross-domain
communications.
Although conventional RPC systems can be used for both cross-domain and cross­
machine communications, Bershad et al. observed that the use of conventional RPC
systems for cross-domain communications, whichdominate cross-machine communica­
tions, incurs an unnecessarily high cost. This cost leads system designers to coalesce
weakly related components of microkernel operating systems into a single domain, trading
safety and performance. Therefore, the basic advantages of using the microkernel
approach are not fully exploited. Based on these observations, Bershad et al. designed the
LRPC facility for cross-domain communications, which has better performance than
conventional RPCsystems. Nonetheless, LRPC is safe and transparent and represents a
viablecommunication alternative for microkernel operating systems.
To achieve better performance thanconventional RPC systems, the four techniques
described below are used by LRPC.
4.18.1SimpleControlTransf.r
Whenever possible, LRPC uses acontrol transfermechanism that is simpler than that used
inconventional RPC systems. Forexample, ituses aspecial threads scheduling mechanism,
calledhandoffscheduling (details of the threads and handoffscheduling mechanism are
given inChapter8),fordirect contextswitch from theclient thread totheserverthread ofan
LRPC. In this mechanism, when a client calls a server'sprocedure, it provides the server
with anargument stack and itsown thread ofexecution. The call causes atraptothekernel.
The kernel validates the caller, creates a call linkage, and dispatches the client'sthread
directly to the server domain, causing the server to start executing immediately. When the
calledprocedure completes, control andresults returnthrough thekernelbacktothepointof
theclient'scall. Incontrasttothis,in conventional RPCimplementations, contextswitching
between the client and server threads of an RPC is slow because the client thread and the
server thread are fixed intheir own domains, signaling one another atarendezvous, and the206 Chap.4 • RemoteProcedure Calls
scheduler mustmanipulate system data structures toblock the client'sthread and then select
oneoftheserver'sthreads for execution.
4.18.2Simpl.DataTransfer
In an RPC, arguments andresultsneed to be passedbetween the clientandserverdomains
in the form ofmessages. As compared totraditional RPCsystems,LRPCreducesthe cost
ofdatatransferbyperforming fewercopiesofthe data during its transferfrom one domain
to another. For example, let us consider the path taken by a procedure's argument during
atraditional cross-domain RPC. As shown in Figure4.14(a), anargument inthis case
normally hastobecopied four times:
Client'sdomainFourthcopy
I~, .,
Messagebuffer
Serverstack
Server'sdomain
AsinglecopyMessagebuffer
Kernel'sdomain
(a)
Clientstack
Client'sdomainShared-argument stack
accessible byboththe
clientandserver
Globalsharedvirtual memory Server'sdomain
(b)
Fig.4.14 Datatransfermechanisms in traditional cross-domain RPCand LRPC.
(a)The path taken by a procedure's argument during a traditional
cross-domain RPCinvolves four copy operations. (b)The path tak.enby a
procedure's argument duringLRPCinvolves asingle-copy operation.Sec.4.18 • Lightweight RPC 207
1. From the client'sstack to the RPC message
2. From the message in the client domain to the message in the kernel domain
3. From the message in thekernel domain to the message in the server domain
4. From the message in the server domainto theserver'sstack
Tosimplify this data transferoperation, LRPC uses a shared-argument stack that is
accessible to both the client and the server. Therefore, as shown in Figure 4.14(b), the
sameargument in an LRPC can be copiedonlyonce-from theclient'sstack to the
shared-argument stack. The server uses the argument from the argument stack.Pairwise
allocation ofargument stacks enables LRPC to provide a privatechannel between the
client and server and also allows the copyingofparameters and results as many times as
are necessary to ensure correctand safe operation.
4.18.3SimpleStubs
Thedistinction betweencross-domain andcross-machine calls is usually made transparent
to the stubs by lower levels of the RPC system. This results in an interface andexecution
path that are general but infrequently needed.
The use of a simple model of control and data transferin LRPC facilitates the
generation of highly optimized stubs. Every procedure has a call stub in the client's
domainand an entry stub in the server'sdomain. A three-layered communication protocol
is defined for each procedure in an LRPC interface:
1. End to end, described by thecallingconventions of theprogramming language
andarchitecture
2. Stub to stub, implemented by the stubs themselves
3. Domain to domain, implemented by the kernel
To reduce the cost of interlayer crossings, LRPC stubs blur the boundaries between the
protocol layers. For example, at the time of transferof control, the kernel associates
execution stacks with the initial call frame expected by the called server'sprocedure
and directly invokes the corresponding procedure's entry in the server'sdomain. No
intermediate message examination ordispatching is done, and the server stub starts
executing theprocedure by directly branching to theprocedure's first instruction. Notice
that with this arrangement a simple LRPC needs only one formal procedure call (into
the client stub) and two returns (one out of the server procedure and one out ofthe
clientstub).
4.18.4DesignforConcurrency
When the node of the client and server processes of an LRPC has multiple processors with
a shared memory, special mechanisms are used to achievehigher call throughput and
lower call latency than is possibleon asingle-processor node.Throughput isincreased by
avoiding needless lock contention byminimizing the use of shared-data structures on the208 Chap.4 •RemoteProcedure Cans
critical domain transfer path. On the other hand, latency is reduced by reducing context­
switching overhead by caching domains on idle processors. This is basically a
generalization of the idea of decreasing operating system latency by caching recently
blocked threads on idle processors to reduce wake-up latency. Instead of threads, LRPC
caches domains so that any thread that needs to run in the context of an idle domain can
do so quickly, not justthe thread that ran there most recently.
Based on theperformance evaluation made by Bershad et ale[1990], it was found that
LRPC achieves a factor-of-three performance improvement over more traditional
approaches. Thus LRPC reduces the cost of cross-domain .communication to nearly the
lower bound imposed by conventional hardware.
4.19OPTIMIZATIONS FOR8EntRPERFORMANCE
As with any software design, performance is an issue in the design of a distributed
application. The description of LRPC shows some optimizations that may be adopted for
better performance ofdistributed applications using RPC. Some other optimizations that
may also have significant payoffwhen adopted for designing RPC-based distributed
applications are described below.
4.19.1Concurr.nt Acc.sstoMultlpl.S.rv.rs
Although one of the benefits of RPC is its synchronization property, many distributed
applications can benefit from concurrent access to multiple servers. One ofthe following
three approaches may be used for providing this facility:
1. The use of threads (described in Chapter 8)in theimplementation of a client
process where each thread can independently make remote procedure calls to different
servers. This method requires that the addressing in the underlying protocol is rich enough
to provide correct routing of responses.
2.Another method is the use of the early reply approach [Wilbur and Bacarisse
1987].As shown in Figure 4.15, in this method a call is split into two separate RPC calls,
one passing the parameters to the server and the other requesting the result. In reply to the
first call, the server returns a tag that is sent back with the second call to match the call
with thecorrectresult. The client decides the time delay between the two calls and carries
outotheractivities during this period, possibly making several other RPC calls. A
drawback of this method is that the server must hold the result of a call until the client
makes a request for it. Therefore, ifthe request for results is delayed, it may cause
congestion or unnecessary overhead at the server.
3. The third approach, known as the call buffering approach, was proposed by
Gimson [1985]. In this method, clients and servers do not interact directly with each other.
They interact indirectly viaacall buffer server.Tomake an RPC call, aclient sends itscall
request to the call buffer server, where the request parameters together with the name of
the server and the client are buffered. The client can then perform other activities until itSec.4.19 • Optimizations for Better Performance
Client
Callprocedure (parameter)Server209
Reply(tag)T
Carryoutother
activities
~Request result (tag)
Reply(result)Return (tag)
Executeprocedure
Store (result)
Return (result)
14'ig.4.15 The early reply approach for providingthe facility of concurrentaccess to
multipleservers.
needs the result ofthe RPC call. When the client reaches a state in which itneeds the
result, itperiodically polls the call buffer server to see if the result ofthe call is available,
andifso,itrecovers the result. On the server side, when a server is free, itperiodically
polls the call buffer server to see if there is any call for it. Ifso,itrecovers the call request,
executes it, and makes a call back to the call buffer serverto return the result of execution
to the call buffer server. The method is illustrated in Figure 4.16.
A variant of this approach is used in the Mercury communication systemdeveloped
at MIT [Liskov and Shrira 1988] for supporting asynchronous RPCs. The Mercury
communication system has a new data type calledpromisethat iscreatedduring an RPC
call and is given a type corresponding to those of the results and exceptions of the remote
procedure. When the results arrive, they are stored in the appropriate promise, from where
the caller claims the results at a time suitable to it. Therefore, after making a call, a caller
cancontinue withotherwork and subsequently pick up the results ofthe call from the
appropriate promise.
Apromiseis in one of two states-blocked or ready. It is in a blocked state from the
time ofcreationto the time the results of the call arrive, whereupon it enters the ready
state. Apromisein the ready state is immutable.
Twooperations (readyandclaim)areprovided to allow a caller to check the
status of the promise for the call and to claim the results of the call from it.Theready
operation is used to test the status (blocked/ready) of the promise. It returns true or
falseaccording towhether thepromise is ready or blocked. The claimoperation is210 Chap.4 •RemoteProcedure Calls
Checkforresult(tag)Execute
procedure-LPollingfora
waitingrequest
Continues topollfor
anawaitingrequestReply(no request)
I
: Checkfora waitingrequest
IC~~~~Ver Server
:Checkforawaitingrequest
I
Reply(tag)Client
Pollingfor
resultT
Carryoutother
activities
Fig.4.16 The call buffering approach for providing the facility of concurrent access
to multiple servers.
used to obtain the results of the call from the promise. The claimoperation blocks the
caller until the promise is ready, whereupon it returns the results of the call.
Therefore, ifthecallerwants to continue with otherwork until the promise becomes
ready, it can periodically check the status ofthepromise by using the ready
operation.
4.19.2ServingMultlpl.Requests Simultaneously
Thefollowing typesofdelays are commonly encountered in RPC systems:
1. Delay causedwhile aserverwaits for a resource that is temporarily unavailable.
Forexample, during the courseof a callexecution, a server might have to wait for
accessing a shared file that is currently lockedelsewhere.Sec.4.19 • Optimizations forBetterPerformance 211
2. Adelaycan occur whenaservercalls aremotefunctionthatinvolvesa
considerable amountofcomputation tocomplete orinvolvesaconsiderable
transmission delay.
For better performance, good RPC implementations must have mechanisms to allow
the server to accept and process other requests, instead of being idle while waiting for the
completion of some operation. This requires that a server be designed in such a manner
that it can service multiple requests simultaneously. One method to achieve this is to use
the approach of a multiple-threaded server with dynamic threads creation facility for
serverimplementation (details of this approach are given in Chapter 8).
4.19.3Reducing Per-CallWorkload ofServers
Numerous client requests can quickly affect a server'sperformance when the server has to
doalotof processing for each request. Thus, to improve the overall performance ofanRPC
system, itisimportant tokeeptherequests shortandtheamount ofworkrequired byaserver
foreach request low.One wayof accomplishing thisimprovement istousestateless servers
and let the clients keep track of the progression of their requests sent to the servers. This
approach sounds reasonable because, in most cases, the client portion of an application is
really incharge ofthe flow of information between aclient and a server.
4.19.4ReplyCachingofIdempotent RemoteProcedures
The use of a reply cache to achieve exactly-once semantics in nonidempotent remote
procedures has already been described. However, a reply cache can also be associated with
idempotent remote procedures for improving a server'sperformance when it is heavily
loaded. When client requests to a server arrive at a rate faster than the server can process
the requests, a backlog develops, and eventually client requests start timing out and the
clients resend the requests, making the problem worse. In such a situation, the reply cache
helps because the server has to process a request only once. If a client resends its request,
the server justsends the cached reply.
4.19.5 Proper Selection ofTimeoutValues
To deal with failure problems, timeout-based retransmissions are necessary in distributed
applications. Animportant issue here is how to choose the timeout value. A "too small"
timeout value wiJIcause timers to expire too often, resulting in unnecessary
retransmissions. On the other hand, a "too large" timeout value will cause a needlessly
long delay in the event that a message is actually lost. In RPC systems, servers are likely
to take varying amounts of time to service individual requests, depending on factors such
as server load, network routing, and network congestion. If clients continue to retry
sending those requests for which replies have not yet been received, the server loading and
network congestion problem will become worse. To prevent this situation, proper
selection of timeout values is important. One method to handle this issue is to use some
sort ofback-off strategy of exponentially increasing timeout values.212 Chap.4 •RemoteProcedure Calls
4.19.6Pro,.,Design of RPeProtocol Sp.clflcQtlon
Forbetterperformance, theprotocol specification of an RPC system must be properly
designed so as tominimize theamountofdata that has to be sent over the network and
thefrequency at which it is sent. Reducing theamountofdata tobetransferred helps in
two ways: It requires less time to encodeanddecodethe data and it requiresless time to
transmit the data over the network. SeveralexistingRPC systems use TCPIIPor UDPIIP
as the basic protocol becausethey are easy to use and fit in well with existing UNIX
systemsand networks such as the Internet. This makes it straightforward to write clients
andserversthat run on UNIX systems and standard networks. However, the use of a
standard general-purpose protocol for RPC generally leads to poor performance because
general-purpose protocols have many features to deal with different problems indifferent
situations. Forexample, packets in the IP suite (to which TCP/IPand UDPIIP belong)
have in total 13 headerfields,ofwhich only 3 are useful for an RPC-the source and
destination addresses and thepacketlength. However, several oftheseheaderfields, such
as those dealing with fragmentation andchecksum, have to be filled in by the senderand
verifiedby the receiver to make them legal IP packets. Some ofthese fields, such as the
checksum field, are time consuming to compute. Therefore, forbetterperformance, an
RPC system should use a specialized RPC protocol. Ofcourse, a new protocol for this
purposehas tobedesigned from scratch, implemented, tested, and embedded inexisting
systems, so it requires considerably more work.
4.20CASESTUDIES: SUNAPC,DeEAPC
Many RPC systemshave been built and are in use today. NotableonesincludetheCedar
RPCsystem[Birrell and Nelson 1984], Courierin the Xerox NS family ofprotocols
[XeroxCorporation 1981], the Eden system [Almes et at1985], the CMU Spice system
[Jones et al. 1985], Sun RPC [Sun Microsystems 1985], Argus [Liskov and Scheifler
1983],Arjuna[Shrivastava et aI. 1991], the research system built at HP Laboratories
[Gibbons 1987],NobelNet's EZ RPC [Smith 1994], Open Software Foundation's (OSF's)
DeERPC[Rosenberry et al. 1992], which is a descendent ofApollo's Network
Computing Architecture (NCA), and the HRPC system developed at theUniversity of
Washington [Bershad et al. 1987]. Ofthese, the best known UNIX RPC system is the Sun
RPC.Therefore, the Sun RPC will be described in this section as a case study. In addition,
due to the policy used in thisbook todescribeDeEcomponents as case studies, the DCE
RPC will also be briefly described.
4.10.1SunRPe
StubGeneration
Sun RPC uses the automatic stubgeneration approach, although users have the
flexibility ofwriting the stubs manually. An application's interface definition is written
in an IDL calledRPCLanguage (RPCL). RPCLis anextension ofthe Sun XDRSec.4.20 • Case Studies: SUDRPC,DeERPC 213
language that was originally designed for specifying external data representations. As
an example, the interface definition of the stateless file service, described in Section
4.8.1, is given in Figure 4.17. As shown in the figure, an interface definition contains
a program number (which is 0 x 20000000 in our example) and a version number of
the service (which is 1 in our example), the procedures supported by the service (in
our example READ and WRITE), the input and output parameters along with their
types for each procedure, and the supporting type definitions. The three values program
number (STATELESS_FS_PROG), version number (STATELESS_FS_VERS), and a
procedure number (READ or WRITE) uniquely identify a remote procedure. The
READ and WRITE procedures are given numbers 1 and 2, respectively. The number
ois reserved for a null procedure that is automatically generated and is intended to be
used to test whether a server is available. Interface definition file names have an
extension .x.(for example, StatelessFS.x).
/*Interfacedefinitionforastatelessfileservice (StatelessFS)
infileStatelessFS.x */
constFILE_NAME_SIZE =16
constBUFFER_SIZE =1024
typedefstring FileName<FILE_NAME_SIZE>;
typedeflong Position;
typedeflongNbytes;
structData{
tongn:
charbuffer[BUFFER_SIZE];
};
structreadargs{
FileName
Position
Nbytes
};
structwriteargs{
FileName
Position
Data
};filename;
position;
n;
filename;
position;
data;
programSTATELESS_FS_PROG {
versionSTATELESS_FS_VERS {
Data
Nbytes
}=1;
}=0x2oooo000;READ(readargs) =1;
WRITE(writeargs) =2;
Fig. 4.17 Interface definition for a stateless file service written in RPCL of Sun RPC.214 Chap.4 •RemoteProcedure Calls
The IDL compiler is called rpcgenin Sun RPC. From an interface definition file,
rpcgengenerates the following:
1. A header file that contains definitions of common constants and types defined in
the interface definition file. It also contains external declarations for all XDR marshaling
andunmarshaling procedures that are automatically generated. The name of the header file
is formed by taking the base name of the input file to rpcgenand adding a .hsuffix (for
example, StatelessFS.h). This file is manually included in client and server program files
and automatically included in client stub, server stub, and XDR filters files using
#include.
2. An XDR filters file that contains XDR marshaling and unmarshaling procedures.
These procedures are used by the client and server stub procedures. The name of this file
is formed by taking the base name of the input file to rpcgenand adding a _xdr.csuffix
(for example, StatelessFS_xdr.c).
3. A client stub file that contains one stub procedure for each procedure defined in
the interface definition file. A client stub procedure name is the name of the procedure
given in the interface definition, converted to lowercase and with an underscore and the
version number appended. For instance, in our example, the client stub procedure names
forREADandWRITEprocedures will be read_landwrite_l,respectively. The name of
theclient stub file is formed bytaking the base name of the input file to rpcgenand adding
a_clnt.csuffix (for example, StatelessFS_clnt.c).
4. A server stub file that contains the mainroutine, the dispatch routine, and one stub
procedure for each procedure defined in the interface definition file plus a null
procedure.
Themainroutine creates the transport handles and registers the service. The default
is to register the program on both the UDP and TCP transports. However, a user can select
which transport to use with a command..line option to rpcgen.
Thedispatch routine dispatches incoming remote procedure calls to the appropriate
procedure. The name used for the dispatch routine is formed by mapping the program
name to lowercase characters and appending an underscore followed by the version
number (for example, statelessfsprogFy.
The name of the server stub file is formed by taking the base name of the input file
torpcgenand adding a _svC.csuffix (for example, StatelessFS_svc.c).
Now using the files generated by rpcgen,an RPC application is created in the
following manner:
1. The application programmer manually writes the client program and server
program for the application. The skeletons ofthese two programs for our example
application of stateless file service are given Figures 4.18 and 4.19, respectively.
Notice that the remote procedure names used in.these two programs are those of
the stub procedures (read_landwrite_J).Sec. 4.20 • Case Studies: Sun RPC, DCE RPC
rAskeletonofclientsourceprogramforthestatelessfileservice infileclient.c *1
#include<stdio.h>
#include-erpc/rpc.rc-
#include"StatelessFS.h"
main(argc,argv)
intargc;
char**argv;215
CLIENT
char
readargs
writeargs
Data
Nbytes*client_.handle;
*server_host_name ="paris";
read_args;
write_args;
*read_result;
*write_result;
client_handle =clnt_create (server_host_name, STATELESS_FS_PROG,
STATELESS_FS_ VERS,"udp");
/*Getaclienthandle.Createssocket*/
if(client_handle ==NULL){
ctnt_pcreateerror (server_host_name);
retum(1); 1*Cannotcontactserver*/
};
/*PrepareparametersandmakeanRPC toreadprocedure*/
read_args.filename ="example";
read_args.position =0;
read_args.n =500:
read_result=read_1(&read_args, client_handle);
/*PrepareparametersandmakeanRPCto writeprocedure *1
write_args.filename ="example";
write_args.position =501;
write_args.data.n =100;
rStatementsforputting100 bytesofdatain&write_args.data.buffer */
write_result =write_l(&write_args, client_handle);
clnt_destroy (client_handle);
/*Destroytheclienthandlewhendone.Closessocket *1
Fig. 4.18 A skeleton of client source program for the stateless file service of Figure 4.17.216 Chap.4 •RemoteProcedure Calls
rAskeletonofserversourceprogramforthestatelessfifeserviceinfileserver.c */
#include-cstdio.n»
#include<rpclrpc.h>
#include"StatelessFS.h"
/*READPROCEDURE */
Data*read_1(args)/*Inputparametersasasingleargument */
readargs *args;
{
staticDataresult; /*Mustbedeclaredasstatic*/
/*Statementsforreading args.nbytesfromthefile args.filename starting
fromposition args.position, andforputtingthedatareadin &result.buffer
andtheactualnumberofbytesreadin result.n*/
return(&result); /*Returntheresultas asingleargument */
}
rWRITEPROCEDURE */
Nbytes *write_1(args)rInputparametersasasingleargument */
writeargs *args;
{
staticNbytesresult; /*Mustbedeclaredasstatic */
rStatementsfor writingargs.data.n bytesofdatafromthebuffer
&args.data.bufferinto thefUeargs.filename startingatposition
args.position */
/*Statementforputtingthe actualnumberofbyteswrittenin result*/
return(&result);
Fig. 4.19 A skeleton of server source program for the stateless file service of Figure 4.17.
2. The client program file is compiled to get aclient object file.
3. The server program file iscompiled to get a server object file.
4.The client stub file and the XDRfilters file are compiled to get aclient stub object
file.
5.The server stub file andtheXDRfilters file are compiled to get a server stub
objectfile.
6. Theclientobjectfile, the client stub object file, and the client-side RPCRuntime
library are linked together to get the client executable file.
7. The server object file, the server stub object file, and the server-side RPCRuntirne
library are linked togetherto get the server executable file.
Theentireprocess is summarized in Figure 4.20.Sec. 4.20 • Case Studies: Sun RPC, DCE RPC 217
Thisfileis manuallyincludedin
clientandserver programfiles,
andautomatically includedin
clientstub,serverstub,andXDR
filtersfilesusing#include
Client
executable fileClient-side
APCRuntime
libraryOnlythesethreefilesare manuallywritten
andeditedbyanapplication programmer
Server
executable file
Fig.4.20 The steps in creatingan RPC application in Sun RPC.
Procedure Arguments
In Sun RPC, a remote procedure can accept only one argument and return only one result.
Therefore, procedures requiring multiple parameters as input or as output must include
them as components of a single structure. This is the reason why the structures Data(used
as a single output argument to the READprocedure), readargs (used as a single input
argument to the READprocedure), and writeargs (used as a single input argument to the
WRITEprocedure) have been defined in our example of Figures 4.17-4.19. If a remote
procedure does not take an argument, a NULL pointer must still be passed as an argument
to the remote procedure. Therefore, a Sun RPC call always has two arguments-the first
is a pointer to the single argument of the remote procedure and the second is a pointer to
a client handle (see the calls for read_landwrite_lin Fig. 4.18). On the other hand, a218 Chap.4 •RemoteProcedure Calls
return argument of a procedure is a pointer to the single result. The returned result must
be declared as a static variable in the server program because otherwise the value of the
returned result becomes undefined when the procedure returns (see the return argument
resultin Fig. 4.19).
Marshaling Arguments andResults
Wehave seen that Sun RPC allows arbitrary data structures to be passed as arguments and
results. Since significant data representation differences can exist between the client
computer and the server computer, these data structures are converted to eXternal Data
Representation (XDR) and back using marshaling procedures. The marshaling procedures
to be used are specified by the user and may be either built-in procedures supplied in the
RPCRuntime library or user-defined procedures defined in terms of the built-in
procedures. The RPCRuntime library has procedures for marshaling integers of all sizes,
characters, strings, reals, and enumerated types.
Since XDR encoding and decoding always occur, even between a client and server
of the same architecture, unnecessary overhead is added to the network service for those
applications in which XDR encoding and decoding are not needed. In such cases, user­
defined marshaling procedures can be utilized. That is, users can write their own
marshaling procedures verifying that the architectures of the client and the server
machines are the same and, ifso, usethe data without conversion. If they are not the same,
thecorrectXDR procedures can be invoked.
CallSemantics
Sun RPC supports at-least-once semantics. After sending a request message, the
RPCRuntime library waits for a timeout period for the server to reply before
retransmitting the request. The number of retries is the total time to wait divided by the
timeout period. The total time to waitand the timeout period have default values of 25and
5 seconds, respectively. These default values can be set to different values by the users.
Eventually, if no reply is received from the server within the total time to wait, the
RPCRuntime library returns a timeout error.
Client-Server Binding
Sun RPC does not have a networkwide binding service for client-server binding. Instead,
each node has a local binding agent called portmapper that maintains a database of
mapping ofall local services (as already mentioned, each service is identified by its
program numberand version number) and their port numbers. The portmapper runs at a
well-known port number on every node.
When a server starts up, it registers its program number, version number, and port
number with the local portmapper. When a client wants to do an RPC, it must first find
out theportnumber of the server that supports the remote procedure. For this, the client
makes a remote request to the portmapper at theserver'shost, specifying the program
number and version number (see clnt_create part of Fig. 4.18). This means that a clientSec. 4.20 • Case Studies: Sun RPC, DeERPC 219
must specify the host name of the server when it imports a service interface. In effect, this
means that Sun RPChas no location transparency.
Theprocedure clnt_create isusedbyaclient to import aserviceinterface. Itreturns
aclienthandle that contains thenecessary information forcommunicating with the
corresponding serverport, such as the socket descriptor and socket address. The client
handle is used by the client to directly communicate with the server when making
subsequent RPCs to procedures of the service interface (see RPCs made to read_land
write_lprocedures in Fig. 4.18).
Exception Handling
TheRPCRuntime library of Sun RPC has several procedures forprocessing detected
errors. The server-side error-handling procedures typically send a reply message back to
the client side, indicating thedetected error. However, the client-side error-handling
procedures provide the flexibility to choosetheerror-reporting mechanism. That is, errors
may be reported to users eitherby printing errormessages tostderror by returning strings
containing errormessages to clients.
Security
Sun RPC supports the following three types of authentication (often referred to as
flavors):
1. Noauthentication. This is the default type. In this case, no attempt is made by the
serverto check a client'sauthenticity beforeexecuting the requested procedure.
Consequently, clients do not pass any authentication parameters in request messages.
2.UNIX-style authentication. This style is used to restrict access toa service to a
certainset of users. In this case, the uidandgidof the user running the client program are
passed in every requestmessage, and based on this authentication information, theserver
decideswhethertoexecutetherequested procedure or not.
3.DES-style authentication. DataEncryption Standard (DES) is an encryption
technique described inChapter11. InDES-style authentication, each user has a globally
unique name callednetname. Thenetname of the user running the client program ispassed
inencrypted form in every request message. On the serverside, theencrypted netname is
firstdecrypted and then the serveruses theinformation innetname to decide whetherto
executetherequested procedure or not.
TheDES-style authentication isrecommended for users who need more security than
UNIX-style authentication. RPCs using DES-style authentication are also referred to as
secure RPC.
Clients have the flexibility to select any ofthe above three authentication flavors for
an RPC. The type ofauthentication can bespecified when a client handle is created. It is
possible to use a different authentication mechanism for different remote procedures
within a distributed application by setting the authentication type to the flavor desired
before doing the RPC.220 Chap.4 •RemoteProcedure Calls
Theauthentication mechanism ofSun RPC is open ended in the sense that in addition
to the three authentication typesmentioned above users are free to invent and use new
authentication types.
Special Types of RPCs
Sun RPC provides supportforasynchronous RPC,callback RPC,broadcast RPC, and
batch-mode RPC.
Asynchronous RPC isaccomplished by setting the timeout value ofan RPC to zero
andwritingtheserversuch that no reply is generated for the request.
To facilitate callback RPC, the clientregisters thecallback service using a transient
program numberwith the local portmapper. Theprogram numberis then sent as part of
the RPC requestto the server.The serverinitiates a normal RPC requestto theclientusing
thegivenprogram numberwhen it is ready to do the callback RPC.
Abroadcast RPC isdirectedto theportmapper ofall nodes. Each node'sportmapper
then passes it on to the local servicewith the given program name. The clientpicks up any
replies one by one.
Batch-mode RPC isaccomplished bybatchingofclient calls that require no reply and
thensendingthem in a pipelineto theserveroverTCPII~
Critiques ofSUDRPC
In spite of its popularity, some ofthecriticisms normally madeagainstSun RPC are as
follows:
1. Sun RPC lacks locationtransparency becausea client has to specify the host name
oftheserverwhen itimportsaserviceinterface.
2. Theinterface definition language ofSun RPC does not allow a general
specification ofprocedure arguments and results. It allows only a single argument
and a single result. This requirement forcesmultiplearguments or return values to
bepackaged as a single structure.
3. Sun RPC is not transport independent and thetransport protocol islimitedto
eitherUDP or TCP. However, a transport-independent versionofSun RPC,
knownasTI-RPC(transport-independent RPC), has been developed bySun-Soft,
Inc.TI-RPCprovides a simple and consistent way in which transports can be
dynamically selecteddepending upon user preference and theavailability ofthe
transport. DetailsofTI-RPCcan be found in [Khanna 1994].
4. In UDP, Sun RPC messages are limited to 8 kilobytes in length.
5. Sun RPC supports onlyat-least-once callsemantics, which may not be acceptable
for some applications.
6. Sun RPC does not have a networkwide client-server bindingservice.
7. We saw in Section4.18 that threads can be used in the implementation ofa client
or aserverprocessforbetterperformance ofanRPC-based application. Sun RPC
does not includeanyintegrated facility for threads in the client or server, although
Sun OS has a separate threads package.Sec. 4.20 • Case Studies: Sun RPC, DeERPC
4.10.2DeEAPC221
TheDeERPC is one of the most fundamental components ofDeEbecause it is the basis
for allcommunication inDeE.It is derived from the Network Computing System (NCS)
developed by Apollo (now part of Hewlett-Packard).
TheDeERPCalso uses the automatic stub generation approach. An application's
interface definition is written in IDL. As an example, the interface definition of the
stateless file service of Figure 4.17 is rewritten in Figure 4.21 in IDL. Notice that, unlike
Sun RPC, DeERPC IDL allows a completely generalspecification of procedure
arguments and results. As shown in the figure, each interface is uniquely identified by a
universally unique identifier (VVID) that is a 128-bit binary number represented in the
IDL file as an ASCII string in hexadecimal. The uniqueness of each VVID is ensured by
incorporating in it the timestamp and the location of creation. A UUID as well as a
template for the interface definition isproduced by using the uuidgenutility.Therefore, to
create the interface definition file for a service, the first step istocall the uuidgenprogram.
Theautomatically generated template file is then manually edited to define the constants
and the procedure interfaces of the service.
When the IDL file is complete, it is compiled using the IDL compiler to generate the
client and server stubs and a header file.The client and server programs are then manually
written for an application. Finally, the same steps as that of Figure 4.20 are used to get the
client and server executable files.
[uuid(b20a 1705-3c26-12d8-8ea3-04163aOdcefz)
version(1.0»
interfacestateless_fs
(
const long FILE_NAME_SIZE =16
const long BUFFER_SIZE =1024
typedefchar FileName[FILE_NAME_SIZE];
typedefchar Buffer[BUFFER_SIZE);
voidread(
[in]FileName
[in]long
[in,out]long
[out]Buffer
);
voidwrite(
[in]FileName
(in]long
(in,out]long
[in]Buffer
);filename;
position;
nbytes;
buffer;
filename;
position;
nbytes;
buffer;
Fig. 4.21 Interface definition ofthe stateless file service of
Figure 4.17 written in the IDLofDeERPC.222 Chap.4 •RemoteProcedure Calls
The default call semantics of a remote procedure in DCE RPC is at-most-once
semantics. However, for procedures that are of idempotent nature, this rather strict call
semantics is not necessary. Therefore, DCE RPC provides the flexibility to application
programmers to indicate as part of a procedure's IDL definition that it is idempotent. In
this case, error recovery is done via a simple retransmission strategy rather than the more
complex protocol used to implement at-most-once semantics.
The DCE RPC has a networkwide binding service for client-server binding that is
based on its directory service.(the details of the DCE directory service are given in
Chapter 10). For the description here, it is sufficient to know that every cell in a DeE
system has a component called Cell Directory Service (CDS), which controls the naming
environment used within a cell. Moreover, on each DCE server node runs a daemon
process called rpcd(RPC daemon) that maintains a database of (server, endpoint) entries.
Anendpoint is a process address (such as the TCP/IP port number) of a server on its
machine.
When an application server initializes, it asks the operating system for an endpoint.
It then registers this endpoint with its local rpcd. At the time of initialization, the server
also registers its host address with the CDS of its cell.
When a client makes its first RPC involving the server, the client stub first gets the
server'shost address byinteracting with the server(s) of theCDS, making arequest to find
it a host running an instance of the server. It then interacts with the rpcd (an rpcd has a
well-known endpoint on every host) of the server'shost to get the endpoint of the server.
The RPC can take place once the server'sendpoint is known. Note that this lookup is not
needed on subsequent RPCs made to the same server.
The steps described above are used for client-server binding when the client and the
server belong to the same cell. A client can also do an RPC with a server that belongs to
another cell. In this case, the process of getting the server'shost address also involves
Global Directory Service (GDS), which controls the global naming environment outside
(between) cells (for details see Chapter 10).
The DCE RPC also provides broadcast facility. To use this facility, a remote
procedure has to be given the broadcast attribute in its defining IDL file. When a
procedure with this attribute is called, the request is sent to all servers of the requested
interface. All the servers receiving the request respond, but only the first response is
returned to the caller; the others are discarded by the RPCRuntime library.
4.11SUMMARY
Remote Procedure Call (RPC) is a special case of the general message-passing model of
IPC that has become a widely accepted IPC mechanism in distributed computing systems.
Its popularity is due to its simple call syntax, familiar procedure call semantics, ease of
use,generality, efficiency, and specification of a well-defined interface. Ideal transparency
of RPC means that remote procedure calls are indistinguishable from local procedure
calls. However, this is usually only partially achievable.
In theimplementation of an RPC mechanism, five pieces of programs are involved:
the client, the client stub, the RPCRuntime, the server stub, and the server. The purposeSec.4.21•Summary 223
of the client and server stubs is to manipulate the datacontained in acall or reply message
so that it is suitable for transmission overt.henetwork or for use by the receiving process.
On the other hand, the RPCRuntime provides network services in a transparent
manner.
The two types of messages involved in the implementation of an RPC system are
call messages and reply messages. Call messages are sent by the client to the server
forrequesting theexecution of a remote procedure, and reply messages are sent by the
server to the client for returning the result of remote procedure execution. The process
of encoding and decoding of the data of these RPC messages is known as
marshaling.
Servers of an RPC-based application may either be stateful or stateless. Moreover,
depending on the time duration for which an RPC server survives, servers may be of three
types-instance-per-call servers,instance-per-transaction/session servers, and persistent
servers. The choice of a particular type of server depends on the needs of the application
being designed.
The two choices of parameter-passing semantics in the design of an RPC mechanism
are call-by-value and call-by-reference. Most RPC mechanisms use the call-by-value
semantics because the client and server processes exist in different address spaces.
The call semantics of an RPC mechanism determines how often the remote procedure
may be executed under fault conditions. The different types of call semantics used in RPC
mechanisms are possibly or may be, last one, last of many, at least once, and exactly once.
Of these, the exactly-once call semantics is the strongest and most desirable.
Based on their IPC needs, different systems use one of the following communication
protocols for RPC: the request (R) protocol, the request/reply (RR) protocol, and the
request/reply/acknowledge-reply (RRA) protocol. In addition to these, special commu­
nication protocols are used for handling complicated RPCs that invoJve long-duration
calls or large gaps between calls or whose arguments and/or results are too large to fit in
asingle-datagram packet.
Client-server binding is necessary for a remote procedure call to take place. The
general model used forbinding is that servers export operations to register their
willingness to provide service and clients import operations when they need some service.
A client may be bound to a server at compile time, at link time, or at call time.
Some special types of RPCs operate in a manner different from the usual RPC
protocol. For example, asynchronous RPC provides a one-way message facility from
client to server, callback RPC facilitates a peer-to-peer paradigm instead of a client-server
relationship among the participating processes, broadcast RPC provides the facility of
broadcast and multicast communication instead of one-to-one communication, and batch­
mode RPC allows the batching of client requests, which is a type of asynchronous mode
ofcommunication, instead of the usual synchronous mode of communication.
Unlike the conventional RPC systems, in which most of the implementation
decisions are made when the RPC system is designed, the choices of transport protocol,
datarepresentation, and control protocol are delayed until bind time in an RPC system
designed for a heterogeneous environment. For this, the binding facility used by such an
RPC system is made considerably richer in information than the binding used by
conventional RPC systems.224 Chap. 4 • Remote Procedure Calls
Bershad et al. [1990] proposed the use of Lightweight Remote Procedure Call
(LRPC), which is a communication facilitydesigned andoptimized forcross-domain
communications inmicrokemel operating systems. For achieving betterperformance than
conventional RPC systems, LRPC uses the following four techniques: simple control
transfer, simple data transfer, simple stubs, and design for concurrency.
Someoptimizations that may be used to improve theperformance ofdistributed
applications that use an RPC facility are concurrent access to multiple servers, serving
multiple requestssimultaneously, reducing percallworkload ofservers, reply cachingof
idempotent remoteprocedures, properselection oftimeout values, and properdesign of
RPCprotocol specification.
EXERCISES
4.1. What was the primary motivation behind the development of the RPC facility? How does an
RPCfacility make the jobofdistributed applications programmers simpler?
4.2. What are the main similarities anddifferences between the RPC model and the ordinary
procedure call model?
4.3.In theconventional procedure call model, the caller and the callee procedures often useglobal
variables to communicate with each other. Explain why such global variables are not used in
theRPCmodel.
4.4.In RPC, the called procedure may be on the same computer as the calling procedure oritmay
beon adifferent computer. Explain why the term remoteprocedure callis used even when the
calledprocedure is on the same computer as the calling procedure.
4.5.What are the main issues in designing a transparent RPCmechanism? Isitpossible to
achievecomplete transparency of an RPC mechanism? If no, explain why. If yes, explain
how.
4.6.Achieving complete transparency of an RPC mechanism that allows the calJer and callee
processes to be on different computers is nearly impossible due to the involvement of the
network in message communication between the two processes. Suppose an RPC mechanism
is tobedesigned in which the callerand callee processes are always on the same computer.
Is itpossible to achieve complete transparency ofthis RPC mechanism? Give reasons for your
answer.
4.7.What is a "stub"?How are stubs generated? Explain how the use of stubs helps in making an
RPCmechanism transparent.
4.8. A server is designed to perform simple integerarithmetic operations (addition, substraction,
multiplication, and division). Clients interact with this server by using an RPC mechanism.
Describe the contents of the call and reply messages of this RPC application, explaining the
purpose of each component. In case of an error, such as division by zero or arithmetic
overflow, the server must suitably inform the client about the typeof error.
4.9. Write marshaling procedures for both tagged and untagged representations for marshaling the
message contentsofthe RPC application ofExercise 4.8.
4.10. A user-defined program object isa structure consisting ofthe following basic data types inthat
order: a Boolean, an integer, a long integer, and a fixed-length character string of eight
characters. Writemarshaling procedures for both tagged and untagged representations for this
program object. Assume that the RPC software provides marshaling of the basic data types.Chap. 4 • Exercises 225
4.11.ThecallerprocessofanRPCmust wait for a reply from the calleeprocessaftermakinga call.
Explainhow this can actuallybe done.
4.12.Differentiate between statefulandstateless servers.Whydosomedistributed applications use
stateless serversin spite of the fact that statefulserversprovide aneasierprogramming
paradigm and aretypically moreefficient thanstateless servers?
4.13.Suggest asuitable servercreation semantics for each of the following types of
applications:
(a)Aserviceisneededonly once in a while,and thesessionforwhichaclientinteracts with
theserverof thisserviceinvolves theexchange of asinglecall and a singlereplymessage
between theclientandserverprocesses.
(b)Aserviceisneededonly once in a while,and thesessionforwhichaclientinteracts with
theserverofthisservicenormally involves theexchange ofseveralcall and reply
messages between theclientandserverprocesses.
(c)Aservercanservicetherequests ofmultiple clients.
4.14.Aserveris to be sharedbymultiple clients.Describe aschemefordesigning theremote
procedures offeredby theserverso thatinterleaved orconcurrent requests fromdifferent
clientsdo notinterfere with each other.
4.15.Why do most RPC systems supportcall-by-value semantics forparameter passing?
4.16.Discussthesimilarities anddifferences between thefollowing parameter-passing semantics
that may be used in an object-based system:
(a)Call-by-object-reference
(b)Call-by-move
(c)CalJ-by-visit
4.17.Explain why RPC semantics isnormally different from the conventional procedure call
semantics. Clarifythedifferences amongmay-be, last-one, last-of-many, at-least-once, and
exactly-once callsemantics. Explainhow each of these may be implemented.
4.18.Whatisanorphancall?How are orphancallshandledin theimplementation ofthefollowing
types of call semantics:
(a)Last-one callsemantics
(b)Last-of-many callsemantics
(c)At-least-once callsemantics
4.19.Suggestwhethermay-be, last-one, last-of-many, at-least-once, orexactly-once callsemantics
shouldbe used for each ofthefollowing applications (givereasonsforyouranswer):
(a) Formakingarequestto a time serverto get the currenttime.
(b) Formakingarequesttoanode'sresource manager to get the currentstatusofresource
availability of its node.
(c) Forperiodically broadcasting the total numberofcurrentjobsat its node by aprocess
manager in asystemin which the processmanagers ofall nodes mutually cooperate to
share the overallsystemload.
(d) Formakingarequestto acomputation servertocompute the value of an equation.
(e) Formakingarequestto abooking serverto get the currentstatusofavailability of
seats.
(f)Formakingarequestto abooking servertoreservea seat.
(g) Formakingarequestto a file servertoposition theread-write pointerofa file to a
specified position.
(h) Formakingarequestto a file servertoappendarecordto anexistingfile.226 Chap.4 • Remote Procedure Calls
(i)For makinga requesttoa nameservertoget thelocationof a namedobjectin a system
thatdoes notsupportobject mobility.
G)For makingarequesttoa nameserverto getthe locationof a namedobjectin a system
that supportsobject mobility.
4.20.ExplainwhymostRPCsystemsdo notuse acknowledgment messages. Differentiate among
R, RR,andRRAprotocolsfor RPCs.Giveanexampleof anapplicationin whicheachtype
of protocolmay bethe mostsuitableone to use.
4.21.Supposeittakestime T(Tisverylarge)foraservertoprocessanRPCrequest.Eventhough
a clientmakingtheRPCrequestknowsthatit willreceivethereplyfor its requestfromthe
serveronlyafter time T,it willunnecessarily keep waitingfor the replyfrom the serverfor
thisentiredurationin situationswherethe requestmessagedoes notreachthe serverdue to
failureofthe communication linkbetweentheclientandtheserverortheservercrasheswhile
processingtheclient's request.Devisea mechanism toavoidthissituation.Thatis, itshould
bepossibleforaclienttodetectanexceptionconditionandtotakecorrectiveactionasearly
as possible.
4.22.Supposeyou have to design an RPC mechanism forinteraction betweenclients and a file
server,frequently requiringtransferof largevolumeof data in betweenthem. However, the
underlyingnetworkhasalimitationofmaximumpacketsizeof4kilobytes.Supposethetime
to transfera 4..kilobytepacketis 4ms, and the time to do a null RPC (i.e., 0 data bytes)is
0.5ms.IftheaverageamountofdatatransferredforeachRPCrequestis 16 kilobytes, which
of the followingtwo methodswillyou preferto usein yourdesign:
(a) UsingseveralphysicalRPCsforonelogicalRPC,eachphysicalRPC transferring asingle
packetof data
(b) Usinga singleRPCwiththe data transferredas multidatagram messages
4.23. What are the main advantages of an RPC system that allows the binding between a client and
a server to change dynamically? What are the main issues involved in providing this
flexibility?Describea mechanism to handleeach of the issuesmentionedby you.
4.24.A serveris normallydesignedto servicemultipleclientsand is often bound simultaneously
tomultipleclients.Doesasituationeverarisewhenaclientshouldbe simultaneously bound
to multipleservers?If no,explain why.If yes,give twoexamplesof such a situation.
4.25.Discusstherelativeadvantagesand disadvantages ofbindingaclientandaserveratcompile
time,at linktime,and at caJltime.
4.26.Given the interfacenameof a server,discuss the relativeadvantagesand disadvantages of
usingthe broadcastmethodand the methodof usinga nameserverfor locatingthe server.
4.27.WhatiscallbackRPC facility?Giveanexampleof an application wherethisfacilitymaybe
useful. What are the main issues involved in supporting this facility in an RPC system?
Describea mechanism to handleeach of theseissues.
4.28.Give an exampleof an applicationwhereeachof the following facilitiesmay be useful:
(a) BroadcastRPCfacility
(b) MulticastRPCfacility
Describea mechanism to implementeach of these facilities.
4.29.Givethecharacteristics ofapplications forwhichthe batch-mode RPCfacilitymaybe useful.
Whatare themainproblemsin usingthis facility?
4.30.Findoutthedetailsoftheclient..serverbinding mechanism of theHRPCsystem [Bershadet
a1.1987],andexplainhowthechoicesof transportprotocol,data representation, andcontrol
protocolare delayeduntilbindtimein thissystem.Chap. 4 • Bibliography 227
4.31.What was the primary motivation behind the development of the Lightweight RPC(LRPC)
system [Bershadet al. I990]? Describesome of thetechniques usedinthe LRPCsystemthat
makes it more efficient than conventional RPC systems.
4.32.Inaclient-servermodelthat isimplementedbyusinga simpleRPC mechanism,aftermaking
anRPCrequest,aclientkeepswaitinguntilareplyisreceivedfrom theserverfor itsrequest.
Itwould be more efficient to allow the client toperform other jobs while the server is
processing itsrequest (especially when the request processing time is long). Describe three
mechanisms that may be used in this case to allow a client to perform otherjobs while the
server is processing itsrequest.
4.33.Aclient-servermodelisto beimplementedby using anRPCmechanism. Ithasbeenrealized
that a shared server is an expensive resourceof an RPC mechanism becauseit has to service
requestsfrom manyclients.Suggest someguidelinesthat maybe usedfordesigninga shared
server for improving the overall performance of the corresponding RPCmechanism.
BIBLIOGRAPHY
[Almes 1986] Almes, G. T., "The Impact of Language and System on Remote Procedure Call
Design,"In: Proceedings ofthe 6thInternational Conference onDistributed Computing Systems,
IEEE Press, Piscataway,NJ, pp. 414-421 (May 1986).
[Almeset al, 1985]Almes,G.T., Black~A.P.,Lazowska,E. D.~andNoe,1.D., HTheEdenSystem:
ATechnical Review," IEEETransactions on Software Engineering, Vol.SE-Il ~No. 1 ~pp.43-59
(1985).
[Baconand Hamilton 1987]Bacon, J.M.,andHamilton,K.G.,"DistributedComputingwithRPC:
The Cambridge Approach," Technical Report No. 117 ~Computer Laboratory, University of
Cambridge, England (1987).
[Bal et al. 1987] Bal, H. E., Renesse, R., and Tanenbaum, A. S.,"Implementing Distributed
Algorithms Using Remote Procedure Calls," In: Proceedings oftheAFIPSNational Computer
Conference, Chicago, IL, pp. 499-506 (June 1987).
[Bal etal, 1989] Bal, H. E.)Steiner,J.G.~and Tanenbaum,A. S., "Programming Languages for
Distributed Computing Systems," ACMComputing Surveys, Vol.21,No.3,pp.261-322
(1989).
[Bershad etal, 1987]Bershad,B. N.,Ching, D.T.,Lazowska,E. D.~Sanislo,J., andSchwartz, M.~
"A Remote Procedure Call Facility for Interconnecting Heterogeneous Computer Systems,"
IEEETransactions on Software Engineering, Vol.SE-13,No.8,pp.880-894 (1987).
[Bershad et al.1990] Bershad, B. N., Anderson, T. E., Lazowska, E. D., and Levy, H. M.,
"Lightweight Remote ProcedureCall," ACMTransactions onComputer Systems, Vol.8,No.1,
pp.37-55(1990). © ACM, Inc., 1990.
[Birrell1985] Birrell, A. D., "Secure Communication Using Remote Procedure Calls," ACM
Transactions on Computer Systems, Vol. 3~No. I ~pp. 1-14 (1985).
[Birrell and Nelson 1984]Birrell,A.D., andNelson,B.,"Implementing RemoteProcedureCalls,"
ACMTransactions on Computer Systems, Vol.2,No.1,pp.39-59(1984).
[Birrelletal. 1982] Birrell,A. D., Levin, R., Needham,R. M., and Schroeder,M. D., "Grapevine:
An Exercise in Distributed Computing," Communications oftheACM~Vol.25,No.4,pp.
260-274 (1982).228 Chap. 4 • Remote ProcedureCalls
[Black et al. 1986] Black, A., Hutchinson, N., Jul, E., and Levy, H., "Object Structure in the
EmeraldSystem,"In: Proceedings ofthelstACMConference on Object ...Oriented Programming
Systems, Languages, and Applications (OOPSLA ...1986),pp.78-86(1986).
[Black et al. 1987] Black,A., Hutchinson,N., Jul, E., Levy,H., and Carter,L., "Distribution and
AbstractTypesinEmerald," IEEE Transactionson Software Engineering, Vol.SE-13,No. I,pp.
65-76(1987).
[Corbin1991]Corbin, 1.R.,The ArtofDistributed Applications, Springer-Verlag, NewYork,NY
(1991).
[Davison et al, 1992] Davison,A., Drake, K., Roberts, W., and Slater, M., Distributed Window
Systems, A Practical Guide to XlIand OpenWindows, Addison-Wesley, Reading, MA (1992).
[DES 1977] DATAENCRYPTION STANDARD, FIPS Publication 46, National Bureau of
Standards, U.S. Departmentof Commerce, Washington DC(January 1977).
[Gibbons 1987J Gibbons, P B., "A Stub Generator for Multi-language RPC in Heterogeneous
Environment," IEEE Transactions on Software Engineering, Vol.SE-J3, No. I,pp.77-87
(1987).
[Gifford andGlasser1988] Gifford, D., and Glasser, N.,"Remote Pipes and Procedures for
Efficient Distributed Communication," ACMTransactions on Computer Systems, Vol.6,No.3,
pp.258-283 (1988).
[Gimson 1985] Girnson, R., "Call Buffering Service," Technical Report No. 19,Programming
Research Group, Oxford University, Oxford, England (1985).
[Goscinski 1991] Goscinski,A., "Distributed Operating Systems,The Logical Design," Addison­
Wesley,Reading, MA (1991).
[Hamilton 1984] Hamilton, K. G., "A Remote Procedure Call System," Ph.D. Dissertation,
Technical Report No. 70,Computer Laboratory,Universityof Cambridge, England (December
1984).
[Harbinson 1992] Harbinson,S. ~,Modula-S, Prentice-Hall,Englewood Cliffs, NJ (1992).
[Hiltunen andSchlichting 1995] Hiltunen, M. A.,and Schlichting, R. D., "Constructing a
Configurable Group RPC Service," In: Proceedings ofthe 15th International Conference on
Distributed Computing Systems, IEEE Press, Piscataway,NJ (May 1995).
[Hutchinson etal.1989]Hutchinson, N.C.,Peterson, L.L.,Abbott,M.B.,andO'Malley, S., "RPC
in the x-Kernel: Evaluating New Design Techniques," In: Proceedings ofthe 12th ACM
Symposium on Operating Systems Principles, pp. 91-101 (1989).
[Joneset al, 1985]Jones, M.B., Rashid, R.F.,andThompson, M.R.,"Matchmaker:An Interface
SpecificationLanguageforDistributedProcessing,"In: Proceedings ofthe12thACM Symposium
on Principles ofProgramming Languages, pp.225-235 (1985).
[Karger1989] Karger,P.A., "Using Registersto OptimizeCross-DomainCall Performance,"In:
Proceedings ofthe 3rd Conference on Architectural SupportforProgramming Languages and
Operating Systems, pp.194-204 (April 1989).
[Khanna 1994] Khanna, R. (Ed.), Distributed Computing: Implementation and Management
Strategies, Prentice-Hall,EnglewoodCliffs, NJ (1994).
[KimandPurtilo1995]Kim,T.H.,andPurtilo,J. M.,"Configuration-LevelOptimizationof RPC­
Based Distributed Programs," In:Proceedings ofthe 15th International Conference on
Distributed Computing Systems, IEEE Press, Piscataway, NJ(May1995).
[LinandGannon 1985] Lin, K. 1.,and Gannon, J. D., "Atomic Remote Procedure Call," IEEE
Transactions on Software Engineering, Vol.SE-ll,No.10,pp. 1126-1135 (1985).Chap. 4 • Bibliography 229
[Liskov et al, 1981] Liskov, B., Moss,E.,Schaffert, C., Sheifler, R., and Snyder, A., "CLU
Reference Manual," In:Lecture Notes in Computer Science114,Springer-Verlag, Berlin
(1981).
[Liskov and ScheiDer 1983] Liskov, B., and Scheifler, R.,"Guardians andActions: Linguistic
Supportfor Robust, Distributed Programs," ACMTransactions on Programming Languages and
Systems, Vol. 5,No.3,pp.381-404 (1983).
[LiskovandShrira1988] Liskov, B., and Shrira,L.,"Promises: Linguistic SupportforEfficient
Asynchronous Procedure Calls in Distributed Systems," In:Proceedings oftheACM
SIGPLAN'88 Conference onProgramming Language Design and Implementation, Association
forComputing Machinery, New York; NY, pp. 260-267 (June 1988).
[Lockhart Jr.1994]Lockhart, Jr., H. W., OSFDeE:Guide to Developing Distributed Applications,
IEEEComputer SocietyPress, Los Alamitos, CA(J994).
[Nelson 1991] Nelson, G. (Ed.), SystemsProgramming withModula-T, Prentice-Hall, Englewood
Cliffs, NJ (1991).
[Panzieri andSrivastava 1988]Panzieri, F., andSrivastava, S. K.,"Rajdoot: ARemoteProcedure
CallMechanism withOrphan Detection andKilling," IEEE Transactions on Software
Engineering, Vol.SE-14,pp.30-37(1988).
[Rosenberry et al,1992JRosenberry, W., Kenney, D.,and Fisher, G., OSF DISTRIBUTED
COMPUTING ENVIRONM't~1: Understanding DeE',O'Reilly &Associates, Sebastopol, CA
(1992).
[Schroeder andBurrows 1990]Schroeder, M.D.,andBurrows, M.,"Performance ofFirefly
RPC,"A('MTransactions onComputer Systems, Vol. 8,No.1,pp.1-17(1990).
[Shirley et al, 1994] Shirley,J.,Hu,\V.,and Magid, D., Guide to Writing D('EApplications, 2nd
ed.,O'Reilly&Associates, Sebastopol, CA (1994).
[Shrivastava et al,1991]Shrivastava, S., Dixon, G. N., and Parrington, G.D.,"AnOverview of the
ArjunaProgramming System," JEE~'Software (January 1991).
[Smith 1994] Smith, B., "Client/Server Made Easy," BYTE(March 1994).
[Spector 1982]Spector, A. Z.,"Performing RemoteOperations Efficiently on a Local Computer
Network," Communications oftheACM,Vol.25,No.4,pp.246-259 (1982).
[Srivastava andPanzieri 1982]Srivastava, S. K., and Panzieri, F.,"TheDesign of Reliable Remote
Procedure CallMechanism," IEEE Transactions on Computers, Vol. C-31, No. 7 (1982).
[Sun Mlcrosystems 1985]"Remote Procedure CallProtocol Specification," Networking on the Sun
Workstation, SunMicrosystems, Mountain View, CA (1985).
[SunMicrosystems 1990]Network Programming, SunMicrosystems, Mountain View, CA
(1990).
[Tanenbaum and Van Renesse 1988]Tanenbaum, A. S., and Van Renesse, R., "A Critique of the
Remote Procedure CallParadigm," In:Proceedings oftheE'UTECO'88 Conference, Vienna,
Austria,North-Holland, Amsterdam, pp.775-783 (April 1988).
['"fayandAnanda 1990]Tay, B. H., and Ananda, A. L., "A Survey of Remote Procedure Calls,"
Operating Systems Review, Vol. 24, pp. 68-79(1990).
[Walker et al.1990]Walker, E. F.,Floyd, R., and Neves, P., "Asynchronous RemoteOperation
Execution inDistributed Systems," In:Proceedings ofthe 10th International Conference on
Distributed Computing Systems, IEEE Press, Piscataway, NJ, pp.253-259 (1990).
[WilburandBacarisse 1987]Wilbur,S.,andBacarisse, B.,"Building Distributed Systems with
RemoteProcedure Call,"Software Engineering Journal, pp.148-159 (September 1987).
[XeroxCorporation 1981J"Courier: The Remote Procedure CallProtocol," XeroxSystem
Integration Standard XSIS-038 112,Stanford, CT (1981).230 Chap.4 •RemoteProcedure Calls
POINTERS TO818UOGRAPHIES ONTHEINTERNET
I could not find a bibliography dedicated only to Remote Procedure Calls. However, the
following bibliographies containreferences on this topic:
ftp:ftp.cs.umanitoba.calpub/bibliographies/OsIIMMD_IV.html
ftp:ftp.cs.umanitoba.ca/pub/bibliographies/Os/os.html
ftp:ftp.cs.umanitoba.calpub/bibliographieslMisc/misc.l.htmI
ftp:ftp.cs.umanitoba.ca/pub/bibliographieslParalleUJPDC.htmlCHAPTER5
Distributed Shared
Memory
5.1 INTRODUOION
In Chapter 3, it was mentioned that the two basic paradigms for interprocess
communication are as follows:
•Shared-memory paradigm
•Message-passing paradigm
Message-passing systems (described in Chapter3), or systems supporting Remote
Procedure Calls (RPCs) (described in Chapter 4), adhere to the message-passing
paradigm. This paradigm consists of two basic primitives for interprocess
communication :
Send(recipient, data)
Receive(data)
The sending process generates the datato be shared and sends itto the
recipient(s) with which it wants to communicate . The recipient(s) receive the data.
231232 Chap.5 • Distributed SharedMemory
This functionality is sometimes hidden in language-level constructs. For example, RPC
provides automatic message generation and reception according to a procedural
specification. However, the basic communication paradigm remains the same because
thecommunicating processes directly interact with each otherforexchanging the
shared data.
Incontrast to themessage-passing paradigm, the shared-memory paradigm
provides toprocesses in a system with a shared address space. Processes use this
address space in the same way they use normal local memory. That is, processes access
data in the shared address space through the following two basic primitives, of course,
with some variations in the syntax and semantics in different implementations:
data=Read(address)
Write(address, data)
Readreturns the dataitemreferenced byaddress, andwritesets the contents
referenced byaddressto the value of data.
We saw in Chapter 1 that the two major kinds ofmultiple-instruction, multiple­
data-stream (MIMD) multiprocessors that have become popularand gained commer­
cialacceptance are tightly coupled shared-memory multiprocessors and loosely cou­
pleddistributed-memory multiprocessors. The use of a shared-memory paradigm for
interprocess communication is natural for distributed processes running on tightly
coupled shared-memory multiprocessors. However, for loosely coupled distributed­
memory systems, no physically shared memory is available to support the shared­
memory paradigm forinterprocess communication. Therefore, until recently, the
interprocess communication mechanism in loosely coupled distributed-memory multi­
processors was limited only to the message-passing paradigm. But some recent loosely
coupleddistributed-memory systems have implemented a software layer on top of the
message-passing communication system to provide a shared-memory abstraction to the
programmers. Theshared-memory abstraction gives these systems the illusion of
physically shared memory and allows programmers to use the shared-memory
paradigm. The software layer, which is used for providing the shared-memory
abstraction, can beimplemented eitherin anoperating system kernel or in runtime
library routines with proper system kernel support. The term Distributed Shared
Memory (DSM) refers to the shared-memory paradigm applied to loosely coupled
distributed-memory systems [Stumm and Zhou 1990].
As shown in Figure 5.1, DSM provides a virtual address space shared among
processes on loosely coupled processors. That is, DSM is basically an abstraction
thatintegrates the local memory of different machines in a network environment into
a single logical entity shared by cooperating processes executing on multiple sites.
The shared memory itselfexists only virtually. Application programs can use it in
the same way as a traditional virtual memory, except, of course, that processes using
it can run on different machines in parallel. Due to the virtual existence of the
shared memory, DSM is sometimes also referred to as Distributed Shared Virtual
Memory (DSVM).Sec.5.2 • GeneralArchitecture of DSMSystems
Distributed sharedmemory
(existsonly virtually)
Communication Network
Fig. 5.1 Distributed shared memory (DSM).
5.2GENERAL ARCHITEOURE OFDSMSYSTEMS233
The DSM systemsnormally have anarchitecture of the form showninFigure5.1. Each
nodeofthesystemconsists of one or more CPUsand amemory unit. The-nodes are
connected by ahigh-speed communication network. Asimplemessage-passing system
allowsprocesses ondifferent nodes to exchange messages with each other.
The DSM abstraction presents a largeshared-memory space to the processors ofall
nodes. In contrastto the shared physical memory intightlycoupledparallelarchitectures,
thesharedmemoryofDSM exists only virtually. A software memory-mapping manager
routinein each node mapsthe local memory onto the sharedvirtual memory. To facilitate
themapping operation, theshared-memory space is partitioned intoblocks.
Datacachingis awell-known solutiontoaddressmemory access latency. The idea of
datacachingisused inDSM systemstoreducenetworklatency.That is,the main memoryof
individual nodes isused to cachepiecesoftheshared-memory space. The memory-mapping
managerofeach node views itslocal memoryas a bigcacheoftheshared-memory spacefor
itsassociated processors. The basic unit ofcachingis amemory block.
Whenaprocesson a node accesses somedata from a memory block of the shared­
memory space,the local memory-mapping manager takeschargeof itsrequest. If the
memory blockcontaining theaccessed data isresidentin the local memory, the requestis
satisfied bysupplying theaccessed data from the local memory. Otherwise, anetwork
block fault is generated and thecontrolispassedto theoperating system.Theoperating234 Chap.5 • Distributed SharedMemory
system then sends a message to the node on which the desired memory block is located
to get the block. The missing block is migrated from the remote node to the client
process's node and the operating system maps it into the application's address space. The
faultinginstruction is thenrestarted and can now complete. Therefore, thescenario is that
data blocks keep migrating from one node to anotheron demand but no communication
is visible to the user processes. That is, to the user processes, the system looks like a
tightlycoupledshared-memory multiprocessors system in which multipleprocesses freely
read and write the shared-memory atwill,Copiesof datacachedin local memory
eliminate network traffic for a memory access on cachehit, that is, access to an address
whose data is stored in the cache. Therefore, network traffic is significantly reducedif
applications show a high degree oflocalityofdata accesses.
Variations ofthis general approach are used in different implementations depending
onwhetherthe DSM system allows replication and/ormigration ofshared-memory data
blocks.Thesevariations are described inSection5.6.1.
5.3DESIGNANDIMPlEMENTAnON ISSUESOFDSM
Important issues involved in the design and implementation ofDSMsystems are as
folJows:
1. Granularity. Granularity refers to the block size of a DSM system,that is, to the
unitofsharing and the unit ofdatatransferacross the network when a network block fault
occurs.Possible unitsare a few words, a page, or a few pages. Selecting properblock size
is animportant partofthe design ofa DSM system because block size is usually a measure
ofthegranularity ofparallelism explored and theamountof network traffic generated by
network block faults.
2. Structure ofshared-memory space. Structure refers to the layout of the shared data
in memory. The structure oftheshared-memory spaceofa DSM system is normally
dependent on the type of applications that the DSM system is intended to support.
3. Memory coherence and access synchronization. In a DSM systemthat allows
replication ofshared data items, copies ofshared data items may simultaneously be
available in the main memories ofanumberofnodes. In this case, the main problem is
to solve the memory coherence problem that deals with the consistency ofa piece of
shared data lying in the main memories oftwo or more nodes. This problem issimilarto
that which arises with conventional caches [Smith 1982], in particular withmulticache
schemes forshared-memory multiprocessors [Frank 1984, Goodman 1983, Katz et al.
1985. Yen et al. 1985]. Since different memory coherence protocols makedifferent
assumptions and trade-offs, the choiceis usually dependent on thepatternof memory
access. The terms coherence andconsistency are used interchangeably in the literature.
In a DSM system, concurrent accesses to shared data may be generated. Therefore,
amemorycoherence protocol alone is not sufficient tomaintain theconsistency of shared
data. In addition, synchronization primitives, such assemaphores, event count, and lock,
are needed to synchronize concurrent accesses to shared data.Sec.5.4 • Granularity 235
4. Datu location and access. To share data in a DSMsystem, it should be possible
to locate and retrieve the data accessed bya user process. Therefore, a DSMsystem must
implement some form of data block locating mechanism in order to service network data
block faults to meet the requirement of the memory coherence semantics being used.
5.Replacement strategy. If the local memory of a node is full, a cache miss at that
node implies not only a fetch of the accessed data block from a remote node but also a
replacement. That is, a data block of the local memory must be replaced by the new data
block.Therefore, a cachereplacement strategy is also necessary in the design of a DSM
system.
6. Thrashing. In a DSM system, data blocks migrate between nodes on demand.
Therefore, iftwo nodes compete for write access to a single data item, the
corresponding data block may be transferred back and forth at such a high rate that no
real work can get done. A DSM system must use a policy to avoid this situation
(usually known as thrashing).
7. Heterogeneity. The DSM systems built for homogeneous systems need not
address the heterogeneity issue. However, if die underlying system environment is
heterogeneous, the DSM system must be designed to take care of heterogeneity so thatit
functions properly with machines having different architectures.
These design and implementation issues of DSM systems are described insubsequent
sections.
5.4GRANULARITY
One of the most visible parameters tobe chosen in the design of a DSM system is the
block size. Several criteriaforchoosing thisgranularity parameter aredescribed below.
Just as with paged main memory, there are a number of trade-offs and no single criterion
dominates.
5.4.1FactorsInfluencing 810ckSizeSelection
In a typical loosely coupledmultiprocessor system, sending large packets of data (for
example, 4 kilobytes) is not much more expensive than sending small ones (for example,
256 bytes) [Li and Hudak 1989J.This is usually due to the typical software protocols and
overhead of the virtual memory layer of the operating system. This fact favors relatively
large block sizes. However, other factors that influence the choice of block size are
described below [Nitzberg and Virginia Lo 1991].
1. Paging overhead. Because shared-memory programs provide locality of refer­
ence, a process is likely to access a large region of its shared address space in a small
amount of time. Therefore, pagingoverhead is less for large block sizes as compared to
the paging overhead for small block sizes.236 Chap.5 • Distributed SharedMemory
2. Directory size. Another factoraffecting thechoiceofblock size is the need to
keepdirectory information abouttheblocksin the system. Obviously, thelargerthe
blocksize, the smaller the directory. This ultimately resultsinreduced directory
management overhead forlargerblock sizes.
3. Thrashing. Theproblemofthrashing mayoccurwhen data items in the same data
blockare being updatedbymultiple nodes at the same time, causinglargenumbersofdata
blocktransfers amongthe nodes withoutmuchprogress in theexecution oftheapplication.
Whileathrashing problemmayoccurwith any block size, itismore likely with largerblock
sizes, asdifferent regionsinthe same block may be updatedbyprocesses ondifferent nodes,
causingdatablock transfers,that are not necessary withsmallerblocksizes.
4. False sharing. Falsesharingoccurswhen two different processes access two
unrelated variables that reside in the same datablock(Fig. 5.2). In such a situation, even
thoughtheoriginalvariables are notshared,thedatablockappearsto besharedby the two
processes. The larger is the blocksize, the higheris theprobability of falsesharing,due
to the fact that the same data block may containdifferent datastructures that are used
independently. Notice that false sharingofablockmay lead to a thrashing problem.
Process P1accesses.....-----f p
data in this area 1
ProcessP2accesses..._----1:
data in this area P2
Adata block
5.4.1UsingPage51z8as810ckSizeFig.5.2 False sharing.
Therelativeadvantages anddisadvantages ofsmall and large block sizes make it difficult
for a DSM designer todecideon aproperblocksize.Therefore, asuitablecompromise in
granularity, adoptedbyseveralexistingDSMsystems, is to use the typicalpage size ofa
conventional virtualmemory implementation as the block size ofa DSM system. Using
page size as the blocksizeofa DSMsystemhas thefollowing advantages [Li and Hudak
1989]:
1. Itallowsthe useofexisting page-fault schemes (i.e.,hardware mechanisms) to
triggera DSM page fault. Thus memory coherence problems canberesolved in
page-fault handlers.Sec.5.5 • StructureofShared-Memory Space 237
2. Itallowstheaccessrightcontrol(needed for each sharedentity)to bereadily
integrated into thefunctionality ofthememory management unitofthesystem.
3. As long as a page can fit into a packet,page sizes do not imposeundue
communication overhead at the time ofnetwork pagefault.
4.Experience hasshownthat a page size is a suitabledataentityunit with respect
tomemory contention.
5.5STRUauRE OFSHARED-MEMORY SPACE
Structure definestheabstract view of the shared-memory spaceto bepresented to the
application programmers ofa DSMsystem.Forexample, theshared-memory spaceofone
DSMsystemmayappearto itsprogrammers as astorage for words, whilethe
programmers ofanotherDSMsystemmay view its shared-memory space as a storagefor
dataobjects.Thestructure andgranularity of a DSM systemarecloselyrelated[Nitzberg
and Virginia Lo 1991]. The three commonly usedapproaches forstructuring theshared­
memory space of a DSMsystemare[Nitzberg andVirginia Lo 1991] as follows:
1. Nostructuring. Most DSM systemsdo notstructure theirshared-memory space.
Inthesesystems, theshared-memory space is simplyalineararray of words. An
advantage ofthe useofunstructured shared-memory spaceis thatitisconvenient to
chooseanysuitablepage size as the unit of sharingand a fixed grain size may be used for
allapplications. Therefore, it issimpleand easy to designsuch a DSM system. It also
allowsapplications toimposewhatever datastructures they want on the sharedmemory.
IVY [Li and Hudak1989JandMether[Minnich andFarber1989] use this approach.
2.Structuring by data type. In thismethod, theshared-memory space is structured
eitheras acollection ofobjects(as inClouds[Dasgupta eta1.1991] and Orca [Bal et a1.
1992]) or as a collection ofvariables in thesourcelanguage (as inMunin[Bennett et al.
1990] and Midway [Bershad et al. 1993]). The granularity in such DSM systems is an
objector avariable. But since the sizes of the objectsand data types vary greatly, these
DSMsystems usevariable grain size to match the size of the object/variable being
accessed by theapplication. The use of variable grain size complicates thedesignand
implementation ofthese DSM systems.
3.Structuring as adatabase. Another methodis tostructure thesharedmemory like
adatabase. Forexample, Linda[Carriero andGelernter 1989] takes this approach. Its
shared-memory space is ordered as anassociative memory (amemory addressed by
contentratherthanbyname or address) calledatuplespace ~whichis acollection of
immutable tupleswith typed data items in theirfields. A set of primitives that can be
addedto any base language (such as C and FORTRAN) areprovided to placetuplesin the
tuple space and to read or extractthemfromtuplespace. To perform updates, old data
items in the DSM are replaced by new data items. Processes selecttuples by specifying
thenumberoftheirfields and their values or types. Although thisstructure allowsthe
location of data to be separated from its value, it requires programmers to usespecial238 Chap.5 •Distributed SharedMemory
access functions to interact with the shared-memory space. Therefore, access to shared
data isnontransparent. In most other systems, access to shared data is transparent.
5.6CONSISTENCY MODELS
Consistency requirements vary from application to application [Bennett et a1.1990,
Cheriton 1986,Garcia-Molina and Wiederhold 1982]. A consistency modelbasically
refers to the degree of consistency that has to be maintained for theshared-memory data
for the memory to work correctly for a certain set ofapplications. It isdefinedas a set of
rules that applications must obey ifthey want the DSM system to. providethe degree of
consistency guaranteed by theconsistency model. Several consistency models have been
proposed in the literature. Ofthese, the main ones are described below.
It may be noted here that the investigation of newconsistency models is currently an
active area ofresearch. The basic idea is to invent a consistency model that can allow
consistency requirements to be relaxed to a greaterdegree than existing consistency
models, with the relaxation done in such a way that a set ofapplications can function
correctly. This helps in improving theperformance of theseapplications because better
concurrency can be achieved by relaxing the consistency requirement. However,
applications that depend on a stronger consistency model may not perform correctly if
executed in a system that supports only a weaker consistency model. This is because if a
systemsupports thestronger consistency model, then the weaker consistency model is
automatically supported but the converse is not true.
StrictConsistency Model
Thestrictconsistency modelis thestrongest form of memory coherence, having the most
stringent consistency requirement. Ashared-memory system is said to support the strict
consistency model if the.valuereturned by a read operation on a memory address isalways
the same as the value written by the most recent write operation to that address,
irrespective of the locations of the processes performing the read and write operations.
That is, all writes instantaneously become visible to all processes.
Implementation ofthe strict consistency model requires the existence of an absolute
global time so that memoryread/write operations can becorrectly orderedto make the
meaning of "mostrecent" clear. However, as explained inChapter 6, absolute
synchronization of clocks of all the nodes of a distributed system is not possible.
Therefore, theexistence of an absolute global time in a distributed system is also not
possible. Consequently, implementation of the strict consistency model for a DSM system
ispractically impossible.
Sequential Consistency Model
Thesequential consistency modelwas proposed by Lamport [1979]. A shared-memory
system is said to support the sequential consistency model if all processes see the same
order of all memory access operations on the shared memory. The exact order in which theSec.5.6 • Consistency Models 239
memory access operations areinterleaved does not matter. That is, ifthe three operations
read('1),write(WI)'read('2)areperformed on amemory address in that order, any of
theorderings ('1,WI''2),('"'2,WI),(w.,'"'2),(W.,'2''1),(r2''1,WI),(r2'WI''1)
of the three operations isacceptable provided allprocesses see the same ordering. If one
process sees one of the orderings of the three operations andanotherprocess sees a
different one, thememory is not asequentially consistent memory. Note here that the only
acceptable ordering for a strictly consistent memory is (rl'WI,'2)'
Theconsistency requirement ofthesequential consistency model is weakerthan that
of the strict consistency model because the sequential consistency model does not
guarantee that a read operation on aparticular memory addressalways returns the same
value as written by the most recent write operation to that address. As a consequence, with
asequentially consistent memory, running a program twice may not give the same result
in the absence of explicitsynchronization operations. Thisproblem does not exist in a
strictlyconsistent memory.
ADSMsystemsupporting thesequential consistency model can be implemented by
ensuring that nomemory operation is started until all the previous ones have been
completed. Asequentially consistent memory provides one-copy/single-copy semantics
becauseall theprocesses sharinga memorylocationalways see exactly the same contents
stored in it. This is the most intuitively expected semantics for memory coherence.
Therefore, sequential consistency isacceptable by most applications.
Causal Consistency Model
Thecausalconsistency model,proposed by Hutto and Ahamad [1990], relaxes the
requirement of thesequential consistency model for betterconcurrency. Unlike the
sequential consistency model, in the causal consistency model, all processes see only
those memory reference operations in the same (correct) orderthat arepotentially causally
related.Memory reference operations that are not potentially causally related may be seen
bydifferent processes in different orders. A memory reference operation (read/write) is
said to be potentially causally related to anothermemory reference operation if the first
one might have been influenced in any way by the second one. For example, if a process
performs a readoperation followed by a write operation, the write operation ispotentially
causally related to the read operation becausethecomputation of the value written may
havedepended in some way on the value obtained by the read operation. On the other
hand, a write operation performed by one process is not causally related to a write
operation performed byanotherprocess if the first process has not read eitherthe value
written by the second process or any memory variable that was directlyorindirectly
derived from the value written bythe second process.
A shared memory system is said to support the causal consistency modelifall write
operations that are potentially causally related are seen by all processes in the same
(correct) order. Write operations that are not potentially causally related may be seen by
different processes indifferent orders. Note that "correct order"means that if a write
operation (w2)iscausally related to anotherwriteoperation (Wi),theacceptable orderis
(WI'w2)becausethe value written by W2might have been influenced in some way by the
value written by WI'Therefore, (w2'WI)is not an acceptable order.240 Chap.5 •Distributed SharedMemory
Obviously, in the implementation ofashared-memory systemsupporting the causal
consistency model, there is a need to keep track ofwhich memory reference operation is
dependent on which other memory reference operations. This can be done by constructing
andmaintaining adependency graph for the memory access operations.
Pipelined Random-Access Memory Consistency Model
Thepipelined random-access memory (PRAM) consistency model, proposed by Lipton
andSandberg [1988],provides aweakerconsistency semantics than the consistency
modelsdescribed so far. It only ensuresthat all write operations performed by a single
processare seen by all otherprocesses in the order in which they were performed asifall
the write operations performed by a single processare in a pipeline. Writeoperations
performed bydifferent processes may be seen by different processes indifferent orders.
Forexample, ifWIlandWl2are twowriteoperations performed by aprocessPIinthat
order, and w21andW22are two write operations performed by aprocess P2in that order,
aprocessP3may see them in the order[(WII,WI2),(W21'W2Z)]andanotherprocessP4
may see them in the order [(wz.,WZ2),(WIJ'w,z)].
ThePRAMconsistency model is simple and easy to implement and also has good
performance. It can be implemented by simply sequencing the write operations
performed ateachnodeindependently ofthe write operations performed onother
nodes. It leads to betterperformance than the previous modelsbecauseaprocessneed
not wait for a write operation performed by it tocomplete beforestartingthe next one
since all write operations ofa single process are pipelined. Noticethat insequential
consistency allprocesses agree on the same order of memory reference operations, but
inPRAMconsistency allprocesses do not agree on the same orderofmemory
reference operations. Therefore, for theexample given above, either[(WIl'WIZ), (WZlt
W22)]or [(W21,W22),(wJ"WIZ)]is anacceptable ordering forsequential consistency
but not both. That is, unlike PRAM consistency, bothprocesses P3andP4must agree
on the same order.
Processor Consistency Model
Theprocessor consistency model, proposed byGoodman [1989], is very similarto the
PRAMconsistency model with an additional restriction ofmemory coherence. That is, a
processor consistent memory is bothcoherent andadheresto thePRAMconsistency
model.Memory coherence means that for any memory locationallprocesses agree on the
sameorderofall writeoperations to that location. In effect, processor consistency ensures
that all write operations performed on the same memory location (nomatterby which
processthey areperformed) are seen by all processes in the same order. This requirement
is inadditionto therequirement imposed by the PRAM consistency model.Therefore, in
theexample given for PRAM consistency, ifWIZandW22are write operations for writing
to the same memorylocationx,allprocesses must see them in the same order-wlZ before
W22orW22before W12.This means that for processor consistency bothprocesses P3and
P4must see the write operations in the same order, which may be either[(WII'WIZ),(WZl'
W22)]or[(W21'W22),(Wll'WJ2)].Notice that, for this example, processor consistency andSec.5.6 • Consistency Models 241
sequential consistency lead to the same final result, but this may not be true for other
cases.
WeakConsistency Model
Theweakconsistency model,proposed by Dubois et a1.[1988], is designed to take
advantage of the following two characteristics common to many applications:
1. It is not necessary to show the changein memory done by every write operation
to other processes. The results of several write operations can becombined and sent to
otherprocesses only when they need it.Forexample, when a process executes in a critical
section, other processes are notsupposed to see the changes made by the process to the
memory until the processexits from the critical section. In this case, all changesmade to
the memory by the processwhile it is in its critical section need be made visible to other
processes only at the time when the process exits from the critical section.
2.Isolatedaccesses to shared variables are rare. That is, in many applications, a
process makes several accesses to a set of shared variables and then no access at all to the
variables in this set for a long time.
Bothcharacteristics imply that better performance can beachieved ifconsistency is
enforced on a group of memory reference operations rather than on individual memory
reference operations. This is exactly the basic idea behind the weak consistency model.
The main problem inimplementing this idea is determining how the system can
know that it is time to show the changes performed by a process to other processes since
this time is different for different applications. Since there is no way for the system to
know this on its own, the programmers are asked to tell this to the system for their
applications. For this, a DSMsystem that supports the weak consistency model uses a
special variable called a synchronization variable. Theoperations on it are used to
synchronize memory. That is, when a synchronization variable is accessed by aprocess,
the entire (shared) memory is synchronized by making all the changes to the memory
made by all processes visible to all other processes. Note that memory synchronization in
a DSM system will involve propagating memory updates done at a node to all other nodes
having a copy ofthe same memory addresses.
Forsupporting weak consistency, the following requirements must be met:
1. Allaccesses tosynchronization variables must obey sequential consistency
semantics.
2. Allprevious writeoperations must becompleted everywhere before an access to
asynchronization variable is allowed.
3. Allprevious accesses to synchronization variables must be completed before
access to a nonsynchronization variable is allowed.
Note that the weak consistency modelprovides betterperformance at the cost of
puttingextraburden on the programmers.242 Chap.5 • DistributedSharedMemory
ReleaseConsistency Model
We saw that in the weak consistency model the entire (shared) memory is synchronized
when asynchronization variableisaccessed by a process, and memory synchronization
basically involves the following operations:
1. All changes made to the memory by the process are propagated to other nodes.
2. All changes made to the memory by other processes are propagated from other
nodes to the process's node.
A closer observation shows that this is not really necessary because the first
operation need only be performed when the process exits from a critical section and
the second operation need only be performed when the process enters a critical section.
Since a single synchronization variable is used in the weak consistency model, the
system cannot know whether a process accessing a synchronization variable is entering
a critical section or exiting from a critical section. Therefore, both the first and second
operations are performed on every access to a synchronization variable by a process.
For better performance, the releaseconsistency model[Gharachorloo et al. 1990]
provides a mechanism to clearly tell the system whether a process is entering a critical
section or exiting from a critical section so that the system can decide and perform only
either the first or the second operation when a synchronization variable is accessed by
a process. This is achieved by using two synchronization variables (called acquireand
release) instead of a single synchronization variable. Acquireis used by a process to
tell thesystemthatitisabouttoenteracriticalsection,so that the systemperforms
only the second operation when this variable is accessed. On the other hand, release
is used by a process to tell the system that it has justexited a critical section, so that
the system performs only the first operation when this variable is accessed. Pro­
grammers are responsible for putting acquireandreleaseat suitable places in their
programs.
Release consistency may also be realized by using the synchronization mechanism
based on barriers instead of critical sections. A barrierdefines the end of a phase of
execution of a group of concurrently executing processes. All processes in the group must
complete their execution up to a barrier before any process is alJowed to proceed with its
execution following the barrier. That is, when a process of a group encounters a barrier
during its execution, itblocks until all other processes in the group complete their
executions up to the barrier. When the last process completes its execution up to the
barrier, all shared variables are synchronized and then all processes resume with their
executions. Therefore, acquireisdeparture from abarrier, and releaseiscompletion of the
execution of the last process up to a barrier.
A barrier can be implemented by using a centralized barrier server. When a barrier
is created, it is given a count of the number of processes that must be waiting on it before
they can all be released. Each process of a group of concurrently executing processes
sends a message to the barrier server when it arrives at a barrier and then blocks until a
reply is received from the barrier server.The barrier server does not send any replies until
all processes in the group have arrived at the barrier.Sec.5.6 • Consistency Models
Forsupporting releaseconsistency, the following requirements must be met:243
1. Allaccesses toacquireandreleasesynchronization variables obey processor
consistency semantics.
2. Allprevious acquires performed by aprocessmust be completed successfully
before the process is allowed to perform a data access operation on the
memory.
3. Allprevious data access operations performed by a process must be completed
successfully before a releaseaccess done by the processis allowed.
Note that acquires andreleasesof locks of different critical regions (or barriers) can
occurindependently of each other. Gharachorloo et al.[1990]showed that ifprocesses use
appropriate synchronization accesses properly, a release consistent DSM system will
producethe same results for an application as that if the application wasexecuted on a
sequentially consistent DSM system.
Avariation of release consistency islazy release consistency, proposed by Keleher et
al. [1992], and is more efficient than the conventional release consistency. In the
conventional approach, when a process does a releaseaccess, the contents of all the
modified memory locations at theprocess's node are sent to all other nodes that have a
copy of the same memory locations in their local cache. However, .in the lazy approach,
themodifications are not sent to other nodes at the time of release. Rather, these
modifications are sent to other nodes only on demand. That is, when a process does an
acquireaccess, all modifications of other nodes are acquired by the process's node.
Therefore, themodifications that were to be sent to this node at the time of releaseaccess
will be received by the node now (exactly when it is needed there). Lazy release
consistency hasbetterperformance because in this method no network traffic is generated
at all until an acquireaccessisdonebyaprocessatsomeothernode.
Discussion of Consistency Models
Inthedescription above, wesaw some of the main consistency models. Several others have
beenproposed in the literature. A nice overview of theconsistency models can be found in
[Mosberger 1993].It is difficult to grade the consistency models based on performance
becausequitedifferent results are usually obtained fordifferent applications. That is, one
application may have good performance for one model, but anotherapplication may have
goodperformance for some other model. Therefore, in the.design of a DSM system, the
choice of a consistency model usually dependson several other factors, such ashow easy is
ittoimplement, how close isits semantics to intuition, how much concurrency does itallow,
and how easy is itto use (does it impose extra burden on the programmers).
Among the consistency modelsdescribed above, strict consistency is never used in
the design of a DSM system because its implementation is practically impossible. The
mostcommonly used model in DSM systems is the sequential consistency modelbecause
it can be implemented, it supports the most intuitively expected semantics for memory
coherence, and it does not impose any extra burden on the programmers. Another244 Chap.5 •Distributed SharedMemory
important reason for its popularity is that a sequentially consistent DSM system allows
existing multiprocessor programs to be run on multicomputer architectures without
modification. This is because programs written for multiprocessors normally assume that
memory is sequentially consistent. However, it is very restrictive and hence suffers from
thedrawback of low concurrency. Therefore, several DSM systems are designed to use
otherconsistency models that are weaker than sequential consistency.
Causal consistency, PRAM consistency, processor consistency, weak consistency,
and release consistency are the main choices in the weaker category. The main problem
with the use of causal consistency, PRAM consistency, and processor consistency models
in the design of a DSM system is that they do not support the intuitively expected
semantics for memory coherence because different processes may see different sequences
ofoperations. Therefore, with these three models it becomes the responsibility of the
programmers to avoid doing things that work only if the memory is sequentially
consistent. In this respect, these models impose extra burden on the programmers.
Weak consistency and release consistency models, which use explicitsynchroniza­
tion variables, seem more promising for use in DSM design because they provide better
concurrency and also support the intuitively expected semantics. The only problem with
theseconsistency models is that they require the programmers to use the synchronization
variables properly. This imposes some burden on the programmers.
Note that one of the main reasons for taking all the trouble to implement aD5M
system is to support the shared-memory paradigm to make programming of distributed
applications simpler than in the message-passing paradigm. Therefore, some DSM system
designers are of the opinion that no extra burden should be imposed on the programmers.
Designers having this view prefer to use the sequential consistency model.
5.6.1Implam.ntlng Sequential Conslst.ncy Model
We saw above that the most commonly used consistency model in DSM systems is the
sequential consistency model. Hence, a description of the commonly used protocols for
implementing sequentially consistent D5M systems is presented below. A protocol for
implementing arelease-consistent DSM system will be presented in the next section.
Protocols forimplementing the sequential consistency model in a DSM system
depend to a great extent on whether the DSM system allows replication and/or migration
ofshared-memory data blocks. The designer of a DSM system may choose from among
the following replication and migration strategies [Stumm and Zhou 1990]:
1.Nonreplicated, nonmigrating blocks (NRNMBs)
2.Nonreplicated, migrating blocks (NRMBs)
3. Replicated, migrating blocks (RMBs)
4. Replicated, nonmigrating blocks (RNMBs)
The protocols that may be used for each of these categories are described below.The
data-locating mechanisms suitable for each category have also been described. Several of
the ideas presented below were first proposed and used in the IVY system [Li 1988].Sec.5.6 • Consistency Models 245
Nonreplicated, Nonmigrating Blocks
This is the simplest strategy forimplementing asequentially consistent DSMsystem.
Inthis strategy, eachblockof thesharedmemory has a single copy whose location is
alwaysfixed.Allaccessrequests to ablockfrom any node are sent to the owner node
ofthe block, which has the only copy ofthe block. On receiving arequestfrom aclient
node, the memory management unit(MMU) andoperating systemsoftware of the
ownernodeperform the access requeston the block and return a response to theclient
(Fig. 5.3).
Clientnode
(sends request and
receives response)
RequestOwner node of the block
(receives request, performs data
access, and sends response)
Response
Fig. 5.3 Nonreplicated, nonmigrating blocks(NRNMB) strategy.
Enforcing sequential consistency istrivialinthis case becausea node having a shared
block can merely perform all the access requests (on the block) in the orderitreceives
them.
Although themethodis simple and easy to implement, it suffers from the following
drawbacks:
•Serializing data access createsabottleneck.
•Parallelism, which is a majoradvantage ofDSM, is not possible with this
method.
Data Locating in the NRNMB Strategy. TheNRNMB strategy has the
following characteristics:
1.Thereis a single copy ofeach block in the entiresystem.
2. Thelocation of ablockneverchanges.
Basedon these characteristics, the bestapproach forlocatingablockin this case is
to use asimplemapping function to map a blockto a node. When a fault occurs,the fault
handlerofthefaultingnode uses the mapping function to get the locationoftheaccessed
block and forwards the access requestto that node.246 Chap.5 • Distributed SharedMemory
Nonreplicated, Migrating Blocks
Inthis strategy each block of the shared memory has a single copy in the entire system.
However, each access to a block causes the block to migrate from its current node to the
node from where it is accessed. Therefore, unlike the previous strategy in which the owner
node of a block always remains fixed, in this strategy the owner node of a block changes
as soon as the block is migrated to a new node (Fig. 5.4). When a block is migrated away,
it isremoved from any local address space it has been mapped into. Notice that in this
strategy only the processes executing on one node can read or write a given data item at
anyonetime.Therefore the method ensures sequential consistency.
Clientnode
(becomes newownernode of
block after its migration)Ownernode
(owns the block before
itsmigration)
Block request0==0
Blockmigration
Fig.5.4 Nonreplicated, migrating blocks (NRMB) strategy.
The method has the following advantages [Stumm and Zhou 1990]:
1.Nocommunication costs are incurred when a process accesses data currently held
locally.
2. It allows the applications to take advantage of data access locality. If an
application exhibits high locality of reference, the cost of data migration is
amortized over multiple accesses.
However, the method suffers from the following drawbacks:
1. It is prone to thrashing problem. That is, a block may keep migrating frequently
from one node to another, resulting in few memory accesses between migrations
and thereby poor performance.
2. Theadvantage ofparallelism cannotbe availed in this method also.
DataLocating in theNRMBStrategy. In the NRMB strategy, although there
is a single copy ofeach block, the location of a block keeps changing dynamically.
Therefore, oneofthe following methods may beused in this strategy to locate a block:
1. Broadcasting. In this method, each node maintains an owned blocks table that
contains an entry for each block for which the node is the current owner (Fig. 5.5). WhenSec. 5.6 • Consistency Models
Node 1Node boundary
NodeINode boundary
NodeAt247
Block address
(changes dynamically)
Contains an entry for
each block for which
this node is the current
owner
Owned blocks tableBlock address
(changes dynamically)
Contains an entry for
each block for which
this node is the current
owner
Owned blocks tableBlock address
(changes dynamically)
Contains an entry for
each block for which
this node ;sthe current
owner
Owned blocks table
Fig. 5.5 Structure andlocations ofownedblockstable in the broadcasting
data-locating mechanism for NRMB strategy.
a fault occurs, the fault handlerof the faulting node broadcasts aread/write request on the
network. The node currently having the requested block then responds to the broadcast
request by sendingthe block to the requesting node.
A major disadvantage of thebroadcasting algorithm is that it does not scale well.
When arequestisbroadcast, notjustthe node that has the requested block but all nodes
must process the broadcast request. This makes the communication subsystem a potential
bottleneck. Thenetwork latency of a broadcast may also require accesses to take a long
time tocomplete.
2.Centralized-server algorithm. In this method, a centralized server maintains a
block table that contains the location information for all blocks in the shared-memory
space (Fig. 5.6). The location and identity of the centralized server is well known to all
nodes.
When a fault occurs,the faulthandlerof the faulting node (N)sends a request for the
accessed block to the centralized server. The centralized server extracts the location
information oftherequested block from the block table, forwards the request to that node,
andchangesthe location information inthecorresponding entry of the block table to node
N.Onreceiving the request, the currentownertransfers the block to node N,which
becomes the newownerof the block.
Thecentralized-server method suffers from two drawbacks: (a) thecentralized server
serializes location queries, reducing parallelism, and (b) the failure of the centralized
serverwill cause the DSM system to stop functioning.
3.Fixeddistributed-server algorithm. The fixed distributed-server scheme is a direct
extension of thecentralized-server scheme. It overcomes the problems of the centralized­
serverschemebydistributing the role of the centralized server.Therefore, in this scheme,
there is a block manager on several nodes, and each block manager is given a248
Node 1Nodeboundary
NodeINodeboundary
NodeIfChap.5 •Distributed SharedMemory
Block Owner
address node
(remains (changes
fixed) dynamically)
Containsanentryfor
eachblockinthe shared-
memoryspace
Blocktable
Centralized serverFig. 5.6 Structure and location of block table
in thecentralized-server data­
locating mechanism for NRMB
strategy.
predetermined subset of data blocks to manage (Fig. 5.7). The mapping from data blocks
to block managers and their corresponding nodes is described bya mapping function.
Whenever a fault occurs, the mapping function is used bythe faulthandlerof the faulting
node to find out the node whose block manager is managing the currently accessed block.
Then a request for the block is sent to the block manager of that node. The block manager
handles the request exactly in the same manner as that described for thecentralized-server
algorithm.
Nodeboundary
Node1 NodeINodeboundary
NodeIf
Block Owner
address node
(remains (changes
fixed) dynamically)
Containsentriesfora
fixedsubsetofallblocks
intheshared-memory
space
Blocktable
BlockmanagerBlock Owner
address node
(remains (changes
fixed) dynamically)
Containsentriesfora
fixedsubsetofallblocks
intheshared-memory
space
Blocktable
BlockmanagerBlock Owner
address node
(remains (changes
fixed) dynamically)
Containsentriesfora
fixedsubsetofallblocks
intheshared-memory
space
Blocktable
Blockmanager
Flg.5.7 Structure and locations of block table in the fixed distributed-server
data-locating mechanism for NRMB strategy.Sec. 5.6 • Consistency Models 249
4. Dynamic distributed-server algorithm. This scheme does not use any block
manager and attempts to keep track of the ownership information of all blocks in each
node. For this, each node has a block table that contains the ownership information for all
blocks in the shared-memory space (Fig. 5.8). However, the information contained in the
ownership field is not necessarily correct at all times, but if incorrect, it at least provides
thebeginning of a sequence of nodes to be traversed to reach the true owner node of a
block.Therefore, this field gives the node a hint on the location of the owner of a block
and hence is called the probable owner.
Node1Nodeboundary
NodeINodeboundary
NodeM
Block Probable
address node
(remains (changes
fixed) dynamically)
Containsanentryfor
eachblockintheshared-
memoryspace
BlocktableBlock Probable
address node
(remains (changes
fixed) dynamically)
Containsanentryfor
eachblockintheshared-
memoryspace
BlocktableBlock Probable
address node
(remains (changes
fixed) dynamically)
Containsanentryfor
eachblockinthe shared-
memoryspace
Blocktable
(f'ig.5.8Structure andlocations of block table in the dynamic distributed-server
data-locating mechanism for NRMB strategy.
When a fault occurs, the faulting node (N)extracts from its local block table the node
information stored in the probable owner field of the entry for the accessed block. It then
sends a request for the block to that node. If that node isthe true owner of the block, it
transfers the block to node Nand updates the location information of the block in its local
block table to node N.Otherwise, it looks up its local block table, forwards the request to
the node indicated in theprobable-owner field of the entry for the block, and updates the
value of this field to node N.When node Nreceives the block, it becomes the new owner
of the block.
Replicated, Migrating Blocks
A major disadvantage of thenonreplication strategies is lack of parallelism because only
the processes on one node can access data contained in a block at any given time. To
increaseparallelism, virtually all DSM systems replicate blocks. With replicated blocks,
readoperations can be carried out in parallelat multiple nodes by accessing the local copy
of the data. Therefore, the average cost of read operations is reduced because no250 Chap.5 • Distributed SharedMemory
communication overhead isinvolved if areplicaofthe data exists at the local node.
However, replication tends toincrease the costofwriteoperations becausefor a write to
ablockall itsreplicas must be invalidated orupdated tomaintain consistency.
Nevertheless, if theread/write ratio is large, the extra expensefor the write operations may
be more than offset by the loweraveragecostofthe read operations.
Replication complicates thememory coherence protocol due to the requirement of
keepingmultiple copiesofablockconsistent. The two basic protocols that may be used
forensuring sequential consistency in this case are as follows:
1.Write-invalidate. In thisscheme, aJlcopiesofa pieceofdataexceptone are
invalidated before a write can beperformed on it.Therefore, when a write fault occurs
at a node, its fault handlercopiestheaccessed block from one oftheblock'scurrent
nodes to its own node, invalidates allothercopiesofthe block by sendinganinvalidate
message containing the block addressto the nodes havinga copyofthe block, changes
theaccessofthe local copy ofthe block to write, and returns to the faultinginstruction
(Fig. 5.9). Afterreturning, the node "owns"that block and can proceed with the write
operation andotherread/write operations until the block ownership isrelinquished to
someothernode. Notice that in this method, afterinvalidation ofa block, only the node
thatperforms the write operation on the block holds the modified versionofthe block.
Nodeshavingvalidcopies
ofthedata brockbefore
writeoperation
ellenlnode
(hasthevalid cop~
ofthedatablockafter
writeoperation)
Fig.5.9 Write-invalidate memory coherence approach for replicated. migrating
blocks (RMB) strategy.Sec. 5.6 • Consistency Models 251
Ifoneofthenodes that had a copy ofthe block before invalidation tries toperform
amemory accessoperation (read/write) on the block after invalidation, a cache miss
willoccurand the fault handlerof that node will have to fetch the blockagain from
a node having a valid copy of the block. Therefore theschemeachieves sequential
consistency.
2.Write-update. In thisscheme, a writeoperation iscarriedout byupdating all
copiesof the data on which the write is performed. Therefore, when a write fault occurs
at a node, the fault handlercopies theaccessed block from one oftheblock'scurrentnodes
to its own node, updatesallcopiesof the block by performing the write operation on the
local copy of the block and sendingthe address of the modified memory location and its
new value to the nodes having a copy of the block, and then returns to the faulting
instruction (Fig. 5.10). The write operation completes only after all the copiesof the block
have been successfully updated. Notice that in this method, after a write operation
completes, all the nodes that had a copy of the block beforethe write also have a valid
copy of the block after the write. In this method, sequential consistency can beachieved
by using a mechanism to totally orderthe write operations of all the nodes so that all
processes agree on the orderof writes. One methodto do this is to use a global sequencer
tosequence the write operations of all nodes. In this method, the intended modification of
each write operation is first sent to the global sequencer. The sequencer assigns the next
Nodeshavingvalidcopies
ofthedatablockbothbeforeand
afterwrite operation
Clientnode
(alsohasavalidcopy
ofthedata blockafter
writeoperation)
Fig. S.10 Write-update memory coherence approach for replicated, migrating
blocks (RMB) strategy.252 Chap.5 • Distributed SharedMemory
sequence number to the modification and multicasts the modification with this sequence
number to all the nodes where a replica of the data block to be modified is located (Fig.
5.11). The write operations are processed at each node in sequence number order.That is,
when a new modification arrives at a node, its sequence number is verified as the next
expected one. If the verification fails, either a modification was missed or a modification
was received out of order, in which case the node requests the sequencer for a
retransmission of the missing modification. Obviously, a log of recent write requests must
be maintained somewhere in this method. Note that the set of reads that take place
between any two consecutive writes is well defined, and theirordering is immaterial to
sequential consistency.
Othernodes haVing
areplicaofthe
datablock
Clientnode
(hasareplica
of the data block)Sequenced
modification
Sequenced0modification
Fig. 5.11 Global sequencing mechanism to sequencethe writeoperationsof all nodes.
The write-update approach is very expensive for use with loosely coupled
distributed-memory systems because it requires a network access on every write operation
and updates all copies of the modified block. On the other hand, in the write-invalidateapproach, updates are only propagated when data are read, and several updates can take
place (because many programs exhibit locality of reference) before communication is
necessary. Therefore, most DSM systems use the write-invalidate protocol. In the basic
implementation approach of the write-invalidate protocol, there is a status tag associated
witheach block. The status tag indicates whether the block is valid, whether it is shared,
and whether it is read-only or writable. With this status information, read and write
requests are carried out in the following manner [Nitzberg and Virginia Lo 1991]:Sec.5.6 • Consistency Models 253
Read Request
1. Ifthereisalocal blockcontaining thedataandifitis valid,therequestis satisfied
by accessing the local copy of the data.
2.Otherwise, the fault handler of the requesting node generates a read fault and
obtains a copy of the block from a node having a valid copy of the block. If the
block was writable on another node, this read request will cause it to become read­
only.The read request is now satisfied by accessing the data from the local block,
which remains valid until an invalidate request is received.
Write Request
1. If there is a local block containing the data and if it is valid and writable, the
request is immediately satisfied by accessing the local copy of the data.
2. Otherwise, the fault handler of the requesting node generates a write fault and
obtains a valid copy of the block and changes its status to writable. A write fault
for a block causes the invalidation of all other copies of the block. When the
invalidation of all other copies of the block completes, the block is valid locally
and writable, and the original write request may now be performed.
Data Locating in the RMBStrategy. The following data-locating. issues are
involved in the write-invalidate protocol used with the RMB strategy:
1. Locating the owner of a block. An ownerof a block is the node that owns the
block, namely, the most recent node to have write access to it.
2. Keeping track of the nodes that currently have a valid copy of the block.
One of the following algorithms may be used to address these two issues:
1. Broadcasting. In this method, each node has an owned blocks table (Fig. 5.12).
This table of a node has an entry for each block for which the node is the owner. Each
entry of this table has a copy-set field that contains a list of nodes that currently have
a valid copy of the corresponding block.
When a read fault occurs, the faulting node (N)sends a broadcast read request
on the network to find the ownerof the required block. The owner of the block
responds by adding node Nto theblock'scopy-set field in its owned blocks table
and sending a copy of the block to node N.Similarly, when a write fault occurs, the
faulting node sends a broadcast write request on the network for the required block.
On receiving this request, the owner of the block relinquishes itsownership to node
Nand sends the block and its copy set to node N.When node Nreceives the block
and the copy set, it sends an invalidation message to all nodes in the copy set. Node
Nnowbecomes the new owner of the block, and therefore an entry is made for the
block in its local-owned blocks table. 'The copy-set field of the entry is initialized to
indicate that there are no other copies of the block since all the copies were
invalidated.254
Node 1Nodeboundary
NodeIChap.5 • Distributed SharedMemory
Nodeboundary
NodeM
Block Copy-set
address (changes
(changes dynamically
dynamically)
Containsanentryfor
eachblockforwhich
thisnodeistheowner
OwnedblockstableBlock Copy-set
address (changes
(changes dynamically)
dynamically)
Containsanentryfor
eachblockforwhich
thisnodeistheowner
OwnedblockstableBlock ~opy-set
address (changes
(changes ~ynamically)
dynamically)
Containsanentryfor
eachblockforwhich
thisnodeistheowner
Ownedblockstable
Fig. 5.12 Structure and locations of owned blocks table in the broadcasting
data-locating mechanism for RMB strategy.
The method of broadcasting suffers from the disadvantages mentioned during
thedescription of thedata-locating mechanisms for the NRMB strategy.
2. Centralized-server algorithm. This method is similar to the centralized-server
algorithm of the NRMB strategy. However, in this case, each entry of the block table,
managed by the centralized server, has an owner-node field that indicates the current
owner node of the block and a copy-set field that contains a list of nodes having a valid
copy of the block (Fig. 5.13).
When aread/write fault occurs, the faulting node (N)sends aread/write fault request
for theaccessed block tothe centralized server. For aread fault, the centralized server adds
nodeNto theblock'scopy set and returns the owner node information to nodeN.Onthe
other hand, for a write fault, it returns both the copy set and owner node information to
nodeNand then initializes thecopy-set field to contain only node N.NodeNthen sends
a request for the block to the ownernode. On receiving this request, the ownernode
returns a copy of the block to node N.In a write fault, node Nalso sends an invalidate
message to all nodes in the copy set. Node Ncan then perform the read/write
operation.
Thedisadvantages of thecentralized-server algorithm have already been mentioned
duringdescription ofthedata-locating mechanisms for the NRMB strategy.
3. Fixed distributed-server algorithm. This scheme is a direct extension of the
centralized-server scheme. In this scheme, the role of the centralized serveris distributed
to several distributed servers.Therefore, in this scheme, there is a block manager on
several nodes (Fig. 5.14). Each block manager manages a predetermined subset of blocks,
and amapping function is used to map a block to a particular blockmanager and its
corresponding node. When afault occurs, the mapping function is used to find the location
of the block manager that is managing the currently requested block. Then a request forSec. 5.6 • Consistency Models
Nodeboundary
Node 1NodeINodeboundary
NodeIf255
BlockOwnernode Copy-setaddress
(remains(changes (changes
fixed)dynamically) dynamically~
Containsanentryforeachblock
intheshared-memory space
Blocktable
Fig. 5.13 Structure andlocation of block table in the centralized-server data-locating
mechanism for RMB strategy.
theaccessed block is sent to the block manager ofthat node. A request is handled in
exactly the same manneras thatdescribed for thecentralized-server algorithm.
Theadvantages andlimitations of the fixed distributed-server algorithm have already
beenmentioned during the description of thedata-locating mechanisms for the NRMB
strategy.
Node1Nodeboundary
Node;Nodeboundary
NodeM
BlockOwnernode Copy-setaddress
(remains(changes (changes
fixed)dynamicaUy) dynamicafly~
Containsentriesforafixed
subsetofallblocksinthe
shared-memory space
Blocktable
BlockmanagerBlockOwnernode Copy-setaddress
(remains(changes (changes
fixed)dynamicaUy} dynamicaffy~
Containsentriesforafixed
subsetofallblocksinthe
shared-memory space
Blocktable
BlockmanagerBlockOwnernode ~opy-setaddress
(remains(changes Kchanges
fixed)dynamically) ~ynamica"y)
Containsentriesforafixed
subsetofallblocksinthe
shared-memory space
Blocktable
Blockmanager
Fig.5.]4Structure andlocations ofblocktable in the fixed distributed-server
data-locating mechanism for RMB strategy.256 Chap.5 •Distributed SharedMemory
4. Dynamic distributed-server algorithm. This scheme works in a similar manner
as the dynamic distributed-server algorithm of the NRMB strategy. Each node has a
block table that contains an entry for all blocks in the shared-memory space (Fig. 5.15).
Each entry ofthe table has a probable-owner field that gives the node a hint on the
locationofthe owner of the corresponding block. In addition, if a node is the true
ownerofa block, the entry for the block in the block table of the node also contains
a copy-set field that provides a list of nodes having a valid copy of the block.
Node 1Nodeboundary
Node;Nodeboundary
NodeM
Block ProbableCopy-setaddressowner
(remains (changes(changes
fiXed) dynamically)dynamically)
Anentryhas
Containsan avaluein
entryforeach thisfieldonly
blockinthe ifthisnodeis
shared-memory thetrueowner
space ofthe
corresponding
block
BlocktableBlockProbableCopy-set.ddressowner
(remains(changes(changes
~ixed)dynamically)dynamically)
Anentryhas
Containsan avaluein
entryforeach thisfieldonly
blockinthe ifthisnodeis
shared-memory thetrueowner
space oftha
corresponding
block
BlocktableBlock ProbableCopy-setaddressowner
(remains (changes(changes
fixed)dynamically)dynamically)
Anentryhas
Containsan avaluein
entryforeach thisfieldonly
blockinthe ifthisnodeis
shared-memory thetrueowner
space ofthe
corresponding
block
Blocktable
Fig. 5.15 Structure and locations of block table in the dynamic distributed-server
data-locating mechanism for RMB strategy.
When a fault occurs, the fault handler of the faulting node (N)extracts the probable­
owner node information for the accessed block from its local block table and sends a
request for the block to that node. If that node is not the true owner of the block, it looks
up its local block table and forwards the request to the node indicated in the probable ...
owner field ofthe entry for the block. On the other hand, ifthe node is the true owner of
the block, it proceeds with the request as follows. For a read fault, it adds node Nin the
copy-set field of the entry corresponding to the block and sends a copy of the block to
nodeN,which then performs the read operation. For a'write fault, itsends a copy of the
block and its copy-set information to node Nand deletes the copy-set information of that
block from the local block table, On receiving the block and copy-set information, node
Nsends an invalidation request to all nodes in the copy set.After this, it becomes thenew
owner of the block, updates its local block table, and proceeds with performing the write
operation.Sec. 5.6 • Consistency Models 257
To reduce the length of the chain of nodes to be traversed to reach the true owner of
a block, the probable-owner field of a block in a node'sblock table is updated as follows
[Li and Hudak 1989]:
(a)Whenever the node receives an invalidation request
(b)Whenever the node relinquishes ownership, that is, on a write fault
(c)Whenever the node forwards a fault request
In the first two cases, the probable-owner field ischanged to the new owner ofthe
block. In the third case, the probable-owner field is changed to the original faulting node
(N).This is because, if the request is for write, the faulting node (N)isgoing to be the new
owner. If the request is for read, we know that after the request is satisfied, the faulting
node(N)will have the correct ownership information. In either case, it is a good idea to
change the probable-owner field of the block to node N.
It has been proved in [Li and Hudak 1989] that a fault on anynode for a block
eventually reaches the true owner of the block, and if there are altogether Mnodes, it will
take at most M - 1 messages to locate the true owner of a block.
Some refinements of the data-locating algorithms described above may be found in
[Li and Hudak 1989].
Replicated, Nonmigrating Blocks
In this strategy, a shared-memory block may be replicated at multiple nodes of the
system, but the location of each replica is fixed. A read or write access to a memory
address is carried out by sending the access request to one of the nodes having a
replica of the block containing the memory address. All replicas of a block are kept
consistent byupdating them all in case of a write access. A protocol similarto the
write-update protocol is used for this purpose. Sequential consistency is ensured by
using a global sequencer to sequence the write operations of all nodes (Fig. 5.11).
Data Locating in the RNMBStrategy. The RNMB strategy has the following
characteristics:
1. The replica locations of a block never change.
2. All replicas of a data block are kept consistent.
3. Only a read request can be directly sent to one of the nodes having a replica of the
block containing the memory address on which the read request is performed and
all write requests have to be first sent to the sequencer.
Based on these characteristics, the best approach of data locating for handling read!
writeoperations in this case is to have a block table at each node and a sequence table
with the sequencer (Fig. 5.16). The block table of a node has an entry for each block
in the shared memory. Each entry maps a block to one of its replica locations. The
sequence table also has an entry for each block.in the shared-memory space. Each entry
of the sequence table has three fields-a fieldcontaining the block address, a replica-258
Node1Nodeboundary
Node;Chap.5 •Distributed SharedMemory
Nodeboundary
NodeM
Block Replica
address node
(remains (remains
fixed) fixed)
Containsanentry
foreachblockin
theshared-memory
spaceBlock Replica
address node
(remains (remains
fixed) fixed)
Containsanentry
foreachblockin
theshared-memory
spaceBlock Replica
address node
(remains (remains
fixed) fixed)
Containsanentry
foreachblockin
theshared-memory
space
Blocktable Blocktable Blocktable
BlockReplicaSequence
addresssetnumber(is
f.remainslremainsIncremented
IXed)ixed)byonefor
eve':Y.newmodification
intheblock)
Containsanentry
foreachblockin
theshared-memory
space
Sequence table
Centralized sequencer
Fig. 5.16 Structure and locations of block table and sequence table in the centralized
sequencer data-locating mechanism for RNMB strategy.
set fieldcontaining a list of nodes having a replica of the block, and a sequence number
field that is incremented by Ifor every new modification performed on the block.
Forperforming a read operation on a block, the replica location of the block is
extracted from the local block table and the read request is directly sent to that node.
A writeoperation on a block is sent to the sequencer. The sequencer assigns the next
sequence number to the requested modification. It then multicasts the modification
with this sequence number to all the nodes listed in the replica-set field of the entry
for the block. The write operations are performed at each node in sequence" number
order.
Note that, to prevent all read operations on a block getting serviced at the same
replica node, as far as practicable, the block table of different nodes should have
different replica locations entered in the entry corresponding to the block. This will help
in evenly distributing the read operations on the same block emerging from different
nodes.Sec.5.6 • Consistency Models
5.6.2 Munin:A ReleaseConsistent DSMSystem259
Wesaw in the discussion ofconsistency models that in additiontosequential consistency,
releaseconsistency isalsopromising andattractive for use inDSM systems. Therefore, asa
case study ofareleaseconsistent DSM system, a description of the Munin system is
presented below[Bennett et al. 1990,Carter et al. 1991, Carteret al. 1994].
Structure ofShared-Memory Space
Theshared-memory space of Munin is structured as acollection ofsharedvariables
(includes program datastructures). The shared variables aredeclared with the keyword
sharedso thecompiler canrecognize them. Aprogrammer can annotate a shared variable
with one of the standard annotation types(annotation types for shared variables are
described later). Each shared variable, bydefault, is placed by the compiler on a separate
page that is the unit of data transferacross the networkby the MMU hardware. However,
programmers can specify that multiple shared variables having the same annotation type be
placed in the same page. Placing of variables of different annotation types inthe same page
is notallowedbecause the consistency protocol used for a page dependson theannotation
type of variables contained inthe page. Obviously, variables of size larger than the size of a
page occupy multiple pages. The shared variables are declared with the keyword sharedso
thecompiler canrecognize them.
Implementation ofRelease Consistency
In thedescription ofrelease consistency, we saw that for release consistency applications
must bemodeled around critical sections. Therefore a DSM system that supports release
consistency must have mechanisms andprogramming language constructs forcritical
sections. Munin provides two such synchronization mechanisms-a lockingmechanism
and abarriermechanism.
The locking mechanism useslocksynchronization variables with acquirel.ock and
releaseLock primitives foraccessing these variables. The acquirel.ock primitive with alock
variable as its parameter isexecuted by a process to enter a critical section, andthe
releaseLock primitive with the same lock variable as its parameter isexecuted by the
process to exit from the critical section. To ensurerelease consistency, write operations on
shared variables must be performed only within critical sections, but read operations on
shared variables may be performed eitherwithin or outsideacritical section. Modifications
made to ashared variable within acritical section are sent to othernodes having a replicaof
the shared variable only when the process making the update exits from the critical section.
Ifprograms of anapplication are properly structured asdescribed above, the DSM system
will appear to be sequentially consistent.
When aprocessmakes an acquirel.ock requestforacquiring alock variable, thesystem
firstchecksifthe lock variable is available on the local node. If not, the probable-owner
mechanism is used to find the locationof thecurrentownerof the lock variable, and the
requestis sent tothat node. Whether the lock ison the local or remote node, ifitis free, it is
grantedto therequesting process.Otherwise, therequesting processis added to the end ofChap.5 •Distributed SharedMemory
the queue of processes waitingto acquire the lock variable.When the lock variableis
releasedbyitscurrentowner,itisgiventothenextprocessinthewaitingqueue.
The barrier mechanism usesbarriersynchronization variableswitha waitAtBarrier
primitiveforaccessingthese variables. Barriersare implemented byusingthecentralized
barrierserver mechanism.
In a network page fault, the probable-owner-based dynamic distributed-server
algorithm(alreadydescribedduringthedescriptionofRMBstrategy)is usedinMuninto
locateapagecontainingtheaccessedshared variable.Amechanism similartothecopy-set
mechanism(alsodescribedduringthe description ofRMB strategy)isusedtokeeptrackof
allthereplicalocationsofapage.
Annotations forSharedVariables
ThereleaseconsistencyofMuninallows applications tohavebetterperformancethanina
sequentiallyconsistentDSMsystem.Forfurther performanceimprovement, Munindefines
severalstandardannotationsforsharedvariablesandusesadifferentconsistencyprotocol
for each type that is most suitable for that type. That is, consistency protocols in this
approachareappliedat thegranularityofindividualdataitems.Thestandard annotations
andtheconsistencyprotocolforvariablesofeachtypeareasfollows[Bennettet a1.1990]:
I. Read-only. Shared-datavariablesannotatedasread-onlyareimmutabledataitems.
These variablesare read butnever writtenafter initialization. Therefore,the questionof
consistencycontroldoesnotarise.Asthesevariablesarenever modified, theiraverageread
costcanbereduceddrasticallybyfreelyreplicatingthemonallnodesfromwheretheyare
accessed.Therefore,whena referencetosucha variablecausesa networkpagefault,the
pagehavingthevariableiscopiedtothefaultingnodefromoneofthenodesalreadyhaving
acopyofthepage.Read-onlyvariablesareprotectedbytheMMUhardware,andanattempt
towritetosuchavariablecausesafatalerror.
2.Migratory. Sharedvariables that are accessed in phases, where each phase
correspondsto a series of accessesby a single process, may beannotatedas migratory
variables.Thelocking mechanism is usedtokeepmigratoryvariablesconsistent.Thatis,
migratoryvariablesare protectedby lock synchronization variables and are used within
criticalsections.
Toaccessamigratory variable,aprocessfirstacquiresalockforthevariable,usesthe
variableforsometime,andthenreleasesthelockwhenithasfinishedusingit.Atatime,the
systemallowsonlyasingleprocesstoacquirealockforamigratoryvariable.Ifa network
page faultoccurswhena processattemptsto acquirea lockfor a migratory variable,the
pageis migratedtothefaultingnodefromthenodethatisitscurrentowner.The NRMB
strategyisusedinthiscase.Thatis,pagesmigratefromonenodetoanotheronademand
basis, but pages are not replicated. Therefore, only one copy of a page containing a
migratoryvariableexistsinthesystem.
Migratoryvariablesarehandledefficientlybyintegratingtheirmovementwiththatof
thelockassociatedwiththem.Thatis,thelockandthevariablearesenttogetherinasingle
messageto thelocationofthenextprocessthatisgiventhelockforaccessing it.Sec.5.6 • Consistency Models 261
3.Write-shared. Aprogrammer may use this annotation with a shared variable to
indicateto thesystemthat the variable is updated concurrently bymultiple processes, but
theprocesses do not update the same parts of the variable. For example, in a matrix,
different processes canconcurrently updatedifferent row/column elements, with each
processupdating only the elements of onerow/column. Munin avoids the false sharing
problem ofwrite-shared variables by allowing them to be concurrently updated by
multiple processes.
Awrite-shared variable is replicated on all nodes where a processsharing is located.
That is, when access to such a variable causes a network page fault to occur, the page
having the variable is copied to the faulting node from one of its currentnodes. If the
access is a write access, the system first makes a copy of the page (called twinpage)and
then updates the originalpage. The process may perform several writes to the page before
releasing it. When the page is released, the system performs aword-by-word comparison
of the original page and the twin page and sends the differences to all nodes having a
replica of the page.
When a node receives the differences of a modified page, the system checks if the
local copy of the page wasalso modified. If not, the local copy of the page is updated by
incorporating thereceived differences in it. On theother hand, if the local copy of the page
was also modified, the local copy, its twin, and the received differences arecompared
word by word. If the same word has not been modified in both the local and remotecopies
ofthe page, the words of the original local page are updated by using the differences
received from the remotenode. On the other hand, ifthecomparison indicates that the
same word was updatedin both the local and remote copies of the page, a conflictoccurs,
resulting in a runtime error.
4.Producer-consumer. Shared variables that are written (produced) by only one
process and read (consumed) by a fixed set of other processes may beannotated to be of
producer-consumer type. Munin uses an "eagerobjectmovement" mechanism for this
type of variable. In this mechanism, a variable is moved from the producer's node to the
nodes of the consumers in advance of when they are requiredso that no network page fault
occurs when a consumer accesses the variable. Moreover, the write-update protocol is
used to update existing replicas of the variable whenever theproducer updates the
variable. If desired, the producer may send several updates togetherby using the locking
mechanism. In this case, the procedure acquires asynchronization lock, makes several
updates on the variable, and then releases the lock when the variable or the updates are
sent to the nodes of consumer processes.
5.ResuLt.Result variables are just the opposite ofproducer-consumer variables in
the sense that they are written by multiple processes but read by only one process.
Different processes write to different parts of the variablethat do not conflict. The variable
is read only when all its parts have been written. For example, in anapplication there may
bedifferent "worker" processes togenerate and fill the elements ofeachrow/column of
a matrix, and once the matrix is complete, itmay be used by a "master" process for further
processing.
Munin uses a special write-update protocol for result variables in which updates are
sent only to the node having the master process and not to all replica locations of the262 Chap.5 •Distributed SharedMemory
variable (eachworkerprocessnode has a replicaofthevariable). Sincewrites to the
variablebydifferent processes do notconflict, allworkerprocesses areallowedtoperform
writeoperations concurrently. Moreover, sinceresultvariables are not read until all parts
havebeenwritten,aworkerprocessreleasesthevariableonly when it has finishedwriting
allpartsthat it issupposed to write, whenallupdatesare senttogetherin asinglemessage
to themasterprocessnode.
6. Reduction. Sharedvariables thatmustbeatomically modified may be anno­
tated to be ofreduction type.Forexample, in aparallelcomputation application, a
globalminimum must be atomically fetchedandmodified if it isgreaterthan the
localminimum. InMunin,areduction variable isalwaysmodified by being locked
(acquire lock),read,updated, andunlocked (release lock). For betterperformance, a
reduction variable isstoredat a fixed ownerthatreceives updates to thevariable
fromotherprocesses, synchronizes theupdates received fromdifferent processes,
performs theupdates on thevariable, andpropagates theupdated variable to its
replicalocations.
7.Conventional. Sharedvariables that are not annotated as oneoftheabovetypes
areconventional variables. Thealreadydescribed releaseconsistency protocol ofMunin
is used to maintain theconsistency ofreplicated conventional variables. The write
invalidation protocol is used in this casetoensurethat noprocesseverreadsastale
versionofaconventional variable. The page containing aconventional variable is
dynamically movedto thelocationofaprocessthat wants to performa writeoperation on
thevariable.
Experience withMuninhasshownthatread-only, migratory, andwrite-shared annotation
types are very useful because variables ofthese types are frequently used, but producer­
consumer, result,andreduction annotation types are oflittle use becausevariables of these
typesare lessfrequently used.
5.7REPLACEMENT STRATEGY
InDSMsystemsthatallowshared-memory blocksto bedynamically migrated/replicated,
thefollowing issuesmustbeaddressed when the available spaceforcachingshareddata
fillsup at anode:
1.Whichblockshouldbereplaced to make space for a newly required block?
2.Whereshouldthereplaced blockbeplaced?
5.7.1WhichIlocktolleplac.
Theproblemofreplacement has been studiedextensively for paged main memories and
shared-memory multiprocessor systems. The usual classification ofreplacement algo­
rithmsgroupthem into the following categories [Smith1982]:Sec.5.7 • Replacement Strategy 263
1.Usagebasedversusnon-usage based.Usage-based algorithms keep track of the
historyofusageofacacheline (or page) and use this information to make replacement
decisions. That is, the reuse of a cachelinenormally improves thereplacement status of
that line. Least recentlyused(LRU)is anexample ofthis type ofalgorithm. Conversely,
non-usage-based algorithms do not take the record ofuseofcachelines into accountwhen
doingreplacement. First in, first out (FIFO) and Rand (random orpseudorandom) belong
to this class.
2.Fixedspaceversusvariable space.Fixed-space algorithms assume that the cache
size is fixed while variable-space algorithms are based on the assumption that the cache
size can be changed dynamically depending on the need. Therefore, replacement in fixed­
spacealgorithms simplyinvolves theselection of aspecificcacheline. On the otherhand,
in avariable-space algorithm, a fetch does not imply a replacement, and aswap-out can
take place without a corresponding fetch.
Variable-space algorithms are notsuitablefor a DSM systembecauseeachnode's
memory that acts as cachefor the virtualJy shared memory is fixed in size. Moreover, as
compared tonon-usage-based algorithms, usage-based algorithms are more suitablefor
DSM systems becausethey allow to take advantage ofthe data access locality feature.
However, unlike most cachingsystems, which use a simpleLRUpolicy for replacement,
most DSM systemsdifferentiate the status ofdata items and use a priority mechanism. As
anexample, thereplacement policy used by the DSM systemofIVY[Li 1986, 1988] is
presented here. In the DSM system of IVY,eachmemory block of a node is classified into
one of the folJowing five types:
1.Unused.A free memory block that is not currently being used.
2. Nil.A block that has been invalidated.
3.Read-only. Ablock for which the node has only read access right.
4.Read-owned. A block for which the node has only read access right but is also the
ownerof the block.
5. Writable. A block for which the node has write access permission. Obviously, the
node is the ownerof the block becauseIVYuses the write-invalidate protocol.
Based on this classification ofblocks,thefollowing replacement priority is used:
1. Both unused and nil blocks have the highestreplacement priority. That is, they
will bereplaced first if a block is needed. It is obviousfor an unused block to have the
highestreplacement priority. A nil block also has the same replacement prioritybecause
itis nolongeruseful and future access to the blockwouldcauseanetworkfault to occur.
Notice that a nil blockmay be a recentlyreferenced block, and this is exactly why a simple
LRU policy is not adequate.
2. Theread-only blocks have the next replacement priority. This is becausea copy
ofaread-only blockisavailable with its owner, and therefore itispossible to simply
discardthat block. When the node again requires that blockin the future, the block has to
bebroughtfrom itsownernode at that time.264 Chap.5 • Distributed SharedMemory
3.Read-owned and writable blocks for which replica(s) exist on some other node(s)
have the next replacement priority because it is sufficient to pass ownership to one of the
replicanodes. The block itselfneed not be sent, resulting in a smallermessage.
4.Read-owned and writable blocks for which only this node has a copy have the
lowestreplacement prioritybecausereplacement of such a block involves transferof the
block'sownership as well as the block from the current node to some othernode. An LRU
policy is used to select a block for replacement when all the blocks in the local cache have
the same priority.
5.7.2Wiler. to'lac.a"-placed Block
Once a memory block has been selected for replacement, it should be ensured that if there
is some useful information in the block, it should not be lost. For example, simply
discarding a block having unused, nil, or read-only status does not lead to any loss of data.
Similarly, discarding aread-owned or a writable block for which replica(s) exist on some
othernode(s) is also harmless. However, discarding aread-owned or a writable block for
which there is no replica on any other node may lead to loss of useful data. Therefore, care
mustbetaken to store them somewhere before discarding. The two commonly used
approaches for storing a useful block at the time of its replacement are as follows:
I.Usingsecondary store.In this method, the block is simply transferred on to alocal
disk. The advantage of this method is that it does not waste any memory space, and if the
node wants to access the same block again, itcan get the block locally without a need for
network access.
2. Using the memory space ofother nodes. Sometimes it may be faster to transfer a
block over the network than to transfer it to a local disk. Therefore, anothermethod for
storing a useful block is to keep track of free memory space at all nodes in the system and
to simply transferthe replaced block to the memory of a node with available space. This
method requires each node to maintain a table of free memory space in all other nodes.
This table may be updated by having each node piggyback its memory status information
during normal traffic.
5.8THRASHING
Thrashing is said to occur when the system spends a large amount of time transferring
shared data blocks from one node to another, compared to the time spent doing the useful
work ofexecuting application processes. It is a serious performance problem with DSM
systems that allow data blocks to migrate from one node to another. Thrashing may occur
in the following situations:
1. When interleaved data accesses made by processes on two or more nodes causes
a data block to move back and forth from one node to another in quick succession
(aping-pong effect)Sec.5.8 • Thrashing 265
2. When blockswithread-only permissions arerepeatedly invalidated soon after
they are replicated
Suchsituations indicatepoor (node) localityinreferences. If notproperly handled,
thrashing degrades systemperformance considerably. Therefore, steps must be taken to
solve this problem. Thefollowing methods may be used to solve the thrashing problem in
DSM systems:
I.Providing application-controlled locks.Locking data topreventother nodes from
accessing that data for a short period oftime can reducethrashing. Anapplication­
controlled lock can be associated with each data block to implement this method.
2. Nailing a blockto a node foraminimum amountoftime.Another methodto
reducethrashing is todisallow a block to be taken away from a node until a minimum
amountof timetelapsesafter itsallocation to that node. The time tcaneitherbe fixed
statically or be tuned dynamically on the basis of access patterns. Forexample, Mirage
[Fleisch andPopek1989Jemploys this method to reduce thrashing anddynamically
determines theminimum amountoftime for which a block will be available at a node on
the basis of access patterns.
The main drawback of thisschemeis thatitis verydifficulttochoosetheappropriate
value for the time t.If the value is fixed statically, it is liableto beinappropriate in many
cases. For example, if aprocessaccesses a block for writing to it only once, other
processes will beprevented fromaccessing the block until time telapses. On the other
hand, if a processaccesses a block for performing severalwriteoperations on it, time t
mayelapsebefore the processhasfinished using the block and the system may grant
permission toanotherprocess for accessing the block. Therefore, tuning the value oft
dynamically is thepreferred approach. In this case, the value oftfor a block can be
decidedbased on pastaccesspatternsofthe block. The MMU'sreference bits may be used
for this purpose. Another factor that may be used for deciding the value. oftfor a block
is the length of the queue of processes waitingfor their turn to access the block.
3. Tailoring the coherence algorithm to theshared-data usagepatterns. Thrashing
can also be minimized by using different coherence protocols forshareddata having
different characteristics. Forexample, thecoherence protocol used in Munin for write­
sharedvariables avoidsthe false sharingproblem, whichultimately results in the
avoidance ofthrashing.
Notice from the description above that complete transparency ofdistributed shared
memory is compromised somewhat while trying to minimize thrashing. This isbecause
most of the approaches described aboverequiretheprogrammer's assistance. For
example, in themethodofapplication-controlled locks, the use oflocks needs to be
directed toward a particular shared-memory algorithm and hence the shared-memory
abstraction can nolongerbetransparent. Moreover, theapplication must be aware of the
shareddata it is accessing and its shared accesspatterns. Similarly, Muninrequires
programmers toannotate sharedvariables withstandard annotation types, which makes
theshared-memory abstraction nontransparent.266
5.9OTHERAPPROACHES TODSMChap.5 • Distributed SharedMemory
Depending on the manner in which data caching (placement and migration of data) is
managed, there are three main approaches for designing a DSM system:
1. Data caching managed by the operating system
2. Data caching managed by the MMU hardware
3. Data caching managed by the language runtime system
This being a book on operating systems, in this chapterwe mainly concentrate on
the first approach. Systems such as IVY [Li 1986] and Mirage [Fleish and Popek
1989] fall in this category. In these systems, each node has its own memory and
access to a word in another node's memory causes a trap to the operating system. The
operating system then fetches and acquires the page containing the accessed word
from the remote node's memory by exchanging messages with that machine. There­
fore, in these systems, the placement and migration of data are handled by the
operating system. For completion, the other two approaches of designing a DSM
system are briefly described below.
The second approach is to manage caching by the MMU. This approach is used
inmultiprocessors having hardware caches. In these systems, the DSM implementation
is done either entirely or mostly in hardware. For example, if the multiprocessors are
interconnected by a single bus, their caches are kept consistent by snooping on the
bus. In this case, the DSM is implemented entirely in hardware. The DEC Firefly
workstation belongs to this category. On the other hand, if the multiprocessors are
interconnected by switches, directories are normally used in addition to hardware
caching to keep track of which CPUs have which cache blocks. Algorithms used to
keep cached data consistent are stored mainly in MMU microcode. Therefore, in this
case, the DSM is implemented mostly in hardware. Stanford's Dash [Lenoski el al.
1992] and MIT'sAlewife [Agarwal et al. 1991, Kranz et al. 1993] systems belong to
this category. Notice that in these systems, when a remote access is detected, a
message is sent to the remote memory by the cache controller or MMU (not by the
operating system software).
The third approach is to manage caching by the language runtime system. In
these systems, the DSM is structured not as a raw linear memory of bytes from 0 to
total size of the combined memory of all machines, but as a collection of program­
ming language constructs, which may be shared variables and data structures (in
conventional programming languages) or shared objects (in object-oriented program­
ming languages). In these systems, the placement and migration of shared variables/
objects are handled by the language runtime system in cooperation with the operating
system. That is, when a variable/object is accessed by a process, it is the responsibility
of the runtime system and the operating system to successfully perform the requested
accessoperation on the variable/object independently of its current location. An
advantage of this approach is that programming languages may be provided with
features to allow programmers to specify the usage pattern of shared variables/objectsSec.5,]0•Heterogeneous DSM 267
for their applications, and the system can support several consistency protocols and
use the one most suitable for a shared variable/object. Therefore, these systems can
allowconsistency protocols to be applied atthegranularity of individual data items
and can rely on' weakerconsistency modelsthansequential consistency modelfor
betterconcurrency. However, adrawback ofthisapproach is that it imposes extra
burdenonprogrammers. Munin[Bennett et al. 1990] and Midway [Bershad etat
1993] are examples ofsystems thatstructure theirDSM as a collection ofshared
variables and data structures. On theotherhand,Orca[Bal et al. 1992] and Linda
[Carriero andGelernter 1989] are examples ofsystems thatstructure theirDSM as a
collection ofsharedobjects.
5.10HETEROGENEOUS DSM
Computers ofdifferent architectures normally havedifferent characteristic features. For
example, supercomputers andmultiprocessors aregoodatcompute-intensive applications
whilepersonal computers andworkstations usually havegooduserinterfaces. A
heterogeneous computing environment allowstheapplications toexploitthe bestofall the
characteristic featuresofseveraldifferent typesofcomputers. Therefore, heterogeneity is
oftendesirable indistributed systems,
Heterogeneous DSM is a mechanism thatprovides theshared-memory paradigm in
aheterogeneous environment andallowsmemory sharingamongmachines ofdifferent
architectures. At firstglance,sharingmemory amongmachines ofdifferent architectures
seemsalmostimpossible. However, basedon the measurements made on their
experimental prototype heterogeneous DSM,calledMermaid, Zhouet al. [1990, 1992]
haveconcluded thatheterogeneous DSM is not only feasiblebut can also be comparable
inperformance to itshomogeneous counterpart (at least for someapplications). Thetwo
main issues in building a DSMsystemon anetworkofheterogeneous machines are data
conversion andselection ofblocksize.Theseissuesaredescribed below. The following
description isbasedon thematerial presented in[Zhouet al.1990,1992J.
5.1O.1 DataConversion
Machines ofdifferent architectures may use different byteorderings andfloating-point
representations. Whendata istransferred from anodeofone type to a node ofanother
type, it must be converted beforeitisaccessed on thedestination node.However, the
unitofdatatransfer in a DSM systemisnormally a block. Therefore, when ablock
ismigrated between twonodesofdifferent types,thecontents oftheblockmust be
converted. But theconversion itselfhas to be basedonthetypesofdatastoredin the
block. It is not possible for the DSM systemtoconvertablockwithoutknowing the
typeofapplication-level datacontained in theblockand the actualblocklayout.
Therefore, itbecomes necessary to takeassistance fromapplication programmers, who
know the layoutofthememory being used by theirapplication programs. Two
approaches proposed in theliterature fordataconversion in aheterogeneous DSM are
described below.268 Chap.5 • Distributed SharedMemory
Structuring the DSM System as aCollection of Source
Language Objects
In thismethod, the DSM systemisstructured as acollection ofvariables orobjectsin the
sourcelanguage so that the unit ofdatamigration is anobjectinsteadofa block. A DSM
compiler is used that adds conversion routinesfortranslating variables/objects in thesource
language amongvariousmachine architectures. For each accessto ashared-memory object
from aremotenode, acheckismadeby theDSMsystemifthemachineofthe node that
holdstheobjectand therequesting node arecompatible. Ifnot, asuitableconversion routine
isusedtotranslate theobjectbeforemigrating it to therequesting node.
Thismethodofdataconversion is used in the Agorashared-memory system[Bisiani
eta1.1987]. In Agora,eachmachine marksmessages with amachine tag. Amessage
contains anobjectbeingmigrated from one node to another. Messages between identical
orcompatible machines do notrequiretranslation. Whentranslation isnecessary, the type
ofinformation associated with thedestination contextis used to do a one-pass translation
oftheobject.Depending on the field tag and the machine requirements fordataalignment,
thetranslation processmayinvolvesuchoperations asfield-by-fieJd swapping ofbytes,
inserting/removing gaps where necessary, andshuffling ofbits.
Structuring a DSMsystemas acollection ofsourcelanguage objects may be useful
from the dataconversion pointofview but is generally notrecommended due to
performance reasons. This isbecause objectsinconventional programming languages
typically arescalars(single-memory words), arrays, and structures. Noneofthese types is
suitableas asharedentityofa DSMsystem.Foreachsharedentity,accessrightsmustbe
issuedforeveryentityand themigration ofanentityinvolves communication overhead.
Therefore, thechoiceofscalardata types as a unit ofsharingwouldmake asystemvery
inefficient. On theotherhand,arraysmayeasilybe too large to be treatedas unitsof
sharinganddatamigration. Largedataobjectslead to false sharingandthrashing, and
theirmigration oftenrequires fragmentation andreassembly operations to becarriedout
on them due to the limitedpacketsizeoftransport protocols.
Allowing Only One Type of Data in a Block
Thismechanism is used in Mermaid [Zhou et al. 1990, 1992], which uses a page size as
itsblocksize.Therefore, apagecancontainonly one typeofdata. InMermaid, the DSM
page(block)tableentrykeepsadditional information identifying the type ofdata
maintained in thatpageand theamountofdataallocated to the page. Whenever a page is
movedbetween twomachines ofdifferent architectures, aroutineconverts the data in the
pageto theappropriate format.Mermaid requirestheapplication programmers toprovide
theconversion routinefor each user-defined data type in the application. Mermaid
designers pointedout that the cost ofconverting apageis smallcompared to theoverall
costofpagemigration.
Zhouetale[1990]identified thefollowing limitations ofthisapproach:
1.Allowing apagetocontaindataofonly one type may lead to wastageofmemory
due tofragmentation, resulting inincreased pagingactivity.Sec.5.10 • Heterogeneous DSM 269
2. Themechanism requires that the compilers used on different types of machines
must becompatible in the sense that in the compiler-generated code the size of each data
type and the order of the fields within compound structures must be the same on each
machine. If incompatible compilers are used for an application to generate code for two
different machines such that the size of the application-level data structures differs for the
two machines, the mapping between pages on the two machines would not beone to one.
That is, it may not be possible for a structure to fit on a page in its entirety after the
conversion or, conversely, some data from the following page may beneeded in order to
complete theconversion of the current page [Zhou et al. 1990]. This complicates the
conversion process.
3. Another problem associated with this method is that entire pages are converted
even though only a small.portion may be accessed before it is transferred away.
Sometimes this problem may be more severe in the first method, which converts an entire
object. For example, a large array may occupy several pages of memory, and migration of
this object would convert the data in all the occupied pages even when only the first few
array elements may be accessed before the object is transferred away.
4. The mechanism is not fully transparent because it requires the users to provide the
conversion routines for user-defined data types and a table specifying the mapping of data
types toconversion routines. The transparency problem may be solved by automatically
generating the conversion routines and the mapping table by using a preprocessor on the
user program [Zhou et al. 1990].
Anotherserious problem associated with the data conversion issue inheterogeneous
DSM systems is that of the accuracy of floating-point values in numerical applications.
Since an application has no control over how often a data is migrated or converted,
numerical accuracy of floating-point data may be lost ifthe data isconverted several times
and the results may become numerically questionable.
5.10.2BlockSize Salaction
Recall that in a homogeneous DSM system the block size is usually the same size as
a native virtual memory (VM) page, so that the MMU hardware can be used to trigger
a DSM block fault. However, in a heterogeneous environment, the virtual memory
page size may be different for machines of different types. Therefore, block size
selection becomes acomplicated task in such a situation. Zhou et al. [1990, 1992]
proposed the use of one of the following algorithms for block size selection in a
heterogeneous DSM system:
1. Largest page size algorithm. In this method, the DSM block size is taken as the
largest VM page size of all machines. Since VM page sizes are normally powers of 2,
multiplesmallerVM pages fit exactly in one DSM block. If a page fault occurs on a node
with a smaller page size, it will receive a block of multiple.pages that includes the desired
page. This algorithm suffers from the same false sharing and thrashing problems
associated with large-sized blocks.270 Chap.5 • Distributed SharedMemory
2. Smallest page size algorithm. In this method, the DSM block size is taken as the
smallestVMpage size ofall machines. If apage fault occurs on a node with alarger page
size,multiple blocks (whose total size is equal to the page size of the faulting node) are
movedto satisfy the page fault. Although thisalgorithm reducesdatacontention, it suffers
from the increased communication and block table management overheads associated
withsmall-sized blocks.
3. Intermediate page size algorithm. Tobalancebetween the problems oflarge- and
small-sized blocks, a heterogeneous DSM system may select to choosea block size
somewhere in between the largest VMpage size and the smallest VMpage size of all
machines.
5.11ADVANTAGES OFDSM
Distributed SharedMemory is ahigh-level mechanism forinterprocess communication in
looselycoupled distributed systems. It is receiving increased attention because of the
advantages it has over the message-passing mechanisms. Theseadvantages arediscussed
below.
5.11.1Simpl.rAbstraction
Bynow it is widely recognized that directly programming looselycoupleddistributed­
memory machines usingmessage-passing models is tedious and error prone. The main
reason is that the message-passing models force programmers to beconscious of data
movement between processes at all times, since processes mustexplicitly use
communication primitives andchannels or ports. To alleviate this burden, RPC was
introduced toprovideaprocedure call interface. However, even in RPC, since the
procedure call isperformed in an address space different from that ofthecaller'saddress
space, it is difficultfor thecallerto passcontext-related data orcomplex datastructures;
that is, parameters must be passed by value. In the message-passing model, the
programming task is further complicated by the fact that data structures passedbetween
processes in the form of messages mustbepackedand unpacked. The shared-memory
programming paradigm shields the application programmers from many such low-level
concerns. Therefore, the primary advantage ofDSM is the simplerabstraction it provides
to theapplication programmers oflooselycoupleddistributed-memory machines.
5.11.1ktt.rPortability ofDistributed Application
Programs
The access protocol used in case ofDSM is consistent with the way sequential
applications access data. This allows for a more natural transition fromsequential to
distributed applications. In principle, distributed application programs written for a
shared-memory multiprocessor system can be executed on adistributed shared-memory
systemwithoutchange.Therefore, it is easier to port an existingdistributed applicationSec.5.11•Advantages ofDSM 271
program to adistributed-memory system with DSM facility than to a distributed-memory
systemwithoutthis facility.
5.11.3letterPerformance ofSomeApplications
Thelayerofsoftware thatprovides DSMabstraction isimplemented on topofamessage­
passingsystem and uses the servicesof theunderlying message-passing communication
system.Therefore, inprinciple, theperformance ofapplications that useDSM is expected to
be worse than if they use message-passing directly. However, this is not always true, and it
has been found that some applications using DSM can even outperform theirmessage­
passingcounterparts. This ispossiblefor three reasons [Stummand Zhou 1990]:
1.Localityofdata.Thecomputation model of DSM is to make the data more
accessible by moving it around. DSM algorithms normally move data between nodes in
large blocks. Therefore, in thoseapplications thatexhibitareasonable degreeoflocality
in their data accesses, communication overhead isamortized overmultiple memory
accesses. Thisultimately results in reduced overallcommunication cost for such
applications.
2.On-demand datamovement. Thecomputation modelofDSM also facilitates 00­
demandmovement ofdata as they are being accessed. On the otherhand, there are several
distributed applications thatexecutein phases, where each computation phase ispreceded
by adata-exchange phase. The time needed for the data-exchange phase is often dictated
by thethroughput ofexistingcommunication bottlenecks. Therefore, in suchapplications,
theon-demand datamovement facilityprovided by DSM eliminates thedata-exchange
phase, spreads the communication load over a longer period of time, and allows for a
greaterdegreeofconcurrency.
3.Largermemory space.With DSM facility, the total memory size is the sum ofthe
memory sizesofall the nodes in the system,Thus, paging and swapping activities, which
involvedisk access, arc greatly reduced.
5.11.4FlexibleCommunication Environment
Themessage-passing paradigm requires recipient identification andcoexistence of the
senderandreceiver processes. That is, the senderprocess of a piece ofdata must
know the names ofitsreceiver processes (exceptinmulticast communication), and the
receivers of the data must exist at the time the data is sent and in a state that they can
(oreventually can)receivethe data. Otherwise, the data is undeliverable. Incontrast,
theshared-memory paradigm of DSM provides a more flexible communication
environment inwhichthesenderprocess need not specify the identity ofthereceiver
processes ofthe data.Itsimply places the data in the shared memory and thereceivers
accessitdirectly from the shared memory. Therefore, thecoexistence ofthesender
and receiver processes is also not necessary in theshared-memory paradigm. In fact,
thelifetimeofthe shared data is independent of the lifetime ofanyofitsreceiver
processes.272 Chap.5 •Distributed SharedMemory
5.11.5Eas.of'roc.ssMigration
Migration of a process from one node to another in a distributed system (described in
Chapter8) has been shown to be tedious and time consuming due to the requirement of
transferring the migrant process's address space from its old node to its new node.
However, the computation model of DSM provides the facility of on-demand migration of
data between processors. This facility allows the migrant process to leave its address space
on its old node at the time of migration and fetch the required pages from its new node
on demand at the ·time of accessing. Hence in a distributed system with DSM facility,
process migration isas simple asdetaching theprocess control block (PCB) of the migrant
process from the processor of the old node and attaching it to the ready queue of the new
node'sprocessor. A PCB is a data block or a record associated with each process that
containsuseful information such as process state, CPU registers, scheduling information,
memory management information, I/O status information, and so on. This approach
provides a very natural and efficient form of process migration between processors in a
distributed system.
5.11SUMMARY
Programming of applications for loosely coupled distributed-memory machines with the
message-passing paradigm is a difficult and error-prone task. The Distributed Shared
Memory (DSM) facility simplifies this programming task by providing a higher level
abstraction thatallows programmers to write programs withthe shared-memory paradigm,
which is consistent with the way sequential applications access data.
Important issues involved in the design and implementation of a DSM system are
granularity of data sharing, structure of the shared-memory space, memory coherence and
accesssynchronization, data location and access, replacement strategy, handling of
thrashing, and heterogeneity.
Granularity refers to block size, which is the unit of data sharing and data transfer
across the network. Both large- and small-sized blocks have their own advantages and
limitations. Several DSM systems choose the virtual memory page size as block size so
that the MMU hardware can be used to trigger a DSM block fault.
The structure of the shared-memory space of a DSM system defines the abstract view
to be presented to application programmers of that system. The three commonly usedmethods for structuring the shared-memory space of a DSM system are no structuring,
structuring by data type, and structuring as a database. The structure and granularity of a
DSM system are closely related.
Memory coherence isan important issue inthe design of aDSM system. Itdeals with
theconsistency of a data block lying in the main memories of two or more nodes of the
system. Several consistency models have been proposed in the literature to handle this
issue. The main ones described in this chapter are strict consistency, sequential
consistency, causal consistency, PRAM consistency, processor consistency, weak
consistency, and release consistency.
Ofthese, sequential consistency and release
consistency are appropriate for a large number of applications.Sec.5.12 • Summary 273
Protocols forimplementing thesequential consistency model inaDSM systemdepend
on thefollowing fourreplication andmigration strategies used by the DSM system:
1.Nonreplicated, nonmigrating blocks(NRNMBs)
2.Nonreplicated, migrating blocks(NRMBs)
3.Replicated, migrating blocks(RMBs)
4.Replicated, nonmigrating blocks(RNMBs)
Protocols forimplementing sequential consistency for eachofthesestrategies have
beendescribed in this chapter. The data-locating mechanisms suitablefor each case have
also been described. Inaddition, the Munin system has been presented as anexample of
areleaseconsistent DSM system.
Replacement strategydeals with the selection of a block to be replaced when the
available space for cachingshared data fills up and the placement ofareplaced block. The
usualclassifications ofreplacement algorithms areusage-based versusnon-usage-based
andfixed-space versusvariable-space. DSM systems use fixed-space, usage-based
replacement algorithms. At the time of its replacement, a useful block may be placed in
eitherthesecondary storageof the local node or the memory space of some other
node.
Thrashing is a serious performance problem with DSM systems that allow data
blocks to migratefrom one node to another. Methods that may be used to solve the
thrashing problem in DSM systemsareproviding application-controlled locks, nailing a
block to a node for a minimum amountof time, and tailoring the coherence algorithm to
theshared-data usage patterns.
Depending on themannerin which data cachingismanaged, there are three main
approaches todesigning a DSM system: data cachingmanaged by the operating system,
datacachingmanaged by the MMU hardware, and data cachingmanaged by thelanguage
runtimesystem.
Heterogeneous DSM is a mechanism that provides the shared-memory paradigm
in aheterogeneous environment and allows memory sharingamongmachines with
different architectures. The two main issues in building thisfacilityare data conversion
andselection ofblock size. Two approaches proposed in theliterature for data
conversion in aheterogenous DSM are structuring the DSM system as a collection of
sourcelanguage objectsandallowing only one type of data in a DSM block. Three
algorithms that may be used for block size selection in aheterogeneous DSMsystem
are largest page size algorithm, smallest page size algorithm, andintermediate page size
algorithm.
Research has shown that DSM systemsare viable, and they have severaladvantages
overthemessage-passing systems. However, they are still far from mature. Most existing
DSMsystemsare very small experimental orprototype systemsconsisting ofonly a few
nodes. The performance results to date are also preliminary and based on a small group
ofapplications or asynthetic workload. Nevertheless, research has provedthat DSM
effectively supports parallelprocessing andpromises to be a fruitful and excitingareaof
research for thecomingdecade.274 Chap. 5 • Distributed SharedMemory
EXERCISES
5.1.Thedistributed shared-memory abstraction isimplemented by using the services of the
underlying message-passing communication system.Therefore. inprinciple, theperformance
ofapplications that use DSM is expected tobeworse than if they use message passing
directly. In spite of this fact, why do some distributed operating systemdesigners supportthe
DSMabstraction intheirsystems? Are there any applications that can have betterperformance
in a system with DSM facility than in a system that has only message-passing facility? If yes,
give the types of such applications. If no, explain why.
5.2.Discussthe relative advantages anddisadvantages of using large block size and small block
size in the design ofablock-based DSM system. Why do most DSM system designers prefer
to use the typical page size used in a conventional virtual-memory implementation as the
block size of the DSM system?
5.3.Itis often said that the structure of theshared-memory space and the granularity of data
sharingin a DSM system are closely related. Explain why.
5.4.What is false sharing? When is it likely to occur?Can this problem lead to any otherproblem
in a DSM system?Give reasons for your answer.
5.5.What should be done to minimize the false sharing problem? Can this problem becompletely
eliminated? What other problems may occur if one tries to completely eliminate the false
sharingproblem?
5.6.Discussthe relative advantages anddisadvantages of using the NRNMB. NRMB, RMB, and
RNMBstrategies in the design of a DSM system.
5.7.Discussthe relative advantages anddisadvantages of the various data-locating mechanisms
that may beused in a DSM system that uses the NRMB strategy.
5.8. Asequentially consistent DSM system uses the RMB strategy. Itemploys thewrite-invalidate
approach forupdating data blocks and the centralized-server algorithm for locating the owner
of a block and keeping track of the nodes that currently have a valid copy of the block. Write
pseudocode for theimplementation of the memory coherence schemeofthis DSM system.
5.9.Why is a global sequencer needed in a sequentially consistent DSM system that employs the
write-update protocol?
5.10.Most DSM systems in which cachingis managed bytheoperating system use the write­
invalidate scheme for consistency instead of the write-update scheme. Explain why.
5.11.Differentiate between weak consistency and release consistency. Which of the two will you
preferto use in the design of a -DSM system?Give reasons for your answer.
5.12.Aprogrammer is writing an application for arelease-consistent DSM system. However the
application needs,sequential consistency to produce correct results. What precautions must the
programmer take?
S.13.Differentiate between PRAM consistency andprocessor consistency.
5.14.Give the relative advantages anddisadvantages ofsequential and release consistency
models.
5.15.What is causal consistency? Give anexample of anapplication for which causal consistency
is the most suitableconsistency model.
5.16.Proposeasuitablereplacement algorithm for a DSM system whose shared-memory space is
structured as objects. One of the goals in this case may be to minimize memory
fragmentation.
5.17.Why does the simple LRU policy often used for replacing cache lines in a buffer cachenot
work well as a replacement policy for replacing blocks in a DSM system?Chap. 5 • Bibliography 275
5.18.To handle the issue ofwheretoplace a replaced block,theDSMsystem of Memnet [Delp
1988]uses the concept of "home memory," inwhich each block has ahome memory. When
replacement of ablock requires that the block be transferred to some other node's memory,
the block is transferred to the node whose memory is the home memory for the block. What
are theadvantages anddisadvantages ofthis approachascompared totheonepresented inthis
chapter?
5.19.What are the main causes of thrashing in a DSM system? What are the commonly used
methods to solve the trashing problem in a DSM system?
5.20. Complete transparency of a DSM system is compromised somewhat when a method is used
to minimize thrashing. Therefore, thedesigner of a DSMsystem is of the opinion that instead
of using a method to minimize thrashing, a method should be used by which the system
automatically detects and resolyes this problem. Propose a method by which the system can
detect thrashing and a method toresolve it once it has been detected.
5.21.A distributed system has DSM facility. The process-scheduling mechanism of this system
selects another process to run when a fault occurs for the currently running process, and the
CPU is utilized while the block is being fetched. Twosystem engineers arguing about how to
better utilize the CPUs of this system have the following opinions:
(a) The first one says that if a large number of processes are scheduled for execution at a
node, the available memory space of the node can be distributed among these processes
so that almost always there will be a ready process to run when a page fault occurs. Thus,
CPUutilization can be kept high.
(b)The second one says that if only a fewprocesses are scheduled for execution at a node,
theavailable memory space of the nodecan beallocated toeach of thefew processes, and
each process will produce fewer page faults. Thus,CPU utilization can be kept high.
Whose argument is correct? Give reasons for your answer.
5.22. What arethe three main approaches for designing a DSM system?
5.23. What are some of the issues involved in building a DSM system on a network of
heterogeneous machines? Suggest suitable methods for handling these issues.
5.24.AreDSMsystems suitable for both LANandWANenvironments? Give reasons for your
answer.
5.25. Suggest some programming practices that will reduce network block faults in a DSM
system.
5.26. Write pseudocode descriptions for handling a block fault in each of the following types of
DSM systems:
(a)ADSM system that uses the NRNMB strategy
(b) A DSM system that uses the NRMB strategy
(c)ADSM system that uses the RMBstrategy
(d) A DSM system that uses the RNMB strategy
Youcanmake any assumptions that you feel necessary, but state the assumptions made.
BIBLIOGRAPHY
[AdveandHill 1990] Adve,S.,and Hill,M;"WeakOrdering: ANew Definition," In: Proceedings
ofthe 17th International Symposium onComputer Architecture, Association for Computing
Machinery, New York, NY,pp. 2-14(1990).276 Chap. 5 • Distributed SharedMemory
[Agarwaletal. 1991] Agarwal, A., Chaiken, D.,D'Souza, G., Johnson, K., Kranz, D., Kubiatowicz,
J.,Kurihara, K., Lim, B., Maa, G., Nussbaum, D., Parkin, M., and Yeung, D., "The MIT Alewife
Machine: ALarge-Scale Distributed Memory Multiprocessor," In:Proceedings ofthe Workshop
on Scalable Shared Memory Multiprocessors, Kluwer Academic, Norwell, MA (1991).
[Bal1991] Bal, H. E., Programming Distributed Systems, Prentice-Hall, London, England
(1991).
[8al et al. 1992]Bal,H.E.,Kaashoek, M.F.,andTanenbaum, A. S., "Orca: A Language for Parallel
Programming ofDistributed Systems:' IEEE Transactions onSoftware Engineering, Vol.SE-18,
pp.190-205 (1992).
[Baldoni et al. 1995] Baldoni, R., Mostefaoui, A., and Raynal, M., "Efficient Causally Ordered
Communications forMultimedia Real Time Applications," In:Proceedings ofthe 4th
International Symposium on High Performance Distributed Computing, IEEE,New York
(1995).
[Bennett et al, 1990JBennett, J., Carter, J., and Zwaenepoel, W.,"Munin: Distributed Shared
Memory BasedonType-Specific Memory Coherence," In: Proceedings ofthe1990Conference
on Principles and Practice ofParallel Programming, Association forComputing Machinery,
New York, pp. 168-176 (1990).
[Bershad et al, 1993] Bershad, B. N.,Zekauskas, M.1,andSawdon, W. A.,"TheMidway
Distributed SharedMemory System," In:Proceedings ofthe IEEE COMPCON Conference,
IEEE, New York, pp. 528-537 (1993).
[BisianiandRavishankar 1990JBisiani,R., andRavishankar, M., "Plus: A Distributed Shared­
Memory System," In: Proceedings ofthe 17th International Symposium on Computer
Architecture, Association forComputing Machinery, New York, NY, pp. 115-124 (1990).
[Bisiani et al. 1987] Bisiani, R., Alleva, F., Correrini, F., Forin, A., Lecouat, F., and Lerner, R.,
"Heterogeneous ParallelProcessing: TheAgoraShared Memory," Technical ReportNo. CMU­
CS-87-112, Computer ScienceDepartment, Carnegie-Mellon University (March 1987).
[Bisianiet al. 1989]Bisiani,R.,Nowatzyk, A., andRavishankar, M.,"Coherent SharedMemory on
aDistributed Memory Machine," In:Proceedings ofthe International Conference on Parallel
Processing, IEEE, New York, pp. 133-141 (August 1989).
[Campine et al. 1990]Campine, G. A., Geer, Jr., D. E, and Ruh, W. N., "Project Athena as a
Distributed Computer System," IEEE Computer, Vol. 23, pp. 40-51(1990).
[Carriero andGelernter 1989]Carriero, N., and Gelernter, D., "Lindain Context," Communica­
tionsofthe ACM, Vol. 32,No.4,pp.444-458 (1989).
[Carriero etal, 1986] Carriero, N.,Gelernter, D., and Leichter, 1,"Distributed DataStructures in
Linda," In: Proceedings ofthe ACM Symposium on Principles ofProgramming Languages,
Association forComputing Machinery, New York (1986).
[Carteretal, 1991] Carter,1.B., Bennett, 1K., and Zwaenepoel, W.,"Implementation and
Performance ofMunin," In:Proceedings ofthe 13th Symposium on Operating Systems
Principles, Association forComputing Machinery, New York, NY, pp. 152-164 (1991).
[Carteret al.1994]Carter,J.B., Bennett, 1K., andZwaenepoel, W.,"Techniques for Reducing
Consistency-Related Communication inDistributed SharedMemory Systems," ACM Transac­
tions on Computer Systems, Vol. 12 (1994).
[Chase et al. 1989] Chase, J. S.,Amador, F. G., Lazowska, E. D., Levy, H. M., and Littlefield, R.
J.,"TheAmberSystem: Parallel Programming on aNetwork ofMultiprocessors," In:
Proceedings ofthe 12thSymposium on Operating Systems Principles, Association forComputing
Machinery, New York, NY, pp. 147-158 (1989).Chap.5 • Bibliography 277
[Cheong andVeidenbaum 1988] Cheong, H., and Veidenbaum, A. V., "A Cache Coherence
Scheme with Fast Selective Invalidation," In:Proceedings ofthe 15th International Symposium
onComputer Architecture, Association for Computing Machinery, New York, NY, pp.299-307
(1988).
[Cheriton 1986]Cheriton, D. R.,"Problem-Oriented Shared Memory: A Decentralized Approach to
Distributed SystemDesign," In:Proceedings ofthe 6thInternational Conference on Distributed
Computing Systems, IEEE, New York, pp. 190-197 (May 1986).
[Cheriton et al. 1991] Cheriton, D. R.,Goosen,H.A.,and Boyle, P. D., "Paradigm: A Highly
Scalable Shared-Memory Multicomputer Architecture," IEEE Computer, Vol. 24,No.2,pp.
33-46(1991).
[CoxandFowler1989JCox, A. L., and Fowler, R.1.,"The Implementation of aCoherent Memory
Abstraction on a NUMAMultiprocessor: Experiences with PLATINUM," In:Proceedings ofthe
12thSymposium on Operating Systems Principles, Association for Computing Machinery, New
York, NY,pp. 32-34(December 1989).
[Dasgupta et al. 1991] Dasgupta, P.,LeBlanc, R.L, Ahmad, Jr.,M.,and Ramachandran, U.~"The
CloudsDistributed Operating System," IEEEComputer, Vol.24, No. 11, pp. 34-44(1991).
[Delp1988] Delp, G.S.•"TheArchitecture andImplementation of MemNet: An Experiment on
High-Speed Memory Mapped Network Interface," Ph.D. Dissertation, Department ofComputer
Science, University of Delaware (1988).
[Delpet al, 1991] Delp, G. S.,Farber, D. J., Minnich, R. G.,Smith,1.M.,and Tam,M. C.,"Memory
as a Network Abstraction," IEEE-'Network, Vol. 5,pp.34-41(1991).
[Dubois et al, 1986] Dubois, M.,Scheurich, C.,and Briggs, F.A., "Memory Access Buffering in
Multiprocessors," In:Proceedings oftheJ3thAnnualSymposium on Computer Architecture,
Association forComputing Machinery, New York, NY,pp. 343-442 (1986).
[Duboiset al, 1988] Dubois, M.,Scheurich, C.,and Briggs, F.A.,"Synchronization, Coherence, and
Event Ordering in Multiprocessors," IEEE Computer, Vol. 21,No.2,pp.9-21(1988).
[Fekete et al. 1995] Fekete,A, Kaashoek, F., and Lynch, N.~"Providing Sequentially-Consistent
Shared Objects Using Group and Point-to-Point Communication," In:Proceedings oftheJ5th
International Conference on Distributed Computing Systems, IEEE,New York (May-June
1995).
[Fleisch 1987] Fleisch, B. D., "Distributed Shared Memory in a Loosely Coupled Distributed
System," In: Proceedings ofthe1987ACMSIGCOMM Workshop, Association for Computing
Machinery, New York, NY (1987).
[FleischandPopek1989] Fleisch, B. D., and Popek, G. J., "Mirage: ACoherent Distributed Shared
Memory Design," In:Proceedings ofthe12thACM Symposium on Operating System Principles,
Association forComputing Machinery, New York, NY,pp. 211-223 (December 1989).
[Forinet al. 1989] Forin, A., Barrera, L, Young, M., and Rashid, R.,"Design, Implementation, and
Performance Evaluation of a Distributed Shared Memory Server for Mach," In: Proceedings of
the1989Winter Usenix Conference (January 1989).
[Frank1984] Frank, S. J.,"Tightly Coupled Multiprocessor System Speeds Memory-Access
Times,"Electronics, pp.164-169 (January 1984).
[Garcia MolinaandWiederhold 1982]Garcia-Molina, H., and Wiederhold, G., "Read-Only
Transactions in a Distributed Database," ACMTransactions on Database Systems, Vol.7,No.2,
Association forComputing Machinery, New York, NY,pp. 209-234 (1982).278 Chap. 5 • Distributed Shared Memory
[Gharachorloo et al.1990]Gharachorloo, K., Lenoski, D., Laudon, J., Gibbons, P, Gupta, A.,and
Hennessy, J., "Memory Consistency and Event Ordering inScalable Shared-Memory Multi­
processors," In:Proceedings ofthe 17th Annual Symposium on Computer Architecture,
Association forComputing Machinery, New York, NY, pp. 15-26(1990).
[Gharachorloo et al.1991]Gharachorloo, K., Gupta, A.,and Hennessy, J., "Performance
Evaluation of Memory Consistency Models for Shared-Memory Multiprocessors," In:Proceed­
ingsofthe 4th International Conference on Architectural Support for Programming Languages
and Operating Systems, IEEEComputer Society Press, Los Alamitos, CA, pp. 245-257
(1991).
[Ghose 1995] Ghose, K., "SNOW: Hardware Supported Distributed Shared Memory over a
Network ofWorkstations," In:Proceedings ofthe 24th Annual International Conference on
Parallel Processing, IEEE, New York (August 1995).
[Goodman 1983]Goodman, J. R.,"UsingCache Memory to Reduce Processor-Memory Traffic,"
In:Proceedings ofthe 10th Annual Symposium on Computer Architecture, Association for
Computing Machinery, New York, NY, pp. 124-131 (June1983).
[Goodman 1989]Goodman, 1.R.,"CacheConsistency andSequential Consistency," Technical
Report No. 61,IEEEScalable Coherent Interface Working Group, IEEE, New York (1989).
[Goodman et al, 1989]Goodman, 1.R., Vernon, M. K., and Woest, P.1., "Efficient Synchronization
Primitives forLarge-Scale Cache-Coherent Multiprocessors," In:Proceedings ofthe 3rd
International Conference on Architectural Support forProgramming Languages and Operating
Systems, IEEEComputer Society Press, Los Alamitos, CA, pp.64-73(1989).
[HartyandCheriton 1992] Harty, K., and Cheriton, D.,"Application-Controlled Physical Memory
Using External Page-Cache Management," In:Proceedings ofthe 5th International Conference
on Architectural Support for Programming Languages and Operating Systems, Association for
Computing Machinery, New York, NY, pp. 187-]99 (1992).
[Hutto and Ahamad 1990] Hutto, P.W.,and Ahamad, M., "Slow Memory: Weakening Consistency
toEnhance Concurrency inDistributed SharedMemories," In:Proceedings ofthe 10th
International Conference on Distributed Computing Systems, IEEE, New York, pp. 302-311
(1990).
[Johnson et al, 1995] Johnson, D., Lilja, D., and Riedl, J., "A Circulating ActiveBarrier
Synchronization Mechanism," In:Proceedings ofthe 24th Annual International Conference on
Parallel Processing, IEEE, New York (August]995).
[Katz et al, 1985] Katz, R. H., Eggers, S. 1., Wood, D. A.,Perkins, C. L., and Sheldon, R. G.,
"Implementing aCacheConsistency Protocol," In:Proceedings ofthe 12thAnnualSymposium
on Computer Architecture, Association forComputing Machinery, New York, NY, pp. 276-283
(June1985).
[Keleher et al, 1992] Keleher, P.,Cox, A. L., and Zwaenepoel, W.,"Lazy Release Consistency," In:
Proceedings ofthe 19th International Symposium on Computer Architecture, Association for
Computing Machinery, New York, NY, pp. ]3-21(1992).
[Kessler and Livny 1989] Kessler, R. E., and Livny, M., "An Analysis ofDistributed Shared
Memory Algorithms," In:Proceedings ofthe 9th International Conference on Distributed
Computing Systems, IEEE, New York, pp. 98-104(June1989).
[Kranzet al,1993] Kranz, D., Johnson, K.,Agarwal, A.,Kubiatowicz, J. J., and Lim, B.,
"Integrating Message Passingand Shared Memory: Early Experiences," In:Proceedings ofthe
4th Symposium on Principles and Practice ofParallel Programming, Association forComputing
Machinery, New York, NY, pp. 54-63(May1993).Chap.5 • Bibliography 279
[Lamport 1979]Lamport, L.,"HowtoMakeaMultiprocessor Computer ThatCorrectly Executes
Multiprocess Programs," IEEE Transactions on Computers, Vol.C-28,IEEE,New York, pp.
690-69] (1979).
[Lenoski andWeber1995)Lenoski, D. E.,and Weber, W. D.,Scalable Shared-Memory
Multiprocessing, Morgan Kaufmann, SanFrancisco, CA(1995).
[Lenoski etal,1992]Lenoski, D.,Laudon, J.,Gharachorloo, K., Weber, W. D., Gupta,A.,
Hennessy, J.,Horowitz, M., and Lam, M,S.,"TheStanford DashMultiprocessor," IEEE
Computer, Vol.25,No.3,pp.63-79(1992).
(Lenoski etal, 1993J Lenoski, D.,Laudon, 1., Joe, T., Nakahira, D.,Steves,L.,Gupta,A.,and
Hennessy, J.,"TheDASHPrototype: LogicOverhead andPerformance," IEEE Transactions on
Parallel and Distributed Systems, Vol.4,No.1,pp.41-61(1993).
[Li1986] Li, K., "Shared Virtual Memory onLoosely Coupled Multiprocessors," Ph.D.
Dissertation, Technical ReportNo.YALE/DCS/RR-492, Department ofComputer Science, Yale
University (September 1986).
[Li1988]Li,K.,"IVY: A SharedVirtualMemory SystemforParallelComputing," In:Proceedings
oftheInternational Conference on Parallel Processing. IEEE, New York, pp. 94-101(August
1988).
[LiandHudak1989] Li, K., andHudak.P.,"Memory Coherence inSharedVirtualMemory
Systems," ACM Transactions on Computing Systems, Vol.7,No.4,pp.321-359 (1989).
[LiandSchaefer 19891Li, K., andSchaefer, R.,"AHypercube SharedVirtualMemory System,"
In:Proceedings oftheInternational Conference on Parallel Processing, Pennsylvania State
University Press,pp.125-132(]989).
(Lilja1993JLilja,D.1.,"CacheCoherence inLarge-Scale Shared-Memory Multiprocessors: Issues
andComparisons," AC~MComputing Surveys, Vol.25,pp.303-338 (1993).
[LiptonandSandberg 1988]Lipton,R.1.,andSandberg, J.S.,"Pram:AScalable Shared
Memory," Technical ReportNo.CS-TR-]80-88,Princeton University (1988).
[Liskov19881Liskov,B.,"Distributed Programming inArgus,"Communications ofthe ACM, Vol.
31,No.3,pp.300-313 (J988).
[Minnich andFarber1989]Minnich, R. G.,and Farber, D.J.,"TheMetherSystem:ADistributed
SharedMemory forSunOS4.0,"In:Proceedings ofthe/989Summer Usenix Conference, pp.
5]-60(1989).
[Minnich andFarber19901Minnich, R. (]., and Farber,D.1.,"Reducing HostLoad,Network
Load, and Latency in aDistributed SharedMemory," In:Proceedings ofthe 10th International
Conference on Distributed Computing Systems, IEEE,New York (June )990).
[Mosberger 1993]Mosberger, D.,"Memory Consistency Models," Technical ReportNo.TR93/11,
Department ofComputer Science, University ofArizona (1993).
[Nitzberg andVirginia Lo1991]Nitzberg, N.,andVirginiaLo,"Distributed SharedMemory:A
SurveyofIssuesandAlgorithms," IEEE Computer, Vol.24,No.11,pp.52-60(1991).
[Oguchi etal,1995]Oguchi,M.,Aida,H.,andSaito,T., "AProposal for aDSMArchitecture
Suitable for aWidelyDistributed Environment and ItsEvaluation," In:Proceedings ofthe 4th
International Symposium on High Performance Distributed Computing, IEEE,New York
(August 1995).
[Ramachandran andKhalidi1989JRamachandran. U., andKhalidi,M.Y.A., HAn Implementation
ofDistributed SharedMemory," First Workshop on Experiences with Building Distributed and
Multiprocessor Systems, UsenixAssociation, Berkeley, CA,pp.21-38(1989).280 Chap. 5 • Distributed SharedMemory
[Sane et al, 1990] Sane,A.,MacGregor, K., and Campbell, R.,"Distributed VirtualMemory
Consistency Protocols: DesignandPerformance," Second IEEE Workshop on Experimental
Distributed Systems, IEEE, New York, pp. 91-96(October 1990).
[Scheurich andDubois 1988] Scheurich, C., and Dubois,M.,"Dynamic PageMigration in
Multiprocessors withDistributed GlobalMemory," In:Proceedings ofthe 8th International
Conference on Distributed Computing Systems, IEEEComputer SocietyPress, Los Alamitos,
CA, pp. 162-169 (June 1988).
[Shrivastava etal. 1991]Shrivastava, S., Dixon, G. N., and Parrington, G. D., "An Overview of the
ArjunaDistributed Programming-System," IEEE Software, pp.66-73(January 1991).
[SinghalandShivaratri 1994]Singhal,M.,andShivaratri, N. G.,Advanced Concepts inOperating
Systems, McGraw Hill,New York (1994).
[Sinhaet al. 1991] Sinha,P.K.,Ashihara, H.,Shimizu,K.,andMaekawa, M.,"Flexible User­
Definable Memory Coherence Scheme inDistributed SharedMemory ofGALAXY," In:
Proceedings ofthe 2nd European Distributed Memory Computing Conference (EDMCC2),
Springer-Verlag, New York, pp. 52-61(April 1991).
[Smith1982]Smith,A.J.,"CacheMemories," ACM Computing Surveys, Vol. 14, No.3,pp.
437-530, New York, NY (1982).
[StummandZhou1990]Stumm,M.,andZhou,S.,"Algorithms Implementing Distributed Shared
Memory," IEEE Computer, Vol. 23,No.5,New York, NY, pp. 54-64(1990).
[18mandUsu 1990] Tam, V.,and Hsu,M.,"FastRecovery inDistributed SharedVirtualMemory
Systems," In:Proceedings ofthe 10th International Conference on Distributed Computing
Systems, IEEE, New York, pp.38-45(May-June 1990).
(18m et al, 1990] Tam,M.C.,Smith,J.M., and Farber, D.J.,"ATaxonomy-Based Comparison of
SeveralDistributed SharedMemory Systems," Operating Systems Review, Vol.24,pp.40-67
(1990).
[Tartalja andMilutinovic 1996]Tartalja,I.,andMilutinovic, V.(Eds.), The Cache Coherence
Problem in Shared-Memory Multiprocessors: Software Solutions, IEEEComputer SocietyPress,
LosAlamitos, CA (1996).
[TheelandFleisch 1995] Theel,O.E.,andFleisch,B.D.,"Design andAnalysis ofHighly
Available andScalable Coherence Protocols forDistributed SharedMemory Systems Using
Stochastic Modeling," In:Proceedings ofthe 24th Annual International Conference on Parallel
Processing, IEEE,New York (August 1995).
[WuandFuchs1989]Wu,K.L.,and Fuchs, W.K.,"Recoverable Distributed SharedVirtual
Memory: Memory Coherence andStorageStructures," In:Proceedings ofthe 19th International
Symposium on Fault-Tolerant Computing, pp.520-527 (June 1989).
[Yenetal,1985]Yen,D.W.L.,Yen,W.C.,and Fu,K.,"DataCoherence Problem in aMulticache
System," IEEE Transactions on Computers, Vol. C-34, No.1,pp.56-65,New York, NY
(1985).
[Zhou et al. 1990] Zhou,S.,Stumm, M., and McInerney, T.,"Extending Distributed Shared
Memory toHeterogeneous Environments," In:Proceedings ofthe 10thInternational Conference
onDistributed Computing Systems, IEEE, New York, pp. 30-37(May-June 1990).
[Zhouet al. 1992] Zhou, S., Stumm, M., Li, K., and Wortman, D., "Heterogeneous Distributed
SharedMemory," IEEE Transactions on Parallel and Distributed Systems, Vol. 13,No.5,New
York, NY, pp. 540-554 (1992).Chap.5 •PointerstoBibliographies on theInternet
POINTERS TO818UOGRAPHIES ONTHEINTERNET
Bibliography containing references onDistributed SharedMemory can be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslParallelJdsm.html
Bibliography containing references onDistributed Memory Systemscan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographies/ParalleUdistmem.htrnl281
Bibliography containing references onCacheMemories andRelated Topicscan be
found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslMisc/cache.html
Bibliography containing references onSingleAddressSpaceOperating Systems(SASOS)
andRelatedTopicscan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/sasos.htmlCHAPTER6
SynchronizQtion
6.1 INTRODUOION
Adistributed system consists ofacollection ofdistinct processes that are spatially
separated and run concurrently. In systems with multiple concurrent processes, it is
economical to share the system resources (hardware or software) among the concurrently
executing processes . In such a situation, sharing may be cooperative orcompetitive .That
is, since the number of available resources ina computing system is restricted,one process
must necessarily influence the action of other concurrently executing processes as it
competes for resources. For example, for a resource (such as a tape drive) that cannot be
usedsimultaneously by multiple processes, a process willing to use it must wait if another
process is using it. At times, concurrent processes must cooperate either to achieve the
desiredperformance ofthe computing system or due to the nature of the computation
beingperformed .Typical examples of process cooperation involve two processes that bear
aproducer-consumer or client-server relationship to each other. For instance, a client
process and a file server process must cooperate whenperforming file access operations.
Bothcooperative andcompetitive sharing require adherence to certain rules of behavior
thatguarantee that correct interaction occurs. The rules for enforcing correct interaction
areimplemented in the form of synchronization mechanisms. This chapterpresents
282Sec.6.2 • Clock Synchronization 283
synchronization mechanisms that aresuitablefordistributed systems. Inparticular, the
following synchronization-related issues are described:
• Clock synchronization
• Event ordering
• Mutual exclusion
•Deadlock
•Election algorithms
6.2ClOCKSYNCHRONIZATION
Everycomputer needs a timer mechanism (called a computer clock) to keep track of
currenttime and also for various accounting purposes such ascalculating the time spent
by a process in CPU utilization, diskI/(),and so on, so that the corresponding user can
be charged properly. In a distributed system, an application may have processes that
concurrently run on rnultiple nodes of the system. For correctresults, several such
distributed applications require that the clocksof the nodes are synchronized with each
other. For example, for adistributed on-linereservation systemto be fair, the only
remaining seat booked almost simultaneously from two different nodes should be offered
to the client who booked first, even if the time difference betweenthe twobookings is very
small.Itmay not be possibletoguarantee thisifthe clocks of the nodes ofthe system are
notsynchronized. In adistributed system,synchronized clocks also enableone tomeasure
thedurationofdistributed activities that start on one node and terminate onanothernode,
for instance, calculating the time taken to transmita message from one node to anotherat
any arbitrary time. It is difficult to get the correctresult in this case if the clocks of the
sender and receiver nodes are not synchronized. There are several other applications of
synchronized clocks in distributed systems. Some good examples ofsuchapplications
may be found in [Liskov 1993].
Thediscussion above shows that it is the job ofadistributed operating system
designer to devise and use suitablealgorithms forproperly synchronizing theclocksof a
distributed system. This section presentsadescription of suchalgorithms. However, for a
betterunderstanding ofthesealgorithms, we will first discuss how computer clocks are
implemented and what arc the main issues in synchronizing theclocksof adistributed
system.
6.2.1HowComputer ClocksAreImplemented
Acomputer clock usually consistsof threecomponents-a quartz crystal that oscillates at
awell-defined frequency, a counterregister, and a constant register. The constant register
is used to store a constant value that is decidedbasedon thefrequency ofoscillation of
the quartz crystal. The counterregisteris used to keep track of the oscillations ofthe
quartz crystal. That is, the value in the counterregisterisdecremented by1for each
oscillation ofthe quartz crystal. When the value ofthecounterregisterbecomes zero, an284 Chap.6 •Synchronization
interrupt isgenerated and its value is reinitialized to the value in the constant register.
Eachinterrupt iscalledaclocktick.
Tomakethecomputer clockfunction as anordinary clockused by us in our day-to­
day life, the following thingsare done:
1.Thevalue in the constant registerischosenso that60clockticksoccurin a
second.
2.Thecomputer clockissynchronized withrealtime(external clock).Forthis, two
more values are storedin thesystem-a fixedstartingdateand time and the
numberofticks. For example, inUNIX,timebeginsat0000onJanuary1, 1970.
At the time ofinitialbooting,thesystemasks theoperator toenterthecurrentdate
and time. The systemconverts theenteredvalue to the numberofticksafterthe
fixedstartingdate and time. At everyclocktick, the interrupt serviceroutine
increments the value ofthenumberofticks to keep the clockrunning.
6.2.1DriftingorClocks
Aclockalwaysruns at a constant ratebecauseitsquartzcrystaloscillates at awell-defined
frequency. However, due todifferences in thecrystals, the rates at whichtwoclocksrun
arenormally different from each other. The difference in theoscillation periodbetween
twoclocksmightbeextremely small,but the difference accumulated overmany
oscillations leads to an observable difference in thetimesofthe twoclocks,nomatterhow
accurately they were initialized to the same value. Therefore, with the passageof time, a
computer clockdriftsfromthereal-time clockthat was used for its initialsetting. For
clocksbasedonaquartzcrystal,thedriftrate isapproximately 10-6,givingadifference
of1secondevery1,000,000 seconds, or 11.6 days [Coulouris et al. 1994]. Hencea
computer clockmustbeperiodically resynchronized with the real-time clockto keep it
nonfaulty. Evennonfaulty clocksdo notalwaysmaintain perfecttime.Aclockis
considered nonfaulty ifthereis aboundon theamountofdriftfrom real time for any given
finite time interval.
Moreprecisely, let ussupposethat when the real time is t,the time value of a clock
pisCp(t).Ifallclocksinthe world were perfectly synchronized, wewouldhaveCp(t)=
tfor allpand allt.Thatis, if Cdenotesthe time value ofaclock,in the ideal case dCldt
shouldbe 1.Therefore, if themaximum drift rate allowable isp,aclockis said to be
nonfaulty ifthefollowing condition holdsfor it:
dC
l-p~-~l+p
dt
AsshowninFigure6.1,aftersynchronization with aperfectclock,slow and fast
clocksdriftinopposite directions from the perfectclock.Thisisbecausefor slow clocks
dCldt<1 and for fast clocksdCldt> 1.
Adistributed systemconsistsofseveralnodes,eachwith its own clock,runningat
itsownspeed.Because ofthenonzero driftratesofallclocks,the setofclocksof a
distributed systemdo notremainwellsynchronized withoutsomeperiodic resynchroniza-Slowclock region
dC<1
dtSec. 6.2 • Clock Synchronization
Q)
E
.~
.x:oo[5Fastclock region
dC>1
dtPerfectclock
dC-1dt -285
Fig. 6.1 Slow, perfect, andfast clocks. Realtime
tion. This means that the nodes of a distributed system must periodically resynchronize
their local clocks to maintain a global time base across the entire system. Recall from
Figure 6.1 that slow and fast clocks drift in opposite directions from the perfect clock.
Therefore, oftwo clocks, if one isslow and one is fast, at a time atafter they were
synchronized, themaximum deviation between the time value of the two clocks will be
2pat.Hence, to guarantee that no two clocks in a set of clocks ever differ by more than
0, the clocks in the set must be resynchronized periodically, with the time interval between
twosynchronizations being less than or equal to 0/2p.Therefore, unlike a centralized
system in which only the computer clock has to be synchronized with the real-time clock,
adistributed system requires the following types of clock synchronization:
1. Synchronization ofthecomputer clocks with real-time (or external) clocks. This
typeofsynchronization is mainly required for real-time applications. That is, external
clocksynchronization allows the system to exchange information about the timing of
events with other systems andusers.
An external time source that is often used as a reference forsynchronizing computer
clocks with real time is the Coordinated Universal Time (UTC). The UTC is an
international standard. Many standard bodies disseminate UTesignals by radio,
telephone, and satellite. For instance, the WWV radio station in the United States and the
Geostationary Operational Environmental Satellites (GEOS) are two such standard
bodies.Commercial devices (called timeproviders) areavailable to receive and interpret
these signals. Computers equipped with time provider devices can synchronize their
clocks with these timing signals.
2. Mutual (or internal) synchronization ofthe clocks ofdifferent nodes ofthe system.
This type of synchronization is mainly required for those applications that require a
consistent view of time across all nodes of a distributed system as well as for the
measurement of the duration of distributed activities thatterminate on a node different
from the one on which they start.
Note that externally synchronized clocks are also internally synchronized. However,
theconverse is not true because with the passageof time internally synchronized clocks
may drift arbitrarily far from external time.286 Chap.6 • Synchronization
6.1.3ClockSynchronlzQtlon Issues
We have seen that no two clockscan be perfectly synchronized. Therefore, in
practice, twoclocksare said to be synchronized at aparticular instanceoftime if the
difference in time values of the two clocksis less than somespecified constant 8.
Thedifference in time values oftwoclocksiscalledclock skew. Therefore, a set of
clocksare said to be synchronized if theclockskewofany two clocksin this set is
less than 8.
Clocksynchronization requires each node to read the othernodes'clockvalues.
Theactualmechanism used by a node to read otherclocksdiffersfrom one
algorithm to another. However, regardless ofthe actual readingmechanism, a node
canobtainonly an approximate viewofitsclockskew with respecttoothernodes'
clocksin thesystem. Errorsoccurmainlybecauseofunpredictable communication
delaysduringmessage passing used to deliveraclocksignal or a clockmessage
from one node to another. A minimum valueoftheunpredictable communication
delaysbetween two nodes can be computed bycounting the time neededtoprepare,
transmit, andreceiveanemptymessage in theabsence oftransmission errorsand
anyothersystemload.However, ingeneral, it isratherimpossible tocalculate the
upperboundofthis value because itdepends on theamountofcommunication and
computation goingon inparallelin thesystem,on thepossibility thattransmission
errorswillcausemessages to betransmitted severaltimes, and on otherrandom
events,such as pagefaults,processswitches, or theestablishment ofnewcommu­
nication routes.
Animportant issue in clocksynchronization is that time mustneverrun
backward because thiscouldcauseseriousproblems, such as the repetition ofcertain
operations that may be hazardous incertaincases.Noticethatduringsynchronization
a fastclockhas to be sloweddown.However, if the time ofa fastclockis
readjusted to the actual time all at once, it may lead to running thetimebackward
for that clock.Therefore, clocksynchronization algorithms arenormally designed to
gradually introduce such achangein the fast running clockinsteadofreadjusting it
to thecorrecttime all at once. One way to do this is to maketheinterrupt routine
moreintelligent. Whenanintelligent interrupt routineisinstructed by theclock
synchronization algorithm to slow downitsclock,itreadjusts theamountoftime to
beaddedto theclocktime for each interrupt. Forexample, suppose that if 8msec is
addedto theclocktime on eachinterrupt in thenormalsituation, whenslowing
down, the interrupt routineonlyadds 7msec on each interrupt until the correction
hasbeenmade.Although notnecessary, forsmooth readjustment, theintelligent
interrupt routinemay also advance itsclockforward, if it is found to be slow, by
adding9msec on eachinterrupt, insteadofreadjusting it to the correcttime all at
once.
6.1.4ClockSynchronlzQtlon Algorithms
Clocksynchronization algorithms may be broadly classified ascentralized and
distributed.Sec.6.2 • Clock Synchronization 287
Centralized Algorithms
Incentralized clocksynchronization algorithms one node has a real-time receiver. This
node is usually calledthetimeservernode,and the clock time ofthis node is regarded as
correctand used as the reference time. The goal of the algorithm is to keep the clocksof
allothernodessynchronized with the clock time of the time server node. Depending on
the role of the time server node, centralized clocksynchronization algorithms are again of
twotypes-passive timeserverand active time server.
PassiveTime Server Centralized Algorithm. In this method, each node
periodically (with the interval between two periods being less than or equal to 8/2p)sends
amessage ("time=?")to the time server. When the time server receives the message, it
quickly responds with a message ("time=T"),whereTis the current time in the clock of
the time server node. Let us assume that when the client node sends the "time=?"
message, its clock time is To,and when itreceives the "time=T"message, its clocktime
isT).SinceToandT)are measured using the same clock, in the absence of any other
information, the best estimate of the time required for thepropagation of themessage
"time=T"from the time server node to the client'snode is(T1-To)/2.Therefore, when
the reply is received at the client'snode, its clockisreadjusted to'T+(T1-To)/2.
Since there may be unpredictable variation in the message propagation timebetween
two nodes, (T)-To)/2is not a very good estimate of the time to be added to Tfor
calculating thecurrenttime of the client'snode clock. Several proposals have been made
to improve this estimated value. Two such methods are described below. The first one
assumes the availability of someadditional information and the second one assumes that
no additional information is available:
1. In this method, it is assumed that the approximate time taken by the time server
to handle the interrupt and process a "time=?" request message is known. Let this time
be equal to 1. Then a better estimate ofthe time taken for propagation ofthe message
"time=J'"from the tirne server node to the client'snode would be (T)-To-/)/2.
Therefore, in this method, when the reply is received at the client'snode, its clock is
readjusted toT+(T)-To- I)/2.
2. This method was proposed byCristian [1989]. In this method, several
measurements ofT)-Toare made, and those measurements for which T)-Toexceeds
somethreshold value are considered to beunreliable and discarded. The average ofthe
remaining measurements is thencalculated, and half of the calculated value is used as the
value to be added to T.Alternatively, the measurement for which the value of T 1-Tois
minimum isconsidered to be the 1110staccurate one, and halfofthis value is used as the
value to be added to T.One limitation of this approach is the need to restrictthenumber
ofmeasurements forestimating the value to be added to T,since these are directly related
to the message traffic generated and theoverhead imposed by the algorithm.
Active Time Server Centralized Algorithm. In the passive time server
approach, the time server only responds to requests for time from other nodes. On the other
hand, in the active time server approach, the time server periodically broadcasts its clock
time("time=T").The other nodes receive the broadcast message and use the clock time in288 Chap.6 •Synchronization
the message for correcting their own clocks. Each node has a priori knowledge ofthe
approximate time(To)required forthe propagation ofthe message "time=T"from thetime
sever node toitsownnode.Therefore, whenthebroadcast message isreceived atanode,the
node'sclock isreadjusted tothetime T+To.Amajordrawback ofthismethod isthatitisnot
fault tolerant. If the broadcast message reaches too late at a node due to some
communication fault,theclock ofthatnode willbereadjusted toan incorrect value.Another
drawback of this approach is that it requires broadcast facility to besupported by the
network.
Another active time server algorithm that overcomes thedrawbacks of the above
algorithm istheBerkeleyalgorithm. Itwasproposed byGusella andZatti [1989] forinternal
synchronization ofclocks of a group of computers running the Berkeley UNIX. In this
algorithm, the time server periodically sends a message ("time=?")to all the computers in
the group. On receiving this message, each computer sends back its clock value to the time
server. The time server has a priori knowledge of the approximate time required for the
propagation ofa message from each node to itsown node. Based on this knowledge, it first
readjusts theclock values ofthe reply messages. Itthen takes efault-tolerantaverage ofthe
clock values ofall thecomputers (including itsown).Totake the fault-tolerant average, the
time server chooses asubset of allclock values that do not differ from one anotherby more
than aspecified amount, and the average is taken only for the clock values in this subset.
Thisapproach eliminates readings from unreliable clocks whose clock values could have a
significant adverse effect ifan ordinary average was taken.
Thecalculated average is the current time to which all the clocksshould be
readjusted. The time server readjusts its own clock to this value. However, instead of
sending the calculated currenttime back to the other computers, the time server sends the
amount by which each individual computer's clock requires adjustment. This can be a
positive or a negative value and is calculated based on the knowledge the time server has
about the approximate time required for the propagation of a message from each node to
its own node.
Centralized clocksynchronization algorithms suffer from two major drawbacks:
I. They are subject to single-point failure. If the time server node fails, the clock
synchronization operation cannot be performed. This makes the system unreli­
able. Ideally, a distributed system should be more reliable than its individual
nodes. If one goes down, the rest should continue to function correctly.
2. From a scalability point of view it is generally not acceptable to get all the time
requests serviced by a single time server. In a large system, such a solution puts
a heavy burden on that one process.
Distributed algorithms overcome these drawbacks.
Distributed Algorithms
Recall that externally synchronized clocks are also internally synchronized. That is, if
eachnode'sclock is independently synchronized with real time, all the clocks of the
system remain mutually synchronized. Therefore, a simple method for clock synchroniza-Sec.6.2 • Clock Synchronization 289
tion may be to equip each node of the system with a real-time receiverso that each node's
clock can be independently synchronized with real time. Multiple real-time clocks (one
for each node) are normally used for this purpose.
Theoretically, internal synchronization of clocks is not required in this approach.
However, in practice, due to the inherent inaccuracy of real-time clocks, different real­
time clocks produce different time. Therefore, internal synchronization is normally
performed for better accuracy. One of the following two approaches is usually used for
internalsynchronization in this case.
GlobalAveraging Distributed Algorithms. In this approach, the clock process
at each node broadcasts its local clock time in the form of a special "resync" message
when its local time equals To+iRfor some integer i,whereTois a fixed time in the past
agreed upon by all nodes and Ris a system parameter that depends on such factors as the
total number of nodes in the system, the maximum allowable drift rate, and so on. That
is, a resync message is broadcast from each node at the beginning of every fixed-length
resynchronization interval. However, since the clocks of different nodes run at slightly
different rates, these broadcasts will not happen simultaneously from all nodes.
Afterbroadcasting the clock value, the clock process of a node waits for time T,
whereTis aparameter to be determined by the algorithm. During this waiting period, the
clock process collects the resync messages broadcast by other nodes. For each resync
message, the clock process records the time, according to its own clock, when the message
was rcceived. At the end of the waiting period, the clock process estimates the skew of its
clock with respect to each of the other nodes on the basis of the times at which it received
resync messages. Itthen computes a fault-tolerant average of the estimated skews and uses
itto correct the local clock before the start of the next resynchronization interval.
The global averaging algorithms differ mainly in the manner in which the fault­
tolerant average of the estimated skews is calculated. Two commonly used algorithms are
described here:
1. Thesimplestalgorithm is to take the average of the estimated skews and use it as
thecorrection for the local clock. However, to limit the impact of faulty clocks on the
average value, the estimated skew with respect to each node is compared against a
threshold, and skews greater than the threshold are set to zero before computing the
average of the estimated skews.
2. In another algorithm, each node limits the impact of faulty clocks by first
discarding the mhighest and m lowest estimated skews and then calculating the average
of the remaining skews, which is then used as the correction for the local clock. The value
ofmis usually decided based on the total number of clocks (nodes).
Localized Averaging Distributed Algorithms. The global averaging algo­
rithms do not scale well because they require the network to support broadcast facility and
also because of the large amount of message traffic generated. Therefore, they are suitable
for small networks, especially for those that have fully connected topology (in which each
node has a direct communication link to every other node). The localized averaging
algorithms attempt to overcome these drawbacks of the global averaging algorithms. In290 Chap.6 •Synchronization
this approach, the nodes of a distributed system are logically arranged in some kind of
pattern, such as a ring or a grid. Periodically, each node exchanges its clock time with its
neighbors in the ring, grid, or other structure and then sets its clock time to the average
ofits own clock time and the clock times of its neighbors.
6.2.5(aseStudy:Distributed nmeService
Twopopularservices for synchronizing clocks and for providing timing information over
a wide variety ofinterconnected networks are the Distributed Time Service (DTS) and the
Network Time Protocol (NTP). DTS is a component of DCE (Distributed Computing
Environment) that is used to synchronize clocksofa network of computers running DCE,
and NTP is used in the Internet for clock synchronization. DTS is briefly described below
as a case study of clock synchronization. Details of NTP can be found in [Mills 1991].
In aDeEsystem, each node is configured as either a DTSclientor aDTS server. On
each DTS client node runs a daemon process called a DTS clerk. Tosynchronize its local
clock, each DTS clerk makes requests to the DTS servers on the same LAN for timing
information. The DTS servers provide timing information to DTS clerks or to other DTS
servers upon request. Tomake them publicly known, each DTS server exports its name to
a LAN profile.
DTS does not define time as a single value. Instead, time is expressed as an interval
containing thecorrecttime. By using intervals instead of values, DTS provides the users
with aclearideaofhow faroffthe clock might befrom reference time.
A DTS clerk synchronizes its local clock in the following manner. It keeps track of
the drift rate ofits local clock, and when itdiscovers that the time error of the local clock
hasexceeded the allowable limit, it initiates resynchronization by doing an RPC with all
the DTS servers on its LAN requesting for the time. Each DTS server that receives this
message returns a reply containing a time interval based on the server'sown clock. From
thereceived replies, the DTS clerk computes its new value of time in the following
manner(see Fig. 6.2 for an example). At first, time intervals that do not intersect with the
majorityoftime intervals are considered tobe faulty and discarded. For instance, in Figure
6.2, the value supplied by DTS server 3 is discarded. Then the largest intersection falling
within the remaining intervals is computed. The DTS clerk then resets its clock value to
themidpoint ofthis interval. However, instead ofresetting the clock to the calculated
value all at once, an intelligent interrupt routine is used to gradually introduce such a
change in the clock time.
Note that due to the use ofthe method of intersection for computing new clock value,
it isrecommended that each LAN in a DCE system should have at least three DTS servers
toprovidetime information.
In addition to DTS clerks synchronizing their clocks with DTS servers, the DTS
serversofa LAN also communicate among themselves periodically to keep their clocks
mutually synchronized. They also use the algorithm of Figure 6.2 to compute the new
clock value.
So far we have seen how clocks of nodes belonging to the same LAN are
synchronized. However, a DCE system.may have several interconnected LANs. In this
case, a need arises to synchronize the clocks of all nodes in the network. For this, one DTSSec.6.2 • Clock Synchronization
Timeintervals
suppliedby
DTSserver1
DTSserver2
DTSserver3
DTSserver 4Discarded
interval-----.~ Time291
Largestintersection falling
withintheremaining intervals I
I
Midpointofthisinterval
isthenewclock value
Fig.6.2 Computationof new clock value in DTS fromobtained time intervals.
server of each LAN is designated. a global server. Although not necessary for external
synchronization, it isrecommended that each global server be equipped with a time
provider device to receive UTesignals. The global servers of all LANs communicate
amongthemselves periodically to keep their clocks mutually synchronized. Since the
global server of a LAN is also a DTS server, its clock value is automatically used to
synchronize the clocks of other nodes in the LAN. In this manner, DTS synchronizes the
clocks of all nodes in the network.
DTS istransparent toDeEusers in the sense that users cannot access DTS directly.
However, DTS application programming interface (API) provides a rich set of library
procedures to allow DTS applications to perform time-related activities to control their
executions. In particular, there are library procedures to get the current time, to convert
between binary and ASCII representations of time, to manipulate binary time information,
tocompare two times, to perform arithmetic operations on times, to get time zone
information, and so on. In addition, there is an administrative interface to DTS that allows
a system administrator to perform administrative operations such as configuring and
dynamically reconfiguring the number of DTS clients and DTS servers on a LAN,292 Chap.6 •Synchronization
changing a DTS server into a global server when the global server of a LAN fails, and
setting the maximum inaccuracy and error tolerance to decide how frequently
resynchronization should take place.
6.3EVENTORDERING
Keeping the clocks in a distributed system synchronized to within 5 or 10msec is an
expensive and nontrivial task. Lamport [1978] observed thatfor most applications it is not
necessary to keepthe clocks in a distributed system synchronized. Rather, it is sufficient
to ensure that all events that occur in a distributed system be totally ordered in a manner
that isconsistent with an observed behavior.
For partial ordering of events, Lamport defined a new relation called happened­
beforeand introduced the concept of logical clocks for ordering of events based on the
happened-before relation. He then gave a distributed algorithm extending his idea of
partial ordering to a consistent total ordering of all the events in a distributed system. His
idea is presented below.
6.3.1HOPfMn.d-kfor. Ralotlon
Thehappened-before relation (denoted by ~)on a set of events satisfies the following
conditions:
1. Ifaandbare events in the same process and aoccurs before b,thena~b.
2. Ifais the event of sending a message by one process and bis the event of the
receipt of the same message by another process, then a~b.This condition holds
by the law ofcausality because a receiver cannot receive a message until the
sender sends it, and the time taken to propagate a message from its sender to its
receiveris always positive.
3. Ifa~bandb~c,thena~c.That is,happened-before isa transitive relation.
Notice that in a physically meaningful system, an event cannot happen before itself,
that is,a~ais not true for any event a.This implies that happened-before is an
irreflexive partial ordering on the set of all events in the system.
In terms of the happened-before relation, twoevents aandbare said to be concurrent
if they are not related by the happened-before relation. That is, neither a~bnorb--7a
is true. This is possible if the two events occur in different processes that do not exchange
messages eitherdirectly or indirectly via other processes. Notice that this definition of
concurrency simply means that nothing can be said about when the two events happened
or which one happened first. That is, two events are concurrent if neither can causally
affect the other. Due to this reason, the happened-before relation is sometimes also knownas the relation of
causalordering.
Aspace-time diagram (such as the one shown in Fig. 6.3) is often used to illustrate
the concepts ofthehappened-before relation and concurrent events. In this diagram, eachSec. 6.3 • Event Ordering 293
ProcessP1 Process P2 ProcessP3
Fig.6.3 Space-time diagram for three processes.
vertical line denotes a process, each dot on a vertical line denotes an event in the
corresponding process,and each wavy line denotes a message transfer from one process
to another in the direction of the arrow.
From this space-time diagram it is easy to see that for two events aandb,a~bis
true ifand only if there exists apath from atobby moving forward in timealong process
and message lines in the direction of the arrows. For example, some of the events of
Figure 6.3 that are related by the happened-before relation are
elO~ell
e30~e24
ell~e32e20~e24ell~e23 e2l~el3
(sincee30-)e22ande22~e24)
(sinceeII~e23'e23~e24'ande24~e32)
On the other hand, two events aandbare concurrent if and only if no path exists
either from atoborfrOITIbtoa.For example, some of the concurrent events ofFigure
6.3 are
6.3.2 logical ClocksConcept
To determine that an event ahappened before an event b,either a common clock or
a set of perfectly synchronized clocks is needed. We have seen that neither of these is
available in a distributed system. Therefore, in a distributed system the happened-before
relation must be defined without the use of globally synchronized physical clocks.294 Chap.6 •Synchronization
Lamport [1978]provided a solution for this problem by introducing theconcept of
logical clocks.
The logical clocks conceptis a way to associate atimestamp (which may be simply
anumberindependent ofany clock time) with each system event so that events that are
related to each otherby thehappened-before relation(directly orindirectly) can be
properly orderedin thatsequence. Underthis concept, each processP;has a clock C;
associated with it that assigns a numberC,{a)to any event ain that process. The clock of
eachprocessiscalleda logical clockbecausenoassumption is made about the relation of
thenumbers C;(a)tophysical time. In fact, the logical clocks may beimplemented by
counters with no actual timing mechanism. With each process having its own clock, the
entire system ofclocks is represented by the function C, which assigns to any event bthe
numberC(b),whereC(b)=Cj(b)ifbis an event in process Pj.
The logical clocks ofa system can be considered to becorrectif the events of the
system that are related to each other by the happened-before relationcan beproperly
orderedusing these clocks. Therefore, thetimestamps assigned to the events by the system
of logical clocksmust satisfy the following clock condition:
For any two eventsaandb.ifa~b.thenC(a)<C(b).
Note that we cannotexpecttheconverse condition to hold as well, since that would
imply that any two concurrent events must occurat the same time, which is not necessarily
true for all concurrent events.
6.3.3Impl.m.ntatlon of logical Clocks
From the definition ofthehappened-before relation, it follows that the clockcondition
mentioned above is satisfied if the following conditions hold:
Cl:Ifaandbare two events within the same process Piandaoccurs before b,then
Ci(a)<Cj(b).
C2:Ifais the sending of a message by process Piandbis the receipt ofthat message
byprocessPj,thenC;(a)<Cj(b).
Inadditionto theseconditions, which are necessary to satisfy theclock condition, the
following condition isnecessary for thecorrectfunctioning ofthe system:
C3:AclockC,associated with aprocessPimust always go forward, never
backward. That is,corrections to time of a logical clock must always be made by
addingapositivevalue to the clock, never by subtracting value.
Obviously, anyalgorithm used forimplementing a set of logical clocks must satisfy
all these three conditions. Thealgorithm proposed byLamport is given below.
To meet conditions CI,C2, and C3, Lamport's algorithm uses the following
implementation rules:Sec. 6.3 • Event Ordering 295
IRl:EachprocessPiincrements C,between any twosuccessive events.
IR2:If eventais the sending of a message mby process Pi'themessagemcontains
atimestamp Tm=Cia),and upon receiving the message maprocessPjsetsC,greater
than or equal to its present value but greaterthanTm:
RuleIR1ensuresthatcondition C1issatisfiedand rule IR2 ensures that condition C2
is satisfied. Both IR1and IR2 ensure that condition C3 is also satisfied. Hence the simple
implementation rules IR1 and IR2 guarantee a correct system oflogical clocks.
Theimplementation of logical clocks can best be illustrated with anexample. How
a system oflogical clocks can be implemented either by using counters with no actual
timingmechanism or by using physical clocks is shown below.
Implementation of Logical Clocks byUsingCounters
As shown in Figure 6.4, two processes PIandP2each have a counterCIandC2,
respectively. The counters act as logical clocks. At the beginning, the counters are
initialized to zero and a process increments itscounterby 1whenever an event occurs in
that process. If the event is sending of a message (e.g., events e04ande14),the process
includes the incremented value of the counterin the message. On the other hand, if the
event isreceiving of a message (e.g., events e)3ande~g),instead of simply incrementing
thecounterby1, a check is made to see iftheincremented countervalue is less than or
equal to the timestamp in the received message. If so, the countervalue iscorrected and
e13C2=-35
since 3 is less than
timestamp 4
Process P2--"'-------- .........- C2=0C1=8eoa
C1=7eo7
C1=6 Bos
Q) C1=5 Bos
Et=C1=4 904
C1=3 e03
C1=2 Bo2
C1=1eo1
C1=O
ProcessPt
Fig. 6.4 Example illustrating the implementation of logical clocks byusing counters.296 Chap.6 • Synchronization
set to 1plus the timestamp in the received message (e.g., in event eJ3).If not, the counter
value is left as it is (e.g., in event e08).
Implementation of Logical Clocks by Using Physical
Clocks
Theimplementation of the example of Figure 6.4 by using physical clocks instead of
counters is shown in Figure 6.5. In this case, each process has a physical clock associated
with it. Each clock runs at a constantrate. However, the ratesat which different clocks run
are different. For instance, in the example of Figure 6.5, when the clock ofprocessPIhas
ticked 10 times, the clock of process P2has ticked only 8 times.
Physicalclocktimes
aftercorrections (ifany)Physicalclocktimes if
nocorrectionsweremade
e08 101
110 8893
907100 8085614
80690 7277
90s80 64 69
CD 70 5661913Ei=Bo460 48------------- ..
50 40-------------- ....80340 32 812--------------80230 24-----------------20 16911-------------- ----eo110 8--------------0 0
ProcessP1 ProcessP2
Fig. 6.5 Example illustrating the implementation of logical clocks by using physical
clocks.
To satisfy condition CI, the only requirement is that the physical clock of a
process must tick at least once between any two events in that process. This is usually
not a problem because a computer clock is normally designed to click several times
between two events that happen in quick succession. To satisfy condition C2, for aSec.6.4 • MutualExclusion 297
message-sending event (e.g., events e04andeI4),the process sending the message
includes its currentphysical time in the message. And for a message-receiving event
(e.g., events el3ande~g),a check is made to see if the current time in the receiver's
clock is less than or equal to the time included in the message. If so, the receiver's
physical clockiscorrected by fast forwarding its clock to be1 more than the time
included in themessage (e.g., in event e13).If not, the receiver's clock is left as it is
(e.g., in event e~g).
6.3.4TotalOr.rlng ofEv.nts
We have seen how a system of clocks satisfying the clock condition can be used to
order the events of a system based on the happened-before relationship among the
events. We simply need to order the events by the times at which they occur.
However, recall that the happened-before relation is only a partial ordering on the set
of all events in the system. With this event-ordering scheme, it is possible that two
eventsaandbthat are not related by the happened-before relation (either directly or
indirectly) may have the same timestamps associated with them. For instance, if
eventsaandbhappenrespectively inprocesses PIandP2'when the clocks of both
processes show exactly the same time (say 100), both events will have a timestamp of
100. In this situation, nothing can be said about the order of the two events.
Therefore, for total ordering on the set of all system events, an additional requirement
is desirable: No two events ever occur at exactly the same time. To fulfill this
requirement, Lamport proposed the use of any arbitrary total ordering of the processes.
For example, process identity numbers may be used to break ties and to create a total
ordering of events. For instance, in the situation described above, the timestamps
associated with events aandbwill be 100.001 and 100.002, respectively, where the
process identity numbers of processes PIand.P2are 001 and 002, respectively. Using
this method, we now have a way to assign a unique timestamp to each event in a
distributed system to provide a total ordering of all events in the system.
6.4MUTUAL EXCLUSION
There are several resources in a system that must not be used simultaneously bymultiple
processes ifprogram operation is to be correct. For example, a file must not be
simultaneously updated by multiple processes. Similarly, use of unit record peripherals
such as tape drives or printers must be restricted to a single process at a time. Therefore,
exclusive access to such a. shared resource by a process must be ensured. This
exclusiveness of access is called mutual exclusion between processes. The sections of a
program that need exclusive access to shared resources are referred to as critical sections.
For mutual exclusion, means are introduced to prevent processes from executing
concurrently within their associated critical sections.
Analgorithm forimplementing mutualexclusion must satisfy the following
requirements:298 Chap.6 • Synchronization
1. Mutual exclusion. Given a shared resource accessed by multiple concurrent
processes, at any time only one process should access the resource. That is, a
process that has been granted the resource must release it before itcan be granted
to another process.
2.No starvation. If every process that is granted the resource eventually releases it,
every request must beeventually granted.
Insingle-processor systems, mutual exclusion is implemented using semaphores,
monitors, and similar constructs. The three basic approaches used by different algorithms
forimplementing mutual exclusion in distributed systems are described below. Interested
readers who want to explore further on this topic may refer to [Agarwal and Abbadi 1991,
Bulgannawar and Vaidya 1995, Rayna11991, Sanders 1987,Suzuki and Kasami 1985].To
simplify our description, weassume that each process resides atadifferent node.
6.4.1C.ntrallzM Approach
In this approach, one of the processes in the system is elected as the coordinator
(algorithms for electing a coordinator are described later in this chapter) and coordinates
the entry to the critical sections. Each process that wants to enter a critical section must
first seek permission from the coordinator. If no other process is currently in that critical
section, the coordinator canimmediately grant permission to the requesting process.
However, if two or more processes concurrently ask for permission to enter the same
critical section, the coordinator grants permission to only one process at a time in
accordance with some scheduling algorithm. After executing a critical section, when a
process exits the critical section, it must notify the coordinator so that the coordinator can
grantpermission toanotherprocess (if any) that has also asked for permission to enter the
same critical section.
An algorithm for mutual exclusion that uses the centralized approach is described
here with the help of an example. As shown in Figure 6.6, let us suppose that there is a
coordinator process(Pc:)and three other processes PI'P2,andP3in the system. Also
assume that the'requests are granted in the first-come, first-served order for which the
coordinator maintains a request queue. Suppose PIwants to enter a critical section for
which it sends a requestmessage to Pc.On receiving the request message, Pcchecks to
see whether some otherprocessiscurrently in that critical section. Since no other process
is in the critical section, P;immediately sends back a replymessage granting permission
toPl.When the reply arrives, PIenters the critical section.
Now suppose that while PIis in the critical section P2asks forpermission to enter
the same critical section by sending a request message to Pc.SincePIis already in the
critical section, P2cannotbegranted permission. The exact method used to deny
permission varies from one algorithm to another. For our algorithm, let us assume that the
coordinator does not return any reply and the process that made the request remains
blocked until itreceives the reply from thecoordinator. Therefore, P,does not send a reply
toP2immediately and enters its request in the request queue.
Again suppose that while PIis still in the critical section P3also sends a request
message to P;asking for permission to enter the same critical section. Obviously, P3Sec.6.4 • MutualExclusion
Fig. 6.6 Example illustrating thecentralized
approach for mutual exclusion.299
Q)
en
«SQ)
Q)a:e
L.....-IInitialstatus
~__--.l~Statusafter@~ Statusafter @
~~~ St~usafterQD
____ ---'1Status after <V
Status of
requestqueue
cannotbegrantedpermission, so no reply is sent immediately toP3byPC'and itsrequest
isqueuedin therequestqueue.
Nowsuppose PIexitsthecriticalsectionandsendsareleasemessage toP;releasing
itsexclusive accessto thecriticalsection.Onreceiving thereleasemessage,P;takes the
firstrequestfrom the queueofdeferred requests and sends a reply message to the
corresponding process, granting itpermission toenterthecriticalsection.Therefore, in
this case, P;sends a reply message toPz.
Onreceiving the reply message, P2entersthecriticalsection,and when it exits the
criticalsection,it sends a releasemessage toPc.AgainP;takesthe firstrequestfrom the
requestqueue(in this case requestofP3)and sends a reply message to thecorresponding
process(P3)'Onreceiving the reply message, P3entersthecriticalsection,andwhenit
exits the criticalsection,itsendsareleasemessage toPc.Now since there are no more
requests,P,keepswaitingfor the next requestmessage.
Thisalgorithm ensuresmutualexclusion because, at a time, the coordinator allows
only one processtoenteracriticalsection.Thealgorithm alsoensuresthat nostarvation
willoccurbecauseofthe useoffirst-come, first-served scheduling policy. The main
advantages ofthisalgorithm is that it is simpletoimplement andrequires only three
messages percriticalsectionentry: arequest,a reply, and a release. However, itsuffers
from the usual drawbacks ofcentralized schernes. Thatis, asinglecoordinator issubject300 Chap.6 •Synchronization
to a single point of failure and can become a performance bottleneck in a large system.
Furthermore, for failure handling, means must be provided to detect a failure of the
coordinator, to elect a unique new coordinator, and to reconstruct its request queue before
thecomputation can be resumed.
6.4.1Dlstribut.d Approach
In thedistributed approach, the decision making for mutual exclusion is distributed across
theentire system. That is,all processes that wanttoenter thesamecritical section cooperate
with each other before reaching a decision on which process will enter the critical section
next.The firstsuchalgorithm waspresented byLamport [1978]basedonhis event-ordering
schemedescribed in Section ·6.3. Later, Ricart and Agrawala [1981] proposed a more
efficient algorithm that also requires there be atotal ordering of allevents in the system.As
an example of a distributed algorithm for mutual exclusion, Ricart and Agrawala's
algorithm isdescribed below.Inthe following description weassume that Lamport's event­
ordering scheme is used to generatea unique timestamp foreach event inthe system.
When a process wants to enter a critical section, it sends a request message to all
other processes. The message contains the following information:
1. The process identifier of the process
2. The name of the critical section that the process wants to enter
3. A unique timestamp generated by the process for the request message
On receiving a request message, a process either immediately sends back a reply
message to the sender or defers sending a reply based on the following rules:
1.Ifthereceiverprocess is itselfcurrently executing in the critical section, it simply
queues the request message and defers sending a reply.
2. If the receiver process is currently not executing in the critical section but is
waiting for its turn to enter the critical section, it compares the timestamp in the
received request message with the timestamp in its own request message that it
has sent to other processes. If the timestamp of the received request message is
lower, it means that the senderprocess made a request before the recciver process
to enter the critical section. Therefore, the receiver process immediately sends
back a reply message to the sender. On the other hand, if the receiverprocess's
own request message has a lower timestamp, the receiverqueues the received
request message and defers sending a reply message.
3. If the receiverprocess neither is in the critical section nor is waiting for its turn
to enter the critical section, it immediately sends back a reply message.
A process that sends out a request message keeps waiting for reply messages from
other processes. Itenters the critical section as soon as ithas received reply messages from
all processes. After it finishes executing in the critical section, it sends reply messages to
allprocesses in its queue and deletes them from its queue.Sec.6.4 • MutualExclusion 301
To illustrate how the algorithm works, let us consider the example of Figure 6.7.
There are four processes PI,P2'P3'andP4'While process P4is in a critical section,
processesPIandP2want to enter the same critical section. To get permission from other
processes, processes PIandP2send request messages with timestamps 6 and 4
respectively to other processes (Fig. 6.7(a)).
Now let us consider the situation in Figure 6. 7(b).Since process P4is already in the
critical section, itdefers sending a reply message to PIandP2and enters them in its
queue. Process P3is currently not interested in the critical section, so it sends a reply
TS=6
Fig. 6.7 Example illustrating the distributed algorithm for mutual exclusion: (a)status
when processes PIandP2send request messages to other processes while
processP4is already in the critical section; (b)status while process P4is
still in critical section; (c)status after process P4exits critical section; (d)
status after process P2exits critical section.302 Chap.6 • Synchronization
message to bothPIandPz.ProcessPzdefers sending a reply message toPIand enters
P1in its queue becausethetimestamp (4) in its own request message is less than the
timestamp (6) inPI'Srequestmessage. On the other hand, PIimmediately replies to P2
becausethetimestamp (6) in its requestmessage is found to be greaterthan thetimestamp
(4)ofP2'Srequest message.
Nextconsider thesituation in Figure 6.7{c).When process P4exits the critical
section, it sends a reply message to allprocesses in its queue (in this case to processes PI
andP2)and deletes them from its queue. Now since process P2hasreceived a reply
message from all other processes (PI'P3,andP4),it enters the critical section. However,
processPIcontinues to wait since it has not yet received a reply message from process
P2•
Finally, when process P2exits the critical section, it sends areply message toPI(Fig.
6.7(d».Now since process PIhasreceived a reply message from all other processes, it
enters the critical section.
Thealgorithm guarantees mutualexclusion because a process can enterits critical
section only after getting permission from all other processes, and in the case of a conflict
only one oftheconflicting processes can getpermission from all otherprocesses. The
algorithm also ensures freedom from starvation since entry to the critical section is
scheduled according to thetimestamp ordering. Ithas also been proved by Ricart and
Agrawala [1981] that the algorithm is free from deadlock. Furthermore, if there are n
processes, thealgorithm requiresn-Irequestmessages andn-lreplymessages, giving a
totalof2(n-I)messages per critical section entry. However, this algorithm suffers from
the following drawbacks becauseoftherequirement that allprocesses mustparticipate in
a critical section entry request by any process:
1. In a system having nprocesses, thealgorithm is liable to npoints of failure
because ifone of the processes fails, the entire scheme collapses. This is because the failed
process will not reply to requestmessages that will be falsely interpreted as denial of
permission by therequesting processes, causingall therequesting processes to wait
indefinitely.
Tanenbaum [1995] proposed a simple modification to thealgorithm to solve this
problem. In the modified algorithm, insteadofremaining silent by deferring the sending
ofthe reply message in cases when permission cannot be granted immediately, the
receiver sends a"permission denied"replymessage to therequesting processand then
later sends an OKmessage when the permission can be granted. Therefore, a reply
message (either"permission denied" or OK) is immediately sent to the requesting process
in any case. Iftherequesting processdoes not receive a reply from a process within a fixed
timeoutperiod, it eitherkeeps trying until the process replies or concludes that the process
has crashed. When the requesting process receives a "permission denied"reply message
from one or more oftheprocesses, itblocks until an OK message is received from all of
them.
2. Thealgorithm requires that each process know the identity of all the processes
participating in themutual-exclusion algorithm. Thisrequirement makesimplementation
ofthealgorithm complex becauseeach process ofa group needs to dynamically keep trackSec.6.4 • MutualExclusion 303
ofthe processes entering or leaving the group. Thatis, when aprocess joins agroup, it
must receive the names of all the other processes in the group, and the name of the new
process must be distributed to all the other processes in the group. Similarly, when a
processleavesthegrouporcrashes, allmembers ofthatgroupmust beinformed so that
they can deleteit from theirmembership list.Updating ofthemembership list is
particularly difficultwhenrequestand reply messages arealreadybeingexchanged among
theprocesses ofthe group. Therefore, thealgorithm issuitableonly for groupswhose
member processes are fixed and do not changedynamically.
3. In this algorithm, aprocesswillingtoenteracriticalsectioncan do so only after
communicating with all otherprocesses andgettingpermission from them. Therefore,
assuming that thenetwork canhandleonly one message at a time, the waitingtime from
themoment theprocessmakesarequesttoenteracriticalregionuntil itactuallyenters
thecriticalsectionis the time for exchanging 2(n-1)messages in asystemhavingn
processes. Thiswaitingtime may be large if thereare too many processes in thesystem.
Therefore, thealgorithm issuitableonly for a small groupofcooperating processes.
Someimprovements to thisalgorithm have been proposed in theliterature. For
instance, asimpleimprovement ispossible byusingthe idea of majority consensus
ratherthan the consensus ofallotherprocesses forcriticalsectionentry[Tanenbaum
1995].Thatis, in an algorithm that uses the idea ofmajority consensus, aprocesscan
enteracriticalsectionas soon as it has collected permission from amajority ofthe
otherprocesses, ratherthan from all ofthem. Note that in this algorithm aprocesscan
grantpermission for acriticalsectionentryto only a singleprocessat a time. Two other
possible improvements to thealgorithm can befoundin[Carvalho andRoucairol 1983,
Maekawa et al.1987).
6.4.3Token-Passing Approach
In thismethod, mutualexclusion isachieved by using a singletoken that is circulated
amongtheprocesses in thesystem.Atokenis aspecialtypeofmessage thatentitlesits
holdertoenteracriticalsection.Forfairness, theprocesses in thesystemarelogically
organized in a ring structure, and the token is circulated from one processtoanother
aroundthe ringalwaysin the same direction (clockwise oranticlockwise).
Thealgorithm works as follows. Whenaprocessreceives the token, it checksif it
wants to enteracriticalsectionand acts as follows:
• Ifitwants to enteracriticalsection,itkeepsthetoken,entersthecriticalsection,
and exits from the criticalsectionafterfinishing its work in the criticalsection.It
thenpassesthe token alongthe ring to its neighbor process. Note that the process
canenteronly one criticalsectionwhenitreceives the token. If itwantstoenter
anothercriticalsection,itmust wait until itgets the token again.
• Ifitdoes not want to enteracriticalsection,itjustpassesthe token alongthe ring
to itsneighbor process.Therefore" ifnoneoftheprocesses isinterested inentering
acriticalsection,thetokensimplykeepscirculating aroundthe ring.304 Chap.6 •Synchronization
Mutual exclusion isguaranteed bythealgorithm becauseatanyinstance of timeonly
one process can be in a critical section, since there is only a single token. Furthermore,
since the ring is unidirectional and a process is permitted toenter only one critical section
each time it gets the token, starvation cannot occur. In this algorithm the number of
messages per critical section entry may vary from 1(when every process always wants to
enter a critical section) to an unbounded value (when no process wants to enter a critical
section). Moreover, for a total of nprocesses in the system, the waiting time from the
moment a process wants to enter a critical sectionuntil its actual entry may vary from the
time needed to exchange 0 to n-ltoken-passing messages. Zero token-passing messages
are needed when the process receives the token just when it wants to enter the critical
section, whereas n-Imessages are needed when the process wants to enter the critical
sectionjustafter it has passed the token to its neighbor process.
The algorithm, however, requires the handling of the following types of failures:
1. Processfailure. A process failure in the system causes the logical ring to break.
In such a situation, a new logical ring must be established to ensure the continued
circulation of the tokenamong other processes. This requires detection of a failed process
and dynamic reconfiguration ofthe logical ring when a failed process is detected or when
a failed process recovers after failure.
Detection of a failed process can be easily done by making ita rule that a
process receiving the token from its neighbor always sends an acknowledgment
message to its neighbor. With this rule, a process detects that its neighbor has failed
when it sends the token to it but does not receive the acknowledgment message within
a fixed timeout period. On the other hand, dynamic reconfiguration of the logical ring
can be done by maintaining the current ring configuration with each process. When a
process detects that its neighbor has failed, it removes the failed process from the
group by skipping itand passing the token to the process after it (actually to the next
alive process in the sequence). When a process becomes alive after recovery, it simply
informs the neighbor previous to it in the ring so that it gets the token during the next
round of circulation.
2.Losttoken.If the token is lost, a new token must be generated. Therefore, the
algorithm must also have mechanisms to detect and regenerate a lost token. One method
to solve this problem is to designate one of the processes on the ring as a "monitor"
process. The monitor process periodically circulates a "who has the token?" message on
the ring. This.message rotates around the ring from one process to another.All processes
simply pass this message to their neighbor process, except the process that has the tokenwhen it receives this message. This process writes its identifier in a special field of the
message before passing it to its neighbor. When the message returns to the monitor
process after one complete round, it checks the special field of the message. If there is no
entry in this field, it concludes that the token has been lost, generates a new token, and
circulates it around the ring.
There are two problems associated with this
method-the monitor process may
itself fail and the "who has the token?" message may itself get lost. Both problems may
be solvedbyusing more than one monitor processes. Each monitor process independ­
ently checks the availability of the token on the ring. However, when a monitor processSec.6.5 • Deadlock 305
detects that the token is lost, it holds an electionwithothermonitorprocesses to decide
whichmonitorprocess will generate and circulate a new token (election algorithms are
described later in this chapter). An election is needed to preventthegeneration of
multiple tokens that may happen when each monitor process independently detects that
the token is lost, and each one generates a new token.
6.5DEADLOCK
We saw in the previous section that there are several resources in a system for which
the resource allocation policy must ensure exclusive access by a process. Since a system
consists of a finite number of units of each resource type (for example, three printers,
six tape drives, four disk drives, two CPUs, etc.), multiple concurrent processes
normally have to compete to use a resource. In this situation, the sequence of events
required to use a resource by a process is as follows:
I. Request. The process first makes a request for the resource. If the requested
resource is not available, possibly because itis being used by another process, the
requesting process must wait until the requested resource is allocated to it by the
system. Note that if the system has multiple units of the requested resource type, the
allocation of any unit of the type will satisfy the request. Also note that a process may
request as many units of a resource as it requires with the restriction that the number
of units requested may not exceed the total number of available units of the
resource.
2.Allocate. The system allocates the resource to the requesting process as soon
as possible. It maintains a table in which itrecordswhether each resource is free or
allocated and,ifit isallocated, to which process. If the requested resource is currently
allocated to another process, the requesting process is added to a queue ofprocesses
waiting for this resource. Once the system allocates the resource to the requesting
process, that process can exclusively use the resource by operating on it.
3. Release. After the process has finished using the allocated resource, it releases the
resource to the system. The system table records are updated at the time of allocation and
release to reflect the current status of availability of resources.
The request and release of resources are system calls, such as requestandreleasefor
devices,openandclosefor files, and allocateandfreefor memory space. Notice that of
the three operations, allocateis the only operation that the system can control. The other
twooperations are initiated by a process.
With the above-mentioned pattern of request, allocation, and release of resources,
if the total request made by multiple concurrent processes for resources of a certain
type exceeds the amount available, some strategy is needed to order the assignment of
resources in time. Care must be taken that the strategy applied cannotcause a
deadlock, that is, a situation in which competing processes prevent their mutual
progress even though no single one requests more resources than are available. It may306 Chap.6 • Synchronization
happen that some ofthe processes that entered the waiting state (because the requested
resources were not available at the time of request) will never again change state,
because the resources they have requested are held by other waiting processes. This
situation is calJed deadlock, and the processes involved are said to be deadlocked.
Hence, deadlock is the state of permanent blocking of a set of processes each of
which is waiting for an event that only another process in the set can cause. All the
processes in the set block permanently because all the processes are waiting and hence
none of them will ever cause any of the events that could wake up any of the other
members ofthe set.
Adeadlock situation can be best explained with the help of an example. Suppose
that a system has two tape drives TIandT2and the resource allocation strategy is
such that a requested resource is immediately allocated to the requester if the resource
is free. Also suppose that two concurrent processes PIandP2make requests for the
tape drives in the following order:
1.PIrequests for one tape drive and the system allocates TIto it.
2. P2requests for one tape drive and the system allocates T2to it.
3.PIrequests for one more tape drive and enters a waiting state because no tape
drive is presently available.
4. P2requests for one more tape drive and it also enters a waiting state because no
tape drive is presently available.
From now on, PIandP2will wait for each other indefinitely, since PIwill not
releaseTIuntil it gets T2to carry out its designated task, that is, not until P2has
released T2,whereas Pzwill not release T2until it gets TI.Therefore, the two
processes are in a state of deadlock. Note that the requests made by the two processes
are totally legal because each is requesting for only two tape drives, which is the total
numberoftape drives available in the system. However, the deadlock problem occurs
because the total requests of both processes exceed the total number ofunits for the
tape drive and the resource allocation policy is such that it immediately allocates a
resource on request if the resource is free.
In the context ofdeadlocks, the term "resource" applies not only to physical
objects (such as tape and disk drives, printers, CPU cycles, and memory space) but
also to logical objects (such as a locked record in a database, files, tables, semaphores,
and monitors). However, these resources should permit only exclusive use by a single
process at a time and should be nonpreemptable. Anonpreemptable resource is one
that cannot be taken away from a process to which it was allocated until the process
voluntarily releases it. If taken away, it has ill effects on the computation already
performed by the process. For example, a printer is a nonpreemptable resource
because taking the printer away from a process that has started printing but has not
yetcompleted its printing job and giving itto another process may produce printed
output that contains a mixture of the output of the two processes. This is certainly
unacceptable.Sec. 6.5 • Deadlock
6.5.1Necessary Conditions forDeadlock307
Coffman et al. [1971] stated that the following conditions arenecessary for adeadlock
situation tooccurina system:
1.Mutual-exclusion condition. If aresource is held by a process, anyotherprocess
requesting for thatresource must wait until the resource has been released.
2.Hold-and-wait condition. Processes areallowed torequestfor new resources
withoutreleasing theresources that they are currently holding.
3.No-preemption condition. Aresource that has been allocated toaprocessbecomes
available forallocation toanotherprocessonly after it has been voluntarily
released by the process holdingit.
4.Circular-wait condition. Two or more processes must form acircularchainin
which each processiswaiting for a resource thatisheld by the next memberof
thechain.
All fourconditions must hold simultaneously in asystemfor adeadlock to occur.If
anyoneof them is absent,nodeadlock can occur. Noticethat the four conditions are not
completely independent because thecircular-wait condition impliesthehold-and-wait
condition. Although these four conditions aresomewhat interrelated, it is quite usefulto
consider themseparately to devise methods fordeadlock prevention.
6.5.2Deadlock Modeling
Deadlocks canbemodeledusingdirectedgraphs.Beforepresenting agraphical model for
deadlocks, someterminology from graph theory isneeded:
1.Directed graph.Adirected graph is a pair (N, E),whereNisanonempty setof
nodes and Eis a set of directededges.Adirected edge is an orderedpair(a,b),
whereaandbare nodes in N.
2.Path.Apath is a sequence of nodes (a, b, c,...,i,j)of adirectedgraph such that
(a,b), (b,c),...,(i,j)aredirectededges.Obviously, a pathcontains at least two
nodes.
3. Cycle. Acycle isapath whose first and last nodes are the same.
4.Reachable set.Thereachable setofa nodeais the set ofall nodes bsuch that a
pathexistsfromatob.
5.Knot.A knot.is a nonempty setKof nodes such that the reachable set of each node
inKisexactlythe setK.A knotalwayscontains one or more cycles.
Anexample of adirectedgraph isshowninFigure6.8. The graph has a set of nodes
{a,b,c,d,e,f}and a set of directededges{(a,b), (b,c), (c,d), (d,e),(e,j),if,a), (e,
b)}.It has two cycles(a,b,c,d,e,f,a)and(b,C,d,e,b).It also has a knot {a,b,C,d,
e,11thatcontains the two cycles of the graph.308 Chap.6 •Synchronization
e
Fig. 6.8 A directed graph.
For deadlock modeling, a directed graph, called a resourceallocation graph,is used
in which both the set ofnodes and the set of edges are partitioned into two types, resulting
in the following graph elements:
1. Process nodes. A process node represents a process of the system. In a resource
allocation graph, it is normally shown as a circle, with the name of the process written
inside the circle (nodes PI'Pz,andP3ofFig. 6.9).
2. Resource nodes. Aresource node represents a resource of the system. In a
resource allocation graph, it is normally shown as a rectangle with the name ofthe
resource written inside the rectangle. Since a resource type R,may have more than one
unit in the system, each such unit is represented as a bullet within the rectangle. For
instance, in the resource allocation graph of Figure 6.9, there are two units ofresourceRJ,
one unitofR2,and three units ofR3•
3.Assignment edges.An assignment edge is a directed edge from a resource node to
a process node. It signifies that the resource is currently held by the process. In multiple
units of a resource type, the tail of an assignment edge touches one ofthe bullets in the
rectangle to indicate that only one unit of the resource is held by that process. Edges (R1,
PI),(RI,P3),and(R2,P2)are the three assignment edges in the resource allocation graph
of Figure 6.9.
4.Requestedges.A request edge isadirected edge from a process node to aresource
node. It signifies that the process made a request for a unit of the resource type and is
currently waiting for that resource. Edges (PI'R2)and(P2,RI)are the two request edges
in the resource allocation graph of Figure 6.9.Sec.6.S •Deadlock 309
GAprocessnamedPi'
I:RjIAresourceRjhaving3unitsinthe system.
~ ProcessPiholdingaunitofresourceRj'
~ ProcessPirequesting foraunitof resourceRj'
Fig. 6.9 Resource allocation graph.
Constructing a Resource Allocation Graph
A resource allocation graph provides an overall view of the processes holding or waiting
for the various resources in the system. Therefore, the graph changes dynamically as the
processes in the system request for or release resources or the system allocates a resource
to a process. That is, when a process Pirequests for a unit of resource type Rj,arequest
edge(Pi' Rj)is inserted in the resource allocation graph. When this requestcan be
fulfilled, a unit of resource R,isallocated toPiand the request edge (Pi' Rj)is
instantaneously transformed to anassignment edge(Rj,Pi).Later, when PireleasesRj,the
assignment edge(Rj,Pi)is deleted from the graph.
Note that in many systems the resource allocation graph is not constructed in the
above-mentioned manner. Rather it is used as a tool for making resource allocation
decisions that do not lead to deadlock. In these systems, for the available resources,
different request/release sequences are simulated step by step, and afterevery step, the
graph is checked for deadlock. Later, in the resource allocation strategy, only those310 Chap.6 •Synchronization
sequences are allowed that do not lead to deadlock. Therefore, in these systems, the
resource allocation graph is basically used to formulate a deadlock free resource allocation
strategy.
Necessary andSufficient Conditions for Deadlock
In aresource allocation graph, acycle isa necessary condition for a deadlock toexist. That
is, if the graph has no cycles, then it represents a state that is free from deadlock. On the
other hand, ifthe graph contains a cycle, a deadlock may exist. Therefore, thepresence of
a cycle in a general resource allocation graph is a necessary but not a sufficient condition
for theexistence of deadlock. For instance, the resource allocation graphofFigure6.9
contains a cycle(PhRz,PZ,RhP,)but does not represent adeadlock state. This is
becausewhenP3completes usingR)and releases it, RIcan beallocated toPz.With both
R1andR2allocated to it, P2can now complete its job after which it will releasebothRI
andR2.As soon as R2is released, it can be allocated to PI'Therefore, allprocesses can
finish their jobone by one.
Thesufficient condition fordeadlock is different for the following different cases:
1. A cycle in the graph is both a necessary and a sufficient condition fordeadlock if
all theresource typesrequested by theprocesses forming the cycle have only a single unit
each.
Forexample, the resource allocation graph of Figure 6.10 shows a deadlock state in
whichprocesses PIandPzaredeadlocked. Notice that in this graph, although there are
three units of resource R3,itis not involved in the cycle (PI ,Rz,Pz,RI ,PI)'BothRIand
Rzthat areinvolved in the cycle have only one unit each. Therefore, the cycle represents
adeadlock state.
2. A cycle in the graph is a necessary but not a sufficient condition fordeadlock if
one or more of the resource types requested by the processes forming the cycle have more
than one unit. In thiscase, a knot is a sufficient condition fordeadlock.
Fig.6.10 Acy.clerepresenting a deadlock.Sec. 6.5 • Deadlock 311
Wehavealreadyseenthatthecycle (PI'R2,P2,R},PI)inthegraphofFigure6.9
doesnotrepresentadeadlock. ThisisbecauseresourcetypeRIhastwounitsandthereare
noknotsinthe graph.Nowsupposethatinthesamegraph P3requestsforR2andarequest
edge(P3'Rz)is added to the graph. The modified graph is shownin Figure 6.11. This
graph has two cycles(PI'R2,P2,«;PI)and(P3,R2,P2,R},P3)and a knot {PI'Pz,
P3,R.,R2}.Sincethe graph contains a knot,itrepresents adeadlock state in which
processes p.,Pz,andP3aredeadlocked.
Fig. 6.11 A knotrepresenting a deadlock.
In terms of the resource allocation graph, the necessary andsufficient conditions for
deadlock can besummarized as follows:
• Acycle is a necessary condition fordeadlock.
• If there is only a single unit of each resource t.ypeinvolved in the cycle, a cycle
is both a necessary and asufficient condition for adeadlock to exist.
• If one or more of the resource types involved in the cycle have more than one unit,
a knot is a sufficient condition for adeadlock to exist.
Wait-for Graph
When all the resource types have only a single unit each, a simplified form ofresource
allocation graph is normally used. The simplified graph is obtained from the original
resource allocation graph by removing theresource nodes and collapsing theappropriate
edges. This simplificat.ion is based on the observation that a resource can always be
identified by itscurrentowner(process holding it). Figure 6.12 shows an exampleof a
resource allocation graph and its simplified form.
Thesimplified graph is commonly known as a wait-forgraph (Wf-'G) because it
clearly shows which processes arewaitingfor which otherprocesses. For instance, in the
WFGofFigure6.12(b),processes PIandP3arcwaitingforP2and process Pziswaiting
forPJ•Since WFG is constructed only when each resource type has only a single unit, a
cycle is both a necessary andsufficient condition fordeadlock in a WFG.312 Chap.6 •Synchronization
.....----Simplified to--+
(a) (b)
Fig.6.12 Aconversion from a resource allocation graph to a WFG:
(0)resource allocation graph; (b)corresponding WFG.
6.5.3Handling Deadlocks InDistributed Systems
In principle, deadlocks in distributed systems are similar to deadlocks in centralized
systems. Therefore, the description of deadlocks presented above holds good both for
centralized and distributed systems. However, handling of deadlocks in distributed
systems is more complex than incentralized systems because the resources, the processes,
and other relevant information are scattered on different nodes of the system.
Three commonly used strategies to handle deadlocks are as follows:
1. Avoidance. Resources are carefully allocated to avoid deadlocks.
2. Prevention. Constraints are imposed on the ways in which processes request
resources in order to prevent deadlocks.
3. Detection and recovery. Deadlocks are allowed to occur and adetection algorithm
is used to detect them. After a deadlock is detected, it is resolved by certain
means.
Although the third strategy isthe mostcommonly usedone indistributed systems, for
completion, the other two strategies will also bebriefly described.
At this point, it may also be noted that some people prefer to make a distinction
between two kinds of distributed deadlocks-resource deadlocks andcommunication
deadlocks. As already described, a resource deadlock occurs when two or more
processes wait permanently for resources held by each other. On the other hand, a
communication deadlock occurs among a set of processes when they are blocked
waiting for messages from other processes in the set in order to start execution but
there are no messages in transit between them. When there are no messages in transit
between any pair of processes in the set, none of the processes will ever receive aSec.6.5 • Deadlock 313
message. This implies that all processes in the set are deadlocked. Communication
deadlocks can be easily modeled byusing WFGs to indicate which processes are
waiting to receive messages from which other processes. Hence, the detection of
communication deadlocks canbedone in the same manneras that for systems having
only one unit of each resource type.
Deadlock Avoidance
Deadlock avoidance methods use some advance knowledge of the resource usage of
processes to predict the future state of the system for avoiding allocations that can
eventually lead to a deadlock. Deadlock avoidance algorithms are usually in the following
steps:
1. When a process requests for a resource, even if the resource is available for
allocation, it is not immediately allocated to the process. Rather, the system
simplyassumes that the request is granted.
2. With the assumption made in step 1and advance knowledge of the resource usage
ofprocesses, the system performs some analysis to decide whether granting the
process's request is safe or unsafe.
3. The resource is allocated to the process only when the analysis of step 2 shows
that it is safe to do so; otherwise the request is deferred.
Since the algorithms for deadlock avoidance are based on the concept of safe and
unsafe states, it is important to look at the notion of safety inresource allocation. A system
is said to be in a safe state if it is not in a deadlock state and there exists some ordering
of theprocesses inwhich the resource requests of the processes can be granted to run all
of them to completion. For aparticular safe state there may be many such process
orderings. Any ordering of the processes that can guarantee thecompletion of all the
processes is called a safe sequence. The formation of a safe sequence is based on the idea
of satisfying the condition that, for any process Piin a safe sequence, the resources that
Pican still request can be satisfied by the currently available resources plus the resources
held by all the processes lying before Piin the safe sequence. This condition guarantees
that process Pican be run to completion because if the resources that Pineeds are not
immediately available, Pican wait until all other processes in the sequence lying before
Pihave finished. When they have finished, Pican obtain all its needed resources and run
tocompletion. A system state is said to be unsafeif no safe sequence exists for that
state.
The concept of safe and unsafe states can be best illustrated with the help of an
example. Let us assume that in a system there are a total of 8 units of a particular resource
type for which three processes PI'Pz,andP3arecompeting. Suppose the maximum units
of the resource required byPJ,Pz,andP3are 4, 5, and 6, respectively. Also suppose that
currently each of the three processes is holding 2 units of the resource. Therefore, in the
current state of the system, 2 units of the resource are free. The current state of the system
can be modeled as shown in Figure 6.13(a).314 Chap.6 • Synchronization
P1P2P3
IMax 45 6
IHolds 222
(a)Free=2
P1P2P3
IMax 45 6
IHolds 422
(b)Free=0,
P1P2P3IMax - 5 6
IHolds 022
/~
P1P2P3 P1P2P3
IMax - 56IMax- 5 6
fHolds 0 52IHolds 0 2 6
(d)Free=1 (~Free=0,"P1P2 P3 P1P2P3
IMax - - 6 tMax - 5-
IHoldsa0 2 IHolds 02a
(e)Free=6 (g)Free=6
Fig. 6.13 Demonstration that the state in (a)is a safe state and has two safe sequences.
Now let us tryto find out whether the state of Figure 6.13(a)is safe or unsafe. The
analysis performed in Figure 6.13 shows that this state is safe because there exists a
sequence ofallocations that allows all processes to complete. In fact, as shown in the
figure, for this state there are two safe sequences, (PhP2' P3)and(PhP3' P2).Let us
see thescheduling of the resource units for the first of these two safe sequences. Starting
from the state of Figure 6.13(a),thescheduler could simply run PIexclusively, until it
asked for and got two more units of the resource that are currently free, leading to the state
of Figure 6.13(b).WhenPIcompletes and releases the resources held by it, we get the
state of Figure 6.13(c). Then the scheduler chooses to run P2'eventually leading to the
state of Figure 6.13(d). When P2completes and releases the resources held by it, the
system enters the state of Figure 6.13(e).Now with the available resources, P3can be run
to completion. The initial state of Figure 6.13(a)is a.safe state because the system, by
careful scheduling, can avoid deadlock. This example also shows that for a particular state
there may be more than one safe sequence.Sec. 6.5 • Deadlock 315
Ifresource allocation is not done cautiously, the system may move from a safe state
to an unsafe state. For instance, let usconsider theexample shown in Figure 6.14. Figure
6.14(a)is the same initial state as that of Figure 6.l3(a).This time, suppose processP2
requests for one additional unit of the resource and the same is allocated to it by the
system. The resulting system state is shown in Figure 6.14(b).The system is no longer in
a safe state becausewe only have one unit oftheresource free, which is not sufficient to
run anyofthe three processes tocompletion. Therefore, there is no safe sequence for the
stateofFigure6.14(b).Thus the decision to allocate one unit ofthe resource to P2moved
the system from a safe state to an unsafe state.
Fig. 6.14 Demonstration that anallocation
[nay move the systemfrom a safe
to an unsafe state.P1P2P3
IMax 45 6
IHolds 22 2
(a)Free=2,
P1 P2 P3
IMax 4 5 6
IHolds 2 3 2
(b)Free = 1
It isimportant to note the following remarks about safe and unsafe states:
1. The initial state in which no resources are yetallocated and all are available (free)
is always a safe state.
2. From a safe state, the system can guarantee that allprocesses can be run to
completion.
3. An unsafe state is not a deadlock state, but it may lead to a deadlock state. That
is, from an unsafe state, the system cannotguarantee that all processes can be run
tocompletion.
Deadlock avoidance algorithms basically perform resource allocation in such a
manneras to ensure that the system will always remain in a safe state. Since the initial
stateofa system is always a safe state, whenever aprocessrequests a resource that is
currently available, the system checks to find out if the allocation of the resource to the
process will changethe state of the systemfrom safe to unsafe. If no, the request is
immediately granted; otherwise it is deferred.
Although theoretically attractive, deadlock avoidance algorithms are rarely used in
practicedue to the following reasons:
1. Thealgorithms work on the assumption thatadvance knowledge of theresource
requirements of the various processes is available. However, in practice, processes rarely
know inadvance what their maximum resource needs will be. Modernoperating systems316 Chap.6 •Synchronization
are attempting to provide more and more user-friendly interfaces, and as a result, it is
becoming common to have users who do not have the slightest idea about what their
resource needs are.
2. The algorithms also assume that the number of processes that compete for a
particular resource is fixed and known in advance. However, in practice, the number of
processes is not fixed but dynamically varies as new users log in and log out.
3. The algorithms also assume that the number of units of a particular resource type
is always fixed and known in advance. However, in practice, the actual number of units
available may change dynamically due to the sudden breakdown and repair of one or more
units.
4. The manner in which these algorithms work restricts resource allocation too
severely and consequently degrades the system performance considerably. This is because
the algorithms first consider the worst possible case and then guarantee that the system is
deadlock free even in the worst situation. This worst situation may arise but would be very
unlikely. Thus many safe requests could be turned down.
The practical limitations of deadlock avoidance algorithms become more severe in a
distributed system because the collection of information needed for making resource
allocation decisions at one point is difficult and inefficient. Therefore, the deadlock
avoidance strategy is never used in distributed operating systems.
Deadlock Prevention
This approach is based on the idea of designing the system in such a way that deadlocks
become impossible. It differs from avoidance and detection in that no runtime testing of
potential allocations need be performed.
We saw that mutual-exclusion, hold-and-wait, no-preemption, and circular-wait are
the four necessary conditions for a deadlock to occur in a system. Therefore, if we can
somehow ensure that at least one of these conditions is never satisfied, deadlocks will be
impossible. Based on this idea, there are three important deadlock-prevention methods­
collective requests, ordered requests, and preemption. The first one denies the hold-and­
wait condition, the second one denies the circular-wait condition, and the third one denies
theno-preemption condition.
Themutual-exclusion condition can also be denied for some nonsharable resources
by devising an alternative way of using them. For instance, the following example, taken
from [Tanenbaum 1992], illustrates how this can be done for a printer. A printer is a
nonsharable resource. However, byspooling printer output, several processes can generate
output at the same time. The spooled outputs are.transferred one by one to the printer by
theprinterdaemon. Therefore, the printer daemon is the only process that actually
requests for the physical printer. Since the daemon never requests for any other resources,
deadlock for the printer becomes structurally impossible. Unfortunately, in general, it is
not possible to prevent deadlocks by denying the mutual-exclusion condition because
some resources are intrinsically nonsharable and it is not possible to devise an alternativeSec.6.5 • Deadlock 317
way of using them. Therefore, denial of the mutual-exclusion condition for deadlock
prevention is rarely used. The other three methods that are more commonly used are
described below.
Collective Requests. This method denies the hold-and-wait condition by
ensuring that whenever aprocess requests a resource, itdoes not hold any other resources.
One of the following resource allocation policies may beused to ensure this:
1. A process must request all of its resources before it begins execution. If all the
needed resources are available, they areallocated tothe process sothat the process can run
to completion. If one or more of the requested resources are not available, none will be
allocated and the process would just wait.
2. Instead of requesting all its resources before its execution starts, a process may
request resources during its execution if itobeys the rule that it requests resources only
when it holds no other resources. If the process is holding some resources, it can adhere
to this rule byfirst releasing all of them and then re-requesting all the necessary
resources.
The second policy has the following advantages over the first one:
1. In practice, many processes do not know how many resources they will need until
they have started running. For such cases, the second approach is more useful.
2. A long process may require some resources only toward the end of its execution.
Inthefirst policy,theprocess will unnecessarily hold these resources for theentire
duration of its execution. In the second policy, however, the process can request
for these resources only when it needs them.
Thecollective requests method of deadlock prevention issimple andeffective buthas
the following problems:
1. It generally has low resource utilization because a process may hold many
resources but may not actually use several of them for fairly long periods.
2. It may cause starvation of a process that needs many resources, but whenever it
makes a request for the needed resources, one or more of the resources is not
available.
3. The method also raises an accounting question. When a process holds resources
for extended periods during which they are not needed, itis not clear who should
pay the charge for the idled resources.
OrderedRequests. In this method, each resource type isassigned a unique global
number to impose a total ordering of all resource types. Now a resource allocation policy
is used according to which a process can request a resource at any time, but the process
should notrequest aresource with anumber lower than thenumber of any of the resources
that it is already holding. That is, if.a process holds a resource type whose number is i,it
may request a resource type having the numberj only ifj»i.If the process needs several318 Chap.6 • Synchronization
units of the same resource type, it must issue a single request for all the units. It has been
proven that with this rule the resource allocation graph can never have cycles (denying the
circular-wait condition), and hence deadlock is impossible.
Note that this algorithm does not require that a process must acquire all its resources
in strictly increasing sequence. For instance, a process holding two resources having
numbers 3 and 7 may release the resource having number 7 before requesting a resource
having number 5. This is allowed because when the process requests for the resource
having number 5, it is not holding any resource having number larger than 5.
The ordering of resources is decided according to the natural usage pattern of the
resources. For example, since the tape drive is usually needed before the printer, it would
be reasonable to assign a lower number to the tape drive than to the printer. However, the
natural ordering is not always the same for all jobs. Therefore, a jobthat matches the
decided ordering can be expected to use resources efficiently but others would waste
resources. Another difficulty is that once the ordering is decided, it will stay for a long
time because the ordering iscoded into programs. Reordering will require reprogramming
of several jobs. However, reordering may become inevitable when new resources are
added to the system. Despite these difficulties, the method of ordered requests is one of
the most efficient methods for handling deadlocks.
Preemption. Apreemptable resource is one whose state'can be easily saved and
restored later. Such a resource can be temporarily taken away from the process to which
it is currently allocated without causing any harm to the computation performed so far by
the process. The CPU registers and main memory are examples of preemptable resources.
If the resources are preemptable, deadlocks can be prevented by using either of the
following resource allocation policies that deny the no-preemption condition:
1. When a process requests for a resource that is not currently available, all the
resources held by the process are taken away (preempted) from it and the process is
blocked. The process is unblocked when the resource requested by it and the resources
preempted from it become available and can be allocated to it.
2. When a process requests a resource that is not currently available, the system
checks if the requested resource is currently held by a process that is blocked, waiting for
some other resource. If so, the requested resource is taken away (preempted) from the
waiting process and given to the requesting process. Otherwise, the requesting process is
blocked and waits for the requested resource to become available. Some ofthe resources
that this process is already holding may be taken away (preempted) from it while it is
blocked, waiting for the allocation of the requested resource. The process is unblocked
when the resource requested by it and any other resource preempted from it become
available and can be allocated to it.
In general, the applicability of this method for deadlock prevention is extremely
limited because it works only for preemptable resources. However, the availability of
atomic transactions and global timestamps makes this method an attractive approach for
deadlock prevention in distributed and database transaction processing systems. The
transaction mechanism allows a transaction (process) to be aborted (killed) without any illSec.6.5 • Deadlock 319
effect(transactions aredescribed inChapter 9). This makes it possible topreempt
resources fromprocesses holding them without any harm.
In thetransaction-based deadlock prevention method, each transaction isassigned a
unique priority numberby the system, and when two or more transactions compete for the
sameresource, theirprioritynumbers are used to break the tie. For example, Lamport's
algorithm may be used to generate systemwide globally uniquetimestamps, and each
transaction may be assigned a unique timestamp whenitis created. A transaction's
timestamp may serve as its priority number; a transaction having lower value of timestamp
may have higher prioritybecauseit is older.
Rosenkrantz etat[1978]proposed the following deadlock prevention schemes based
on this idea:
1. Wait-die scheme. In this scheme, ifatransaction 1';requests aresource that is
currently held byanothertransaction 1),T,isblocked(waits) ifits timestamp is lower than
that of1);otherwise it is aborted (dies). For example, suppose that of the three
transactions T1,T2,andT3,1'1is the oldest (has the lowest timestamp value) and T3is the
youngest (has thehighesttimestamp value). Now if T)requests a resource that is currently
held byT2,T1will be blocked and will wait until the resource is voluntarily released by
T2•On theotherhand,ifT3requests a resource held by T2,T3win be aborted.
2. Wait-wound scheme. In this scheme, if a transaction T,requests a resource
currently held byanothertransaction T,T,isblocked(waits) if its timestamp is larger than
that of1);otherwise T,is aborted (wounded byT;).Once again considering the same
exampleoftransactions T), T2,andT),ifTIrequests a resource held by T2,the resource
will bepreempted byabortingT2and will be given to 1').On the other hand, if T3requests
a resource held by T2,T3will be blocked and will wait until the resource is voluntarily
released by T2.
Notice that both schemes favor older transactions, which is quite justified because, in
general, an older transaction has run for a longer period and has used more system
resources than ayoungertransaction. However, the mannerin which the two schemes treat
ayoungertransaction is worth noticing. In the wait-die scheme, a youngertransaction is
aborted when itrequests for a resource held by an older transaction. The aborted
transaction will berestarted after apredetermined time and will be aborted again if the
oldertransaction is still holding the resource. This cycle may be repeated several times
before the younger transaction actually gets the resource. This problem of the wait-die
scheme can be solved by using an implementation mechanism thatensuresthat an aborted
transaction isrestarted only when its requested resource becomes available.
On the other hand, in the wait-wound scheme, when a youngertransaction is aborted
(wounded) by an older transaction, it will be restarted after apredetermined time, and this
timeitwill be blocked (will wait) ifitspreempted resource is being held by the older
transaction. Therefore, theimplementation of thewait-wound scheme is simplerthan the
wait-die scheme. Furthermore, to avoid starvation, it isimportant that in the
implementation of both schemes, a transaction should not be assigned a newtimestamp
when it is restarted after being aborted (a youngertransaction will become olderas time
passes and will not be aborted again and again).320 Chap.6 •Synchronization
Deadlock Detection
In thisapproach fordeadlock handling, the system does not make any attemptto prevent
deadlocks and allows processes torequestresources and to wait for each otherin an
uncontrolled manner. Rather, it uses an algorithm that keeps examining the state ofthe
systemtodetermine whether a deadlock has occurred. When a deadlock isdetected, the
systemtakes some action to recoverfrom the deadlock. Somemethods fordeadlock
detection indistributed systems are presented below, and some ofthe ways to recover
from adeadlock situation arepresented in the next section.
Inprinciple, deadlock detection algorithms are the same in both centralized and
distributed systems. It is based on maintenance ofinformation onresource allocation to
variousprocesses in the form ofaresource allocation graph and searching for acyclelknot
in thegraphdepending onwhetherthe system has single/multiple unitsofeach 'resource
type. However, for simplicity, in the following description weconsider only the case of a
single unit ofeachresource type.Therefore, thedeadlock detection algorithms get
simplified tomaintaining WFG and searching for cycles in the WFG.
Thefollowing steps may be followed to construct the WFG for a distributed
system:
1.Construct aseparate WFG for each site of the system in the following manner.
Using the convention ofFigure 6.9, construct aresource allocation graph for all
theresources located on this site. That is, in the resource allocation graphofa site,
aresource node exists for all the local resources and aprocessnode exists for all
processes that areeitherholding or waitingfor aresourceofthis siteimmaterial
ofwhethertheprocessis local or nonlocal.
2.Converttheresourceallocation graphconstructed instep 1toa corresponding WFG
byremoving theresource nodes and collapsing theappropriate edges. It may be
noted that step 1and this step are mentioned here only for clarityofpresentation.
The actual algorithm may bedesigned to directly construct a WFG.
3. Take the union ofthe WFGs ofall sites and construct a single global WFG.
Let usillustrate theprocedure with the help ofthe simple example shown in Figure
6.15.Suppose that the system is comprised ofonly two sites (S.andS2)with SJ having
tworesources RIandR2andS2having one resourceR3•Alsosupposethat there are three
processes (PI'P2,P3)that are competing for the three resources in the following
manner:
• PIisholdingRIandrequesting forR3
• P2isholdingR2andrequesting forR.
•P3is holding R3andrequesting forR2
Thecorresponding resource allocation graphs for the two sites are shown in Figure
6.15(a).Notice that processes PIandP3appearin the graph ofboth the sites because they
haverequested forresources on both sites. On the otherhand, process P2appears only in
the graph ofsite SIbecausebothresources requested by it are on SI .Sec.6.5 •Deadlock
Fig.6.15 Illustration of theconstruction of a
WFOina distributed system: (a)
resource allocation graphsofeach
site;(b)WFGscorresponding to
graphs in (a);(c)globalWFGby
taking the union of the two local
WFOsof(b).321
~
P2
Site51
(a)Site52
P1
Site51
(b)SiteS2
(c)
Figure6.15(b)shows the corresponding WFGs for the two sites and Figure 6.15(c)
shows the global WFG obtained by taking the union of the local WFGs of the two sites.
Notice that although the local WFGs of the two sites do not contain any cycle, the global
WFG contains a cycle, implying that the system is in a deadlock state. Therefore, this
example shows that the local WFGs are not sufficient to characterize all deadlocks in a
distributed system and the construction of a global WFG by taking the union of all local
WFGs isrequired to finally conclude whether the system isina state of deadlock or not.
The main difficulty in implementing deadlock detection in a distributed system is
how to maintain the WFG. Three commonly used techniques for organizing the WFG in
adistributed system are centralized, hierarchical, and distributed. These techniques are
described below. However, before we describe them,itmaybe noted that one of the most
important features of deadlock detection algorithms is correctness, which depends on the
following properties [Knapp 1987]:
I.Progressproperty. This property states that all deadlocks must be detected in a
finite amount of time.
2. Safety property. Ifadeadlock isdetected, itmust indeed exist. Message delays and
out-of-date WFGs sometimes cause false cycles to be detected, resulting in the
detection of deadlocks that do not actually exist. Such deadlocks are called
phantom deadlocks.322 Chap.6 •Synchronization
Centralized Approach forDeadlock Detection. In thecentralized deadlock
detection approach, thereisalocal coordinator ateach sitethatmaintains aWFG foritslocal
resources, and there isacentral coordinator (also known asa centralized deadlock detector)
that isresponsible forconstructing the union ofall the individual WFGs. The central
coordinator constructs the global WFG from information received from the local
coordinators of all the sites. Inthis approach, deadlock detection is performed as follows:
1. If a cycle exists in the local WFG of any site, it represents a local deadlock. Such
deadlocks are detected and resolved locally by the local coordinator of the site.
2.Deadlocks involving resources at two or more sites get reflected as cycles in the
global WFG. Therefore, such deadlocks are detected and resolved by the central
coordinator.
In thecentralized approach, the local coordinators send local state information to the
centralcoordinator in the form of messages. One ofthe following methods is used to
transferinformation from local coordinators to the central coordinator:
1. Continuous transfer. A localcoordinator sends a message providing the update
done in the local WFG whenever a new edge isadded to or deleted from it.
2. Periodic transfer. To reduce the number of messages, a local coordinator
periodically (when anumber ofchanges haveoccurred initslocalWFG) sendsalist
ofedges added to or deleted from itsWFG since the previous message was sent.
3. Transfer-on-request. A localcoordinator sends a list of edges added to or deleted
from its WFG since the previous message is sent only when the central
coordinator makes a request for it.In this case, the central coordinator invokes the
cycle detection algorithm periodically and requests information from each sitejust
before invoking the algorithm.
Although the centralized deadlock detection approach is conceptually simple, itsuffers
from several drawbacks. First, it is vulnerable to failures of the central coordinator. Hence
specialprovision for handling such faults have to be made. One approach is to provide a
back..up central coordinator thatduplicates thejobofthe central coordinator. Second, the
centralized coordinator canconstitute aperformance bottleneck inlarge systems having too
many sites. Third, the centralized coordinator may detect false deadlocks. Below we
illustrate with a simple example how the algorithm may lead to the detection of false
deadlocks and then we describea method to overcome this third drawback.
Let usconsider the same system configuration as that of Figure 6.15 and this time
supposethat the three processes (PI'P2,P3)compete for the three resources (R1,R2,R3)
in thefollowing manner:
Step1:PIrequests for RIandRIis allocated to it.
Step2:P2requests for R2andR2is allocated to it.
Step3:P3requests for R3andR3is allocated to it.
Step4:P2requests for R1and waits for it.Sec. 6.5 • Deadlock
Step 5:P3requests for R zand waits for it.
Step6:PIreleasesR1and R,is allocated to Pz­
Step7:PIrequests for R3and waits for it.323
Assuming that the method of continuous transfer is employed by the algorithm, the
following sequence of messages will be sent to the central coordinator:
ml:from site SIto add the edge (R I,PI)
m2:from site SIto add the edge (Rz,Pz)
m-:from site S2to add the edge (R3,P3)
m4:from site SIto add the edge (P2'RI)
mi:from site SIto add the edge (P3,Rz)
m.;from site SIto delete edges (R I,PI)and(Pz,R1),and add edge (R),P2)
m7:from site 5zto add edge (PI'R3)
The resource allocation graphs maintained bythe local coordinators of the two sites
and the central coordinator are shown in Figure 6.16 (for clarity of presentation, the
resource allocation graphs are shown instead of the WFGs). Figure 6.16(a)shows the
graphs after step 5, that is, after message mshas been received by the central coordinator,
and Figure 6.16(b)shows the graphs after message m-,has been received by the central
coordinator. The graph of the central coordinator in Figure 6.16(b)has no cycles,
indicating that the system is free from deadlocks. However, suppose that message m7from
siteSzis received before message m6from site 51by the central coordinator. In this case,
the central coordinator's view of the system will be as shown in the resource allocation
graph of Figure 6.16(c).Therefore, the central coordinator will incorrectly conclude that
a deadlock has occurred and may initiate deadlock recovery actions. Although the above
example shows the possibility of detection of phantom deadlocks when the method of
continuous transfer of information is used, phantom deadlocks may even get detected in
the other two methods of information transfer due to incomplete or delayed
information.
One method to avoid the detection of false deadlocks is to use Lamport's
algorithm to append a unique global timestamp with each message. In our above
example, since message m-from site Sz to the central coordinator is caused by the
request from site SI(see step 7), message m-will have a later timestamp than
message m6'Now if the central coordinator receives message m-beforem6and
detects a false deadlock, before taking any action to resolve the deadlock, it first
confirms if the detected deadlock is a real one. For confirmation, it broadcasts a
message asking all sites ifany site has a message with timestamp earlierthanTfor
updation of the global WFG. On receiving this message, if a site has a message with
timestamp earlier than T,it immediately sends it to the central coordinator; otherwise
it simply sends a negative reply. After receiving replies from all the sites, the central
coordinator updates the global WFG (if there are any update messages), and if the
cycle detected before still exists, itconcludes that the deadlock is a real one and324
Resource allocation
graphofthelocal
coordinator ofsite81Resource allocation
graphofthelocal
coordinator ofsite52
(a)Chap.6 •Synchronization
Resource allocation
graphmaintained by
thecentralcoordinator
R
Site51 Site52
(b)
Centralcoordinator
(c)Centralcoordinator
Fig. 6.16 Local and global resource allocation graphs in the centralized deadlock
detection approach: (a)resource allocation graphs after step 5; (b)resource
allocation graphs after step 7; ( c)resource allocation graph of the central
coordinator showing false deadlock if message m7is received before m6by
the central coordinator.
initiates recovery actions. Notice that in our above example, in reply to its broadcast
message, the central coordinator will receive message m6from site S,and a negative
reply from site S2.Therefore, after final updation of the global graph, the central
coordinator's view of the system will change from that of Figure 6.16(c)to that in
Figure6.16(b).Hence no deadlock resolution action will beinitiated.
Hierarchical Approachfor Deadlock Detection. Ithas beenobserved thatfor
typical applications most WFG cycles are very short. In particular, experimental
measurements have shown that 90% of all deadlock cycles involve only two processes
[Grayet al. 1981].Therefore, thecentralized approach seemsto belessattractive formost
real applications because of the significant time and message overhead involved inSec.6.5 • Deadlock 325
assembling all thelocalWFGsat thecentralcoordinator. Furthermore, tominimize
communications cost,ingeographically distributed systems, deadlock shouldbedetected
by a site locatedascloseaspossible to the sites involved in thecycle.But this is not
possible in thecentralized approach. Thehierarchical approach overcomes theseandother
drawbacks ofthecentralized approach.
Thehierarchical deadlock detection approach uses alogicalhierarchy (tree)of
deadlock detectors. Thesedeadlock detectors arecalledcontrollers. Eachcontroller is
responsible fordetecting onlythosedeadlocks thatinvolvethe sites falling withinitsrange
in thehierarchy. Therefore, unlikethecentralized approach inwhichtheentireglobal
WFGismaintained at asinglesite, in the hierarchical approach it isdistributed overa
numberofdifferent controllers. Eachsite has its own localcontroller thatmaintains its
own local graph.
In the tree representing thehierarchy ofcontrollers, theWF(ito bemaintained by a
particular controller isdecidedaccording to thefollowing rules:
1. Eachcontroller that forms aleafofthehierarchy treemaintains the local WFGof
asinglesite.
2. Each nonleafcontroller maintains aWFGthat is the unionoftheWFGsofits
immediate children in thehierarchy tree.
Thelowestlevelcontroller that finds a cyclein itsWFGdetectsadeadlock and takes
necessary actiontoresolveit.Therefore, a WFG that contains acyclewillneverbepassed
as it is to a higherlevelcontroller.
Let usillustrate themethodwith thehelpoftheexample showninFigure6.17.There
are four sites and sevencontrollers in thesystem.Controllers A, B,C, andDmaintain the
localWFGsofsites51' 52, 53' and54,respectively. Theyform the leavesofthe
controllers' hierarchy tree.Controller E,being the parent of controllers AandB,maintains
theunionoftheWFGsofcontrollers AandB.Similarly, controller Fmaintains theunion
oftheWFGsofcontrollers CandD.Finally,controller Gmaintains theunionofthe
WFGsofcontrollers EandF.
Noticefrom the figurethat thedeadlock cycle(PI'P3'Pz,PI)thatinvolves sitesS,
andSzgetsreflected in the WFG ofcontroller E,but thedeadlock cycle(P4'Ps,P6,P7'
P4)thatinvolves sitesS2' S3'and54getsreflected only in the WFGofcontroller G. This
isbecausecontroller Gis the first controlJer in thehierarchy inwhoserangeall the three
sites82,S3'and84arecovered. Alsonoticethatalthough we have shownthedeadlock
cycle(p),P3,P2'P,in theWFGofcontroller GtoreflecttheunionoftheWFGsof
controllers EandF,this will neverhappeninpractice. This isbecause, whencontroller E
detectsthedeadlock, it willinitiatearecovery actioninsteadofpassingitsWFGas it is
tocontroller G.
Fully Distributed Approaches for Deadlock Detection. In the fully dis­
tributeddeadlock detection approach, eachsiteofthesystemsharesequalresponsibility
fordeadlock detection. Surveysofseveralalgorithms basedon thisapproach canbefound
in[Knapp1987,Singhal1989].Belowwedescribe twosuchalgorithms. The first one is
basedon theconstruction ofWFGs,and thesecondone is a probe-based algorithm.326 Chap.6 • Synchronization
Controller F
Site81
Controller ASite82
Controller BSite83
Controller CSite54
Controller 0
Fig.6.17 Hierarchical deadlock detection approach.
WFG-Based Distributed Algorithm forDeadlock Detection. Thedescrip­
tionbelowfollows from the description ofthe fully distributed deadlock detection
algorithm presented in(Silberschatz andGalvin1994]. As in the centralized and
hierarchical approaches, in theWFG-based distributed algorithm, eachsitemaintains its
own local WFG. However, to model waitingsituations thatinvolveexternal (nonlocal)
processes, aslightlymodified formofWFG is used. In this modified WFG,anextranode
Pexisaddedto the local WFGofeach site, and this node is connected to the WFG ofthe
corresponding site in the following manner:
1. Anedge(PhPex)is added if processPiiswaitingfor aresource inanothersite
beingheld by any process.
2. Anedge(Pex'Pj)isaddedifPjis aprocessofanothersite that is waitingfor a
resource currently beingheldbyaprocessofthis site.
Toillustrate theconstruction ofthismodified WFG,let usconsider theexample of
Figure6.18. Inthis example there are two sites, and the local WFGsofeach site are shownin
Figure6.18(a). Themodified WFGsofthe two sites aftertheadditionofnodePexareshown
inFigure6.18(b).Theexplanation for theedgesinvolving node Pexare as follows:Sec.6.5 • Deadlock
Site 8,(a)
(b)327
Fig.6.18 Example illustrating the
WFG-based fullydistributed
deadlock detection algorithm:
(u)localWFGs;(b)localWFGs
afteradditionofnodePex;
(c)updated local WFG of site 52
afterreceiving thedeadlock
detection message from site 5 I' (c)
I. In the WFG of site Sf,edge(P"j>ex)isadded because process P,is waiting for
a resource in site 52that is held by process P3'and edge (P ex'P3)is added
because process P3is a process of site 52that is waiting to acquire a resource
currently held by process Pzof siteS,.
2. In the WFG of site S2'edge(P3,Pex)is added because process P3is waiting for
a resource in site 5) that is held by process P2'and edge (Pex'PI)is added
because process PIis a process of site S Ithat is waiting to acquire a resource
currently held by process P3of site52'
Now these modified WFGs are used for deadlock detection in the following manner.
If a local WFG contains a cycle that does not involve node Pex'a deadlock that involves
only local processes of that site has occurred. Such deadlocks can be locally resolved
without the need to consult any other site.
On the other hand, if a local WFG contains a cycle that involves node Pex'there is
a possibility of adistributed deadlock that involves processes of multiple sites.Toconfirm
a distributed deadlock, a distributed deadlock detection algorithm is invoked bythe site328 Chap.6 •Synchronization
whose WFG contains the cycle involving node Pex•The algorithm works as described
below.
Suppose acycle involving node Pexisdetected intheWFG of site Sj.This cycle must
beofthe form
which means that process Pkis waiting for an external resource that belongs to some other
site (saySj).Therefore, site Sjsends adeadlock detection message to site Sj.This message
does not contain the complete WFG of site S,butonly thatpart ofthe WFG that forms the
cycle. For instance, in our example of Figure 6.18, if site SIdetects its cycle first, it sends
a message like (P ex'P3,P2,P"Pex)to siteS2sincePIis waiting for a resource in site
S2·
On receiving the message, site S,updates its local WFG by adding those edges ofthe
cycle that do not involve node Pexto its WFG. That is, inour example, edges (P3,P2)and
(P2,PI)will be added to the local WFG of site S2'resulting in the new WFG of Figure
6.18(c).
Now if the newly constructed WFG of site Sjcontains a cycle that does not involve
nodePex'a deadlock exists and an appropriate recovery procedure must be initiated. For
instance, in our example, the newly constructed WFG of site S2contains a cycle (P J,P3,
P2,PJ)that does not involve node PexoHence, inour example, the system is in adeadlock
state.
On the other hand, if a cycle involving node Pexis found in the newly constructed
WFG of site Sj' S,sends adeadlock detection message to the appropriate site (say Ss),and
the whole procedure is repeated by site SkoIn this manner, after a finite number of
deadlock detection message transfers from one site to another, either a deadlock is
detected or the computation for deadlock detection halts.
A problem associated with the above algorithm is that two sites may initiate the
deadlock detection algorithm independently for a deadlock that involves the same
processes. For instance, in our example of Figure 6.18, sites SlandS2may almost
simultaneously detect the cycles (P ex'P3,P2,PI'Pex)and (P ex'PJ,P3,Pex)respectively
in their local WFGs, and both may send a deadlock detection message to the other site.
The result will be that both sites will update their local WFGs and search for cycles. After
detecting a deadlock, both may initiate a recovery procedure that may result in killing
more processes than is actually required to resolve the deadlock. Furthermore, this
problem also leads to extra overhead in unnecessary message transfers and duplication of
deadlock detection jobs performed at the two sites.
One way to solve the above problem is to assign a unique identifier to each process
Pi[denoted as ID(Pi)].Now when a cycle of the form (Pex9Pi'Pj'..0'Pi,Pex)is found
in the local WFG of a site, this site initiates the deadlock detection algorithm by sending
a deadlock detection message to the appropriate site only if
Otherwise, this site does not take any action and leaves the job of initiating the deadlock
detection algorithm to some other site.Sec.6.5 • Deadlock
Let us apply the modified algorithm to our example of Figure 6.18. Let329
Now suppose both sites SIandSzalmost simultaneously detect the cycles (Pex'P3,r;P1,Pe,.)and(Pex'PJ,P3,Pex),respectively, in their local WFGs. Since ID(P 1)<
ID(P3),so site S Iwill initiate the deadlock detection algorithm. On the other hand, since
ID(P3)>ID(P,),siteSzdoes not take any action on seeing the cycle in its local WFG.
When site S2receives the deadlock detection message sent to it by site SI'itupdates its
local WFG and searches for a cycle in the updated WFG. It detects the cycle (PI,P3,Pz,
PI)in the graph and then initiates a deadlock recovery procedure.
Probe-Based Distributed Algorithm forDeadlock Detection. The probe­
based distributed deadlock detection algorithm described belowwas proposed byChandy
et al.[1983]and is known astheChandy-Misra-Hass (or eMH)algorithm. Itisconsidered
to be the best algorithm to date for detecting global deadlocks in distributed systems. The
algorithm allows a process to request for multiple resources at a time.
The algorithm is conceptually simple and works in the following manner. When a
process that requests for a resource (or resources) fails to get the requested resource (or
resources) and times out, it generates a special probemessage and sends itto the process
(or processes) holding the requested resource (or resources). The probe message contains
the following fields (assuming that each process in the system is assigned a unique
identifier):
1.Theidentifier of the process justblocked
2. The identifier of the process sending this message
3. The identifier of the process to whom this message is being sent
On receiving a probe message, the recipient checks tosee if ititself is waiting for any
resource (or resources). If not, this means that the recipient isusing the resource requested
by the process that sent the probe message to it. In this case, the recipient simply ignores
the probe message. On the other hand, ifthe recipient is waiting for any resource (or
resources), it passes the probe message to the process (or processes) holding the resource
(or resources) for which it is waiting. However, before the probe message is forwarded,
the recipient modifies its fields in the following manner:
1.The first field is left unchanged.
2. The recipient changes the second field to its own process identifier.
3. The third field is changed to the identifier of the process that willbe the new
recipient of this message.
Every new recipient of the probe message repeats this procedure. If the probe
message returns backto the original sender (the process whose identifier is inthefirst field
of the message), a cycle exists and the system is deadlocked.330 Chap.6 •Synchronization
Let us illustrate the algorithm with the help of the simple example shown in Figure
6.19. Notice that this figure depicts the same situation as that of Figure 6.18(a)but in a
slightly different style. Suppose that process PIgets blocked when it requests for the
resource held by process P3.Therefore PIgenerates a probe message (PI'PI,P3)and
sends it to P3.WhenP3receives this message, it discovers that it is itself blocked on
processes P2andr;Therefore P3forwards the probes (PI'P3'P2)and(PitP3'Ps)to
processes P2andPs,respectively. When Psreceives the probe message, it ignores it
because it is not blocked on any other process. However, when P2receives the probe
message, it discovers that it is itself blocked on processes PIandP4·Therefore P2
forwards the probes (PhP2,PJ)and(PitP2,P4)to processes PIandP4,respectively.
Since the probe returns to its original sender (PI)'a cycle exists and the system is
deadlocked.
Site~Fig.6.19 Example illustrating theeMH
distributed deadlock detection
algorithm.
The CMH algorithm is popular, and variants of this algorithm are used in most
distributed locking schemes due to the following attractive features of the algorithm:
1. The algorithm is easy to implement, since each message is of fixed length and
requires few computational steps.
2. The overhead of the algorithm is fairly low.
3. There is no graph constructing and information collecting involved.
4. False deadlocks are not detected by the algorithm.
5. It does not require anyparticular structure among the processes.
Ways for Recovery from Deadlock
When a system chooses to usethe detection and recovery strategy for handling deadlocks,
it is not sufficient to simply detect deadlocks. The system must also have some way to
recover from a detected deadlock. One of the following methods may be used in a system
to recover from a deadlock:
• Asking for operator intervention
• Termination of process(es)
• Rollback ofprocess(es)Sec.6.5 • Deadlock 331
AskingforOperator Intervention. Thesimplest way is to informtheoperator
thatadeadlock hasoccurredandto let the operator deal with it manually. Thesystemmay
assisttheoperator indecision makingforrecoverybyproviding him or her with a list of
theprocesses involved in thedeadlock.
Thismethodis notsuitable for usc in modern systems because theconcept of
anoperator continuously monitoring thesmooth running ofthesystemfrom the
console hasgradually vanished. Furthermore, although thismethodmay work for a
centralized system, it does not work in a distributed environment because when a
deadlock involving processes ofmultiple sites isdetected, it is not clearwhichsite
shouldbeinformed. If all the sites whoseprocesses areinvolved in thedeadlock are
informed, eachsite'soperator mayindependently take some action for recovery. On
theotherhand,iftheoperator ofonly asinglesite isinformed, theoperator may
favortheprocess (orprocesses) ofits own site while takingarecovery action.
Furthermore, theoperator ofone site may not have the right to interfere with a
process ofanother site for takingrecovery action.Therefore, distributed systems
normally useothermethods described belowinwhichthesystemrecovers automati­
cally from a deadlock.
Termination ofProcessies). Thesimplest way toautomatically recoverfrom a
deadlock is toterminate (kill) one or more processes and toreclaimtheresources held
by them, which can then be reallocated. Deadlock recovery algorithms based on this
ideaanalyzetheresource requirements andinterdependencies of theprocesses involved
in adeadlock cycleand then selecta set of processes, which,if killed, can breakthe
cycle.
Rollback ofProcess(es). Killingaprocessrequires itsrestartfrom the very
beginning, whichprovesto be very expensive, particularly when the processhasalready
run for a substantially longtime.To break a deadlock, it issufficient toreclaimtheneeded
resources from the processes that were selected for being killed. Also notice that to
reclaimaresource from aprocess, it issufficient to roll back the processto a point where
theresource was not allocated to theprocess. Themethodofrollback isbasedon this
idea.
In thismethod,processes arecheckpointed periodically. Thatis, aprocess's state (its
memory image and the list ofresources held by it) is written to a file at regularintervals.
Therefore, the filemaintains a history of the process's states so that, if required, the
processcan berestarted from any of its checkpoints. Now when a deadlock isdetected,
themethoddescribed in theprocesstermination approach is used to selecta setof
processes to be killed. However, this time, insteadoftotalrollback(killing)oftheselected
processes, theprocesses are rolled back only as far as necessary to break the deadlock.
Thatis, eachselectedprocessis rolled back to a checkpoint atwhichtheneededresources
can bereclaimed from it.
Although therollback approach mayappearto be less expensive than the process
termination approach, this is not alwaystruebecauseoftheextraoverhead involved in the
periodic checkpointing of all the processes. Ifdeadlocks are rare in a system,it may be
cheaperto use the processtermination approach.332 Chap.6 •Synchronization
Issues in Recovery from Deadlock
Twoimportant issues in the recovery action are selection of victims and use of transaction
mechanism. These are described below.
Selection ofVictim(s). In any of the recovery approaches described above,
deadlock is broken by killing or rolling back one or more processes. These processes are
called victims. Notice that even in the operatorintervention approach, recovery involves
killing one or more victims. Therefore, an important issue in any recovery procedure is to
select the victims. Selection ofvictim(s) is normally based on two major factors:
1. Minimization ofrecovery cost. This factor suggests that those processes should be
selected as victims whose termination/rollback will incur the minimum recovery cost.
Unfortunately, it is not possible to have a universal cost function, and therefore, each
system should determine its own cost function to select victims. Some of the factors that
may beconsidered forthis purpose are (a) the priority of the processes; (b) the nature of
the processes, such as interactive or batch and possibility of rerun with no ill effects; (c)
the number and types of resources held by the processes; (d) the length of service already
received and the expected length of service further needed by the processes; and (e) the
total number of processes that will beaffected.
2. Prevention ofstarvation. If a system only aims at minimization of recovery cost,
it may happen that the same process (probably because its priority is very low) is
repeatedly selected as a victim and may never complete. This situation, known as
starvation, must be somehow prevented in any practical system. One approach to handle
this problem is to raise the priority of the process every time it is victimized. Another
approach is to include the number of times a process is victimized as a parameter in the
cost function.
UseofTransaction Mechanism. After a process is killed or rolled back for
recovery fromdeadlock, ithastobererun. However,rerunning aprocess maynotalways be
safe, especially when the operations already performed by the process are nonidempotent.
For example, if a process has updated the amount of a bank account by adding a certain
amount to it, reexecution of the process will result in adding the same amount once again,
leaving the balance in the account in an incorrect state. Therefore, the use of a transaction
mechanism (which ensures all or no effect) becomes almost inevitable for most processes
when the system chooses the method of detection and recovery for handling deadlocks.
However, notice that the transaction mechanism need not be used for those processes that
canbererun withnoilleffects.Forexample, rerunofa compilation process hasnoilleffects
because all itdoes isread a source file and produce anobject file.
6.6ElEalON AlGORITHMS
Severaldistributed algorithms require that there be a coordinator process in the entire
system that performs some type of coordination activity needed for the smooth running of
other processes in the system. Two examples of such coordinator processes encounteredSec.6.6 • ElectionAlgorithms 333
in thischapterare thecoordinator in thecentralized algorithm for mutual exclusion and
the central coordinator in thecentralized deadlock detection algorithm. Since all other
processes in the system have to interact with the coordinator, they all must unanimously
agree on who the coordinator is.Furthermore, ifthecoordinator process fails due to the
failure of the site on which it is located, a new coordinator process must be elected to take
up the job of the failed coordinator. Election algorithms are meant for electing a
coordinator process from among the currently running processes in such a manner that at
any instance of time there is a single coordinator for allprocesses in the system.
Election algorithms are based on the following assumptions:
1. Each process in the system has a unique priority number.
2.Whenever an election is held, the process having the highest priority number
among the currently active processes is elected as the coordinator.
3. On recovery, a failed process can take appropriate actions to rejoin the set of
active processes.
Therefore, whenever initiated, an election algorithm basically finds out which of the
currently active processes has the highest priority number and then informs this toall other
active processes. Different election algorithms differ in the way they do this. Two such
election algorithms are described below. Readers interested in other election algorithms
may refer to [Tel 1994]. For simplicity, in the description ofboth algorithms we will
assume that there is only one process on each node of the distributed system.
6.6.1 The BullyAlgorithm
This algorithm was proposed byGarcia-Molina [1982]. In this algorithm itisassumed that
every process knows the priority number of every other process in the system. The
algorithm works as follows.
When a process (say Pi)sends arequestmessage to the coordinator and does not
receive a reply within a fixed timeout period, it assumes that the coordinator has failed.
It then initiates an election by sending an electionmessage to every process with a higher
priority number than itself. If Pidoes not receive any response to its election message
within a fixed timeout period, it assumes that among the currently active processes it has
the highest priority number. Therefore it takes up the job of the coordinator and sends a
message (let us call it a coordinator message) to all processes having lower priority
numbers than itself, informing that from now on it is the new coordinator. On the other
hand, ifPireceives a response for its election message, this means that some other process
having higher priority number is alive. Therefore Pidoes not take any further action and
justwaits to receive the final result (a coordinator message from the new coordinator) of
theelectionitinitiated.
When a process (say Pj)receives an electionmessage (obviously from a process
having a lower priority number than itself), it sends-aresponse message (let us call it alive
message) to the sender informing that it is alive and will take over the electionactivity.
NowPjholds an election if it is not already holding one. In this way, the election activity
gradually moves on to the process that has the highest priority number among the334 Chap.6 •Synchronization
currently active processes and eventually wins the election and becomes the new
coordinator.
As part of the recovery action, this method requires that a failed process (say Pk)
must initiate an election on recovery. If the current coordinator's priority number is higher
than that of Pk»then the current coordinator will win the election initiated by Pkand will
continue to be the coordinator. On the other hand, if Pk'spriority number is higher than
that of the current coordinator, itwill not receive any response for its election message.
So it wins the election and takes over the coordinator's jobfrom the currently active
coordinator. Therefore, the active process having the highest priority number always wins
theelection. Hence thealgorithm iscaJledthe "bully"algorithm. It may also be noted here
that if the process having the highest priority number recovers after a failure, it does not
initiate an election because it knows from its list of priority numbers that all other
processes in the system have lower priority numbers than that of its own. Therefore, on
recovery, it simply sends a coordinator message to all other processes and bullies the
currentcoordinator into submission.
Let us now see the working of this algorithm with the help of an example. Suppose
the system consists of five processes PI,P2'P3'P4,and Psand their priority numbers are
1,2, 3, 4, and 5 respectively. Also suppose that at a particular instance of time the system
is in a state in which P2is crashed, and PI'P3,P4,and Psare active. Starting from this
state, the functioning of the bully algorithm with the changing system states is illustrated
below.
1. Obviously, Psisthecoordinator in the starting state.
2. Suppose P5crashes.
3. Process P3sends a request message to P sand does not receive a reply within the
fixed timeout period.
4. Process P3assumes that P shas crashed and initiates an election by sending an
election message to P4andPs (recall that an election message is sent only to
processes with higher priority numbers).
5. When P4receives P3'selection message, it sends an alive message to P3'
informing that it isalive and will take over the election activity. Process Pscannot
respond to P3'selection message because it is down.
6. NowP4holds an election bysending an election message to Ps-
7. Process Psdoes not respond to P4'selection message because itis down, and
therefore, P4wins theelection and sends a coordinator message to PI'P2,andP3,
informing them that from now on it is the new coordinator. Obviously, this
message is not received by P2because it is currently down.
8. Now suppose P2recovers from failure and initiates an election by sending an
election message to P3'P4,andPs.SinceP2'spriority number is lower than that
ofP4(current coordinator), P4will win the election initiated by P2and will
continue to be the coordinator.
9. Finally, suppose Ps recovers from failure. Since Psisthe process with the highest
priority number, it simply sends a coordinator message to PI,P2'P3,andP4and
becomes the new coordinator.Sec. 6.6 • Election Algorithms
6.6.2 ARingAlgorithm335
The following algorithm is based on the ring-based election algorithms presented in
[Tanenbaum 1995,Silberschatz and Galvin 1994]. In this algorithm it isassumed that all
theprocesses in the system are organized in a logical ring. The ring is unidirectional in the
sense that all messages related to the electionalgorithm are always passed only in one
direction (clockwise/anticlockwise). Every process in the systemknows the. structure of
the ring, so that while trying to circulate amessage over the ring, ifthesuccessor of the
senderprocessis down, the sender can skip over the successor, or the one after that, until
an active member is located. The algorithm works as follows.
When a process (say Pi)sends arequestmessage to thecurrentcoordinator and does
not receive a reply within a fixed timeoutperiod, it assumes that the coordinator has
crashed.Therefore it initiates an electionby sending an electionmessage to its successor
(actually to the first successor that iscurrently active). This message contains the priority
number of process Pi'On receiving the electionmessage, the successor appends its own
priority number to the message and passes iton to the next active memberin the ring. This
member appends its own priority number to the message and forwards it to its own
successor. In this manner, the electionmessage circulates over the ring from one active
process to anotherandeventually returns back to processPi.ProcessPirecognizes the
message as its own electionmessage by seeing that in the list ofpriority numbers held
within the message the first priority number is its own priority number.
Note that when process Pireceives its own electionmessage, the message contains
the list of priority numbers of all processes that are currently active.Therefore ofthe
processes in this list, it elects the process having the highest prioritynumberas the new
coordinator. Itthencirculates acoordinator message over the ring to inform all the other
active processes who the new coordinator is. When the coordinator message comes back
to process Piaftercompleting its one round along the ring, it is removed by process Pi.
At this point all the active processes know who the current coordinator is.
When a process (say Pj)recovers after failure, it creates an inquirymessage and
sendsitto its successor. The message contains the identity of processPj•If thesuccessor
is not the currentcoordinator, itsimply forwards the enquiry message to its own successor.
In this way, the inquiry message moves forward along the ring until it reaches the current
coordinator. On receiving an inquiry message, the currentcoordinator sends a reply to
processP,informing that it is the currentcoordinator.
Notice that in this algorithm two or more processes mayalmostsimultaneously
discover that thecoordinator hascrashedand then each one may circulate anelection
message over the ring. Although this results ina little waste of networkbandwidth, it does
not cause any problem because every processthat initiated an electionwill receive the
same list of active processes, and all of them will choose the same process as the new
coordinator.
6.6.3Discussion oftheTwoElectionAlgorithms
In the bully algorithm, when the process having the lowest priority numberdetects the
coordinator's failure and initiates an election, in a system having total nprocesses,336 Chap.6 •Synchronization
altogether n-2elections are performed one after another for the initiated one. That is, all
the processes, except the active process with the highest priority number and the
coordinator process that has just failed, perform elections by sending messages to all
processes with higher priority numbers. Hence, in the worst case, the bully algorithm
requiresO(n2)messages. However, when the process having the priority number just
below the failed coordinator detects that the coordinator has failed, it immediately elects
itself as the coordinator and sends n-2coordinator messages. Hence, in the best case, the
bully algorithm requires only n-2messages.
On the other hand, in the ring algorithm, irrespective of which process detects the
failure of the coordinator and initiates an election, an election always requires 2(n-l)
messages (assuming that only the coordinator process has failed); n-lmessages are
needed for one round rotation of the election message, and another n-lmessages are
needed for one round rotation of the coordinator message.
Next letusconsider thecomplexity involved intherecovery of aprocess. Inthe bully
algorithm, a failed process must initiate an election on recovery. Therefore, once again
depending on the prioritynumberof theprocess thatinitiates therecovery action, the bully
algorithm requires O(n2)messages in the worst case, and n-lmessages in the best case.
On the other hand, in the ring algorithm, a failed process does not initiate an election on
recovery but simply searches for the current coordinator. Hence, the ring algorithm
requires only nl2messages on an average for recovery action.
In conclusion, as compared to the bully algorithm, the ring algorithm is more
efficient and easier to implement.
6.7SUMMARY
Sharing system resources among multiple concurrent processes may be cooperative or
competitive in nature. Both cooperative and competitive sharing require adherence to
certain rules of behavior that guarantee that correct interaction occurs. The rules for
enforcing correct interaction are implemented inthe form of synchronization mechanisms.
In this chapter we saw the synchronization issues in distributed systems and mechanisms
to handle these issues.
For correct functioning of several distributed applications, the clocks of different
nodes of a distributed system must be mutually synchronized as well as with the external
world (physical clock). Clock synchronization algorithms used in distributed systems are
broadly classified into two types-centralized and distributed. In the centralized
approach, there is a time server node and the goal of the algorithm is to keep the clocks
of all other nodes synchronized with the clock time of the time server node. In the
distributed approach,clock synchronization isdoneeither by global averaging orlocalized
averaging of the clocks of various nodes of the system.
Lamport observed that for most applications clock synchronization is not required,
andit is sufficient to ensure that allevents that occur in a distributed system can betotally
ordered in amanner thatisconsistent withanobserved behavior.Therefore, hedefined the
happened-before relation and introduced the concept of logical clocks for ordering of
events based on the happened-before relation. The happened-before relation, however, isChap. 6 • Exercises 337
only a partial ordering on the set of all events in the system. Therefore, for total ordering
on the set of all system events, Lamport proposed the use of any arbitrary total ordering
of the processes.
There are several resources in a system for which exclusive access by a process must
be ensured. This exclusiveness of access is called mutual exclusion between processes,
and the sections of a program that need exclusive access to shared resources are referred
to as critical sections. The three basic approaches used by different algorithms for
implementing mutualexclusion in distributed systems are centralized, distributed, and
token passing. In the centralized approach, one of the processes in the system is elected
as the coordinator, which coordinates the entry to the critical sections. In the distributed
approach, all processes that \vant to enter the same critical section cooperate with each
other before reaching a decision on which process will enter the critical section next. In
thetoken-passing approach, mutual exclusion is achieved by using a single token that is
circulated among the processes in the system.
Deadlock is the state of permanent blocking of a set of processes each of which is
waiting for an event that only another process in the set can cause. In principle, deadlocks
in distributed systems are similar to deadlocks in centralized systems. However, handling
of deadlocks in distributed systems is more complex than in centralized systems because
the resources, the processes, and other relevant information are scattered on different
nodes of the system.
The three commonly used strategies to handle deadlocks are avoidance, prevention,
and detection and recovery. Deadlock avoidance methods use some advance knowledge of
the resource usage of processes to predict the future state of the system for avoiding
allocations that can eventually lead to a deadlock. Deadlock prevention consists of
carefully designing the system so that deadlocks become impossible. In the detection and
recovery approach, deadlocks are allowed to occur, are detected bythe system, and then
are recovered. Of the three approaches, detection and recovery is the recommended
approach for handling deadlocks in distributed systems. The three approaches used for
deadlock detection in distributed systems are centralized, hierarchical, and fully
distributed. For recovery from a detected deadlock, a system may use one of the following
methods: asking for operator intervention, termination of process(es), or rollback of
process(es).
Severaldistributed algorithms require that there be a coordinator process in the entire
system. Election algorithms arc meant for electing a coordinator process from among the
currently running processes. Two election algorithms that were described in this chapter
are the bully algorithm and the ring algorithm.
EXERCISES
6.1. Write pseudocode for analgorithm thatdecides whether a given set of clocksare
synchronized or not. What input parameters areneededin youralgorithm?
6.2. How do clocksynchronization issues differ in centralized anddistributed computing
systems?338 Chap. 6 • Synchronization
6.3.Explainwhyone-time synchronization of theclocksofall the nodes of a distributed system
is notsufficient andperiodic resynchronization is necessary. How will you determine the
intervalfor periodic resynchronization?
6.4. Adistributed system has three nodes N.,N2,andN3,each having its own clock. The clocks
ofnodesN), N2,andN3tick800,810, and795times per millisecond. The system uses the
external synchronization mechanism, in which all three nodes receivethe real time every 30
secondsfrom anexternaltime source and readjust their clocks. What is the maximum clock
skew that will occur in this system?
6.5.Differentiate between internalsynchronization andexternal synchronization ofclocksin a
distributed system.Externally synchronized clocks are also internally synchronized, but the
converse is not true. Explain why.
6.6.Animportant issue in clock synchronization incomputer systemsis that time must never run
backward. Give two examples to show why this issue is important. How can afast clock be
readjusted to take care ofthis issue?
6.7.Indistributed systems, there may beunpredictable variation in the message propagation time
between two nodes. Explain why. How does this problem make the task of synchronizing
clocksin adistributed systemdifficult? Give two methods that can beused in a clock
synchronization algorithm to handle this problem.
6.8.Give two examples to show that for most distributed applications, whatusuallymatters is not
that allprocesses agree on exactly what time it is, but rather that they agree on the orderin
whicheventsoccur.
6.9.Using the space-time diagram of Figure 6.20,list all pairs of concurrent eventsaccording to
thehappened-before relation.
}'ig.6.20 Aspace-time diagram.
6.10.Add amessage-sending event to the space-time diagram of Figure 6.20that isconcurrent to
eventses, e6'ande7'Now add a non-message-sending event that is concurrent toeventse),
e2'ande3'
6.11.Explaintheconceptof logical clocks and their importance indistributed systems. A clock of
acomputer system must never run backward. Explainhow this issue can be handled in an
implementation of the logical clocks concept.Chap. 6 • Exercises 339
6.12.In thecentralized approach to mutual exclusion described in thischapter, thecoordinator
grantspermission forcriticalsectionentry to the first processin the queue. In some systems,
itmay bedesirable to grantpermission to some higher priorityjobsbeforeotherlower priority
jobs.Modifythealgorithm to take care of this and show how youraJgorithm satisfiesthe00­
starvation property.
6.13.The first generalalgorithm forimplementing mutualexclusion in adistributed environment
wasdeveloped byLamport (1978).Find the detailsofthisalgorithm andcompare its
performance andreliability with that of Ricart and Agrawala's [1981]algorithm.
6.14.Writepseudocode for the majority-consensus-based distributed algorithm for mutual
exclusion inwhichaprocesswilling to enteracriticalregion sends a requestmessage to all
otherprocesses andentersthecriticalregion as soon as it receivespermission from amajority
of theprocesses.
6.15. What isa"deadlock"? What are the four necessary conditions for adeadlock tooccur?Give
suitableexamples to prove that if anyone of the four conditions is absent, no deadlock is
possible.
6.16. Prove that the presence of a cycle in a general resource allocation graph is a necessary but not
asufficient condition for theexistence ofdeadlock.
6.17.Prove that for a systemhavingonly one unit of each resource type thepresence of a cycle in
aresource allocation graph is both a necessary and asufficient condition for theexistence of
deadlock.
6.18. Write the pseudocode of analgorithm thatdetermines whether a givenresource allocation
graphcontains adeadlock.
6.19.A system has three types of resources, R1,Rz,andR3,and their numbers of units are 3, 2, and
2,respectively. Fourprocesses PI'Pz,P3,andP4arecurrently competing for these resources
in thefollowing manner:
(a)PIisholdingone unit of RIand isrequesting for one unit of R2.
(b)P2isholdingtwo units of R2and isrequesting for one unit each of RIandR3•
(c)P3isholdingone unit of RJand isrequesting for one unit of R2.
(d)P4isholdingtwo units of R3and isrequesting for one unit of RI•
Determine which, if any, of the processes aredeadlocked in thissystemstate.
6.20. A distributed systemuses the following IPCprimitives:
(a)send(receiver_process_id, scnderprocessjd,message)
(b)receive(sender_process_id, message)
Theprimitives aresynchronous in the sense that the senderblocksif thereceiveris not ready
toreceivethemessage and thereceiver blocks until a message isreceived from the sender.
What is the minimum numberofcommunicating processes for acommunication deadlock to
occurin thissystem?Give reasons for your answerand give an example of acommunication
deadlock thatinvolves aminimum numberofprocesses.
6.21.Assume that in the distributed systemofExercise 6.20 anIPetakes place only between two
types of processes--clients and servers. That is, one is alwaysa client and the otheris a
server. A clientalwaysexecutes the IPCprimitives in(send,receive) sequence. That is, for all
IPes,aclientfirstexecutes asendto send a requestmessage to aserverand then executes a
receivetoreceivethe reply for its request. On the otherhand, aserveralwaysexecutes the IPC
primitives in(receive,send) sequence. That is, for all IPCs, a serverfirstexecutes areceive
to receive a requestfrom a client and then, afterprocessing, itexecutes asendto send the
result of processing to the client. Is a communication deadlock possible in thissystem?Give
reasonsfor your answer.340 Chap. 6 • Synchronization
6.22.Differentiate among safe, unsafe, and deadlock states. Assume that in a system there are total
10units of a resource for which four processes PI'P2,P3,andP4are competing. Suppose the
maximum unitsoftheresource required by PI'P2,P3,andP4are3,6,5,and4,respectively, and
they arecurrently holding 2, 1,3,and 2unitsofthe resource, respectively.Find outwhether the
currentstate of the system issafe or unsafe. If itissafe, enumerate aJlthe safe sequences.
6.23.There are four units of a resource in a system. Three processes compete to use this resource,
each of which needs at most two units. Prove that a deadlock situation will never arise no
matter in which order the processes acquire and release the resource units.
6.24.Prove that an unsafe state is not a deadlock state.
6.25.Give an example to show that if the resources are not cleverly scheduled to the competing
processes, a system may enter an unsafe state from a safe state. Now use the same example
to show the following:
(a) The system may enter a deadlock state from the unsafe state.
(b) All competing processes may successfully complete without the system entering into a
deadlock state from the unsafe state.
6.26.Discuss why advance knowledge of the resource usage of processes is essential to avoid
deadlocks. Why is the deadlock avoidance strategy never used in distributed systems for
handling deadlocks?
6.27.Deadlocks maybeprevented in a system bycarefully designing the system so that at least one
of the necessary conditions for deadlock is never satisfied. Based on this idea, suggest a
deadlock prevention scheme for each of the following:
(a) That denies the mutual-exclusion condition
(b) That denies the hold-and-wait condition
(c) That denies the circular-wait condition
(d) That denies the no-preemption condition
Discuss the practical applicability of each of these schemes.
6.28.Prove that the following resource allocation policies prevent deadlocks:
(a)Ordered requests
(b) Collective requests
6.29.A system uses the preemption method for deadlock prevention. Suppose the system currently
has five transactions T), T2,T3,T4,andT«,their timestamp values being 11'12,13,t4,andIs,
respectively (t)>12>13>14>Is).Explain what happens if:
(a) The system uses the wait-die scheme and T2requests for a resource held by Ts.
(b) The system uses the wait-die scheme and T4requests for a resource held by TJ•
(c) The system uses the wait-wound scheme and T3requests for a resource held by T4•
(d) The system uses the wait-wound scheme and Tsrequests for a resource held by T2•
6.30.What is a phantom deadlock? What might be the reason for phantom deadlocks in a
distributed system? Suppose that in the centralized deadlock detection scheme described in
thischapterthetransfer-on-request method is used to transfer information from local
coordinators to the central coordinator. Give an example to show that the algorithm may still
detect a phantom deadlock.
6.31.Acentralized deadlock detection algorithm thatdoes notdetect false deadlocks wasdeveloped
by Stuart et al. [1984]. Find out how this algorithm prevents the detection of false
deadlocks.
6.32.Writepseudocode for the probe-based distributed algorithm for deadlock detection in a
distributed system. What are the main advantages of this algorithm over a WFG-based
distributed algorithm?Chap. 6 • Bibliography 341
6.33.Whatproblems may arise when a process is killed/rolled back and then restarted as the result
of adeadlock? Suggestsuitablemethods to handle these problems. Whatconclusions can be
drawnfrom these problems inconnection with the properselection of victims for recovery
from adeadlock state?
6.34.What are the main issues involved in theselection of victims for recovery from adetected
deadlock? Suggestasuitablevictimselection algorithm. How does your algorithm take care
of astarvation problem?
6.35. Why are election algorithms normally needed in a distributed system? A LAN-based
distributed system has broadcast facility.Suggesta simple electionalgorithm for use in this
system.
6.36.Initiation of anelectionis actually needed only when the currentcoordinator processfails.
However, this is not the case in the bully algorithm, in which an electionis also initiated
whenever a failed process recovers. Is this really necessary? If yes, explain why. If no, suggest
amodification to the bully algorithm in which an ejectionis initiated only when the current
coordinator fails.
6.37. In the ring-based electionalgorithm described in this chapter, a unidirectional ring was used.
Suppose the ring is bidirectional. Can theelectionalgorithm be made more efficient? If no,
explain why. If yes, suggestsuch analgorithm andcompare the number of messages needed
forelectingacoordinator in the two algorithms, assuming that there are nprocesses in the
system.
6.38. In the ring-based electionalgorithm described in this chapter, two or more processes may
almostsimultaneously discover that the coordinator hascrashedand then each one may
circulate anelectionmessage over the ring. Although this does not cause any problem in the
election, it results in waste of network bandwidth. Modify the algorithm so that only one
electionmessage circulates completely round the ring and others are detected and killed as
soon as possible.
6.39.What will happen in a bully algorithm for electingacoordinator when two or more processes
almostsimultaneously discover that thecoordinator hascrashed?
818UOGRAPHY
[Adelstein andSinghal1995]Adelstein, F.,andSinghal,M.,"Real-Time CausalMessage Ordering
inMultimedia Systems," In:Proceedings oftheJ5th International Conference on Distributed
Computing Systems, IEEE, New York (May-June 1995).
[Agarwal andAbbadi 1991] Agarwal, D.,and El Abbadi, A.,"An Efficient and Fault-Tolerant
Solution ofDistributed MutualExclusion," ACM Transactions on Computer Systems, Vol.9,
Association forComputing Machinery, New York, pp. 1-20(1991).
[Badal1986] Badal, D. Z., "The Distributed Deadlock Detection Algorithm," ACM Transactionson
Computer Systems, Vol.4,No.4,Association forComputing Machinery, New York,pp. 320-337
(1986).
[Barborak etal,1993]Barborak, M., Malek, M., and Dahbura, A., "The Consensus Problem in
Fault-Tolerant Computing," ACM Computing Surveys, Vol. 25, Association forComputing
Machinery, New York, pp. 171-220 (1993).
[Bernstein et al, 1987]Bernstein, P. A.,Hadzilacos, V.,andGoodman, N.,Concurrency and
Recovery in Database Systems, Addison-Wesley, Reading, MA, pp. 289-307 (1987).342 Chap. 6 • Synchronization
(Bracha and Toueg 1984]Bracha,G., and Toueg, S., "A Distributed Algorithm forGeneralized
Deadlock Detection." In: Proceedings ofthe 3rdACMSymposium on Principles ofDistributed
Computing, Association forComputing Machinery, New York, pp. 285-301 (1984).
[Bracha and Toueg 1987]Bracha, G., and Toueg, S., "Distributed Deadlock Detection,"
Distributed Computing, Vol. 2, pp. 127-138 (1987).
[Bulgannawar and Vaidya 1995JBulgannawar, S., andVaidya,N.H.,"Distributed K-Mutual
Exclusion," In:Proceedings ofthe 15th International Conference on Distributed Computing
Systems, IEEE, New York (May-June ]995).
[Carvalho and Roucairol 1983]Carvalho, O.S.F.,andRoucairol, G., "On Mutual Exclusion in
Computer Networks," Communications ofthe ACM, Vol. 26,No.2,Association forComputing
Machinery, New York, pp. 146-]47 (1983).
[Chandy and Lamport 1985] Chandy, K. M., and Lamport, L.,"Distributed Snapshots:
Determining GlobalStates of Distributed Systems," ACMTransactions on Computer Systems,
Vol. 3, No. I,Association forComputing Machinery, New York, pp. 63-75(1985).
[Chandy and Misra 1982J Chandy, K.M., and Misra, 1., "A Distributed Algorithm forDetecting
Resource Deadlocks inDistributed Systems," In:Proceedings oftheACMSymposium on
Principles ofDistributed Computing, Association forComputing Machinery, New York, pp.
157-164 (August ]982).
[Chandy et ale1983J Chandy, K. M.,Misra, 1.,and Haas, L. M.,"Distributed Deadlock Detection,"
ACMTransactions on Computer Systems, Vol.I,No.2,Association forComputing Machinery,
New York, pp. 144-156 (1983).
[Choudhary et al, 1989] Choudhary, A. N., Kohler, W. H.,Stankovic, 1.A.,and Towsley, D., "A
Modified PriorityBasedProbeAlgorithm forDistributed Deadlock Detection andResolution,"
IEEE Transactions on Software Engineering, Vol. SE-15, No. l,pp.10-17(1989).
[Cidon et ale1987]Cidon,I., Jaffe, J. M.,and Sidi, M., "LocalDistributed Deadlock Detection by
CycleDetection andClustering," IEEE Transactions on-Software Engineering, Vol. SE-13, No.
I,pp.3-14(1987).
[CotTman etal,1971]Coffman, Jr., E. G. Elphick, M. 1., and Shoshani, A.,"System Deadlocks,"
ACMComputing Surveys, Vol. 3,No.2,Association forComputing Machinery, New York, pp.
67-78(1971).
[Coulouris et al. 1994]Coulouris, G. F.,Dollimore, J.,andKindberg, T.,Distributed Systems
Concepts and Design, 2nd ed., Addison-Wesley, Reading, MA (1994).
[Cristian 1989] Cristian, F.,"Probabilistic ClockSynchronization," Distributed Computing, Vol. 3,
pp.146-158 (1989).
[Cristian 1991] Cristian, F.,"Understanding Fault-Tolerant Distributed Systems," Communications
oftheACM,Vol. 34,Association forComputing Machinery, New York, pp. 56-78(1991).
[Cristian and Fetzer 1995]Cristian, F., and Fetzer, C., "Fault-Tolerant External Clock
Synchronization," In:Proceedings oftheJ5thInternational Conference on Distributed
Computing Systems, IEEE, New York (May-June 1995).
[Drummond and Babaoglu 1993] Drummond, R., and Babaoglu, 0.,"Low-Cost Clock
Synchronization," Distributed Computing, Vol. 6, pp. 193-203 (1993).
[Duboisetal, 1988]Dubois,M.,Scheurich, C., andBriggs,F.A.,"Synchronization, Coherence, and
EventOrdering inMultiprocessors," JEEE Computer, Vol. 21, pp. 9-21(1988).Chap. 6 • Bibliography 343
[Elmagarmid 1986]Elmagarmid, A.K., "A Survey of Distributed Deadlock Detection
Algorithms," ACMSIGMOD, Vol. 15,No.3,pp.37-45(1986).
[Fidge1991]Fidge, C.,"LogicalTimeinDistributed Computing Systems," IEEE Computer, Vol.
24,pp.28-33(1991).
[Fredrickson andLynch 1987] Fredrickson, N., and Lynch, N., "Electing aLeaderin a
Synchronous Ring,"JournaloftheACM,Vol. 34, pp. 98-115(1987).
[Garcia-Molina 1982]Garcia-Molina, H.,"Elections in aDistributed Computing System," IEEE
Transactions onComputers, Vol.C-31, No.1,pp.48-59(1982).
[Garg1996]Garg, V. K.,PrincipLes ofDistributed Systems, KluwerAcademic, Norwell, MA
(1996).
[Goscinski 1991] Goscinski, A.,Distributed Operating Systems, The LogicalDesign,Addison­
Wesley, Reading, MA(1991).
[Gray et al, 1981] Gray,J.N., Homan, P.,Korth,H.F., andObermarck, R.L., "A Straw Man
Analysis of the Probability ofWaiting and Deadlock inDatabase Systems," Technical Report RJ
3066,IBMResearch Laboratory, San Jose, CA (1981).
[Gusella and Zatti1989]Gusella, R., and Zatti, S., "The Accuracy of the Clock Synchronization
Achieved byTEMPO in Berkeley UNIX 4.3BSD," IEEETransactions on Software Engineering,
Vol. SE-15, No.7,pp.847-853 (1989).
[Jefferson 1985]Jefferson, D. R., "Virtual Time," ACMTransactions on Programming Languages
and Systems, Vol. 7,No.3,pp.404-425 (1985).
[Knapp 1987]Knapp, E., "Deadlock Detection inDistributed Databases," ACMComputing
Surveys, Vol.19,No.4,pp.303-328 (1987).
[KopetzandOchsenreiter 1987]Kopetz, H., and Ochsenreiter, W.,"ClockSynchronization in
Distributed Real-Time Systems," IEEETransactions onComputers, Vol. C-36, pp. 933-940
(1987).
[Lamport 1978]Lamport, L., "Time, Clocks, and the Ordering of Events in a Distributed System,"
Communications oftheACM,Vol. 21,No.7,pp.558-565 (1978).
[Lamport 1990]Lamport, L.,"Concurrent Reading and Writing of Clocks," ACMTransactions on
Computer Systems, Vol. 8, pp. 305 -310 (1990).
[Lamport and Smith 1984] Lamport, L., and Smith, P.M., "Byzantine ClockSynchronization," In:
Proceedings ofthe 3rdACMSymposium onPrinciples ofDistributed Computing, Association for
Computing Machinery, New York, pp. 68-74(1984).
[Lamport andSmith1985]Lamport, L., and Smith, P.M., "Synchronizing Clocks in the Presence
ofFaults,"JournaloftheACM, Vol.32, No. I,Association forComputing Machinery, New York,
pp.52-78(1985).
[Leeand Kim 1995] Lee, S., and Kim, 1.L.,44AnEfficient Distributed Deadlock Detection
Algorithm," In:Proceedings ofthe 15th International Conference onDistributed Computing
Systems, IEEE, New York (May-June 1995).
[Liskov 1993] Liskov, B., "Practical Uses of Synchronized Clocks in Distributed Systems,"
Distributed Computing, Vol.6, pp. 211-219 (1993).
[Lockhart 1994]Lockhart, Jr., H. W., OSFDeE:Guide to Developing Distributed Applications,
IEEEComputer Society Press, Los Alamitos, CA (1994).344 Chap. 6 • Synchronization
[Maekawa et al. 1987J Maekawa, M.,Oldehoeft, A. E., and Oldehoeft, R. R.,Operating Systems:
Advanced Concepts, Benjamin/Cummings, WhitePlains,NY (1987).
[Mattern 1993]Mattern, F.,"Efficient Algorithms forDistributed Snapshots andGlobalVirtual
TimeApproximation," JournalofParallel and Distributed Computing, Vol. 18, No.4,pp.
423-434 (1993).
[Mills 1991] Mills, D. L.,"Internet TimeSynchronization: TheNetwork TimeProtocol," IEEE
Transactions on Communications, Vol. 39, No. ]0,pp.]482-1493 (1991).
[Misra and Chandy 1982] Misra,J., andChandy,K. M.,"ADistributed GraphAlgorithm: Knot
Detection," ACMTransactions on Programming Languages andSystems, Vol. 4,No.4,pp.
678-686 (1982).
[Mitchell and Merritt1984JMitchelJ, D. P.,andMerritt,M.1.,"ADistributed Algorithm for
Deadlock Detection andResolution," In:Proceedings ofthe 3rdACM Symposium on Principles
ofDistributed Computing, Association forComputing Machinery, New York, pp. 282-284
(1984).
[Natrajan 1986]Natrajan,N.,"ADistributed SchemeforDetecting Communication Deadlocks,"
IEEE Transactions on Software Engineering, Vol.SE-12,No.4,pp.531-537 (1986).
[Prattand Nguyen1995] Pratt, G. A., and Nguyen, 1.,"Distributed Synchronous Clocking," IEEE
Transactions on Parallel and Distributed Systems, Vol. 6,No.3,pp.314-328 (1995).
[Ramanathan et al, 1990a] Ramanathan, P.,Kandlur, D. D., and Shin, K.G.,"Hardware-Assisted
Software ClockSynchronization forHomogeneous Distributed Systems," IEEE Transactions on
Computers, Vol. C-39, No.4,pp.514-524 (1990).
[Ramanathan et ale1990b] Ramanathan, P.,Shin, K.G.,and Butler, R. W.,"Fault-Tolerant Clock
Synchronization inDistributed Systems," IEEE Computer, Vol. 23, No. 10, pp. 33-42(1990).
[Raynal 1991] Raynal,M.,"ASimpleTaxonomy forDistributed MutualExclusion Algorithms,"
ACMOperating Systems Review, Vol. 25, pp. 47-50(1991).
[Raynal 1992] Raynal,M.,"AboutLogicalClocksforDistributed Systems," ACM Operating
Systems Review, Vol. 26, No. ], pp. 41-48(1992).
[Ricartand Agrawala 1981] Ricart, G., and Agrawala, A. K., "An Optimal Algorithm forMutual
Exclusion inComputer Networks," Communications ofthe ACM, Vol. 24, No. I,pp.9-17
(1981).
[Roesler and Burkhard 1989]Roesler, M., and Burkhard, W. A.,"Resolution ofDeadlocks in
Object-Oriented Distributed Systems," IEEE Transactions on Computers, Vol. 38,No.8,pp.
1212-1224 (1989).
[Rosenberry et al, 1992] Rosenberry, W., Kenney, D., and Fisher, G., OSP'DISTRIBUTED
COMPUTING ENVIRONMENT, Understanding DeE,O'Reilly&Associates, Sebastopol, CA
(1992).
[Rosenkrantz et al, 1978] Rosenkrantz, D. 1.,Stearns, R. E., and Lewis,P.M.,"System Level
Concurrency Control forDistributed Database Systems," ACM Transactions on Database
Systems, Vol. 3,No.2,pp.178-198 (1978).
[Sanders 1987] Sanders,B.A.,"TheInformation Structure ofDistributed MutualExclusion," ACM
Transactions on Computer Systems, Vol. 5, pp. 284-299 (1987).
[Shinand Ramanathan 1987]Shin, K.G.,andRamanathan, P,"ClockSynchronization of a Large
Multiprocessor Systemin thePresence ofMalicious Faults,"IEEE Transactions on Computers,
Vol.C-36,No.1,pp.2-12(1987).
[Shinand Ramanathan 1988]Shin, K.G.,andRamanathan, P.,"Transmission DelaysinHardware
ClockSynchronization," IEEE Transactions on Computers, Vol. C-37, No. 11, pp. 1465-1467
(1988).Chap.6 •Pointers toBibliographies on theInternet 345
[Silberschatz andGalvin1994]Silberschatz, A., andGalvin,P.B.,Operating Systems Concepts,
4th ed.,Addison-Wesley, Reading, MA(1994).
[SinghandKurose1994]Singh,S.,andKurose,J.,"Electing 'Good'Leaders," JournalofParallel
andDistributed Computing, Vol. 21, pp. 184-201 (1994).
[Singhal 1989]Singhal,M.,"Deadlock Detection inDistributed Systems," IEEE Computer, Vol.22,
No. 11, pp. 37-48(1989).
[Singhaland Shivaratri 1994]Singhal,M.,andShivaratri, N.G.,Advanced Concepts inOperating
Systems, McGraw-Hill, New York (1994).
[Sinhaand Natrajan 1985]Sinha,M. K., and Natrajan, N., "APriorityBasedDistributed Deadlock
Detection Algorithm," IEEE Transactions on Software Engineering, Vol.SE-ll,No.1,pp.67-80
(1985).
[Srikanth and Teueg 1987]Srikanth, T. K., and Teueg,S.,"Optimal ClockSynchronization,"
JournalofACM,Vol. 34,No.3,pp.626-645 (1987).
[Stalling 1995]Stalling, W.,Operating Systems, 2nded.,Prentice-Hall, Englewood Cliffs,NJ
(1995).
[Steinman et al. 1995]Steinman, 1. S., Lee, C. A.,Wilson,L.F., andNicol,D. M.,"GlobalVirtual
Time and Distributed Synchronization," In:Proceedings ofthe 9th Workshop on Parallel and
Distributed Simulation, pp.139-148 (1995).
[Stuartet al,1984]Stuart,D.,Buckley, G., and Silberschatz, A.,HACentralized Deadlock
Detection Algorithm," Technical Report,University ofTexas at Austin(J984).
[Suzuki and Kasami 1985]Suzuki,I.,andKasami, T.,"ADistributed Mutual Exclusion
Algorithm," ACMTransactions on Computer Systems, Vol. 3,No.4,pp.344-349 (1985).
[Tanenbaum 1992}Tanenbaum, A. S.,Modern Operating Systems, Prentice-Hall, Englewood
ClitTs,NJ(1992).
[Tanenbaum 1995]Tanenbaum, A.S.~Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ(1995).
[Tel1994] Tel,(J.,Introduction to Distributed Algorithms, Cambridge University Press, New York,
NY (1994).
[Turek and Shasha 1992]Turek,1., andShasha,D.,"TheManyFacesofConsensus inDistributed
Systems," IEEE Computer, Vol. 25, pp. 8-17(1992).
[Vasanthavada andMarinos 1988]Vasanthavada, N.,andMarinos, P. N.,"Synchronization of
Fault-Tolerant ClocksinthePresence ofMalicious Failures," IEEE Transactions on Computers,
Vol.C-37,No.4,pp.440-448 (1988).
[Wuu and Bernstein 1985]Wuu, G. T., and Bernstein, A.J.,"FalseDeadlock Detection in
Distributed Systems," IEEE Transactions on Software Engineering, Vol.SE-II,No.8,pp.
820-821 (1985).
[Yang and Marsland 1994]Yang,Z.,andMarsland, T. A.(Eds.),Global States and Time in
Distributed Systems, IEEEComputer SocietyPress,LosAlamitos, CA(1994).
POINTERS TOBIBI.IOGRAPHIES ONTHEINTERNET
Bibliography containing references onTime inDistributed Systemscan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributed/dist-time.html346 Chap.6 •Synchronization
Bibliography containing references onSynchronization ofConcurrent Processes can be
found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslParalleVpar.synch.html
Bibliographies containing references onothertopicscoveredin thischaptercan be found
at:
ftp:ftp.cs.umanitoba.calpu blbibliographies/OslIMMD _IV.html
ftp:ftp.cs.umanitoba.ca/publbibliographieslMisc/misc.l.htm1CHAPTER7
Resource
Management
7.1 INTRODUOION
Distributed systems are characterized by resource multiplicity and system transparency.
Every distributed system consists of a number ofresources interconnected by a
network. Besides providing communication facilities, the network facilitates resource
sharing by migrating a local process and executing it at a remote node of the network.
A process may be migrated because the local node does not have the required
resources or the local node has to be shut down. A process may also be executed
remotely if the expected turnaround time will be better. From a user's point of view,
the set of available resources in a distributed system acts like a single virtual system.
Hence, when a user submits a process for execution, it becomes the responsibility of
the resource manager of the distributed operating system to control the assignment of
resources to processes and to route the processes to suitable nodes of the system
according to these assignments . A resource can be logical, such as a shared file, or
physical, such as a CPU. For our purpose, we will consider a resource to be a
processor of the system and assume that each processor forms a node of the
distributed system. Thus, in this chapter, we will be interchangeably using the terms
nodeandprocessor to mean the same thing.
347348 Chap.7 •Resource Management
Aresource manager schedules theprocesses in adistributed systemtomakeuseof
thesystemresources in such a mannerthatresource usage,response time,network
congestion, andscheduling overhead areoptimized. Avarietyofwidelydiffering
techniques andmethodologies forscheduling processes ofadistributed systemhavebeen
proposed. Thesetechniques can bebroadlyclassified into three types:
1. Task assignment approach, inwhicheachprocess submitted by a user for
processing isviewedas acollection ofrelatedtasks and these tasks are scheduled
tosuitablenodes so as to improve performance
2. Load-balancing approach, inwhichall theprocesses submitted by the users are
distributed amongthenodesofthesystemso as toequalize theworkload among
thenodes
3. Load-sharing approach, whichsimplyattempts toconserve theabilityofthe
systemtoperformwork by assuring that no node is idle whileprocesses wait for
beingprocessed
Ofthethreeapproaches, the task assignment approach haslimitedapplicability in
practical situations becauseit works on the assumption that thecharacteristics ofall the
processes to bescheduled areknowninadvance. Furthermore, thescheduling algorithms
that fall in this category do notnormally takecareofthedynamically changing stateof
thesystem.Therefore, thisapproach will becovered verybrieflyjustto give an ideaof
how it works. Beforepresenting adescription ofeachofthesetechniques, thedesirable
featuresofa good global scheduling algorithm arepresented.
7.2 DESIMILE FEATURES OFAGOOD GLOBAL
SCHEDUUNG ALGORITHM
7.2.1 No A PrIori Knowledge abouttheProcess8s
Agoodprocess scheduling algorithm shouldoperate withabsolutely no apnon
knowledge abouttheprocesses to beexecuted. Scheduling algorithms thatoperatebased
on theinformation aboutthecharacteristics andresource requirements oftheprocesses
normally poseanextraburdenupon the users who mustspecifythisinformation while
submitting theirprocesses forexecution.
7.1.1 Dynamic InNature
It isintended that a good process-scheduling algorithm shouldbe able to take care ofthe
dynamically changing load (orstatus)ofthevariousnodesofthesystem.Thatis,process
assignment decisions shouldbebasedon thecurrentloadofthesystemand not on some
fixedstaticpolicy. For this, sometimes it is also recommended that the scheduling
algorithm shouldpossesstheflexibility tomigrateaprocessmore than oncebecausethe
initialdecision ofplacingaprocesson aparticular node may have to be changed afterSec.7.2 • Desirable Featuresof a GoodGlobal Scheduling Algorithm 349
some time to adapt to the new system load. This feature mayalso require that the system
supportpreemptive process migration facility in which a process can bemigrated from
one node to anotherduring the course of its execution.
7.2.3QuickDecision-Making Capability
A goodprocess-scheduling algorithm must make quick decisions about the assignment of
processes to processors. This is an extremely important aspect of the algorithms and
makes many potential solutions unsuitable. For example, an algorithm that models the
system by a mathematical program and solves it on-line is unsuitable because it does not
meet this requirement. Heuristic methods requiring less computational effort while
providing near-optimal results are therefore normally preferable to exhaustive (optimal)
solution methods.
7.2.4Balanced SystemPerformance andScheduling
Overhead
Several global scheduling algorithms collect global state information and use this
information in making process assignment decisions. A common intuition is that greater
amounts of information describing global system state allow more intelligent process
assignment decisions to be made that have a positive affect on the system as a whole. In
a distributed environment, however, information regarding the state of the system is
typically gathered at a higher cost than in a centralized system. The general observation
is that, as overhead is increased in an attempt to obtain more information regarding the
global state of the system, the usefulness of that information is decreased due to both the
aging of the information being gathered and the low scheduling frequency as a result of
the cost of gathering and processing that information. Hence algorithms that provide near­
optimal system performance with a minimum of global state information gathering
overhead arc desirable.
7.2.5Stability
A scheduling algorithm is said to be unstable ifitcan enter a state inwhich all the nodes of
the system are spending all of their time migrating processes withoutaccomplishing any
useful work in an attempt to properly schedule the processes for better performance. This
form of fruitless migration of processes is known as processor thrashing. Processor
thrashing can occur insituations whereeach nodeofthe system hasthepower ofscheduling
its ownprocesses andscheduling decisions either are made independently of decisions
made by other processors or are based on relatively old data due to transmission delay
between nodes. Forexample, itmayhappen that nodes nlandn2bothobserve thatnode n3is
idle and then both offload a portion of their work to node n3without being aware of the
offloading decision made by the other. Now if node n3becomes overloaded due to the
processes received from both nodes nlandn2'then it may again start transferring its
processes toother nodes. This entire cycle may be repeatedagain and again, resulting inan
unstable state.This iscertainly notdesirable foragood scheduling algorithm.350 Chap.7 •Resource Management
Processor thrashing can also occur if processes in transit to a lightly loaded node are
not taken into account. In this case, several processes'may be migrated to the same node,
possiblyproducing instabilities. For example, suppose at a particular instance of time node
nJ is very busy and node n2is the least busy node. Also suppose that node n.is activated
every 2 seconds and on an average it takes 20 seconds for a process to reach node n2from
nodenl'Then node n.couldconceivably send at least 10 processes to noden2before the
first one was received. This could result in an unstable situation. A simple method to
overcome this problem isto keep track of which node has been sent processes recently and
use this information in an effort to mitigate the problem and to minimize process
movement. More sophisticated techniques to deal with stability are possible, but they
require the retention of more past data and hence are expensive.
7.2.6Scalability
Ascheduling algorithm should be capableofhandling small as well as large networks. An
algorithm that makes scheduling decisions by first inquiring the workload from all the
nodes and then selecting the most lightly loaded node as the candidate for receiving the
process(es) has poor scalability factor. Such an algorithm may work fine for small
networks but gets crippled when applied to large networks. This is because the inquirer
receives a very large number of replies almost simultaneously, and the time required to
process the reply messages for making a host selection is normally too long. Moreover, the
N2(Nis the total number of nodes in the system) nature ofthe algorithm creates heavy
network traffic and quickly consumes network bandwidth. A simple approach to make an
algorithm scalable is to probe only mofNnodes for selecting ahost. The value of mcan
bedynamically adjusted depending upon the value of N.
7.1.7FaultTol.raftC8
A goodscheduling algorithm should not be disabled by the crash of one or more nodes of
the system. At any instance of time, itshouldcontinue functioning for nodes that are up
at that time. Moreover, if the nodes are partitioned into two or more groups due to link
failures, the algorithm should be capableof functioning properly for the nodes within a
group.Algorithms that have decentralized decision-making capability andconsider only
available nodes in their decision-making approach have better fault tolerance
capability.
7.1.8FairnessorSarvle.
While the averagequalityofserviceprovided is clearly an important performance index,
how fairly service is allocated is also a common concern. For example, two users
simultaneously initiating equivalent processes expect to receive about the same quality of
service. Several researchers think that global scheduling policies that blindly attempt to
balance the average load on allthe nodes ofthe system are not good from the point of view
offairnessofservice. This is because in any load-balancing scheme, heavily loaded nodes
will obtain all the benefits while lightly loaded nodes will suffer poorerresponse time thanSec.7.3 • Task Assignment Approach 351
thatin astand-alone configuration. Whatisdesirable is a fair strategythat will improve
response time to the formerwithoutundulyaffecting the latter. Forthis, the conceptof
loadbalancing has to be replaced by theconceptofloadsharing,thatis, a node will share
someofitsresources as long as its users are not significantly affected.
7.3TASKASSIGNMENT APPROACH
7.3.1 The Basic Idea
In thisapproach, aprocessisconsidered to becomposed ofmultiple tasks and the goal is
to find an optimal assignment policyfor the tasks ofanindividual process. Typical
assumptions found in task assignment workare asfollows:
• Aprocesshasalreadybeen split into piecescalledtasks. This splitoccursalong
naturalboundaries, so thateachtask will have integrity initselfand data transfers
amongthe tasks will be minimized.
• Theamountofcomputation required byeachtask and the speedofeachprocessor
areknown.
• Thecostofprocessing each task on everynodeofthesystemisknown.Thiscost
isusuallyderivedbasedon theinformation aboutthespeedofeachprocessor and
theamountofcomputation required byeachtask.
• Theinterprocess communication (fPC)costsbetween everypairoftasks isknown.
TheIPCcostisconsidered zero(negligible) for tasks assigned to the same node.
Theyareusuallyestimated by ananalysisofthe static program ofaprocess. For
example, duringtheexecution oftheprocess,iftwo tasks communicate ntimes
and if the average time for each intertask communication ist,theintertask
communication cost for the two tasksisnXt.
•Otherconstraints, such asresource requirements ofthe tasks and the available
resources ateachnode,precedence relationships amongthe tasks, and so on, are
alsoknown.
•Reassignment ofthe tasks is generally notpossible.
With these assumptions, the taskassignment algorithms seek toassignthe tasks ofa
processto the nodes ofthedistributed systemin such a mannerso as toachievegoals such
as thefollowing:
•Minimization ofIPecosts
•Quickturnaround time for the complete process
• A high degreeofparallelism
•Efficient utilization ofsystemresources ingeneral
Thesegoalsoftenconflictwitheachother.Forexample, whileminimizing IPetends
toassignall the tasks ofaprocessto asinglenode,efficient utilization ofsystemresources352 Chap.7 •ResourceManagement
tries todistribute the tasks evenly among the nodes. Similarly, while quick turnaround
time and a high degree ofparallelism encourage parallelexecution ofthe tasks, the
precedence relationship among the tasks limits their parallelexecution. Also notice that in
caseofm tasks and qnodes, there are mqpossible assignments oftasks to nodes. In
practice, however, the actual numberofpossibleassignments oftasks to nodes may be less
thanmqdue to the restriction thatcertaintaskscannotbeassigned tocertainnodes due to
theirspecificresource requirements; therequired resource(s) may not be available on all
the nodes ofthe system.
Toillustrate with anexample, let usconsider theassignment problemofFigure7.1.
This is the same problemdiscussed byStone[1977]. It involves only two task assignment
parameters-the taskexecution cost and the intertask communication cost. This system is
made up ofsix tasks {tI,t2,t3,t4,Is,t6}and two nodes {nI'n2}.Theintertask
communication costs(c;j)and theexecution costs(Xab)ofthe tasks are given in tabular
form inFigure7.1(a)and(b),respectively. An infinite cost for a particular taskagainsta
particular node in Figure 7.1 (b)indicates that the task cannotbeexecuted on that node due
to thetask'srequirement ofspecificresources that are not available on that node. Thus,
taskt2cannotbeexecuted on nodenzand task t6cannotbeexecuted on nodenI.In this
modelofadistributed computing system, there is no parallelism ormultitasking oftask
execution within a program. Thus the total cost ofprocessexecution consistsofthe total
execution costofthe tasks on their assigned nodes plus the intertask communication costs
between tasksassigned todifferent nodes.
Figure7.1(c)shows a serial assignment ofthe tasks to the two nodes in which the
first three tasks are assigned to noden.and theremaining three are assigned to noden2.
Observe that thisassignment is aimed at minimizing the totalexecution cost. But if both
theexecution costs and the communication costs are taken into account, the total cost for
thisassignment comes out to be 58. Figure 7.1(d)shows an optimal assignment of the
tasks to the two nodes that minimizes totalexecution andcommunication costs. In this
case,although theexecution cost is more than that oftheprevious assignment, the total
assignment cost is only 38.
7.3.2FindinganOptimalAsslgnm.nt
Theproblemoffinding an assignment oftasks to nodes that minimizes totalexecution and
communication costs was elegantly analyzed using anetwork flow model and network
flowalgorithms by Stone [1977, 1978] and a numberofotherresearchers [Lo 1988, Wu
and Liu 1980, Bokhari 1979]. In this approach, anoptimalassignment is found by creating
a staticassignment graph, as shown in Figure 7.2. In this graph, nodes nIandn2represent
the two nodes (processors) ofthedistributed system and nodes t.through 16represent the
tasksofthe process. The weights oftheedgesjoiningpairsoftask nodes represent
intertask communication costs. The weight on the edge joininga task node to node n.
represents theexecution cost of that task on node nzand vice versa.
Acutsetin this graph is definedto be a set ofedges such that when these edges are
removed, the nodes of the graph are partitioned into two disjoint subsets such that the
nodes in one subsetarereachable fromnIand the nodes in the otherarereachable from
n2.Each task node is reachable fromeithernIorn2.No proper subset ofa cutset is alsoSec.7.3 • TaskAssignment Approach
Intertask communication costs
t1t2t3t4t5t6
'10640 0 12
'26081230
'34800110
140120 0 50
150311500
te12000 0 0
(a)
Serialassignment
Task Node
11 n,
12 n1
13 n1
'4 n2
15 n2
Ie n2
(c)Execution costs
TasksNodes
n, n2
t15 10
t2 2 00
134 4
'46 3
'55 2
4; 00 4
(b)
Optimalassignment
Task Node
11 n1
t2 n1
13 n1
14 n1
1s n1
'6n2
(dJ353
Serialassignment execution cost(x)=X11+X21+X31+X42+XS2+X62
=5+2+4+3+2+4=20
Serialassignment communication cost(c)=C14+C15+C16+C24+C25+~6+C34+~s+C36
=0+0+12+12+3+0+0+11+0=38
Serial assignment total cost =x+C=20+38=58
Optimalassignment execution cost (x)=X11+X21+X31+X41+XS1+x62
=5+2+4+6+5+4=26
Optimalassignment communication cost(c)=C16+C26+~+C46+CS6
=12+0+0+0+0=12
Optimalassignment total cost=x+C=26+12=38
Fig. 7.1 A taskassignment problem example. (a)intertask communication costs;
(b)execution costs of the tasks on the two nodes; (c)serial assignment;
(d)optimalassignment.354 Chap.7 •Resource Management
Minimumcostcut
I.'ig.7.2 Assignment graph for the assignment problem of Figure 7.1with minimum
cost cut.
a cutset, that is, a cutset is a minimal set. Each cutset corresponds in aone-to-one manner
to a task assignment.
The weight of a cutset is the sum of the weights of the edges in the cutset. It
represents the cost of the corresponding taskassignment since the weight of a cutset sums
up theexecution andcommunication costs for that assignment. An optimal assignment
may beobtained by finding a minimum-weight cutset. This may be done by the use of
network flow algorithms, which are among the class ofalgorithms with relatively low
computational complexity. The bold line in Figure 7.2 indicates a minimum-weight cutset
thatcorresponds tothe optimal assignment of Figure 7.1 (d).Note that if task t1is assigned
to noden2'then the edge to node n2is cut, but this edge carries the cost of executing task
t)on nodenl.Similarly, other edges cut between task t)and other nodes of the graph
represent actualcommunication costs incurred by this assignment forcommunication
between tasktIand the other corresponding nodes.
In atwo-processor system, an optimal assignment can be found in polynomial time
byutilizing Max Flow/Min Cut algorithms [Shen and Tsai 1985]. However, for an
arbitrary numberof processors, the problem is known to be Nonpolynomial (NP) hard. An
NP hardproblemiscomputationally intractable because it cannot besolved in polynomial
time. Thus, for more general cases, several researchers have turned to heuristic algorithms
that are computationally efficient but may yield suboptimal assignments. Readers
interested in some of these heuristic algorithms may refer to [Arora and Rana 1980, Ere
1982, Lo 1988].Sec.7.4 • Load-Balancing Approach 355
It may be noted that in the model described above, the tasks of a process were
assigned to the various nodes ofthe system. This modelmay begeneralized tothe general
taskassignment problem in which several processes are to be assigned. In this case, each
process is treated to be a task of the process force and the intcrprocess communication
costs are assumed to be known.
Severalextensions to the basic task assignment modeldescribed above have been
proposed in the literature. In addition to the task assignment cost and the intertask
communication costparameters of the basic task assignment model, the extended models
take into account other parameters such as memory size requirements ofthe task and
memory size constraint oftheprocessors, precedence relationship among the tasks, and so
on. However, we will not discuss this topic any further becauseof thelimitedapplicability
of the task assignment approach in practical situations. Readers interested in someofthese
extended models may refer to [Lo 1988, Chu and Lan 1987, Rao et a1.1979].
7.4LOAD-BALANCING APPROACH
The scheduling algorithms using this approach are known as load-balancing algorithms or
load-leveling algorithms. Thesealgorithms arc based on the intuition that, for better
resource utilization, it isdesirable for the load in a distributed system to be balanced
evenly. Thus, a load-balancing algorithm tries to balance the total system load by
transparently transferring theworkload from heavily loaded nodes to lightly loaded nodes
in anattempttoensuregood overall performance relative to some specific metric of
systemperformance. Whenconsidering performance from the user point of view, the
metric involved is often the response time of the processes. However, when performance
isconsidered from the resource point of view, the metric involved is the total system
throughput. In contrastto response time, throughput isconcerned with seeing that all users
are treated fairly and that all are making progress. Notice that the resource view of
maximizing resource utilization iscompatible with the desire to maximize system
throughput. Thus the basic goal of almost all the load-balancing algorithms is tomaximize
the total system throughput.
7.4.1 ATaxonomy ofl.oad-Balancing Algorithms
Thetaxonomy presented here is a hierarchy of the features of load-balancing algorithms.
The structure of the taxonomy is shown in Figure 7.3. To describe a specific load­
balancing algorithm, ataxonomy user traces paths through the hierarchy. A description of
thistaxonomy is given below.
Static versus Dynamic
At thehighestlevel, we may distinguish between staticanddynamic load-balancing
algorithms. Staticalgorithms use only information about the average behavior of the
system, ignoring the currentstate of the system. On the other hand, dynamic algorithms
react to the systemstate that changesdynamically.356 Chap.7 •Resource Management
DeterministicLoad-balancing algorithms
Dynamic
Probabilistic
Cooperative Noncooperative
Fig. 7.3 A taxonomy of load-balancing algorithms.
Staticload-balancing algorithms are simpler because there is no need to maintain and
process system state information. However, the potential of static algorithms is limited by
the fact that they do not react to the current system state. The attraction of dynamic
algorithms is that they do respond to system state and so are better able to avoid those
states with unnecessarily poor performance. Owingto this reason, dynamic policies have
significantly greater performance benefits than static policies. However, since dynamic
algorithms must collect and react to system state information, they are necessarily more
complex than static algorithms.
Deterministic versusProbabilistic
Staticload-balancing algorithms may be either deterministic orprobabilistic. Determi­
nistic algorithms use the information about the properties of the nodes and the
characteristics of the processes to be scheduled to deterministically allocate processes to
nodes. Notice that the task assignment algorithms basically belong to the category of
deterministic static load-balancing algorithms.
Aprobabilistic load-balancing algorithm usesinformation regarding staticattributesof
the system such as number of nodes, the processing capability of each node, the network
topology, and so on, to formulate simple process placement rules. For example, suppose a
system has two processors PIandP2and four terminals tl,12,13,andt4'Then a simple
processplacement rule can be, assign all processes originating at terminals 11and12to
processor PIandprocesses originating atterminals 13and14toprocessor P2'Obviously,such
staticload-balancing algorithms have limited potential to avoid those states that have
unnecessarily poor performance. For example, suppose at the time a particular process
originates at terminal IIprocessor PIis very heavily loaded and processor P2is idle.
Certainly, processor P2isabetterchoice for the process in such asituation.Sec.7.4 • Load-Balancing Approach 357
In genera], the deterministic approach is difficult to optimize and costs more to
implement. The probabilistic approach is easier to implement but often suffers from
having poor performance.
Centralized versusDistributed
Dynamic scheduling algorithms may be centralized ordistributed. In acentralized
dynamic scheduling algorithm, theresponsibility ofscheduling physically resides on a
single node. On the otherhand, in a distributed dynamic scheduling algorithm, the work
involved in making process assignment decisions is physically distributed among the
various nodes of the system. In the centralized approach, the system state information is
collected at a single node at which all scheduling decisions are made. This node is called
thecentralized servernode.All requests for process scheduling are handled by the
centralized server, which decides about the placement of a new process using the state
information stored in it.The centralized approach can efficiently make process assignment
decisions because the centralized server knows both the load at each node and the number
of processes needing service. In the basic method, t.heother nodes periodically send status
update messages to the central server node. These messages are used to keep the system
stateinformation up to date at the centralized server node. One might consider having the
centralized server query the other nodes for state information. This would reduce message
traffic if state information was used to answer several process assignment requests, but
since nodes can change their load any time due to local activities, this would introduce
problems of stale state information.
Aproblem associated with the centralized mechanism is that of reliability. If the
centralized server fails, all scheduling in the system would cease. A typical approach to
overcome this problem would be to replicate the server on k+1 nodesifit is to survive
kfaults (node failures). In this approach, the overhead involved in keeping consistent all
thek+1replicas of the server may be considerably high. A typical solution to reduce this
overhead is to forgo strong consistency and use a cheapermechanism to update the
multiple copies of the server. This solution is based on the idea that strict consistency is
not necessary in this case for the system to function properly.
Theimer and {Jantz [1989] proposed that if occasional delays in service of several
seconds are acceptable, one can use the simplerapproach of reinstantiation to improve the
reliability of the centralized scheduling mechanism. In this approach, rather than
maintaining k+1 server replicas, a single server is maintained and there are kentities
monitoring the server to detect its failure. When failure is detected, a new instance of the
server is brought up, which reconstructs its state information by sending a multicast
message requesting immediate state update. The time during which the scheduling service
is unavailable will be the sum of the time to detect failure of the previous server, the time
to load the server program on the new server, the time to resolve the possibility of multiple
concurrent instantiations among the kentities, and the time to reconstruct the global state
information on the new server [Theimer and Lantz 1989].
Incontrast to thecentralized scheme, a distributed scheme does not limit the
scheduling intelligence toone node. Itavoids the bottleneck of collecting stateinformation
atasingle node and allows the scheduler to react quickly to dynamic changes inthe system358 Chap.7 •ResourceManagement
state. Adistributed dynamic scheduling algorithm is composed ofkphysically distributed
entitiesel'e2'...,ekeEachentity is considered alocalcontroller. Each local controller runs
asynchronously andconcurrently with the others, and each is responsible for making
scheduling decisions fortheprocesses ofapredetermined setof nodes. Each entity e,makes
decisions based on a systemwide objective function, rather than on a local one. Each e,
makesdecisions on an equal basis with the other entities; that is, there is no master entity,
even forashort period oftime. Inafully distributed algorithm, each node has itsown entity
and hence k=Nfor a system having Nnodes. In this case, each entity is responsible for
makingscheduling decisions forthe processes ofitsown node, whichincludes bothtransfer
oflocalprocesses and acceptance ofremote processes.
Cooperative versusNoncooperative
Distributed dynamic scheduling algorithms may be categorized ascooperative and
noncooperative. Innoncooperative algorithms, individual entities act as autonomous
entitiesand make scheduling decisions independently of the actions of other entities. On
theotherhand, in cooperative algorithms, the distributed entities cooperate with each
otherto make scheduling decisions. Hence, cooperative algorithms are more complex and
involve larger overhead than noncooperative ones. However, the stability of a cooperative
algorithm is better than that of a noncooperative algorithm.
7.4.1ISlu.sInhslgnlng load-Ialanclng Algorithms
Designing a goodload-balancing algorithm is a difficult task because of the following
issues:
• Loadestimation policy, which determines how to estimate the workload of a
particular nodeofthe system
• Process transfer policy, which determines whether to execute a process locally or
remotely
• State information exchange policy, which determines how to exchange the system
loadinformation among the nodes
• Location policy, which determines to which node a process selected for transfer
should be sent
• Priority assignment policy, which determines the priority of execution of local and
remote processes at a particular node
•Migration limiting policy, which determines the total number of times a process
can migrate from one node to another
Theseissues are discussed below. For this discussion, we divide the processes within
the system into two classes: local processes and remote processes. A local process is one
that isprocessed at itsoriginating node and a remote process is one that is processed at
a nodedifferent from the one on which it originated. A new process, arriving from the
external world at a node, becomes a local process if it is admitted to that node forSec.7.4 • Load-Balancing Approach 359
processing. Otherwise, itistransferred across the network and becomes a remote process
at thedestination node.
LoadEstimation Policies
The main goal of load-balancing algorithms is tobalancetheworkload on all the nodes
ofthe system. However, before an algorithm canattempttobalancethe workload, it is
necessary to decide how to measure the workload of a particular node. Hence the first
issue in any load-balancing algorithm is to decide on the method to be used to estimatethe
workload of aparticular node.Estimation of the workload of a particular node isa difficult
problem for which no completely satisfactory solution exists. A node'sworkload can be
estimated based on some measurable parameters. Theseparameters could include time­
dependent andnode-dependent factors such as the following:
• Total number ofprocesses on the node at the time ofloadestimation
• Resource demands of these processes
•Instruction mixes of these processes
•Architecture and speed of the node'sprocessor
Since the measurement of load would occur quite often and the load would reflect the
currentstate of the node, its calculation must he very efficient. This rules out an
exhaustive use of all parameters eveniftheir relative importance is known. Thus several
load-balancing algorithms use the total number of processes present on the node as a
measure of the node'sworkload. However, several designers believe that this is an
unsuitable measure for such an estimate since the true load could vary widely depending
on theremaining service times for those processes. Therefore anothermeasure used for
estimating anode'sworkload is the sum of the remaining servicetimes of all the processes
on that node. However, in thiscase another issue that must be resolved is how to estimate
theremaining service time of the processes. Bryant and Finkel [1981] have proposed the
use of one of the foJlowing methods for this purpose:
1.Memoryless method. This method assumes that all processes have the same
expected remaining service time, independent of the time used so far. The use of
this method for remaining service time estimation of a process basically reduces
the loadestimation method to that of total number of processes.
2.Pastrepeats. This method assumes that the remaining service time ofa process is
equal to the time used so far byit.
3.Distribution method.If thedistribution of service times is known, the associated
process's remaining service time is the expected remaining timeconditioned by
the time already used.
Neitherthe method of counting the total numberofprocesses nor the method of
taking the sum of the remaining service times of all processes is suitable for use as load
estimation policiesin modern distributed systems. This is becausein modern distributed360 Chap.7 •Resource Management
systems,evenonanidlenode,severalprocessessuchasmailandnewsdaemons,window
managers,andsoon,existpermanently.Moreover,manyofthesedaemonprocesseswake
upperiodically,checkto see if there is anythingthatthey haveto do, and if not,go back
to sleep. Therefore, an acceptable method for use as the load estimation policy in these
systemswouldbetomeasuretheCPUutilizationofthenodes[Tanenbaum1995]. Central
processing unit(CPU)utilization is defined as the number ofCPU cycles actually
executed per unit of real time. Obviously,the CPU utilizationof a heavily loaded node
will be greater than the CPU utilizationof a lightlyloaded node.The CPU utilizationof
anodecan be measuredbysetting upa timertoperiodicallyobservethe CPUstate(idlel
busy).
ProcessTransfer Policies
The strategy of load-balancing algorithms is based on the idea of transferring some
processes from the heavily loaded nodes to the lightly loaded nodes for processing.
However,to facilitate this, itis necessaryto devise a policy to decide whether a node is
lightly or heavilyloaded.Most of the load-balancingalgorithmsuse the threshold policy
to make this decision.The threshold valueof a nodeis thelimitingvalueof its workload
and is used to decide whethera node islightlyor heavily loaded.Thus a new process at
anodeisacceptedlocallyforprocessingiftheworkloadofthenodeisbelowitsthreshold
valueatthattime.Otherwise,anattemptismadetotransfertheprocesstoalightlyloaded
node. The threshold value of a node may be determined by any of the following
methods:
1. Static policy. In this method, each node has a predefined threshold value
depending on its processing capability. This threshold value does not vary with the
dynamic changes in workload at local or remote nodes. The main advantage of this
methodis that no exchangeof stale informationamong the nodes is requiredin deciding
the threshold value.
2.Dynamic policy.Inthis method,thethresholdvalueofa node (nj)iscalculatedas
aproductoftheaverageworkloadofallthenodesandapredefinedconstant (c;).Foreach
noden.,the value of c,depends on the processing capability of node n,relative to the
processing capability of an other nodes. In this method, the nodes exchange state
information by using one of the state information exchange policies (described Jater).
Although thedynamicpolicygives a morerealisticvalueof thresholdfor each node,the
overhead involved in exchange of state information makes its applicability
questionable.
Mostload-balancingalgorithmsuseasinglethresholdandthusonlyhaveoverloaded
andunderloadedregions[Fig.7.4( a)].In thissingle-thresholdpolicy,a nodeacceptsnew
processes(either localor remote) ifits load is belowthe thresholdvalueand attemptsto
transfer local processes and rejects remote execution requests if its load is above the
threshold value.Thereforethedecisionregardingboth the transferof localprocessesandthe acceptanceof remoteprocessesis donebasedon a single-thresholdvalue.The useofSec. 7.4 • Load-Balancing Approach
Fig. 7.4 The load regions of
(a)single-threshold policy and
(b)double-threshold policy.Overloaded
Underloaded
(a)Threshold361
Overloaded
1--------1 Highmark
Normal
foo--------t Lowmark
Underloaded
(b)
asingle-threshold value may lead to fruitless process transfers, making the scheduling
algorithm unstable because a node's load may be below the threshold when it decides to
accept a remote process, but its load may become larger than the threshold as soon as the
remote process arrives. Therefore, immediately after receiving the remote process, the
node will again try to transfer one or more of its processes to some other node. Moreover,
Alonso and Cova [1988] observed:
• A node should only transfer one or more of its processes to another node ifsuch
a transfer greatly improves the performance of the rest of its local processes.
• A node should accept remote processes only if its load is such that the added
workload ofprocessing theseincoming processes does not significantly affect the
service to the local ones.
To reduce the instability of the single-threshold policy and to take care of these two
notions, Alonso and Cova [1988] proposed a double-threshold policy called the high-low
policy.As shown in Figure 7 .4(b),the high-low policy uses two threshold values called
highmarkandlowmark,which divide the space of possible load states of a node into the
following three regions:
•Overloaded-above the high-mark and low-mark values
•Normal-above the low-mark value and below the high-mark value
•Underloaded-below both values
Anode'sload state switches dynamically from one region to another, as shown in Figure
7.5.
Now depending on the current load status of a node, the decision to transfer a local
process or to accept a remote process isbased on the following policies [Alonso and Cova
1988]:362
Job
arrival/departureJob
arrival/departureChap.7 •Resource Management
Job
arrival/departure
Fig.7.5 State transition diagram of the load of a node in case of double-threshold policy.
• When the loadof the node isin theoverloaded region, new local processes are sent
to be run remotely and requests to accept remote processes are rejected.
• When the load of the node is inthe normal region, new local processes run locally
and requests to accept remote processes are rejected.
• When the load of the node is in the underloaded region, new local processes run
locally and requests to accept remote processes are accepted.
Notice that the high-low policy guarantees a predefined level of performance to the
node owners. It accounts for the overhead that the load-balancing algorithm may incur in
transferring and receiving a remote process. A process will not be transferred to another
node unless it is worthwhile, and a remote process will not be accepted unless there is
enough excess capacity to handle it [Alonso and Cova 1988].
Location Policies
Once a decision has been made through the transfer policy to transfer a process from a
node, the next step is to select the destination node for that process's execution. This
selection is made by the location policy of a scheduling algorithm. The main location
policies proposed in the literature are described below.
Threshold. In this method, a destination node is selected at.random and a check
is made to determine whether the transfer of the process to that node would place it in a
state that prohibits the node to accept remote processes. If not, the process is transferred
to the selected node, which must execute the process regardless of its state when the
process actually arrives. On the other hand, if the check indicates that the selected node
is in a state that prohibits itto accept remote processes, another node is selected atrandom
and probed in the same manner. This continues until either a suitable destination node is
found or the numberof probes exceeds'a static probe limit Lp•In the latter case, the node
on which the process originated must execute the process. Eager et al. [1986b] performed
simulations by using the single static threshold transfer policy and this threshold location
policy.Theirsimulation results showed that the performance of this policy is surprisingly
insensitive to the choice of probe limit; the performance with a small (and economical)Sec.7.4 • Load-Balancing Approach 363
probe limit (e.g., 3 or 5) is almost as good as the performance with a large probe limit
(e.g., 20). The simulation results also showed that the threshold policy provides substantial
performance improvement relativeto no load balancing. Thisindicates that very simple
schemes can yield significant benefits.
Shortest. In this method, Lpdistinct nodes are chosenat random, and each is
polled in turn to determine its load. The processistransferred to the node having the
minimum load value, unless that node'sload is such that it prohibits the node to accept
remote processes. If none of the polled nodes can accepttheprocess,it isexecuted at its
originating node. If a destination node is found and the processistransferred there, the
destination node must executethe process regardless ofits state at the time the process
actually arrives. A simple improvement to the basic shortest policy is to discontinue
probingwhenever a node with zero load is encountered, since that node is guaranteed to
be anacceptable destination.
Theshortestpolicy uses more state information, in a more complex manner, than
does thethreshold policy. But Eager et a1.[1986b] found, through their simulation results,
that the performance of theshortestpolicy is not significantly better than that of the
simplerthreshold policy. This suggests that state information beyondthat used by the
threshold policy or a more complex usage of state information is of little benefit.
Bidding. In this method, the system is turned into a distributed computational
economy with buyers and sellers of services [Waldspurger et al. 1992,Malone et al. 1988].
Each node in the networkisresponsible for two roles with respect to the bidding process:
manager and contractor. The manager represents a node having a process in need of a
location toexecute, and thecontractor represents a node that is able to accept remote
processes. Note that a single node takes on both these roles and no nodes are strictly
managers or contractors alone. To select a node for its process, the manager broadcasts a
request-for-bids message to all other nodes in the system. Upon receiving this message,
thecontractor nodes return bids to the manager node. The bids containthe quoted prices,
which vary based on the processing capability, memory size, resource availability, and so
on, of the contractor nodes. Of the bids received from the contractor nodes, the manager
node chooses the best bid. The best bid for a manager's request may mean the cheapest,
fastest, or best price-performance, depending on theapplication for which the requestwas
made. Once the best bid is determined, theprocessistransferred from the manager node
to the winning contractor node. But it is possible that acontractor node may
simultaneously win many bids from many other manager nodes and thus become
overloaded. Topreventthis situation, when the best bid is selected, a message is sent to
theownerof that bid. At that point the bidder may chooseto accept or reject that process.
A message is sent back to the concerned manager nodeinforming it as towhetherthe
process has been accepted or rejected. A contractor node may reject a winning bid because
ofchangesin its state betweenthe time the bid was made and the time it was notified that
it won the bid. If the bid is rejected, the biddingprocedure is started all over again.
Biddingalgorithms areinteresting becausethey provide full autonomy to the nodes
to decide whethertoparticipate in the global scheduling process. For example, amanager
node has the powerto decide whether to send a process to a contractor node, which
responds with bids, and a contractor node has the powerto decide whetherit wants to364 Chap.7 •Resource Management
accept remote processes. A contractor node is never forced to accept remote processes if
it does not choose to do so. On the other hand, the two main drawbacks ofbidding
algorithms are that they create a great deal of communication overhead and it is very
difficult to decide a good pricing policy. Both factors call for a proper choice of the
amountand type of information exchanged during bidding. For a bidding algorithm, the
amount and type of information exchanged are generally decided in such a manner so as
to balance the effectiveness and performance of the algorithm. A variety of possibilities
existconcerning thetype and amount ofinformation exchanged inorder tomake decisions
[Stankovic and Sidhu 1984, Smith 1980, Hwang et aJ. 1982, Stankovic 1984].
Pairing. The method of accomplishing load balancing employed by the policies
described until now is to balance or reduce the variance between the loads experienced by
all the nodes ofthe system. Contrary to this approach, the method of accomplishing load
balancing by the pairing policy is to reduce the variance of loads only between pairs of
nodes of the system. This location policy was proposed by Bryant and 'Finkel [1981]. In
this method, two nodes that differ greatly in load are temporarily paired with each other,
and theload-balancing operation is carried out between the nodes belonging to the same
pair by migrating one or more processes from the more heavily loaded node to the other
node. Several node pairs may exist simultaneously in the system. A node only tries to find
a partner if it has at least two processes; otherwise migration from this node is never
reasonable. However, every node is willing to respond favorably to a pairing request.
In the basic pairing method, each node asks some randomly chosen node if itwill pair
with it. While awaiting an answer, the querier rejects any queries from other nodes. If it
receives a rejection, it randomly selects another node and tries to pair again. If it receives
a query from its own intended partner, a pair is formed. After the formation of a pair, one
or more processes are migrated from the more heavily loaded node of the two nodes to the
other node in order to balance the loads on these two nodes. The processes to be migrated
are selected by comparing their expected time to complete on their current node with the
expected time to complete on its partner. Migration delay is included in this estimate. The
process with the best ratio of service time on the partner node to service time on the
current node is selected to be sent first. Decisions for migrating other processes are based
on theassumption that the first process has been received by the partner node and the load
of the partner node has been updated to reflect the presence of this process on it. The pair
is broken as soon as the process migration is over. During the time that a pair is in force,
both members of the pair reject other pairing queries. Some other variations of the pairing
mechanism can be found in [Bryant and Finkel 1981].
StateInformation Exchange Policies
We have seen that the dynamic policies require frequent exchange of state information
among the nodes of the system. In fact, a dynamic load-balancing algorithm faces a
transmission dilemma because of the two opposing impacts the transmission of a
message has on the overall performance of the system. On the one hand, the
transmission improves the ability of the algorithm to balance the load. On the other
hand, it raises the expected queuing time of messages because of the increase in theSec.7.4 • Load-Balancing Approach 365
utilization of the communication channel. Thus proper selection of the state information
exchange policy is essential. The proposed load-balancing algorithms use one of the
following policies for this purpose.
Periodic Broadcast. In this method each node broadcasts its state information
after the elapse of every tunits of time. Obviously this method is not good because it
generates heavy network traffic and also because there is a possibility of fruitless
messages (messages from those nodes whose state has not changed during the last tunits
of time) being broadcast. Furthermore, the scalability of this method is poor because the
number of messages generated for state information exchanges will be too large for
networks having many nodes.
Broadcast When State Changes. This method avoids the problem of fruitless
message exchanges of the periodic broadcast method by ensuring that a node broadcasts
its state information only when the state of the node changes. A node'sstate changes when
a process arrives at that node or when a process departs from that node. A process may
arrive at a node either from the external world or from some other node in the system. A
process departs from a node when either its execution is over or it is transferred to some
other node.
A further improvement in this method can be obtained by observing that it is not
necessary to report every small change in the state of a node'to all other nodes because a
node can participate in the load-balancing process only when it is either underloaded or
overloaded. Therefore in the refined method, a node broadcasts its state information only
when itsstate switches from the normal load region toeither the underloaded region or the
overloaded region. Obviously this refined method works only with the two-threshold
transfer policy.
On-Demand Exchange. A node needs to know about the state of other nodes
only when it is eitherunderloaded oroverloaded. Themethodofon-demand exchange of
state information is based on this observation. In this method a node broadcasts a
Statelnformationkequest message when its state switches from the normal load region to
either the underloaded region or the overloaded region. On receiving this message, other
nodes send their current state to the requesting node. Notice that this method also works
only with the two-threshold transfer policy.
Further reduction in the number of messages is possible in this method by
observing that the requesting node does not need the state information of all other
nodes. Rather, the state information of only those nodes is useful for the requesting
node, which can cooperate with it in the load-balancing process. That is, ifthe
requesting node is underloaded, only overloaded nodes can cooperate with it inthe
load-balancing process and vice versa. Therefore, in the improved on-demand exchange
policy, the status of the requesting node is included in the StatelnformationRequest
message. On receiving the Statelnformationkequest message, only those nodes reply
that can cooperate with the requesting node in the load-balancing process. Other nodes
do not send any reply.
Exchange byPolling. All the methods described above use the method of
broadcasting due to which their scalability ispoor.The polling mechanism overcomes this366 Chap.7 •Resource Management
limitation byavoiding the use ofbroadcast protocol. This method is based on the idea that
there is no need for a node to exchange its state information with all other nodes in the
system. Rather, when anode needs thecooperation of some other node for load balancing,
it can search for a suitable partner by randomly polling the other nodes one by one.
Therefore state information is exchanged only between the polling node and the polled
nodes. The polling process stops either when a suitable partner is found or a predefined
poll limit is reached.
Priority Assignment Policies
When process migration is supported by a distributed operating system, it becomes
necessary to devise a priority assignment rule for scheduling both local and remote
processes at aparticular node. One of the following priority assignment rules may be used
for this purpose:
1. Selfish. Local processes are given higher priority than remote processes.
2. Altruistic. Remote processes are given higher priority than local processes.
3. Intermediate. The priority of processes depends on the number of local processes
and the number of remote processes at the concerned node. If the number of local
processes is greater than or equal to the number of remote processes, local
processes are given higher priority than remote processes. Otherwise, remote
processes are given higher priority than local processes.
Lee and Towsley [1986] studied the effect of these three priority assignment policies
on the overall response time performance. The results of their study show the
following:
• The selfish priority assignment rule yields the worst response time performance of
the three policies. This is due to the extremely poor performance of remote
processes under this policy. However, it yields the best response time performance
for local processes. Consequently, this policy imposes a severe penalty for
processes that arrive at a busy node and is beneficial for processes arriving at a
lightly loaded node.
• The altruistic priority assignment rule achieves the best response time perform­
ance of the three policies. However, under this policy remote processes incur
lower delays than local processes, which is somewhat unrealistic in the sense that
local processes are theprincipal workload ateach node while remote processes are
secondary workload.
• Theperformance of the intermediate priority assignment rule falls between the
other two policies. Interestingly enough, the overall response time performance of
this policy is much closer to that of the altruistic policy. Under this policy, local
processes are treated better than remote processes for a wide range of system
utilizations.Sec.7.5 • Load-Sharing Approach 367
Migration- Limiting Policies
Another important policyto be used by a distributed operating systemthatsupports
processmigration is todecideabout the total numberoftimesaprocessshouldbeallowed
tomigrate. Oneofthefollowing twopoliciesmay be used for this purpose.
Uncontrolled. Inthis case, a remoteprocessarrivingat a node is treatedjustas
aprocessoriginating at the node. Therefore, underthis policy, a processmay bemigrated
anynumberof times. This policy has the unfortunate property ofcausinginstability.
Controlled. Toovercome theinstability problemoftheuncontrolled policy,most
systemstreatremoteprocesses different from local processes and use a migration count
parameter to fix a limit on the numberoftimes that a processmaymigrate. Severalsystem
designers feel thatprocessmigration is anexpensive operation andhenceaprocessshould
not beallowedtomigratetoo frequently. Hence this groupofdesigners normally favors
anirrevocable migration policy.Thatis, theupperlimitofthe value of migration countis
fixed toI,andhenceaprocesscannotbemigrated more than once underthis policy.
However, somesystemdesigners feel thatmultiple processmigrations, especially for long
processes, may be very useful for adapting to thedynamically changing statesofthe
nodes. Thus this groupofdesigners sets theupperlimitofthe value of migration count
to some value k>1. The value of kmay bedecidedeitherstatically ordynamically. Its
value may also be different forprocesses havingdifferent characteristics. Forexample, a
longprocess(aprocesswhoseexecution time is large) may be allowedtomigratemore
times as compared to a short process.
7.5lOAD-SHARING APPROACH
Severalresearchers believethat load balancing, with its implication ofattempting to
equalize workload on all the nodes of the system,is not an appropriate objective. Thisis
becausetheoverhead involved ingathering stateinformation toachievethisobjective is
normally very large, especially indistributed systems havinga largenumberofnodes.
Moreover, loadbalancing in thestrictestsense is not achievable becausethenumberof
processes in anodeisalwaysfluctuating and thetemporal unbalance amongthe nodes
existsat everymoment, evenif the static (average) load isperfectly balanced [Livny and
Melman 1982]. In fact, for the properutilization of theresources of adistributed system,
it is notrequired tobalancethe load on all the nodes. Rather, it is necessary andsufficient
toprevent the nodes from being idle while some othernodeshave more than two
processes. Therefore thisrectification isoftencalleddynamic load sharinginsteadof
dynamic load balancing.
7.5.1IssuesinDesigning load-Sharing Algorithms
Similarto theload-balancing algorithms, thedesignof aload-sharing algorithm also
requires thatproperdecisions be made regarding loadestimation policy,processtransfer
policy, state information exchange policy,locationpolicy,priorityassignment policy, and368 Chap.7 •ResourceManagement
migration limiting policy.However, as compared to load balancing, it is simpler to decide
about most of these policies in the case of load sharing. This is because, unlike load­
balancing algorithms, load-sharing algorithms do not attempt to balance the average
workload on all the nodes of the system. Rather,they only attempt to ensure that no node
is idle when a node is heavily loaded. The priority assignment policies and the migration
limiting policies for load-sharing algorithms are the same as that for the load-balancing
algorithms. Hence their description will not berepeated again. Other policies for load
sharing are described below.
LoadEstimation Policies
Since load-sharing algorithms simply attempt to ensure that no node is idle while
processes wait for service at some other node, it is sufficient to know whether a node is
busy or idle. Thus load-sharing algorithms normally employ the simplest load estimation
policy of counting the total number of processes on a node.
Once again the simple load estimation policy of counting the total number of
processes on a node is not suitable for use in modern distributed systems because of the
permanent existence of several processes on an idle node. Therefore, measuring CPU
utilization should be used as a method of load estimation in these systems.
ProcessTransfer Policies
Since load-sharing algorithms are normally interested only in the busy or idle states of a
node, most of them employ the all-or-nothing strategy. This strategy uses the single­
threshold policy with the threshold value of all the nodes fixed at 1. That is, a node
becomes a candidate for accepting a remote process only when it has no process, and a
node becomes a candidate for transferring a process as soon as it has more than one
process. Krueger and Livny [1987]pointed out that the all-or-nothing strategy is not good
in the sense that a node that becomes idle is unable to immediately acquire new processes
to execute even though processes wait for service at other nodes, resulting in a loss of
available processing power in the system. They suggested that, to avoid this loss,
anticipatory transfers to nodes that are not idle but are expected to soon become idle are
necessary. Thus to take care of this loss, some load-sharing algorithms use a threshold
value of 2 instead of 1.
Notice here that if the measure of CPU utilization is used as the load estimation
policy,the high-low policy (asdiscussed forload balancing) should be used as theprocess
transfer policy.
Location Policies
In load-sharing algorithms, the location policy decides the sender node or the receiver
node of a process that is to be moved within the system for load sharing. Depending on
the type of node that takes the initiative to globally search for a suitable node for the
process, the location policies are of the following types:Sec.7.5 • Load-Sharing Approach 369
•Sender-initiated policy,in which the sendernodeoftheprocessdecideswhere to
send the process
•Receiver-initiated policy,in which the receivernode of the processdecidesfrom
where to get the process
Each of these policies are described below along with their relative merits and
demerits.
Sender-Initiated Location Policy. Inthesender-initiated locationpolicy,heavily
loaded nodes search for lightly loaded nodes to which work may be transferred. That is, in
this method, when a node'sload becomes more than the threshold value, iteitherbroadcasts
amessage orrandomly probes the other nodes one by one to find a lightly loaded node that
can accept one or more of its processes. Anode isaviable candidate forreceiving a process
from the sendernode only if the transfer of the process to that node would not increase the
receivernode'sload above its threshold value. In the broadcast method, the presence or
absenceof a suitable receivernode is known as soon as the sender node receives reply
messages from the other nodes. On the other hand, in the random probing method, the
probingcontinues untileithera suitable receivernode is found or the numberof probes
reaches astatic probe limit, as Lp.Ifasuitable receivernode isnot found, the nodeon which
the process originated mustexecutethat process. The method of probing with a fixed limit
has better scalability than thebroadcast methodbecauseitensuresthat thecost of executing
theload-sharing policy will not be prohibitive even in large networks. Eager et a1.[1986a]
found through their analysis thatthe performance ofthispolicy is insensitive tothechoiceof
probe limit: the performance with a small probe limit (e.g., 3 or 5) is nearly as good as the
performance with a large probe limit (e.g., 20).
Receiver-Initiated Location Policy. In thereceiver-initiated location policy,
lightly loaded nodes search for heavily loaded nodes from which work may be transferred.
Thatis, in this method, when anode'sload falls belowthethreshold value, it either
broadcasts amessage indicating its willingness to receive processes forexecuting or
randomly probes the other nodes one by one to find a heavily loaded node that can send
one or more of its processes. A node is a viable candidate for sending one of its processes
only if the transferof the process from that node would not reduce its load below the
threshold value. In the broadcast method, a suitable node is found as soon as the receiver
node receives reply messages from the other nodes. On the other hand, in the random
probingmethod, the probingcontinues untileithera node is found from which a process
can beobtained or the number ofprobes reaches a static probe limit, Lp•In the latter case,
the node waits for a fixed timeout period before attempting again to initiate a transfer.
It may be noted here that, in sender-initiated algorithms, scheduling decisions are usually
made at processarrival epochs (or a subset thereot), whereas in receiver..initiated
algorithms, scheduling decisions are usually made at processdeparture epochs (or a subset
thereof). Owing to this, receiver-initiated policiestypically require the preemptive transfer
ofprocesses whilesender-initiated policies can work even with those systems that do not
supportpreemptive processmigration facility.Apreemptive process migration facility
allows the transferof anexecuting process from one node to another. On the otherhand,370 Chap.7 •Resource Management
in systems supporting only non-preemptive processmigration facility, a process can only
betransferred prior to beginning its execution. Preemptive process migration is costlier
thannon-preemptive process migration since theprocess state, which must accompany the
process to its new node, becomes.much more complex after execution begins. Receiver­
initiated process transfers are mostly preemptive since it is unlikely that a receiver node
would open negotiation with a potential sender at the moment that a new process arrived
at the sender node. Process transfers that are sender initiated, however, may beeither non­
preemptive or preemptive, depending on which process the sender chooses to transfer.
Eager et al. [1986a] used simple analytical models forcomparing the performance of
the two policies relative to each other and to that of a system in which there is no load
sharing. Their results, which are valid over a wide range of system parameters, show the
following [Eager et al. 1986a]:
• Both sender-initiated and receiver-initiated policies offer substantial performance
advantages over the situation in which no load sharing is attempted.
•Sender-initiated policies are preferable to receiver-initiated policies at light to
moderate system loads. This is because in a lightly loaded system the receiver­
initiated policy generates a large number of probe messages because all the free
nodes desperately hunt for work.
•Receiver-initiated policies are preferable at high system loads, but only ifthe costs
of process transfer under the two strategies are comparable. This is because the
receiver-initiated policy does not put extra load on the system at critical times
(when the system is heavily loaded), but the sender-initiated policy generates a
large number of probe messages precisely when the system is heavily loaded and
can least tolerate extra load generated by probe messages.
• If the cost of process transfer under receiver-initiated policies is significantly
greater than under the sender-initiated policies due to the preemptive transfer of
processes, sender-initiated policies provide uniformly better performance.
StateInformation Exchange Policies
Sinceload-sharing algorithms do not aim at equalizing the average load on all the nodes,
it is not necessary for the nodes to periodically exchange the state information with each
other. Rather, a node needs to know the state of other nodes only when it is either
underloaded or overloaded. Therefore, in load-sharing algorithms, a node normally
exchanges state information with other nodes only when its state changes. The two
commonly used policies for this purpose are described below.
Broadcast When State Changes. In this method, a node broadcasts a
StatelnformationRequest message when it becomes either underloaded or overloaded.
Obviously, in the sender-initiated policy, a node broadcasts this message only when it
becomes overloaded, and in thereceiver-initiated policy, this message is broadcast by a
node when it becomes underloaded. Inreceiver-initiated policies that use afixed threshold
valueof1,this method of state information exchange is called broadcast-when-idle
policy.Sec.7.6 • Summary 371
Poll When State Changes. Since amechanism that uses broadcast protocol is
unsuitable for large networks, the polling mechanism is normally used in such systems.
In this method, when a node'sstatechanges, it does not exchange stateinformation
with all other nodes but randomly polls the other nodes one by one and exchanges state
information with the polled nodes. The state exchange processstopseitherwhen a
suitablenode for sharingload with the probing node has been found or the numberof
probeshasreachedthe probe limit. Obviously, in sender-initiated policy,pollingis done
by a node when it becomes overloaded, and inreceiver-initiated policy,pollingis done
by a node when it becomes underloaded. In receiver-initiated policies that use a fixed
threshold valueof1, this method of state information exchange is called poll-when-idle
policy.
7.6SUMMARY
Aresource manager of adistributed operating systemschedules theprocesses in a
distributed system to any one or more or a pool of free resources that can optimize a
combination ofresource usage, response time, network congestion, andscheduling
overhead. Theprocessscheduling decisions are based on such factors as the resource
requirements of theprocesses, theavailability ofthe various resources on different nodes
of the system, and the static and/or dynamic state information of the various nodes of the
system. A good global scheduling algorithm should possess features such as having no a
prioriknowledge about the processes, beingdynamic in nature, and having quick
decision-making capability, balanced systemperformance andscheduling efficiency,
stability, scalability, fault tolerance, and fairness of service. The three different approaches
used for the design ofglobalscheduling algorithms are the task assignment approach, the
load-balancing approach, and theload-sharing approach.
In the task assignment approach, the process assignment decisions arebasically
based on a priori knowledge of thecharacteristics of both the processes to be executed and
the system. The basic task assignrnent model deals with the assignment of tasks to the
various nodes of the system in such a manner so as to minimize interprocess
communication costs and improve the turnaround time for the complete task force. Some
extensions to the basic task assignment model also consider factors such as interference
costs,precedence relationships, or memory size constraints. The task assignment approach
haslimitedapplicability becauseitworks on the assumption that thecharacteristics of all
theprocesses to bescheduled are known in advance and also because task assignment
algorithms are generally not dynamic in nature.
In theload-balancing approach, the process assignment decisions attempt to equalize
theaverageworkload on all the nodes ofthe system. The basic problem associated with
thedynamic load-balancing algorithms is to decide about the amount of global state
information to be used. Although only limited success has been achieved in thisdirection,
the results of the efforts made have shown that attempting to gather a large amount of
information todescribe thecurrentglobal state of the system more accurately is not
alwaysbeneficial. Hence, the degree of global knowledge in analgorithm must be, in372 Chap.7 • Resource Management
some way, normalized to the complexity of the performance objective of the algorithm.
This relationship and normalization are the subject of current research.
Finally, in the load-sharing approach, the process assignment decisions attempt to
keep all the nodes busy if there are sufficient processes in the system for all the nodes.
This is achieved by ensuring that no node is idle while processes wait to be processed at
other nodes. Since load-sharing algorithms do not attempt to balance the load on all the
nodes, they are simpler and easier .to implement as compared to load-balancing
algorithms. "However, for the various global scheduling algorithms, there is no absolute
answer to the question, "Isalgorithm Abetter than B?"Therefore, getting a better
understanding of the processes involved in global scheduling has to be the aim of study
of this type of algorithms.
EXERCISES
7.1.For global scheduling algorithms, whyareheuristicmethodsproviding near-optimal results
normallypreferableto optimalsolutionmethods?
7.2.Whatis "processorthrashing"?Giveexamplesoftwoglobalschedulingalgorithmsthatmay
lead to processor thrashing. Suggestnecessary measures to be taken to handle this
problem.
7.3.Supposeyouhavetodesignascheduling algorithm basedonthetaskassignmentapproachfor
schedulingthetasksof processesto beprocessedina distributed system.Whattypesof cost
informationwouldyouliketo haveforthetasksof a process?Suggestmethodsthat maybe
used to makea roughestimateof thesecosts.
7.4.A systemconsistsof threeprocessors PI'P2'and"P3'anda processhavingfour tasks 11, 12,
t3'andt4is to be executedon this system.Suppose Eijis the cost of executing task t,on
processor PjandCijisthecommunication costbetweentasks t,andtjwhenthetwotasksare
assigned to different processors. LetEll=31,EI2=4,En=14,E21=I,E22=5,£23=6,
E31=2,E32=4,£33=24, E41=3,E42= 28,E43=10,CI2= 35,C13= 3,CI4=8,C23= 6 ,
C24=4,andC34=23.Findanoptimal assignment ofthetaskstotheprocessorsandcalculate
thecost of optimal assignment. Nowcomparethiscostwiththeassignmentcostof thecase
in which tIandt2are assignedto PI'13is assignedto P2'andt4is assignedto P3.
7.5.Asystemconsistsoftwoprocessors PIandP2'andaprocesshavingsixtasks 1),t2,13,14,ts,
and16istobeexecutedonthissystem.Suppose Eijisthecostofexecutingtask Iionprocessor
Pj'Cijis thecommunication cost betweentasks Iiandtjwhenthe two tasksare assignedto
differentprocessors,and lijistheinterference costbetweentasks t,andtjwhenthetwotasks
are assigned to the same processor. Interference costs reflect the degree of incompatibility
betweentwo tasks and are incurredwhenthe two tasks are assignedto the same node [Lo
1988].Let Ell=20, £12=50, E 21=25,E22=10,£31=5, £32=20, £41=10,E42=20,Est=10,
£52=20, £61=50,£62=10,C12=15,C23=50,C34=15,C4s=50,andCS6=15.Thevaluesof
allotherCijarezero.Furthermore, theinterference costbetweenanypairof tasksis 10(i.e.,
Iij=10ifiis notequal to j).Findthe assignmentcosts forthe following cases:
(a) Task IIisassignedto PIandallothertasksareassignedto P2,andinterference costisnot
takeninto account.
(b) Task sets {lit12,13}and{/4'Is,t6}are assigned to PIandP2,respectively, and
interferencecost is not takenintoaccount.
(c) Task 11is assignedto p)and all other tasksare assignedto P2'andinterference cost is
takenintoaccount.Chap. 7 • Exercises 373
(d) Task sets {titt2,13}and{t4,'5' '6} are assigned to PIandP2'respectively, and
intetference cost is taken into account.
What conclusion can be drawn from the assignment costs of these four cases?
7.6. Acomputer system has three processors PI'P2'andP3'Itis to be used to process the same
type of processes, all of which have six tasks tit12,13,14,ts, and16'Assumethatthearrival
rate of processes is a deterministic process. Also assume that every task's execution time is
exponentially distributed with the mean execution time of tasks t.,12,13,14,15'and16being
1, 10, 1, 10, 1,and 10,respectively.There isa strong precedence relationship among the tasks
of a process, and task ljof a process can be executed only when the execution of task t;(i<
j)of the same process has been completed. Which one of the following assignments will yield
the best response times and which one will yield the worst response times for the processes
executed on this system:
(a) Task pairs (t),(2),(t3'(4),and (ts, 16)are assigned to processors PI'P2'andP3'
respectively.
(b) Task pairs (I),(6),(12,13),and(t4't5)are assigned to processors PI'P2'andP3'
respectively.
(c) Task pairs (t1,t4),(12, 15),and(13, (6)are assigned to processors PI'P2'andP3'
respectively.
Give reasons for your answer.
7.7. A system has two processors PIandP2withp)having limited memory capacity and P2having
unlimited memory. A process having multiple tasks is to be executed on this system. The
execution costs for each task on each processor, the intertask communication costs, the
memory requirement of each task, and the total memory capacity of processor PIis given.
SupposeaJis the assignment that minimizes the total execution and communication costs
without the memory size constraint, and a2is the assignment that minimizes the total
execution and communication costs with the memory size constraint. Prove that the tasks
assigned to PIfor assignment a2is a subset of the tasks assigned to PIfor assignment at.
7.8.Comment on the practical applicability of the task assignment approach as a scheduling
scheme for distributed systems.
7.9.Comment on the practical applicability of the load-balancing approach as a scheduling
scheme for the following types of distributed systems:
(a) A LAN-based distributed system
(b) A WAN-based distributed system
(c) A distributed system based on the processor-pool model
(d)A distributed system based on the workstation-server model
7.10. A distributed operating system designer isof theopinion that state information inadistributed
system is typically gathered at a high cost. Therefore, for a distributed system based on the
processor-pool model, heor shedecides to use a load-balancing policy that uses the following
simple process placement rule: Execute allprocesses originatingfrom terminal ionprocessor
j(j«i).The value ofjisdefinedfor all values ofi,and for several values ofi,the valueof
jmay be the same.
In your opinion, is the designer's choice of the scheduling algorithm appropriate for this
system? Give reasons for youranswer.What drawbacks, ifany,does this scheduling algorithm
have? If you feel that this algorithm is not appropriate for this system, suggest a suitable
global scheduling algorithm for this system.
7.11.Suppose you have to design a centralized load-balancing algorithm for global scheduling of
processes in adistributed system. What issues must you handle? Suggest asuitable method for
handling each of the issues mentioned by you.374 Chap. 7 • Resource Management
7.12. Suppose you have todesign a load-balancing algorithm for adistributed system. Which of the
selfish, altruistic, and intermediate priority assignment policies willyou use in your algorithm
if the distributed system is based on the following:
(a) Workstation-server model
(b) Processor-pool model
Give reasons for your answer.
7.13. Suppose you have decided to use the high-low policy as the process transfer policy of a Joad­
balancing algorithm for a distributed system. Suggest a suitable method that you will use in
yourimplementation for choosing the high-mark and low-mark values. Do these threshold
values have to be the same for all processors in the system? Give reasons for your answer.
7.14. Load balancing in the strictest sense is not achievable in distributed systems. Discuss.
7.15. What are the main differences between the load-balancing and load-sharing approaches for
process scheduling in distributed systems? Which of the various policies to beused in the
implementation of the two approaches are different and which of them are same?
7.16. Suppose you have todesign a load-sharing algorithm for a distributed system. Will you prefer
to use a sender-initiated or a receiver-initiated location policy in your algorithm? Give reasons
for your answer.
7.17.Suggest some policies that may beused for load estimation in load-balancing algorithms.
Discuss the relative advantages and disadvantages of the policies suggested by you. Which
one of the policies suggested by you can also beused for load-sharing aJgorithms? If none,
suggest a suitable load estimation policy for a load-sharing algorithm.
7.18. A system has two processors PIandP2.Suppose at a particular instance of time, PIhas one
process with remaining service time of 200 seconds and P2has100processes each with a
remaining service time of 1second. Now suppose a new process enters the system. Calculate
the response time of the new process if:
(a) The new process is a )-second process and it is allocated to PIfor execution.
(b) The new process is a )-second process and it is allocated to P2for execution.
(c) The new process isa 200-second process and it is allocated to PIfor execution.
(d) The new process is a 200-second process and it is allocated to P2for execution
Assumethat there are noother new arrivals inthe system. From the obtained results, what can
you conclude about load estimation policies to be used in load-balancing algorithms?
7.19.Adistributed system does not support preemptive process migration facility. Youare todesign
a load-sharing algorithm for scheduling of processes in this system. Will you use a sender­
initiated or a receiver-initiated location policy for your algorithm? Give reasons for your
answer.
7.20. Adistributed system uses the all-or-nothing strategy as the process transferpolicy for its load­
sharing algorithm. Explain why the processing capabilities of the processors of this system
may notbeproperly utilized. Suggest a suitable method to overcome this problem.
7.21.What research issues do you think need further attention in the area of global scheduling of
processes in distributed systems?
BIBliOGRAPHY
[AhrensandHansen1995]Ahrens, J. P,and Hansen, C. D., "Cost-Effective Data-Parallel Load
Balancing," In:Proceedings ofthe24thAnnual International Conference onParallel Processing,
eRePress, Boca Raton, FL (August )995).Chap.7 •Bibliography 375
[Alonso and Cova 1988] Alonso,R., andCova,L. L.,"Sharing JobsAmongIndependently Owned
Processors," In:Proceedings ofthe 8thInternational Conference on Distributed Computing
Systems,IEEE,New York, pp. 282-288 (June1988).
[AroraandRana1980]Arora,R. K., and Rana, S.P.,"Heuristic Algorithms forProcess
Assignment inDistributed Computing Systems," Information Processing Letters,Vol.11,No.
4/5, pp.199-203 (1980).
[Atallahet al, 1992] Atallah,M.1.,Black,D.C.,Marinescu, D.C.,Seigel,H.1., andCasavant, T.
L.,"Models andAlgorithms forCo-scheduling Compute-Intensive TasksonaNetwork of
Workstations," JournalofParallel and Distributed Computing, Vol.16,pp.319-327 (1992).
[BarakandShiloh 1985] Barak,A.,andShiloh,A.,"ADistributed LoadBalancing Policyfora
Multicomputer," Software--Practice andExperience, Vol. 15,No.9,pp.901-913 (1985).
[Bokhari 1979]Bokhari, S. H.,"DualProcessor Scheduling withDynamic Reassignment," IEEE
Transactions on Software Engineering, Vol.SE-5,No.4,pp.341-349 (1979).
[Bokhari 1981a]Bokhari, S. H.,"OntheMapping Problem," IEEE Transactions on Computers,
Vol.C-30,No.3,pp.207--214 (]98!).
[Bokhari 1981b]Bokhari, S.H.,"AShortest TreeAlgorithm forOptimal Assignments Across
Spaceand Time in aDistributed Processor System," IEEE Transactions on Software Engineering,
Vol.SE-7,No.6,pp.583-589 (]981).
[Bonomi and Kumar1990]Bonomi,F.,andKumar,A.,"Adaptive Optimal LoadBalancing in a
Heterogeneous Multiserver System with aCentral JobScheduler," IEEE Transactions on
Computers, Vol.C-39,pp.1232-1250 (1990).
[Bryantand Finkel 1981] Bryant,R.M.,andFinkel,R. A., "A StableDistributed Scheduling
Algorithm," In:Proceedings ofthe 2nd International Conference onDistributed Computing
Systems, IEEE,New York, pp. 314-323 (April1981).
[Casavant andKuhl1986JCasavant, T. L.,and Kuhl, 1. G.,"AFormalModelofDistributed
Decision Makingand ItsApplication toDistributed LoadBalancing," In:Proceedings ofthe 6th
International Conference onDistributed Computing Systems, IEEE,New York, pp. 232-239
(May1986).
[Casavant andKuhl1988a)Casavant, T. L., and Kuhl, J.G.,"ATaxonomy ofScheduling in
General Purpose Distributed Computing System," IEEE Transactions on Software Engineering,
Vol.SE-14,No.2,pp.141-]54 (1988).
[Casavant andKuhl1988b}Casavant, T.L., and Kuhl, J.G.,"EffectsofResponse andStability
onScheduling inDistributed Computing Systems," IEEE Transactions on Software Engineering,
Vol.SE-14,No. 11, pp. 1578-1587 (1988).
[ChangandOldham 1995)Chang,H. W.D., andOldham, W.1. B.,"Dynamic TaskAllocation
Models forLargeDistributed Computing Systems," IEEE Transactions on Parallel and
Distributed Systems, Vol. 6, No. 12, pp. 1301-1315 (J995).
[ChouandAbraham 1982]Chou,T. C. K., and Abraham, 1. A.,"LoadBalancing inDistributed
Systems," IEEETransactions on Software Engineering, Vol.SE-8,No.4,pp.401-412 (1982).
[ChouandAbraham 1983]Chou,T. C. K., and Abraham, 1.A.,"LoadDistribution UnderFailure
inDistributed Systems," IEEETransactions onComputers, Vol.C-32,No.9,pp.799-808
(1983).
lChuet al, 1980] Chu,W.,Holloway, L. J., Lan, M. T., and Efe, K., "Task Allocation inDistributed
DataProcessing," IEEE Computer, Vol.13,pp.57-69(1980).376 Chap. 7 • Resource Management
[ehuand Lan 1987] Chu, W.W.•and Lan, L. M-T.•"Task Allocation andPrecedence Relations for
Distributed Real-Time Systems:' IEEETransactions on Computers. Vol. C-36. No.6.pp.
667-679 (1987).
[Clarkand McMillin 1992J Clark.H.•andMcMillin. B.,"DAWGS-A Distributed Compute
ServerUtilizing IdleWorkstations," JournalofParallelandDistributed Computing. pp.175-186
(February 1992).
[Dandamudi 1995]Dandamudi, S.,"Performance ImpactofScheduling Discipline onAdaptive
LoadSharinginHomogeneous Distributed Systems," In:Proceedings oftheJ5thInternational
Conference onDistributed Computing SystemsIEEE. New York (1995).
[Eageret al.19868]Eager, D. L., Lazowska, E. D., and Zahorjan, J., "AComparison ofReceiver­
Initiated andSender-Initiated Adaptive LoadSharing:' Performance Evaluation, Vol. 6, pp.
53-68(1986).
[Eageretal.1986b]Eager. D. L., Lazowska, E.D., andZahorjan, 1.,"Adaptive LoadSharingin
Homogeneous Distributed Systems," IEEETransactions on Software Engineering, Vol.SE-12.
No.5,pp.662-675 (1986).
[Ere1982]Efe,K.,"Heuristic Modelsof TaskAssignment Scheduling inDistributed Systems,"
IEEEComputer, Vol. 15., pp. 50-56(1982).
[Ereand Groselj 1989]Efe, K., and Groselj,B.,"Minimizing ControlOverheads inAdaptive Load
Sharing," In:Proceedings ofthe 9thInternational Conference on Distributed Computing Systems,
IEEE. New York, pp. 307-3]5 (June 1989).
[EreandKrishnamoorthy 1995] Efe, K., and Krishnamoorthy, V.,"Optimal Scheduling of
Compute-Intensive Tasks on a Network ofWorkstations," IEEETransactions onParallel and
Distributed Systems, Vol. 6,No.6,pp.668-673 (1995).
[EreandSchaar1993JEfe,K., and Schaar, M., "Performance ofCo-scheduling on aNetwork of
Workstations," In:Proceedings ofthe 13th International Conference onDistributed Computing
Systems, IEEE, New York, pp. 525-53] (J993).
[EI·Rewini et al,1994]EI-Rewini, H.,Lewis, T., and Ali,H.,TaskScheduling inParallel and
Distributed Systems, Prentice-Hall, Englewood Cliffs,NJ(1994).
[EI-Rewiniet ale1995]El-Rewini, H.,Lewis, T., and Ali, H., "Task Scheduling inMultiprocessing
Systems," IEEEComputer, Vol. 28, No. ]2, pp. 27-37(December J995).
[Ferguson et al, 1988] Ferguson, D.,Yemini, Y.,and Nikolaou, C.,"Microeconomic Algorithms for
LoadBalancing inDistributed Computer Systems," In:Proceedings ofthe 8thInternational
Conference onDistributed Computing Systems,IEEE,New York, pp. 491-499 (1988).
[Gao et al. 1984]Gao, C., Liu, 1. W. S., and Railey, M., "LoadBalancing Algorithms in
Homogeneous Distributed Systems," In: Proceedings ofthe1984International Conference on
Parallel Processing, CRCPress, Boca Raton, FL,pp.302-306 (August 1984).
[Hagman 1986]Hagman, R.,"Process Server:Sharing Processing Powerin a Workstation
Environment," In:Proceedings ofthe 6thInternational Conference onDistributed Computing
Systems, IEEE, New York, pp. 260-267 (1986).
[Heirichand Taylor 1995] Heirich,A.,and Taylor, S.,"AParabolic LoadBalancing Method," In:
Proceedings ofthe 24th AnnualInternational Conference onParallel Processing, CRC Press,
BocaRaton, FL (August 1995).
[UsuandLiu 1986] Hsu, C. H., and Liu, 1. W. S., "Dynamic LoadBalancing Algorithm in
Homogeneous Distributed Systems," In:Proceedings ofthe 6thInternational Conference on
Distributed Computing Systems, IEEE, New York, pp. 216-222 (May 1986).Chap. 7 • Bibliography 377
[Hwanget al, 1982] Hwang, K., Croft, W. J., Goble, G.H., Wah, B. W., Briggs, F.A.,Simmons,
W.R.,and Coates, C. L., "A UNIX-Based LocalComputer Network with Load Balancing," IEEE
Computer, Vol.15,pp.55-66(April1982).
[Kleinrock andKorfhage 1989]Kleinrock, L.,and Korfhage, W.,"Collecting UnusedProcessing
Capacity: AnAnalysis ofTransient Distributed System," In:Proceedings ofthe 9th International
Conference on Distributed Computing Systems, IEEE, New York, pp. 482-489 (June 1989).
[Krueger andChawla1991]Krueger, P.,andChawla,R.,"TheStealthDistributed Scheduler," In:
Proceedings ofthe 11thIntemational Conference on Distributed Computing Systems, IEEE,New
York, pp. 336-343 (1991).
[Krueger andLivny1987] Krueger, P., and Livny, M., "The DiverseObjectives ofDistributed
Scheduling Policies," In: Proceedings ofthe 7th International Conference on Distributed
Computing Systems, IEEE, New York, pp. 242-249 (September 1987).
[Kunz1991] Kunz, T.,"TheInfluence ofDifferent Workload Descriptions on aHeuristic Load
Balancing Scheme," IEEE Transactions on Software Engineering, Vol.SE-17,No.7,pp.
725-730 (1991).
[LeeandTowsley 1986] Lee, K.1., and Towsley, D.,"AComparison ofPriority-Based
Decentralized LoadBalancing Policies," In:Proceedings ofthe 10th Symposium on Operating
System Principles, Association forComputing Machinery, New York, NY,pp.70-77(November
1986).
[LinandRaghavendra 1992] Lin, H. C., and Raghavendra, C. S., "A Dynamic Load-Balancing
Policy with a CentralJobDispatcher (LBC),"IEEE Transactions on Software Engineering, Vol.
18,No.2,pp.148-158 (1992).
[Litzkow et at.1988] Litzkow, M. 1.,Livny,M., andMukta,M. W.,"Condor-A Hunter of Idle
Workstations," In:Proceedings ofthe 8thInternational Conference on Distributed Computing
Systems, IEEE, New York, pp. 104-1]1(June1988).
[LivnyandMelman 1982]Livny, M., and Melman, M.,"LoadBalancing inHomogeneous
Broadcast Distributed Systems," In:Proceedings ofthe ACM Computer Network Performance
Symposium, pp.47-55(April 1982).
[Lo 1988] Lo, V. M., "Heuristic Algorithms for Task Assignment inDistributed Systems," IEEE
Transactions on Computers, Vol.37,No. II,pp.1384-1397 (1988).
[Malone etal,1988] Malone, T.W.,Fikes,R. E.,Grant,K. R.,and Howard, M.T.,"Enterprise: A
Market-like TaskScheduler forDistributed Computing Environments," The Ecology of
Computation, Huberman, B. A., Ed., North-Holland, Amsterdam, pp.177-205 (1988).
[MehraandWah1995a]Mehra, P., and Wah, B., "Synthetic Workload Generation for Load­
Balancing Experiments," IEEE Parallel and Distributed Technology,Systems and Applications,
pp.4-19(Fall1995).
[Mebraand Wah 1995b]Mehra,P.,and Wah, B.,Load Balancing: An Automated Learning
Approach, WorldScientific, River Edge, NJ(1995).
[Milojcic 1994]Milojcic, D.S.,Load Distribution, Implementation for the Mach Microkemel,
Verlag Vieweg, Wiesbaden (1994).
[Mirchandaney et al,1989a]Mirchandaney, R.,Towsley, D., and Stankovic, J.A.,"Adaptive Load
Sharing in Heterogeneous Systems," In:Proceedings ofthe 9th International Conference on
Distributed Computing Systems, IEEE,NewYork,NY,pp.298-306 (June 1989).
[Mircbandaney et al.1989b]Mirchandaney, R., Towsley, D., andStankovic, 1.A.,"Analysis of the
Effects of Delays on Load Sharing," IEEE Transactions on Computers, Vol. 38, pp. 1513-1525
(1989).378 Chap. 7 • Resource Management
[Mukta and Livny 1987]Mukta,M. W., and Livny, M., "Scheduling RemoteProcessing Capacity
inaWorkstation-Processor BankComputing Systems," In:Proceedings ofthe 7th International
Conference on Distributed Computing Systems, IEEE,New York, NY, pp. 2-9(September
1987).
[Niand Hwang 1985]Ni,L.M., andHwang,K.,"Optimal LoadBalancing inaMultiple Processor
SystemwithManyJobClasses," IEEE Transactions on Software Engineering, Vol.SE-Il,No.
5, pp.491-496 (1985).
[Niet al. 1985J Ni, L. M., Xu, C. W., and Gendreau, T. B., "A Distributed Drafting Algorithm for
LoadBalancing," IEEE Transactions on Software Engineering, Vol.SE-ll,No. 10, pp.
1153-1161 (1985).
[Nichols 1987]Nichols,D.A.,"UsingIdleWorkstations in aSharedComputing Environment," In:
Proceedings ofthe IIth Symposium on Operating System Principles, Association forComputing
Machinery, New York, NY, pp. 5-12,(November 1987).
[Pulidas etal, 1988]Pulidas,S.,Towsley, D., and Stankovic, 1.A.,"Imbedding Gradient Estimators
inLoadBalancing Algorithms," In:Proceedings ofthe 8th International Conference on
Distributed Computing Systems, IEEE, New York, NY, pp. 482-490 (1988).
[Rao et al, 1979]Rao,G.S.,Stone,H.S., andHu, T.C.,"Assignment of TasksinaDistributed
Processor SystemwithLimited Memory," IEEE Transactions on Computers, Vol.C-28,No.4,
pp.291-299 (1979).
[Shenand Tsai 1985]Shen,C. C., and Tsai, W. H., "A GraphMatching Approach toOptimal Task
Assignment inDistributed Computing Systems withMinimax Criterion," IEEE Transactions on
Computers, Vol. C-34, pp. 197-203 (1985).
[Shirazi et al, 1995]Shirazi,B.A.,Hurson,A. R., and Kavi,K.M.(Eds.),Scheduling and Load
Balancing in Parallel and Distributed Systems, IEEEComputer SocietyPress, Los Alamitos, CA
(1995).
[Shivaratri andKrueger 1990]Shivaratri, N.G.,and Krueger, P.,"TwoAdaptive Location Policies
forGlobalScheduling Algorithms," In:Proceedings ofthe 10th International Conference on
Distributed Computing Systems, IEEE,New York, NY, pp. 502-509 (1990).
[Shivaratri et al, 1992] Shivaratri, N. G.,Krueger, P.,andSinghal,M.,"LoadDistributing for
LocallyDistributed Systems," IEEE Computer, Vol. 25, No. 12, pp. 33-44(1992).
[Singhaland Shivaratri 1994]Singhal, M., andShivaratri, N. G.,Advanced Concepts in Operating
Systems, McGraw-Hili, New York (1994).
[Smirni et al. 1995]Smirni,E., Rosti, E., and Serrazi,G.,"Performance GainsfromLeaving Idle
Processors inMultiprocessor Systems;' In:Proceedings ofthe 24th AnnualInternational
Conference on Parallel Processing, CRCPress,BocaRaton,FL(August 1995).
[Smith1980]Smith,R. G.,"TheContract NetProtocol: High-Level Communication andControl
.in aDistributed Problem-Solver," IEEE· Transactions on Computers, Vol.C-29,No. 12, pp.
1104-1113 (1980).
[Srinivasan and Jha1995]Srinivasan, S.,and Jha, N. K., "TaskAllocation forSafetyand
Reliability inDistributed Systems," In:Proceedings ofthe 24thAnnualInternational Conference
on Parallel Processing, CRePress,BocaRaton,FL(August 1995).
[Stankovic 1984JStankovic, J.A.,"Simulation ofThreeAdaptive, Decentralized Controlled, Job
Scheduling Algorithms," Computer Networks, Vol. 8,No.3,pp.]99-217 (1984).
[Stankovic 1985]Stankovic, 1.A.,"Stability andDistributed Scheduling Algorithms," IEEE
Transactions on Software Engineering, Vol.SE-l1,No. 10, pp. 1141-1152 (1985).Chap.7 •Bibliography 379
[Stankovic andSidhu1984)Stankovic, 1.A., and Sidhu,I. S.,"AnAdaptive BiddingAlgorithm for
Processes, Clusters andDistributed Groups," In:Proceedingsofthe4thInternationalConference
on Distributed Computing Systems, IEEE,New York, NY, pp. 49-59(May(984).
[Stone1977]Stone,ItS.,"Multiprocessor Scheduling with the Aid of Network FlowAlgorithms,"
IEEE Transactionson Software Engineering, Vol.SE-3,No.1,pp.85-93(1977).
[Stone1978]Stone,H. S.,"Critical LoadFactorsinTwo-Processor Distributed Systems," IEEE
Transactions on Software Engineering, Vol.SE-4,No.3,pp.254-258 (1978).
[Stumm 1988]Stumm,M.,"TheDesignandImplementation ofaDecentralized Scheduling Facility
for aWorkstation Cluster," In:Proceedings ofthe 2nd IEEE Conference on Computer
Workstations, IEEE,New York, NY,pp.12-22(March1988).
[Svensson 1990]Svensson, A.,"History-An Intelligent LoadSharingFilter,"In:Proceedings of
the 10thInternationalConferenceon DistributedComputingSystems, IEEE,New York, NY, pp.
546-553 (1990).
[Tanenbaum 1995]Tanenbaum, A.S.,Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs,Nl(1995).
[Tantawi and Towsley1985] Tantawi, A.N.,andTowsley, D.,"Optimal StaticLoadBalancing in
Distributed Computer Systems," JournalofACM,Vol. 32,No.2,pp.445-465 (1985).
[Theimer andLantz1989]Theimer, M. M., and Lantz,K.A.,"Finding IdleMachines in a
Workstation-Based Distributed System," IEEE Transactionson Software Engineering, Vol. 15,
pp.1444-1458 (1989).
[Tilborg and Wittie1984]Tilborg, A.M.,andWittie,L. D.,"WaveScheduling-Decentralized
Scheduling ofTaskForcesinMulticomputers," IEEE Transactionson Computers, Vol.C-33,pp.
835-844 (1984).
[Wah1984]Wah,B.W.,HAComparative StudyofDistributed Resource Sharing on
Multiprocessors," IEEE Transactionson Computers, Vol.C-33,pp.700-711 (1984).
[Wah and Juang1985]Wah, B. W., and luang,J-Y,"Resource Scheduling forLocalComputer
Systems with aMultiaccess Network," IEEE Transactionson Computers, Vol.C-34,No.2,pp.
1144-1157 (1985).
[Waldspurger et al,1992]Waldspurger, C. A.,Hogg,T.,Huberman, B. A.,Kephart, 1.0.,and
Stornetta, W. S.,"Spawn: ADistributed Computational Economy," IEEE Transactions on
Software Engineering, Vol. 18,No.2,pp.103-117 (1992).
[WangandMorris1985]Wang, Y.T., and Morris,R.1.T.,"LoadSharinginDistributed Systems,"
IEEE Transactionson Computers, Vol.C-34,No.3,pp.204-217 (1985).
[WuandLiu1980]Wu, C. S., and Liu,M. T.,"Assignment ofTasks and Resources forDistributed
Processing," In:Proceedings ofthe 1980 International Conference on Computers and
Communications (COMPc"ON-80), IEEE, New York,NY,pp.655-662 (Fall 1980).
[Zhou1988]Zhou,S.,HATrace-Driven Simulation StudyofDynamic LoadBalancing," IEE'E
Transactionson Software Engineering, Vol. 14, pp. 1327-1341 (1988).380 Chap.7 •Resource Management
POINTERS TOBI8ll0GRAPHIES ONTHEINTERNET
Bibliographies containing references on the topics coveredin thischaptercan be found
at:
ftp:ftp.cs.umanitoba.calpublbibliographieslParallellLoad.Balance.l.html
ftp:ftp.cs.umanitoba.calpublbibliographieslParallellLoad.Balance.2.html
ftp:ftp.cs.umanitoba.ca/publbibliographieslParallellload.balance.5.html
ftp:ftp.cs.umanitoba.ca/publbibliographieslParalleVscheduling.html
ftp:ftp.cs.umanitoba.ca/publbibliographieslDistributedldshell.htmlCHAPTER8
Process
Management
8.1 INTRODUOION
In aconventional (centralized) operating system, process management deals with
mechanisms andpoliciesfor sharing the processor ofthe system among all processes.
Similarly, in a distributed operating system, the main goal-of process management is to
make the best possible use of the processing resources of the entire system by sharing
them among all processes .Threeimportant concepts are used in distributed operating
systems to achievethis goal:
1. Processor allocation deals with the process of deciding which process should be
assigned to which processor .
2. Process migration deals with the movement of a process from its currentlocation
to theprocessor to whichithas been assigned.
3. Threads deals with fine -grained parallelism forbetterutilization of theprocessing
capability of thesystem.
Theprocessor allocation concepthas already been described in the previous chapter
onresource management. Therefore , thischapterpresents adescription of theprocess
migration andthreadsconcepts.
381382 Chap.8 •ProcessManagement
8.2PROCESS MIGRATION
Processmigration istherelocation of aprocess from itscurrent location (the sourcenode)
to another node (the destination node).The flow of execution of a migrating process is
illustrated in Figure 8.1.
ProcessP1in
executionDestination
node
r
I
r
I
I
I,
I
I
ISource
node
Execution
suspendedTime Process P1in
execution
Transfer of :
control:
...z-Io------ --------...;;:~ Execution
resumedFreezing
time
Fig. 8.1 Flow of execution of a migrating process.
A process may be migrated either before it starts executing on its source node or
during the course of its execution. The former is known as non-preemptive process
migration and the latter is known as preemptive process migration. Preemptive process
migration is costlier than non-preemptive process migration since the process environ­
ment must also accompany the process to its new node for an already executing
process.
Process migration involves the following major steps:
1. Selection of a process that should be migrated
2. Selection of the destination node to which the selected process should be
migrated
3. Actual transfer of the selected process to the destination node
The first two steps aretaken care of bythe process migration policy and thethirdstep
is taken care ofby the process migration mechanism. The policies for the selection of a
source node, a destination node, and the process to be migrated have already been
described in the previous chapter on resource management. This chapter presents a
description ofthe process migration mechanisms used by the existing distributed
operating systems.Sec.8.2 • ProcessMigration
8.2.1 Desirable Featuresofa Good Proc.ss Migration
Mechanism383
A good process migration mechanism must possess transparency, minimal interferences,
minimal residue dependencies, efficiency, robustness, and communication between
coprocesses.
Transparency
Transparency is animportant requirement for a system that supports process migration.
The following levels of transparency can be identified:
1. Object access level. Transparency at the object access level is the minimum
requirement for a system to support non-preemptive process migration facility. Ifa system
supportstransparency at the object access level, access to objects such as files and devices
can be done in a location-independent manner. Thus, the object access level transparency
allows free initiation of programs at an arbitrary node. Of course, to support transparency
at object access level, the system must provide a mechanism for transparent object naming
and locating.
2. System call and interprocess communication level. So that a migrated process
does notcontinue to depend upon its originating node after being migrated, it is necessary
that all system calls, including interprocess communication, are location independent.
Thus, transparency at this level must be provided in a system that is to support preemptive
process migration facility. However, system calls to request the physical properties of a
node need not be locationindependent.
Transparency ofinterprocess communication is also desired for the transparent
redirection of messages during the transient state of a process that recently migrated. That
is, once a message has been sent, it should reach its receiver process without the need for
resending it from the sender node in case the receiver process moves to another node
before the message is received.
Minimal Interference
Migration of a process should cause minimal interference to the progress of the process
involved and to the system as a whole. One method to achieve this is by minimizing the
freezing time of the process being migrated. Freezing time is defined as the time period
for which the execution of the process is stopped for transferring its information to the
destination node.
Minimal Residual Dependencies
No residual dependency should be left on the previous node. That is, a migrated process
should not in any way continue to depend on its previous node once it has started
executing on its new node since, otherwise, the following will occur:384 Chap.8 •ProcessManagement
• The migrated process continues to impose a load on its previous node, thus
diminishing some of the benefits of migrating the process.
• A failure or reboot of the previous node will cause the process to fail.
Emciency
Efficiency isanother major issue in implementing processmigration.The main sourcesof
inefficiency involved with process migration are as follows:
• The time required for migrating a process
• The cost of locating an object (includes the migrated process)
• The cost of supporting remote execution once the process is migrated
All these costs should be kept to minimum as far as practicable.
Robustness
The process migration mechanism must also be robust in the sense that the failure of a
node other than the one on which a process is currently running should not in any way
affect the accessibility or execution of that process.
Communication between Coprocesses of a Job
One further exploitation of process migration is the parallel processing among the
processes of a single job distributed over several nodes. Moreover, if this facility is
supported, to reduce communication cost, it is also necessary that these coprocesses be
able to directly communicate with each other irrespective of their locations.
8.2.2Proc.ssMigration M.chanlsms
Migration of a process is a complex activity that involves proper handling of several
sub-activities in order to meet the requirements of a good process migration
mechanism listed above. The four major subactivities involved in process migration
are as follows:
1. Freezing the process on its source node and restarting it on its destination node
2. Transferring the process's address space from its source node to its destination
node
3. Forwarding messages meant for the migrant process
4. Handlingcommunication betweencooperating processesthathavebeenseparated
(placed on different nodes) as a result of process migration
The commonly used mechanisms for handling each of these subactivities are
described below.Sec.8.2 • ProcessMigration 38S
Mechanisms for Freezing and Restarting a Process
Inpreemptive process migration, the usual process is to take a "snapshot" of theprocess's
state on its source node and reinstate the snapshot on the destination node. For this, at
some point during migration, the process is frozen on its source node, its state information
is transferred to its destination node, and the process is restarted on itsdestination node
using this state information. By freezing the process, we mean that the execution of the
process is suspended and all external interactions with the process are deferred. Although
the freezing and restart operations differ from system to system, some general issues
involved in these operations aredescribed below.
Immediate andDelayed Blockingofthe Process. Before a process can be
frozen, its execution must be blocked. Depending upon the process's current state, it may
be blocked immediately or the blocking may have to be delayed until the process reaches
a state when it can be blocked. Some typical cases are as follows [Kingsbury and Kline
1989]:
1. If the process isnotexecuting a system call, it can be immediately blocked from
further execution.
2. If the process is executing a system call but is sleeping at an interruptible priority
(a priority at which any received signal would awaken the process) waiting for a
kernel event to occur, it can be immediately blocked from further execution.
3. If the process is executing a system call and is sleeping at a noninterruptible
priority waiting for a kernel event to occur, itcannot be blocked immediately. The
process's blocking has to be delayed until the system call is complete. Therefore,
in this situation, a flag is set, telling the process that when the system call is
complete, it should block itselffrom further execution.
Note that there may be some exceptions to this general procedure of blocking a
process. For example, sometimes processes executing in certain kernel threads are
immediately blocked, even when sleeping at noninterruptible priorities. The actual
mechanism varies from one implementation to another.
FastandSlow I/O Operations. In general, after the process has been blocked,
the next step in freezing the process is to wait for the completion of all fast I/O operations
(e.g., disk 110) associated with the process. The process is frozen after the completion of
all fast I/O operations. Note that it is feasible to wait for fast I/O operations to complete
before freezing the process. However, itis not feasible to wait for slow 110operations,
such as those on apipe or terminal, because the process must be frozen ina timely manner
for theeffectiveness of process migration. Thus proper mechanisms are necessary for
continuing these slow I/O operations correctly after the process starts executing on its
destination node.
Information aboutOpen Files. Aprocess's stateinformation alsoconsistsof
the information pertaining to filescurrently open by the process. This includes such
information as the names or identifiers of the files, their access modes, and the current386 Chap.8 •ProcessManagement
positions of their file pointers. In a distributed system that provides a network transparent
execution environment, there is no problem in collecting this state information because the
same protocol isused to access local as well as remote files using the systemwide unique
file identifiers. However, several UNIX-based network systems uniquely identify files by
their full pathnames [Mandelberg and Sunderam 1988,Alonso and Kyrimis 1988]. But in
these systems itis difficult for a process in execution to obtain a file'scomplete pathname
owing to UNIX file system semantics. A pathname losessignificance once a file has been
openedby a process because the operating system returns to the process a file descriptor
that the process uses to perform all I/O operations on the file. Therefore, in such systems,
it isnecessary to somehow preserve a pointerto the file so that the migrated process could
continue to access it. The following two approaches are used for this:
1. In the first approach [Mandelberg and Sunderam 1988], a link is createdto the file
and thepathname of the link is used as an access point to the file after the process
migrates. Thus when the snapshot oftheprocess's stateisbeing created, a link (witha
special name) is created to each file that is in use by the process.
2. In the second approach [Alonso and Kyrimis 1988], an open file's complete
pathname isreconstructed when required. For this, necessary modifications have to be
incorporated in the UNIX kernel. For example, in the approach described in [Alonso and
Kyrimis 1988], each file structure, where information about open files is contained, is
augmented with apointerto adynamically allocated character stringcontaining the
absolute pathname ofthe file to which it refers.
Anotherfile system issue is that one or more files being used by the process on its
source node may also be present on itsdestination node. For example, it is likely that the
code for system commands such asnroff, ccisreplicated at every node. It would be more
efficientto access these files from the local node at which the process is executing, rather
thanaccessing them across the network from the process's previous node [Agrawal and
Ezzat 1987]. Anotherexample is temporary files that would be more efficiently created at
the node on which the process is executing, as by default these files are automatically
deleted at the end ofthe operation. Therefore, forperformance reasons, the file state
information collected at the source node should be modified properly on the process's
destination node in order to ensure that, whenever possible, local file operations are
performed instead of remote file operations. This also helps inreducing the amount ofdata
to betransferred at the time ofaddress space transfer because the files already present on
thedestination node need not betransferred.
Reinstating theProcessonitsDestination Node. On thedestination node, an
empty process state is created that is similar to that allocated during process creation.
Depending upon the implementation, the newly allocated processmayormay not have the
same process identifier as the migrating process. In some implementations, this newly
created copy ofthe process initially has a process identifier different from the migrating
process in orderto allow both the old copy and the new copy to exist and be accessible
at the same time. However, if the process identifier of the new copy of the process is
different from its old copy, the new copy'sidentifier is changed to the original identifierSec.8.2 • ProcessMigration 387
in asubsequent step before the process starts executing on the destination node. The rest
of the system cannot detect the existence of two copies of the process because operations
on both of them are suspended. Once all the state of the migrating process has been
transferred from the source node to the destination node and copied into the empty process
state, the new copy of the process isunfrozen and the old copy isdeleted. Thus the process
is restarted on its destination node inwhatever state it was in before being migrated.
It may be noted here that the method described above to reinstate the migrant process
isfollowed in the most simple and straightforward case. Several special cases may require
special handling and hence more work. For example, when obtaining the snapshot, the
process may have been executing a system call since some calls are not atomic. In
particular, as described before, this can happen when the process is frozen while
performing an I/O operation on a slow device. If the snapshot had been taken under such
conditions, correct process continuation would be possible only if the system call is
performed again. Therefore normally acheck is made for these conditions and, ifrequired,
the program counter is adjusted as needed to reissue the system call.
Address Space Transfer Mechanisms
A process consists of the program being executed, along with the program's data, stack,
and state. Thus, the migration of a process involves the transfer of the following types of
information from the source node to the destination node:
•Process's state, which consists of the execution status (contents of registers),
scheduling information, information about main memory being used by the
process (memory tables), I/O states (I/O queue, contents of I/O buffers, interrupt
signals, etc.), a list of objects to which the process has a right to access (capability
list),process's identifier, process's user and group identifiers, information about
the files opened by the process (such as the mode and current position of the file
pointer), and so on
•Process's address space (code, data, and stack of the program)
For nontrivial processes, the size of the process's address space (several megabytes)
overshadows the size of the process's stateinformation (few kilobytes). Therefore the cost
of migrating a process is dominated by the time taken to transfer its address space.
Although it is necessary to completely stop theexecution of the migrant process while
transferring its state information, it ispossible to transfer the process's address space
without stopping its execution. In addition, the migrant process's stateinformation must
betransferred to thedestination node before it can start its execution on that node.
Contrary to this, the process's address space can be transferred to thedestination node
either before or after the process starts executing on thedestination node.
Thus in all the systems, the migrant process's execution is stopped while transferring
its state information. However, due to the flexibility in transferring theprocess's address
space at any time after the migration decision is made, the existing distributed systems use
one of the following address space transfermechanisms: total freezing, pretransferring, or
transfer on reference.388 Chap. 8 • ProcessManagement
TotalFreezing. In thismethod, a process's execution is stopped while its address
space is being transferred (Fig. 8.2). This method is used in DEMOSIMP [Powell and
Miller 1983], Sprite [Douglis and Ousterhout 1987], and LOCUS [Popek and Walker
1985] and is simple and easy to implement. Its main disadvantage is that if a process is
suspended for a long time during migration, timeouts may occur, and if the process is
interactive, the delay will be noticed by the user.
TimeSource
nodeDestination
node
Freezing
timeExecution
suspendedMigration decision made
Transferof
address space
Execution
resumed
Fig. 8.2 Totalfreezing mechanism.
Pretransferring, In this method, the address space is transferred while the
process isstill running on thesource node(Fig.8.3).Therefore, once thedecision hasbeen
made to migrate a process, it continues to run on its source node until its address space
has been transferred to the destination node. Pretransferring (also known as precopying)
is done as an initial transfer of the complete address space followed by repeated transfers
of the pages modified during the previous transfer until the number of modified pages is
relatively small or untilnosignificant reduction in thenumberof modifiedpages (detected
using dirty bits) is achieved. The remaining modified pages are retransferred after the
process is frozen for transferring its state information [Theimer et al. 1985].
In the pretransfer operation, the first transfer operation moves the entire address
space and takes the longest time, thus providing the longest time for modifications to the
program's address space to occur. The second transfer moves only those pages of the
address space that were modified during the first transfer, thus taking less time and
presumably allowing fewer modifications to occur during its execution time. Thus
subsequent transfer operations have to move fewer and fewer pages, finally converging to
zero or very few pages, which are then transferred after the process is frozen. It may be
noted here that the pretransfer operation is executed at a higher priority than all otherSec.8.2 • ProcessMigration
TimeSource
nodeDestination
node389
Freezing
lime
Fig. 8.3Migration decision made
Transfer of
address space
Execution
resumed
Pretransfer mechanism.
programs on the source node to prevent these other programs from interfering with the
progress of the pretransfer operation.
This method is used in the V-System [Theimer et al. 1985]. In this method, the
freezing time is reduced so migration interferes minimally with the process'sinteraction
with other processes and the user. Although pretransferring reduces the freezing time of
the process, it may increase the total time for migration due to the possibility of redundant
page transfers. Redundant pages are pages that are transferred more than once during
pretransferring because they become dirty while the pretransfer operation is being
performed.
Transfer on Reference. This method is based on the assumption that processes
tend to use only a relatively small part of their address spaces while executing . In this
method, the process's address space is left behind on its source node, and as the relocated
process executes on itsdestination node, attempts to reference memory pages results in the
generation of requests to copy inthe desired blocks from their remote locations. Therefore
in thisdemand-driven copy-on-reference approach, a page of the migrant process's
address space is transferred from its source node to its destination node only when
referenced (Fig. 8.4). However, Zayas [1987J also concluded through his simulation
results that prefetching of one additional contiguou s page per remote fault improves
performance.
This method is used in Accent [Zayas 1987]. In this method, the switching time of
the process from its source node to its destination node is very short once the decision
about migrating the process has been made and is virtually independent of the size of the
address space. However, this method is not efficient in terms of the cost of supporting
remoteexecution once the process is migrated, and part of the effort saved in the lazy
transfer of an address space must beexpended as the process accesses its memory390 Chap.8 •ProcessManagement
Source
nodeDestination
node
Time
Execution
suspended-r-+- -....f_M:.:,.:igrationdecisionmade
Freezing
timeExecution
resumed
On-demandtransfer
ofaddressspace
Fig. 8.4 Transfer-on-reference mechanism.
remotely.Furthermore, this method imposes acontinued loadon the process's source node
and results in failure of the process if the source node fails or is rebooted.
Message-Forwarding Mechanisms
In moving a process, it must be ensured that all pending, en-route, and future messages
arrive at the process's new location. The messages to be forwarded to the migrant
process's new location can be classified into the following:
Type1: Messages received at the source node after the process's execution has been
stopped on its source node and the process's execution has not yet been started on its
destination node
Type2: Messages received at the source node after the process's execution has
started on its destination node
Type3: Messages that are to be sent to the migrant process from any other node
after it has started executing on the destination node
The different mechanisms used for message forwarding in existing distributed
systems are described below.
Mechanism ofResending the Message, This mechanism is used in the
V-System [Cheriton 1988, Theimer et al. 1985] and Amoeba [Mullender et al. 1990].to
handle messages of all three types.In this method, messages of types 1and 2 are returned
to thesenderas not deliverable or are simply dropped, with the assurance that the sender
of the message is storing a copy of the data and is prepared to retransmit it.Sec. 8.2 • Process Migration 391
Forexample, in V-System, a message of type 1or 2 is simplydropped and thesender
isprompted toresenditto theprocess's new node. The interprocess communication
mechanism ofV-Systenl ensuresthatsenderswill retry untilsuccessful receiptofa reply.
Similarly inAmoeba, for allmessages of type 1, the sourcenode'skernelsendsa"try
again later, this processisfrozen"message to the sender. Aftertheprocesshasbeen
deletedfrom the sourcenode, those messages willcomeagain at some point oftime, but
this time as type 2messages. For all type 2messages, thesourcenode'skernelsends a
"thisprocessisunknown at this node" message to the sender.
In thismethod, uponreceiptof anegative reply, the senderdoes alocateoperation
to find the new whereabouts of theprocess, andcommunication isreestablished. Both
V-System andAmoeba use the broadcasting mechanism tolocateaprocess(object
locating mechanisms aredescribed inChapter 10).Obviously, in thismechanism,
messages of type3are sent direct! yto theprocess's destination node.
Thismethoddoes not requireanyprocessstate to be left behindon theprocess's
sourcenode.However, the main drawback ofthismechanism is that the message­
forwarding mechanism ofprocessmigration operation isnontransparent to theprocesses
interacting withthemigrantprocess.
Origin Site Mechanism. ThismethodisusedinAIX'sTCF(Transparent
Computing Facility) [Walker and Mathews 1989] and Sprite[Douglis andOusterhout
1987]. The processidentifier ofthesesystemshas theprocess's originsite (orhomenode)
embedded in it, and each site is responsible forkeeping information about the current
locations of all the processes createdonit.Therefore, aprocess's currentlocationcan be
simplyobtained byconsulting itsoriginsite. Thus, in these systems, messages fora
particular processarealwaysfirst sent to its originsite. The originsite then forwards the
message to theprocess's currentlocation. Thismethodisnot good from areliability point
ofviewbecause the failure oftheoriginsite will disruptthemessage-forwarding
mechanism. Another drawback ofthismechanism is thatthereisacontinuous load on the
migrantprocess '8originsiteevenaftertheprocesshasmigrated from that node.
linkTraversal Mechanism. InDEMOSIMP [Powell andMiller1983], to
redirectthemessages oftype 1, a message queuefor themigrantprocessiscreatedon its
sourcenode. All the messages ofthis type are placedin thismessage queue. Upon being
notifiedthat theprocessisestablished on thedestination node, all messages in thequeue
are sent to the destination node as a part ofthemigration procedure.
Toredirectthemessages of types 2 and 3, a forwarding addressknownaslinkis
left at the sourcenodepointing to thedestination nodeofthemigrant process. The
mostimportant partofa link is the message processaddressthat has two components.
The first component is asystemwide, unique, process identifier. Itconsists ofthe
identifier of the node on which the processwascreatedand auniquelocalidentifier
generated bythat node. The secondcomponent is the last knownlocation ofthe
process. Duringthelifetime of a link, the first component ofitsaddress never
changes; thesecond, however, may.Thusto forward messages oftypes 2 and 3, a
migrated process islocatedbytraversing a series of links (starting from the node
where the process wascreated) that form a chainultimately leadingto theprocess's
currentlocation. The second component of a link is updated when the corresponding392 Chap. 8 • Process Management
processisaccessed from a node. This is done to improve the efficiency of subsequent
locating operations for the same process from that node.
Thelinktraversal mechanism used by DEMOSIMP for message forwarding suffers
from the drawbacks of poor efficiency and reliability. Several links may have to be
traversed to locate a process from a node, and if any node in the chain of links fails, the
process cannot be located.
LinkUpdateMechanism. In Charlotte [Artsy and Finkel 1989], processes
communicate vialocation-independent Jinks,whichare capabilities for duplex commu­
nication channels. During the transfer phase of the migrant process, the source node sends
link-update messages to the kernels controlling all of the migrant process's communica­
tion partners. These link update messages tell the new address of each link held by the
migrant process and are acknowledged (by the notified kernels) for synchronization
purposes. This task is not expensive since it is performed in parallel. After this point,
messages sent to the migrant process on any of its links will be sent directly to the migrant
process's new node. Communication requests postponed while the migrant process was
being transferred are buffered at the source node and directed to the destination node as
a part of the transfer process. Therefore, messages of types 1and 2 are forwarded to the
destination node by the source node and messages of type 3 are sent directly to the
process's destination node.
Mechanisms forHandling Coprocesses
In systems that allow process migration, another important issue is the necessity to
provide efficient communication between a process (parent) and its subprocesses
(children), which might have been migrated and placed on different nodes. The two
different mechanisms used by existing distributed operating systems to take care of this
problem are described below.
Disallowing Separation ofCoprocesses. The easiest method of handling
communication between coprocesses is to disallow their separation. This can be achieved
in the following ways:
1. By disallowing the migration of processes that wait for one or more of their
children to complete
2. By ensuring that when a parent process migrates, its children processes will be
migrated along with it
The first method is usedby some UNIX-based network systems [Alonso and Kyrimis
1988,Mandelberg and Sunderam 1988] and the second method is used by V-System
[Theimer etal. 1985].Toensure thataparentprocess willalways bemigrated along withits
children processes, V-System introduced the conceptoflogical host. V-System address
spaces and their associated processes are grouped into logical hosts. A V-System process
identifier isstructured asa(logical-host-id, local-index) pair.Intheextreme, each program
can be run in its own logical host. There may bemultiple logical hosts associated with a
single node; however, alogical host islocal toasingle node. In V-System,allsubprocessesSec.8.2 • ProcessMigration 393
ofaprocesstypically executewithin asingle logicalhost.Migration of aprocessisactually
migration ofthelogicalhostcontaining thatprocess.Thus, typically, all subprocesses ofa
processaremigrated togetherwhen the processismigrated [Theimer et al.1985].
The main disadvantage ofthismethodis that it does not allow the use ofparallelism
withinjobs,which isachieved byassigning the various tasks ofajobto thedifferent nodes
of thesystemandexecuting themsimultaneously on these nodes. Furthermore, in the
methodemployed by V-System, the overhead involved inmigrating aprocessis large
when its.logical host consistsof several associated processes.
Home Node or Origin Site Concept. Sprite[Douglis andOusterhout 1987]
uses its home node concept(previously described) forcommunication betweenaprocess
and itssubprocess when the two are runningondifferent nodes.UnlikeV-System, this
allows the complete freedomofmigrating aprocessor itssubprocesses independently and
executing them on different nodesofthe system. However, since all communications
between aparentprocessand itschildren processes take place via the home node, the
message traffic and the communication costincreaseconsiderably. Similardrawbacks are
associated with the conceptoforigin site of IJOCUS [Popek and Walker 1985].
8.2.3ProcessMigration inHeterogeneous Systems
When a process is migrated inahomogeneous environment, theinterpretation ofdata is
consistent on both the source and the destination nodes.Therefore, thequestionofdata
translation does not arise. However, when a processismigrated in aheterogeneous
environment, all theconcerned data must be translated from the sourceCPU format to the
destination CPU format before it can be executed on thedestination node. If the system
consistsoftwo CPU types, each processor must be able to convertthe data from the foreign
processor type into its own format. If a third CPU' is added,eachprocessor must be able to
translate between itsownrepresentation and thatoftheothertwoprocessors. Hence, in
general,aheterogeneous system having nCPU types must have n(n-l)piecesoftranslation
software inordertosupportthe facility of .migrating a processfrom any node to any other
node. An example for fourprocessor types is shown in Figure8.5(a).This isundesirable, as
adding a new CPU type becomes a moredifficulttask over time.
Maguire and Smith [1988] proposed the use of the external data representation
mechanism forreducing thesoftware complexity of thistranslation process. In this
mechanism, astandard representation is used for the transport of data, and each processor
needs only to be able to convertdata to and from the standard form. This boundsthe
complexity of thetranslation software. Anexample for fourprocessor types isshownin
Figure8.5(b).Theprocessofconverting from aparticular machine representation to
externaldatarepresentation format is calledserializing, and thereverseprocessiscalled
deserializing.
Thestandard datarepresentation format is calledexternaldata representation, and its
designer mustsuccessfully handletheproblemofdifferent representations fordatasuch as
characters, integers, andfloating-point numbers. Ofthese, the handling offloating-point
numbers needsspecialprecautions. The issues discussed byMaguire and Smith [1988] for
handling floating-point numbers inexternaldatarepresentation schemeare given below.394 Chap.8 •ProcessManagement
(a)
43
78
Externaldata
M------frepresentation .._----\
(b)
Fig. 8.5 (a)Example illustrating the need for J2pieces of translation software
required in a heterogeneous system having 4 types of processors. (b)
Example illustrating the need for only 8 pieces of translation software in a
heterogeneous system having 4 types of processors when the external data
representation mechanism is used.
A floating..point number representation consists of an exponent part, a mantissa part,
and a sign part. The issue of proper handling of the exponent and the mantissa has been
described separately because the side effects caused by an external data representation
affect each of the two components differently.
Handling the Exponent
Thenumberof bits used forthe exponent of afloating-point number varies from processor
to processor. Let us assume that, for the exponent, processor Auses 8 bits, processor B
uses 16 bits, and the external data representation designed by the users of processorSec.8.2 • ProcessMigration 395
architecture Aprovides12bits (an extra 4 bits for safety). Also assume that all three
representations use the same number of bits for the mantissa.
In this situation, a process can be migrated from processor AtoBwithout any
problem in representing itsfloating-point numbers because the two-step translation
process of the exponent involves the conversion of8bits of data to 12bits and then 12
bits of data to 16 bits, having plenty of room for the converted data in both steps.
However, a process that has some floating-point data whose exponent requires more than
12bits cannot be migrated from processor BtoAbecause this floating-point data cannot
berepresented in the external data representation, which has only 12bits for the exponent.
Note that the problem here is with the design of the external data representation, which
will not even allow data transfer between two processors, both of which use 16bits for the
exponent, because the external data representation has only12bits for this purpose. This
problem can be eliminated byguaranteeing that the external data representation have at
least as many bits in the exponent as the longest exponent of anyprocessor in the
distributed system.
A second type of problem occurs when a floating-point number whose exponent is
less than or equal to 12bits but greater than 8bits istransferred from processor BtoA.
In this case, although the external data representation has a sufficient number of bits to
handle the data, processor Adoes not. Therefore, in this case, processor Amust raise an
overflow or underflow (depending on the sign of the exponent) upon conversion from the
external data representation or expect meaningless results. There are three possible
solutions to this problem:
1. Ensuring that numbers used by programs that migrat.ehave a smaller exponent
value than the smallest processor's exponent value in the system
2.Emulating the larger processor's value
3.Restricting themigration of the process to only those nodes whose processor's
exponent representation is at least as large as that of the source node's
processor
The first solution imposes a serious restriction on the use of floating-point numbers,
and this solution may be unacceptable byserious scientific computations. The second
solution may be prohibitively expensive in terms of computation time. Therefore, the third
solution of restricting the direction of migration appears to be a viable solution. For this,
each node of the system keeps a list of nodes that can serve as destinations for migrating
a process from this node.
Handling the Mantissa
The first problem in handling the mantissa is the same as that of handling the exponent.
Let us assume that the exponent field is of the same size on all the processors, and for the
mantissa representation, processor Auses32bits,processor Buses64bits, and the
external data representation uses 48 bits. Due to similar reasons as described for handling
theexponent, in this case also the migration of a process from processor AtoBwill have396 Chap.8 •ProcessManagement
noproblem, but themigration ofaprocessfromprocessor BtoAwill result in the
computation being carried out in "half-precision." This may not be acceptable when
accuracy ofthe result is important. As inhandling theexponent, toovercome thisproblem,
theexternal datarepresentation must have sufficient precision to handle the largest
mantissa, and thedirection ofmigration should be restricted only to the nodes having a
mantissa at least as large as the source node.
The second problem inhandling themantissa is the loss ofprecision due to
multiple migrations between a setofprocessors, where our example processors Aand
Bmight be a subset. This is a concern only in the mantissa casebecauselossofone
or more bits oftheexponent iscatastrophic, while loss of bits in the mantissa only
degrades theprecision ofcomputation. It may appear that the loss in precision due to
multiple migrations maybecumulative, and thus a series ofmigrations may totally
invalidate acomputation. However, if the external datarepresentation isproperly
designed tobeadequate enoughtorepresent the longest mantissa ofanyprocessor of
thesystem,theresulting precision will never be worse than performing thecalculation
on theprocessor that has the least precision (leastnumberofbits for the mantissa)
amongall theprocessors ofthe system. This is because the remote computations can
beviewed as "extraprecision" calculations with respect to the floating point ofthe
processor with least precision.
Handling Signed-Infinity andSigned-Zero
Representations
Twootherissues that need to beconsidered in the design ofexternal data representation
are thesigned-infinity andsigned-zero representations. Signedinfinity is a value supported
by some architectures thatindicates that thegenerated result is too large (overflow) or too
small(underflow) to store.Otherarchitectures may use the sign bit ofa value that would
otherwise be zero, thus giving rise to a signed zero.
Now the problem is that these representations may not be supported on all systems.
Therefore, whiledesigning thetranslation algorithms, properdecisions must be made
about how to deal with these situations. However, in a good design, the external data
representation must take care ofthese values so that a given processor caneithertake
advantage ofthis extra information or simply discard it.
8.1.4AcJvontQgas ofProcassMigration
Processmigration facility may beimplemented in adistributed system for providing one
or moreofthe following advantages to the users:
1. Reducing average response time ofprocesses. The average response timeofthe
processes ofa nodeincreases rapidly as the load on the node increases. Processmigration
facility may beused to reduce the average response timeoftheprocesses ofa heavily
loaded node by migrating andprocessing someofitsprocesses on a node that is eitheridle
or whose processing capacity isunderutilized.Sec.8.2 • ProcessMigration 397
2. Speeding up individual jobs.Process migration facility maybe used to speed up
individual jobs in two ways. The first method is to migrate the tasks of a job to the
different nodes of the system and to execute them concurrently. The second approach is
to migrate a job to a node having a faster CPU or to a node at which it has minimum
turnaround time due to various reasons (e.g., due to specific resource requirements of the
job). Of course, the gain in execution time must be more than the migration cost
involved.
3. Gaining higherthroughput. In a system that does not support process migration,
it is very likely that CPUs of all the nodes are not fully utilized. But in a system with
process migration facility, the capabilities of the CPUs of all the nodes can be better
utilizedby using a suitable load-balancing policy. This helps in improving the throughput
of the system. Furthermore, process migration facility may also be used to properly mix
I/O and CPU-bound processes on a global basis for increasing the throughput of the
system.
4. Utilizing resources effectively. In a distributed system, the capabilities of the
various resources such as CPUs, printers, storage devices, and so on, of different nodes are
different. Therefore, depending upon the nature of aprocess, itcan be migrated tothe most
suitable node to utilize the system resources in the most efficient manner. This is true not
only for hardware resources but also for software resources such as databases, files, and
so on.Furthermore, there are some resources, such as special-purpose hardware devices,
that are not remotely accessible by a process. For example, it may be difficult to provide
remote access to facilities to perform fast Fourier transforms or array processing or this
access may be sufficiently slow to prohibit successful accomplishment of real-time
objectives [Smith 1988]. Process migration also facilitates the use of such resources by a
process of any node because the process can be migrated to the resource's location for its
successful execution.
5.Reducing networktraffic.Migrating a process closer to the resources it is using
most heavily (such as files, printers, etc.) may reduce network traffic in the system if the
decreased cost of accessing its favorite resources offsets the possible increased cost of
accessing its less favored ones. In general, whenever a process performs data reduction (it
analyzes and reduces the volume of data by generating some result) on some volume of
data larger than the process's size, it may be advantageous to move the process to the
location of the data [Smith 1988]. Another way to reduce network traffic by process
migration is to migrate and clustertwo or more processes, which frequently communicate
with each other, on the same node of the system.
6. Improving system reliability. Process migration facility may be used to improve
system reliability in several ways. One method is to simply migrate a critical process to
a node whose reliability is higher than other nodes in the system. Another method is to
migrate a copy of a critical process to some other node and to execute both the original
and copied processes concurrently on different nodes. Finally, in failure modes such as
manual shutdown, which manifest themselves as gradual degradation of a node, the
processes of the node, for their continued execution, may be migrated to anothernode
before the dying node completely fails.398 Chap.8 •ProcessManagement
7. Improving system security. A sensitive process may be migrated and run on a
secure node that is not directly accessible to general users, thus improving the security of
that process.
8.3THMADS
Threads are apopularway to improve application performance through parallelism. In
traditional operating systems the basicunitof CPU utilization is a process. Each process
has its own program counter, its own registerstates, its own stack, and its own address
space. On the other hand, in operating systems with threads facility, the basic unit of CPU
utilization is a thread. In these operating systems, a process consists of an address space
and one or more threads of control [Fig. 8.6(b)].Each thread of a process has its own
program counter, its own registerstates, and its own stack. But all the threads of a process
share the same address space. Hence they also share the same global variables. In addition,
all threads of a process also share the same set of operating system resources, such as open
files, child processes, semaphores, signals, accounting information, and so on. Due to the
sharing of address space, there is no protection between the threads of aprocess. However,
this is not a problem. Protection between processes is needed because different processes
may belong to different users. But a process (and hence all its threads) is always owned
by a single user. Therefore, protection between multiple threads of a process isnot
necessary. If protection is required between two threads ofa process, itispreferable to put
them in different processes, instead of putting them in a single process.
Fig. 8.6 (a)Single-threaded and(b)
multithreaded processes. A single­
threaded process corresponds to a
process of a traditional operating
system.(b)Addressspace
ITJITJITJ
(a)Addressspace
Threadsshare a CPU in the same way as processes do. That is, on a uniprocessor,
threads run in quasi-parallel (time sharing), whereas on a shared-memory multiprocessor,
as many threads can run simultaneously as there are processors. Moreover, like traditional
processes, threads can create child threads, can block waiting for system calls tocomplete,
and can change states during their course of execution. At a particular instance of time, a
thread can be in anyoneofseveral states: running, blocked, ready, or terminated. Due to
thesesimilarities, threads are often viewed as miniprocesses. In fact, in operating systemsSec. 8.3 • Threads 399
with threads facility, a process having a single thread corresponds to a process of a
traditional operating system [Fig. 8.6(a)].Threads are often referred to as lightweight
processes and traditional processes are referred to as heavyweight processes.
8.3.1Motivations forUsingThreads
The main motivations for using a multithreaded process instead of multiple single­
threaded processes for performing some computation activities are as follows:
1. Theoverheads involved in creating a new process are in general considerably
greater than those of creating a new thread within a process.
2.Switching between threads sharing the same address space is considerably
cheaperthan switching between processes that have their own address spaces.
3. Threads allow parallelism to be combined with sequential execution and blocking
system calls [Tanenbaum 1995]. Parallelism improves performance and blocking
system calls make programming easier.
4. Resource sharing can be achieved more efficiently and naturally between threads
of a process than between processes because all threads of a process share the
same address space.
Theseadvantages areelaborated below.
Theoverheads involved in the creation of a new process and building its execution
environment are liable to be much greater than creating a new thread within an existing
process. This is mainly because when a new process is created, its address space has to be
created from scratch, although a part of it might be inherited from the process's parent
process.I-Iowever, when a new thread is created, it uses the address space of its process
that need not be created from scratch. For instance, in case of a kernel-supported virtual­
memory system, a newly created process will incur page faults asdata and instructions are
referenced for the first time. Moreover, hardware caches will initially contain no data
values for the new process, and cache entries for the process's data will be created as the
process executes. These overheads may also occur in thread creation, but they are liable
to be less. This is because when the newly created thread accesses code and data that have
recently been accessed by other threads within the process, it automatically takes
advantage of any hardware or main memory caching that has taken place.
Threads also minimize context switching time, allowing the CPUtoswitchfrom one
unit ofcomputation to another unit of computation with minimal overhead. Due to the
sharing of address space and other operating system resources among the threads of a
process, the overhead involved in CPU switching among peer threads is very small as
compared to CPU switching among processes having their own address spaces. This is the
reason why threads are called lightweight processes.
To clarify how threads allow parallelism to be combined with sequential execution
and blocking system calls, let us consider the different ways in which a server process can
beconstructed. One of the following three models maybe used to construct a server
process (e.g., let us consider the case of a file server) [Tanenbaum 1995]:400 Chap.8 •ProcessManagement
1.Asasingle-thread process.This model uses blocking system calls but without any
parallelism. In this method, the file server gets a client'sfile access request from the
request queue, checks the request for access permissions, and if access is allowed, checks
whether a disk access is needed to service the request. If disk access is not needed, the
request is serviced immediately and areply is sent to theclient process. Otherwise, the file
server sends a disk access request to the disk server and waits for a reply.After receiving
the diskserver'sreply, it services the client'srequest, sends a reply to the client process,
and goes back to get the next request from the request queue.
In this method, the programming of the server process is simple because of the use
of blocking system call; after sending its request, the file server blocks until a reply is
received from the disk server. However, if a dedicated machine is used for the file server,
the CPU remains idle while the file server is waiting for a reply from the disk server.
Hence, no parallelism is achieved in this method and fewer client requests are processed
per unit of time.
Theperformance of a server implemented as a single-thread process is often
unacceptable. Therefore, itis necessary tooverlap theexecution of multiple client requests
by allowing the file server to work on several requests simultaneously. The next two
models support parallelism for this purpose.
2.Asafinite-state machine. This model supports parallelism but with nonblocking
system calls. In this method, the server is implemented as a single-threaded process and
is operated like a finite-state machine. An event queue is maintained in which both client
request messages and reply messages from the disk server are queued. Whenever the
thread becomes idle, ittakes the next message from theevent queue. If itisaclient request
message, a check is made for access permission and need for disk access. If disk access
is needed to service the request, the file server sends a disk access request message to the
disk server. However, this time, instead of blocking, it records the current state of the
client'srequest in a table and then goes toget the next message from theevent queue. This
message may either be a request from a new client or a reply from the disk server of a
previous disk access request. If it is a new client request, it is processed as described
above. On the other hand, if it is a reply from the disk server, the state of the client's
request that corresponds to the reply is retrieved from the table, and the client'srequest is
processed further.
Although the method achieves parallelism, itis difficult to program the server
process in this method due tothe useof nonblocking system calls.The server process must
maintain entries for every outstanding client request, and whenever a disk operation
completes, the appropriate piece of client state must be retrieved to find out how to
continue carrying out the request.
3.Asa groupofthreads.This model supports parallelism with blocking system
calls. In this method, the server process is comprised of a single dispatcher thread and
multiple workerthreads. Either the worker threads can be created dynamically,
whenever a request comes in, or a pool of threads can be created at start-up time to
deal with as many simultaneous requests as there are threads. The dispatcher thread
keeps waiting in a loop for requests from the clients. When a client request arrives, it
checks it for access permission. If permission is allowed, it either creates a new workerSec. 8.3 • Threads 401
thread or chooses an idle worker thread from the pool (depending onwhether the
worker threads are created dynamically orstatically) and hands over the requestto the
worker thread. The controlis then passed on to the worker thread and the dispatcher
thread'sstatechanges from running to ready. Now the worker thread checks to see if
a disk access is needed for the request or if it can be satisfied from the block cache
that is shared by all the threads. If disk access is needed, it sends a disk access request
to the disk server and blocks while waiting for a reply from the disk server. At this
point, the scheduler will be invoked and a thread will be selected to be run from the
group of threads that are in the ready state. The selectedthread may be the dispatcher
thread or another worker thread that is now ready to run.
This method achieves parallelism whileretaining the idea of sequential processes that
make blocking system calls. Therefore, a server process designed in this way has good
performance and is also easy to program.
Wesaw the motivation for using threads in the design of server processes. Often there
are some situations where client processes can also benefit from the concurrency made
possible by threads. For example, a clientprocessmay use a divide-and-conquer algorithm
to divide data into blocks that can be processed separately. It can then send each block to
a server to be processed and finally collectandcombine the results. In this case, a separate
client thread maybe used to handle each data block to interact with the different server
processes. Similarly, when a file is to be replicated on multiple servers, a separate client
thread can be used to interact with each server. Some client application userinterfaces can
also benefit by using threads to give the interface back to a user while a long operation
takes place. Clientprocesses that perform lots ofdistributed operations can also benefit
from threads by using a separate thread to monitor each operation.
Finally, the use of threads is also motivated by the fact that a set of threads using a
shared address space is themost natural way to program many applications. For example,
in anapplication that uses the producer-consumer model, the producer and the consumer
processes must share a common buffer.Therefore, programming theapplication in such
a way that the producer andconsumer are two threads of the same process makes the
software design simpler.
8.3.2Models for Organizing Threads
Depending on an application's needs, the threads of a process of the application can be
organized indifferent ways. Three commonly used ways to organize the threads ofa
process are as follows [Tanenbaum 1995]:
1.Dispatcher-workers model.We have already seen the use of this model in
designing a server process. In this model, the process consists of a single dispatcher thread
and multiple worker threads. The dispatcher' thread accepts requests from clients and, after
examining the request, dispatches therequestto one of the free worker threads for further
processing of the request. Each worker thread works on a different clientrequest.
Therefore multiple client requests can be processed in parallel. An exampleofthis model
is shown in Figure 8.7(a).402 Chap.8 • ProcessManagement
Requests
Port
(a)
Requests
(b)
Requests
(c)Aserverprocessfor
processing incomingrequests
Aserverprocessforprocessing incomingrequests
thatmaybeofthree differenttypes,eachtypeof
requestbeinghandledbyadifferentthread
Aserverprocessforprocessing incomingrequests,
eachrequestprocessed inthreesteps,eachstep
handledbyadifferentthreadandoutputofone
stepusedasinputtothenextstep
Fig.8.7 Models for organizing threads: (a)dispatcher-workers model;(b)team
mode);(c)pipeline model.Sec. 8.3 • Threads 403
2. Teammodel. In thismodel,allthreadsbehaveasequalsin the sense that thereis
nodispatcher-worker relationship forprocessing clients'requests. Eachthreadgets and
processes clients' requests on its own. Thismodelis often used for implementing
specialized threadswithinaprocess. Thatis, eachthreadoftheprocessisspecialized in
servicing aspecific type of request. Therefore, multiple typesofrequests can be
simultaneously handled by theprocess. Anexample ofthis model is showninFigure
8.7(b).
3. Pipeline model. Thismodelisusefulforapplications based on the producer­
consumer model,inwhichtheoutputdatagenerated by one part oftheapplication is used
asinputforanotherpartoftheapplication. In thismodel,thethreadsofaprocessare
organized as apipeline so that the outputdatagenerated by the first threadis used for
processing by thesecondthread,theoutputofthesecondthreadis used for processing by
the third thread,and so on. The outputofthe lastthreadin thepipelineis the final output
oftheprocessto which the threadsbelong.Anexample ofthismodelisshowninFigure
8.7(c).
8.3.3Issues In· Designing QThreadsPackage
Asystemthatsupports threadsfacilitymustprovidea setofprimitives to its users for
threads-related operations. Theseprimitives ofthesystemaresaid to form a threads
package. Someoftheimportant issues in designing athreadspackage aredescribed
below.
ThreadsCreation
Threads can be created eitherstatically or dynamically. Inthe static approach, the number
ofthreadsofaprocessremainsfixed for its entirelifetime, while in the dynamic approach,
thenumberofthreadsofaprocesskeepschanging dynamically. In thedynamic approach,
aprocessisstartedwith asinglethread,newthreadsarecreatedas and when needed
duringtheexecution oftheprocess,and athreadmaydestroyitselfwhenitfinishes its job
bymakingan exit call. On the otherhand,in the static approach, thenumberofthreads
ofaprocessisdecidedeitherat the time ofwritingthecorresponding program orwhen
theprogram iscompiled. In thestaticapproach, a fixed stack is allocated to each thread,
but in the dynamic approach, the stack size ofathreadisspecified as aparameter to the
systemcall forthreadcreation. Otherparameters usuallyrequired by thissystemcall
includescheduling priorityand theprocedure to beexecuted to run this thread. The system
callreturnsathreadidentifier for thenewlycreatedthread. This identifier is used in
subsequent callsinvolving thisthread.
ThreadsTermination
Termination ofthreadsisperformed in amannersimilarto thetermination ofconventional
processes. Thatis, athreadmayeitherdestroyitselfwhen it finishes its jobbymakingan
exitcall or be killedfromoutsidebyusingthe killcommand andspecifying thethread404 Chap.8 •ProcessManagement
identifier as its parameter. In many cases, threads are never terminated. For example, we
saw.above that in a process that uses statically created threads, the number of threads
remainsconstant for the entire life ofthe process. In such a process, all its threads are
createdimmediately after theprocessstarts up and then these threads are never killed until
theprocessterminates.
ThreadsSynchronization
Since all the threads ofaprocessshare acommon address space, some mechanism must
be used to preventmultiple threads from trying to access the same data simultaneously.
For example, suppose two threads ofaprocessneed toincrement the same global variable
within the process. For this to occursafely, each thread must ensure that it has exclusive
access for this variable for some period oftime. A segment ofcode in which a thread may
beaccessing some shared variable is called a criticalregion.Topreventmultiple threads
fromaccessing the same data simultaneously, it issufficient to ensure that when one
thread is executing in a critical region, no otherthread is allowed to execute in a critical
region in which the same data is accessed. That is, the execution of critical regions in
which the same data is accessed by the threads must be mutually exclusive in time. Two
commonly used mutual exclusion techniques in a threads packageare mutex variables and
condition variables.
Amutexvariable is like a binary semaphore that is always in one of two states,
locked or unlocked. A thread that wants to executein a critical region performs a lock
operation on thecorresponding mutex variable. If the mutex variable is in the unlocked
state, the lockoperation succeeds and the state ofthe mutex variable changes from
unlocked to locked in a single atomic action. After this, the thread can execute in the
critical region. However, if the mutex variable is already locked, depending on the
implementation, the lock operation is handled in one ofthe following ways:
1. The thread is blockedand entered in a queue of threads waiting on the mutex
variable.
2. A status code indicating failure is returned to the thread. In this case, the thread
has the flexibility to continue with some other job. However, to enter the critical
region, the thread has to keep retrying to lock the mutex variable until it
succeeds.
A threads package maysupportboth byproviding different operations for actually
locking and obtaining the status ofa.mutex variable.
In amultiprocessor system in which different threads run in parallel on different
CPUs, it may happen that two threads perform lock operations on the same mutex variable
simultaneously. In such a situation, one ofthem wins, and the loser is either blocked or
returned a status code indicating failure.
When a thread finishes executing in itscritical region, itperforms an unlockoperation
on thecorresponding mutex variable. At this time, ifthe blocking method isused and ifone
ormore threads are blocked waiting on themutex variable, oneofthem isgiven thelockand
its state is changedfromblockedto running while others continue towait.Sec.8.3 • Threads 405
Mutex variables are simple to implement because they have only two states.
However, their use is limited to guarding entries to critical regions. For more general
synchronization requirements condition variables are used. A condition variable is
associated with a mutex variable and reflects a Boolean state of that variable. Waitand
signalare two operations normally provided for a condition variable. When a thread
performs a waitoperation on acondition variable, the associated mutex variable is
unlocked, and the thread is blocked until a signaloperation is performed by some other
thread on the condition variable, indicating that the event being waited for may have
occurred. When a thread performs a signaloperation on the condition variable, the mutex
variable is locked, and the thread that was blocked waiting on the condition variable starts
executing in the critical region. Figure 8.8 illustrates the use of mutex variable and
condition variable for synchronizing threads.
Thread1
Lock(mutex_A)
succeeds
Criticalregion
(usesshared resourceA)
Unlock(mutex_A)
Signal(A_free)Thread2
Lock(mutex_A) fails
: Wait (A_free),,,
:Blockedstate,,,,
T'Lock(mutex_A)
succeeds
Mutex_Aisamutexvariableforexclusiveuseofshared resourceA.
A_freeisaconditionvariable for resource Atobecomefree.
Fig.8.8 Use of mutex variable and condition variable for synchronizing threads.
Condition variables are often used for cooperation between threads. For example, in
an application in which two threads of a process have a producer-consumer relationship,
theproducer thread creates data and puts it in a bounded buffer, and the consumer thread
takes the data from the buffer and uses it for further processing. In this case, if the buffer
is empty when the consumer thread checks it, that thread can bemade to wait on a
nonempty condition variable, and when the producer thread puts some data in the buffer,
it can signal the nonempty condition variable. Similarly, if the buffer is full when the
producer thread checks it, that thread can be made to wait on a nonfullcondition variable,
and when the consumer thread takes out some data from the buffer, it can signal the
nonfullcondition variable. In this way,the two threads can work in cooperation with each
other by the use of condition variables.406 Chap.8 •ProcessManagement
ThreadsScheduling
Another important issue in the design of a threads package is how to schedule the threads.
Threads packages often provide calls to give the users the flexibility to specify the
scheduling policy to be used for their applications. With this facility, an application
programmer can use the heuristics of the problem to decide the most effective manner for
scheduling. Some of the special features for threads scheduling that may be supported by
a threads package are as follows:
1. Priority assignment facility. In a simple scheduling algorithm, threads are
scheduled onafirst-in, first-out basisortheround-robin policy isusedtotimeshare theCPU
cycles among the threads ona quantum-by-quantum basis, withallthreads treated asequals
by the scheduling algorithm. However, a threads-scheduling scheme may provide the
flexibility to the application programmers to assign priorities to the various threads of an
application inorder toensure that important ones can be run ona higher priority basis.
Apriority-based threadsscheduling scheme may be either non-preemptive or
preemptive. In the former case, once a CPU is assigned to a thread, the thread can use it
until it blocks, exits, or uses up its quantum. That is, the CPU is not taken away from the
thread to which it has already been assigned even if another higher priority thread
becomes ready to run. The higher priority thread is selected to run only after the thread
that is currently using the CPU releases it. On the other hand, in the preemptive scheme,
a higher priority thread always preempts a lower priority one. That is, whenever a higher
priority thread becomes ready to run, the currently running lower priority thread is
suspended, and the CPU is assigned to the higher priority thread. In this scheme, a thread
can run only when no other higher priority thread is ready to run.
2.Flexibility to vary quantum size dynamically. A simple round-robin scheduling
scheme assigns a fixed-length quantum to timeshare the CPU cycles among the threads.
However, a fixed-length quantum is not appropriate on amultiprocessor system because
there may befewer runnable threads than there are available processors. In this case, it
would be wasteful to interrupt a thread with a context switch to the kernel when its
quantum runs out only to have itplacedrightback in the running state. Therefore, instead
of using a fixed-length quantum, a scheduling scheme may vary the size of the time
quantum inversely with the total number of threads in the system. This algorithm gives
good response time to short requests, even on heavily loaded systems, but provides high
efficiency on lightly loaded systems.
3.Handoffscheduling. Ahandoffscheduling scheme allows a thread to name its
successor if it wants to. For example, after sending a message to anotherthread, the
sending thread can give up the CPU and request that the receiving thread be allowed to
run next. Therefore, this scheme provides the flexibility to bypass the queue of runnable
threads and directly switch the CPU to the thread specified by the currently running
thread.Handoff scheduling can enhance performance if itiswisely used.
4.Affinityscheduling. Another scheduling policy that may be used for better
performance on amultiprocessor system is affinity scheduling. In this scheme, a thread is
scheduled on the CPU it last ran on in hopes that part ofits address space is still in that
CPU'scache.Sec. 8.3 • Threads 407
SignalHandling
Signalsprovide software-generated interrupts andexceptions. Interrupts areexternally
generated disruptions ofathreadorprocess, whereas exceptions arecausedbythe
occurrence ofunusual conditions duringathread's execution. Thetwomainissues
associated withhandling signalsin amultithreaded environment are asfollows:
1. Asignalmustbehandledproperly nomatterwhichthreadoftheprocessreceives
it.RecallthatinUNIXasignal's handler mustbe aroutinein theprocess
receiving thesignal.
2.Signalsmustbeprevented fromgettinglost. Asignalgets lost whenanothersignal
ofthesametypeoccursinsomeotherthreadbeforethe first one is handledby the
threadinwhichitoccurred. Thishappens becauseanexception condition causing
thesignalis'storedin aprocesswide globalvariablethatisoverwritten byanother
exception condition causingasignalofthesametype.
Anapproach forhandling theformerissueis tocreateaseparate exception handler
threadineachprocess. In thisapproach, theexception handlerthreadofaprocessis
responsible forhandling allexception conditions occurring in anythreadoftheprocess.
Whenathreadreceives asignalfor anexception condition, itsendsanexception
occurrence message to theexception handler threadand waits until the exception is
handled. Theexception message usually includes information abouttheexception
condition, thethread,and theprocessthatcausedtheexception. Theexception handler
threadperforms itsfunction according to the type ofexception. Thismayinvolvesuch
actionsasclearing theexception, causingthevictimthreadtoresume,orterminating the
victimthread.
On theotherhand, an approach forhandling thelatterissueis toassigneachthread
itsownprivateglobalvariables forsignaling exception conditions, so thatconflicts
between threadsoverthe useofsuchglobalvariables neveroccur.Suchvariables are said
to bethreadwide globalbecause thecodeofathreadnormally consists ofmultiple
procedures. In thisapproach, newlibraryprocedures areneededtocreate,set, andread
thesethreadwide globalvariables.
8.3.4Implementing a Threads Package
Athreadspackage can beimplemented eitherin userspaceor in the kernel.In the
description below, the two approaches arereferred to asuser-level andkernel-level,
respectively. In theuser-level approach, theuserspaceconsistsofaruntime system
that is a collection ofthreadsmanagement routines. Threads run in the user spaceon
topoftheruntime systemand are managed by it.Theruntime systemalsomaintains
astatusinformation tabletokeeptrackofthecurrentstatusofeachthread.This
tablehas one entryperthread.Anentryofthistablehas fields for registers' values,
state,priority, andotherinformation ofathread.Allcallsof thethreadspackage are
implemented ascallsto theruntime systemprocedures thatperform thefunctions
corresponding to the calls. Theseprocedures alsoperform threadswitching if the408 Chap.8 •ProcessManagement
thread that made the call has to be suspended during the call. That is, two-level
scheduling isperformed in this approach. The scheduler in the kernel allocates
quantatoheavyweight processes, and thescheduler ofthe runtime system divides a
quantum allocated to aprocessamong the threads of that process. In this manner,
theexistence of threads is made totally invisible to the kernel. The kernel functions
in amanner similarto anordinary kernel that manages only single-threaded,
heavyweight processes. This approach is used by the SunOS 4.1 Lightweight
Processes package.
On the other hand, in the kernel-level approach, no runtime system is used and the
threads are managed by the kernel. Therefore, the threads status information table is
maintained within the kernel. All calls that might block a thread are implemented as
system calls that trap to the kernel. When a thread blocks, the kernel selects anotherthread
to be run. The selected thread may belong to eitherthe same processas thatofthe
previously running thread or a different process.Hence, the existence ofthreads is known
to the kernel, and single-level scheduling is used in this approach.
Figure 8.9 illustrates the twoapproaches forimplementing a threads package. The
relativeadvantages anddisadvantages oftheapproaches are as follows:
T Processes andtheirthreads
User
18P8ce
Runtimesystem
(maintains threadsstatusinformation)
Kernel Kernel
SPice(maintains processes statusinformation)
(a)
."ig.8.9 Approaches for implementing a
threads package: (a)user level;
(b)Kemellevel.Processes andtheirthreads
Kernel
(maintains threadsstatus information)
(b)T
User
il-----------I
Kernel
space.L ----'Sec. 8.3 • Threads 409
1. Themostimportant advantage oftheuser-level approach isthatathreadspackage
can beimplemented on topofanexistingoperating systemthatdoes not supportthreads.
This is not possible in thekernel-level approach becausein thisapproach theconceptof
threadsmust be incorporated in thedesignofthekernelofanoperating system.
2. In the user-level approach, due to the use oftwo-level scheduling, usershave the
flexibility to usetheirowncustomized algorithm toschedule thethreadsofaprocess.
Therefore, depending on theneedsofanapplication, ausercandesignand use the most
appropriate scheduling algorithm for theapplication. This is not possible in thekernel­
levelapproach because asingle-level scheduler isusedthatis built into the kernel.
Therefore, users only have the flexibility tospecifythroughthesystemcallparameters the
priorities to beassigned to thevariousthreadsofaprocessand toselectanexisting
algorithm from a set ofalreadyimplemented scheduling algorithms.
3.Switching thecontextfrom one threadtoanother isfasterin theuser-level
approach than in the kernel-level approach. Thisisbecausein theformerapproach context
switching isperformed bytheruntimesystem,whilein thelatterapproach a trap to the
kernelisneededforit.
4. In the kernel-level approach, thestatusinformation tableforthreadsismaintained
within the kernel.Due to this, the scalability ofthekernel-level approach ispooras
compared to theuser-level approach.
5. Aseriousdrawback associated with the user-level approach is that with this
approach the useofround-robin scheduling policytotimeshare theCPUcyclesamongthe
threadson aquantum-by-quantum basis is not possible [Tanenbaum 1995].Thisis due to
the lack of clockinterrupts withinasingleprocess. Therefore, onceathreadisgiventhe
CPUto run, there is no way to interrupt it, and it continues to run unless it voluntarily
givesuptheCPU.This is not the case with the kernel-level approach, inwhichclock
interrupts occurperiodically, and thekernelcankeeptrackoftheamountofCPUtime
consumed by athread.Whenathreadfinishes using its allocated quantum, it can be
interrupted bythe kernel, and the CPUcan be given to another thread.
Acrudeway tosolvethisproblem is to have the runtime systemrequestaclock
interrupt aftereveryfixed unit oftime (say everyhalfasecond) to give it control
[Tanenbaum 1995].Whentheruntimesystemgetscontrol,thescheduler candecideifthe
threadshouldcontinue runningor theCPUshouldnow beallocated toanotherthread.
6.Another drawback oftheuser-level approach isassociated with the implementa­
tionofblocking systemcalls. In the kernel-level approach, implementation ofblocking
systemcalls isstraightforward because whenathreadmakessuch a call, ittraps to the
kernel,where it is suspended, and thekernelstartsa newthread.However, in the user­
levelapproach, athreadshouldnot beallowed tomakeblocking systemcalls directly.
Thisisbecauseif athreaddirectlymakesablocking systemcall, allthreadsofitsprocess
will bestopped, and thekernelwillschedule anotherprocessto run.Therefore, thebasic
purposeofusingthreadswill be lost.
Acommonly usedapproach toovercome thisproblem is to use jacketroutines. A
jacketroutinecontains extracodebeforeeachblocking systemcall to first makeacheck410 Chap.8 •ProcessManagement
to ensure if the call will cause a trap to the kernel. The call is made only if it is safe (will
not cause a trap to the kernel); otherwise the thread is suspended and another thread is
scheduled to run. Checking the safety condition and making the actual call must be done
atomically.
With some success, few attempts have been made tocombine the advantages of user­
level and kernel-level approaches in the implementation of a threads package. For
example, the FastThreads package [Anderson et al. 1991] and the threads package of the
Psychemultiprocessor operating system [Marsh et aJ. 1991] provide kernel support for
user-level thread scheduling. On the other hand, Mach [Black 1990] enables user-level
code to provide scheduling hints to the kernel'sthread scheduler. The details of threads
implementation in Mach is given in Chapter 12.
8.3.5(aseStudy:DCEThreads
The C Threads package developed for the Mach operating system and the Lightweight
Processes package developed for the SunOS are two examples of commercially
available threads packages. In addition, to avoid incompatibilities between threads
designs, IEEE has drafted a POSIX (Portable Operating System Interface for Computer
Environments) threads standard known as P-Threads. Twoimplementations of this
standard are the DCE Threads developed by the Open Software Foundation (OSF) for
theOSF/Ioperating system and the GNU Threads developed by the Free Software
Foundation for the SunOS. The DCEThreads package, which is based on the PlOO3.4a
POSIX standard, is described below as a case study. A description of another threads
package, the C Threads package, is given in Chapter 12 as a part of the description of
the Mach operating system.
The user-level approach is used for implementing the DCEThreads package. That is,
DCE provides a set of user-level library procedures for the creation, termination,
synchronization, and so on, of threads. Toaccess thread services from applications written
in C,DeEspecifies an application programming interface (API) that is compatible to the
POSIX standard. If a system supporting DeEhas no intrinsic support for threads, theAPI
provides an interface to the DCE threads library that is linked to application procedures.
On the other hand, if a system supporting DCEhas operating system kernel support for
threads, the DCE is set up to use this facility. In this case, the API serves as an interface
to the kernel-supported threads facility.
ThreadsManagement
TheDeEThreads package has a number of library procedures for managing threads.
Some of the important ones are as follows:
•pthread_create is used to create a new thread in the same address space as the
calling thread. The thread executes concurrently with its parent thread. However,
instead of executing the parent'scode, it executes a procedure whose name is
specified as an input parameter to thepthread_create routine.Sec.8.3 • Threads 411
•pthread_exit is used to terminate thecallingthread.Thisroutineiscalledby a
threadwhenithasfinished doingits work.
•pthreadjjoinis used to causethecaningthreadtoblockitselfuntil the thread
specified in thisroutine's argument terminates. Thisroutineissimilarto thewait
systemcallofUNIX and may be usedby aparentthreadto wait for a childthread
tocomplete execution.
•pthread_detach is used by a parentthread to disownachildthread.Bycalling
pthread_detach, theparentthreadannounces that thespecified childthreadwill
neverbepthreadjjoined(waitedfor). If the childthreadevercallspthread_exit,
itsstackandotherstateinformation areimmediately reclaimed. Innormalcases,
thiscleanuptakesplaceaftertheparenthasdoneasuccessful pthreadjjoin.
•pthread_cancel is used by a threadto killanotherthread.
•pthread_setcancel is used by a threadtoenableordisableabilityofotherthreads
to kill it. Itallowsathreadtopreventit fromgettingkilledbyanotherthreadat
suchtimeswhenkillingthethreadmighthavedevastating effects,forexample, if
thethreadhas amutexvariable lockedat the time.
ThreadsSynchronization
TheDeEThreads package provides supportfor both mutexvariables andcondition
variables forthreadssynchronization. Mutexvariables are used when accessto ashared
resource bymultiple threadsmustbemutually exclusive in time. On the otherhand,
condition variables are used with mutexvariables toallowthreadstoblockand wait for
asharedresource alreadylockedbyanotherthreaduntil the threadusingitunlocksitand
signalsthewaitingthread.
TheDeEThreads package supports thefollowing typesofmutexvariables, which
differin how they deal with nestedlocks:
1. Fast.A fastmutexvariable is one that causesathreadtoblockwhen the thread
attempts to lock an alreadylockedmutexvariable. Thatis,nestedlockingofa fastmutex
variable is notpermitted. Notethat fast mutex variables may lead to deadlock. For
instance, ifathreadtries to lock the samemutexvariableasecondtime, adeadlock will
occur.
2.Recursive. Arecursive mutexvariable is one that allowsathreadto lock an
alreadylockedmutexvariable. Thatis,nestedlockingofarecursive mutexvariable is
permitted witharbitrarily deepnestings. Noticethatrecursive mutexvariables willnever
lead todeadlock, Itis theresponsibility oftheapplication programmers toultimately
unlockarecursive mutexvariable asmanytimesas it islocked.
3.Nonrecursive. Anonrecursive mutexvariable is one that neitherallowsathread
tolockanalreadylockedrnutexvariable norcausesthethreadtoblock.Rather,anerror
isreturned to thethreadthatattempts to lock an alreadylockednonrecursive mutex
variable. Noticethatnonrecursive mutexvariables avoidthedeadlock problem associated
with fast mutexvariables.412 Chap.8 •ProcessManagement
Some of the main DeEthread calls for threads synchronization are as follows:
•pthread_mutex_init is used to dynamically create a mutex variable.
•pthread_mutex_destroy is used to dynamically delete a mutex variable.
•pthread_mutex_lock is used to lock a mutex variable. If the specified mutex
variable isalready locked, the thread that makes thiscall isblocked untilthe mutex
variable is unlocked.
•pthread_mutex_trylock is used to make an attempt to lock a mutex variable. If the
mutex variableis already locked, thecalJreturns withan unsuccessful result rather
than causing the thread to block.
•pthread_mutex_unlock is used to unlock a mutex variable.
•pthread_cond_init is used to dynamically create a condition variable.
•pthread_cond_destroy is used to dynamically delete a condition variable.
•pthread_cond_wait is used to wait on a condition variable. The calling thread
blocks until a pthread_cond_signal or apthread_cond_broadcast is executed for
the condition variable.
•pthread_cond_signal is used to wake up a thread waiting on the condition
variable. If multiple threads are waiting on the condition variable, only one thread
is awakened; others continue to wait.
•pthread_cond_broadcast is used to wake up all the threads waiting on the
condition variable.
Another area where mutual exclusion is needed is in the use of UNIXlibrary
procedures. The standard library procedures of UNIX are not reentrant. Therefore, to
prevent inconsistencies that may be caused by.threads switching occurring at arbitrary
points in time, it is necessary to provide mutual exclusion for the individual calls.
DeEsolves this problem by providing jacketroutinesforanumber of nonreentrant
UNIX system calls (mostly 110procedures). Threads call the jacketroutines instead of the
UNIX system calls. The jacketroutines take necessary action on behalfof the thread
before or after invoking the system call to avoid any potential problem. For example, the
jacketroutines ensure that only one thread calls any particular service at a time.
For several other UNIX procedures, DeEprovides a single global mutex variable to
ensure that only one thread at a time is active in the library.
ThreadsScheduling
TheDeEThreads package supports priority-based threads scheduling. It allows the users
to specify not only the priorities for individual threads but also the scheduling algorithm
tobeused so that important threads can take priority over other threads, getting the
necessary CPU time whenever they need it. Auser can choose from one of the following
threads-scheduling algorithms:
I.Firstin,firstout(FIFO).In this method, the first thread of the first nonempty
highest priority queue is always selected to run. The selected thread continues to executeSec.8.3 • Threads 413
untiliteither blocks or exits. After the thread finishes execution, the same method is used
to select a new thread for CPU allocation. The algorithm may cause starvation of low­
priority threads.
2.Roundrobin (RR). In this method, also, the first nonempty highest priority queue
is located. However, instead of running the first thread on this queue to completion, all the
threads on this queue are given equal importance by running each thread for a fixed
quantum in around-robin fashion. This algorithm mayalso cause starvation of low­
priority threads.
3. Default. In this method, the threads on all the priority queues are run one after
another using a time-sliced, round-robin algorithm. The quantum allocated to a thread
variesdepending on its priority; the higher the priority, the larger thequantum. Notice that
in this algorithm there is no starvation because all threads get to run.
The following system calls allow users to select a scheduling algorithm of their
choice and to manipulate individual threads priorities:
•pthread_setscheduler is used to select a scheduling algorithm.
•pthreadgetscheduler is used to know which scheduling algorithm is currently in
effect.
•pthreadsetprio is used to set the scheduling priority of a thread.
• pthread getprio is used to know the scheduling priority of a thread.
SignalHandling
Signals may be generated due to either an exception condition occurring during a thread's
execution, such as a segmentation violation, or a floating-point exception or due to an
external interrupt, such as when t.heuser intentionally interrupts the running process by
hitting the appropriate key on the keyboard. In DeE,anexception condition is handled by
the thread in which it occurs. However, an external interrupt is handled by all the
concerned threads. That is, when an external interrupt occurs, the threads package passes
it to all the threads that are waiting for the interrupt.
DeEalso includes the POSIX sigwaitandsigaction services that may be used for
signal handling instead of catching signal handlers in the traditional way.These services
operate at a different level than signal handlers but can achieve the same results. The
sigwaitservice allows a thread to block until one of a specified set of interrupt-based
signals (also known asasynchronous signals) isdelivered. On theother hand, the sigaction
service allows for per-thread handlers to be installed for catching exception-based signals
(also known as synchronous signals).
ErrorHandling
TheUNIXsystem calls as well as the standard PlOO3.4aP-Threads calls report errors by
setting a global variable, errno,and returning -1.In this method of handling errors, an
error may get lost when the global errnovariable is overwritten by an error occurring in414 Chap.8 •ProcessManagement
some other thread before the previous errnovalue is seen and handled by the thread in
which it occurred. To overcome this problem, each thread in DeEhas its own private
errnovariable for storing its own error status. This variable is saved and restored along
with other thread-specific items upon thread switches. The error-handling interface of
DeEallows the programmers to inspect the value of this variable. Another method that
maybeused inDeEfor error handling is to have system calls raise exceptions when
errors occur.
8.4SUMMARY
This chapter has presented a description of the two important process management
concepts in distributed operating systems: process migration and threads.
Process migration deals with the transparent relocation of a process from one node
to another in a distributed system. Aprocess may be relocated before it starts executing
or during the course of its execution. The former is called non-preemptive process
migration and the latter is known as preemptive process migration. Preemptive process
migration is costlier than non-preemptive process migration because the handling of the
process's state, which must accompany the process to its new node, becomes much more
complex after execution begins.
Process migration policy deals with the selection of a source node from which to
migrate a process, a destination node to which the process will be migrated, and the
migrant process. These selection decisions are taken by a suitable global scheduling
algorithm used for the process migration policy. Onthe other hand, a process migration
mechanism deals with the actual transfer of the process from its source node to its
destination node and the forwarding and handling of related messages during and after
migration. The commonly used method for preemptive process migration is to freeze the
process on its source node, transfer its state information to its destination node, and restart
the process on its destination node using this state information.
The cost of migrating a process isdominated by the time taken to migrate its address
space. Total freezing, pretransferring, and transfer on reference are the mechanisms used
by the existing systems for address space transfer. The different mechanisms used for
message forwarding in the existing distributed systems are the mechanism of resending
the message, the origin site mechanism, the link traversal mechanism, and the link update
mechanism. The two different mechanisms for communication between a process and its
subprocesses that might have been migrated and placed on different nodes are the logical
host concept and the home node or origin site concept.
Process migration in heterogeneous systems becomes more complex than in
homogeneous systems due to the need for data translation from the source node data
format to the destination node data format. The external data representation mechanism
helps in reducing the software complexity of this translation process. Of the various types
of data, such as characters, integers, and floating-point numbers, the handling of floating­
point numbers needs special precautions.
The existing implementations of process migration facility have shown that
preemptive process migration is possible, although with higher overhead and complexityChap. 8 • Exercises 415
thanoriginally anticipated. The cost of migration led some system designers to conclude
that it is not a viable alternative, while others disagree. However, the topic is still an active
research area with mixed reactions.
Threads are an increasingly popular wayto improve application performance through
parallelism. In operating systems with t.hreadsfacility, a process consists of an address
space and one or more threads of control. Each thread ofaprocess has its own program
counter, its own registerstates, and its own stack. But all the threads of a process share
the same address space. Threads are often referred to as lightweight processes, and
traditional processes are referred to as heavyweight processes.
A major motivation for threads is to minimize context switching time, allowing the
CPU to switch from one unit of computation to another unit of computation with minimal
overhead. Another important motivation for threads isto allow parallelism to becombined
with sequential execution and blocking system calls. The use of threads is also motivated
by the fact that a set of threads using a shared address space is the most natural way to
program many applications.
The three commonly used ways to organize the threads of a process are the
dispatcher-workers model, the team model, and the pipeline model,
The set of primitives provided to users for threads-related operations are said to form
a threads package. Some of the important issues in designing a threads package are
creation, termination, synchronization, and scheduling of threads and handling of signals
and errors.
A threads package can be implemented either in user space or in the kernel. Both
approaches have their own advantages and limitations.
EXERCISES
8.1.Differentiate between preemptive andnon-preemptive processmigration. What are their
relativeadvantages anddisadvantages? Suppose you have to design a process migration
facility for a distributed system. What factors will influence yourdecision to design a
preempti ve or anon-preemptive processmigration facility?
8.2.What are some of the main issues involved in freezing a migrant process on its source node
andrestarting it on itsdestination node? Give a method for handling each of these issues.
8.3.What are the main similarities anddifferences between theimplementation of thefollowing
twoactivities:
(a)Interrupting aprocess toexecute ahigherpriority process and then restarting the
interrupted processafter some time on the same node
(b)Freezing amigrant process and then restarting it on adifferent node
8.4.From the point of view of supporting preemptive processmigration facility, is a stateless or
statefulfileserverpreferable? Give reasons for your answer.
8.S.When a migrantprocessisrestarted on itsdestination node after migration, it is given the
sameprocessidentifier thatithad on its source node. Is this necessary? Give reasons for your
answer.
8.6. The cost of migrating a process is dominated by the time taken to transferits address space.
Suggestsomemethods that may be used to minimize this cost.416 Chap. 8 • Process Management
8.7. A distributed system supports DSM (Distributed Shared Memory) facility. Suggest a suitable
address space transfer mechanism that you will use to design a process migration facility for
this system.
8.8.Which one or more of the address space transfer mechanisms described in this chapter are
suitable for a process migration facility with the following goals?
(a) High performance is the main goal.
(b) High reliability is the main goal.
(c) Effectiveness ofprocess migration policy is the main goal.
(d) Simple implementation is the main goal.
(e) Both reliability and effectiveness of process migration policy are important goals.
If more than one mechanism is suitable for a particular case, which one will you prefer to use
and why?
8.9. Which one or more of the message-forwarding mechanisms described in this chapter are
suitable for a process migration facility with the following goals?
(a) Transparency is the main goal.
(b) Reliability is the main goal.
(c) Performance is the main goal.(d) Simple implementation is the main goal.
If more than one mechanisms are suitable for a particular case, which one will you prefer to
use and why?
8.10. Which of the mechanisms described in this chapter to handle communication among
coprocesses are suitable for a process migration facility with the following goals?
(a) Performance is the main goal.
(b) Reliability is the main goal.
(c) Simple implementation is the main goal.
If more than one mechanisms are suitable for a particular case, which one will you prefer to
use and why?
8.11. What are some of the main issues involved in designing a process migration facility for a
heterogeneous distributed system?
8.12. The process migration facility of a distributed system does not allow free migration of
processes from one node to another but has certain restrictions regarding which node's
processes can
bemigrated to which other nodes of the system. What might be the reasons
behind imposing such a restriction?
8.13. When should the external data representation mechanism be used in the design of a process
migration facility? Suppose you have to design the external data representation format for a
process migration facility. What important factors will influence your design decisions?
8.14. A distributed system has three types of processors A, B,and C.The numbers of bits used for
the exponent of a floating-point number by processors of types A,B,and C are 8, 12,and 16,
respectively; the numbers of bits used for the mantissa of a floating-point number by
processors of types At B,andCare16,32, and 64, respectively. In this system, from which
processor type to which processor type should process migration be allowed and from which
processor type to which processor type should processor migration not be allowed? Give
reasons for your answer.
8.15. List some of the potential advantages and disadvantages of process migration.
8.16. In operating systems in which a process is the basic.unit of CPU utilization, mechanisms are
provided to protect a process from other processes. Do operating systems in which a thread
is the basic unit of CPU utilization need to provide similar mechanisms to protect a thread
from other threads? Give reasons for your answer.Chap. 8 • Exercises 417
8.17.Theconceptofthreadsis often used in distributed operating systemsforbetterperformance.
Can this concept also be useful for betterperformance inothermultiprocessor operating
systems and inoperating systemsforconventional centralized time-sharing systems? Give
reasons for youranswer.
8.18. List the maindifferences andsimilarities between threads and processes.
8.19.What are the main advantages anddisadvantages of using threads insteadofmultiple
processes? Give anexample of anapplication that would benefit from the use of threads and
anotherapplication that would not benefitfrom the use of threads.
8.20.In adistributed system,parallelism improves performance andblocking systemcalls make
programming easier.Explain how the conceptofthreads can be used to combine both
advantages.
8.21.Give an example to show howaserverprocesscan bedesigned tobenefitfrom the
concurrency madepossible by threads. Now give an example to show how a clientprocess
can bedesigned tobenefitfrom the concurrency madepossible by threads.
8.22.Give asuitableexample for each of the following:
(a) Anapplication in which a process usesmultiple threadsthat are organized in the
dispatcher-workers model
(b) Anapplication in which a process uses multiple threads that are organized in the team
model
(c) Anapplication in which a process uses multiple threads that are organized in thepipeline
model
8.23.Afileserverworks in the following manner:
(a)Itacceptsa client request for file access.
(b)Itthen tries to service the requestusing data in a cache that it maintains.
(c) If the requestcannotbeserviced from the cacheddata,itmakes a requestto the disk
serverfor the data and sleeps until a reply is received. On receiving the reply, it caches
the data received andservices theclient'srequest.
Assumethat the hit ratio for the cache is0.7. That is, 70% of all the requests are serviced using
cacheddata and access to disk server is neededonly for serving 30% of all requests. Also
assume that, on acache hit, the request servicetime is 20msec and on acache miss the request
servicetime is 100msec. How many requests per second can beserviced if the file serveris
implemented asfollows?
(a) Asingle-threaded process
(b) Amultithreaded process
Assume that threadsswitching time isnegligible.
8.24.Differentiate between handoffscheduling and affinity scheduling of threads. In your opinion,
which of the two is a more desirable feature for a threads package and why?
8.25. Write pseudocode for athreads-scheduling algorithm thatprovides the flexibility to vary
quantum sizedynamically and also supports handoffscheduling.
8.26.What are the main issues in handling signals in a multithreaded environment? Describe a
method for handling each of these issues.
8.27.Discusstherelativeadvantages anddisadvantages ofimplementing a threads package in user
space and in the kernel.
8.28.Theoperating systemofacomputer usesprocesses as the basic unit of CPU utilization. That
is,it does not supportthreads. Can threads facilitybeprovided in thiscomputer system
without modifying theoperating system kernel? If no, explain why. If yes, explainhow.418 Chap.8 • Process Management
BIBLIOGRAPHY
[Agrawal and Ezzat 1987] Agrawal, R., and Ezzat, A. K., "Location Independent Remote
Executionin NEST," IEEE Transactions on Software Engineering, Vol.SE-13,No.8(1987).
[Alonsoand Kyrimis1988] Alonso,R.,and Kyrimis,K.,"AProcessMigration Implementation for
a UNIXSystem,"In: Proceedings ofthe Winter 1988UsenixConference, UsenixAssociation,
Berkeley, CA(February 1988).
[Anderson et al.1991]Anderson, T. E., Bershad, B. N., Lazowska, E. D., and Levy, H. M.,
"Scheduler Activations: EffectiveKernelSupportfor the User-Level Managementof Parallel­
ism,"In: Proceedings ofthe 13thACM Symposium on Operating System Principles, Association
for Computing Machinery, NewYork,NY,pp. 95-109 (1991).
[ArtsyandFinkel 1989]Artsy, Y.,andFinkel,R.,"Designinga ProcessMigrationFacility," IEEE
Computer, Vol.22, pp.47-56(1989).
[Black1990]Black, D., "Scheduling Support for Concurrency andParallelism in the Mach
OperatingSystem," IEEE Computer, Vol.23, pp. 35-43 (1990).
[Butterfield and Popek 1984] Butterfield, D. A., and Popek, G. 1,"Network Tasking in the
LOCUSDistributedUNIXSystem," In: Proceedings ofthe Summer 1984Usenix Conference,
UsenixAssociation, Berkeley, CA, pp.62-71 (June 1984).
[Cheriton 1988]Cheriton,D. R.,"The V Distributed System," Communications ofthe ACM, Vol.
31,No.3,pp. 314-333 (1988).
[Coulouris et al, 1994J Coulouris, G. F., Dollimore, 1., andKindberg, T.,Distributed Systems
Concepts and Design, 2nded.,Addison-Wesley, Reading,MA (1994).
[Douglisand Ousterhout 1987]Douglis,F.,and Ousterhout, J., "ProcessMigrationin theSprite
Operating System," In: Proceedings ofthe 7th International Conference on Distributed
Computing Systems, IEEE,New York,NY,pp. 18-25 (September 1987).
[DougUsandOusterhout 1991]Douglis,F.,and Ousterhout, J.,"Transparent ProcessMigration:
DesignAlternatives and the Sprite Implementation," Software-Practice and Experience, Vol.
21, pp. 757-785 (1991).
[Draves et al, 1991] Draves, R. P., Bershad, B. N., Rashid, R. F., and Dean, R. W., "Using
Continuations toImplementThread Management andCommunication inOperatingSystems,"In:
Proceedings ofthe 13th ACM Symposium on Operating System Principles, Association for
Computing Machinery, NewYork,NY,pp. 122-136 (1991).
[FerrariandSunderam 1995]Ferrari,A., and Sunderam, V.S., "TPVM: Distributed Concurrent
ComputingwithLightweightProcesses,"In: Proceedings ofthe 4th International Symposium on
High Performance Distributed Computing (August1995).
[Goscinski 1991]Goscinski, A.,"Distributed Operating Systems,The LogicalDesign," Addison­
Wesley,Reading,MA (1991).
[Huang et al, 1995] Huang,C., Huang, Y.,andMcKinley, P.K., "A Thread-Based Interfacefor
Collective Communication onATMNetworks," In:Proceedings ofthe 15th International
Conference on Distributed Computing Systems, IEEE,New York,NY(May-June 1995).
[Hunter1988]Hunter,C., "Process Cloning:A System for Duplicating UNIXProcesses," In:
Proceedings ofthe Winter 1988Usenix Conference, UsenixAssociation, Berkeley, CA(February
1988).
[Ju11989]Jul,E.,"Migrationof Light-Weight ProcessesinEmerald," tcosNewsletter, Vol.3,No.
1,pp.20-23(1989).Chap.8 • Bibliography 419
[Jul et al. 1988] Jul, E.,Levy,H.,Norman,H., andAndrew,B.,"Fine-Grained Mobilityinthe
Emerald System," ACMTransactions onComputer Systems, Vol. 6,No.1,pp.109-133
(1988).
[Kingsbury andKline 1989) Kingsbury, B.A.,and Kline, J. T.,"JobandProcessRecovery in a
UNIX-Based Operating System," In:Proceedings oftheWinter1989UsenixConference, Usenix
Association, Berkeley, CA, pp.355-364 (1989).
[Litzkow 1987]Litzkow,M.1.,"Remote UNIX-Turning IdleWorkstations intoCycleServers,"
In:Proceedings oftheSummer 1987UsenixConference, UsenixAssociation, Berkeley, CA(June
1987).
[1.101989]Lo,V.M.,"Process Migration forCornmunication Performance," TCOSNewsletter, Vol.
3,No.1,pp.28-30(1989).
[Lockhart 1994JLockhart, Jr., H. W., OSFDC'E:GuidetoDeveloping Distributed Applications,
IEEEComputer SocietyPress, Los Alamitos, CA(1994).
[Maguire andSmith1988]Maguire, Jr.,G.Q. andSmith,1M.,"Process Migration: Effectson
Scientific Computation," ACM-SIGPLAN Notices, Vol. 23,No.3,pp.102-106 (1988).
[Mandelberg andSunderam 1988]Mandelberg, K.I.,andSunderam, V.S.,"Process Migration in
UNIXNetworks," In:Proceedings oftheWinter1988UsenixConference, UsenixAssociation,
Berkeley, CA(February 1988).
[Marsh etale1991]Marsh,B.D.,Scott,M. L.,LeBlanc, T.J., andMarkatos, E.P.,"First-Class
User-Level Threads," In:Proceedings oftheJ3thACMSymposium onOperating System
Principles, Association forComputing Machinery, NewYork, NY, pp. 110-121 (1991).
[MuIJender et al, 1990] Mullender, S..J.,VanRossum,G., Tanenbaum, A.S.,VanRenesse,R.,and
VanStaverene, H.,"Amoeba: ADistributed Operating Systemfor the 1990s," IEEEComputer,
Vol. 23,No.5,pp.44--53(1990).
[Nutt1991]NUH,G. L,Centralized andDistributed Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ(1991).
[PopekandWalker 1985]Popek,G.r,andWalker,B.r,TheLOCUS Distributed System
Architecture, MIT Press, Cambridge, MA (1985).
[PowellandMiller1983]Powell,M.L.,andMiller,B.P.,"Process Migration inDEMOS/MP," In:
Proceedings ofthe 9thACMSymposium onOperating SystemPrinciples, Association for
Computing Machinery, New York, NY,pp.110-119 (November 1983).
[Rosenberry et al. 1992) Rosenberry, W.,Kenney, D., and Fisher, G.,OSFDISTRIBUTED
C()MPU71NG ENVIR()NMENT, Understanding DeE,O'Reilly &Associates, Sebastopol, CA
(1992).
[Schwan etaJ.1991]Schwan,K.,Zhou,H.,andGheith,A.,"Real-Time Threads," ACM-SIGOPS
Operating Systems Review,Vol. 25,No.4,pp.35-46(1991).
[Sinhaet al.1991]Sinha,P. K., Park. K., Jia,X.,Shimizu, K., and Maekawa, M.,"Process
Migration Mechanism intheGalaxyDistributed Operating System," In:Proceedings ofthe5th
International Parallel Processing Symposium, IEEE,New York, NY,pp.611-618 (April
1991).
[Smith1988]Smith,J. M.,HASurveyofProcess Migration Mechanisms," ACM-SIGOPS
Operating Systems Review,Vol. 22, pp. 28-40(July 1988).
[Stalling 1995]Stalling, W.,Operating Systems, 2nd ed., Prentice-Hall, Englewood Cliffs,NJ
(1995).
[Tanenbaum 1995]Tanenbaum, A. S.,Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ(1995).420 Chap. 8 • Process Management
[Tbeimer et al. 1985] Theimer, M. M., Lantz K. A., and Cheriton, D. R., "Preernptable Remote
Execution Facilities for the V System," In:Proceedings ofthe 10th ACMSymposium on
Operating System Principles, Association for Computing Machinery, New York, NY,pp. 2-12
(December 1985).
[Thekkath and Eggers 1994] Thekkath, R., and Eggers, S. J., "Impact of Sharing-Based Thread
Placement on Multithreaded Architectures," In:Proceedings ofthe21stInternational Symposium
onComputer Architecture, Association for Computing Machinery, New York,NY,pp. 176-186
(1994).
[Walker and Mathews 1989] 'Walker,B. 1.,and Mathews, R. M., "Process Migration in AIX's
Transparent Computing Facility (TCF)," TCOS Newsletter, Vol.3, No. I, pp. 5-7(1989).
[Zayas 1987] Zayas, E. R., "Attacking the Process Migration Bottleneck," In:Proceedings ofthe
11thACMSymposium on Operating Systems Principles, Association for Computing Machinery,
New York, NY,pp. 13-22(November 1987).
POINTERS TO818UOGRflPHIES ONTHEINTERNET
Bibliographies containing references onProcess Migration can be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributed/migrate.html
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedldshell.html
Bibliography containing references onThreads and Multithreading can be found at:
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/threads.htm1CHAPTER9
Distributed File
Systems
9.1INTRODUCnON
In acomputer system, a fileis a named objectthatcomesintoexistence byexplicit
creation, is immune to temporary failures in the system, and persists until explicitly
destroyed. The two main purposes of using files are as follows:
1. Permanent storage ofinformation. This is achieved by storing a fileon a
secondary storage media such as a magnetic disk.
2. Sharingofinformation. Files provide a natural and easy means of information
sharing. That is, a file can be createdby oneapplication and then shared with
different applications at a later time.
Afilesystemis asubsystem of anoperating system that performs file management
activities such asorganization, storing, retrieval, naming, sharing, and protection offiles.
It isdesigned to allow programs to use a set of operations thatcharacterize the file
abstraction and free the programmers fromconcerns about the details of space allocation
and layout of the secondary storage device. Therefore, a file system provides an
abstraction ofa storage device; that is, itis aconvenient mechanism for storing and
retrieving information from the storage device.
421422 Chap.9 • Distributed FileSystems
Adistributed file system provides similar abstraction to the users ofa distributed
system and makes it convenient for them to use files in a distributed environment. The
design and implementation of adistributed file system, however, is more complex than a
conventional file system due to the fact that the users and storage devices are physically
dispersed.
In addition to the advantages ofpermanent storage and sharing of information
provided by the file system of a single-processor system, a distributed file system
normally supports the following:
1. Remote information sharing. A distributed file system allows a file to be
transparently accessed by processes ofany node of the system irrespective of the file's
location. Therefore, a process on one node can create a file that can then be accessed at
a later time by some other process running on another node.
2. Usermobility. In adistributed system, user mobility implies that a user should not
be forced to work on a specific node but should have the flexibility to work on different
nodes atdifferent times. This property is desirable due toreasons such as coping with node
failures, suiting the nature of jobs of some users who need to work at different places at
different times, and enabling use of any of the several nodes in those environments where
workstations are managed as a common pool. A distributed file system normally allows
a user to work on different nodes at different times without the necessity of physically
relocating the secondary storage devices.
3. Availability. For better fault tolerance, files should be available for use even in the
event of temporary failure of one and more nodes of the system. To take care of this, a
distributed file system normally keeps multiple copies of a file on different nodes of the
system. Each copy is called a replicaof the file. In an ideal design, both the existence of
multiple copies and their locations are hidden from the clients.
4. Diskless workstations. Disk drives are relatively expensive compared to the cost
of most other parts in a workstation. Furthermore, since a workstation is likely to be
physically placed in the immediate vicinityofa user, the noise and heat emitted from a
disk drive are annoying factors associated with a workstation. Therefore, a diskless
workstation is more economical, is less noisy, and generates less heat. A distributed file
system, with its transparent remote file-accessing capability, allows the use of diskless
workstations in a system.
Adistributed file system typically provides the following three types of services.
Each can be thought of as a component of adistributed file system.
1. Storage service. It deals with the allocation and management of space on a
secondary storage device that is used for storage of files in the file system. It provides a
logical view ofthe storage system by providing operations for storing and retrieving data
in them. Most systems use magnetic disks as the secondary storage device for files.
Therefore, the storage service is also known as disk service. Furthermore, several systems
allocate disk space in units of fixed-size blocks, and hence, the storage service is also
known as block service in these systems.Sec. 9.2 • Desirable Features of a Good Distributed File System 423
2.Truefileservice.It isconcerned with the operations onindividual files, such as
operations foraccessing andmodifying thedatain files and for creatinganddeletingfiles.
Toperform theseprimitive fileoperations correctly andefficiently, typicaldesignissues
of a true file servicecomponent includefile-accessing mechanism, file-sharing semantics,
file-caching mechanism, filereplication mechanism, concurrency controlmechanism,
dataconsistency andmultiple copyupdateprotocol, and access controlmechanism. Note
that the separation of thestorageservicefrom the true file servicemakes it easy to
combine different methods ofstorageanddifferent storagemediain asinglefile
system.
3. Name service.Itprovides amapping between textnamesfor files and references
to files, that is, file lOs. Text namesarerequired because, asdescribed inChapter10, file
IDs areawkward anddifficultforhumanusers toremember and use. Most file systemsuse
directories toperform thismapping. Therefore, the name serviceis alsoknownas a
directory service.Thedirectory serviceisresponsible forperforming directory-related
activities such ascreation anddeletionofdirectories, addinga new file to a directory,
deleting a file from a directory, changing the name ofa file,movinga file from one
directory to another, and so on.
Thedesignandimplementation ofthestorageserviceofadistributed filesystemis
similarto that of the storageserviceof acentralized file system. Readersinterested in the
detailsof thestorageservicemayreferto any good book on operating systems
[Tanenbaum 1987,Silberschatz andGalvin1994]. The designandimplementation details
of the name servicewill bepresented in the next chapter. Therefore, thischapterwill
mainly deal with the designandimplementation issues of the true file servicecomponent
ofdistributed filesystems.
9.2DESIRA8lE FEATURES OFAGOOD DISTRI8UTED FilE
SYSTEM
A gooddistributed filesystemshould have the featuresdescribed below.
1.Transparency. Thefollowing four types of transparencies aredesirable:
•Structure transparency. Although notnecessary, forperformance, scalability, and
reliability reasons, adistributed filesystemnormally usesmultiple fileservers.
Each file serverisnormally a userprocessorsometimes a kernel processthat is
responsible forcontrolling a set of secondary storagedevices (used for file
storage)ofthe node on which itruns. Inmultiple file servers, the multiplicity of
fileserversshouldbetransparent to theclientsofadistributed filesystem.In
particular, clientsshouldnot know the numberorlocations ofthe fileserversand
thestoragedevices.Ideally, a distributed filesystemshouldlook to its clientslike
aconventional filesystemofferedby acentralized, time-sharing operating
system.424 Chap. 9 • Distributed File Systems
•Accesstransparency. Both local and remote files should be accessible in the same
way. That is, the file system interface should not distinguish between local and
remote files, and the file system should automatically locate an accessed file and
arrange for the transport ofdata to the client'ssite.
• Naming transparency. The name ofa file should give no hint as to where the file
islocated. Furthermore, a file should be allowed tomove from one node to another
in a distributed system without having to change the name of the file.
•Replication transparency. Ifafileisreplicated onmultiple nodes, boththeexistence
ofmultiplecopies and their locations should be hidden from theclients.
2. User mobility. In adistributed system, a user should not be forced to work on a
specific node but should have the flexibility to work on different nodes at different times.
Furthermore, the performance characteristics ofthe file system should not discourage
users from accessing their files from workstations other than the one at which they usually
work. One way to support user mobility is to automatically bring auser'senvironment
(e.g.,user'shome directory) at the time of login to the node where the user logs in.
3. Performance. Theperformance of a file system is usually measured as the average
amount of time needed to satisfy client requests. In centralized file systems, this time
includes the time foraccessing the secondary storage device on which the file is stored and
the CPU processing time. In a distributed file system, however, this time also includes
networkcommunication overhead when the accessed file is remote. Although acceptable
performance is hard to quantify, it is desirable that the performance of a distributed file
system should be comparable to that of a centralized file system. Users should never feel
the need to make explicit file placement decisions to improve performance.
4. Simplicity andeaseofuse.Several issues influence the simplicity and ease of use
of a distributed file system. The most important issue is that the semantics of the
distributed file system should be easy to understand. This implies that the user interface
to the file system must be simple and the numberofcommands should be as small as
possible. In an ideal design, the semantics ofa distributed file system should be the same
as that of a file system for a conventional centralized time-sharing system. Another
important issue for ease of use is that the file system should be able to support the whole
range of applications.
5. Scalability. It isinevitable that a distributed system will grow with time since
expanding the network by adding new machines or interconnecting two networks together
iscommonplace. Therefore, a good distributed file system should be designed to easily
cope with the growth ofnodes and users in the system. That is, such growth should not
cause serious disruption of service or significant lossofperformance to users. In short, a
scalable design should withstand high service load, accommodate growth of the user
community, and enable simple integration of added resources.
6.Highavailability. Adistributed file system should continue to function even when
partial failures occur due to the failure ofone or more components, such as a
communication link failure, a machine failure, or a storage device crash. When partial
failures occur, the file system may show degradation in performance, functionality, orSec. 9.2 • Desirable Features of a Good Distributed File System 425
both.However, thedegradation shouldbeproportional, in some sense, to the failed
components. Forinstance, itisquiteacceptable that the failure causestemporary lossof
serviceto small groupsof users.
Highavailability andscalability aremutually relatedproperties. Bothproperties call
for a design in which both control and data are distributed. Thisisbecausecentralized
entitiessuch as a centralcontroller oracentraldatarepository introduce both asevere
point of failure and a performance bottleneck. Therefore, a highly available andscalable
distributed filesystemshouldhavemultiple andindependent file servers controlling
multiple andindependent storagedevices. Replication of files at multiple serversis the
primarymechanism forproviding highavailability.
7. High reliability. In a good distributed filesystem,theprobability of lossofstored
datashouldbeminimized as far as practicable. Thatis, users should not feel compelled
to makebackupcopiesoftheir files becauseoftheunreliability ofthe system. Rather, the
filesystemshouldautomatically generate backupcopiesofcriticalfiles that can be used
in theeventof loss of the originalones.Stablestorageis apopulartechnique used by
several file systemsfor high reliability.
8. Data integrity. Afile isoftensharedbymultiple users. For a shared file, the file
systemmustguarantee theintegrityofdatastoredin it.Thatis,concurrent accessrequests
frommultiple users who are competing toaccessthe file must beproperly synchronized
by the use ofsome form of concurrency controlmechanism. Atomictransactions are a
high-level concurrency controlmechanism oftenprovided to the users by afilesystemfor
data integrity.
9.Security. Adistributed filesystemshouldbesecureso that its users can be
confident of theprivacy of their data. Necessary security mechanisms must be
implemented toprotectinformation storedin a file systemagainstunauthorized access.
Furthermore, passing rights to access a file should be performed safely; that is, the
receiverofrightsshouldnot be able topass them furtherifhe or she is not allowedto do
that.
Aconsequence oflarge-scale distributed systems is that the casual attitudetoward
securityis notacceptable. Afundamental question is whoenforces security. For this, the
generaldesignprinciple is that a systemwhosesecuritydepends on theintegrity ofthe
fewestpossible entitiesis more likely to remainsecureas it grows.
10. Heterogeneity. As aconsequence oflarge scale, heterogeneity becomes
inevitable indistributed systems. Heterogeneous distributed systems provide the
flexibility totheirusers to use different computer platforms fordifferent applications. For
example, a user may use a supercomputer forsimulations, aMacintosh fordocument
processing, and a UNIX workstation forprogram development. Easy access to shareddata
acrossthesediverseplatforms wouldsubstantially improve usability. Therefore, a
distributed filesystemshouldbedesigned to allow a variety of workstations toparticipate
in thesharingof files via the distributed filesystem.Another heterogeneity issue in file
systems is the ability to accommodate severaldifferent storagemedia.Therefore, a
distributed filesystemshouldbedesigned to allow the integration of a new type of
workstation orstoragemedia in a relatively simplemanner.426
9.3 FilEMODELSChap. 9 • Distributed File Systems
Differentfilesystemsusedifferentconceptualmodelsof a file.The two mostcommonly
usedcriteriaforfilemodelingare structureand modifiability. File modelsbasedon these
criteria are described below.
9.3.1Unstructured andStructured Files
Accordingtothesimplestmodel,a fileisan unstructuredsequenceofdata.Inthismodel,
there is no substructureknown to the file serverand the contents of each file of the file
system appears to the file server as an uninterpreted sequence of bytes. The operating
systemis notinterestedin theinformationstoredin the files.Hence,the interpretationof
the meaningand structureof thedata stored in the files are entirelyup to the application
programs. UNIXand MS-DOS use this file model.
Anotherfile modelthat israrely used nowadaysis the structuredfile model.In this
model, a file appears to the file server as an ordered sequence of records. Records of
differentfilesof the same file system can be of differentsize.Therefore, many typesof
filesexist ina filesystem,eachhavingdifferentproperties.In this model,a recordis the
smallestunitoffiledatathatcan beaccessed,andthefilesystemreador writeoperations
are carriedout on a set of records.
Structuredfilesareagainoftwo types-files withnonindexedrecordsandfileswith
indexedrecords.In the former model,a file record is accessed byspecifyingits position
withinthe file,for example, the fifth record from the beginningof the file or the second
record fromthe end of the file. In the latter model,recordshave one or more key fields
andcan beaddressedbyspecifyingthe valuesof thekeyfields.In filesystemsthatallow
indexedrecords,a file ismaintainedas a B-treeor other suitabledata structureor a hash
table is usedto locate recordsquickly.
Most modern operating systems use the unstructured file model. This is mainly
becausesharingofafilebydifferentapplicationsiseasierwiththeunstructuredfilemodel
ascomparedto the structuredfile model.Sincea filehas nostructurein the unstructured
model,differentapplicationscan interpret the contents of a file in different ways.
In additionto data items, files also normally have attributes. A file's attributesare
informationdescribingthatfile.Eachattributehasanameandavalue.Forexample,typical
attributesofafilemaycontaininformationsuchasowner,size,accesspermissions,dateof
creation,dateoflastmodification,anddateoflastaccess.Userscanreadandupdatesomeof
theattributevaluesusingtheprimitivesprovidedbythefilesystem.Notice,however,that
althoughausermayreadthevalueofanyattribute,notallattributesareuser modifiable. For
example,a user may update the value of the access permissionsattribute, but he or she
cannotchangethevalueofthesizeordateofcreationattributes.Thetypesofattributesthat
canbeassociatedwithafilearenormallyfixedbythefilesystem.However,a filesystem
maybedesignedtoprovidetheflexibilitytocreateandmanipulateuser-definedattributesin
additiontothosesupportedbythefilesystem.
File attributes are normally maintained and used by the directory service because
they are subject to different access controls than the file they describe. Notice thatSec.9.4 •File-Accessing Models 427
althoughfileattributes aremaintained andusedby the directoryservice,theyarestored
withthecorresponding fileratherthanwiththefilenamein the directory. Thisismainly
becausemanydirectorysystemsallowfilesto be referenced by morethanone name.
9.3.2Mutable QndImmutabl. Files
According to the modifiability criteria, files are of two types-mutable andimmutable.
Most existing operating systems use the mutable file model. In this model, an update
performed on a file overwrites on its old contents toproducethe new contents. Thatis, a
file isrepresented as a single stored sequence that is altered by each update operation.
On the other hand, some more recent file systems, such as the Cedar File System
(CFS) [Gifford et at1988], use the immutable file model. In this model, a file cannot be
modified once ithas been createdexcept to be deleted. The file versioning approach is
normally used to implement file updates, and each file is represented by a history of
immutable versions. That is, rather than updating the same file, a new version of the file
is created each time a changeis made to the file contents and the old version is retained
unchanged. In practice, the use of storage space may be reduced by keeping only a record
of thedifferences between the old and new versions rather than creating the entire file
once again.
Gifford et al. [1988] emphasized that sharing only immutable files makes it easy to
supportconsistent sharing. Due to this feature, it is much easier tosupport filecaching and
replication in a distributed system with the immutable file model because it eliminates all
the problems associated with keeping multiple copies of a file consistent. However, due
to the need to keep multiple versions of a file, the immutable file model suffers from two
potential problems-increased use of disk space and increased disk allocation activity.
Somemechanism is normally used to prevent the disk space from filling instantaneously.
For example, the CFS [Gifford et al. 1988]uses akeepparameter as the number ofmost
current versions of a file to be retained. To keep track of the most current versions, each
filename is suffixed with a version number, for example, "demo.abc!6" is a name for
version 6 of the file with the base name of demo.abc. Therefore, if the value of the keep
parameter of this file is 1,thecreation of a new version of the file will cause the file
demo.abc!6 to be deleted and its disk space to be reused for the new file named
demo.abel?When the value of the keepparameter isgreaterthan 1for a file, that is, when
multiple versions of a file exist, users may use a particular version of the file by specifying
its full name. However, when the version numberpart of a file is not specified, by default,
CFS uses the lowest version number for some operations, such asdelete,and highest
version number for other operations, such as open.
9.4FilE-ACCESSING MODELS
The manner in which a client'srequest to access a file is serviced depends on the file­
accessing model used bythe file system. The file-accessing model of a distributed file
system mainly depends on two factors-the method used for accessing remote files and
the unit of data access.428 Chap.9 • Distributed FileSystems
9.4.1Accessing kmot.FII.s
A distributed file system may use one of the following models to service a client'sfile
access request when the accessed file is a remote file:
1. Remote service model. In this model, the processing of the client'srequest is
performed at the server'snode. That is, the client'srequest for file access is delivered
to the server, the server machine performs the access request, and finally the result is
forwarded back to the client. The access requests from the client and the server replies
for the client are transferred across the network as messages. Notice that the data
packing and communication overheads per message can be significant. Therefore, if
the remote service model is used, the file server interface and the communication
protocols must be designed carefully to minimize the overhead of generating messages
as well as the number of messages that must be exchanged in order to satisfy a
particular request.
2. Data-caching model. In the remote service model, every remote file access
request results in network traffic. The data-caching model attempts to reduce the amount
of network traffic by taking advantage of the locality feature found in file accesses. In this
model, if the data needed to satisfy the client'saccess request is not present locally, it is
copied from the server'snode to the client'snode and is cached there. The client'srequest
is processed on the client'snodeitselfby using the cached data. Recently accessed data
are retained in the cache for some time so that repeated accesses to the same data can be
handled locally. A replacement policy, such as the least recently used (LRU),is used to
keep the cache size bounded.
Ascompared to the remote access model, this model greatly reduces network traffic.
However, in this model, there is a possibility that data of a particular file may
simultaneously be available in different caches. Therefore, a write operation often incurs
substantial overhead because, inaddition to modifying the locally cached copy of the data,
the changes must also be made in the original file at the server node and in any other
caches having the data, depending on the relevant sharing semantics. The problem of
keeping the cached data consistent with the original file content is referred to as the cache
consistency problem. Methods to handle this problem will be described later in this
chapter.
Ascompared to the remote service model, the data-caching model offers the
possibility of increased performance and greater system scalability because it reduces
network traffic, contention for the network, and contention for the file servers.
Therefore, almost all existing distributed file systems implement some form of
caching. In fact, many implementations canbethought of as a hybrid ofthe remote
service and the data-caching models. For example, LOCUS [Popek and Walker 1985]
and the Network File System (NFS) [Sandberg et al. 1985] use the remote service
model but add caching for better performance. On the other hand, Sprite [Nelson et al.
1988] uses the data-caching model but employs the remote service method under
certaincircumstances.Sec.9.4 • File-Accessing Models
9.4.2 UnitorDataTrans'.r429
In filesystemsthat use the data-caching model, an important designissue is to decidethe
unitofdata transfer. Unit ofdatatransferrefers to the fraction(or itsmultiples) ofa file
data that is transferred to and from clientsas a result of a singleread or write operation.
The four commonly used data transfermodels based on this factor are as follows:
1.File-level transfermodel.In this model, when an operation requires file data to be
transferred across the networkineitherdirection between aclientand a server, the whole
file is moved.
Inaddition to itsconceptual simplicity, this model has several advantages
[Satyanarayanan et al. 1985]. First, transmitting an entire file in response to a single
requestis moreefficient thantransmitting it page by page in response to several requests
because the network protocol overhead isrequired only once. Second, it has better
scalability becauseitrequires feweraccesses to file servers, resulting inreducedserver
load and networktraffic. Third, disk access routineson the servers can be better optimized
if it is known that requests are always for entire files ratherthan for random disk blocks.
Fourth, once an entirefile is cached at a client'ssite, itbecomes immune toserverand
network failures. Hence the model also offers a degreeofintrinsic resiliency. Finally, it
alsosimplifies the task of supporting heterogeneous workstations. This isbecauseit is
easiertotransform an entire file at one time from the form compatible with the file system
ofserverworkstation to the form compatible with the file system of the client workstation
or vice versa.
On theotherhand, the main drawback of this model is that it requires sufficient
storage space on the client'snode for storingall therequired files in their entirety.
Therefore, thisapproach fails to work with very large files, especially when the client runs
on adisklessworkstation. Even when the client'sworkstation is not diskless, files that are
larger than the local disk capacity cannotbeaccessed at all.Furthermore, if only a small
fractionofa file is needed, moving the whole file is wasteful.
Amoeba [Mullender andTanenbaum 1984], CFS [Gifford et al. 1988], and the
Andrew File System(AFS-2) [Satyanarayanan 1990b] arc a few examples ofdistributed
systems that use the file-level transfermodel. AFS-3, which is an upgraded version of
AFS-2, also alJows files to be cached in large chunks(64kilobytes) rather than in their
entirety. This feature was later incorporated in AFS to allow a workstation to access files
that are too large to fiton its local disk.
2.Block-level transfermodel.In this model, file data transfers across the network
between aclientand aservertake place in units offile blocks. A file block is a contiguous
portionofa file and is usually fixed in length. For file systemsin which block size is equal
to virtual memory page size, this model is also calledapage-level transfer model.
Theadvantage ofthis model is that it does not requireclientnodes to have large storage
space. It also eliminates the need to copy an entirefile when only a small portion of the
file data is needed. Therefore, this model can be used in systems having diskless
workstations. Itprovides large virtual memory forclientnodes that do not have their own
secondary storage devices. However, when an entirefile is to be accessed, multipleserver430 Chap.9 •Distributed FileSystems
requests are needed in this model, resulting in morenetwork traffic and more network
protocol overhead. Therefore, this model has poor performance ascompared to the file­
leveltransfer model when the access requests are such that most files have to be
transferred in their entirety. The Apollo Domain File System [Leach et al. 1983], Sun
Microsystem's NFS[Sandberg 1987], LOCUS [Popek and Walker 1985], and Sprite
[Nelsonet al, 1988] are a few examples ofdistributed systemsthat use the block-level
transfermodel.
3. Byte-level transfer model. In this model, file data transfers across the network
between aclientand aservertake place in units ofbytes. This model provides maximum
flexibility becauseit allows storage and retrieval ofanarbitrary sequential subrange ofa
file,specified by an offset within a file, and a length. The main drawback ofthis model
is thedifficulty incachemanagement due to the variable-length data fordifferent access
requests. TheCambridge FileServer[Dion 1980, Mitchell and Dion 1982, Needham and
Herbert1982] uses this model.
4. Record-level transfer model. The three file data transfermodelsdescribed above
arecommonly used with unstructured file models. The record-level transfermodel is
suitablefor use with those file models in which file contents arestructured in the form of
records. In this model, file data transfers across the network between aclientand aserver
takeplacein unitsofrecords. The Research StorageSystem(RSS) [Gray 1978, Gray et
al. 1981], which supports complex accessmethods tostructured andindexedfiles, uses the
record-level transfermodel.
9.5FILE-SHRRING SEMANTICS
A shared file may be simultaneously accessed bymultiple users. In such a situation, an
important designissue for any file system is to clearlydefine when modifications offile
data made by a user are observable byotherusers. This is definedby the type offile­
sharingsemantics adoptedby a file system. Levy and Silberschatz [1990]definedthe
following types of file-sharing semantics:
1. UNIX semantics. Thissemantics enforces an absolute time ordering on all
operations andensuresthat every read operation on a file sees the effects ofallprevious
writeoperations performed on that file [Fig. 9.1(a)].In particular, writes to an open file
by a user immediately becomevisible to other users who have this file open at the same
time.
The UNIX semantics iscommonly implemented in file systems for single­
processor systems because it is the most desirable semantics and also because itis
easy toserialize allread/write requests. However, implementing UNIXsemantics in a
distributed file system is not an easy task. One may think that this semantics can be
achieved in adistributed system by disallowing files to be cached at client nodes and
allowing asharedfile to be managed by only one file serverthatprocesses all read
and write requests for the file strictly in the orderin which it receives them. However,
even with this approach, there is a possibility that, due to network delays, clientSec. 9.5 • File-Sharing Semantics 431
1aIbIcI
New file
contentslalblcldlel
t
ReadI
16Append(e)
I
15!Retrieved file
contents
lalblcldlel
New file
contentsAppend(d)
I
t4
!IaIbIcIdI
New file
contentsRetrieved file
contents
'aIbIe'
t
ReadI
t3Append(c)
I
12
~Originalfile
contents
[U]]
i
I
t1
(a)
Nodeboundary
I
IINodeboundary
I
I
I
13:sendsreadrequestI
I
J
I
11:originalfilecontents is:t2:sendsappend(c)request
I[ill] :
I
(4:readrequestof client :
node1reachesand :
[illJis returned :
toclientnode1 :
15:appendrequestof :
client node 2 reaches :
and the file contents is:
updatedtoIaIbIcI:
(b)
Fig. 9.1 (u)Example ofUNIXfile-sharing semantics; (b)anexample explaining why
it isdifficult toachieveUNIXsemantics in adistributed filesystemeven
when the sharedfile ishandled by a single server.
requests from different nodes may arrive and get processed at the server node in an
order different from the actual order in which the requests were made [Fig. 9.1 (b)].
Furthermore, having all file access requests processed by a single server and
disallowing caching on client nodes is not desirable in practice due to poor
performance, poor scalability, and poor reliability of the distributed file system.
Therefore, distributed file systems normally implement a more relaxed semantics of
file sharing. Applications that need to guarantee UNIX semantics for correct function­
ing should use special means (e.g., locks) for this purpose and should not rely on the
underlying semantics of sharing provided bythe file system.432 Chap. 9 • Distributed File Systems
2. Session semantics. For this semantics, the foJIowing file access pattern is
assumed: A client opens a file, performs a series of read/write operations on the file, and
finally closes the file when he or she is done with the file. A sessionis a series of file
accesses made between the open and close operations. In session semantics, all changes
made to a file during a session are initially made visible only to the client process (or
possibly to all processes on the client node) that opened the session and are invisible to
other remote processes who have the same file open simultaneously. Once the session is
closed, the changes made to the file are made visible to remote processes only in later
starting sessions. Already open instances of the file do not reflect these changes.
Notice that with session semantics multiple clients are allowed to perform both read
and writeaccesses concurrently on thesame file.In thiscase,eachclient maintains itsown
image of the file. When a client closes its session, all other remote clients who continue
to use the file are actually using a stale copy of the file. Furthermore, using session
semantics raises the question of what should bethe final file image when multiple file
sessions, each one having a different file image, are closed one after another. Notice that
when a session is closed its file image is sent back to the server, so the final file image
depends on who closes last. However, there is a possibility that due to network delays file
images from different nodes may arrive and get processed at the server node in an order
different from the actual order in which the sessions were closed. Therefore, in practice,
it is easier to implement the alternative that says that the final file image is the image
maintained by one of the active sessions; the actual one is left unspecified. That is, the
final file image is nondeterministic.
Observe that session semantics should be used only with those file systems that use
the file..level transfer model. This is because coupling the session semantics with caching
parts of files may complicate matters, since a session is supposed to read the image of the
entire file that corresponds to the time it was opened.
3.Immutable shared-files semantics. This semantics is based on the use of the
immutable file model. Recall that an immutable file cannot be modified once it has been
created. According to this semantics, once the creator of a file declares it to be sharable,
the fileis treated asimmutable, sothat itcannot be modified any more. Changes tothe file
arehandled bycreating a newupdated version ofthe file.Each versionof the fileistreatedas an entirely new file.Therefore, the semantics allows files to be shared only in the read­
only mode. With this approach, since shared files cannot be changed at all, the problem
of when to make the changes made to a file by a user visible to other users simply
disappears.
4.Transaction ..like semantics. This semantics is based on the transaction mecha..
nism, which is a high-level mechanism for controlling concurrent access to shared,
mutable data. A transaction is a set of operations enclosed in..between a pair of begin_
transaction- andend_transaction ..likeoperations. The transaction mechanism ensures
that the partial modifications made to the shared data by a transaction will not be
visible to other concurrently executing transactions until the transaction ends (its end_
transaction is executed). Therefore, in multiple concurrent transactions operating on a
file, the final file content will be the same as if all the transactions were run in some
sequential order. In the Cambridge File Server [Needham and Herbert 1982], theSec.9.6 • File-Caching Schemes 433
beginning and end ofatransaction areimplicitin theopenandclosefileoperations,
andtransactions caninvolve only one file. Thus, a file sessionin thatsystemis
actually a transaction.
9.6FILE-CACHING SCHEMES
Filecachinghasbeenimplemented inseveralfilesystemsforcentralized time-sharing
systemstoimprove file I/Operformance (e.g., UNIX [McKusick eta1.1985]). The idea
in filecachingin thesesystemsis to retain recentlyaccessed file data in main memory, so
thatrepeated accesses to the same information can behandled withoutadditional disk
transfers. Becauseoflocalityin file access patterns, filecachingreducesdisktransfers
substantially, resulting inbetteroverallperformance ofthe file system. The property of
localityin file access patternscan as well be exploited indistributed systemsbydesigning
asuitablefile-caching scheme. Inaddition tobetterperformance, afile-caching scheme
for adistributed filesystemmay also contribute to itsscalability andreliability because
it ispossibletocacheremotely locateddata on a client node. Therefore, everydistributed
filesystemin serious use today uses some form of file caching. Even AT&T's RemoteFile
System(RFS)[Rifkineta1.]986],whichinitiallyavoided cachingtoemulate UNIX
semantics, now uses it.
Inimplementing afile-caching schemefor acentralized file system, one has to make
several key decisions, such as the granularity ofcacheddata (large versus small), cache
size (large versus small, fixed versus dynamically changing), and thereplacement policy.
A goodsummary ofthesedesignissues is presented in [Smith 1982]. In additionto these
issues, a file-caching scheme for adistributed filesystemshould also addressthe
following keydecisions:
I.Cachelocation
2.Modification propagation
3.Cachevalidation
Thesethreedesignissues are described below.
9.6.1 Cache location
Cachelocation refers to the place where the cacheddata is stored. Assuming that the
originallocationofa file is on its server'sdisk, there are three possiblecachelocations in
adistributed filesystem(Fig. 9.2).
1.Server'smain memory. When no cachingschemeis used, before a remoteclient
can access a file, the file must first be transferred from the server'sdisk to the server's
mainmemory and then across the networkfrom the server'smain memory to the client's
main memory. Therefore, the total cost involved is one disk access and one network434 Chap.9 • Distributed FileSystems
Nodeboundary
®Client's
mainmemory
Client's
diskServer's
mainmemory
Server's
disk®
Notavailablein
disklessworkstationsOriginal
filelocation
CDNocaching
®Cachelocatedinserver'smainmemory
®Cachelocatedinclient'sdiskoCachelocatedinclient'smainmemoryFig.9.2 Possible cache locations in a
file-caching scheme for a distributed
file system.
access. A cache located in the server'smain memory eliminates the disk access cost on a
cache hit, resulting in a considerable performance gain as compared to no caching.
The decision to locate the cache in the server'smain memory may be taken due
to one or more of the following reasons. It is easy to implement and is totally transparent
to the clients. It is easy to always keep the original file and cached data consistent since
both reside on the same node. Furthermore, since a single server manages both the cached
data and the file, multiple accesses from different clients can be easily synchronized to
support UNIX-like file-sharing semantics.
However, having the cache in the server'smain memory involves a network access
for each file access operation by a remote client and processing of the access request by
the server.Therefore, itdoes noteliminate the network access cost and does notcontribute
to the scalability and reliability of the distributed file system.
2. Client's disk. The second option is to have the cache in a client'sdisk. A cache
located in a client'sdisk eliminates network access cost but requires disk access cost on
acache hit.Acache on adisk has several advantages. The first is reliability. Modifications
to cached data are lost in a crash if the cache is kept in volatile memory. Moreover, ifthe
cached data is kept on the client'sdisk, the data is still there during recovery and there is
no need to fetch it again from the server'snode. The second advantage is large storage
capacity.As compared to a main-memory cache, a disk cache has plenty of storage space.
Therefore, more data can be cached, resulting in a higher hit ratio. Furthermore, severalSec.9.6 • File-Caching Schemes 435
distributed file systems use the file-level data transfermodel in which a file is always
cached in its entirety. In these systems, if a file is too large to fitin amain-memory cache,
theadvantages of filecachingcannotbe availed for it. Therefore, disk cache is particularly
useful for those systemsthat use the file-level transfermodelbecauseitallows the caching
of most large files unless the file to be cachedis larger than the available disk space. The
thirdadvantage isdisconnected operation. A system mayuse aclient'sdiskcachingand
the file-level transfermodel to support disconnected operation. Aclient'sdiskcachealso
contributes toscalability and reliability because on a cache hit the access requestcan be
serviced locallywithoutthe need to contactthe server.
The main drawback ofhavingcachedd.ataon a client'sdisk is that this policy does
not work if the system is to support diskless workstations. Furthermore, with this caching
policy, a disk access is required for each access request even when there is cache hit.
Therefore, the access time is still considerably large. Notice that a server'smain-memory
cacheeliminates disk access but requires networkaccess on acache hit. On the other hand,
aclient'sdisk cache eliminates network access but requires disk access on a cache hit.
Therefore, when adecision has to be made whetherto docachingin theserver'smain
memory or the client'sdisk, the former is somewhat faster, and itis always much simpler
[Tanenbaum 1995].
3. Client's main memory. The third alternative is to have the cache in a client'smain
memory. A cache located in a client'smain memory eliminates both network access cost
and disk access cost. Therefore, itprovides maximum performance gain on a cache hit. It
also permits workstations to be diskless. Like a client'sdisk cache, a client'smain­
memory cache also contributes toscalability and reliability because on a cache hit the
access request can be serviced locally without the need to contactthe server. However, a
client'smain-memory cache is not preferable to aclient'sdisk cache when large cache size
andincreased reliability of cached data are desired.
The relative advantages of the three cache locationpoliciesaresummarized in Figure
9.3. In conclusion, amain-memory cache and a disk cache emphasize different
functionality. While a main-memory cacheemphasizes reducedaccess time, a disk cache
emphasizes increased reliability andautonomy ofclientmachines. Furthermore, when
faced with a choice between having a cache on the servernode versus the client node, the
latter is always preferable because it also contributes toscalability and reliability.
9.6.2Modification PropagQtion
In file systems in which the cache is located on clients'nodes, a file's data may
simultaneously becachedon multiple nodes. In such a situation, when the caches of all
these nodes containexactly the same copiesof the file data, we say that the caches are
consistent. It ispossible for the caches to become inconsistent when the file data is
changed by one of the clients and the corresponding datacachedat other nodes are not
changed ordiscarded.
Keeping file data cachedat multiple client nodes consistent is animportant design
issue in those distributed filesystemsthat use client caching. A variety of approaches to436 Chap. 9 • Distributed File Systems
Costofremoteaccessincaseofnocaching
=onediskaccess +onenetworkaccess
Cachelocation Accesscoston Advantages
cachehit
Server'smain Onenetwork 1.Easyto implement
memory access2.Totallytransparent to
theclients
3.Easytokeeptheoriginal
fileandcacheddata
consistent
4.EasytosupportUNIX-
likefile-sharing semantics
Clientsdisk Onedisk 1.Reliabilityagainst crashes
access2.largestoragecapacity
3.Suitableforsupporting
disconnected operation
4.Contributes toscalability
andreliability
Clientsmain -- 1.Maximum performance gain
memory2.Permitsworkstationsto be
diskless
3.Contributes toscalability
andreliability
Fig.9.3 Summary of the relative advantages of the three cache location policies.
handle this issue have been proposed and implemented. These approaches depend on the
schemes used for the following cache design issues for distributed file systems:
1. When to propagate modifications made to a cached data to the corresponding file
server
2. How to verify the validity of cached data
The modification propagation schemes are presented below and the cache validation
schemes are presented in the next section.
A distributed file system may use one of the modification propagation schemes
described below. The file-sharing semantics supported by the distributed file system
depends greatly on the modification propagation scheme used. Furthermore, the
modification propagation scheme used has a critical effect on the system's performance
and reliability.Sec. 9.6 • File-Caching Schemes
Write-through Scheme437
In this scheme, when a cache entry is modified, the new value is immediately sent to
the server for updating the master copy of the file. This scheme has two main
advantages-high degree of reliability and suitability for UNIX-like semantics. Since
everymodification isimmediately propagated to the server having the master copy of
the file, the risk of updated data getting lost (when a client crashes) is very low. A
major drawback of this scheme is its poor write performance. This is because each write
access has to wait until the information is written to the master copy of. the server.
Notice that with the write-through scheme the advantages of data caching are only for
read accesses because the remote service method is basically used for all write accesses.
Therefore, this scheme is suitable for use only in those cases in which the ratio of read­
to-write accesses is fairly large.
Delayed- WriteScheme
Although the write-through scheme helps on reads, it does not help in reducing the
network traffic for writes. Therefore, to reduce network traffic for writes as well, some
systems use the delayed-write scheme. In this scheme, when acache entry is modified, the
new value is written only to the cache and the client justmakes a note that the cache entry
has been updated. Some time later, all updated cache entries corresponding to a file are
gathered togetherand sent to the server at a time.
Depending on when the modifications are sent to the file server, delayed-write
policies are of different types. Three commonly used approaches are as follows:
1. Writeon ejectionfrom cache. Inthis method, modified data in acache entry issent
tothe server when the cache replacement policyhas decided to eject itfrom the client's
cache. This method can result in good performance, but some data can reside in the
client'scache for a long time before they are sent to the server [Ousterhout et al. 1985].
Such data are subject to reliability problem.
2. Periodic write. In this method, the cache is scanned periodically, at regular
intervals, and any cached data that have been modified since the last scan are sent to
the server. Sprite [Nelson et al. 1988] uses this method with an interval of 30
seconds.
3. Writeon close. In this method, the modifications made to a cached data by aclient
are sent to the server when the corresponding file is closed by the client. Notice that the
write-on-close policy is a perfect match for the session semantics. However, it does not
help much in reducing network traffic for those files that are open for very short periods
or are rarely modified. Furthermore, the close operation takes a long time because all
modified data must be written to the server before the operation completes. Therefore, this
policy should be used only in cases in which files are open for long periods and are
frequently modified. The ITC File System [Satyanarayanan etal,1985] uses the write-on­
close policy.438 Chap.9 • DistributedFileSystems
The delayed-write policy helps in performance improvement for write accesses due
to the following reasons:
1. Writeaccesses complete more quickly because thenew value is written only in the
cache of the client performing the write.
2. Modified data may be deleted before it is time to send them to the server. For
example, many programs create temporary files, use them, and then delete them
soon after they are created. In such cases, modifications need not be propagated
at all to the server, resulting in a major performance gain.
3. Gathering of all file updates and sending them together to the server is more
efficient than sending each update separate Iy.
Delayed-write schemes, however, suffer from reliability problems, since modifica­
tions not yet sent to the server from a client'scache will be lost if the client crashes.
Another drawback of thisapproach isthat delaying the propagation ofmodifications to the
server results in fuzzier file-sharing semantics, because when another process reads the
file, what itgets depends on the timing.
9.6.3(acheValidationSchemes
A file data may simultaneously reside in the cache of multiple nodes. The modification
propagation policy only specifies when the master copy of a file at the server node is
updated upon modification of a cache entry. It does not tell anything about when the file
data residing in the cache of other nodes is updated. Obviously, a client'scache entry
becomes stale as soon as some other client modifies the data corresponding to the cache
entry in the master copy of the file. Therefore, it becomes necessary to verify if the data
cached at a client node is consistent with the master copy. If not, the cached data must be
invalidated and the updated version of the data must be fetched again from the server.
There are basically two approaches to verify the validity of cached data-the client­
initiated approach and the server-initiated approach [Levy and Silberschatz 1990].These
are described below.
Client-Initiated Approach
In this approach, a client contacts the server and checks whether its locally cached data is
consistent with the master copy. The file-sharing semantics depends on the frequency of
the validity check. One of the following approaches may be used:
1. Checking beforeevery access. This approach defeats the main purpose of caching
because the server has to be contacted on every access. But it is suitable for supporting
UNIX-like semantics.
2. Periodic checking. In this method, acheck is initiated every fixed interval of time.
The main problem of this method isthat itresults in fuzzier file-sharing semantics because
the data on which an access operation is performed is timing dependent.Sec.9.6 • File-Caching Schemes 439
3. Check onfileopen.In thismethod,aclient'scacheentryisvalidated only when the
clientopensthecorresponding file for use. This methodissuitableforsupporting session
semantics. Observe that onemethodforimplementing sessionsemantics in adistributed file
systemis to use the file-level transfermodelcoupledwith thewrite-on-close modification
propagation policyand thecheck-on-file-open cachevalidation policy.
Thevaliditycheckisperformed bycomparing the timeoflastmodification ofthe
cachedversionofthedatawith the server'smastercopyversion.Ifthe two are the same,
thecacheddatais up to date. Otherwise, it is stale and hencethecurrentversionofthedata
isfetchedfrom the server. Insteadofusingtimestamps, versionnumbers orchecksums can
be used.
Server-Initiated Approach
Ifthefrequency ofthevaliditycheckis high, the client-initiated cachevalidation approach
generates a largeamountofnetwork traffic and consumes precious serverCPU time.
Owingto thisreason,the AFS that initiallyused the client-initiated approach (inAFS-I)
switched to theserver-initiated approach (inAFS-2andAFS-3)[Satyanarayanan 1990b,
1992].
In thismethod, aclientinforms the file serverwhenopeningafile,indicating
whether the file is beingopenedforreading, writing, or both. The file serverkeepsa
recordofwhichclienthas which file openand in what mode. In thismanner, the server
keepsmonitoring the file usage modes being used by different clientsand reacts whenever
itdetectsapotential forinconsistency. Apotential forinconsistency occurswhen two or
moreclientstry to open afile inconflicting modes. For example, if a file is open for
reading, otherclientsmay beallowed to open it for readingwithoutanyproblem, but
openingit forwritingcannotbeallowed. Similarly, a newclientshouldnot beallowedto
open a file in any mode if the file isalreadyopen for writing. Whenaclientclosesa file,
itsendsanintimation totheserveralong with any modifications made to the file. On
receiving such anintimation, theserverupdatesitsrecordof which clienthaswhichfile
openin what mode.
When a new clientmakes arequesttoopenanalreadyopen file and if the serverfinds
that the new open modeconflicts with the alreadyopen mode, the servercan bedesigned
to deny the requestorqueuetherequestordisablecachingandswitchto theremote
servicemode of operation for thatparticular file byaskingall theclientshavingthe file
open toremovethat file from theircaches.Themethodofdisabling cachingis used in
Sprite[Nelsoneta1.1988].
Although theserver-initiated approach described aboveis quiteeffective, it has the
following problems:
1.Itviolatesthetraditional client-server model in whichserverssimplyrespondto
servicerequestactivities initiatedbyclients.Thismakesthe code for clientand
serverprograms irregular andcomplex.
2. Itrequiresthat fileserversbestateful.Asexplained later,statefulfileservershave
adistinctdisadvantage overstateless fileserversin theeventof a failure.440 Chap. 9 • Distributed File Systems
3. A check-on-open, client-initiated cache validation approach must still be used
along with the server-initiated approach. For example, a client may open a file,
cache it, and then close it after use. Upon opening it again for use, the cache
content must be validated because there is a possibility that some other client
might have subsequently opened, modified, and closed the file.
In another server-initiated approach, known as the callback policy in AFS
[Satyanarayanan 1990b],acache entry isassumed to be validunless otherwise notified by
the server. In this method, instead of recording the access modes of all clients for an open
file,theserver only keeps a record of the clients who have cached a file (or a part of it).
This record is maintained on a per-filebasis, and corresponding toeach file maintained by
the server, the server maintains a listof the clients who have the file's data cached in their
cache irrespective of whether the client currently has the file open for use or not. The
server promises to notify all clients of a cached file before allowing any modification to
the file by any other client.
In AFS, which implements session semantics, whenever a server receives a
request to close a file that has been modified, it notifies all the clients having that file
data in their caches to discard their cached data and consider it invalid. Clients having
this file open at that time discard their copy when the current session is over. Other
clients discard their copies at once. Notice that in this method the server need not be
informed about opensof already cached files. It need only be informed about the
closeofa writing session. As a result, the server need not receive open validation
requestsoflocally cached files. If the client machine crashes, it is assumed that all its
local files may be inconsistent. Therefore, upon recovery from a cache, it generates a
cache validation request for each file that is cached on its local disk.
9.7FilEREPUCATION
High availability is a desirable feature of a good distributed file system and file
replication is the primary mechanism for improving file availability. A replicated file
is a file that has multiple copies, with each copy located on a separate file server. Each
copy of the set of copies that comprises a replicated file is referred to as a replicaof
the replicated file.
9.7.1Dlrr.,..-c. ktw.8n Replication andCaching
Replication isoften confused withcaching, probably because they bothdeal with multiple
copiesofa data. However, the two concepts have the following basic differences:
1. A replica is associated with a server, whereas a cached copy is normally
associated with a client.
2. The existence of a cached copy is primarily dependent on the locality in file
access patterns, whereas the existence ofa replica normally depends on
availability and performance requirements.Sec.9.7 • File Replication 441
3. Ascompared to acached copy, a replica is more persistent, widely known, secure,
available, complete, and accurate.
4. A cached copy is contingent upon a replica. Only by periodic revalidation with
respect to a replica can a cached copy be useful.
Satyanarayanan [1992]distinguishes a replicated copy from a cachedcopy by calling
themfirst-class replicasandsecond-class replicas, respectively.
9.7.2Advantages ofR.plicatlon
Thereplication of data in a distributed system offers the following potential benefits:
1.Increased availability. One of the most important advantages of replication is that
it masks and tolerates failures in thenetwork gracefully. In particular, the system remains
operational andavailable to the users despite failures. Byreplicating critical data on
servers with independent failure modes, the probability that one copy of the data will be
accessible increases. Therefore, alternate copies of a replicated data can be used when the
primary copy is unavailable.
2.Increased reliability. Many applications require extremely high reliability of their
data stored in files. Replication is veryadvantageous for such applications because it
allows the existence of multiple copies of their files. Due to the presence of redundant
information in the system, recovery from catastrophic failures (such as permanent loss of
data of a storage device) becomes possible.
3.Improved response time. Replication also helps in improving response time
because it enables data to be accessed either locally or from a node to which access time
is lower than the primary copy access time. The access time differential may arise either
because of network topology or because ofuneven loading of nodes.
4.Reduced network traffic.If a file's replica is available with a file server that
resides on a client'snode, the client'saccess requests can be serviced locally, resulting in
reduced network traffic.
5.Improved systemthroughput. Replication also enables several clients'requests for
access to the same file to be serviced in parallel by different servers, resulting in improved
system throughput.
6.Betterscalability. As the number of users of a shared file grows, having all access
requests for the file serviced by a single file server can result in poor performance due to
overloading of the file server. Byreplicating the file on multiple servers, the same requests
can now be serviced more efficiently by multiple servers due to workload distribution.
This results in better scalability.
7.Autonomous operation. In adistributed system that provides file replication as a
service to their clients, all files required bya client for operation during a limited time
period may be replicated on the file server residing at the client'snode. This will facilitate442 Chap. 9 • Distributed File Systems
temporary autonomous operation of client machines. Adistributed systemhaving this
feature can supportdetachable, portablemachines,
9.7.3RapllcQtlon Transparency
Transparency is animportant issue in file replication. Areplicated fileservicemust
function exactlylike anonreplicated fileservicebutexhibitimproved performance and
reliability. That is, replication offiles should be designed to betransparent to the users
so thatmultiple copiesofareplicated fileappearas a single logicalfile to its users.
Forthis, the read, write, and otherfileoperations should have the same clientinterface
whether they apply to a nonreplicated file or to a replicated file. Two important issues
relatedtoreplication transparency are naming ofreplicas and replication control.
Naming of Replicas
Insystemsthatsupportobjectreplication. a basicquestion iswhetherdifferent replicas
of anobjectshould be assigned the same identifier ordifferent identifiers. Obviously,
thereplication transparency requirement calls for the assignment ofasingleidentifier
to allreplicasofan object. Assignment of a single identifier to allreplicasofanobject
seemsreasonable forimmutable objectsbecause a kernel can easily supportthis type
ofobject.Any copy found bythe kernel can be used, because all copiesareimmutable
andidentical; there is only one logical objectwith a given identifier. However, in
mutableobjects,different copiesofareplicated object may not be the same (consistent)
at aparticular instanceoftime. In this case, ifthe same identifier is used for all replicas
oftheobject,the kernel cannotdecide which replicais the most up-to-date one.
Therefore, theconsistency control and management of the various replicas ofamutable
objectshouldbeperformed outside the kernel. Hence itis theresponsibility of the
naming system to map a user-supplied identifier into the appropriate replicaofa
mutableobject.Furthermore, ifall replicas are consistent, the mapping must providethe
locations ofall replicas and a mechanism to identify the relative distances ofthe
replicas from the user'snode.
Replication Control
Another transparency issue isproviding replication control.Replication controlincludes
determining thenumberandlocations of replicas ofareplicated file. That is, do the
users play any role in determining how many copiesofareplicated file should be
createdand on which server should each copy be placed?In areplication transparent
system, the replication control is handled entirelyautomatically, in auser-transparent
manner. However, under certaincircumstances, it isdesirable toexposethese details to
users and to providethem with the flexibility to control the replication process. For
instance, ifreplication facility is provided tosupport autonomous operation of
workstations, users should be provided with the flexibility to create a replica of the
desiredfiles on their local nodes. Similarly, becauseofthe nature ofjob, if a userSec.9.7 • File Replication 443
normally works on two or three different nodes at different times, it may be desirable
toreplicate some of the frequently used files on servers located on allhis or her
workstations.
Depending onwhetherreplication control is user transparent or not, the replication
process is oftwo types:
1.Explicitreplication. In this type, users are given the flexibility to control the entire
replication process.Thatis, when a process creates a file, it specifies the server on which
the file should be placed. Then, if desired, additional copiesof the file can be createdon
other servers on explicitrequest by the users. Users also have the flexibility to delete one
or more replicas ofareplicated file.
2.Implicit/lazy replication. In this type, the entire replication process is automati­
callycontrolled by the system without users'knowledge. That is, when a process creates
a file, it does not provideanyinformation about its location. The system automatically
selects one server for the placement of the file. Later, the system automatically creates
replicas of the file on otherservers, based on some replication policy used by the system.
The system must be intelligent enoughto create and allow the existence ofonly as many
replicas as are necessary and should automatically delete any extracopies when they are
no longer needed. Lazy replication is normally performed in thebackground when the
server has some free time.
9.7.4Multicopy UpdateProblem
As soon as a file system allows multiple copies of the same (logical) file to exist on
different servers, it is faced with the problem ofkeepingthem mutually consistent. That
is, a situation must not be allowed to arise whereby independent conflicting updates have
been made to different copies of the same file. In fact, maintaining consistency among
copies when a replicated file isupdatedis the major design issue ofa file system that
supports replication of files. Some of the commonly usedapproaches to handle this issue
aredescribed below.
Read-Only Replication
This approach allows the replication of onlyimmutable files. Since immutable files are
used only in the read-only mode and because mutable files cannot be replicated, the
multicopy updateproblem does not arise. Files known to be frequently read and modified
only once in a while (once in several months), such as files containing the object code of
systemprograms, can be treated as immutable tiles forreplication using this approach.
Read-Any- Write-All Protocol
The read-only replication approach is toorestrictive in the sense that it allows the
replication of onlyimmutable files. Obviously, a replication scheme that can supportthe
replication ofmutablefiles as well is desirable. A simple multicopy update protocol that444 Chap. 9 • Distributed File Systems
allows the replication of mutable files is the read-any-write-all protocol. In this method,
a readoperation on areplicated file isperformed by reading any copy of the file and a
writeoperation by writing to all copies of the file. Some form of locking has to be used
tocarry out a write operation. That is, before updating any copy,all copies are locked, then
they are updated, and finally the locks are released to complete the write. The protocol is
suitable for implementing UNIX-like semantics. Notice that, in this protocol, the
availability ofa write operation is severely restricted since all copies must be available for
theoperation to complete, but the read operation is responsive since the nearest copy can
be used.
Available-Copies Protocol
The main problem with the read-any-write-all protocol is that a write operation cannotbe
performed if anyofthe servers having a copy of the replicated file is down at the time of
the write operation. The available-copies protocol relaxes this restriction and allows write
operations to be carried out even when some of the servers having a copy ofthereplicated
file are down. In this method, a read operation is performed by reading any available copy,
but a write operation is performed by writing to all available copies. The basic idea behind
thecorrectfunctioning of this protocol is that when a server recovers after a failure, it
bringsitselfup to date by copying from other servers before accepting any user request.
Failed servers (sites) are dynamically detected by high-priority status management
routines and configured outofthe system while newly recovered sites are configured back
in. This protocol provides betteravailability than theread-any-write-all protocol but does
notpreventinconsistencies in the presence of communication failures such as network
partition. Only clean, detectable site crashes are handled correctly by this method.
Primary-Copy Protocol
Another simple method to solve the multicopy update problem is the primary-copy
protocol. In this protocol, for each replicated file, one copy is designated as the primary
copy and all the others are secondary copies. Read operations can beperformed using any
copy,primaryor secondary. But, all write operations are directly performed only on the
primary copy. Each server having a secondary copy updates its copy eitherby receiving
notification ofchanges from the server having the primary copy or by requesting the
updatedcopy from it.
Theconsistency semantics implemented dependson when the secondary copies are
updated. For instance. for UNIX-like semantics. when the primary-copy serverreceives an
update request, it immediately orders all the secondary-copy servers to update their copies.
Some form oflocking is used and the write operation completes only when all the copies
have been updated. Therefore, in this case, the primary-copy update protocol is simply
anothermethodofimplementing theread-any-write-alJ protocol.
Afuzzierconsistency semantics results if a write operation completes as soon as the
primary copy has been updated. The secondary copies are then lazily updated eitherin the
background or whenrequested for an updated version by their servers. In this way, all the
secondary copies will ultimately get updated and reach a consistent state.Sec. 9.7 • File Replication 445
Quorum-Based Protocols
Theread-any-write-all andavailable-copies protocolscarinothandlethenetworkpartition
problem in which the copies of a replicated file are partitioned into two more active
groups. Moreover, the primary-copy protocol is too restrictive in the sense that a write
operation cannot be performed if the server having the primary copy is down. Gifford
[1979a]presented a simple quorum protocol that is capableof handling the network
partition problem and can increase the availability of write operations at the expense of
read operations.
Aquorum-based protocol works as follows. Suppose that there are a total of ncopies
of a replicated file F.To read the file, a minimum rcopies of Fhave to be consulted. This
set ofrcopies is called a readquorum. Similarly, to perform a write operation on the file,
a minimum wcopies of Fhave to be written. This set of wcopies iscalled a writequorum.
The restriction on the choice of the values of randwis that the sum of the read and write
quorums must be greaterthan the total number of copies n(r+w>n).This restriction
guarantees that there is a nonnull intersection between every read quorum and every write
quorum. That is, there is at least one common copy of the file between every pair of read
and write operations resulting in at least one up-to-date copy in any read/write quorum.
Since the quorum protocol does not require that write operations beexecuted on all
copies of a replicated file, some copies will be obsolete, and therefore, it becomes
necessary to be able to identify a current (up-to-date) copy in a quorum. This is normally
achieved by associating a version number attribute with each copy. The version number
of a copy is updated every time the copy is modified. A copy with the largest version
number in a quorum is current. The new version number assigned to each copy is one
more than the version number associated with the current copy.
Aread isexecuted as follows:
1. Retrieve a read quorum (any rcopies) of F.
2. Of the rcopies retrieved, select the copy with the largest version number.
3. Perform the read operation on the selected copy.
A write is executed as follows:
1.Retrieve a write quorum (any wcopies) of F.
2. Of the wcopies retrieved, get the version number of the copy with the largest
version number.
3.Increment the version number.
4. Write the new value and the new version number to all the wcopies of the write
quorum.
To further clarify how this protocol works, let us consider the example of Figure
9.4(a).There are total of eight copies of the replicated file (n=8) and the values of read
and write quorums are 4 and 5, respectively (r=4,w=5). Therefore, the condition
r+w>nis satisfied. Now suppose a write operation is performed on the write quorum446 Chap. 9 • Distributed File Systems
5 6Readquorums
,,_---h~ ~_"
""1 2 -, : 1 •
" " 8 : : , \ I 2
I • •
, I I\ ,
\,7 3,/ 3 4
..........._----- ......'"
(a)Writequorums(b)
Fig. 9.4 Examples of quorum consensus algorithm: (a) n=8tr=4tw=5~(b)n=8t
r=2tw=7.
comprised of copies 3, 4, 5, 6, and 8. All these copies get the new version and the new
version number. Now any subsequent read operation will require a read quorum of four
copies because r=4.Obviously any read quorum will have to contain at least one copy of
the previous write quorum. For theread quorum shown in the figure, copy number 3is the
common copy. When the version numbers of the copies belonging to the read quorum are
seen, the version number of copy number 3 is found to belarger than the other copies of
the read quorum. Therefore, the read operation is performed using copy number 3.
Another example in which r=2andw=7is shown in Figure 9.4(b).
The quorum protocol described above is a very general one, and several special
algorithms can be derived from it.A few are described below.
1.Read-any-write-all protocol. Theread-any-write-all protocol isactually a special
caseofthegeneralized quorum protocol with r=1andw=n.This protocol is suitable for
use when the ratio of read to write operations is large.
2.Read-all- write-any protocol. For this protocol r=nandw=1.This protocol may
be used in those cases where the ratio of write to read operations is large.
3.Majority-consensus protocol. In this protocol, the sizes of both the read quorum
and the write quorum are made either equal or nearly equal. For example, if n=11, a
possible quorum assignment for this protocol will be r=6andw=6.Similarly, when
n=12, a possible quorum assignment will be r=6andw=7.This protocol is commonly
used in those cases for which the ratio of read to write operations is nearly 1.
4. Consensus with weighted voting. In all the quorum-based protocols described
above, all copies of a replicated file are given equal importance. In other words, all copies
are assigned a single vote.The generalized quorum protocol can also be used to model the
varying"importance" of different copies of a replicated file by assigning each copy some
numberofvotes. The votes per copy can be adjusted for performance or reliabilitySec.9.8 • Fault Tolerance 447
reasons. Forexample, supposethatofthenreplicasof areplicated file, which are located
ondifferent nodes,thereplicaat nodeAisaccessed morefrequently thanotherreplicas.
Thisfact can be modeled byassigning more votes to the copy at node Athanother
replicas.
In thisapproach, a readquorum ofrvotes is collected to read a file and a write
quorumofwvotes to write a file. Sincethe votes assigned toeachcopyare not the same,
the size ofaread/write quorum depends on thecopiesselected for thequorum. The
numberofcopiesin thequorumwill be less ifthenumberof votesassigned to theselected
copiesisrelatively more.Ontheotherhand, the numberofcopiesin thequorumwill be
more if the numberof votes assigned to theselected copiesisrelatively less.Therefore,
toguarantee that there is a nonnullintersection between every readquorumandevery
writequorum, thevaluesofrandwarechosensuch that r+wisgreaterthan the total
numberof votes (v)assigned to the file (r+w>v).Here,vis the sum of the votes ofall
thecopiesof thefile.
9.8FAUlTTOlERANCE
Faulttolerance is animportant issue in the designof adistributed filesystem.Various
types of faults couldharmtheintegrity of the data storedby such a system. For instance,
aprocessor loses the contents of its main memory in theeventof a crash. Such a failure
couldresultinlogically complete butphysically incomplete fileoperations, makingthe
data that are storedby the file syst.em inconsistent. Similarly, duringarequest processing,
theserverorclientmachine maycrash,resulting in the loss ofstateinformation ofthe file
beingaccessed. Thismay have an uncertain effecton theintegrityoffile data. Also, other
adverseenvironmental phenomena such astransient faults(causedbyelectromagnetic
fluctuations) ordecayofdisk storage devicesmayresultinthe loss or corruption ofdata
storedby a file system.Aportionofa diskstoragedeviceis said to be "decayed" if the
data on that portionof thedeviceareirretrievable.
Theprimary fileproperties thatdirectlyinfluence theabilityof adistributed file
systemtotoleratefaults are as follows [Levy and Silberschatz 1990]:
1.Availability. Availability of a file refers to the fraction of time for which the file
isavailable for use. Note that the availability property depends on thelocationofthe file
and thelocations of itsclients(users). For example, ifanetwork ispartitioned due to a
communication link failure, a file may be available to theclientsof some nodes, but at the
same time, it may not be available to theclientsofothernodes.Replication is aprimary
mechanism forimproving theavailability of a file.
2.Robustness. Robustness ofa file refers to its powertosurvivecrashesofthe
storagedeviceanddecaysof thestoragemedium onwhichit is stored. Storagedevices
that areimplemented by using redundancy techniques, such as a stable storagedevice,are
oftenused to store robustfiles. Note that a robustfile may not be available until the faulty
component has been recovered. Furthermore, unlikeavailability, robustness isindepend­
ent ofeitherthelocationofthe file or the locationofitsclients.448 Chap. 9 • Distributed File Systems
3. Recoverability. Recoverability of a file refers to its ability to berolled back to an
earlier,consistent state when an operation on the file fails or is aborted by the client.
Notice that a robust file is not necessarily recoverable and vice versa. Atomic update
techniques such as a transaction mechanism are used to implement recoverable files.
The file replication technique has already been described in the previous section. The
atomic transactions mechanism used for atomic update is described in the next section.
Thestable-storage technique and the effect of a service paradigm on the fault tolerance of
distributed file systems are described below.
9.8.1Stabl.Storag.
In context of crash resistance capability, storage may be broadly classified into three
types:
I. Volatilestorage, such asRAM, which cannot withstand power failures or machine
crashes. That is, the data stored in a volatile storage is lost in the event of a power
failure or a machine crash.
2. Nonvolatile storage, such as a disk, which can withstand CPU failures but cannot
withstand transient 1/0faults and decay of the storage media. Although fairly
reliable, nonvolatile storage media such as a disk have complicated failure modes
and may prove to be insufficiently reliable for storing critical data.
3. Stable storage, which can even withstand transient 110faults and decay of the
storage media. It is a storage approach introduced by Lampson [1981].
The basic idea of stable storage is to use duplicate storage devices to implement a
stable device and to try to ensure that any period when only one of the two component
devices is operational is significantly less than the mean time between failures (MTBF) of
astable device. Therefore, adisk-based stable-storage systemconsists of apair ofordinary
disks (say disk 1and disk 2)that are assumed to bedecay independent. Each block on disk
2 is an exact copy of the corresponding block on disk 1.Unexpected faults that affect disk
storage may occur, but effective fault tolerance facilities are provided to ensure that both
the disks are not damaged at the same time. This is achieved by imposing restrictions on
how the two disks are accessed.
As with conventional disks, the two basic operations related to a stable disk are read
and write. A read operation first attempts to read from disk 1.If it fails, the read is done
from disk 2. A write operation writes to both disks, but the write to disk 2 does not start
until that for disk 1 has been successfully completed. This is to avoid the possibility of
both disks getting damaged at the same time by a hardware fault. Read and write actions
to eachofthe disks use retries of actions to tolerate the effects of transient hardware
faults.
In addition, there is a crash recovery action that restores the internal consistency of
data stored on the two disks after a crash has occurred. This recovery action compares the
contents of the two disks block by block. Whenever two corresponding blocks differ, theSec.9.8 • Fault Tolerance 449
block having incorrect data isregenerated from the corresponding block on the other disk.
Thecorrectness of a data block depends on the timing when the crash occurred. For
instance, if the system crashes after disk 1is updated but before disk 2is updated or while
disk 2 is being updated, the data block on disk 1is the correctone. On the other hand, if
the system crashes while disk 1 is being updated, the data block on disk 2 is the correct
one.Ofcourse, in the latter case, the update operation must be performed once again from
the beginning.
Notice that a stable-storage system uses ordinary fallible disks and converts them into
reliable virtual devices whose probability of failure is negligible. Stable storage is suitable
for those applications that require a high degree of fault tolerance, such as atomic
transactions.
9.8.2EffectofServiceParadigm onFaultTol.rance
Aserver may be implemented by using anyoneof the following two service paradigms­
stateful or stateless. The two paradigms are distinguished by one aspect of the client­
serverrelationship-whether or not the history of the serviced requests between a client
and a server affects the execution of the next service request. The stateful approach
depends on the history of the serviced requests, but the stateless approach does not depend
on it.
Stateful File Servers
A stateful file server maintains clients'stateinformation from one access request to the
next. That is, for two subsequent requests made by a client to a stateful server for
accessing a file, some state information pertaining to the service performed for the
client as a result of the first request execution is stored by the server process. This state
information is subsequently used when executing the second request. To allow the file
server to decide how long to retain the state information of a client, all access requests
for a file by a client are performed within an open and a close operations called a
session.The server creates state information for a client when the client starts a new
sessionbyperforming an open operation, maintains the state information for the entire
duration of the session, and discards the state information when the client closes the
session by performing a close operation. To illustrate how a stateful file server works,
let usconsider a file server for byte-stream files that allows the following operations
on files:
Open(filename, mode):This operation is used to open a file identified by filename
in thespecified mode.When the server executes this operation, itcreates an entry for
this file in a file-table that it uses for maintaining the file state information of all the
open files. The file state information normally consistsof theidentifier of the file, the
open mode, and the current position of a nonnegative integer pointer, called the read­
write pointer. When a file is opened, its read-write pointeris set to zero and the
server returns to the client a file identifier (fid)that is used by the client for
subsequent accesses to that file.450 Chap. 9 • Distributed File Systems
Readtfid,n, buffer): Thisoperation is used to get nbytesofdata from the file
identified byftdinto thespecified buffer.When the server executes thisoperation, it
returnsto the client nbytesoffile datastartingfrom the byte currently addressed by
theread..write pointerand then increments theread-write pointerbyn.
Writetfid,n,buffer):Onexecution ofthisoperation, the server takes nbytesofdata
from the specified buffer,writes it into the file identified byfidat the byte position
currently addressed by theread-write pointer,and then increments theread-write
pointerbyn.
Seekifid,position): Thisoperation causestheservertochangethe value oftheread­
writepointerofthe fileidentified bylidto the new value specified asposition.
Close(jid):Thisstatement causestheserverto delete from usfile-table the file state
information ofthe fileidentified bylid.
The file servermentioned above is stateful becauseitmaintains thecurrentstate
information for a file that has been opened for use by a client. Therefore, as shown in
Figure 9.5, after opening a file, if a client makes two subsequent Readtfid,100,buj)
requests, for the first requestthe first 100 bytes (bytes 0 to 99) will be read and for the
secondrequestthe next 100 bytes (bytes 100 to 199) will be read.
Clientprocess Serverprocess
Open(filename, mode)...Filetable
fid ModeRfWReturn(fid) Ipointer
,..,.
Read(fid,100,buf) ..
Return(bytes0to99)
Read(fid,100,buf)
Return
(bytes100to 199)
Fig. 9.5 An example of a stateful file server.
Stateless File Servers
Astateless fileserverdoes not maintain anyclientstateinformation. Therefore every
requestfrom a clientmust be accompanied with all the necessary parameters to
successfully carryout thedesiredoperation. That is, each request identifies the file and the
positionin the file for the read/write access. For example, a server for byte-stream files
thatallowsthefollowing operations on files is stateless:Sec.9.8 • Fault Tolerance 451
Read(filename, position, n, buffer): Onexecution ofthisoperation, theserver
returnsto theclientnbytesofdataofthe fileidentified byfilename. Thereturned
data isplacedin thespecified buffer.Thevalueoftheactualnumberofbyteswritten
isalsoreturned to theclient.Theposition withinthe file from wheretobeginreading
isspecified as theposition parameter.
Writeifilename, position, n, buffer): Whentheserverexecutes thisoperation, it
takesnbytesofdata from the specified bufferandwritesit into the file identified by
filename. Theposition parameter specifies thebyteposition withinthe file from
whereto startwriting. Theserverreturnsto theclienttheactualnumberofbytes
written.
AsshowninFigure9.6, this file serverdoesnotkeeptrackofany file state
information resulting from aprevious operation. Therefore, ifaclientwishestohave
similareffectas that in Figure9.5, the following two read operations mustbecarried
out:
Read(filename, 0, 100, buj)
Read(filename, 100, 100, buj)
Clientprocess Serverprocess
File state information
FileModeAIW Read
name pointer (filename, 0, 100, buf)....
Return (0 to 99 bytes)
Read
(filename, 100, 100, buf)
...
Return
(100 to 199 bytes)
Fig. 9.6 An exampleof astateless file server.
Noticethat in this case,thereis no need to use the sessionconceptwithopenand
closeoperations because each file operation standson its own. However, asshownin
Figure9.6, aclientprocessnormally keepstrackofthestateinformation ofthe files that
are in use by it. Sun Microsystems' NFS uses stateless fileservers[Sandberg eta1.
1985].452 Chap.9 •Distributed FileSystems
Advantages of Stateless Service Paradigm inCrash
Recovery
The useofstateless file servers by many distributed file systems is justifiedbythe fact that
stateless servers have a distinct advantage over stateful servers in the event of a failure.
Forexample, with stateful servers, if a server crashes and then restarts, the state
information that it was holding may be lost and the client process might continue its task
unaware of the crash, producing inconsistent results. Similarly, when a client process
crashesand then restarts, the server is left holding state information that is no longer valid
butcannoteasily be withdrawn. Therefore, the statefuJservice paradigm requires complex
crashrecovery procedures. Both client and server need to reliably detect crashes. The
serverneeds to detect client crashes so that it can discard any state itis holding for the
client, and the client must detect server crashes so that it can perform necessary error­
handling activities.
The stateless service paradigm makes crash recovery very easy because no client
stateinformation is maintained by the server and each request containsall theinformation
that isnecessary to complete the request. When a server crashes while serving a request,
the client need only resend the request until the server responds, and the server does no
crashrecovery at all. When a client crashesduring request processing, no recovery is
necessary foreitherthe client or the server. Therefore stateless servers can be constructed
aroundrepeatable operations. That is, if a client just resends a request until a response is
received for it, data will never be lost due to a server crash.
The stateless service paradigm, however, imposes the following constraints on the
designofthe distributed file system [SiIberschatz and Galvin 1994]:
1. Each request ofthe stateless service paradigm identifies the file by its filename
insteadofa low-level file identifier. If the translation of remote names to local names is
done for each request, the request processing overhead will increase. To avoid the
translation process, each file should have a systemwide unique low-level name associated
with it.
2. Theretransmission of requests byclients requires that the operations supported by
stateless servers be idempotent. Recall that an idempotent operation has the same effect
and returns the same output no matter how many times it is executed repeatedly. Self­
contained read and write operations areidempotent, since they use an absolute byte count
toindicatethe position within a file and do not rely on an incremental offset. Similarly,
operations todelete afile should also be made idempotent if the stateless service paradigm
is used.
The stateless service paradigm also suffers from the drawbacks of longer request
messages and slower processing of requests. Request messages are longer because every
requestmust beaccompanied with all the necessary parameters to successfully carry out
the desired operation. On the otherhand, request processing is slower because a stateless
serverdoes not maintain any state information to speed up the processing. Furthermore,
in some cases, stateful service becomes necessary. For instance, in internetworks,
messages may not be received in the same order in which they were sent. A statefulSec.9.9 • AtomicTransactions 453
service is preferable in such a case, since by the maintained state it is possibleto order the
messages correctly (seeChapter3). Similarly, ifthe file system uses the server-initiated
cache validation approach, itcannot use the stateless service paradigm since the server has
to maintain a record of which files are cached bywhich clients (see Section 9.6.3).
9.9ATOMIC TRANSACTIONS
Anatomictransaction (or justtransaction for short) is a computation consisting of a
collection ofoperations that take place indivisibly in the presence of failures and
concurrent computations. That is, either all of the operations are performed successfully
or none of their effects prevail, and other processes executing concurrently cannot modify
orobserveintermediate states of the computation. Transactions help to preserve the
consistency of a set of shared data objects in the face of failures and concurrent access.
They make crash recovery much easier, because a transaction can only end in two states­
transaction carried out completely or transaction failed completely.
Transactions have the following essential properties:
1.Atomicity. This property ensures that to the outside world all the operations of a
transaction appear to have been performed indivisibly. Two essential requirements for
atomicity are atomicity with respect to failures and atomicity with respect to concurrent
access.Failureatomicity ensures that if a transaction's work is interrupted by a failure,
any partially completed results will be undone. Failure atomicity is also known as the all­
or-nothing property because a transaction is always performed eithercompletely or not at
all. On the other hand, concurrency atomicity ensures that while a transaction is in
progress, other processes executing concurrently with the transaction cannot. modify or
observeintermediate states of the transaction. Only the final state becomes visible to other
processes after the transaction completes. Concurrency atomicity is also known as
consistency property because a transaction moves the system from one consistent state to
another.
2.Serializability. This property (also known as isolation property) ensures that
concurrently executing transactions do not interfere with each other. That is, the
concurrent execution of a set of two or more transactions isseriallyequivalent inthe sense
that the ultimate result of performing themconcurrently is always the same as if they had
beenexecuted one at a time in some (system-dependent) order.
3.Permanence. This property (also known as durability property) ensures that once
atransaction completes successfully, the results of its operations becomepermanent and
cannotbe lost even if the corresponding process or the processor on which itis running
crashes.
To easily remember these properties, Harder and Reuter [1983] suggested the
mnemonic ACID, where A,C, I, and Drespectively stand for atomicity (failure atomicity),
consistency (concurrency atomicity), isolation (serializability), and durability (perma­
nence).Therefore, transaction properties are also referred to as ACIDproperties.454 Chap.9 •Distributed FileSystems
9.9.1 N••dforTransactionsIn QFII.Service
Theprovision oftransactions in a file service is needed for two main reasons:
1.Forimproving therecoverability offiles in the event offailures. Due to the
atomicity property of transactions, if a server or clientprocess halts unexpectedly due to
ahardware fault or a software errorbefore a transaction iscompleted, the server
subsequently restores any files that were undergoing modification to their original states.
Notice that for a file service that does not supporttransaction facility,unexpected failure
oftheclientor server process during the processing ofanoperation may leave the files
that were undergoing modification in aninconsistent state. Without transaction facility, it
may bedifficultor evenimpossible in some cases to roll back (recover) the files from their
currentinconsistent state to their original state.
2.Forallowing theconcurrent sharing of mutable files by multiple clients in a
consistent manner.Iffile access requests from multiple clients for accessing the same file
areexecuted withoutsynchronization, thesequences ofread and write operations requested
bydifferent clients may be interleaved inmany ways, some ofwhich would notleave thefile
intheintended state.Therefore, unsynchronized execution ofaccess requests from multiple
clients,ingeneral,results in unpredictable effects onthefile. Transaction facility is basically
ahigh-level synchronization mechanism that properly serializes the access requests from
multipleclientsto maintain the shared file inthe intended consistent state.
The following examples illustrate how the transaction facilityofa file service helps
topreventfileinconsistencies arising from eventsbeyond a client'scontrol, such as
machine orcommunication failures or concurrent access to files by other clients.
Inconsistency Due to System Failure
Consider the banking transaction of Figure 9.7, which is comprised of fouroperations (oJ'
a2, a3' a4) fortransferring $5 from account X to account Z. Suppose that thecustomer
accountrecords are stored in a file maintained by the file server. Read/write access to
customer accountrecords are done by sending access requests to the file server. In the base
fileservicewithouttransaction facility, the joboftransferring $5 fromaccountXtoaccount
Z will be performed by theexecution ofoperations 0I ,02'03,anda4in that order. Suppose
the initial balancein both the accounts is $100.Therefore, if all the four operations are
performed successfully, the final balances in accounts X and Z will be $95 and $105,
respectively. Now suppose a system failure occurs after operation a3has been successfully
performed but before operation a4hasbeenperformed. Inthissituation, accountXwillhave
81:readbalance (x)ofaccount X
82:readbalance (z)ofaccountZ
83:write (x- 5)toaccountX Fig.9.7 A set of operations to transfer $5
84:write (z+5)toaccount Z from account Xto account Z.Sec.9.9 • AtomicTransactions 455
beendebitedbutaccountZ will not have been credited. Therefore $5vanishes becausethe
finalbalances inaccounts X and Z are $95 and $100, respectively (Fig. 9.8). Successful
reexecution of the four operations willcausethe final balances inaccounts X and Z to
become$90 and $105, respectively, which is not what was intended.
Letthe initialbalanceinboththe accountsof Figure9.7 be$100.
Successful
execution
a1:x=100
a2:z=100
a3:x=95
a4:z=105
Final result
x=95
z=105Unsuccessfulexecution
a1:x= 100
a2:z=100
a3:x=95
Systemcrashes
Final result
VVhenthe four VVhenthefour
operationsare not operations aretreated
treated as atransaction asa transaction
x=95
z=100x=100
z=100
Fig. 9.8 Possible final results in successful andunsuccessful executions with and
withouttransaction facility of the operations ofFigure9.7.
On the other hand, in a file service with transaction facility, the four operations a) ,
a2'a3'anda4can betreatedas a single transaction so that they can beperformed
indivisibly. In this case, ifthetransaction getsexecuted successfully, obviously the final
balances ofaccounts X and Z will be $95 and $105, respectively. However, if the
transaction failsin-between, the final balances inaccounts X and Z will be rolledback to
$100each,irrespective of what was the intermediate stateofthebalances in the two
accounts when the failure occurred (Fig. 9.8). Therefore, in caseofa failure, the balances
of the two accounts remainunchanged and thereexecution ofthetransaction will not
causeanyinconsistency.
Inconsistency Due toConcurrent Access
Consider the twobankingtransactions T}andTzofFigure9.9.Transaction T1,which is
meant for transferring $5 fromaccountXtoaccountZ,consistsoffouroperations al'a2,
a3'anda4.Similarly, transaction T2,which is meantfortransferring $7 from accountY456 Chap. 9 • Distributed File Systems
81:readbalance (x)ofaccount X
82:readbalance (z)ofaccount Z
83:write(x-5)toaccount X
84:write(z+5)toaccount Z
T1:Transfer$5fromaccount Xtoaccount Z.
b1:readbalance (y)ofaccount Y
b2:readbalance (z)ofaccount Z
~:write(y-7)toaccount Y
b4:write(z+7)toaccount Z
T2:Transfer$7fromaccount Ytoaccount Z.Fig.9.9Twobanking transactions.
to account Z~consists of four operations bI,b2,b3,andb4•The net effects of executing
the two transactions should be the following:
• To decrease the balance in account X by $5
• To decrease the balance in account Yby $7
• To increase the balance in account Z by $12
Assuming that the initial balance in all the three accounts is $100, the final balances
of accounts X, 1':and Zafter the execution of the two transactions should be $95, $93, and
$112, respectively.
In a base file service without transaction facility, ifthe operations corresponding to
the two transactions are allowed to progress concurrently and if the file system makes no
attempt to serialize the execution of these operations, unexpected final results may be
obtained. This is because the execution of the operations corresponding to the two
transactions may get interleaved in time in an arbitrary order. Two such possible
interleavings thatproduce unexpected final results are shown in Figure 9.10. The cause of
the error is that both clients are accessing the balance in account Z and then altering it in
a manner that depends on its previous value.
In a file service with transaction facility, the operations of each of the two
transactions can be performed indivisibly, producing correctresultsirrespective of which
transaction is executed first. Therefore, a transaction facility serializes the operations of
multiple transactions to prevent file inconsistencies due to concurrent access. However,
notice that the complete serialization of all transactions (completing one before the next
one isallowed to commence) that access the same data isunnecessarily restrictive andcan
produce long delays in the completion of tasks. In many applications, itis possible to
allow some parts of multiple concurrent transactions to be interleaved in time and still
produce the correct result. For instance, twopossible interleavings of the operations of the
two transactions of Figure 9.9 that produce correct results are shown in Figure 9.11.Sec.9.9 •AtomicTransactions
Lettheinitialbalanceinallthethree accounts
ofthetwo transactions ofFigure 9.9be$100.457
Fig.9.10 Twointerleavings of the
operations of the two
transactions of Figure
9.9that produce
unexpected final results. Time
Fig. 9.11 Two interleavings of the
operations of the two
transactions of Figure
9.9 that produce correct
final results. TimeAnillegalschedule Anotherillegal schedule
81:x=100 b1:y=100
b.:y=100 b2:z=100
82:z=100 81:x=100
b2:z>100 82:z=100
83:x=95 b3:y=93
b3:y=93 b4:z=107
84:z=105 83:x=95
b4:z=107 84:z=105
Finalresult Finalresult
x=95 x=95
y=93 y=93
z=107 z=105
Lettheinitialbalanceinallthethree accounts
ofthetwo transactions ofFigure9.9be$100.
Alegalschedule Anotherlegal schedule
81:x=100 b1:y=100
b1:Y= 100 b2:z=100
82:z=100 81:x=100
83:x=95 b3:y=93
84:z=105 b4:z=107
b2:v-105 82:z=107
b3:z=93 83:x=95
b4:z=11284:z=112
Finalresult Finalresult
x=95 x=95
y=93 y=93
z=112 z=112458 Chap. 9 • Distributed File Systems
Any interleaving of the operations of two or more concurrent transactions is known
as aschedule. All schedules that produce the same final result as if the transactions had
been performed one at a time in some serial order are said to be serially equivalent. Serial
equivalence is used asacriteria for the correctness ofconcurrently executing transactions.
It is up to the system to ensure that a serially equivalent schedule is always selected to
execute a set of concurrently executing transactions. By allowing the system the freedom
to choose any ordering of the operations it wants to, provided it produces the correct final
result, we eliminate the need for programmers to do their own mutual exclusion, thus
simplifying the programming task.
9.9.2Or-rations for Transaction-lased File Service
In a file system that provides a transaction facility, a transaction consists of a sequence of
elementary file access operations such as read and write. The actual operations and their
sequence that constitute a transaction is application dependent, and so it is the client's
responsibility toconstruct transactions. Therefore, theclient interface to such afile system
must include special operations for transaction service. The three essential operations for
transaction service are as follows:
begin_transaction ~returns (TID): Begins a new transaction and returns a unique
transaction identifier (TID). This identifier is used in other operations of this
transaction. All operations within a beginfransaction and anend_transaction form
the body of the transaction.
end_transaction (TID)~returns (status): This operation indicates that, from the
viewpoint of the client, the transaction completed successfully. Therefore the
transaction is terminated and an attempt is made to commit it. The returned status
indicates whether the transaction has committed or is inactive because itwasaborted
by either the client or the server. If the transaction commits, all of its changes are
made permanent and subsequent transactions will see the results of all the changes to
files made by this transaction. On the other hand, if the transaction was aborted, none
of the changes requested so far within the transaction will become visible to other
transactions. A transaction is aborted either on explicit request by the client or in the
event of system failures that disrupt the execution of the transaction.
abort_transaction (TID): Aborts the transaction, restores any changes made so far
within the transaction to the original values, and changes its status to inactive. A
transaction is normally aborted in the event of some system failure. However, aclient
may use this primitive to intentionally abort a transaction. For instance, consider the
transaction of Figure 9.12, which consists of three write operations on a file. In
Figure9.12(a),all three operations are performed successfully, and after the end_
transaction operation, the transaction makes the new file data visible to other
transactions. However, in Figure 9.12( b),the third write operation could not succeed
because of lack of sufficient disk space. Therefore, in this situation, the client may
use theabort_transaction operation to abort the transaction so that the results of the
two write operations are undone and the file contents is restored back to the value itSec.9.9 • AtomicTransactions
Fig. 9.12 Illustrating the use of
abort_transaction
operation: (a)allthree
operations areperformed
successfully so the
transaction commits; (b)all
threeoperations could not
beperformed successfully so
thetransaction was aborted.459
TID=begin_transaction
write(TIDJfile,position,n,buffer) --+returns(ok)
wri1e(TIDJfile,position,n,buffer) --+returns(ok)
write(TID, file,position,n,buffer) -+returns(ok)
end_transaction (TID)
(a)
TID=begin_transaction
write(TID, file,position,n,buffer)-+returnsIOkl
write(TID, file, position, n,buffer) --+returns ok
write(TID, file, position, n,buffer)--+returns (disk full error)
abort _transaction (TID)
(b)
had before the transaction started. Notice that, once a transaction has been committed
or aborted in the server, its state cannotbe reversed bythe client or the server.
Consequently, anabortfransaction request would fail if a client issued it after that
transaction had been committed.
In a file system with transaction facility, in addition to the three transaction service
operations described above, the transaction service also has file access operations. Each
file access operation ofthetransaction servicecorresponds to anelementary file service
operation. The parameters of the file access operations of thetransaction service are the
same as those of the elementary file service operations except for an additional argument
to specify the transaction identifier (TID) of the transaction to which the operation
belongs. For instance, the following are file access operations fortransaction serviceofthe
stateless server for the byte-stream files ofSection9.8.2:
Tread(TID,filename, position, n, buffer): Returns to the clientnbytes of the
tentative data resulting from the TIDif any has been recorded; otherwise it has the
same effect as Read(filename, position, n, buffer).
Twrite(TID,filename, position, n, buffer): Has the same effect as Write(filename,
position, n, buffer) but records the new data in a tentative form that is made
permanent only when the TIDcommits.
9.9.3Recovery Techniques
From the point of view of a server, a transaction has two phases (Fig. 9.13). The first phase
starts when the serverreceivesabegin_transaction requestfrom a client. In this phase, the
file access operations in thetransaction arcperformed and the client adds changes to file
itemsprogressively. Onexecution of theendtransaction orabort_transaction operation,
the first phase ends and the second phase starts. In the second phase, the transaction is
eithercommitted or aborted. In a commit, thechanges madebythetransaction to file
items are made permanent so as to make them visible to othertransactions as well. On the
otherhand, in an abort, the changesmade by the transaction to file items are undone to
restore the files to the state they were in before the transaction started.orabort_transaction
r460
beglR-transaction
r
Execution offile
accessoperations
inthetransaction
1
end_transaction
r
Commit
(makechangesmade
bythetransaction to
fileitemspermanent)
1Abort
(undochangesmade
bythetransaction to
fileitems)
1Chap.9 • Distributed FileSystems
TCtientadds
changesto
F fileitemsirstphase progressively
thatare
recordedina
reversible manner
bytheserver.
Changesmade
bythetrans­
actiontofile
Secondphase itemsareeither
1perma.nentlYrecordedor
undoneby
theserver.
Fig. 9.13 The two phases of a transaction.
The fact that in the secondphase the transaction mayeitherbecommitted oraborted
requiresthat the file updateoperations in the first phasemust beperformed in such a way
that they may be eitherpermanently recorded or undone. Therefore, while atransaction is
in its first phase, and hence subjecttoabortion, itsupdatesmust berecorded in areversible
manner. The two commonly usedapproaches forrecording fileupdatesin areversible
mannerare the file versions approach and thewrite-ahead logapproach.
File Versions Approach
A basictechnique toensurefilerecoverability is to avoid overwriting the actual data in
physical storage.The file versions approach is based on this technique. As shown in
Figure9.14, in this approach, when atransaction begins, the currentfileversionis used
for all file access operations (withinthetransaction) that do not modifythe file. Recall that
as soon as a transaction commits, thechanges made by it to a file become public.
Therefore, thecurrentversionofa file is the version produced by the most recently
committed transaction.
Whenthe firstoperation thatmodifies thefile is encountered within the transaction, the
servercreatesatentative versionofthe file for the transaction from the currentfile version
andperforms theupdateoperation on thisversionofthe file.Fromnow on, all subsequent
fileaccessoperations (read or write) within the transaction are.performed on thistentative
fileversion.Whenthetransaction iscommitted, thetentative file version is made the new
currentversionand theprevious currentversionofthe file is added to the sequence ofold
versions. On theotherhand, ifthe transaction isaborted,thetentative fileversionis simply
discarded and thecurrentfile version continues toremainthecurrentversion.Sec.9.9 • AtomicTransactions 461
Transaction progress Fileversionmanagement
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-------.. ~v,is added ~
tothe ,
sequence of ~
oldversions "•Currentfile
version(\{)
/
/
/
/
/
/
I
/
Atentative
file version
(V,)forthe
transactionAccess
Access
Vtis used for all
subsequent file access
operatiiS (readorwrite) Vtbecomes
~ __~~~~ the new~crrentVttov,v~rSion
Vcremains
the current
versionFirstfileupdate
operation encountered
in thetransaction
1begin_trrsactlon
Vcis used forall file
accessoperations in
thetransaction that do
notmoorthefile Create
."ig.9.14 The file versions approach for recording file updates in a reversible manner.
Notice that a transaction can modify more than one file. In this situation, there is a
tentative version of each file for the transaction. Furthermore, since a file may be involved
in several concurrent transactions, itmay have several tentative versions existing at the
same time. In this situation, when one of the concurrent transactions commits, the
tentative version corresponding to thattransaction becomes the current version of the file.
Since the remaining tentative versions of the file are no longer based on the current
version, they are handled as follows. When the next transaction out of the concurrent
transactions commits, and if there are no serializability conflicts between this transaction
and the previously committed transactions, the tentative version corresponding to this
transaction is merged with the current version, creating a new current version that includes
thechanges made by all of the transactions thathave.already committed. On the other
hand, if there are serializability conflicts, all the transactions that are involved except the
first one to commit are aborted. A serializability conflictoccurs when two or more
concurrent transactions are allowed to access the same data items in a file and one or more
of these accesses is a write operation.462 Chap. 9 • Distributed File Systems
Shadow Blocks Technique forImplementing FileVersions. The tentative
versions of files behave like copies of the file version from which they are derived.
However, copying the entire file for each transaction that modifies it may be wasteful and
prohibitive, especially for large files. The shadow blocks technique is an optimization that
allows the creation of a tentative version of a file without the need to copy the full file.
In fact, it removes most of the copying.
A file system uses some form of indexing mechanism to allocate disk space to files.
As shown in Figure 9.15(a),in this method, the entire disk space is partitioned into fixed-
'--- ~
0123
4 5 6 7
8 9 1011
121314152
8
6
9
123
5
7
10
11
13
14
15
The storage space ofa
disk partitioned into blocksIndexfor Indexfor List of
file F1file~freeblocks
(a)
13
14
1513
14
15
Listof
free blocks: : 3
: : 5
• I
I • 7
• I
• • 10 I0 I
~O,:Atransaction : : 11
:modifies block: 3 I I~ 13
:4 and appends: 1 :Transaction:
18newblock to I :aborts I4 14
. :the file data:5: : 1 15
CurrentIndex: : Tentative I'.
offile~ I ••index of • : Current List of
: : fileF1DI: Li~~~~_o!!i~e_~!._!r':':_~l~~~3•• I
I I I 45••
7 ITransaction' 7
:0 10 : commits : 10
: : 0 1111 11 I I
13: : 3
14: : 1
• •15: : 5
Listof : : Current Listof
freeblocks; ;index offile F1freeblocks
(b)
Fig.9.1S The shadow blocks technique for implementing file versions: (a)example
of disk blocks, file indices, and list of free blocks; (b)allocation and
deallocation of blocks as the transaction progresses.Sec.9.9 • AtomicTransactions 463
length byte sequences called blocks. The file system maintains an index for each file and
a list of free blocks. The index for a particular file specifies the block numbers and their
exact sequence used for storing the file data. For example, in Figure 9.15(a),fileF1uses
the blocks numbered 0, 4, 1 in that sequence and file F2uses the blocks numbered 2, 8,
6, 9, 12 in that sequence. On the other hand, the list of free blocks contains the block
numbers that are currently free and may be allocated to any file for storing new data.
In the shadow blocks technique, a tentative version of a file is created simply by
copyingthe index of the current version of that file. That is, a tentative index of the file
is created from its current index. Now when a file update operation affects a block, a new
disk block is taken from the free list, the new tentative value is written in it, and the old
block number in the tentative index is replaced bythe block number of the new block [see
Fig.9.15(b)]. File update operations that append new data to the file are also handled in
the same way by allocating new blocks from the free list for the appended data and
extending the tentative index of the file. The new blocks allocated to a tentative version
of a file are called shadow blocks. Subsequent writes to the same file block by the
transaction are performed on the same shadow block.
All file access operations in the transaction are performed by using the tentative
index while file access operations of other processes are performed by using the current
index. Therefore, the process running the transaction sees the modified file version, but all
other processes continue to see the original file version. Notice that unmodified file blocks
are shared between these two file versions.
As shown in Figure 9.15(b), if thetransaction aborts, the shadow blocks of the
tentative version of the file are returned to the list of free blocks and the tentative index
is simply discarded. On the other hand, if the transaction commits, the tentative index is
made the current index of the file, and if there is no need to retain the old file version, the
blocks of the original file version whose data were modified by the transaction are added
to the list of free blocks and the old current index is discarded.
TheWrite-Ahead LogApproach
Another commonly used technique for recording file updates in a recoverable manner is
the write-ahead log approach. In this method, for each operation of a transaction that
modifies a file, a record is first created and written to a log file known as a write-ahead
log.After this, the operation is performed on the file to modify its contents.
Awrite-ahead log ismaintained on stable storage and contains a record for each
operation t.hatmakes changes to files. Each record contains the identifier ofthetransaction
that is making the modification, the identifier of the file that is being modified, the items
of the file that are being modified, and the old and new values of each item modified.
To illustrate how the log works, let us again consider thetransaction fortransferring
$5 from account X to account Z. As shown in Figure 9.16, for each operation of the
transaction that makes changes to file items, a record is first created and written to the
write-ahead log. In each record, the old and new values of each item modified by the
operation are separated by a slash.
When the transaction commits, a commitrecord is written to the write-ahead log.
Notice that since the changes due to update operations were made on the file itself, there464 Chap.9 •Distributed FileSystems
x=100;
z=100;
begin_transaction
read balance (x)ofaccount X;
read balance (z)ofaccountZ; Log
write(x-5)toaccount X;-----.Ix=100/9511------1
write (z+5) toaccount Z;
end_transactiont'ig.9.16 An example of creation of
write-ahead log records.
is no need to change the file items when the transaction commits. On the otherhand, if the
transaction aborts, the information in thewrite-ahead log isused to roll back the individual
file items to their initial values, thus bringing the files affected by the transaction to their
original state. For rollback, the write-ahead log records are used one by one, startingfrom
the last record and going backward, to undo the changes described in them.
Thewrite-ahead log also facilitates recovery from crashes. For instance, suppose the
serverprocesshandling the transaction of Figure 9.16 crashes after writing the log record
for the second write operation in the transaction. After the server'smachine is restarted,
thewrite-ahead log is used to identify the exact point of failure. For this, the value ofthe
changed data item in the last record of the log (in this case z) is compared with its value
in the file. One ofthe following actions are taken depending on the status ofthe file:
1. If the value in the file is 100, it means that the crash occurred before the file was
updated. Therefore, the value of the data item in the file is changed to 105.
2. On the otherhand, if the value in the file is 105, it means that the crash occurred
after the file was updated, so nothing needs to be done in this case.
9.9.4Concurrency Control
Serializability is animportant property of atomic transactions that ensures that
concurrently executing transactions do not interfere with each other. However, we have
seen in the example of Figure 9.10 that if the operations oftwo or more concurrent
transactions accessing the same data item are allowed to progress uncontrolled, the
operations ofthesetransactions may get interleaved in time in an arbitrary order,
producing unexpected final results. Therefore, to prevent data inconsistency due to
concurrent access by multiple transactions, everytransaction mechanism needs to
implement aconcurrency control algorithm.
A good concurrency controlmechanism allowsmaximum concurrency with
minimum overhead while ensuring that transactions are run in a mannerso that their
effects on shareddata are serially equivalent. The simplest approach for concurrency
control would be to allow the transactions to be run one at a time so that two transactions
never run concurrently and hence there is no conflict. However, this approach is not good
because it does not allow any concurrency. Total elimination ofconcurrency is neitherSec.9.9 • AtomicTransactions 465
acceptable nor necessary because a transaction normally accesses only a few of the large
number of files available in a system. This observation gives rise to anothersimple
approach to concurrency control. Two transactions should be allowedto runconcurrently
only if they do not use a common file (or data item in general). Although better than the
previous approach, this approach is also unnecessarily restrictive because a pair of
transactions may access the same data item in a manner that does not cause any conflict
(inconsistency of the data item). Furthermore, it is usually not possible to predict which
data items will be used by a transaction. Therefore, more flexible concurrency control
algorithms are normally used by a transaction mechanism. The most commonly used ones
are locking, optimistic concurrency control, and timestamps. Descriptions of these three
approaches follow.
Locklng
This is the oldest and the most widely used approach. In the basic locking mechanism, a
transaction locks a data item before accessing it. Each lock is labeled with the transaction
identifier and only the transaction that locked the data item can access it any number of
times. Other transactions that want to access the same data item must wait until the data
item is unlocked. All data items locked by a transaction are unlocked as soon as the
transaction completes (commits or aborts). Locking is performed by thetransaction
service as a part of the data access operations, and clients have no access to operations for
locking or unlocking data items.
Optimized LockingforBetter Concurrency. The basic locking scheme is too
restrictive and some optimizations have been proposed for better concurrency. Two of
them are described below.
1.Type-specific locking. Asimple lock that is used for all types of accesses to data
items reduces concurrency more than is necessary. Better concurrency can be achieved by
usingtype-specific locking scheme in which more than one type of locks are used based
on the semantics of access operations. For instance, let us consider the simple case of two
types of access operations readandwrite.Notice that multiple transactions that read the
same data item but never write on it do not conflict. Therefore, when a transaction is
accessing a data item in the read-only mode, there is no reason to keep those transactions
waiting that also want to access the data item in the read-only mode. Therefore, instead
of using a single lock for both read and write accesses, separate locks (read locks and write
locks) should be used for the two operations. With these two types of locks, the locking
rules are given in Figure 9.17. If a read lock is set on a data item, other read locks are
permitted but write locks are not permitted. Therefore, an item locked with a read lock
cannot have its value changed byother transactions. On the other hand, when a write lock
is set, no other locks of any kind are permitted. Therefore, a data item locked with a write
lockcannotbe accessed (read or written) byanother transaction.
2.Intention-to-write locks.Recall that a transaction has two phases and the updates
made by a transaction to a data item are tentative in the first phase and are made
permanent only in the second phase. Each transaction is unable to observe the other466 Chap. 9 • Distributed File Systems
TypeoflockTypeoflocktobeset
alreadyset
Read Write
None Permitted Permitted
Read Permitted Notpermitted
Write Notpermitted NotpermittedFig. 9.17 Locking rules incase of read locks
and write locks.
transactions' tentative values.Therefore, whena read lock isset, instead of preventing any
other transaction from writing the locked data item, a transaction should be allowed to
proceed with its tentative writes until it is ready to commit. The value of the item will not
actually change until the writing transaction commits, so, if it is suspended at that point,
the item remains unchanged until the reading transaction releases its lock.
Based on the observation above, for better concurrency, Gifford [1979b] proposed
the use of an "intention-to-write lock"(I-write) and acommitlock instead of a write lock.
Therefore, three types-oflocks are used in this scheme, and the locking rules for them are
given in Figure 9.18. Notice that if a read lock is set, an I-write lock is permitted on the
data item and vice versa. This is because the effects of write are not observable by any
other transaction until the writing transaction commits. If an l-write lock is set, no other
transaction is allowed to have an I-write lock on the same data item.A commit lock is not
permitted if any other type of lock is already set on the data item. Therefore, when a
TypeoflockTypeoflocktobeset
alreadyset
Read I-write Commit
None Permitted Permitted Permitted
Read Permitted Permitted Notpermitted
I-write Permitted Notpermitted Notpermitted
Commit Notpermitted Notpermitted Notpermitted
Fig. 9.18 Locking rules in case of read locks, I-write locks, and commit locks.Sec.9.9 • AtomicTransactions 467
transactionhavingan I-writelockcommits,itsI-writelockisconvertedtoacommitlock,
sothatifthereareanyoutstandingreadlocks,the transaction mustwaituntilitispossible
to set the commit lock.
Two-Phase Locking Protocol. Becauseofthe potential for increased concur­
rency, it is tempting to lock a data item for use by a transaction only for the periodduring
which the transaction actually works on it and to release the lock as soon as the access
operation is over. However, locking and unlocking data items precisely at themoment
they are needed (or no longerneeded) can lead to inconsistency problems. For instance,
twocommonly encountered problems due toearly release (releasing immediately after the
accessoperation finishes) of read locks and write locks are as follows:
1.Possibility ofreadinginconsistent data in case of two or more read accesses by the
same transaction. This is because when read locks and write locks are released early,
between two subsequent read accesses to the same data item by a transaction, another
transaction may update the same data item and commit. Therefore, the second read may
not see the same value of the data item as the first read. Notice that if a transaction reads
a data item only once per transaction, there is no harm in releasing its read lock early.
2. Need for cascaded aborts.Suppose atransaction releases a write lock early and
then some other transaction locks the same data item, performs all its work, and commits
before the first transaction. Afterward, suppose the first transaction aborts. In this
situation, the already committed transaction must now be undone because its results are
based on a value ofthe data item that itshould never have seen. Aborting of already
committed transactions when atransaction aborts is known as cascaded aborting. Because
of the large overhead involved incascaded aborting, itis better to avoid it.
To avoid the data inconsistency problems, transaction systems use the two-phase
locking protocol. In the first phase ofatransaction, known as the growingphase,all locks
needed by the transaction aregradually acquired. Then in the second phase ofthe
transaction, known as the shrinking phase,theacquired locks are released. Therefore,
once atransaction has released any of its locks, itcannot request any more locks on the
same or other data items. Ithas been proved [Eswaran et al. 1976] that if all transactions
use thetwo-phase ·Iocking protocol, all schedules formed by interleaving theiroperations
arescrializable.
Granularity ofLocking. 'Thegranularity of locking refers to the unit of lockable
data items. In a file system supporting transactions, this unit is normally an entire file, a
page, or a record. If many transactions share files, the granularity oflocking can have a
significant impact on how many transactions can beexecuted concurrently. For instance,
if locks can be appliedonly to whole files, concurrency getsseverelyrestricted due to the
increased possibility of false sharing. Falsesharing occurs when two different
transactions access two unrelated data items that reside in the same file (Fig. 9.19). In such
asituation, even though the two data items can be accessed concurrently by the two
transactions, this is not allowed becausethegranularity of locking is a file. Notice that the
lockinggranularity increases concurrency by reducing the possibility of false sharing.468 Chap.9 • Distributed FileSystems
Transaction T1accesses T
1datainthisarea
Transaction T2accesses..-----e 7:
2 datainthisarea
Afile Fig.9.19 False sharing.
However, finer locking granularity leads to larger lock management overhead,
complicates implementation ofrecoverable files, and is more likelyto lead to
deadlocks.
Handling ofLockingDeadlocks. The locking scheme can lead to deadlocks. A
deadlock is a state in which a transaction waits for a data item lockedbyanother
transaction thatin tum waits, perhaps via a chain ofother waiting transactions, for the first
transaction toreleasesomeofits locks. Since a transaction cannotreleaseany lock until
it finishes, none ofthetransactions involved in such a circularwait canproceedunless one
ofthemis aborted. For example, suppose two transactions T)andTzhave locked data
itemsD)andD2,respectively. Now supposethatT)requests a lock on D2andT2requests
a lock onD).Adeadlock results because each transaction has an item of data lockedthat
theotherneeds to access.
Adetaileddescription ofthecommonly usedtechniques forhandling deadlocks was
presented inChapter6. Intransactions, oneofthe following techniques may be used:
1. Avoidance. Onemethodto handle the deadlock problem is to preventdeadlocks.
Deadlocks can beprevented byenforcing thatrequeststo lock data items be always made
in apredefined orderso that there can be no cycle in the who-waits-for-whom graph.
Although the method is quite effective, it may cause data items to be locked too soon,
resulting inreducedconcurrency.
2. Detection. Deadlocks can bedetected byconstructing andchecking who-waits­
for-whom graph. A cycle in the graph indicates theexistence ofa deadlock. When such
acycleisdetected, theservermust select and abort a transaction out of the transactions
involved in the cycle.
3.Timeouts. Associating a timeout period with each lock is anothermethod for
handling deadlocks. Thatis, a lock remainsinvulnerable for a fixed period,after which it
becomes vulnerable. A data item with a vulnerable lock remains locked if no other
transaction iswaitingfor it to get unlocked. Otherwise, the lock is broken (the data item
isunlocked) and the waiting processispermitted to lock the data item for accessing it.The
transaction whose lock has been broken is normally aborted.Sec. 9.9 • Atomic Transactions 469
Three major drawbacks of the timeout approach are (a) it is hard to decide the length
of thetimeoutperiod for a lock; (b) in an overloaded system, the number of transactions
getting aborted due to timeouts will increase, resulting in increased overhead for rerunning
the aborted transactions; and (c) the method favors short transactions over long
transactions because transactions taking a long time are more likely to be penalized.
Optimistic Concurrency Control
This approach for concurrency control by Kung and Robinson [1981] is based on the
observation that access conflicts in concurrently executing transactions are very rare.
Therefore, in this approach, transactions are allowed to proceed uncontrolled up to the end
of the first phase. However, in the second phase, before a transaction is committed, the
transaction is validated to see if any of its data items have been changed by any other
transaction since it started. The transaction is committed if found valid; otherwise itis
aborted.
For the validation process, two records are kept of the data items accessed within a
transaction-a readsetthat contains the data items read by the transaction and a writeset
that contains the data items changed, created, or deleted by the transaction. To validate a
transaction, its read set and write set are compared with the write sets of all of the
concurrent transactions that reached the end of their first phase before it. The validation
fails if any data item present in the read set or write set of the transaction being validated
is also present in the write set of anyof theconcurrent transactions mentioned above.
Two main advantages of the optimistic concurrency control approach are as
follows:
1.Itallows maximum parallelism because all transactions are allowed to proceed
independently in parallel without any need to wait for a lock.
2. It is free from deadlock.
However, itsuffers from the following drawbacks:
1. It requires that old versions of files corresponding to recently committed
transactions be retained for the validation process. This is not necessary either with
locking or timestamping.
2. Although the approach is free from deadlock, it may cause the starvation of a
transaction. This is because a transaction that fails validation is aborted and then restarted
all over again. But ifthetransaction comes into conflict with other transactions for the use
of data items each time itis restarted, it can never pass the validation checks.
Tosolve the starvation problem, Kung and Robinson suggested that the server should
detect a transaction that has been aborted several times. When such a transaction is
detected,itshould be given exclusive access to the data items it uses by the use of a
critical section protected by asemaphore,
3. In anoverloaded system, the number of transactions getting aborted due to access
conflicts may go up substantially, resulting in increased overhead for rerunning the470 Chap.9 •Distributed FileSystems
aborted transactions. Optimistic concurrency control is not a suitable approach for such
situations.
Mullender and Tanenbaum [1985] suggested that locking should be used in
transactions in which several files are changed and where the chance of two transactions
using the same data item is high. On the other hand, optimistic concurrency control should
be used for transactions using one file and in which the likelihood of two transactions
accessing the same data item is·low.
Timestamps
In theoptimistic concurrency control approach, a transaction is validated only after it
hascompleted its first phase. If the validation fails because some conflict is detected,
the transaction is aborted and restarted all over again. Execution of operations of the
transaction that follow the operation that caused the conflict is actually a waste in this
case. Notice that the overhead involved in executing the operations of the transaction
that follow the operation that caused the conflict can be totally avoided if it is possible
to detect the conflict right at the time when the operation causing it is executed. This
is because the transaction can be aborted immediately at the point where the conflict
occurs and it can then berestarted. This has been made possible in the timestamps
approach, in which each operation in a transaction is validated when it is carried out.
If the validation fails, the transaction is aborted immediately and it can then be
restarted.
To perform validation at the operation level, each transaction is assigned a unique
timestamp at the moment it does begin_transaction. In addition, every data item has a
readtimestamp and awrite timestamp associated with it. When a transaction accesses a
data item, depending on the type of access (read or write), the data item'sread timestamp
or write timestamp is updatedto thetransaction's timestamp.
As usual, the write operations of a transaction are recorded tentatively and are
invisible to other transactions until the transaction commits. Therefore, when a transaction
is in progress, there will be a number of data items with tentative values and write
timestamps. The tentative values and timestamps become permanent when the transaction
commits.
Before performing a read operation or a write operation on a data item, the server
performs a validation check by inspecting the timestamps on the data item, including the
timestamps on its tentative values that belong to incomplete transactions. The rules for
validation are as follows:
Validation ofa Write Operation. If the timestamp of the current transaction
(transaction that requested the write operation) is either equal to or more recent than the
read and (committed) write timestamps of the accessed data item, the write operation
passes the validation check. Therefore a tentative write operation isperformed in thiscase.
On the other hand, if the timestamp of the current transaction is older than the timestamp
of the last read or committed write of the data item, the validation fails. This is because
another transaction has accessed the data item since the current transaction started.
Therefore the current transaction is aborted in this case.Sec.9.9 •AtomicTransactions 471
Validation ofa ReadOperation. If thetimestamp ofthecurrenttransaction
(transaction thatrequested the readoperation) is morerecentthan the write timestamps of
allcommitted andtentative valuesoftheaccessed dataitem, the read operation passes the
validation check.However, the readoperation can beperformed immediately only if there
are notentative valuesofthe data item; otherwise it must wait until the completion of the
transactions havingtentative valuesofthe data item. On the otherhand, the validation
checkfails and the currenttransaction isabortedin thefollowing cases:
1. Thetimestamp ofthecurrenttransaction isolderthan the timestamp ofthe most
recent(committed) write to the data item.
2. Thetimestamp ofthecurrenttransaction isolderthan that ofatentative valueof
the data item made by anothertransaction, although itis morerecentthan the
timestamp of thepermanent data item.
Noticethat in the approach described above, atransaction cancomplete its first phase
only if all its operations have been consistent with those of earliertransactions. Therefore,
if atransaction completes its first phase, itcan always be committed, although it may have
to wait for earliertransactions that have tentative copiesof shared data items to
commit.
Thetimestamp-based concurrency controlschemedescribed above is used inthe
SDD-Idatabase system[Bernstein et al. 1980]. A similarschemeusingtimeouts is
described in [Reed 1983]. Timestamp-based concurrency controlschemes aredeadlock
free.
9.9.5Distributed TransQctlon Service
Distributed filesystemshavingtransaction facility need to supportdistributed transaction
service. A distributed transaction service is an extension oftheconventional transaction
service, which can supporttransactions involving filesmanaged by more than one server.
When atransaction involves multiple servers,all the servers need to communicate with
oneanothertocoordinate their actions during the processing ofthetransaction so as to
achieverecoverabiJity andconcurrency controlover the entire set of file operations in the
transaction.
Asimpleapproach tocoordinate the actions of multiple serversinvolved in a
distributed transaction would be to enforcethat allclientrequests pass through a single
server.However, to avoidunnecessary communication overhead, adistributed transaction
servicenormally allowsclientrequests to be sent directlyto theserverthat holds the
relevant fileinsteadofdirecting them via a single server. This approach isdescribed
below. The description is based on the concepts introduced in [Israel et a1.1978] and used
in the XDFS file service[Mitchell and Dion 1982, Sturgis et al. 1980].
In adistributed transaction service,aclientbegins a transaction bysendingabegin_
transaction requestto any server. The contacted serverexecutes thebeginfransaction
requestandreturnstheresulting TID to the client. This serverbecomes thecoordinator for
thetransaction and isresponsible foraborting orcommitting it and for adding other
serverscalledworkers.472 Chap.9 •Distributed FileSystems
Workers are dynamically added to the transaction. For this, a distributed transaction
service has a new operation in addition to the operations ofa traditional transaction
service: The request
add_transaction (TID, server_id of coordinator)
informs a server that it is involved in the TID.
Beforean access request is sent to a server that has not yet joinedthe transaction, an
addjransaction request is sent to the server. When the serverreceives the add_
transaction request, it records the server identifier of the coordinator, makes a new
transaction recordcontaining the TID, and initializes a new log to record the updates to
local files from the transaction. It also makes a call to the coordinator to inform it of its
intention to jointhe transaction. In this manner, each worker comes to know about the
coordinator and thecoordinator comes to know about and keeps a list of all the workers
involved in the transaction. This information enables the coordinator and the workers of
thetransaction tocoordinate with each other at commit time.
Two-Phase Multiserver CommitProtocol
The most crucial part in the design of a distributed transaction service is the committing
ofdistributed transactions. In a distributed transaction, since the files changed within the
transaction are stored on multiple servers, the commit protocol becomes more
complicated. A crash of one server does not normally affect other servers, and hence the
commitprotocol must ensure that the transaction is notcommitted and its changes to the
files arecompleted on some servers if it cannot be completed on all servers involved.
The general protocol for committing distributed transactions has two phases. The
two-phase multiserver commitprotocol given in [Gray 1978] is described below.
When the client of a distributed transaction makes an end_transaction request, the
coordinator and the workers in the transaction have tentative values in their logs
describing theoperations that affect their own files. The coordinator isresponsible for
deciding whetherthe transaction should be aborted or committed; if any server is unable
to commit, the whole transaction must be aborted. Therefore, the end_transaction
operation isperformed in twophases-preparation phase and commitment phase. The
actionsinvolved in each phase are described below.
Preparation Phase.
1.Thecoordinator makes an entry in its log that it is starting the commit
protocol.
2. It then sends a preparemessage to all the workers telling them to prepare to
commit. The message has a timeout value associated with it.
3. When a worker gets the message, it checks to see if it is ready to commit(i.e., it
has notpreviously aborted its part of the transaction). If so, it makes an entry in
its log and replies with a readymessage. Otherwise, itreplies with an abort
message.Sec.9.9 •AtomicTransactions 473
Commitment Phase. At this point, the coordinator has received a readyorabort
reply from each worker or the preparemessage has timed out:
1. If all the workers are ready to commit, the transaction is committed. For this, the
coordinator makes an entry in its log indicating that the transaction has been committed.
It then sends a commitmessage to the workers asking them to commit. At this point, the
transaction is effectively completed, so thecoordinator can report success to the client.
On the other hand, ifany of the replies was abortor thepreparemessage of any
worker got timed out, the transaction is aborted. For this, the coordinator makes an entry
in its log indicating that the transaction has been aborted. It then sends an abortmessage
to the workers asking them to abort and reports failure to the client.
2. When a worker receives the commitmessage, it makes a committed entry inits log
and sends a committed reply to the coordinator. At this point, the part of the transaction
with the worker is treated as completed and its records maintained by the worker are
erased.
3. When the coordinator has received a committed reply from all the workers, the
transaction is considered complete, and an its records maintained by the coordinator are
erased. The coordinator keeps resending the commitmessage until it receives the
committed reply from all the workers.
9.9.6N8st8dTransactions
Nestedtransactions are ageneralization of traditional transactions in which a transaction
may becomposed of other transactions called subtransactions. A subtransaction may in
turn have its own subtransactions. Inthis way, transactions can be nested arbitrarily deep,
forming a family of transactions.
Treeterminology is normally used in describing relationships among the transactions
belonging to the same family. When a transaction starts, it consists of only one transaction
(process) called the top-level transaction. This transaction may fork off children, giving
rise tosubtransactions. Each of these children may again fork off its own children, giving
rise to a further level of subtransactions. When a transaction forks a subtransaction, it is
called the parentof thesubtransaction and thesubtransaction isreferred toas its child.The
termsancestors anddescendants are also used. A transaction is an ancestor and a
descendant of itself.
Committing of Nested Transactions
In anested-transactions system, a transaction may commit only after all its descendants
have committed. However, a transaction may abort at any time. Therefore, in order for an
entiretransaction family to commit, its top-level transaction must wait for other
transactions in the family to commit.
Asubtransaction appears atomic to its parent. That is, the operations it performs take
placeindivisibly with respect to both failures and concurrent computations justas for
traditional transactions. Therefore, the changes made to data items bythesubtransaction474 Chap.9 • Distributed FileSystems
become visible to its parent only after the subtransaction commits and notifies this to its
parent. As a result, the actual committing of any updates performed by the subtransaction
iscontingent upon the commit of each ancestor transaction all the way up to the top-level
transaction.
On the other hand, if a failure occurs that causes a subtransaction to abort before its
completion, all of its tentative updates are undone, and its parent is notified. The parent
may then choose to continue processing and try to complete its task using an alternative
method or it may abort itself. Therefore, the abort of a subtransaction may not necessarily
cause its ancestors to abort. However, if a failure causes an ancestor transaction to abort,
the updates of all its descendant transactions (that have already committed) have to be
undone. Thus no updates performed within an entire transaction family are made
permanent until the top-level transaction commits. Only after the top-level transaction
commits is success reported to the client.
Advantages of Nested Transactions
Nested-transactions facility is considered to be an important extension to the traditional
transaction facility (especially in distributed systems) due to its following main
advantages:
1. It allows concurrency within a transaction. That is, a transaction may generate
severalsubtransactions that run in paraIJelon different processors. Notice that all children
of a parent transaction are synchronized so that the parent transaction stillexhibits
serializability.
2. It provides greater protection against failures, in that itallows checkpoints to be
established within atransaction. This isbecause the subtransactions of aparent transaction
failindependently of the parent transaction and of one another. Therefore, when a
subtransaction aborts, its parent can still continue and may fork an alternative
subtransaction in place of the failed subtransaction in order to complete its task.
9.10DESIGNPRINCIPLES
Based on his experience with the AFS and other distributed file systems, Satyanarayanan
[1992] has stated the following general principles for designing distributed file
systems:
1. Clients have cycles to burn. This principle says that, if possible, it is always
preferable to perform an operation on a client'sown machine rather than performing iton
a server machine. This is because a server is a common resource for all clients, and hence
cyclesofa server machine are more precious than the cycles of client machines. This
principle aims at enhancing the scalability of the design, since it lessens the need to
increase centralized (commonly used) resources and allows graceful degradation of
systemperformance as the system grows in size.Sec. 9.11 • Case Study:DeEDistributed File Service 475
2.Cachewhenever possible.Betterperformance, scalability, usermobility, andsite
autonomy motivatethisprinciple. Cachingof dataat clients' sites frequently improves
overallsystemperformance becauseitmakesdataavailablewherever itisbeingcurrently
used, thus savinga largeamountofcomputing time and networkbandwidth. Caching also
enhances scalability because itreducescontention oncentralized resources.
3. Exploit usage properties. Thisprinciple says that, depending on usage properties
(accessandmodification patterns), filesshouldbegrouped into a small numberofeasily
identifiable classes,and then class-specific properties shouldbeexploited forindependent
optimization forimproved performance. Forexample, filesknownto befrequently read
andmodified only once in awhile can be treatedasimmutable files for read-only
replication. Filescontaining theobjectcodeofsystemprograms are good candidates for
this class.
Notice that the use ofdifferent mechanisms forhandling filesbelonging todifferent
classesforimproved performance makes the design ofa filesystemcomplex. Hence, for
simplicity of design, some designers preferto use a single mechanism forhandling all
files.
4. Minimize systemwide knowledge and change. 'Thisprinciple isaimed at enhancing
thescalability ofdesign. The larger isa distributed system,t.hemoredifficultitistobeaware
at all times of the entirestate of the system and to updatedistributed orreplicated data
structures inaconsistent manner.Therefore, monitoring orautomatically updatingofglobal
information should be avoided'as far as practicable. Thecallback approach for cache
validation and the use of negative rights inanaccess controllist (ACL) based access control
mechanism (described inChapterII)are twoinstances of theapplication of thisprinciple.
The useofhierarchical systemstructure isalso anapplication ofthisprinciple.
5. Trustthe fewestpossibleentities.Thisprinciple is aimed at enhancing the security
ofthe system. For example, itis muchsimplertoensuresecurity based on theintegrity of
the much smallernumberofserversratherthantrustingthousands ofclients. In this case,
it issufficient to onlyensurethephysical securityofthese servers and the software they
run.
6. Batchifpossible. Batching often helps in improving performance greatly. For
example, grouping operations togethercanimprove throughput, although it is often at the
costoflatency.Similarly, transferof data across the network in large chunksrather than
asindividual pages is much more efficient. The full file transferprotocol is an instanceof
theapplication ofthisprinciple.
9.11CASESTUDY:DCEDISTRIBUTED FilESERVICE
Twoofthepopularcommercial filesystemsfordistributed computing systems are Sun
Microsystems' Network FileSystem(NFS) and Open Software Foundation's Distributed
FileService(DFS). DFS is one ofthe many servicessupported byDistributed Computing
Environment (DeE).
As a case study ofhow the concepts and themechanisms described in thischapter
can be used to build a distributed file system, DFS isbrieflydescribed below.Agood476 Chap.9 •Distributed FileSystems
description of NFS can befound in [Khanna 1994,Sandberg 1987,Sandberg et al. 1985].
However, in the following description of DFS, the major differences with NFS have also
been pointed out.
DeE'sDFS has several attractive features and promises to playamajor role in future
distributed computing environments. It is derived from the CMU Andrew File System
(AFS) but possesses many new features. For instance, AFS supports session semantics for
shared files, but DFS.supports more accurate single-site UNIX semantics.
DFS is basically a DeEapplication that makes use of other services of DCE. It uses
DeEthreads to handle multiple file access requests simultaneously, Remote Procedure
Call (RPC) for client-server communication during file access operations, Distributed
Time Service (DTS) for synchronization of the clocks of multiple servers, security service
forclient-server authentication and authorization at the time of file access requests, and
directory service to provide a single global name space for all files so that any file in the
entire system can be accessed by any client from any cell by simply specifying the file
name.
DFShas been designed to allow multiple file systems to simultaneously exist on a
node of a DeEsystem. For example, UNIX, NFS, and DFS's own file system can coexist
on a node to provide three different types of file systems to the users of that node. The
local file system of DFS that provides DFS on a single node is called Episode[Chutani
et al. 1992).As may be expected, when multiple file systems coexist on a node, features
specific to DFS are available only to those users who use the Episode file system. DFS
features are not available to the users of other file systems.
9.11.1DFSFII.Model
Like UNIX, DFS uses the unstructured file model in which a file is an unstructured
sequence of data. A DFS file server handles the contents of a file as an uninterpreted
sequence of bytes. A single file can contain up to 242bytes.
Like UNIX, DFS also uses the mutable file model. That is, for each file there isjust
one stored sequence that is altered by update operations. Note that although DFS uses the
mutable file model, it has a facility called cloning(described later) that allows two stored
sequences of a file to exist simultaneously; one of these is the version of the file before
cloning and the other contains the changes made to the file after cloning.
9.11.2DFSFileSyst.mModel
As shown in Figure 9.20, the DFS file system model has four levels of aggregation. Atthe
lowest level are individual files.At the next level are directories. Each directory usually
contains several files. Above directories are filesets.Each fileset usually contains several
directories. Finally, at the highest level is an aggregate that usually contains multiple
filesets. Each disk partition holds exactly one aggregate.
Like a file system of UNIX, a fileset is a group of files that are administered
(moved, replicated, backed up, etc.) as a set. However, unlike UNIX, a fileset is
normally a subtree of a file system and not the entire file system tree. For example,
a fileset may contain all the files of a single user, or all the files of a group of relatedSec. 9.11 • Case Study: DCE Distributed File Service
Fig. 9.20 Fourlevels ofaggregationin the
DFSfile system model.477
Aggregate
(oneaggregate perdiskpartition)
~I~
FS1 FS2· •• FSj(filesets)
~I~
01 02· ·· OJ(directories)
~I~
Fk(files)
users. With this difference, DI~Sallows multiple filesets per disk partition, a
management advantage over UNIX or NFS, which allow only a single file system per
disk partition. The main advantage is that disk space can be more efficiently utilized
bydynamically rebalancing the space occupancy of different partitions by moving
filesets from nearly full partitions to relatively empty partitions as and when
needed.
9.11.3DFSFile-Accessing Model
Distributed File Service relies on a client-server architecture and uses the data-caching
model for file accessing. A machine in a DCE system is a DFS client, a DFS server, or
both. A DFS client is a machine that uses files in filesets managed by DFS servers. The
main software component of a DFS client machine is the DFS cache manager, which
caches parts of recently used files to improve performance.
On the other hand, a DFS server is a machine having its own disk storage that
manages files in the filescts stored on its local disk and services requests received from
DFS clients. A DFS server machine has the following software components:
1.Episode. This is the DFS local file system.
2. Tokenmanager. The token manger is used to implement the token-based approach
for handling multicache consistency problems (this approach is described later).
3. File exporter. The file exporter accepts file access requests from clients and
returns replies to them. The interaction between clients and the file exporter is done using
DeERPC. In addition to handling requests for the Episode files, the file exporter also
handles requests for all the other file systems that exist on that node. It also handles client
authentication for establishing secure communication channels between clients and the
DFS server. The file exporter ismultithreaded so that several client requests can be
handled simultaneously.478 Chap.9 •Distributed FileSystems
4. Fileset server. The fileset servermanages the local filesets. It keeps track ofhow
many filesets there are and which fileset belongsto which disk partition. It alsoprovides
commands that can be used by the systemadministrator toobtainfilesetinformation, to
manipulate disk quotas offilesets, and to create,delete,duplicate, move, backup, clone,
orrestorean entire fileset.
5. Fileset location server. The fileset locationserverkeepsinformation about which
DFSserversaremanaging which filesets in the cell. If a fileset is movedfrom one DFS
servertoanotheror isreplicated onanotherDFS server, the fileset locationserverrecords
thesechanges. Given the name ofa file, the fileset locationserverreturnstheaddressof
the DFS serverthatmanages the fileset that contains the file. If a fileset is replicated, the
addresses ofall the DFS servers that manageit are returned. When a DFS clientaccesses
a file by specifying its name, its cachemanager gets theaddressofthe DFS serverthat
manages the fileset ofthe file from the fileset locationserver. The cachemanager caches
thisinformation for future use.
6. Replication server. Thereplication servermaintains theconsistency ofthereplicas
offilesets.
Ofthe above mentioned sixcomponents ofa DFS server, the formerthreeresidein
the kernel space and the latter three residein the user space.
When a DFS clientmakes a file access request, the cachemanager oftheclient's
machine firstchecksto see if the requested data isalreadypresentin its cache. If the data
is found in the cache, the file access operation isperformed locallywithoutcontacting a
DFSserver.Otherwise, thecachemanager does anRPCwith the appropriate DFSserver
askingfor the data. The data received from the DFS serveriscachedby the cache manager
for future use.
DFS uses the block-level transfermodel for the unit ofdata transfer. The block size
is 64kilobytes, so many (in some environments most) files will be transferred andcached
intheirentirety.
Tomention about file accessing in NFS, NFS also uses the data-caching model for
fileaccessing and theblock-level transfermodel for the unit ofdata transfer. The block
size in NFS is 8 kilobytes. Forperformance improvement, inaddition to datacaching,
NFS also uses a read-ahead mechanism. In thismechanism, after the file system
component on theclientmachine receives the block that contains theneededdata, it
automatically issues arequestfor the next block, so that it will be available locally in case
it isneededshortly.
9.11.4DFSFII.-Sharlng S.mantlcs
Thestrongest featureofDFS is that, in spite ofusing the data-caching model, it supports
thesingle-site UNIXsemantics. Thatis, every read operation on a file sees the effects of
allprevious writeoperations performed on that file. This is achieved in themanner
described below.
Recall that each DFS serverhas acomponent calledtoken manger. The jobofthe
tokenmanager is to issue tokenstoclientsfor file access requests and to keep track ofSec. 9.11 • Case Study: DeEDistributed File Service 479
which clients have been issued what types of tokens for which files. A client cannot
perform the desired file operation on a piece of file data until itpossesses the proper
token.
The use of a token-based approach to implement thesingle-site UNIX file-sharing
semantics can best be illustrated with the help of an example (see Fig. 9.21). For
simplicity, in this example we assume that there is only one type of token for all types of
file access operations.
Hold.stoken and 2. Token and Token for file F1data for file F1data ofF1given to client AClient machine
~
Client machine
Client
A1.Access F1Server machine
8
(a)
Server machine
ServerClient machine
6'
Client machine
63
(b)
Client machine 4. Revoke Server machine Client machine
token for F13. Access F1
ClientServer Client
A B
5. UpdatedToken for file F16. Token andHolds token anddata of F1given to client Bupdated datadata for file F1(ifany) ofF1
(c)
I4'ig.9.21Token-based approach of DFS for implementing the UNIX file-sharing
semantics: (a)initial state of a servermachine and two client machines;
(b)state after client A receives the token and data for file FI;(c)state after
clientBreceives the token and data for file FI_
Figure9.21(a)shows the initial state of a server and two client machines. At this
time, client Amakes a request to the server for accessing file Fl'The server checks its
stateinformation to see if the token for file F1has been given to any other client. It finds
thatithas not been given to any other client, so it sends the token and data of file FIto
clientAand makes a record ofthis information for future use. ClientAcaches the received
file data and then continues to perform file access operations on this data as many times
as needed. Figure 9.21(b)shows the state of the server and client machines after client A
receives the token and data for file Fl'480 Chap.9 • Distributed FileSystems
Nowsupposeafter some time that client Bmakes arequestto theserverforaccessing
the same file FJ.Theserverchecks its state information and finds that the token for file
F.has been given to client A.Therefore, it does not immediately send the token and data
for fileF1toclientB.Rather it first sends a message toclientAasking back the token for
fileFl.Onreceiving therevocation message, clientAreturns the token along with updated
dataoffileF](ifanyupdates were made) and invalidates itscacheddata for file F).The
serverthen updates its local copy of file F)(if needed) and now returnsthe token and up­
to-datedataoffileF1to clientB.ClientBcachesthereceived file data and then continues
toperform file access operations on this data as many times as needed. Figure9.21(c)
shows the state ofthe server and client machines after client Breceivesthe token and data
forfile.F1•In this way,the single-system UNIXfile-sharing semantics isachieved because
theserverissues the token for a file to only one client at a time. The clientthatpossesses
the token is assuredexclusive access to the file.
Tomaximize performance, betterconcurrency isachieved by using the following
techniques:
1. Type-specific tokens. Notice that multiple clients that read the same file but
neverwrite on it do not conflict. Therefore, when a client is accessing a file in the
read-only mode, there is no reason why otherclientsthat also want to access the file
in theread-only mode should not be given the token for the file. Hence, instead of
using a single token for all types of operations on a file, type-specific tokens are used.
Separate tokens exist for open, read, write, lock, check file status, and update file
statusoperations on files. The server knows the rules for token compatibility. That is,
it will issue multiple read tokens for read accesses to a piece offile data but will not
issue any read token or write token for a piece offile data for which a write token
has already been issued to aclient.
2. Fine-grained tokens. Tominimize theproblem offalse sharing, tokens for
conflicting operations refer only to aportionofa fileinsteadofthe entire file. For
instance, tokens for open, check file status, and update file status operations apply to the
entire file, but tokens for read, write, and lock operations apply only to a portionof a
file.
Every token has an expiration timeof2 minutes. Therefore, if a client does not
respond(eitherdue to a crash or some other reason) to a token revocation message from
a server, the serverjustwaits for 2 minutes and then acts as if the token has been returned
by the client.
Tomention thefile-sharing semantics in NFS, NFS does not supportthe UNIX
semantics for file sharing. It has been widely criticized for having a fuzzy file-sharing
semantics in which a write to a file performed by a client on its cachedcopy of the
file data mayormay not be seen when anotherclientreads the file, depending on
timing. This is because in NFS each cacheddata block has a timer of3 seconds
associated with it. A cacheddata block is discarded when its timerexpires. In
addition, whenever acachedfile isopened,the client contacts theserverto find out
when the file was last modified. If the last modification was done after the client'sSec. 9.11 • Case Study: DeEDistributed File Service 481
copy was cached,the client discards the old copy from its cache,gets the updated
copy from the server, and caches this copy in its cache. Finally, NFS uses the periodic
writemodification propagation schemewith a30-second interval. Thatis, once every
30seconds all themodified blocksofacacheare sent to the server. Due to the use
oftimer-based mechanisms fordiscarding cachedentriesand formodification propa­
gation, NFS does not make good use of data caching.
Another important difference between NFS and DFS that is worth mentioning here
is that NFS allows every machine to be both a clientand aserverat the same time. That
is, anyclientmay also be a server and any servermay also be a client. All machines are
independent and exist in different administrative environments. However, in DFS, a server
assumes thedependency of clients in the same cell. Therefore, theserver-client
relationship in DFS is much more a convention formaster-slave than NFS.
9.11.5File-Caching SchemeInDFS
We have already seen that in DFS recently accessed file data are cachedby the cache
manager ofclientmachines. The local disk of a clientmachine is used for this
purpose. However, in a disklessclientmachine, the local memory is used for caching
file data.
As shown in Figure9.21, in DFS, modifications made to a cachedfile data are
propagated to the file serveronly when the clientreceivesa tokenrevocation message for
the file data. The same is true for cache validation scheme. That is, a cachedfile dataof
aclientmachine isinvalidated (its cache entry is discarded) only when the clientreceives
a tokenrevocation message for the file data from the file server. As long as the client
possesses the token for the specified operation on the file data, the cacheddata is valid and
theclientcancontinue to perform the specified operation on it. In effect, the approach
used for cachevalidation is aserver-initiated approach.
The NFS schemes formodification propagation andcachevalidation have already
beendescribed in theprevious section.
9.11.6ReplicQtion QndCloninginDFS
Distributed FileServiceprovides the facility to replicate files onmultiplefile servers. The
unitofreplication is a fileset, That is, all files ofa fileset are replicated together.
Theexistence ofmultiple replicas of a file is transparent to normal users (client
applications). That is, a filename is mappedto all file servershavingareplicaofthe file.
Therefore, given a filename, the fileset locationserverreturns the addresses ofall the file
servers that have a replicaof the fileset containing the file. DFS uses the explicit
replication mechanism forreplication control. That is, the numberofreplicasfor a fileset
and their locations aredecidedby thesystemadministrator. The fileset serverhas a single
command forreplicating an entire fileset.
Thereplication serverof a server machine isresponsible formaintaining the
consistency ofthe replicas of filesets. The primary-copy protocol is used for this purpose.
Thatis, for each replicated fileset, one copy is designated as theprimarycopy and all the
others are secondary copies. Read operations on a file in a replicated fileset can be482 Chap. 9 • Distributed File Systems
performed using any copy of the fileset, primary or secondary. But all update operations
on a file in the fileset are directly performed only on the primary copy of the fileset. The
replication serverofthe primary copy periodically sends the updated versions ofmodified
files to the replication servers of the secondary copies, which then update their own
replicas.of the fileset.
NFS does not provide the facility to replicate files on multiple servers.
In addition to allowing replication of filesets, DFS also provides the facility to clone
filesets. This facility allows the creation of a new virtual copy of the fileset in another disk
partition and the old copy is marked read only. This facility may be used by the system
administrator to maintain an old version of a fileset, allowing the recovery of the old
versionofaninadvertently deleted file. For example, the system administrator might
instructthe system to clone a fileset every day at midnight so that the previous day'swork
always remains intact in an old version of all files. If a user inadvertently deletes a file,
he or she can always get the old version of the file and once again performthe current
day'supdates on it.
Cloning of a fileset does not take much time because only a virtual copy of the fileset
is made. That is, only the data structures for the files in the fileset are copied to the new
partition and the file data is not copied. The old data structures in the originalpartition are
marked read only. Therefore, both sets of data structures point to the same data blocks.
When a file in the new fileset is updated, new data blocks are allocated for writing the
updated version ofthe data and the corresponding file data structure in the new partition
is updated to point to thenew data blocks. A request to update a file in the original fileset
is refused with an error message.
9.11.7FaultTolaranc.
In addition to allowing replication of filesets, another important feature ofDFS that
helps inimproving its fault tolerance ability is the use of the write-ahead log approach
forrecording file updates in a recoverable manner. In DFS, for every update made to
a file, a log is written to the disk. A log entry contains the old value and the new value
of the modified part of the file. When the system comes up after a crash, the log is
used to check which changes have already been made to the file and which changes
have not yet been made. Those that have not been made are the ones that were lost
due to system crash. These changes are now made to the file to bring it to a consistent
state.Ifan update is lost because the crash occurred before the log for the update was
recorded on the disk, it does not create any inconsistency because the lost update is
treated as if the update was never performed on the file. Therefore the file is always
in aconsistent state after recovery.
Notice that in the log-based crash recovery approach used in DFS, the recovery time
isproportional to the length of the log and isindependent of the size of the diskpartition.
This allows faster recovery than traditional systems like UNIX, in which the recovery time
ofa file system is proportional to the size of its disk partition.
For fault tolerance, the main approach used by NFS is to use stateless file servers.
Notice from Figure 9.21 that DFS servers are stateful because they have to keep track of
the tokens issued to the clients.Sec. 9.] I • Case Study: DeEDistributed File Service
9.11.8AtomicTransactions483
TheDeEdoes not providetransaction processing facilityeitheras a part ofDFSor
as anindependent component. This is mainly becauseDCEcurrently does not possess
services needed fordeveloping andrunning mission critical, distributed on-line
transaction processing (OLTP) applications. Forinstance, OLTPapplications require
guaranteed data integrity, application programming interface withsimplified trans­
actionsemantics, and the ability toextendprograms tosupport RPCs that allow
multiple processes to work together overthenetwork toperform acommon task. Such
services are not currently supported by DCE. However, usersofDeEwho need
transaction processing facility can use Transarc Corporation's EncinaOLTPtechnol­
ogy.Encinaexpands on the DCE framework andprovides a set of standards-based
distributed services forsimplifying theconstruction ofreliable, distributed OLTP
systems withguaranteed data integrity. Inparticular, theservices offeredbyEncinafor
distributed OLTPincludefull data integrity with a transactional two-phase commit
protocol, ahigh-level application programming interface withsimplified transaction
semantics, andadditional transactional semantics required forachieving deterministic
results with RPCs.
Inaddition to Encina, two othertransaction processing environments gaining
popularity areCustomer Information Control System (CIC'S) andInformation Manage­
mentSystem(IMS),both from IBM. CICS is alreadybeing used by more than 20,000
customers in more than 90countries worldwide. Encinaoffersinteroperability withIBM's
CICS.Therefore, CICS can be implemented on topofthe DCE and Encinatechnology.
9.11.9User Interfaces to DFS
Distributed FileServicesupports thefollowing typesofuserinterfaces fordifferent types
of users:
1. Fileserviceinterface. DFS uses native operating systemcommands fordirectory
and fileoperations so that users do not need to learnnewcommands. Forexample, users
on UNIX systemswill usecdtochangedirectory, Isto listdirectory contents, mkdirto
createa newdirectory, and so on. DFS also has several commands that work only for its
own file system(Episode). Theseincludecommands tocheckquotasofdifferent filesets,
to locate the serverofa file, and so on. To accessa file, aclientmay specify the file by
its global nameor by its cell relativename.Detailsoftheobject-naming mechanism of
DeEare given in Chapter 10.
2.Application programming interface. Theapplication programming interface to
DFS is very similartoUNIX.Therefore, application programmers can usestandard file
systemcalls like fopen() foropeninga file,tread() to read from a file, fwrite() to write
to a file, [close() to close a file, and so on. In fact, most existing software will work
immediately by simply recompiling with the DFS libraries.
3.Administrative interface. Theadministrative interface ofDFSprovides commands
that allow the systemadministrator to handle filesets, to install or removeDFS file servers,484 Chap.9 •Distributed FileSystems
and to manipulate ACLs associated with files and directories. The commands for handling
filesets are used by the system administrator tocreate, delete, move, replicate, clone, back
up, or restore filesets. For example, the system administrator may move filesets from one
server machine toother server machines to balance theload across all file server machines
in a cell.
On the other hand, the commands to install or remove file servers allow the system
administrator to dynamically reconfigure the system as needs change. For example, the
systemadministrator maynotice that the DFS performance ofacell is not so goodbecause
there are too many clients and only a few file servers. In this case, he or she may install
anew file server inthecell and move some of the filesets fromalready existing fileservers
of the cell to this file server.
Finally, the commands to manipulate ACLs are used by the system administrator to
revoke some of the access permissions already given to some users or to give additional
permissions to some users.
9.11SUMMARY
A file is a named object that comes into existence by explicit creation, is immune to
temporary failures in the system, and persists until explicitly destroyed. A file system is
asubsystem ofan operating system that performs file management activities such as
organization, storing, retrieval, naming, sharing, and protection of files. A distributed file
system isa distributed implementation of the classical time-sharing model of a file system.
In addition to the advantages of permanent storage and sharing of information provided by
the file system of a single-processor system, a distributed file system normally supports
the following: remote information sharing, user mobility, availability, and diskless
workstations.
The desirable features of a good distributed file system are-transparency (structure
transparency, access transparency, naming transparency, and replication transparency),
user mobility, performance, simplicity and ease of use, scalability, high availability, high
reliability, data integrity, security, and heterogeneity.
From the viewpoint of structure, files are of two types-unstructured and structured.
On the other hand, according to modifiability criteria, files may be mutable or
immutable.
The twocomplementary models for accessing remote files are remote service model
anddata-caching model. In file systems that use the data-caching model, an important
design issue is to decide the unit of data transfer. The four commonly used units for this
purpose are file, block, byte, and record.
In shared files, the file-sharing semantics defines when modifications of file data
made by a user are observable by other users. The four commonly used file-sharing
semantics are UNIX semantics, session semantics, immutable shared-files semantics, and
transaction-like semantics.
Every distributed file system in serious use today uses some form of file
caching because, in addition to better performance, it also contributes to its seal-Sec.9.12 • Summary 485
ability and reliability. In a distributed file system, a cache may be located in a
server'smain memory, a client'sdisk,Ofaclient'smain memory. Keeping file data
cached at multiple client nodes consistent is animportant design issue in distributed
file systems that use client caching. The approaches for handling this issue depend
on the schemes used to propagate modifications made to cached data to the
corresponding file server and to verify the validity of cached data. The write-through
scheme and the delayed-write scheme are the two commonly used schemes for
modification propagation. The cache validation approaches may either be client
initiated or server initiated.
A replicated file is a file that has multiple copies, with each copy located on a
separate file server. Each copy of the set of copies that comprises a replicated file is
referred to as a replicaof the replicated file. Replication of files in a distributed system
offers the following potential benefits: increased availability, increased reliability,
improved response time, reduced network traffic, improved system throughput, better
scalability, and autonomous operation. Maintaining consistency among copies when a
replicated file is updated is the major design issue of a file system that supports replication
of files. Some of the commonly used approaches to handle thisissue are read-only
replication, read-any-write-all protocol, available-copies protocol, primary-copy proto­
col, andquorum-based protocols.
Fault tolerance is an important issue in the design of a distributed file system. The
three primary file properties that directly influence the ability ofadistributed file system
to tolerate faults are availability, robustness, and recoverability. Replication is a primary
mechanism for improving the availability of a file. Robust files are implemented by
redundancy techniques such as stable storage. Recoverable files are realized by atomic
update techniques.
A server may be implemented by using either a stateful or a stateless service
paradigm. A stateful file server maintains clients'state information from one access
request to the next. On the other hand, a stateless file server does not maintain any
client state information. Therefore, every request from a client must be accompanied
with all the necessary parameters to successfully carry out the desired operation. The
stateless service paradigm makes crash recovery very easy because no client state
information ismaintained by the server and each request contains all the needed
information.
An atomic transaction (orjusttransaction for short) is a computation consisting
of acollection ofoperations that take place indivisibly in the presence of failures and
concurrent computations. The three essential properties of transactions are atomicity,
serializability, and permanence. A distributed transaction service is an extension of the
traditional transaction service, which can support transactions involving files managed
bymore than one server. Nested transactions are a generalization of traditional
transactions in which a transaction maybe composed of other transactions called
subtransactions.
The general principles for designing distributed file systems as proposed by
Satyanarayanan are-know that clients have cycles to burn, cache whenever possible,
exploit usage properties, minimize systemwide knowledge and change, trust the fewest
possible entities, and batch if possible.486 Chap. 9 • Distributed FileSystems
EXERCISES
9.1.Inwhataspectsis the design ofadistributed filesystemdifferent from that ofa filesystemfor
acentralized time-sharing system?
9.2.Namethe main components ofadistributed file system. What might bethereasonsfor
separating thevariousfunctions ofadistributed filesysteminto these components?
9.3.In thedesignofadistributed filesystem,highavailability and high scalability aremutually
relatedproperties. Discuss.
9.4.In thedesignofadistributed filesystem,highperformance and high reliability areconflicting
properties. Discuss.
9.5.Whatis animmutable file? Can a file systembedesigned tofunction correctly by using only
immutable files? If no, explainwhy. If yes, explainhow the basic file operations (create,read,
write,delete)can beperformed in this file system for shared files.
9.6.Discusstherelativeadvantages anddisadvantages of using full-file cachingand block caching
modelsfor thedata-caching mechanism of adistributed file system.
9.7.Ofthe four data transfermodelsthat may be used in a distributed filesystemthat uses the data­
cachingmodel for file accessing, which models are suitablefor each of the following types of
distributed systems:
(a) Adistributed systemthatsupports diskless workstations
(b) Adistributed systemin which each node has large disk storagespace
(c) Adistributed system that uses the structured file model in which each file is a groupof
records
If more than one model is suitablefor aparticular case, which model will you preferto use and
why?
9.8.Inyouropinion, where(inservermemory, in clientdisk, or in clientmemory) shouldacache
forcachingdata belocatedin thefollowing types ofdistributed filesystems(givereasonsfor
youranswer):
(a) One that supports diskless workstations
(b) One that uses the file-level transfermodel as unit of data access
(c) One that uses sessionsemantics
(d) One that is designed tooccasionally supportdisconnected operation
(e) One in which the ratio of numberofclientstonumberof fileserversis very large
(t)One that has to handlefairly large files
(g) One that supports UNIX-like file-sharing semantics
If more than one locationissuitablefor aparticular case, which one will you preferto use and
why?
9.9.Suppose you have to designthecachingschemeof adistributed filesystemthat has to support
sessionsemantics. Suggest asuitable solution for each of the following issues in your
design:
(a)Whereto locate a cache?
(b) What shouldbe the unit of data caching?
(c)Whenshouldmodification to acacheddata bepropagated to itsmastercopy?
(d)Whenshouldthevalidation tocheckif acachedcopyofa data isconsistent with itsmaster
copybeperformed?
Givereasonsforyouranswer.Chap. 9 • Exercises 487
9.10. A distributed operating systemdesigner is of the opinionthat since both replication and
caching ofobjectsprovide more or less similaradvantages to adistributed system, both
concepts need notbeimplemented in the same distributed system. Is he or she correct?Give
reasons for your answer. Now differentiate among the following types ofdistributed operating
systemsby listing their relativeadvantages anddisadvantages:
(a) One that implements objectcachingbut no object replication
(b) One that implements objectreplication but no object caching
(c) One that implements both object cachingandobjectreplication
9.11. In the design of a distributed operating system, the data-caching mechanism may be used for
cachingmanydifferent types of data. A separate cache can bemaintained for each type of
data. In your opinion, is it necessary to always keep a cached data up to date? If yes, explain
why. If no, give an example in which a system can function correctly even when processes
accesscacheddata that are not always up to date.
9.12.Suppose a file system uses the client-initiated approach for validating the contents ofclient
caches. Also suppose that the validity check is performed bycomparing the time of last
modification of the cached version of the data with the server'smaster copy version. This file
system will not function correctly in a system in which the clocks of various nodes are not
synchronized. Suggesta scheme that can beused with the client-initiated approach for cache
validation insystemsin which clocks of various nodes are not synchronized.
9.13.Differentiate among the following properties of adistributed file system:
(a) High degree of availability
(b) High degreeofrecoverability
(c) High degree of robustness
Name asuitablemechanism that may be used for implementing each of these properties.
9.14.Explain how a stable-storage systemconverts fallible disks into reliable devices. In the
discussion in this chapter, we saw a stable-storage systemdesigned with two conventional
disks. Can this idea be extended to three disks for better crash resistance capability? If no,
explain why. If yes, explain how.
9.15.Astateful file serverrecords state information for its clients. What problems are associated
with this type of file server? Give two examples where it might be necessary to use stateful
file servers.
9.16. Adistributed system based on the workstation-server model provides on-line help facility to
its users by allowing the users to read the on-linemanuals byusing the mancommand.
Suggestdifferent possible locations for storing the manuals in the system and discuss their
relativeadvantages anddisadvantages.
9.]7.What is a transaction? What are the two main factors that threaten the atomicity of
transactions? Describe how atomicity is ensured for atransaction in both commit and
abort.
9.18.Why are transactions needed in a file service? Give suitable examples toillustrate how
transactions help in doing the following:
(a)Improving therecoverability of files in the event of failures
(b)Allowing theconcurrent sharing of mutable files by multiple clients in a consistent
manner
9.19. Discuss the need for serializability property in transactions. What is the main goal in devising
amechanism forsatisfying thisproperty? Describe at least three mechanisms that may be used
in theimplementation of atransaction facility for satisfying this property. Now compare the
mechanisms described by you to show how close each of them is to the main goal.488 Chap. 9 • Distributed File Systems
9.20. Give two methods that may be used in the design of a file system to record updates to a file
in a reversible manner. That is, the file system provides the flexibility to the users to cancel
the updates made toa file within an open-close session and revert the file back to the state that
it was in before the start of the session.
9.21. Let the initial balance in all the three accounts of the two banking transactions of Figure 9.9
be $100. For these two transactions, enumerate all the schedules that produce different final
values of z.Which of these are legal schedules?
9.22.An application consists of three transactions T}, T2,andT3that are defined below:
T}:begin_transaction
read(x);readtz);write(x-5); write(z+5);
end_transaction
T2:begin_transaction
readiz);write(z-8); read(y); write(y+8);
end_transaction
T3:begin_transaction
read(x); write(x+4); read(y); write(y-4);
end_transaction
Describe how the concurrency of these three transactions can be controlled by using the
following:
(a) Same type of locks for both read and write operations
(b) Type-specific locks
(c)Intention-to-write locks
(d) Optimistic concurrency control scheme
(e)Timestamp-based concurrency control scheme
9.23. What are serially equivalent schedules? For the three transactions of the previous exercise
give at least six schedules that are serially equivalent.
9.24. Figure 9.10 shows two schedules of the operations of the two transactions of Figure 9.9 that
produced unexpected final results. Show that if both transactions use the two-phase locking
protocol, these schedules produce correct results.
9.25. Prove that if all transactions ·of an application use the two-phase locking protocol, all
schedules formed by interleaving their operations are serializable.
9.26.What is false sharing? Discuss the importance of granularity of locks in combating the false­
sharing problem.
9.27.What is a transaction deadlock? Give an example to illustrate how a transaction deadlock
occurs when:
(a) The same type of locks are used for both read and write operations.
(b) Type-specific locks are used.
Now give a method that may be used to avoid transaction deadlocks and apply the method to
your examples to show how it prevents the deadlocks that occurred in cases (a) and (b).
9.28.Suppose the optimistic concurrency control mechanism is used in the implementation of the
transaction mechanism of a file system. Give two examples of concurrently executing
transactions in this system:
(a) One in which the validation check is successful for all transactions and they are
committed successfully
(b) One in which the validation check fails and a transaction has to beabortedChap. 9 • Bibliography 489
9.29.Inwhat manner is the timestamp-basedconcurrency control scheme betterthan theoptimistic
concurrency control scheme? For the example giyen by you for case (b) of the previous
exercise, use the timestamp-based concurrency control scheme and show that the transaction
that was aborted cannot complete its first phase in this case.
9.30. What advantages does nested transactions facility have over traditional transaction facility in
a distributed system? Answer the following questions for a nested transactions family:
(a) Can a transaction commit independent of other transactions in the family?
(b)Can a transaction abort independent of other transactions in the family?
(c) When do the changes made to data items by atransaction become visible to other
transactions in the family?
(d)What happens if a transaction in the family fails?
(e) When are the updates performed by a transaction made permanent?
(f)When does the entire transaction family commit and success is reported to the client?
Give reasons for your answer.
9.31. Inadistributed system based on the workstation-server model, a server machine isdedicated
to work as a file server.The file system usesthe remote service modelforprocessingclients'
requests. With the passage of time, the number of workstations gradually increases in the
system, and it is found that the system performance has degraded because the file server is
often overloaded by requests from clients.As an expert of distributed operating systems, you
are contacted to solve this problem. Describe three different solutions that may be used to
solve this problem.
9.32.Describethe two-phase, multiservercommit protocol. Inthe bankingtransactiongivenbelow,
supposeaccounts XandYbelongtotwodifferentbranches of abank.The localrecords ofthe
two branches are managed by file servers 51and52,respectively.
a1:begin_transaction
a2:read balance (x)of account X
a3:read balance (y)of account Y
a4:write(x-5)toaccountX
as:write(y+5)to account Y
a6:end_transaction
For the above transaction, ifS1is the coordinator and 52is the worker, give the list of
messages exchanged among the client and file servers 5)andS2for the successful execution
of this transaction. What will happen if52crashes after performing operation as?
BIBLIOGRAPHY
[Agrawal and Jalote1995]Agrawal, G., and Jalote, P.,"Coding-Based Replication Schemes for
Distributed Systems," IEEE Transactions on ParallelandDistributed Systems,Vol.6,No.3,pp.
240-251 (1995).
[Ahamad etal. 1991]Ahamad, M.,Ammar,M.H.,andCheung, S.Y.,"Multi-dimensional Voting,"
ACMTransactions onComputer Systems,pp.399-431 (November 1991).
[Barghouti and Kaiser 1991] Barghouti, N. S., and Kaiser, G. E., "Concurrency Control in
Advanced Database Applications," ACMComputing Surveys, Vol. 23,No.3,pp.269-318
(1991).
[Bernstein and Goodman 1981] Bernstein, P. A.,and Goodman, N., "Concurrency Control in
DistributedDatabaseSystems," ACMComputing Surveys,Vol.13,No.2, pp.185-221 (1981).490 Chap. 9 • Distributed File Systems
[Bernstein and Goodman 1984]Bernstein, P. A.,and Goodman, N., "An Algorithm for
Concurrency Control and Recovery in Replicated Distributed Databases," ACMTransactions on
Database Systems, Vol.9,No.4,pp.596-615 (1984).
[Bernstein et al.1980]Bernstein, P.A.,Shipman, D.W.,andRothnie,1.B.,"Concurrency Control
in a System for Distributed Databases (SDD-l)," ACMTransactions on Database Systems, Vol.
5,No.1,pp.18-51(1980).
(Bernstein et al, 1987]Bernstein, P. A., Hadzilacos, V., and Goodman, N.,Concurrency and
Recovery in Database Systems, Addison-Wesley, Reading, MA, pp. 289-307 (1987).
[Brown et al. 1985]Brown,M.,KoJling,K.,and Taft, E., "The Alpine File System," ACM
Transactions on Computer Systems, Vol. 3,No.4,pp.261-293 (1985).
[Chen et al. 1995)Chen,K.,Bunt, R. B., and Eager, D. L.,"WriteCaching inDistributed File
Systems," In:Proceedings ofthe 15th IEEE International Conference on Distributed Computing
Systems, IEEE, New York, NY(May-June 1995).
[Chutani et al.1992]Chutani, S., Anderson, o.T.,Kazar,M. L.,Leverett, B. W., Mason, W.A.,
andSidebotham, R. N., "The EpisodeFileSystem," In:Proceedings ofthe1992USENIX Winter
Conference. USENIX Association, Berkeley, CA, pp. 43-60(1992).
[Claybrook 1992]Claybrook, B., OLTP: Online Transaction Processing Systems, John Wiley, New
York (1992).
[Coulouris et ale1994]Coulouris, G. F., Dollimore, J., and Kindberg, T., Distributed Systems
Concepts and Design, 2nded.,Addison-Wesley, Reading, MA(1994).
[Davcev and Burkhard 1985]Davcev, D., and Burkhard, W.A.,"Consistency and Recovery
Control for Replicated Files," In: Proceedings ofthe10thACM Symposium on Operating Systems
Principles, Association forComputing Machinery, New York, NY, pp. 87-96(December
1985).
[Dion1980JDion,1,"TheCambridge File Server," ACMOperating Systems Review, Vol. 14, No.
4, pp.26-35(1980).
[Eswaran et al, 1976JEswaran, K. P.,Gray, 1N., Lorie, R. A., and Traiger, I.L., "The Notions of
Consistency andPredicate Locks in a Database System," Communications ofthe ACM, Vol. 19,
No. 11, pp. 624-633 (1976).
[Fridrich andOlder1985JFridrich, M., and Older, W., "Helix: The Architecture of the XMS
Distributed FileSystem," IEEE Computer, pp.21-29(1985).
[GilTord19798]Gifford, D. K., "Weighted Votingfor Replicated Data," In: Proceedings ofthe 7th
ACMSymposium on Operating Systems Principles, Association for Computing Machinery, New
York, NY, pp. 150-159 (December 1979).
[Gifford1979b]Gifford, D. K., "Violet: An Experimental Decentralized System," ACMOperating
Systems Review, Vol. 13, No. 5 (1979).
[GilTordet al,1988]Gifford, D. K., Needham, R. M., and Schroeder, M. D., "The CedarFile
System," Communications ofthe ACM, Vol. 31,No.3,pp.288-298 (1988).
[Goscinski 1991]Goscinski, A., Distributed Operating Systems, The Logical Design, Addison­
Wesley, Reading, MA (1991).
[Gray1978]Gray,J.N., "Notes on Database Operating Systems," Lecture Notes in Computer
Science, Vol. 60, Springer-Verlag, Berlin, pp. 393-481 (1978).
[Gray and Cheriton ·1989]Gray, C., and Cheriton, D., "Leases: An Efficient Fault-Tolerant
Mechanism forDistributed File System Consistency," In:Proceedings ofthe 11th ACM
Symposium on Operating Systems Principles, Association forComputing Machinery, New York,
NY, pp.202-210 (1989).Chap. 9 • Bibliography 491
(Gray and Reuter1993]Gray,1.,andReuter,A.,Transaction Processing: Concepts and
Techniques, Morgan Kaufmann, SanFrancisco, CA (1993).
[Gray et al. 1981]Gray,1.N.,Melones, P.,Blasgen,M.W.,Lorie,R.A.,Price,T.G.,Putzulu,G.
P., andTraiger,I.L.,"TheRecovery Manager of theSystemRDatabase Manager," ACM
Computing Surveys, Vol. 13,No.2,pp.223-242 (1981).
[HarderandReuter1983]Harder,T.,and Reuter, A.,"Principles ofTransaction-Oriented Database
Recovery," Computing Surveys, Vol. 15,No.4(1983).
[Herlihy ]986]Herlihy, M., "AQuorum-Consensus Replication MethodforAbstract DataTypes,"
ACMTransactions onComputer Systems, Vol. 4,No.1,pp.32-53(1986).
[Howard et ale1988]Howard, 1.H.,Kazar,M.L.,Menees,S. G.,Nichols, D.A.,Satyanarayanan,
M.,Sidebotham, R. N.,and West, M.1.,"ScaleandPerformance in aDistributed FileSystem,"
AC'MTransactions onComputer Systems,"01.6,No.1,pp.51-81(1988).
[Israel et al,1978]Israel,J. E.,Mitchell, J.G., andSturgis,H.E.,"Separating DatafromFunction
in aDistributed FileSystem," In: D.Lanciaux (Ed.),Operating Systems: TheoryandPractice,
NorthHolland, Amsterdam, pp.17-22(1978).
[Jalote1994]Jalote,P.,FaultTolerance inDistributed Systems,Prentice-Hall, Englewood Cliffs,
NJ(1994).
[Kazaret al, 1990] Kazar,M.L.,Leverett,B.W.,Anderson, O.T.,Apostolides, V.,Bottos,B.A.,
Chutani, S.,Everhart, C.F.,Mason,W.A.,Tu, S. T., and Zayas,E. R.,"Decorum FileSystem
Architectural Overview," In:Proceedings ofthe1990USENIX Summer Conference, USENIX
Association, Berkeley, CA,pp.151-163 (1990).
[Khanna 1994)Khanna,R. (Ed.), Distributed Computing: Implementation andManagement
Strategies, Prentice-Hall, Englewood Cliffs,NJ(1994).
[Kistler 1995]Kistler, J. J.,Disconnected Operation in aDistributed FileSystem,Springer-Verlag,
New York, NY (1995).
[Kistler and Satyanarayanan 1992]Kistler, J. J., and Satyanarayanan, M.,"Disconnected
Operation in theCodaFileSystem," ACMTransactions onComputer Systems, Vol. 10,No.1
(1992).
[Kotz and Ellis 1993]Kotz, D., and Ellis, C. S.,"Caching andWriteback Policies inParallelFile
Systems," JournalofParallel andDistributed Computing, Vol.17,Nos.1and2,pp.140-145
(1993).
[Kumar 1991JKumar,A.,"Hierarchical Quorum Consensus: ANewAlgorithm forManaging
Replicated Data,"IEEETransactions onComputers, Vol. 40,No.9,pp.996-1004 (1991).
(KungandRobinson 1981J Kung, H. T.,andRobinson, J. T.,"00Optimistic Methods for
Concurrency Control," ACMTransactions onDatabase Systems, Vol. 6,No.2,pp.213-226
(1981).
[Ladinetal,1992]Ladin,R.,Liskov,B.,Shrira,L., andGhemawat, S.,"Providing Availability
UsingLazyReplication," ACMTransactions onComputer Systems, Vol. 10,No.4,pp.360-391
(1992).
(Lampson 1981]Lampson, B.W.,"Atomic Transactions inDistributed Systems-Architecture and
Implementation," In: B. W. Lampson, M.Paul, and H. 1. Siegart(Eds.),AnAdvanced Course,
LectureNotes in Computer Science, Vol.105,Springer-Verlag, New York, NY,pp.246-264
(1981).
(Lazowska et al. 1986]Lazowska, E. D.,Zahorjan, J.,Cheriton, D., andZwaenepoel, W.,"File
AccessPerformance ofDiskless Workstations," ACMTransactions onComputer Systems, Vol. 4,
No.3,pp.238-268 (1986).492 Chap. 9 • Distributed FileSystems
[Leach et al. 1983]Leach, ~1.,Levine,P.H., Douros, B. P.,Hamilton, J. A.,Nelson,D.L.,and
Stumpf, B. L.,"TheArchitecture ofanIntegrated LocalNetwork," IEEE Journal on Selected
Areas in Communication, Vol.SAC-I,No.5,pp.842-857 (1983).
[Levine 1986]Levine,P. H.,"TheApolloDOMAIN Distributed File System," In Y. Parkeret al.,
(Eds.),Distributed Operating Systems: Theory and Practice, NATO ASI Series,Springer-Verlag,
New York, NY,Vol. F28, pp. 241-260 (1986).
[Levyand Silberschatz 1990] Levy,E.,andSilberschatz, A.,"Distributed FileSystems: Concepts
andExamples," ACMComputing Surveys, Vol. 22,No.4,pp.321-374 (1990).
[Liskovet al, 1991]Liskov,B.,Ghemawat, S.,Gruber,R., Johnson,P,Shrira,L.,andWilliams, M.,
"Replication in theHarpFile System," In: Proceedings ofthe 13th ACMSymposium on
Operating Systems Principles, Association forComputing Machinery, New York, NY, pp.
226-238 (1991).
[Lockhart Jr.1994]Lockhart, Jr.,H.W.,OSF DCE: Guide to Developing Distributed Applications,
IEEEComputer SocietyPress, Los Alamitos, CA (1994).
[Lyonetal. 1985]Lyon, B., Sager, G.,Chang,J.M.,Goldberg, D.,Kleiman, S., Lyon,T.,Sandberg,
R.,Walsh, D., and Weiss, ~,"Overview of the SUN Network FileSystem," In:Proceedings of
theUSENIX Conference, USENIX Association, Berkeley, CA, pp.1-8(January 1985).
[McKusick et al. 1985]McKusick, M. K., Karels, M. J., and Leffler, S. J., "Performance
Improvements andFunctional Enhancements in4.3BSD," In:Proceedings ofthe1985USENIX
Summer Conference, USENIX Association, Berkeley, CA, pp. 519-531 (1985).
[Mitchelland Dion 1982]Mitchell, 1.G.,and Dion, 1.,"A Comparison ofTwoNetwork- Based File
Servers," Communications of(heACM, Vol. 25,No.4,pp.233-245 (1982).
[Morriset al, 1986] Morris,1.H.,Satyanarayanan, M.,Conner,M.H.,Howard,1.H.,Rosenthal,
D.S.H.,andSmith,F. D.,"Andrew: ADistributed Personal Computing Environment,"
Communications ofthe ACM, Vol. 29,No.3,pp.184-201 (1986).
[Moss1985]Moss,E.,Nested Transactions,An Approach to Reliable Distributed Computing, MIT
Press,Cambridge, MA (1985).
[Mueller et al.1983]Mueller, E. T., Moore,1. D., and Popek, G.J.,"ANestedTransaction
Mechanism forLOCUS," In:Proceedings ofthe 9th ACM Symposium on Operating Systems
Principles, Association forComputing Machinery, New York, NY, pp. 71-85(1983).
[Mullender and Tanenbaum 1984]Mullender, S. J., and Tanenbaum, A. S.,"Immediate Files,"
Software Practice and Experience, Vol. 14,No.4,pp.365-368 (1984).
[Mullender and Tanenbaum 1985]Mullender, S.1., andTanenbaum, A.S., "ADistributed File
ServiceBasedonOptimistic Concurrency Control," In:Proceedings ofthe10thACM Symposium
on Operating Systems Principles, Association forComputing Machinery, New York, NY, pp.
51-62(December 1985).
[Needham and Herbert 1982]Needham, R. M., and Herbert, A. J.,theCambridge Distributed
Computing System, Addison-Wesley, Reading, MA (1982).
[Nelsonet al, 1988]Nelson,M.N., Welch, B. B.,andOusterhout, 1. K.,"Caching in the Sprite
Network FileSystem," ACM Transactions on Computer Systems, Vol. 6, No. I,pp.134-154
(1988).
[Ousterhout et al.1985]Ousterhout, J.K.,Costa,D.,Harrison, D., Kunze, J.A., Kupfler, M., and
Thompson, J.G., "ATrace-Driven Analysis ofthe UNIX 4.2 BSDFileSystem," In:Proceedings
ofthe10th.ACM Symposium on Operating Systems Principles, Association forComputing
Machinery, New York, NY, pp. 15-24(December 1985).Chap. 9 • Bibliography 493
[Popek and Walker 1985] Popek, G. 1.,and Walker, B. 1., TheLOCUS Distributed System
Architecture, MITPress, Cambridge, MA(1985).
[Ramamritham andChrysanthis 1996]Ramamritham, K.,and Chrysanthis, P. K.(Eds.),
Advances in Concurrency Control and Transaction Processing, IEEEComputer Society Press,
Los Alamitos, CA (1996).
[Rangarajan et ale1995] Rangarajan, S., Setia, S.,andTripathi, S. K., "A Fault-Tolerant Algorithm
for Replicated Data Management," IEEE Transactions on ParallelandDistributed Systems, Vol.
6, No. 12, pp. 1271-1282 (1995).
[Reed 1983] Reed, D. P., "Implementing Atomic Actions on Decentralized Data," ACM
Transactions on Computer Systems, Vol. 1,No.1,pp.3-23(1983).
[Rifkin et al. 1986]Rifkin, A. P.,Forbes, M. P., Hamilton, R. L., Sabrio, M., Shar, S., and Yueh,
K., "RFS Architectural Overview," In: Proceedings ofthe USENIX Conference, Atlanta, GA,
USENIX Association, Berkeley, CA, pp. 248-259 (1986).
[Rosenberry et al. 1992] Rosenberry, W., Kenney, D., and Fisher, G., OSFDISTRIBUTED
COMPUTING ENVIRONMENT, Understanding DeE,O'Reilly, Sebastopol, CA (1992).
[Sandberg 1987] Sandberg, R., "The Sun Network File System: Design, Implementation and
Experience," In:Proceedings ofthe USENIX Summer Conference, USENIX Association,
Berkeley, CA, pp. 300-314 (June 1987).
[Sandberg et ale1985]Sandberg, R., Goldberg, D., Kleinman, S.,Walsh, D., and Lyon,B., "Design
andImplementation of the SlJN Network File System," In: Proceedings ofthe USENIX Summer
Conference, Portland, OR, USENIX Association, Berkeley, CA, pp. 119-130 (June 1985).
[Santifaller 1994] Santifaller, M., TCPI1Pand ONCINFS, lntemetworking ina UNIX Environment,
2nd ed., Addison-Wesley, Reading, MA (1994).
[Satyanarayanan 1990a]Satyanarayanan, M., "A Survey of Distributed File Systems," Annual
ReviewofComputer Science,Vol.4, pp. 73-]04(1990).
[Satyanarayanan 1990b]Satyanarayanan, M., "Scalable, Secure, and Highly AvailableDistributed
File Access," IEEEComputer, Vol.23,No.5,pp.9-21(May 1990).
[Satyanarayanan 1992]Satyanarayanan, M., "The Influence of Scale on Distributed File System
Design," IEEE Transactions on Software Engineering, Vol. 18, No. 1 (January 1992).
lSatyanarayanan 1993]Satyanarayanan, M.,"Distributed File Systems," In: S. Mullender (Ed.),
Distributed Systems, 2nd ed., Association for Computing Machinery, New York, NY, pp.
353-383 (1993).
[Satyanarayanan et al.1985]Satyanarayanan, M., Howard, 1. H., Nichols, D. A., Sidebotham, R.
N., Spector, A. Z., and West, M. J., "The ITC Distributed File System: Principles and Design,"
In:Proceedings ofthe 10thACMSymposium onOperating Systems Principles, Association for
Computing Machinery, New York, NY,pp. 35-50(December 1985).
[Satyanarayanan etale1990]Satyanarayanan, M., Kistler, 1.1., Kumar, P.,Okasaki, M. E., Siegel,
E. H., and Steere, D. C., "Coda: A HighlyAvailable File System for a Distributed Workstation
Environment," IEEE Transactions on Computers, Vol. 39,No.4,pp.447-459 (April 1990).
[Schroeder et al. 1985] Schroeder, M. D., Gifford, D. K., and Needham, R. M., "A Caching File
System for a Programmer's Workstation," In: Proceedings ofthe 10th ACMSymposium on
Operating Systems Principles, Association for Computing Machinery, New York,NY,pp. 25-34
(December 1985).
[Silberschatzand Galvin 1994] Silberschatz, A., and Galvin, P.B., Operating System Concepts, 4th
ed., Addison-Wesley, Reading, MA (1994).494 Chap. 9 • Distributed File Systems
[SinghalandShivaratri 1994]Singhal,M., andShivaratri, N. G.,Advanced Concepts in Operating
Systems, McGraw-Hili, New York (1994).
[Smith1982] Smith, A. 1., "CacheMemories," ACMComputing Surveys, Vol. 14,No.3,pp.
473-530 (1982).
[Stalling 1995] Stalling, W.,Operating Systems, 2nd ed., Prentice-Hall, Englewood Cliffs, NJ
(1995).
[Sturgiset al,1980] Sturgis, H., Mitchell, 1. G., and Israel, 1., "Issuesin theDesignand Use of a
Distributed FileSystem," ACMOperating Systems Review, Vol. 14,No.3,pp.55-69(1980).
[Svobodova 1984]Svobodova, L.,"FileServersforNetwork-Based Distributed Systems," ACM
Computing Surveys, Vol. 16,No.4,pp.353-398 (1984).
[Tanenbaum 1987JTanenbaum, A.S.,Operating Systems: Design and Implementation, Prentice­
Hall,Englewood Cliffs, NJ (1987).
[Tanenbaum 1995]Tanenbaum, A. S.,Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ(1995).
[Terry1987] Terry, D. B., "Caching Hints inDistributed Systems," IEEE Transactions on Software
Engineering, Vol. SE-13, No.1,pp.48-54(1987).
[TichyandRuan1984] Tichy, W. F., and Ruan, Z., "Towards a Distributed File System," In:
Proceedings ofthe Summer USENIX Conference, USENIX Association, Berkeley, CA, pp. 87-97
(June 1984).
[Tomlinson et al, 1985J Tomlinson, G. M., Keeffe, D., Wand, I. C., and Wellings, A. 1., "The
PULSE Distributed FileSystem," Software Practice and Experience, Vol. 15, No. 11, pp.
1087-1101 (1985).
[ThrekandShasha1992] Turek, 1., and Shasha, D., "TheMany Faces of Consensus inDistributed
Systems," IEEE Computer, Vol. 25,No.6,pp.8-17(J992).
[Van Renesse andTanenbaum 1988] Van Renesse, R., and Tanenbaum, A.S.,"Voting with
Ghosts," In: Proceedings ofthe 8th IE~EEInternational Conference on Distributed Computing
Systems, IEEE Press, New York, NY, pp. 456-461 (June 1988).
[Weihl1993] Weihl, W. E., "Transaction-Processing Techniques," In: S.Mullender (Ed.),
Distributed Systems, 2nd ed., Association forComputing Machinery, New York, NY, pp.
329-352 (1993).
[Weikum 1991] Weikum, G., "Principles andRealization of Multilevel Transaction Management,"
ACMTransactions on Database Systems, Vol. ]6, No. r,pp.]32-]40 (1991).
POINTERS TOIIIUOGRAPHIES ONTHEINTERNET
Bibliographies containing references on Distributed File Systems can be found at:
ftp:ftp.cs.umanitoba.calpub/bibliographieslDistributed/distfs.html
ftp:ftp.cs.umanitoba.calpub/bibliographieslDistributed/dist.sys.html
Bibliography containing references on ObjectReplication inDistributed Systemscan be
found at:
ftp:ftp.cs.umanitoba.calpub/bibliographieslDistributed/Dist.Sys.htmlChap.9 • PointerstoBibliographies ontheInternet
Bibliography containing references onAFS(Andrew FileSystem)can be found at:
http:www.transarc.comlProductIAFSIFAQ/faq.html#-sub6495CHAPTER10
Naming
10.1 INTRODUmON
Adistributed system supports several types ofobjects such asprocesses, files, I/O devices,
mail boxes, and nodes.The namingfacilityof adistributed operating system enables users
and programs to assign character-string names to objects and subsequently use these
names to refer to those objects. The locating facility, which is an integral part of the
naming facility,maps anobject's name to the object'slocation inadistributed system.The
naming and locating facilities jointly form a naming system that provides the users with
an abstraction of an object that hides the details of how and where an object is actually
located in the network. Itprovides a further level of abstraction when dealing with object
replicas. Given an object name, it returns a set of the locations of the object'sreplicas.
The naming system plays a very important role in achieving the goal of location
transparency in a distributed system. In addition to facilitating transparent migration and
replication of objects, the naming system also facilitates object sharing. Ifvarious
computations want to act upon the same object, they are enabled to do so by each
containing a name for the object.Although the names contained ineach computation may
not necessarily bethe same, they are mapped to the same object in this case.
This chapter presents a description of the various approaches in the design and
implementation of naming systems for distributed systems.
496Sec. 10.2 • Desirable Features of a Good Naming System
10.1DESIRABLE FEATURES OFAGOODNAMING SYSTEM497
Agoodnamingsystemfor adistributed systemshouldhave the features described
below.
1. Location transparency. Location transparency meansthat the name ofanobject
shouldnotrevealany hint as to the physical locationofthe object. Thatis, anobject's
nameshouldbeindependent of thephysical connectivity ortopology of thesystem,or the
currentlocationoftheobject.
2. Location independency. Forperformance, reliability, availability, andsecurity
reasons, distributed systems provide the facility ofobjectmigration thatallowsthe
movement andrelocation ofobjectsdynamically amongthevariousnodes of a system.
Location independency meansthat thenameofanobjectneed not be changed when the
object'slocation changes. Furthermore, a usershouldbe able to access an objectby its
same name irrespective ofthe node from where he or she accesses it.Therefore, the
requirement oflocationindependency calls for a globalnamingfacility with the following
two features:
• Anobjectat any node can be accessed withouttheknowledge ofitsphysical
location (location independency ofrequest-receiving objects).
• Anobjectat any node can issue an access requestwithouttheknowledge of its
ownphysical location (location independency ofrequest-issuing objects). This
property is alsoknownasuser mobility.
Alocation-independent namingsystern must supportadynamic mapping schemeso
that it can map the same objectname to different locations at twodifferent instances of
time.Therefore, location independency is astronger property thanlocation transparency
[Levy and Silberschatz 1990].
3. Scalability. Distributed systems vary in size ranging from one with a few
nodes to one with many nodes. Moreover, distributed systems arenormally open
systems, andtheirsizechanges dynamically. Therefore, it isimpossible to have an a
prioriideaabouthow large the set ofnamesto bedealtwith isliableto get.Hence
anamingsystemmust be capableofadapting to thedynamically changing scaleofa
distributed systemthatnormally leads to a changein the size ofthe name space. That
is, achangein thesystemscaleshouldnotrequireanychangein thenamingor
locating mechanisms.
4. Uniform naming convention. In many existingsystems, different waysofnaming
objects,callednamingconventions, are used for namingdifferent types of objects.For
example, filenamestypically differ from user namesandprocessnames.Insteadof using
suchnonuniform namingconventions, a goodnamingsystemshoulduse the same naming
convention for all types ofobjectsin the system.498 Chap.10 •Naming
5. Multiple user-defined names forthe same object. For a shared object, it is
desirable that different users of the object can use their own convenient names for
accessing it. Therefore, a naming system must provide the flexibility to assign
multiple user-defined names to the same object. In this case, it should be possible for
a user to change or delete his or her name for the object without affecting those of
other users.
6. Group naming. A naming system should allow many different objects to be
identified by the same name. Such a facility is useful to support broadcast facility or to
group objects for conferencing or other applications.
7. Meaningful names. A name can be simply any character string identifying
some object. However, for users, meaningful names are preferred to lower level
identifiers such as memory pointers, disk block numbers, or network addresses. This
is because meaningful names typically indicate something about the contents or
function of their referents, are easily transmitted between users, and are easy to
remember and use. Therefore, a good naming system should support at least two
levels of object identifiers, one convenient for human users and one convenient for
machines.
8. Performance. The most important performance measurement of a naming system
is the amount of time needed to map an object'sname to its attributes, such as its location.
In a distributed environment, this performance is dominated by the number of messages
exchanged during the name-mapping operation. Therefore, a naming system should be
efficient in the sense that the number of messages exchanged in a name-mapping
operation should be as small as possible.
9. Fault tolerance. A naming system should be capable of tolerating, to some
extent, faults that occur due to the failure of a node or a communication link in a
distributed system network. That is, the naming system should continue functioning,
perhaps in a degraded form, in the event of these failures. The degradation can be in
performance, functionality, or both but should be proportional, in some sense, to the
failures causing it.
10. Replication transparency. In a distributed system, replicas of an object are
generally created to improve performance and reliability.A naming system should support
the use of multiple copies of the same object in a user-transparent manner. That is, if not
necessary, a user should not be aware that multiple copies of an object are in use.
11. Locating the nearest replica. When a naming system supports the use of
multiple copies of the same object, it is important that the object-locating mechanism
of the naming system should always supply the location of the nearest replica of the
desired object. This is because the efficiency of the object accessing operation will be
affected if the object-locating mechanism does not take this point into consideration.
This isillustrated by the example given in Figure 10.1, where the desired object is
replicated at nodes N2,N3,andN4and theobject-locating mechanism is such that it
maps to the replica at node N4instead of the nearest replica at node N2.Obviously
this is undesirable.Sec.10.3 • Fundamental Terminologies andConcepts
c O:~tt--__..Object
---
----------------------~--
Iftheobjectlocating mechanism maps tonode N 4instead ofnode N2?
Fig. 10.1 Illustrating the importance of locating the nearest replica of an object.499
12. Locating all replicas. In addition to locating the nearest replica of an object, it
is alsoimportant from a reliability point of view that all replicasofthe desired object be
located by the object-locating mechanism. A need for this property isillustrated in Figure
10.2, where the nearestreplica at node N5iscurrently inaccessible due to a
communication link failure in the network. In this case, anotherreplica of the objectat a
farther node N4can be used.
Client node
Object
Ns
Fig. 10.2 Illustrating the importance of locating all the replicas of an object.
10.3FUNDAMENTAL TERMINOLOGIES ANDCONCEPTS
The naming system is one of the most important components of adistributed operating
systembecauseitenablesother services and objects to be identified and accessed in a
uniform manner. In spite oftheimportance of names, no general unified treatment of them
exists in the literature. This section defines and explains the fundamental terminologies
andconcepts associated with object naming in distributed systems.
10.3.1 Name
Anameisastring composed ofasetofsymbols chosen from afinite alphabet. For example,
SINHA,#173#4879#5965, node-1!node-2!node-3!sinha, laIble,25A2368DM197, etc.
careallvalid names composed of symbols from the ASCII character set. A name is also
called an identifier becauseitis used to denote or identify an object. A name may also be500 Chap.10 •Naming
thought of as a logical object that identifies a physical object to which it is bound from
among acollection of physical objects. Therefore, the correspondence between names and
objects is the relation of binding logical and physical objects for the purpose of object
identification.
10.3.2Human-Orl4Mted andSystem-Oriented Names
Names are used to designate or refer to objects at all levels of system architecture. They
have various purposes, forms, and properties depending on the levels at which they are
defined. However, an informal distinction can bemade between two basic classes of
names widely used in operating systems-human-oriented names and system-oriented
names.
Ahuman-oriented name isgenerally a character string that is meaningful to its users.
For example, lusertsinhalproject-Ilfile-I is ahuman-oriented name.Human-oriented
names are defined by their users. For a shared object, different users of the object must
have the flexibility to define their own human-oriented names for the object for accessing
it. Flexibility must also be provided so that a user can change or delete his or her own
name for the object without affecting those of other users. For transparency, human­
oriented names should be independent of the physical location or the structure of objects
they designate. Human-oriented names are also known as high-level namesbecause they
can be easily remembered by their users.
Human-oriented names are not unique for an object and are normally variable in
length not only for different objects but also for different names for the same object.
Hence, they cannot be easily manipulated, stored, and used by the machines for
identification purpose. Moreover, it must be possible at some level to uniquely identify
every object in the entire system. Therefore, in addition to human-oriented names, which
are useful for users, system-oriented names are needed to beused efficiently by the
system. These names generally are bit patterns of fixed size thatcan beeasily manipulated
and stored by machines. They are automatically generated by the system. They should be
generated in a distributed manner to avoid the problems of efficiency and reliability of a
centralized unique identifier generator. They are basically meant for use by the system but
may also be used by the users. They are also known as uniqueidentifiers andlow-level
names.
Figure 10.3shows a simple naming model based on these two types of names. In this
naming model, a human-oriented name is first mapped (translated) to a system-oriented
name that is then mapped tothe physical locations of the corresponding object'sreplicas.
10.3.3 Name Space
A naming system employs one or more naming conventions for name assignment to
objects. For example, a naming system may use one naming convention for assigning
human-oriented names to objects and another naming convention for assigning system­
oriented names to objects. The syntactic representation of a name as well as its semantic
interpretation depends on the naming convention used for that name. The set of names
complying with a given naming convention is said to form a name space [Terry 1984].Sec. 10.3 • Fundamental Terminologies and Concepts
Physicaladdresses
ofthenamedobject
,.-------- ...,
~ ,
I \
I
I501
Human-oriented t--r-----...
nameSystem-oriented t---.~---- ___
name
First-level
mappingSecond-level
mapping, ,
\ I , ~,----------"
Fig. 10.3 A simple naming model based on the use of human-oriented and
system-oriented names in a distributed system.
10.3.4FlatNameSpace
Thesimplest namespaceis a flat name space wherenamesarecharacter stringsexhibiting
nostructure. Namesdefinedin a flat name space are calledprimitive orflatnames.Since
flatnamesdo not have any structure, itisdifficult toassignunambiguous meaningful
namesto a large set of objects.Therefore, flatnamesaresuitablefor useeitherfor small
namespaceshavingnamesfor only a few objectsor forsystem-oriented namesthat need
notbemeaningful to the users.
10.3.5Partitioned Name Space
Whenthereis a need to assign unambiguous meaningful names to a large set of objects,
anamingconvention thatpartitions the name space into disjointclassesisnormally used.
Whenpartitioning is donesyntactically, whichisgenerally the case, the namestructure
reflectsphysical ororganizational associations. Eachpartitionofapartitioned namespace
iscalledadomainofthe name space.
Eachdomainofapartitioned name space may be viewedas a flat namespace by
itself, and the namesdefinedin adomainmust beuniquewithinthatdomain. However,
twodifferent domains may have a common namedefinedwithinthem. Anamedefinedin
adomainiscalledasimple name. In apartitioned namespace, all objectscannotbe
uniquely identified bysimplenames, and hence compound namesare used for the purpose
ofuniqueidentification. Acompound nameiscomposed ofone or more simplenamesthat
areseparated byaspecialdelimiter character such asI,$,@,%, and so on (following the
UNIXfilesystemconvention, thedelimiter characterIwill be used for the examples and
discussion presented in thischapter). Forexample, lalbleis acompound nameconsisting
of three simplenamesa, b, and c.
Acommonly used type ofpartitioned namespaceis thehierarchical namespace,in
which the namespaceispartitioned intomultiple levelsand isstructured as aninverted502 Chap.10 • Naming
tree. Each node of the name space tree corresponds to a domain of the name space. In this
typeofname space, the number of levels may be eitherfixed or arbitrary. For instance,
theGrapevine system manages a name space tree having two levels [Birrell et aI. 1982],
while in the Xerox Clearinghouse, a name space tree has three levels [Oppen and Dalal
1983]. On the other hand, the DARPA InternetDomain Naming System [Su and Postel
1982] and the Universal Directory Service proposed in [Lantz et a1.1985] allow a name
space tree to have arbitrarily many levels. Names defined in a hierarchical name space are
calledhierarchical names.
Hierarchical names have been used in file systems for many years and have recently
beenadoptedfor naming other objects as well in distributed systems. Several examples of
hierarchical name spaces are also found in our day-to-day life. For instance, telephone
numbers fully expanded to include country and area codes form a four-level hierarchical
name space and network addresses incomputer networks form a three-level hierarchical
name space where the three levels are for network number, node number, and socket
number.
10.3.6Name Server
Name spaces are managed by name servers. A nameserveris a process that maintains
information about named objects and provides facilities that enable users to access that
information. It acts to bind an object'sname to some of its properties, including the
object'slocation [Terry 1984].
In practice, several name servers are normally used for managing the name space of
object names in a distributed system. Each name server normally has information about
only a small subset of the set of objects in the distributed system. The name servers that
store the information about an object are called the authoritative nameserversof that
object[Terry 1984]. To determine the authoritative name servers for every named object,
the name service maintains authority attributes that contain a Jistof the authoritative name
servers for each object.
Partitioned name spaces are easierto manage efficiently as compared to flat name
spaces because they enable the amount of configuration data required in each name server
to be reduced since itneed only be maintained for each domain and not for each individual
object. For example, in a hierarchical name space, it is sufficient that each name server
store only enough information to locate the authoritative name servers for the root domain
of the name tree. The authoritative name servers of the root domain, in turn, should know
thelocations oftheauthoritative name servers of the domains that branch out from the root
domain. In general, the authoritative name servers of a domain should know the locations
oftheauthoritative name servers of only those domains that branch out from that domain.
Forexample, in the name space tree of Figure 10.4, all name servers must know the
locations oftheauthoritative name servers of domain DJ;theauthoritative name servers
of domain D)need only know the locations of the authoritative name servers of domains
Dz,D3,andD4;and theauthoritative name servers of domain D2need only know the
locations of the authoritative name servers of domains D sandD6•Therefore, the amount
ofconfiguration data that must be maintained by name servers at the various levels of the
hierarchy is proportional to the degree of branching of the name space tree. For thisSec.10.3•Fundamental Terminologies andConcepts S03
Fig. 10.4 Domains of a hierarchical name space.
reason, hierarchicaJ namingconventions with several levels are often bettersuited for
naminglargenumberofobjects.
Itisimportant to note that the internal representation of a name serverneed not
necessarily reflectthestructure oftheabstractnaming system. For example, rather than
adopt to a hierarchical internalstructure, a nameservermaycompress hierarchical names
into a flat data structure and do string comparisons ofentirecompound names instead of
matching asequence ofsimple-name components. In fact, some name servers use a
procedure-based strategyratherthantable-based strategytoimplement thebindings in a
givendomainofthe name space. However, one-to-one correspondence between name
servers and domains facilitates easymanagement ofpartitioned name spaces.
10.3.7Name Agent
Thedistribution ofthe name service and the locations of the name servers should be
transparent to theclientsofa name service. This transparency isachieved throughname
agentsthat act between nameserversandtheirclients. A name agent maintains a
knowledge ofexistingname servers. When a clientrequests for a name service, the name
agent uses the propercommunication protocol totransfertheuser'srequest to a proper
name server. On receiving a reply from the server, it forwards it to the client.
Name agents maybe of two types: (a) private,which work for a single client, and (b)
shared,which work for several clients. A privatename agent is structured as a set of
subroutines that are linked to the clientprogram. On theotherhand, a shared name agent
isstructured as a part ofanoperating system kernel, with systemcalls to invoke name
serviceoperations, or as aseparate processthat isaccessed viainterprocess communica­
tionprimitives.
Nameagentsare known byvarious names. For instance, in theCSNETNameServer
they are called"nameserveragentprograms," in the D~~RPA InternetDomain NameS04 Chap. 10 • Naming
Service(DNS) they are called "resolvers," in theDeEDirectory Servicethey are caJled
"clerks," and in the COSIE Name Serverthey are called "userinterfaces."
Namesare always associated with some context. Acontextcan bethoughtofas the
environment in which a name is valid. Because all names are interpreted relativeto some
context,acontext/name pair is said to form a qualified namethat can be used for uniquely
identifying an object.
The notion ofcontexthasprovedto be very useful for partitioning a name space into
smallercomponents. Often,contexts represent a division of the name space along natural
geographical, organizational,.or functional boundaries [Terry 1986]. In a partitioned name
space, each domaincorresponds to acontextofthe name space. Names in a contextcan
begenerated independently ofwhat names exist in any other context. Therefore, a name
mayoccurin more than one context. Contexts may also be nested, as in the case of
hierarchical name spaces. For example, in the name space tree ofFigure 10.5, contextC3
is nested within contextC2,which in turn is nested within contextC1•In nested contexts,
aqualified nameconsistsofa seriesofnamesidentifying, respectively, acontext, a
subcontext, asub-subcontext followed by a name inside the last sub-sub-...context. For
example, inFigure10.5, the qualified name for object 01that isassociated withcontext
C3will beC.IC2/C3101•
For thepurposeof name management, contexts provide a means ofpartitioning the
naminginformation database so that it may be distributed amongmultiple name servers.
Contexts represent indivisible units for storage and replication ofinformation regarding
namedobjects[Terry 1986].
Object(On)Fig. 10.5 Nested contexts.Sec.10.3•Fundamental Terminologies andConcepts
10.3.9NameResolutionsos
Name resolution is the process of mapping an object'sname to the object'sproperties,
such as its location. Since an object's properties are stored and maintained by the
authoritative name servers of that object, name resolution is basically the process of
mapping an object'sname to the authoritative name servers of that object. Once an
authoritative nameserverof the object has been located, operations canbeinvoked toread
or update the object'sproperties.
Each name agent in a distributed system knows about at least one name server a
priori. Toget a name resolved, aclient first contacts its name agent, which in tum contacts
a known name server, which may in turn contact other name servers. Because name
servers must beable to identify each other, they are also treated asobjects and are assigned
names. However, to avoid potential cycles, name servers at a given level of a naming
systemgenerally identify each other with system-oriented, low-level names.
In apartitioned name space, the name resolution mechanism traverses a resolution
chain from one contextto another until the authoritative name servers of the named object
areencountered. As shown in Figure 10.6, a given name is first interpreted in the context
to which it is associated. The interpretation either provides the authoritative name servers
of the named object or returns a new name and a new context to interpret that name. In
the former case the name resolution process ends, while in the latter case the interpretation
processcontinues as before until the authoritative name servers of the named object are
encountered. Notice that if all the contexts involved in the resolution of a name are
managed by a single name server, then the complete name resolution operation is carried
out by a single name server; otherwise more than one name server is involved in the name
resolution operation.
10.3.10Abbreviation/Alias
In case of partitioned name spaces, a qualified name, which is normally a compound
name, may consist of several simple names and may be very long. It may be inconvenient
for a user to specify the qualified name of an object every time he or she wants to use it.
Therefore, in a naming convention forpartitioned name spaces, users are generally
allowed to specify and use their own short-form substitutes for qualified names called
abbreviations. Allabbreviations defined by a user form a private context of that user. A
mapping of abbreviations toqualified names is maintained on a per private context basis.
When a user specifies an abbreviation, it is first converted to a qualified name by using
the mapping associated with the private contextof that user. Therefore, different users
may use the same abbreviation to identify different objects. For example, two users, user-l
anduser-2,may use the same abbreviation my-object-l to identify their objects having the
qualified namesluser-l/project-llgroup-l lobject-l and/user-2/project-5/group-3/object­
1,respectively. Abbreviations are also know as aliases.Notice that aliases are generally
simple names that need to be unique only in a single private context. The symbolic links
facility of the UNIX file system is an example of aliasing facility in a naming system.
In case of aliasing, a binding associates a single simple name with a qualified name.
However, a user may wish to identify an object by one of two or more simple names. AS06 Chap. 10 • Naming
Context(n)
Context(n-1)
Context(1)
Authoritative nameservers
ofthenamedobject
Context(i)=contextatlevel i
Name(i)=validnameincontextatlevel (i)
fili=mappingfunctionfromthenameincontext (i)Fig.10.6Context-by-context name
toanewnameincontext (j) resolution mechanism.
naming system may provide this flexibility to its users by aJlowingmany-to-one bindings
within a context. That is, more than one simple name may be bound to the same qualified
name within a given context. If this facility is provided, the simple names bound to the
same qualified name are called synonyms ornicknames.
10.3.11AbsoluteandRelatlv. Names
Another method to avoid the necessity to specify the full qualified name of an object in
tree-structured name spaces is the use of theconcept of current working context. Acurrent
workingcontextis also known by the shorter names currentcontextorworking context.
According to this concept, a user is always associated with a context that is his or her
current context. A user can change his or her current context whenever he or she
desires.Sec.10.3•Fundamental Terminologies andConcepts 507
In this method, object names can be of two types-absolute or relative. An absolute
namebegins at the root contextof the name space tree and follows a path down to the
specified object, giving the contextnames on the path. On the otherhand, arelativename
defines a path from the currentcontextto thespecified object. It is calleda relative name
becauseit is"relative to" (starts from) the user'scurrentcontext. For example, in the tree­
structured name space ofFigure 10.7, if the user'scurrentcontextisroot-context/context­
1/context-3, the relative name context-S/object- Jrefers to the same object as does the
absolute name root-context/context- J/context-3/context-5/object-l. Means are also pro­
vided in this method to refer to the parent contextof a context. For example, in the UNIX
file-naming convention, which uses tree-structured name space, two periods (..,
pronounced "dotdot") refer to a directory's parent directory (a directory is basically a
context). The root directory is its own parent.
User's
currentcontext
\.-------.
object-1 -------_.object-m
object-l--------. object-n
Fig. 10.7 A tree-structured name space to illustrate absolute and relative names.
In this method, a user mayspecify an objectin anyofthe following ways:
1. Using the full (absolute) name
2. Using a relativename
3.Changing thecurrentcontextfirst and then using a relative name508 Chap.10 •Naming
For example, inFigure 10.7,ifthe user whose current context is root-context/context­
llcontext-3 wants tospecify the object root-context/context-2/context-4/object-l, heor she
can do so in the following ways:
1. Specify the absolute name of the object, which is root-contextlcontext-Zlcontext­
4/object-l.
2. Specify the name of the object relative to hisor hercurrent context as . .I..Icontext­
2/context-4Iobject-l. In this relative name, the first dot dot refers to the parent context of
theuser'scurrent context, which is context-I, and the second dot dot refers to the parent
context of context-I, which is root-context.
3. Notice from the above two name specification methods that a relative name may
beequally long or even longer than the absolute name in somecases.This defeats the main
purpose of the use of relative names. Hence the third method is to first change the current
context of the user and then refer to the object by a name relative to the new context. For
instance, in the example above, the user may first use the context-changing command to
change his or her current context to the context named root-contextlcontext-2Icontext-4
and then simply specify the object by a simple name object-Ithat is relative to the user's
new current context.
10.3.11GenericandMulticast Names
We saw that the use of synonyms requires the naming system to support many-to-one
bindings. On the other hand, the use of generic and multicast names requires the naming
system to support one-to-many bindings. That is, the naming system must allow a simple
name to be bound to a set of qualified names.
In agenericnamingfacility, a name is mapped to anyoneof the set of objects to
which it is bound. This type of facility is useful in situations such as when a user wants
arequest to be serviced by any of the servers capable of servicing thatrequest and the user
is notconcerned with which server services his or her request.
In agroupormulticast namingfacility, a name is mapped to all the members of the
set of objects to which it is bound. This type of facility is particularly useful for the
broadcasting or multicasting of a message.
A naming system that supports descriptive/attribute-based names allows an object to be
identified by a set of attributes or properties that describe the object and uniquely identify
it among the group of objects in the name space. A partitioned name space having a rigid
structure (a rigid set of attributes) is an example of a descriptive naming convention. In
this case, each domain of the name space is used to define an attribute ofthe objects. An
attribute has both a type and a value. The type indicates the format and meaning of the
value field. For example, a typical set of attributes that may be used for uniquely
identifying a file object may be User=Sinha,Creation date=1995104106,File type =
Source,Language =Pascal,Name=Quicksort.Sec. 10.4 • System-Oriented Names sO'
Note that an attribute value may be the sameforseveralobjects,but allattributes
considered together referto asingleobject.Moreover, it is notalwaysnecessary tospecify
all theattributes ofanamingconvention toidentifyanobject.Attribute-based naming
systemsusuallyworkbasedon the idea that aquerymustsupplyenoughattributes so that
thetargetobjectcan beuniquely identified. Alsonoticethat in a partitioned namespace
usingdescriptive namingconvention, domains can bearranged in anyarbitrary manner.
Multicast orgroupnamingfacilitycan beeasilyprovided withattribute-based
namingbyconstructing anattribute for a list ofnames.Groupnamesareparticularly
useful in forming maildistribution lists and accesscontrollists.
10.3.14Source-Routing Name
Manynamespacesmirrorthestructure oftheunderlying physical network. Whenthe
structure ofa namespacehas the same form as the underlying networkofadistributed
system,thenamespacedefinessource-routing names.Asource-routing nameidentifies a
paththroughthenetworkofadistributed system.TheUNIX-to-UNIX Copy(UUCP) name
space that definesnamesofthe form host-I!host-2!host-3!sinha isanexampleofasource­
routingname space. The UUCPstyle names are calledsource-routing namesbecausethe
routethroughthenetwork isspecified at the source computer, Forinstance, in theexample
above, the specified route isfrom host-ltohost-2tohost-3tosinha.TheUUCPstylenames
arerelativenamesbecausethey must be interpreted relative to the startingpoint.
10.4SYSTEM-ORIENTED NAMES
System-oriented namesnormally have the following characteristic features:
1.Theyare large integersor bit strings. For example, in atypicalnamingsystem,
system-oriented namesmay bemembers ofsomelarge set of integers, such as the integers
up to2128_1.
2. They are also referredto asunique identifiers because in mostnamingsystems
they are guaranteed to be unique in both space and time. Thatis, these namesdo not
changeduringtheirlifetime, and once used, they are neverreused.Therefore, in the
namingsystemdiscussed above,a128-bitpatternreferseithertonothingor, if itrefersto
anything, to thesamething atalltimes. This is the main reasonwhy unique identifiers are
so large.
3.Unlikehuman-oriented namesthat are variable in length, all system-oriented
namesof anamingsystemareofthe same size irrespective ofthe type or locationofthe
objectidentified bythesenames. This allowsthenamingofallobjectsuniformly.
4.Sinceall thesystem-oriented namesofanamingsystemare ofuniformsize and
also arenormally shorterthanhuman-oriented names,manipulations likehashing, sorting,
and so on, can be easilyperformed on them. Hence,they aresuitableforefficient handling
bymachines.510 Chap. 10 • Naming
5. They are hard to guess and hence are sometimes also used for security..related
purposes. For example, they may be used as tickets of permission to access objects. A
computation that presents a valid name may be assumed to have been given it deliberately
rather than to have guessed or invented it. This is an example of use of protected names
or capabilities, one of the classical approaches to access control management.
6.System-oriented names are automatically generated by the system.
An important issue associated with system..oriented names is how to create a unique
name for each object in the system. Before describing the methods to handle this issue, it
is useful to mention that system..oriented names can be either unstructured or structured
(see Fig. 10.8 for an example of each type). Unstructured names have a single field of
large integers or bit strings that uniquely identifies an object but does not provide any
other information about the object. On the other hand, structured names contain more than
onecomponent, some of which provide information about the properties of the object
identified by its name. For example, a structured name may have a component that
specifies the node on which the object was created or the node on which the object is
currently located. The two basic approaches for the creation of these two types of system..
oriented names are discussed below.
Asinglefieldoflargeintegersorbitstrings
(a)
Nodeidentifier Localuniqueidentifier
(b)Fig. 10.8 (a)Unstructured and(b)structured
system-oriented names.
10.4.1CentrallHd Approach forGaneratlng
System-Oriented Names
Although the centralized approach may be used for the generation of both unstructured as
well as structured system-oriented names, it is mainly used by a naming system that uses
unstructured names. In this method, a standard, uniform global identifier is generated for
each object in the system by a centralized global unique identifier generator, and some
method is used to partition this global name space among the local domains of each node.
Each node either directly binds these global identifiers to the locally created objects or it
maps its local identifiers for the locally created objects to these global identifiers. In the
latter case, binding of local identifiers to global identifiers can be permanent or
temporary.Sec.10.4•System-Oriented Names 511
Thecentralized approach has the advantages that it is simple and easy to implement
and is the only methodforgenerating unstructured global unique identifiers. However, it
suffers from the drawbacks of poorefficiency andpoorreliability. The single global
uniqueidentifier generator may become a bottleneck for large name spaces. Also, the
continuous generation ofglobal unique identifiers is totally dependent on thereliability of
thecentralized global unique identifier generator.
10.4.2Distributed Approach forG8neratlng
System-Oriented Names
Toovercome thedrawbacks of poorefficiency and poor reliability of thecentralized
approach, several naming systems use the distributed approach for thegeneration of
system-oriented names. However, distributed generation forces the naming system to use
structured objectidentifiers. In thedistributed approach, the hierarchical concatenation
strategy is used to create global unique identifiers. In this strategy, each identification
domainisassigned a unique identifier, and a global unique identifier for anobjectis
createdbyconcatenating the unique identifier ofadomainwith anidentifier used within
this domain. Therefore, global unique identifiers generated in this manner basically
consist of two components-the domainidentifier and anidentifier within this domain.
Notice that each component may in turn consist oftwo or more subcomponents. For
example, the domain identifier for a wide area network may consist of two sub­
components-network identifier and node identifier within this network.
The next question that arises is how to generate uniqueidentifiers within a domain
in anefficient manner. One method to do this is to treat each node of the system as a
domain of the name space and treat a reading from the real-time clock (called timestamp)
of a node as a unique identifier within the node. With this, global unique identifiers take
the form of the pair (node-JD, timestamp). Another method is to treat each server as a
domain and then to allow a server to generate objectidentifiers for the objects it serves in
aserver-specific manner. In this case, global unique identifiers take the form of the pair
(server-JD, server-specific-unique -identifier ).
Although thedistributed approach has better efficiency and reliability as compared to
thecentralized approach, it suffers from the following drawbacks:
1. In aheterogeneous environment, the form and length of identifiers may be
different fordifferent computers (nodes), resulting in nonuniform global unique
identifiers. It may be awkward orinefficient forapplications to beprepared todeal
with the nonuniformity ofthese low-level identifiers.
2. Node boundaries or servers are explicitly visible in this scheme.
10.4.3Generating UniqueIdentifiers intheEvent
ofCrashes
Anotherimportant problemrelated with the creationof unique identifiers (whether global
or local) is to be able to create unique identifiers in the face of crashes. A crash may lead
to loss of the state information of a unique identifier generator. Therefore, upon recovery,512 Chap.10 •Naming
the unique identifier generator may not function correctly, which may result in the
generation ofnonunique identifiers. Two basic approaches are used to solve this problem
[Watson 1981]:
1. Using a clock that operates acrossfailures. In this method, a clock is used at the
locationofthe unique identifier generator. This clockisguaranteed tocontinue operating
across failures, and it will not recycleduring the period within which the needed
identifiers must be unique. However, to implement this method, one may require rather
longidentifiers, depending on thegranularity ofthe clock intervalneeded.
2. Using two or more levels ofstorage.In this method, two or more levels ofstorage
are used and the unique identifiers arestructured in ahierarchical fashion with one field
for each level. A counterassociated with each level contains thehighestvalueofthe
corresponding field assigned. The currentvaluesofthese fields are cachedin main
memory. When a lower level field is about to cycle or the associated storagedevice
crashes,the nexthigherlevelcounterisincremented and thelowerlevelcounters are reset.
If astablestorage (the information on which can survive crashes) is used, two levels of
storage (the upper level being the main-memory storage and the lowerlevel being the
stablestorage)aresufficient forcreatinga safe and efficient uniqueidentifier generator.
Ascompared to the first mechanism, thismechanism can yield shorteridentifiers, but it
is morecomplex toimplement.
10.5OlJEa-lOCADNG MECHANISMS
Object locating is the process ofmapping anobject'ssystem-oriented uniqueidentifier
(UID for short) to the replica locations ofthe object. It may be noted here that the object­
locating operation isdifferent andindependent oftheobject-accessing operation. In a
distributed system, object locatingis only the process of knowing theobject'slocation,
that is, the node on which it is located. On the otherhand, object accessing involves the
processofcarrying out thedesiredoperation (e.g., read, write) on the object. Therefore,
theobject-accessing operation starts only after the object-locating operation has been
carriedout successfully.
Severalobject-locating mechanisms have been proposed and are being used by
variousdistributed operating systems. Thesemechanisms are briefly described below. The
suitability ofaparticular mechanism for adistributed system depends on various factors
such as the scale ofthe system, the type ofUID being used by its naming system, whether
thesystemsupports objectmigration, whetherthe system supports locationtransparency
ofobjects,and so on.
10.5.1Broadcasting
In this method, an object is locatedbybroadcasting arequestfor theobjectfrom a client
node. The requestisprocessed by all nodes and then the nodes currently having the object
replybackto theclientnode.Amoeba [Mullender andTanenbaum 1986] uses this method
forlocatinga remote port.Sec.10.5•Object-Locating Mechanisms 513
The method is simple and enjoys a high degree of reliability because it supplies
all replica locations of the target object. However, it suffers from the drawbacks of
poor efficiency and scalability because the amount of network traffic generated for
each request is directly proportional to the number of nodes in the system and is
prohibitive for large networks. Therefore, this method is suitable only when the
number of nodes is small, communication speed is high, and object-locating requests
are not so frequent.
10.5.2Expanding RingBroadcast
Purebroadcasting isexpensive for large networks. Moreover, direct broadcasting to all
nodes may not be supported by wide-area networks. Therefore, a modified form of
broadcasting, called expanding ringbroadcast (ERB) [Wiebe 1986],is normally employed
in aninternetwork that consists of local area networks (LANs) connected by gateways. In
this method, increasingly distant LANs are systematically searched until the object is
found or until every LAN has been searched unsuccessfully. The distance metric used is
ahop.A hopcorresponds to a gateway between processors. For example, if a message
from processor Atoprocessor Bmust pass through at least two gateways, AandBare two
hops distant. Processors on the same LAN are zero hop distant. A ringis the set of LANs
a certain distance away from a processor. Thus, Ringo[A] isA'slocal network, Ring][A] is
the set of LANs one hop away, and so on.
An ERB search works as follows. Suppose that processor Aneeds to locate object X.
Beginning with i=0, a request message is broadcast to all LANs in Ring;[A]. If a response
is received, the search ends successfully. Otherwise, after a timeout period has elapsed, i
isincremented by 1and the request broadcast is repeated. The ring size iis bounded from
above by the diameter of the internetwork.
Noticethat this methoddoes not necessarily supply all the replicalocations of an
object simultaneously, although it does supply the nearest replica location. Furthermore,
the efficiency of an object-locating operation is directly proportional to the distance of the
object from the client node at the time of locating it.
10.5.3Encoding LocationofObj8ctwithinItsUID
Thisscheme.usesstructured object identifiers. One field of the structured UID is the
locationofthe object. Given a UID, the system simply extracts the corresponding object's
location from its DID by examining the appropriate field of the structured VID. The
extracted location is the node on which the object resides.
This is a straightforward and efficient scheme. One restriction of the scheme,
however, is that an object is not permitted to move once it is assigned to a node, since this
would require its identifier to change. Consequently, an object is fixed to one node
throughout its lifetime. Another limitation of the scheme is that it is not clear how to
support multiple replicas of an object. Therefore, the use of this object-locating scheme is
limited to those distributed systems that do not support object migration and object
replication.514 Chap.10 • Naming
10.5.4S.archlng Cr.atorNoeMFirstandThen
8roadcastlng
This scheme is a simple extension of the previous scheme. The included extension is
basically meant for supporting object migration facility. The method is based on the
assumption that it is very likely for an object to remain at the node where it was created
(although it may not be always true). This is because object migration is an expensive
operation and objects do not migrate frequently.
In this scheme, the location fieldof the structured UID contains the identifier of the
node on which the object was created. Given a UID, the creator node information is
extracted from the UID and a request is sent to that node. If the object no longer resides
on itscreatornode, a failure reply is returned back to the client node. In case of failure,
the object is located by broadcasting the request from the client node. This method of
object locating is used in Cronus [Schantz et al. 1986].
As compared to the broadcasting scheme, this method helps in reducing the network
traffic to a great extent. Furthermore, the scheme is more flexible than the method of
encoding the location of an object within its UID because it allows the system to support
object migration. However, the use of broadcast protocol to locate those objects that are
not found on their creator nodes limits the scalability of this mechanism.
10.5.5UsingForwardLocationPointers
This scheme is an extension of the previous scheme. The goal of this extension is to avoid
the use of broadcast protocol. A forward location pointeris a reference used at a node to
indicate the new location of an object. Whenever an object is migrated from one node to
another, a forward location pointer is left at its previous node. Therefore, to locate an
object, the system first contacts the creator node of the object and then simply follows the
forward pointer or chain of pointers to the node on which the object currently resides.
The method has the advantages of totally avoiding the use of broadcast protocol and
allowing the support of object migration facility. However, the method practically has the
following major drawbacks:
1. Theobject-locating cost is directly proportional to the length of the chain of
pointers to be traversed and grows considerably as the chain becomes longer.
2. It is difficult, or even impossible, to locate an object if an intermediate pointer has
been lost or is unavailable due to node failures. Therefore, the reliability of the
mechanism is poor.
3. The method introduces additional system overhead for upkeep.
10.5.6UsingHint(acheand 8roadcastlng
Another commonly used approach is the cache-broadcast scheme. In this method, a
cache is maintained on each node that contains the (UJD, last known location) pairs
of a number of recently referenced remote objects. Given a UID, the local cache isSec. 10.6 • Human-Oriented Names 515
examined todetermine if it has an entry for the UID. If an entry is found, the
corresponding location information isextracted from the cache. The objectaccess
requestis then sent to the node specified in theextracted location information. If the
objectno longer resides at that node, however, the request is returned with a negative
reply,indicating that the location information extracted from the cache was outdated.
If thespecified DID is not found in the local cacheor if the location information of
the object in the local cache is found to beoutdated, a message is broadcast throughout
the network requesting thecurrentlocation of the object. Each node that receives the
broadcast request performs an internal search for the specified object. A reply message
isreturned to the client node from the node on which the objectis found. This location
of theobjectis then recorded in the client node'scache. Notice that a cache entry only
serves as a hint because it is not always correct.
This scheme can be very efficient if a high degree of locality is exhibited in locating
objects from a node. It is also flexible since it can supportobject migration facility.
Furthermore, the method of on-use update of cachedinformation avoids the expenseand
delay of having to notify other nodes when an objectmigrates. One problem with this
scheme, however, is that broadcast requests will clutterup the network, disturbing all the
nodes even though only a single node is directly involved with each object-locating
operation.
This is the most commonly usedobject-locating mechanism in modern distributed
operating systems. It is used in Amoeba [Mullender etal,1990], V-System [Cheriton and
Mann 1989], DOMAIN [Leach et a1.1983], NEXUS [Tripathi et a1.1987], Mach [Rashid
1987], and Chorus[Rozieret al. 1988].
Figure 10.9 summarizes the various object-locating mechanisms discussed above.
Note that schemes (c),(d),and(e)requirestructured DID whereas schemes (a),(b),and
(j)can work with both unstructured andstructured UIDs. Also notice that only scheme (c)
facilitates the object-locating operation to be carried out withoutthe need to exchange any
message with any other node. However, it is inflexible because it does not support object
migration andobjectreplication facilities.
10.6HUMAN-ORIENTED NAMES
System-oriented names such as 3JA52B5FAD19BlCs,though useful for machine
handling, are not suitable for use by users. Users will have a tough time if they are
required toremember these names or type them in. Furthermore, eachobjecthas only a
singlesystem-oriented name, and therefore all the users sharing an object must remember
and use its only name. To overcome theselimitations, almost all naming systems provide
the facility to the users to define and use their own suitable names for the various objects
in the system. These user-defined object names, which form a name space on top of the
name space for system-oriented names, are called human-oriented names.
Human-oriented names normally have the following characteristics:
1. They are character strings that are meaningful to their users.
2. They are defined and used by the users.516 Chap. 10 • Naming
(a)CDBroadcast requestmessage
®Replyfromthenodeon
whichtheobjectis located
//../ _- \\
l "I \
.,,,,,,,,,,
,
<.
'.
(b)oCDSearching nodesat0
hopdistance
®Searching nodesat1
hopdistanceifthe
searchof0hopfails
(J)Searching nodesati
hopsdistanceifthe
searchesupto;-1
hopsfail
Objectlocationo
oClientnode
@
(c)CDExtracting object'slocationfrom
itsUID.No messageexchange
withanyothernodeis required
forlocatingtheobject
Fig. 10.9 Object-locating mechanisms: (a)broadcasting; (b)expanding-ring
broadcast; (c)encoding the location of an object within its UID;
(d)searching the creator node first and then broadcasting; (e)using forward
location pointers; (f)using hint cache and broadcasting. (Continued on next
page.)Sec. 10.6 • Human-Oriented Names
CreatornodeS17
Objectfocation
®
Creatornode(dJ0)Searchingthecreatornode
®Negativereply
®Broadcastrequestmessage
@Replyfromthenodeon
whichtheobjectislocated
Objectlocati_on®~G)Clientnode0),®.®Pathof
@ messageforwarding
@Replyfromthenodeon® whichtheobjectislocated
(e)
®
(f)0)Searchingoflocalcache
®Broadcast request message
®Reply from thenodeon
whichtheobjectislocated
:Fig. 10.9 (Continued.)
3. Different users can define and use their own suitable names for a shared object
That is, the facility of aliasing is provided to the users.
4.Human-oriented names are variable in length not only in names for different
objects but even in different names for the same object.
5. Due to the facility of aliasing, the same name maybe used by two different users
at the same time to refer to two different objects. Furthermore, a user may use the
same name at different instances of time to refer to different objects. Therefore,
human-oriented names are not unique in either space or time.518 Chap. 10 • Naming
Because of the advantages of easy and efficient management of name space,
hierarchically partitioned name spaces are commonly used for human-oriented object
names. When a hierarchical naming convention is used, it is important to decide whether
to use a constant number of levels or an arbitrary number of levels. That is, ifthe names
of a hierarchical naming system are ofthe form c]/c2/...Ic.,shouldibe constant or
arbitrary? Both schemes have their own advantages and drawbacks. The main advantage
oftheconstant-level scheme is that it is simpler and easier to implement as compared to
thearbitrary-level scheme. This is because all software in the arbitrary-level scheme must
be able to handle an arbitrary number of levels, so software for manipulating names tend
to be more complicated than those for constant-level scheme. The disadvantage of the
constant-level scheme isthat itisdifficult todecide the number of levels, and if new levels
are to be added later, considerably more work has to be done because all the algorithms
for name manipulation must beproperly changed to take care of the new levels.
On the other hand, arbitrary-level schemes have the advantage of easy expansion by
combining independently existing name spaces into a single name space. For example, as
shown in Figure 10.10, two independent name spaces may be combined into one name
new-root
.......
.............."
...,,
\
\
\
\
\,
I
I,,
I
I,
I
I,,,,,
-,'--",--root-2
"".r>:
Iuser-1 user-2,/-<.
: project-1
\~
\ file-1,
\
\,
""'"
........-
Thenewnamespace
Fig.10.10 Combining two name spaces to form a single name space by adding a
new root.Sec.10.6 • Human-Oriented Names 519
space by adding a new root, making the existingroots its children. The major advantage
isthat if a name was unambiguous within itsold name space, itis still unambiguous within
its new name space, even if the name also appeared in some other name space that was
combined. There is no need to change any of the algorithms formanipulating names.
Arbitrary-level schemes, being more flexible than constant-level schemes, are used
by most recent distributed systems. Hence, subsequent sections of this chapterdeal with
arbitrary-level hierarchical name spaces.
The major issues associated with human-oriented names are as follows:
1. Selecting a proper scheme for global object naming
2.Selecting a proper scheme for partitioning a name space into contexts
3.Selecting a proper scheme for implementing context bindings
4. Selecting a proper scheme for name resolution
These issues are described in the next section.
10.6.1Human-Oriented Hierarchical NamingSchemes
Basically there arc four approaches for assigning systemwide uniquehuman-oriented
names to the various objects in a distributed system. These are described below.
Combining anObject'sLocal Name with Its Host Name
This naming scheme uses a name space that is comprised of several isolated name spaces.
Each isolated name space corresponds to a node of the distributed system, and a name in
this name space uniquely identifies an object of the node. In the global system, objects are
named by some combination of their host name and local name, which guarantees a
systemwide unique name. In Ibis [Tichy and Ruan 1984], for instance, file objects are
identified uniquely by names having the form host-name:local-name, wherehost-name is
theidentifier of the node on which the file resides and local-name is a UNIX-like absolute
pathname for the file that identifies it uniquely on its host node.
This naming scheme is simple and easy to implement. Its main drawback, however,
is that it is neither location transparent nor location independent. Furthermore, it is
inflexible in the sense that an object'sabsolute name changes every time an object moves
from one node to another. Therefore, itis not suitable for modemdistributed operating
systems.
Interlinking Isolated Name Spaces into a Single Name
Space
In this scheme also the global name space is comprised ofseveral isolated name spaces.
However, unlike the previous scheme in which the isolatedname spaces remain isolated
throughout, the isolated name spaces are joinedtogetherto form a single naming structure.
The position of these component name spaces in the naming hierarchy is arbitrary. In theS20 Chap.10 •Naming
naming structure, a component name space may be placed below any other component
name space either directly or through other component name spaces. In this scheme there
is no notion ofabsolute pathname. Each pathname is relative to some context, either to the
currentworking context or to the current component name space.
This naming scheme is used in UNIX United [Brownbridge et al. 1982] to join any
numberof UNIX systems to compose a UNIX United system. In the single naming
structure of UNIX United, each component system is a complete UNIX directory tree
belonging to acertain node. The root of each component name space is assigned a unique
name so that they become accessible and distinguishable externally. A component's own
root is still referred to as Iand still serves as the starting point of all pathnames starting
with aI.The UNIX notation ../ is used to refer to the parent of a component's own root.
Therefore, there is only one root that is its own parentand that is not assigned a string
name, namely, the root of the composite structure, which is just a virtual root needed to
make the whole structure a single tree.
A simple example of such a naming structure is shown in Figure 10.10, in which the
composite name structure is comprised of two component name spaces AandBwhose
roots are named root-Iandroot-Z,respectively. As an illustration of relative path naming
in this scheme, note that from within the component name space A,file-Iof the two
component name spaces AandBwill be referred to as luser-Ilproject-Ilfile-I and..Iroot­
2luser-lIproject-l /file-l,respectively. Similarly, if the current working directory of a
client isproject-I of the component name space B,file-I of the two component name
spacesAandBwill be referred to as ../../.Jroot-Iluser-Ilproject-Ilfile-I andfile-l,
respectively.
The main advantage of this naming scheme is that it is simple to joinexisting name
spaces into a single global name space. However, in naming systems that employ this
scheme for global object naming, an important issue that needs to be handled is to allow
clients to continue to use names that were valid in the independent name spaces without
the need to update them to match the new name space structure. For example, in Figure
10.10,luser-llproject-l/file-l is a name used by clients before the two component name
spaces were integrated. Before integration, this name referred to file-lofcomponent name
spaceAfor clients of component name space Aand tofile-lofcomponent name space B
for clients of component name space B.Therefore, it is desirable that after integration of
the twocomponent name spaces, this name should still refer to the same object for the
clients of the two component name spaces. The Global Name Service (GNS), which was
designed and implemented by Lampson and colleagues at the DEC Systems Research
Center[Lampson 1986], provides an interesting solution to this problem. Its approach,
which is based on the use of directory identifiers (DIs) and a table of well-known
directories, is described below.
A GNS has two parts <directory name, value name>. The first part identifies a
directory and the second part refers to a value tree or some portion of a value tree. Each
directory has a unique DI associated with it. Figure 10.10 has been redrawn in Figure
10.11(a) to illustrate the GNS naming scheme.
In the GNS naming convention, file-lof both the component name spaces Aand
B,before their integration, will bereferred to as <./user-l, project-l/file ...I».After
integration ofthe twocomponent name spaces, when a client of component name spaceSec. 10.6 • Human-Oriented Names
Well-known directories
#108=#311/root-1
#251=#311/root-2521
project-1
1
file-1
Well-known directories
project-1
!
file-1(a)
project-1
!
file-1
(b)project-1
1
file-1
#311/root-1/user-3
Fig. 10.11 The GNS approach of accommodating changes in existingname spaces:
(a)combining two name spaces to form a single name space;
(b)restructuring a name space.
Auses this name, its local name agent, which is aware of the local root directory's DI,
prefixes the Dl (#108),thus producing the name <#lOB/user-} ,project-llfile-I», On the
other hand, when a client of component name space Buses the same name, its local
name agent prefixes the Dl (#251)of the root directory of component name space B,
thusproducing the name <#251/user-l, project-Ilfile-l», 'Thename agent then passes
this derived name in a lookup request to a GNS server. Relative names are similarly
converted into local absolute names by a local name agent before being passed to a
GNS server for lookup.
To allow a GNS server to locate a directory given its DI (such as #108),GNS uses
a table of well-known directories. This table contains a list of the root directories of all522 Chap.10 •Naming
component name spaces. Since a name space that was createdbyintegrating two or more
name spaces may again be integrated after some time with some other name space to form
a new name space, this table basically has entries for all those directories that are used as
working roots within the entire name space. In our example of Figure 10.11(a), since there
are only two working roots (root-landroot-2),this table has two entries. Each GNS
serverhas a copy of this table.
Whenever the real root ofthe name space changes, all GNS servers are informed of
the new location ofthe real root. Names that start with the real root (such as <new-root/
root-l/user ..l,project-l Ifile-I» areinterpreted by a GNS server in the usual manner. On
theotherhand, names that start with the DI ofa working root (such as <#1OB/user-l,
project-llftle-l» areinterpreted by using the information for thecorresponding DI'sentry
from the table ofwell-known directories. Therefore, the GNS scheme allows the use of
bothabsolute names and names that are reJative to a working root.
Restructuring ofa name space for accommodating organizational changes is also
supported by GNS. As an example, let us assume that the two component name spaces A
andBofFigure10.10correspond to twodifferent companies that were integrated and now
correspond to two branches ofa single company. Now suppose sometime lateruser...lof
thebranchcorresponding to thecomponent name space Bistransferred to the branch
corresponding to thecomponent name space A.Toaccommodate thischange, if the
subtreeofuser-lis simply moved to the root...]directory, the following problems
occur:
1. User-I is already present in root...1.This problem can beeasily solved by
assigning a new user identifier, say user...3,to thetransferred user.
2.Absolute names of the form <new-root/root ...Zluser-L,...>will nolongerwork
and need to be changed. GNS solves this problem byinserting a"symbolic link"
in placeofthe original entry for user-Iin theroot-2directory, as shown in Figure
10.11(b).The GNS directory lookupprocedure interprets the link as a redirection
to the new directory location of this user.
SharingRemote Name Spaces on Explicit Request
Thisscheme,popularized by SunMicrosystems' Network FileSystem(NFS)[Sandberg
etal.1985], is also based on the idea of attaching theisolatedname spaces ofvarious
nodes to create a new name space. However, unlike the previous schemein which a single
namingstructure iscreatedby the system, in this scheme users are giventheflexibility to
attach acontextofa remote name space to one of the contextsoftheir local name spaces.
Once a remotecontextisattached locally, its objectscan be named in a location­
transparent manner. The goal is to allow some degree ofsharing among the name spaces
ofvariousnodes in a transparent manneronexplicitrequestbythe users. Therefore, the
globalviewofthe resulting name structure is a forest oftrees, one for each node, with
someoverlapping due to the shared subtrees. Notice that, unlike the previous schemein
which the entirename space of each node is attachedto the single naming structure, in this
schemethe users have the flexibility to attach to their local name space tree eithera
complete remotename space tree or a part ofit(subtree). Also notice that a requesttoSec.10.6 • Human-Oriented Names 523
share aremotename space affects only the node from which the request was made and no
other node. This ensuresnodeindependence. The naming offileobjectsin NFS is
described below as an illustration of this scheme.
InNFS,themountprotocol is used to attach a remote name space directory to a
local name space. Therefore, to make a remote directory accessible in atransparent
mannerfrom a node, a mount operation has to be performed from the node. The node
thatperforms the mount operation is called a client node and the node whose name
spacedirectory ismounted is called a servernode. NFS allows every machine to be
both a client and a server at the same time,A server must exportall those directories
of its name space tree that are to be made accessible to remote clients. The complete
subtree rooted at an exported directory is exported as a unit. Therefore, alldirectories
below an exported directory automatically become accessible to a client when the
exported directory is mounted on theclient'slocal name space. This is becausewhen
a client mounts a server'sdirectory, the mounting process sets up a link between the
mount point of the client'slocal name space and the exported directory of the server's
name space. To allow directories to beautomatically exported by a server when it is
booted, the list of directories t.obeexported by theserveris maintained in the fete/
exportsfile.
Thesemantics of the mount operation are that a server's file system directory
exported by the server is mounted over adirectory oftheclient'sfile system. The mounted
directory's subtreeofthe server file system appears to be an integral part of the client's
file system, replacing the subtree descending from the client'slocal directory on which the
server'sdirectory was mounted. The local directory becomes the name of the root ofthe
newlymounted directory. Hence, after the mount operation, local users can access files in
the mounted remote directory in a totally transparent manner. To programs running on the
client machine, there is (almost) no difference between a file located on a remote file
server and a file located on the local disk.
A client can mount a directory in one of the following ways:
1.Manualmounting. In this case, the client uses the mountcommand any time a
server'sdirectory is to be mounted on the client'slocal name space. The umountcommand
allows the client to unmount the directory when the client no longer needs to access the
files in the subtree of the server'sdirectory. A client must be a superuser to use the mount
andumountcommands. This method provides the tlexibility to the clients to dynamically
mount or unmount servers'directories depending onchanging needs.
2.Staticmounting, In the manual mounting scheme, a mountcommand is to be used
every time a server'sdirectory is to be mounted by a client. The static mounting scheme
allows clients to automatically mount the directories of their choice out of the directories
exported by servers withoutmanualintervention. In this method, the shell script for the
commands to mount the desired directories are written in a file called /etefrcon theclient
machine. This shell script is automatically executed when the client machine is booted.
Therefore, allmountings automatically take place at boot time.
3.Automounting. In the static mounting scheme, since mounting is done at boot
time, allservers'directories listed in the letclrcfile of a client are mounted even when not524 Chap.10 • Naming
being used by the client. The automounting scheme allows a server'sdirectory to be
mounted only when the client needs it. That is, in this scheme servers'directories are
mounted and unmounted automatically on a need basis.
In this scheme, a server'sdirectory is associated with a client'slocal directory, but
actualmounting is performed only at the time the client invokes a command to access a
file in the name space below the server'sdirectory. Once mounted, the server'sdirectory
remains mounted for as long as it is needed. Whenever 5 minutes have elapsedwithout the
name space below the server's directory being accessed by the client, the server's
directory isautomatically unmounted.
Another important feature of this scheme is that instead ofa single server's
directories, a set of servers'directories may also be simultaneously associated with a
directory oftheclient'slocal name space. In this case, when the client accesses a file in
the name space below the mounted directory for the first time, the operating system sends
amessage to each of the servers whose directories are associated. The first one to reply
wins, and its directory is mounted.
Theautomounting scheme helps achieve fault tolerance because a serverneed be up
and working only when the client actually needs it. Moreover, when a set ofservers are
associated instead of a single server, only one of them need be up.
For anillustration of thefile-mounting mechanism of NFS, consider the example
given in Figure 10.12 based on the example given in [Silberschatz and Galvin 1994].
Figure IO.12(a) and (b)shows parts ofthe name trees of nodes N)andN2,respectively,
that areofinterest here. The triangles represent subtrees of directories that are of interest.
Since no mounting has been done yet, only local files can beaccessed ateach node..Figure
10.12(c) shows the structure of the portion of interest of the name tree of node NJafter
mounting the directory luser21dir2 of nodeN2over the directory luserJldirJ of nodeNJ•
After this mounting, dir2becomes a shared directory, being shared by the users of nodes
NJandN2•Users on node NIcan access any file within the dir2directory by using the
prefixluserlldirlldir2. Notice that the original subtree below the directory luserlldirl on
node NJis no longer visible.
Anadvantage ofthis scheme is that it provides the flexibility to a user to attach
only the necessary portionsofremote name spaces on his or her local node'sname
space.Another advantage of this scheme is that itis simple to implement as a
modification to UNIX. However, it suffers from several drawbacks. The main drawback
is that the scheme does not provide a consistent global name space for all nodes. Thus
the same object may have different "absolute" names when viewed from different
nodes. For example, Figure 10.12(c) and (d)shows the name tree structures of nodes
N,and N2trespectively, after some mountings done on user requests. Now the absolute
namesofan object in the directory dir2will have the prefixes luserJldirlldir2 and
luser21dir2 on nodesN,andN2,respectively. This lack of absolute naming facility can
causedifficulties fordistributed application programs, since processes running on
different nodes are in different naming domains. For example, an application using
several nodes to process a data file would run into trouble if the file name were
specified asluserJlprojectlldatal; rather than opening the same file, participating
processes on nodes having identifiers romeandpariswouldrespectively openIromelSec. 10.6 • Human-Oriented Names
user1
dir1
(a)
user1
dir1
,,,"-.
,,'dir2-., ,'------------,
(c)dir3,,
" ",,
,"" , ,'------------,
(b)
dir3
dir1
(d)user2
dir2, ,, ,, ,",,,, ,, ,
"------------'.
user2
dir2,,,,, ....,,,,, ...." ,"------------'.S25
Fig. 10.12 Illustrating thefile-mounting mechanism of NFS naming scheme: (a)a
part of the name tree of node Nt; (b)a part of the name tree of node N2;
(c)structure of name tree of node N1aftermounting dir2 of node N2over
dirl;(d)structure of name tree of node N2aftermounting dirtof nodeN,
over dir3.
user1lprojectl /dataland/paris/user 1/projectl /datal.Even if the user were to explicitly
specify/paris/userl /projectl/datal, theprogram wouldfail ifromedid not have paris's
filesystemmounted, or worse, had some othernode'sfilesystemmounted underthe
name/paris.The only way to ensurethat all nodes use the same name for the same
objectis bycarefulmanualmanagement of eachnode'smounttable.Systems using this
approach do not scale well, becauseifeverynodemountseveryother, the numberof
mountpointsin thesystemisproportional ton2(n=totalnumberofnodes),producing
asignificant management andcomputing overhead.
Another seriousdrawback of thisschemeis itsadministrative complexity. The
effectsofafailednode, or taking a node off-line, are that some arbitrary setof
directories ondifferent nodesbecomeunavailable. Likewise, migrating objectsfrom one
node to another requires changes in the name spacesofall theaffected nodes.
Furthermore, theschemedoes not providecomplete transparency becausethespecifica­
tion of a remotedirectory as anargument for the mountoperation is done in a
nontransparent manner; thelocation (that is, node identifier) oftheremotedirectory has
to beprovided. Location independency is also not supported by theschemebecause,
asdiscussed above,theabsolute nameofanobjectdepends on the node from which
itisbeingaccessed.526 Chap. 10 • Naming
A Single Global Name Space
Several distributed operating systems such as LOCUS [Walkeret al. 1983], Sprite [Welch
andOusterhout 1986], V-System [Cheriton and Mann 1989], and Galaxy [Sinha et al.
1991a] use the single global name space approach for object naming. In this scheme, a
single global name structure spans all the objects of all the nodes in the system.
Consequently, the same name space is visible to all users and an object'sabsolute name
is always the same irrespective of the location of the object or the user accessing it.
Therefore, this scheme supports both types of location independency-that ofthe location
of theaccessing object (e.g., process) and the location ofthe accessed object. The property
ofuser mobility for a user, that is, location independency of theaccessing object, can also
beprovided in the mount mechanism of NFSbymounting a shared file system over the
user'shome directories on all machines in a network. However, supporting this properly
for all users in NFS will require significant management andcomputing overhead.
The single global name space approach is the most commonly used approach by
modern distributed operating systems due to its properties of complete .location
transparency and location independency. Therefore, in subsequent sections of this chapter
we willconcentrate on this naming scheme.
10.6.2Partitioning a Name Spaceinto Contexts
Name space management involves the storage and maintenance of naminginformation,
whichconsistsof object names, object attributes, and the bindings between the two. Due
toreliability and space overhead problems in a distributed system, storing the complete
naminginformation at acentralized node or replicating it at every node is not desirable.
Therefore, the naming information is usually decentralized and replicated. That is, instead
of one global name server, there are many name servers, each storing a copy of a portion
ofthecomplete naming information. These name servers interact among themselves to
maintain the naming information and to satisfy the name resolution requests of the users.
A basic problem is how to decompose the naming information database to be distributed
among the name servers. The main goal ofadecomposition mechanism for this purpose
is to minimize the overhead involved in the maintenance of naming information and the
resolution of names.
The notion of contextis used for partitioning a name space into smallercomponents.
Contexts represent indivisible units for storage and replication of information regarding
named objects. A name space is partitioned into contexts by using clustering conditions.
Aclustering condition is anexpression that, when applied to a name, returns either a true
or false value, depending on whether the given name exists in the contextdesignated by
theclustering condition. The three basic clustering methods are algorithmic clustering,
syntactic clustering, and attribute clustering. These are discussed below.
Algorithmic Clustering
In this method, names are clustered according to the value that results from applying a
function to them. Therefore, in algorithmic clustering, the clustering condition is aSec.10.6•Human-Oriented Names 527
predicate ofthe form function(name) =value.For instance, a hash function that clusters
names into buckets is a good example ofaclustering condition foralgorithmic
clustering.
As anillustration, a simple example ofalgorithmic clustering of names is given in
Figure 10.13. In this example, at first,func-lis applied to the names in the name space
topartition them into two contexts. One ofthe twocontextsisstill found to be too large.
Therefore, a second function (junc-2) is applied to the names of this context to further
partition the contextintosmallercontexts. Thus starting with the complete name space as
a singlecontext,asequence ofclustering conditions can be applied to yield a group of
reasonably sizedcontexts.
London Paris Arizona
Poznan Oregon Berlin
Vienna Tokyo Kyoto
Nara Mexico Nebraska
Nagasaki
London Poznan
Berlin Vienna
Oregon Mexico Nara
Nagasaki Nebraska
London Poznan
Berlin Nara
NagasakiVienna Oregon
Mexico Nebraska
func-1(name): if(totalcharacters (name) =even)
return(0)
else return(1);
func-2(name): if(totalvowels (name)=even)
return(0)
else return(1);
Fig. 10.13 An example ofalgorithmic clustering.528 Chap. 10 • Naming
The main advantage of algorithmic clustering mechanism is that it supports
structure-free name distribution. A structure-free namedistribution is one that places no
restriction on the administrative control over parts of'aname space. The partitions of
such a name space do not correspond to the structure of the names, such as their sizes,
or the number of component names, or the order of the component names or characters
within a name, and so on. In particular, the owner of an object may choose its
authoritative nameservers, subject to administrative constraints, independent of the
object'sname. This permits maximum flexibility in the administration assignment (and
reassignment) of authoritative name servers to a given object. Algorithmic clustering
also has the advantage that it allows a healthy name resolution tree to be built even
for flat name spaces. However, the main drawback of the method is difficulty in
devising proper clustering functions. This is because the characteristics of the names to
be defined by the various users is normally unpredictable. Therefore, if the clustering
functions are not devised properly in the beginning, some contexts may become too
large while other contexts may be very small.
Syntactic Clustering
This is the most commonly used approach for partitioning a name space into contexts.
Syntactic clustering is performed using pattern-matching techniques. Patterns are
templates against which a name is compared. They range from names that may simply
contain wildcards, which are denoted by asterisks and match any sequence of characters,
toregular expressions [Terry 1986].Thus, asyntactic clustering condition that is meant for
aparticular pattern, when applied to a name, returns TRUE ifthe name matches the
pattern. All names that match a particular pattern, such as names with a common prefix
prefix*,are considered part of the same context.
As an illustration, two simple examples of syntactic clustering of names are given in
Figure10.14.Figure10.14(a) shows the partitioning of structured names and Figure
lO~14(b) shows the partitioning of flat names. It may be observed from Figure lO.14(a)
that in hierarchically structured name spaces pattern matching is usually performed on a
component-by-component basis and the resulting contexts usually contain only the
unmatched part of the names. Therefore, at subsequent levels, a new clustering condition
is applied only on the truncated part of the names. However, syntactic clustering
conditions are not restricted to matching a single additional component in each step. This
leads to variable syntactic clustering in which a variable number of components can be
matched at a time.
The syntactic clustering mechanism allows names to be resolved in a manner similar
to their structure, as is done by virtually all name management systems. This means that
simple matching suffices as a clustering technique.
Attribute Clustering
The method ofattribute clustering is used by attribute-based namingconventions.
In this method, names are grouped based on the attributes possessed by the
names. An attribute has both a type and a value, where the type indicates theSec. 10.6 • Human-Oriented Names 529
/country/lndialDelhi Icountry/lndiaiBombay
/country/JapanlT okyoIcountry/Japan/Kyoto
luser/sinha/file1 luserlsinha/file2 /userlsinha/file3
file1
file2sinhaIfile1
sinhalfile2
sinhalfile3
pradeep/file 1
pradeep/file2
file2
file3Tokyo
KyotoIndia/Delhi
India/Bombay
JapanlTokyo
Japan/Kyoto
Delhi
BombayMatches the pattern
"/country/*"
(a)
If'ig.10.14 Examples ofsyntactic clustering: (a)partitioning ofstructured names;(b)
partitioning of flat names. (Continued on next page.)
format and meaning of the value field. Therefore, all names havingthe same
attribute (type, value) pair are placedin the same partition in theattribute
clustering mechanism.
As anillustration, a simple example ofattribute clustering of names is given in
Figure 10.15. Observe that in a hierarchically structured name space, attribute
clustering is usually performed on anattribute-by-attribute basis, and the resulting
contexts usuallycontainonly the unmatched attributes of the names. Therefore, at
subsequent levels, a new clustering condition is applied only on the remaining
attributes ofthe names. However, attribute clustering conditions are notrestricted to
matching a single additional attribute in each step and several attributes may be
matched in a single step.S30 Chap.10 •Naming
Poppy Poster
Powder PowerSheep Silky
Shark Silver
Shark
SheepSilver
Silky
(b)
."ig. 10.14 (Continued.)
Type=Object,Name =P1
Name=P2Name=P1Type=Object,Name=P2
Lang=Basic,Name=P1I
Lang=C,Name=P2Matchestheattribute
Type=Source
Fig. 10.15 Example of attribute clustering.Sec. 10.6 • Human-Oriented Names
10.6.3Context81nding531
Thecontexts ofanamespacearedistributed amongthevariousnameserversmanaging
that name space. Thatis, a name servernormally stores only a small subsetofthe setof
contexts ofthe name space. Therefore, whenpresented with a name to be resolved, a
serverfirst looks in local contexts for anauthority attribute for the named object. Recall
that anauthority attribute contains a list of the authoritative nameservers for a named
object.If theauthority attribute for thenamedobjectis not found in a local context,
additional configuration data,calledcontextbindings, mustexistlocallyfor the name
resolution toproceed. Acontextbindingassociates thecontextwithinwhich it is stored
toanothercontext, that is more knowledgeable aboutthenamedobject,and the name
serversthat store that context. The two strategies commonly used toimplement context
bindings innamingsystemsaretable-based strategyandprocedure-based strategy. These
arediscussed below.
Table-Based Strategy
Thisis the most commonly usedapproach for implement.ing context bindings in
hierarchical tree-structured name spaces. In this method, eachcontextis a table having
two fields; the first field stores a component nameofthenamedobjectand thesecond
fieldeitherstorescontextbindinginformation orauthority attribute information. Anentry
corresponding to the last component of a name contains theauthority attribute information
whileotherentriescontaincontextbindings. Thecontextbindings reflect the delegation
ofauthority formanaging parts of the name space. Note that the amountofconfiguration
data that must be storedincontextobjectsat thevariouslevels of the hierarchy is
proportional to thedegreeofbranching of the name space tree. The contexts of a table­
basedstrategyare also knownasdirectories.
As anillustration, anexample oftable-based strategy forimplementing context
bindings is given in Figure 10.16. The figure also illustrates how anobjectcan have two
different human-oriented names in this implementation strategy. Therefore, the users ofa
sharedobjectcanspecifytheir own suitablenames for accessing it.
Procedure-Based Strategy
Nameserversmay also use procedure-based strategyratherthantable-based strategyto
implement thebindings in agiven context.Inthismethod,acontextbindingtakes the form
ofaprocedure, which, when executed, supplies information aboutthe nextcontextto be
consulted for thenamedobject. For instance, in theexamples ofFigure10.14, the syntactic
clustering condition used by each contextcan also be used as the procedure forsupplying
contextbindings for the names definedwithinthatcontext.Noticethat noconfiguration data
isrequired by thisschemeand hence the data management overhead is zero. This scheme,
however, is lessflexiblethan the table-based strategy because, ifrequired, thecontext
bindings cannotbechanged dynamically andindependently for each object. Changing of
contextbindings willrequirechanges in theclustering procedures. Therefore, almostall
namingsystemsuse thetable-based strategyforimplementing contextbindings.532 Chap.10 •Naming
Rootdirectory
havingnameI/'
Component
nameContextbinding(CB)
or
authorityattribute
(M)
user1 (CB)
user2 (CB)
Directoryhaving
name'/user2'Directoryhaving
name'/user1'
ComponentCB/Mname
x (CB)
y (CB)
z (M)
Anauthoritative name
serverofobject '/user21z'
Directoryhaving
name'/user2ly'Component CB/M
name
b (CB)
d (M)
Directoryhaving
namesI/user1/b'
andI/user21x'
Component CB/M
name
(M) c
Anauthoritative name
serverofobjecthaving
twonames '/user11b/c'
and'/user21xlc'CB/MComponent
name
Fig. 10.16 An example of table-based strategy for implementing context bindings.
10.6.4Distribution ofContextsandNameResolution
Mechanisms
Name resolution is the process of mapping an object'sname to the authoritative name
servers of the objectThe process basically involves traversal of a resolution chain of
contexts (using the context binding information of each context in the chain) until the
authority attribute of the named object is found. Obviously, the traversal of the resolution
chainofcontexts for a name is greatly influenced by the locations of these contexts in a
distributed system. Therefore, the name resolution mechanism of a naming system
depends on the policy used for distributing the contexts of the name space of the naming
system. Some of the commonly used name resolution mechanisms are described below.Sec.10.6•Human-Oriented Names 533
Centralized Approach
In thismethod, a single name serverin theentiredistributed systemislocatedat a
centralized node. This name serverisresponsible forstoringallcontexts andmaintaining
thename-mapping information in them up to date. The locationofthecentralized name
serverisknownto allothernodes.Therefore, nameresolution requestsfrom all nodes are
first sent to the centralized nameserver's node. The name serverresolves a name by
traversing thecomplete resolution chainofcontexts locallyand finally returns the
attributes of thenamedobjectto the client node. An example ofasystemwith a
centralized nameserviceis the early DARPA Domain NameSystem[Mockapetris and
Dunlap1988,Cerf"andCain 1983].
The main advantage of thisschemeis that it is simpleand easy to implement. It is
alsoefficient becauseany name resolution requestinvolves only two messages (arequest
and a reply) to be passed across the network. The scheme,however, suffers from several
drawbacks. Forinstance, it does not scale well becausetheperformance ofthecentralized
nameservermaybecome a serious bottleneck for large systems. Furthermore, the
reliability ofthismechanism is also very poor. The inabilityofa node to communicate
with the centralized nameserver'snode due to a link failure of the network willcreatea
situation in which none of the name resolution requestsofthat node can be carriedout.
An even worse situation occursif thecentralized nameserver'snode fails, in which case
none of the name resolution requests from any node of the system can be carriedout.
Fully Replicated Approach
In thismethod,there is a name serverlocatedon each node ofthedistributed systemand
allcontexts arereplicated at every node. That is, the name space database is fully
replicated, andtherefore each name serverhas thename-mapping information for all
objectnames.Obviously, all name resolution requestsofany node are serviced locallyby
the local name server. The Pup name service[Boggs 1983] and the DOLeN (Distributed
Double-Loop Computer Network) system [Lin et a1.1982J use this approach.
Themethodissimpleandefficient because all name resolution requests can be
serviced locallywithoutthe need to communicate with any othernode. The method,
however, involves largeoverhead inmaintaining consistency of naming information in all
serversand hence is not suitablefor large name spaces.
Distribution Based on Physical Structure of Name
Space
This is the most commonly usedapproach forhierarchical tree-structured name spaces. In
thismethod, the name space tree is dividedintoseveralsubtrees that are knownby
different names in different systems, such asdomains inSprite[Welch and Ousterhout
1986] and file groups inLOCUS [Walker et al. 1983]. To differentiate thisconceptwith
otherterminologies usedbefore,the termzoneswill be used here to referto suchsubtrees.
In thisscheme,there are several name servers in the distributed system, with each server
providing storagefor one or more of these zones. An example isshowninFigure10.17.S34 Chap. ]0 • Naming
--~"." ....
//a~\
: b e\
~/":
\cd", I,,
.... ".....,......_-"",
(a)
Name prefixZoneidentifier
ServeridentifierSpecific zone
identifier
/ 51 12
/a 52 19
If/hlp 53 33
/m 52 87
/mlp 53 61
(b)
Fig. 10.17 Distribution and management of contexts based on the physical structure
of the name space: (a)hierarchical name space tree partitioned into zones;
(b)sample name prefix table/cache for the zones of the name tree of (a).
Note that each node of the name space tree corresponds to a context, and therefore the
contexts belonging to the same zone are grouped together in this scheme. Hence, in this
scheme, instead of contexts, zones represent indivisible units for storage and replication
regarding named objects.
In this scheme, the resolution of an object name basically involves the sending of the
name resolution request to the server that manages the subtree (zone) to which the last
component ofthenamebelongs. Forinstance, inFigure 10.17,thenameresolution requests
for the object names laIble,tflh,/ftg, Iflhiplk, lmln,Imlplr,andImlplrlsl must be sent to
serversS2'SitSI'S3'S2' S3'andS3'respectively. To facilitate the mapping of names to
servers,eachclientmaintains a nameprefixtable(alsoknownasa nameprefixcache)thatisSec.10.6 • Human-Oriented Names 535
builtandupdated dynamically. Each entry inthe nameprefix table corresponds tooneofthe
zones of the name space tree. Itcontains the name of the topmost context (directory) in the
zone (called the nameprefix forthe zone) and a zone identifier. Azone identifier consists of
twofields-server identifier andspecific zone identifier-where the specific zone
identifier isassigned to the zone by the server. Ithelps in differentiating among the various
zonesmaintained bythesame server.For example, inFigure 10.17,server S3maintains two
zones both of whose roots have the same name pbut different zone identifiers 33 and61.A
server'sidentifier has its location embedded init.
When a name is to be resolved, the client searches its own name prefix table for a
matching name prefix of the object name to beresolved. Notice that anyoneofI,la, lalb,
or/a/b/eis amatching name prefix for an objectnamedla/ble.If more than one matching
name prefixes are found, the longest one is selected and the client uses the corresponding
zoneidentifier information to send its request directly to the server that stores that zone.
The specific zone identifier of the table entry is also sent along with the request.
When the server receives the request, it uses the specific zone identifier associated
with the request to carry out the requested name resolution. It then maps the rest of the
component names of the named object with the contexts (directories) of the selected zone.
If all theremaining components are mapped, the name resolution operation completes and
theobject'sattributes are returned by the server to the client. On the other hand, if only
a part of the remaining component names is resolved in the selected zone, then some other
zone has to be used for further resolution of the name; that is,a zone crossing is necessary.
In this case, the server returns the next zone'sname prefix to the client for further
processing. The clientthenbroadcasts the new prefix to obtain the zone identifier of the
next zone. The servers that store that zone respond to the broadcast message. Using the
responses, the new zone'sdetails are entered into the name prefix table and the name
resolution proceeds as before by sending the request to a server of the new zone.
The name prefix table is built and updated dynamically with a broadcast protocol.
Initially, each client starts with an empty name prefix table. Entries are added to the name
prefix table of a client only when needed. That is, the name prefix of a zone that has never
beenaccessed by a client will not appear in its name prefix table. In some systems, the
name prefix of the zone containing the root directory of the name space tree is known to
all nodes and is enteredinto a name prefix table at the time of its creation. With this
approach, a client never experiences acomplete miss while searching a name prefix for
any name in the name prefix table.
Notice that in this scheme the name prefix of a zone may simultaneously exist in
multiple name prefix tables of the same or different nodes. Furthermore, the servers of a
zone may change dynamically, providing increased availability, security, and efficiency.
Therefore, an important issue ofthis scheme is the updating of entries in name prefix
tables to keep them consistent. Instead of informing all clients when the server of a zone
they are storing in their name prefix tables changes, the consistency of name prefix table
entries is maintained by detecting and discarding/updating stale table entries on use. That
is, theserverinformation stored in a name prefix table is made up of hints that are
corrected when they are found to be wrong. A hintis a piece of information that can
substantially improve performance ifcorrect but has no semantically negative con­
sequence if incorrect. For maximum performance benefit a hint should nearly always be536 Chap.10 • Naming
correct.Of course, only information that isself-validating upon use is amenable to this
strategy. When a clienttries to use a stale name prefix table entry, it ends up sendingits
namerequestto the wrong server. If the serverno longer exists, the client receivesno reply
and times out. Iftheserverexists but no longer stores the given zone, the serverreports
that fact back to the client. In eithercase, the client recognizes that its table entry is stale,
deletesthe entry, and issues a broadcast forup-to-date serverinformation for the zone to
which the contextcorresponding to the named object'slastcomponent name belongs.
Thisschemehas thefollowing advantages:
1.Matching on a name prefix ratherthan on the full name allows a small numberof
tableentriestocovera largenumberofnames, resulting in good performance. For
example, inFigure10.17, a single table entry for laallows every name ofobjectsin this
zone to go directlyto thecorrectserverwithout the overhead ofabroadcast or global
directory lookup. The zone having prefix name lacanreasonably containtheattribute
information for hundreds or thousands ofobjects.
2. Ascompared toglobaldirectory lookup, in which all directories startingfrom the
root down to the last component nameofthe named object are searched one by one, the
name prefix table helps in bypassing partofthe directory lookup mechanism. The
directory bypass has advantages inperformance and reliability becausea crash on one
nameserverdoes not preventclients from resolving names in zones on otherservers. To
illustrate this, let us see the example given in [Welch and Ousterhout 1986]. In a system
with two zones Iandla,the server for Ineed not be available forresolving the name lalble.
If aclientalready has an entry for lain its name prefix table, then it will use it and
communicate directlywith the serverfor that zone; otherwise it willbroadcast the name
lalbleand the serverforlawillrespond directly to the clientwith zone identifier
information. Inneithercase is the serverforIinvolved. This bypassing mechanism
reducescontention for the upper level directories. However, the bypassing of upper level
directories hasconsequences on thesystem's securitymechanism. Toillustrate this, once
again let us see the example given in [Welch and Ousterhout 1986].Ifthere is a name
prefixla/bleand theclientlooks up the name lalblcld, neitherlanorlalbisexamined; the
clientcommunicates directlywith theservercontaining lalble.This means that any access
controlsindirectories laorlalbwill be ignored. The effect is that all programs implicitly
have search permission along the paths to all the directories. If access to a directory is to
berestricted, it must be restricted with access controls at the level ofthedirectory or
below.
3. Theon-useconsistency checking ofa name prefix table entry results in
considerable savingofconsistency controloverheads becausethere is no need to inform
allclientswhen a table entry they are storing becomes invalid.
Structure-Free Distribution of Contexts
Nameservices should be able to be reconfigured if thepresentservers become
overworked oroverburdened with data or ifthe system scale changesdue to addition or
removalofworkstations (nodes). Reconfiguration often requires changing anobject'sSec. 10.6 • Human-Oriented Names 537
authoritative name server. In the lone-based context distribution approach, changing an
object'sauthoritative name server will require changing its name, storing all the contexts
in the zone that corresponds to the object and is managed bytheobject'scurrent
authoritative name server on the new name server, or creating a new zone for storage with
theobject'snewauthoritative name server. The new zone will be a subzone of the zone
thatcorresponds to the object and is managed by the object'soldauthoritative name
server.The first two solutions areobviously not acceptable. The third solution may require
duplication of some of the contexts in the old as well as the new zones, resulting in the
need to store such contexts on both the object'sold and new authoritative name servers.
For example, in Figure 10.17(a), if theauthoritative name server for the object named
la/bleis to be changed from 82toS4'a new zone containing the contexts named la,lalb,
andlalbleor the contexts named lalb and/alblc will have to be created for storage at S4.
Notice that in the former case two contexts (Iaandlalb)will have to be stored at both S2
andS4'while in the latter case one context (/alb)needs duplication. In large name spaces,
such changes may require the duplication of many contexts. Therefore, the lone-based
scheme has limited flexibility in the assignment/changing of anobject'sauthoritative
name server.
Toovercome this limitation of the approach of distributing contexts based on the
physical structure of the name space, some systems use the structure-free name
distribution scheme. A structure-free namedistribution isone that places no restriction on
theadministrative control over parts of a name space. Therefore, in this scheme, any
context of the name space can be freely stored/moved at any name server independently
of any other context. That is, in this approach, each context may be considered to belong
to its own zone. A name service based on this approach permits maximum flexibility in
theassignment/changing of anobject's authoritative name server. Furthermore, this
scheme also simplifies name management because name servers need not agree on what
zones make up the name space.
In systems using this scheme, some policy isused forthe partitioning and distribution
of contexts among name servers. For example, in Galaxy [Sinha et al. 1991a], the
distribution andreplication of contexts among name servers of various nodes are based on
the idea of improving the reliability of the name resolution mechanism. The details of this
policy is given in [Sinha et al. 1992J.Also notice that in this scheme name space structure
need not but can be exploited to partition and distribute the contexts among name
servers.
In this scheme, the name resolution operation for a given object name is carried out
bytraversing thecomplete resolution chain of contexts on a context-by-context basis until
the named object'sauthoritative name server is encountered. For example, the pathname
lalbleof an object is resolved byfirstconsulting the root context (I)to obtain the location
of thepathname's next context (fa).Recall that this is stored in the root context as a
context-binding information. With the location information obtained, the context lais
consulted next to obtain the location of the pathname's next context (Ialb).Finally, the
namedobject'sauthoritative nameserver'sinformation is obtained by consulting the
contextlalb.Notice that since each contextcan be freely placed at any server, so a name
resolution operation may migrate from server to server, possibly hopping from one node
to another ifthe servers involved are located on different nodes.538 Chap.]0 •Naming
The are two important questions to beaddressed in this type ofnameresolution
mechanism:
1. How should contextobjectsbelocated?
2. How should one interactwith name servers while resolving a name?
Methods to handle these questions aredescribed below.
Locating ContextObjectsDuringName Resolution. Recall that a qualified
nameconsistsofacontext/name pair. That is, a name is always associated with some
context.Therefore, when a user specifies a name to be resolved, its resolution should start
in thecontextto which it is associated. Hence, the first step in the resolution process is to
locate the context. However, locating acontextinvolves resolving its name. Thatis, a
context-locating operation istriggered by theresolution ofa name in the first place. Thus,
weobserveaninfiniterecursion that must be solved using some special technique. Two
commonly used methods to tackle this problem are described below.
1. Using ametaeontext. In this method, a special context, called a metaeontext, is
used that containsthe name and authority attributepairs for all contextobjectsin the name
space. The size ofthemetacontext dependson thenumberofcontexts in the name space.
Ifit is small, it can be stored at all name server nodes. However, ifit is large, it is stored
only at some name server nodes, and other name servers only store pointersto the servers
that store the metacontext. Therefore, given a name to be resolved in a context, the
metacontext is firstconsulted toobtainthe authority attribute of the context. The name is
then sent for resolution to one of the authoritative name servers of the context.
2.Always starting the resolution from the root context. This method is used in
thosenaming systems in which the name space is structured as a single global
hierarchical name tree. In this method, the root contextisreplicated at all name server
nodes. Given a name to be resolved in a context, we say that the name is relative to
that context. A relative name can be converted to an absolute name by prepending the
contextname to it. Recall that an absolute name begins at the root contextofthe name
space.Therefore, in this method, given a name to be resolved in a context, the name
is firstconverted to itsabsolute form and then its resolution starts from the root context.
Since the root contextisavailable at all name servernodes, the resolution of any name
can bestartedat any name servernode.
Interacting with Name Servers DuringName Resolution. We saw that the
variouscontextsofa givenpathname may be stored at different name servers. Therefore,
theresolution ofapathname in such a situation willinvolveinteracting with all the name
servers that store one or more contexts of thepathname. During name resolution, a name
agent may interactwith the name servers in one ofthe following manners:
1.Recursive. In this method, the name agent forwards the name resolution request
to the name serverthat stores the first contextneeded to start the resolution ofthe given
name.Afterthis, the name servers that store the contexts ofthe given pathname areSec. 10.6 • Human-Oriented Names 539
recursively activated one after anotheruntil the authority attribute ofthe named objectis
extracted from the contextcorresponding to the last component name of the pathname.
The last name server returns the authority attributeto its previous name server, which then
returnsitto its own previous name server, and so on. Finally, the first name serverthat
received the requestfrom the name agent returns the authority attribute to the name agent.
Figure 1O.18(a)illustrates the method of recursive interaction.
Client
7
Name
server
(a)
Client
2
3
(b)
Client67
2 5
Fig. 10.18 Methods of interacting with name
serversduringname resolution:
(a)recursive; (b)iterative;
(c)transitive. (c)
As anexample, ifthe name lalbleis to be resolved, the name agent sends it to
the name server (say Sl)of the root context (I)and waits for a reply. ThenS]
searches for the component nameain the root context, extracts thecorresponding
bindinginformation, sends the remaining pathname bleto the name server (say S2)of540 Chap.10 •Naming
the next context (/a),and waits for a reply. Then S2extracts from contextlathe
bindinginformation corresponding to thecomponent nameb,sends the remaining
pathname cto the name server (say S3)of the next context (Ialb),and waits for a
reply. Then S3extracts from contextlalbthe authority attribute corresponding to the
component name c and returns it to S2'which in turn returns it to Sitand finally S,
returns it to the name agent.
Notice that in the recursive name resolution mechanism, the name agent.has little
work to do but the name servers may be involved in processing several requests at the
same time. Therefore, the name servers may get overloaded insituations where the
numberofname agents is too large as compared to the number ofname servers.
Hence, this mechanism is not suitable for use in those systems in which the ratio of
name agents to name servers is very high. Furthermore, to allow a name server to
startanother jobwhen waiting for a response, the name servers have to be
multiprogrammed.
2. Iterative. As shown in Figure 1O.18(b), in this method, name servers do not
call each other directly. Rather, the name agent retains control over the resolution
process and one by one calls each ofthe servers involved in the resolution process. As
in the recursive process, the name agent first sends the name to be resolved to the
nameserverthat stores the first contextneeded to start the resolution of the given
name. The server resolves as many components of the name as possible. If the name
iscompletely resolved, the authority attribute of the named object is returned by the
server to the name agent. Otherwise, the server returns to the name agent the
unresolved portion of the name along with the location information ofanother name
server that the name agent should contactnext..To continue the name resolution, the
name agent sends a name resolution request along with the unresolved portion ofthe
name to the next name server. The process continues until the name agent receives the
authority attribute of the named object.
3. Transitive. In this method, a name is resolved as follows. The name agent first
sends the resolution request to the name server that stores the first contextneeded to
start the resolution process. The server resolves as many components ofthe name as
possible. It then passes on the unresolved portionofthe name to the name server that
stores the next contextneeded to proceed with the resolution process. This name
serverresolves as many components of the name as possible and then passes on the
unresolved portionofthe name to the next name server. The process continues and the
name server .that encounters the authority attribute of the named object returns it
directly to the name agent. The method is illustrated in Figure 10.18(c).
Notice that, as in the recursive method, in this method also the name agent
has little work to do. Also notice from Figure 10.18that the transitive approach
requires the fewest number of messages. However, a sender does not receive any
acknowledgment message once it passes on the resolution operation to another
server.Therefore, thisapproach shouldbeused in systems with reliable commu­
nication. On the other hand, recursive and iterative approaches canbeefficiently
supported byRPC-based communication systems because they use a "call-response"
model.Sec. 10.7 • Name Caches
10.7NAMECACHES541
Readers might have observed that name resolution operations are not likely to be
especially cheap. Based on the measurements made by few researchers in the past, it
has been found that in operating systems that providea flexible, hierarchical name
space, the system overhead involved in name resolution operations isconsiderably
large. For instance, Lefflereta1.[1984]attribute 40%ofthe system call overhead in
UNIX to file name resolution. Also,Mogul's measurements of the UNIX system call
frequency indicatethatname-mapping operations (open, stat, lstat) constitute over 50%
ofthe filesystemcalls [Mogul 1986]. Sheltzer et al. [1986] also made an observation
that in a large distributed system a substantial portion of network traffic is naming
related. Hence it is very desirable for aclientto be able to cache the result of a name
resolution operation for a while, ratherthanrepeating it every time the value is
needed.
Work has been carried out in the past by some researchers [Sheltzer et al. 1986,
Cheriton and Mann 1989] to investigate whetheradistributed name cache is a suitable
solution to improve theperformance of name service as wen as to reduce the overall
systemoverhead. Theconclusion drawn by these researchers is that a simple distributed
name cache can have a substantial positive effect on distributed systemperformance. This
is mainly due to the following characteristics of name service related activities:
1. High degree oflocalityofname lookup. The property of "locality of reference"
has been observed inprogram execut.ion, file access, as well as database access.
Measurements made by Sheltzeret al. [1986] and Cheriton and Mann [1989] clearlyshow
that a high degree oflocality also exists inthe use of pathnames for accessing objects. Due
to this locality feature, a reasonable size name cache, used for caching recently used
naminginformation, can provide excellent hit ratios.
2. Slow update ofname information database. It has also been found that naming
data does not changevery fast, so inconsistencies are rare. The activity of most users
is usually confined to a small, slowly changing subset of the entire name information
database. Furthermore, most naming data have a high read-to-modify ratio. This
behavior implies that the cost of maintaining theconsistency of cached data is
significantly low.
3. On-use consistency ofcached information is possible. An attractive feature of
name service relatedactivity is that it is possibleto find that something does not work if
one tries to use obsolete naming data, so that it can be attended to at the time ofuse. That
is, name cache consistency can bemaintained bydetecting anddiscarding stale cache
entries on use. With on-use consistency checking, there is no need to invalidate allrelated
cacheentries when a naming data update occurs, yet stale data never causes a name to be
mappedto the wrong object.
Some issues specific to the design ofname caches are discussed in the next
section.542 Chap.10 •Naming
10.7.1Typesof Name (aches
Depending on the type of information stored in each entry, a name cache may be of one
of the following types:
1. Directory cache. In this type of name cache, each entry consists of a directory
page. This type of cache is normally used in those systems that use the iterative method
of name resolution. All recently used directory pages that are brought to the client node
during name resolution arecached fora while. For example, LOCUS [Sheltzer et al. 1986]
uses name caches of this type. The argument given by LOCUS designers in favor of
caching directory pages is that common tasks such as listing the contents of a directory,
expanding wild card arguments, and accessing parent directories all use information found
in directory pages. However, this means that for only one useful entry of a directory an
entire page of the directory blocks a large area of precious cache space requiring large­
sized name caches.
2. Prefix cache. This type of name cache is used in those naming systems that use
the zone-based context distribution mechanism. In this type of name cache, each entry
consists of a name prefix and the corresponding zone identifier. Recall that a name prefix
corresponds to a zone in the zone-based context distribution approach. Details of the useof this type of name cache has already been presented inSection 10.6.4.Sprite [Welchand
Ousterhout 1986] and V-System [Cheriton and Mann 1989] use this type of name cache.
This type of name cache is not suitable for use with the structure-free context distribution
approach.
3. Full-namecache. Inthis type of name cache, each entry consists of an object'sfull
pathname and the identifier and location of its authoritative name server. Therefore
requests for accessing an object whose name is available in the local cache can bedirectly
sent tothe object'sauthoritative name server.This typeof namecache can beconveniently
used with any naming mechanism, although it is mainly used by the naming systems that
use the structure-free context distribution approach. Notice that in a prefix cache an entry
usually serves as a mapping information for several objects, but in a full-name cache each
entry serves as a mapping information for only a single object. Therefore, full-name
caches are usually larger in size as compared to prefix caches. This type of name cache
is used in Galaxy [Sinha et al. 1991b].
10.7.2Approaches for Name (acheImplementation
The two commonly used approaches for name cache implementation are as follows:
1. A cache per process
2. A single cache for all processes of a node
Both approaches have their own advantages and drawbacks. In the first approach, a
separate name cache is maintained for each process. Each cache is maintained in the
corresponding process's address space and is usually small in size. Therefore, accessing
of cached information is fast and no memory area of the operating system is occupied bySec.10.7• NameCaches 543
the name caches. However, a process-oriented name cache vanishes with the process.
Therefore every new process must create its name cache from scratch. Hence, if the
processes are short lived, the caches will have short lifetimes, and the true hit ratio will
be fairly low for process-oriented caches due to start-up misses, which are initial misses
that occur when a new,empty cache is created. Furthermore, the use of a process-oriented
cache is limited only to a single process due to which there is a possibility that the same
naminginformation isduplicated in several caches of the same node. To alleviate the
problem of start-up misses, V-System implementation [Cheriton and Mann 1989] uses
cacheinheritance to give cached data a long lifetime. In this method, each process inherits
its initial cache contents from its parent process (usually the V-System command
interpreter or "shell").
In the second approach, a single name cache is maintained at each node for all the
processes of that node. As compared to theprocess-oriented name caches, these caches are
larger in size and are located in the memory area of the operating system. Accessing of
cachedinformation is slower as compared to that of process-oriented caches. However,
cachedinformation in asingle-name cache is long lived and is removed only when the
cachereplacement policy finds it suitable for being removed. Therefore the problem of
start-up misses is not associated with the single-name cache approach, resulting in higher
average hit ratio as compared totheprocess-oriented caches. The possibility ofduplicating
cachedinformation on the same node is also not there in this approach.
Sprite and V-System use process-oriented name caches, whereas LOCUS and Galaxy
use thesingle-name cache approach.
10.7.3Multlcacha Conslstancy
When a naming data update occurs, related name cache entries become stale and must be
invalidated or updated properly. Two commonly used met.hodsfor multicache consistency
of name caches are immediate invalidate and on-use update.
Immediate Invalidate
In this method, all related name cache entries are immediately invalidated when a naming
data update occurs. There are two ways of doing this. In the first approach, whenever a
naming data update operation is performed, an invalidate message identifying the data to
be invalidated is broadcast to all the nodes in the system. Each node'sname caches are
thenexamined for the presence of the updated data, and if it is present, the corresponding
cache entry is invalidated. Although this approach may work well for a system having a
few nodes, its use becomes prohibitive for very large networks having many nodes.
To avoid the use of broadcast protocol, in the second approach, the storage node of
naming data (for example, the storage node of a directory) keeps a list of nodes against
each data that corresponds to the nodes on which the data is cached. When a storage node
receives a request for a naming data update, only the nodes in the corresponding list are
notified to invalidate their corresponding cache entry. This method is acceptable only if
there is a low rate of update to naming data that are shared among nodes and only if a
small number of nodes share a naming data when that data is modified.544 Chap. 10 • Naming
On-UseUpdate
This is the more commonly used method for maintaining name cache consistency. In this
method, no attempt .ismade to invalidate all related cache entries when a naming data
update occurs. Rather, when aclient uses a stale cached data, it is informed by the naming
system that the data being used is either incorrectly specified or stale. On receiving a
negative reply, necessary steps are taken (either by broadcasting or multicasting a request
or by using some other implementation dependent approach) to obtain the updated data,
which is then used to refresh the stale cache entry.
10.8NAMING ANDSECURITY
An important jobof the naming system ofseveral centralized and distributed operating
systems is to control unauthorized access to both the named objects and the information
in the naming database. Many different security mechanisms have been proposed and are
used by operating systems to control unauthorized access to the various resources
(objects) of the system. Chapter 11fully addresses security issues. This section describes
only those security issues that are pertinent to object naming. Three basic naming-related
access control mechanisms are described below.
10.8.1ObJ-ct Namas As Prot.ctlon Hays
In this method, an object'sname acts as a protection key fortheobject. A user who knows
the name of an object (i.e., has the key for the object) can access the object by using its
name. Notice that an object may have several keys in those systems that allow an object
to have multiple names. In this case, any of the keys can beused to access the object.
In systems using this method, users are not allowed by the system to define a name
for an object that they are not authorized to access. Obviously, if a user cannot name an
object, he or she cannot operate on it. This scheme is based on the assumption that object
names cannot be forged or stolen. That is, there is no way for a user to obtain the names
ofotheruser'sobjects and the names cannot beguessed easily.However, inpractice, since
object names are generally picked to be mnemonic, they can often be guessed easily.
Therefore, the scheme does not guarantee a reliable access control mechanism. Another
limitation of this scheme is that itdoes not provide the flexibility of specifying the modes
ofaccess control. That is, a user having a name for an object usually has all types of
possible access rights for the object. For instance, providing only read access to a file
object to one user and both read and write accesses to another user is not possible by this
scheme alone.
10.8.2Capabilities
This is a simple extension of the above scheme that overcomes its limitations. As shown
in Figure 10.19, a capability is aspecialtype of object identifier that contains additional
information redundancy for protection. It may be considered as an unforgeable ticket thatSec.10.8 • NamingandSecurity
Fig. 10.19 The twobasicpartsof a
capability.Objectidentifier RightsinformationS4S
allowsits holders to access the object(identified by itsobjectidentifier part) in one or
morepermission modes(specified by its access controlinformation part).Therefore,
capabilities areobjectnameshavingthefollowing properties:
1.Acapability is asystem-oriented name that uniquely identifies an object.
2. Inadditiontoidentifying anobject,itis also used to protecttheobjectitreferences
bydefining operations that may be performed on theobjectitidentifies.
3. Aclientthatpossesses acapability can access the objectidentified by it in the
modesallowedby it.
4.Thereare usually several capabilities for the same object. Each one confers
different accessrights to its holders. The same capability held bydifferent holders
provides the same access rights toallofthem.
5. Allclientsthat have capabilities to agivenobjectcan share this object. The exact
modeofsharingdepends on thecapability possessed byeachclientofthe same
object.
6.Capabilities areunforgeable protected objectsthat aremaintained by theoperating
systemand only indirectly accessed by the users. Capability-based protection
relies on the fact that the capabilities are never allowedtomigrateinto anyaddress
spacedirectlyaccessible bya userprocess(wheretheycouldbemodified). If all
capabilities are secure, the objects they protectare also secure against
unauthorized access.
When aprocesswants to performanoperation on an object, itmust send to the name
serveramessage containing theobject's capability. The name serververifies if the
capability provided by the client allows the type of operation requested by the client on
therelevantobject.Ifnot, a"permission denied"message isreturned to theclientprocess.
Ifallowed, theclient'srequestisforwarded to themanagerofthe object. Noticethat in the
capability-based approach, there is no checking ofuser identity. If this is required, some
userauthentication mechanism must be used. Chapter11deals with these issues in greater
detail.
10.8.3Associating Prot.ctlon withNamaA.solutlon Path
Protection can beassociated eitherwith anobjector with the name resolution pathofthe
name used to identifythe object. The more common schemeprovides protection on the
nameresolution path.
Systems using this approach usuallyemploy accesscontrollist (ACL) based
protection, whichcontrols accessdependent on theidentityof the user (described in
Chapter 11). The mechanism based on AC:Lrequires, inaddition to theobjectidentifier,
anothertrustedidentifier representing theaccessing principal, theentitywith which accessS46 Chap.10 • Naming
rights are associated. This trusted identifier mightbeapassword, address, or any other
identifier form that cannotbe forged or stolen. An ACL is associated with anobjectand
specifies the user name (user identifier) and the types ofaccess allowed for each user of
that object. When auser requestsaccess to an object, the operating system checks theACL
associated with that object. Ifthat user is listed for the requested access, the access is
allowed. Otherwise, aprotection violation occurs and the user jobis denied access to the
object.
Byassociating an ACL with each context(directory) of the name space, access can
becontrolled to both the named objects and the information in thenamingdatabase. When
a nameserverreceives an access requestfor a directory, it first verifies if the accessing
processisauthorized .fortherequested access. With this approach, name servers do not
provideinformation to clients that are not authorized to have it, and at the same time name
serversdo not accept unauthorized updates to naming information stored in the contexts
ofthe name space.
Regarding accesscontrolto an object, a client accesses anobjectbyspecifying its
name. A name is first resolved using the contextobjectsto find out the named object's
authoritative name server. If the ACL associated with any ofthecontexts thatcorrespond
to the name oftheobjectdoes not allow the client to access contextinformation, the name
specified by theclientcannotbe resolved and the client will automatically not be allowed
to access the objectby using that name.
Notice that, to allow access to an objectin this scheme, a user must be allowedaccess
to both the directories of theobject'spathname and the objectitself.Therefore, associating
protection with the name resolution path of an objectnameprovides anadditional layer
ofprotection to the named object. Also notice that, in systems where objectsmay have
multiple pathnames (such as acyclic or general graphs), a given user may have different
access rights to an object depending on the pathname used.
10.9CASESTUDY:DCEDIREOORY SERVICE
As a case study ofhow the naming concepts andmechanisms described in thischaptercan
beused to build a naming system for a distributed computing system, the DCE Directory
Serviceis briefly described below.
Recall from Chapter1that in a DCE system, users, machines, and other resources are
grouped into cells. Therefore, the DCE Directory Servicemainly has the following types
ofcomponents for intracell and intercell naming:
1. CellDirectory Service (CDS), whichcontrols the naming environment used
within a cell. Every cell has at least one CDS server.
2. Global Directory Service (GDS), whichcontrolsthe global naming environment
outside(between) cells. It links cells togetherso that any cell can be located from
anyothercell. GDS implementation is based on the X.500directory service,
which is an international standard for naming definedby theCCITTand ISO
standards organizations. Therefore, X.500-style names(described later) are used
in DCE for naming cells.Sec. 10.9 • Case Study: DeEDirectory Service 547
Since many DCE users use the Internet, DCE also supports the standard Internet
DomainName System(DNS) for cell naming. Therefore, cell names in DeEcan also be
specified in DNS notation (described later).
10.9.1DCENameSpaceandNamingConvention
TheDCEuses the single global name space approach for object naming. That is, the
DCE name space is a single, worldwide structure, with a global root denoted by the
symbolI....Below this root appears the GDS name space, used to name each cell. If
DNS names are also used to name cells in the same DCE system, its name space also
appears below the DeEglobal root, sitting bythe side of the GDS name space. Finally,
each cell contains its own internal name space, starting from the cell root. An example
of theDCEname space structure is shown in Figure 10.20.
I...
Fig. 10.20 The name space structure of a
DCEsystemhavingncells that
usesbothX.SOOand DNS
notations for cell naming.
Each object in DeEhas a unique name that mainly consists of the following parts
each of which is separated bya slash (see Fig. 10.21):
1. Aprefix.This part indicates whether the name is local to the current cell or global
to the entire DeEname space. The prefix I.:is used to denote a local name,
whereas the prefix I...is used to denote a global name.
Prefix Cellname Localname
/...meansglobal inX.500notationor UNIX-like
/.:meanslocal inDNSnotation hierarchical name
Fig. 10.21 The DCE naming convention. Objectname =prefix/cell name/local nameS48 Chap.10 • Naming
2. Cellname. This is an optional part specified only when the prefix /... is used for
the first part of the name. This part can be specified either in X.5ODnotation or in
DNS notation. A global name must contain this part, whereas a local name must
not contain this part.
3. Localname. This part uniquely identifies an object within a cell. The UNIX-like
hierarchical naming scheme is used for local names.
The X.500 and DNS notations for cell naming are briefly described below.
TheX.SOONotation
The OSI X.500 is an international standard for naming people, computers, resources,
services, or anything else that needs a unique name. It uses the hierarchical, attribute­
based naming scheme (see Fig. 10.22). Therefore, in the X.5ODnotation, a name is
represented by a set of attributes separated by slashes. Each attribute has an attribute type
and one or more values. The type and value of an attribute are separated by an equal sign.
Therefore, a typical X.5ODname may be of the form
[Country»USIOrg Type=COMIOrgName=JBMIDept=ENGIPerson=Nan cyl
which uniquely identifies a person named Nancy who belongs to the ·engineering
department of a company named IBM in the United States. In X.500 terminology, each
Fig.l0.22 Part of an X.500 directory information tree.Sec.10.9• CaseStudy:DCEDirectory Service 549
component of a name is called the relativedistinguished name(RDN) and the full name
is called the distinguished name(DN).
X.500 also provides the facility to define and use aliases, which are similar to
symbolic links in a file system.
The X.500 name tree is called the Directory Information Tree(DIDand the entire
directory structure including the data associated with the nodes is called the Directory
Information Base(D/B).A DIB entry consists of a set of attributes described in the OSI
ASN.lnotation (a standard notation for syntax definitions). For each attribute type, the
description includes a type description and a syntax definition defining representations for
allpermissible values of the type. New attributes can be defined as and when required.
X.500 uses an object-oriented information model for grouping DIB entries into
classes. Each DIB entry has an ObjectClass attribute that determines the class (or classes)
of the object to which an entry refers. For instance, in the DIT of Figure 10.22, Country,
Org'Iype, OrgName, Dept,andPersonare all examples of values of ObjectClass attribute.
Thedefinition of aclass determines which attributes arc mandatory and whichare optional
for entries of the given class. The ObjectClass attribute is always mandatory, whose value
must be the name of one or more classes. If the ObjectClass attribute of an object has two
or more values, that object inherits the mandatory and optional attributes of each of the
corresponding classes.
X.500, being a standard, does not address implementation issues. Readers interested
in a more detailed description of X.500 and methods for its implementation may refer to
[Rose 1992].
The DNS Notation
The DNS is the standard scheme for naming hosts and other resources on the Internet. It
usesahierarchical, tree-structured name space partitioned into domains. In this scheme,
a name consists of one or more strings called labelsseparated by the delimiter ".". There
is nodelimiter at the beginning or end of a name. Names are written with the highest level
domain on the right.
The Internet DNS name space is partitioned bothorganizationally and according to
geography. It divides the world up into top-level domains consisting of country names
such asus(United States) (this is the default top-level domain and is often omitted in the
qualified name of an object belonging to this domain), uk(UnitedKingdom),fr (France),
andjp(Japan). Different countries then have their own organizational domains that form
the next level of domains of the name space tree. For example, in the United States, the
organizational domains are edu(educational institutions), com(commercial organiza­
tions),gov(government agencies), mil(military organizations), net(network support
centers), int(international organizations), and org(organizations not included inany of the
above-mentioned domains). The organizational domains in turn have subdomains such as
stanford. edu,ibm.com, anl.gov, andieee.org. These subdomains in turn have sub­
subdomains such as cs.stanford.edu.
Registration authorities responsible for the registration of names in a domain at a
particular level are different. For example, the domain cs.stanford.edu.us, which stands for
thedepartment ofComputer Science at Stanford educational institution of the United550 Chap.10 •Naming
States, can containany name the department wishes. But the name csin thedomain
stanford.edu.us has to be agreedwith theStanford University authorities, whomanagethe
domainstanford.edu.us. Similarly, the name stanford in thedomainedu.ushas to be
agreedwith the registration authorities whomanagethedomainedu.us,and so on.
Insummary, Figure10.23 shows the three different ways that may be used to refer
to anobjectin DCE.
I...IENG.IBM.COM. USlnancylletters/tollucy
(a)
I...ICountry=US/OrgType=COM/OrgName=IBM/Dept=ENG/nancy/letterslto/lucy
(b)
I.:/nancy/letters/to/lucy
(c)
Fig. 10.23 Three different ways to refer to the same object in DeEDirectory
Service. Global object name with cell name specified in (a)Internet
format (DNS notation) and (b)ODS format (X.500 notation);
(c)local object name within a cell.
10.9.1Intrac.1INamingInDCE
Allnameswithin acell are managed by the CDS, whose functions and implementation are
brieflydescribed below.
CDSDirectories
The CDS ofa cellbasically manages the CDS directories ofthe cell that are organized in
ahierarchical treestructure. Thesedirectories collectively containthenamesandattributes
ofall theobjectswithin the cell. Each CDS directory has anumberofdirectory entries.
Eachdirectory entryconsistsofa name and a set ofattributes. Forexample, adirectory
entryfor aprintermightcontainits name, its location, and itscharacteristics, such as type
and speed.
DCEuses theapproach ofassociating protection with the name resolution pathofan
objectname.Therefore, eachdirectory entry also has protection information associated
with it that specifies which users have what types ofaccess rights (such as read, delete)
for the entry. The CDS manages thisprotection information. Note that permission to
access adirectory entry does not imply permission to access the named object. Protection
information for the named objectismanaged by theserverthatmanages the object.Sec. 10.9 • Case Study: DeEDirectory Service 5S1
Therefore, the server knows which users have what types of access rights for the
object.
Replication of Naming Information
For better performance and reliability, CDS supports replication ofitsinformation, with
the unit of replication being a directory. A collection of directories forms a
clearinghouse. Aclearinghouse is a physical database managed by a CDS server. While
every DCE cell must run at least one CDS server, most will choose to run two or more,
with critical information replicated among them. Each CDS server maintains one or
more clearing houses. Each replica of a directory resides in a different clearinghouse.
The root directory is replicated in all clearinghouses to allow a search for any name
to be begun by any CDS server. This is because when a new directory is created, CDS
automatically creates an entry for this directory in its parent directory (the directory
immediately above the new directory in the hierarchical tree-structured name space).
This entry is used to track the location of the child directory even when the parent and
childdirectories are located in different clearinghouses. The root directory contains
entries for all its children directories. Those directories, in turn, contain entries for their
own children directories, and so on. Therefore, given the root directory, this path of
connectivity enables CDS servers to find every directory (and thus every entry) in the
name space.
Consistency of-Replicated NamingInformation
To maintain the consistency of the naming information in replicated directories, DeE
uses the primary-copy protocol for directory update operations. That is, for each
replicated directory, one copy is designated as the primary copy and all others are
secondary copies. Read operations can be performed using any copy of a replicated
directory, primary or secondary. But all update operations are directly performed only
on the primary copy. One of the following two approaches is used to update the
secondary copies:
1. Update propagation. In this method, when the primary copy of a directory is
updated, the changes are immediately sent to all the secondary copies. This
method is used for updating the naming information that must be kept consistent
all the time.
2.Skulking. In this method, the changes made to the primary copy are accumulated
and areperiodically sent together in a single message. This method is used for
updating less critical naming information.
CDSImplementation
The CDS implementation uses the client-server model. That is, there are CDSserver
daemonprocesses andCDSclientdaemon processes. A CDS server runs on a server
machine, stores and manages one or more clearinghouses, and handles requests to552 Chap.10 •Naming
create, modify, or look up names in its local clearinghouse. On the other hand, a CDS
client, called a CDS clerk, runs on every client machine that uses CDS. A CDS clerk
receives a request from a client application, interacts with one or more CDS servers to
carry out the request, and returns the resulting information to the client. A CDS clerk
also maintains a name cache in which itsaves the results of name resolution requests
for future use. The cache is written to disk periodically so that the information in it can
survive a system reboot or the restart of an application.
How CDS ClerksLearnaboutCDSServers
A CDS clerk learns about the existence of a CDS server in one of the following ways:
1.Bybroadcasting. CDS servers periodically broadcast their existence. CDS clerks
learn about CDS servers by listening to these broadcast messages. This method allows
CDS clerks to learn about all those CDS servers that reside on the same LAN as that of
the CDS clerk.
2.Duringaname resolution. During a name resolution, if a contacted CDS server
cannot completely resolve the name with the information in its local clearinghouse, it
returns to the requesting CDS clerk the location of another CDS server that has more
information about resolving the given name. Such areply from aCDS server during name
resolution helps a CDS clerk to learn the existence of another CDS server that it was
unaware of until now.
3. Bymanagement command. A DCE administrator can use the CDS control
program to create information about a CDS server in a CDS clerk'scache. This method
is normally used when theCDS clerk and the CDS server reside on different LANs so that
broadcast messages sent by the CDS server on its own LAN cannot be received by the
CDS clerk on a different LAN.
Name Resolution
A name resolution operation (called lookupin CDS) is performed in the manner described
below.The steps of this description correspond to the steps of Figure 10.24, which shows
how a simple name resolution operation is performed in DCE:
1. A client application sends a lookup request to its local CDS clerk in an RPC
message.
2. The CDS clerk checks its cache for the name. Ifitis found in the cache, the CDS
clerk returns a reply to the client and the name resolution operation completes.
3. If the name is not found in the cache, the CDS clerk does an RPC with a CDS
server that it knows about.
4. With the directories available in its local clearinghouse, the CDS server tries to
resolve as many components of the name as possible.
5. If the name can becompletely resolved, the CDS server returns the result of name
resolution to the CDS clerk.Sec.10.9• CaseStudy:DCEDirectory Service
Clientmachine
Name
cache3
5Servermachine
DirectoriesSS3
."ig.l0.24 Steps of a simple name resolution in DCE. Complex name resolutions
involving multiple CDS servers use the iterative approach of
Figure JO.18(b).
6. The CDS clerk caches this information in its cache for future use.
7. The CDS clerk finally returns a reply to the clientand the name resolution
operation completes.
If the name can only be partially resolved bythecontacted CDS server in Step 4
above(remember that partial name resolution is always possiblesince the root directory
isreplicated in everyclearinghouse), the CDS server returns to the CDS clerk the location
ofanotherCDSserverthat has more information aboutresolving the given name. The
CDS clerk then interacts with this newly learned CDS server for getting the name
resolved. This step is repeated until the name gels resolved and the CDS clerk receives the
result of name resolution from the last contacted CDS server. That is, the iterative
approach ofinteraction among the name agent and name servers is used during name
resolution. The CDS clerk caches the result of name resolution and theinformation of
newly learned CDS servers and returns a reply to the client.
Notice from the description above that CDS only performs the name resolution
operation. It does not perform an object -accessing operation. To access the object after
successful nameresolution, a client must do an RPC with the server that manages the
named object.
10.9.3Intereell Namingin DeE
A client in one cell may want to access an objectthat belongs to anothercell. To resolve
names that point toobjects inother cells, CDSclerks must have awaytolocate CDS servers
inother cells. Wehave already seenthata DeEsystem hasaGDS namespace forcell names
stored in X.500 notation. This name space is managed by aGDSserver.Wealso saw that in
addition to a ODS name space for cell names, a DeEsystem may also have a DNS name
space for cell names in DNS notation. This name space is managedbyaDNSserver.These
two name spaces map acell name to aCDS serverwithin that cell.554 Chap.10 • Naming
In addition, another component caJledGlobal Directory Agent (GDA) exists in any
cell that needs to communicate with other cells. It can exist either on the same machine
as a CDS server or on an independent machine. In the intercell name resolution example
of Figure 10.25, I have assumed that the GDA exists on an independent machine. A cell
can even have more than one GOA for increased availability and reliability. The CDS
servers of a cell have information about the location of the local GDA.
GOSmachine DNSmachine
DBofGOSnamespace
forcellnames(in X.SOO
Notation)DBofDNSnamespace
forcellnames(inDNS
Notation)
CDSmachineoftheremotecell
towhichthenamedobjectbelongs2
12Name
cacheClient
machineCDS
machine<;<,8..................
~------~"'6""",' ~~~~
...............
Fig.10.25 Intercell name resolution in DeE.
Now let us see the steps involved in the resolution of a name that points to an object
inanothercell. The steps in the following description correspond to the steps of Figure
10.25, which shows how intercell name resolution is performed in DCE:
1. A client application sends a lookup request to its local CDS clerk in an RPC
message.Sec. 10.9 • Case Study: DeEDirectory Service sss
2.TheCDSclerkchecksitscachefor thename.Ifit isfoundin thecache,the CDS
clerkreturnsareplyto theclientand thenameresolution operation completes.
3.If thenameis notfoundin thecache,theCDSclerkdoesan RPC withaCDS
serveraskingfor thelocationoftheGOA.Recallthat aglobalnamemusthave
acellnameandalocalnamemustnothaveacellname.Therefore, byseeingthe
namesupplied by theclient,theCDSclerkknowsthatit is aglobalnameand
theGDAmustbecontacted toresolveits cellname.
4.TheCDSserverreturnsthelocationoftheGDAto theCDSclerk.
5.TheCDSclerkthendoesanRPCwiththeGDA,sending it the cell name
embedded in thenameto beresolved.
6.TheGDAchecksto seewhichnotation hasbeenusedtonamethe cell. If it is
X.500notation, theGOAdoesanRPCwith theGOSserver. On the otherhand,
if thenotation used is DNS notation, theGOAdoesanRPCwith the DNS
server.
7. 'TheODSorDNSserverlooksup thecellnamein itsdatabase.
8. Itreturnsto theGOAtheaddressofa CDSserverin thenamedcell.
9. TheGOAforwards thisinformation to theCDSclerk.
10.TheCDSclerknowusesthisinformation tosenditsnamelookuprequestto
theCDSserverofthe cell to whichthenamedobjectbelongs. TheCDSserver
resolves thenameusing the directories in itsclearinghouse. In thisexample,
weassumethat the contacted CDSservercancompletely resolvethename
with the directories in itsclearinghouse. Ifthis is not the case, an iterative
approach is used by the CDS clerktointeractwithotherCDSserversofthe
remotecell.
11.TheCDSserverreturnstheresultofnameresolution to the CDS clerk.
12.TheCDSclerkcachesthisinformation in itscacheforfutureuse.
13.TheCDSclerkfinallyreturnsareplytotheclientand the nameresolution
operation completes.
10.9.4User Interfaces to the DeEDirectory Service
DeEDirectory Servicesupports thefollowing typesofuserinterfaces for users having
different accessprivileges for thenaminginformation:
1. Browsinginterface. Thisinterface is for users havingtheleastprivilege for the
naminginformation. Itallowsthe users to onlyview the contentandstructure ofcell
directories. Theinterface takesthe form ofabrowser tool that runs on workstations with
windowing software basedon theOSFlMotif graphical userinterface. Thebrowser can
displayanoveralldirectory structure as well as showthecontents ofdirectories. Itcan
also becustomized sothat itdisplays onlyspecific kindsofentries.Recallthateach
directory entryhasprotection information associated withitthatspecifies whichusers
havewhattypesofaccessrightsfor the entry. Whenauseruses the browser tool,only556 Chap.10 • Naming
those directory entries are displayed for which the user has read permission. Other entries
are not displayed.
2. XDS application programming interface. Users can create, modify, and delete
directory entries by using the XDS (XlOpen Directory Server) application programming
interface to write an application that makes direct calls to the DeEDirectory Service.
TheXDSapplication programming interface is consistent with the standard interface to
X.5oo,calledXOM (X/Open Object Management). TheXDSinterface has 13 calls for
manipulating directory objects and for setting up and initializing connections between
clients and directory servers. Some ofthe calls for directory manipulation are add_entry
for adding a new entry to a directory, remove_entry for deleting an entry from a
directory, listfor listing all entries of a directory, readfor reading the attributes of an
object,modify_entry for changing the attributes of an object, and modify_rdn for
renaming an object.
3.Administrative interface. This interface is for users having maximum privilege to
the naming information. It allows the administrators to configure or reconfigure the
naming information within the system. That is, based on the idea of where a directory is
most likely to be used, an administrator decides the distribution and replication of various
directories in the clearinghouses of different CDS servers. For replicated directories,
administrators also specify the mechanism (update propagation or skulking) to beused for
consistency control of the information in each of these directories. Furthermore, an
administrator can also change the access control rights associated with a directory entry
forcontrolling access to it.
10.10SUMMARY
A naming system ofa distributed operating system enables users and programs to assign
character-string names to objects and subsequently use these names to refer to those
objects. It provides the users with an abstraction of an object that hides the details of how
and where an object is actually located in the network.
The desirable features of a good naming system for a distributed system are location
transparency, location independency, scalability, uniform naming convention, provision
for multiple user-defined names for the same object, group naming facility, assignment of
meaningful names to objects, good performance, fault tolerance, replication transparency,
locating the nearest replica, and locating all replicas.
Aname is a string composed of a set of symbols chosen from a finite alphabet. Two
basic classes ofnames widely used in operating systems are human-oriented names and
system-oriented names.
A naming system employs one or more naming conventions for name assignment to
objects. The set of names complying with a given naming convention is said to form a
name space. A name space may either be flat or partitioned. Each partition of apartitioned
name space is called a domain of the name space. A name defined in a domain is called
a simple name. A compound name is composed of one or more simple names that are
separated by a special delimiter character.Sec.10.10•Summary 557
A name server is a process that maintains information about named objects and
provides facilities that enable users to access that information. A name space of a
distributed system is usually managed by several name servers. Each name server
normally has information about only a small subset of the set of objects in the distributed
system. The name servers that store the information about an object are called the
authoritative name servers of that object.
The distribution of the name service and the locations of the name servers should be
transparent to the clients of a name service. This transparency is achieved through name
agents that act between name servers and their clients.
Names are always associated with some context. A context can be thought of as the
environment in which a name is valid. A "context/name" pair is said to form a qualified
name that uniquely identifies an object.
Name resolution isthe process of mapping an object'sname tothe authoritative name
servers of that object.
For ease of use, a naming system usually provides the facility of abbreviations,
relative names, generic names, and multicast names for its human-oriented names.
A naming system that supports descriptive/attribute-based names allows an object to
be identified by a set of attributes or properties that describe the object and uniquely
identify it among the group of objects in the name space.
Object locating is the process of mapping an object's system-oriented unique
identifier to the replica locations of the object. The commonly used object-locating
mechanisms in a distributed system are broadcasting, expanding ring broadcast,
encoding the location of an object within its identifier, searching the creator node first
and then broadcasting, using forward location pointers, and using hint cache and
broadcasting.
The four basic approaches for assigning systemwide unique human-oriented names
to the various objects in a distributed system are combining an object'slocal name with
its host name, interlinking isolated name spaces into a single name space, full/partial
replication of remote name spaces on explicit request, and a single global name
space.
Aname space is partitioned intocontexts by using clustering conditions. Aclustering
condition is an expression that, when applied to a name, returns either a true or a false
value, depending on whether the given name exists in the context designated by the
clustering condition. The three basic clustering methods are algorithmic clustering,
syntactic clustering, and attribute clustering.
A context binding associates the context within which it is stored to another context
that is more knowledgeable about the named object and the name servers that store that
context. Two commonly used strategies to implement context bindings are table-based
strategy and procedure-based strategy. The contexts of a table-based strategy are also
known as directories.
The name resolution mechanism of a naming system depends on the policy used for
distributing the contexts of the name space of the naming system. Some of the commonly
used approaches for the distribution of contexts for name resolution are the centralized
approach, the fully replicated approach, distribution of contexts based on the physical
structure of the name space, and structure-free distribution of contexts.558 Chap. 10 • Naming
Research results have shown that a simple distributed name cache can have
substantial positive effect on distributed system performance. The three types of name
caches used in distributed systems are directory cache, prefix cache, and full-name
cache. The two commonly used approaches for name cache implementation are a cache
per process and a single cache at each node for all processes of the node. The two
commonly used methods for multicache consistency are immediate invalidate and on­
use update.
An important job of the naming system of several centralized and distributed
operating systems is to control unauthorized access to both the named objects and the
information in the naming database. The three basic naming-related access control
mechanisms are object names as protection keys, capabilities, and associating protection
with the name resolution path of an object name.
EXERCISES
10.1.What are the mainjobs performed by the naming subsystem of adistributed operating system?
Is a naming subsystem also needed in an operating system for a centralized time-sharing
system?If no, explain why.If yes, in what aspects does the naming subsystem of adistributed
operating system differ from that of a centralized time-sharing operating system?
10.2.Differentiate between the terms "location transparency" and"location independency." Which
is a more powerful feature and why?
10.3.Theobject-locating mechanism of a distributed operating system is designed to return the
locations of all the replicas of an object. Suggesta mechanism that can be used in this system
to allow a name agent to find out the relative distances of the replicas from the obtained
locations so that the object-accessing request can be sent to the nearest available replica
location.
10.4.Differentiate betweenhuman-oriented andsystem-oriented names used in operating systems.
Is it possible to design a system in which objects are identified only by their system-oriented
names and there are no human-oriented names for objects? If no, explain why. If yes, explain
whatproblems may occur in such a system.
10.5.What is a name space? For a hierarchically structured name space, discuss the relative
advantages anddisadvantages of using a fixed number of levels and allowing an arbitrary
number of levels for the hierarchy.
10.6.Give anexample of each of the following types of name spaces:
(a) A flat name space having 10 names.
(b) Anonhierarchical name space having four domains with each domain having three
names.
(c) Ahierarchical name space having four domains with each domain having three names.
(d) A name space having two nonnested contexts and four qualified names.
(e) A name space having two contexts and four qualified names. One of the contexts is nested
within the other.
to.7.Give an example of a flat name space having 20 names. Use the following to partition this
name space into contexts such that none ofthecontexts contain more than eight names:
(a) Thealgorithmic clustering method
(b) The syntactic clustering method
Specify the clustering conditions used in each case.Chap. 10 • Exercises 5·59
10.8. The object-locating operation can be greatly simplified if thelocation of an object is
embedded in its unique identifier. In spite ofthisadvantage, why is it undesirable to include
the location of an object in its unique identifier?
10.9. In what ways does the creation ofsystem-oriented names in distributed operating systems
differ from their creationincentralized operating systems? Give three different methods that
may be used to createsystem-oriented names in distributed operating systems.
10.10.Suppose adistributed system uses a single global hierarchical name space for its human­
oriented names. The qualified names in this name space are likely to be long, having too
manycomponent names.Therefore, it may be inconvenient for a user to specify the qualified
name of an object every time he or she wants to use it.Suggesttwo methods that may be
used to solve this problem and discuss the relative advantages anddisadvantages ofboth
methods.
10.11. In what manner will the design of the naming systems of the following types ofdistributed
operating systems differ?
(a) One that does not permit object migration and objectreplication
(b) One that permits object migration but does not permit object replication
(c) One that permits object replication but does not permit object migration
(d) One that permits both migration and replication of objects
10.12.Suppose you have to design an object-locating mechanism for the naming system of a
distributed system. What factors will influence your design decision?
10.13. Which one or more of the object-locating mechanisms discussed in the chapter are suitable
for a naming system for the following types of distributed systems:
(a) ALAN-based system having few nodes
(b) ALAN-based system having a large numberofnodes
(c) A WAN-based system
(d) A system that does not permit object migration and object replication
(e) A system that permits object migration but does not permitobject replication
(f)A system that permits object replication but does not permit object migration
(g) A system that permits both migration and replication of objects
If more than one mechanism is suitable for a particular case, which one will you prefer to
use and why?
10.14.What is a "meta-context"? Is it needed in the design of all naming systems that use name
spacespartitioned into contexts'! If yes, explain why. If no, explain in what type of naming
systems itis needed.
10.15.For adistributed system. suppose you have to design a naming system that uses a single
globalhierarchical name space for its human-oriented names and directories formaintaining
context-binding information. To simplify the design and programming, suppose that you
have decided to separate the part of the nanling system that deals with the management of
directories and toimplement it in the form of a directory server. Specify the set of primitives
that you will provide to allow interaction with the directory server.
10.16.Suppose you have to design a name-caching scheme for a naming system. What are the main
issuesinvolved in the design? What features of the naming system will influence the manner
in which you will handle each of these issues in your design?
10.17.Suppose a user inputs the command open(file_name, mode), where file_name isspecified
asleduluserslsinhalprojectJ /filel.Assume that the naming subsystem of this system uses the
following:S60 Chap.10 •Naming
(a) Table-based strategy for contextbindings
(b)Structure-free distribution ofcontexts
(c)Transitive approach of interaction among name agent and name servers during name
resolution
(d) A full name cache for each processon a node
List all the main steps in sequential orderthat the naming subsystem of theoperating system
has to perform to carry out this command. You may make any otherassumptions if needed,
but state your assumptions.
10.18.Explainthe on-use consistency controlmechanism. In what respect is this mechanism better
thanothercommonly usedmechanisms forcacheconsistency? Can this mechanism be used
tomaintain theconsistency ofall types ofcacheddata? Give reasons for your answer.
10.19. In a distributed system,system-oriented names of objectsare to be used to control access to
objects. That is, in this system, a subjectthatpossesses thesystem-oriented name of an
objectwillbeallowed to access the objectin allpossible modes. An important issue in the
design of this system is that system-oriented names must be hard to guess. Suggestsome
methods that can be used to handle this issue.
10.20. In a distributed system,system-oriented names of objectsare to be used as capabilities for
controlling access toobjects. Think of a method that can beused forcreatingsystem-oriented
names that can also be used as capabilities to grantdifferent accesspermissions todifferent
usersofthe same object.
818UOGRAPHY
[Birrelletal. 1982] Birrell, A. D., Levin, R., Needham, R. M., and Schroeder, M. D.,"Grapevine:
AnExercise inDistributed Computing," Communications ofthe ACM, Vol. 25, No.4,pp.
260-274 (1982).
[Boggs1983] Boggs, D. R.,"Internet Broadcasting," Ph.D.Dissertation, Stanford University,
Technical Report No. CSL-83-3, Palo Alto Research Center(1983).
[Brownbridge et al. 1982] Brownbridge, D. R.,Marshall, L.F.,and Randell, B., "The Newcastle
Connection or UNIXes of the World Unite!"Software Practice and Experience, Vol. 12, No. 12,
pp.1147-1162 (1982).
[CerfandCain1983] Cerf, V.G.,and Cain, E.,"The DoD InternetArchitecture Model,"Computer
Networks, Vol. 7,No.5,pp.307-318 (1983).
[Cheriton andMann1989]Cheriton, D.R.,and Mann, T. P.,"Decentralizing aGlobalNaming
ServiceforImproved Performance and Fault Tolerance," ACM Transactions on Computer
Systems, Vol. 7,No.2,pp.147-183 (1989).
[ComerandMurtagh 1986] Comer, D., and Murtagh, T.P.,"TheTilde File Naming Scheme," In:
Proceedings ofthe 6th International Conference on Distributed Computing Systems, IEEEPress,
NewYork, NY, pp. 509-514 (1986).
(ComerandPeterson 1986]Comer,D.,andPeterson, L. L., "A ModelofNameResolution in
Distributed Systems," In:Proceedings ofthe 6th International Conference on Distributed
Computing Systems, IEEE Press, New York, NY,pp.523-530 (1986).
[Coulouris etal,1994JCoulouris, G. F.,Dollimore, J., and Kindberg, T., Distributed Systems
Concepts and Design, 2nd ed.,Addison-Wesley, Reading, MA (1994).Chap.10 •Bibliography 561
[Goscinski 1991]Goscinski, A.,Distributed Operating Systems, The Logical Design, Addison­
Wesley, Reading, MA(1991).
[Kille1992]Kille,S.,Implementing X.400 and X.SOO:The PP and QUIPUSystems, ArtechHouse,
Norwood, MA(1992).
[Lampson 1986JLampson, B. W.,"Designing aGlobalNameService," In:Proceedings ofthe 5th
AnnualSymposium on Principles ofDistributed Computing, Calgary, Canada, Association for
Computing Machinery, New York, NY, pp. 1-10(August 1986).
[Lantzet al,19851Lantz,K.,Edighoffer, J., andHitson,B.,"Towards aUniversal Directory
Service," In:Proceedings ofthe 4thAnnualSymposium on Principles ofDistributed Computing,
Minaki, Canada, Association forComputing Machinery, New York, NY, pp. 250-260 (August
1985).
[Leachetal,1982]Leach,P.1.,Stump,B.L.,Hamilton, J. A., and Levine,P.H.,"UIDsasInternal
Namesin aDistributed FileSystem,"In:Proceedings ofthe/stAnnualSymposium on Principles
ofDistributed Computing, Ontario, Canada, Association forComputing Machinery, New York,
NY,pp.34-41(August 1982).
[1.Jeachetal,1983]Leach,P.J.,Levine,P.H.,Douros,B.P.,Hamilton, J. A.,Nelson,D.L., and
Stumpf, B. L.,"TheArchitecture of anIntegrated LocalNetwork," IEEE Journal on Selected
Areas in Communication, Vol.SAC-I,No.5,pp.842-857 (1983).
[Leffleret al.1984]Leffler,S.,Karels,M., and McKusick, M.,"Measuring andImproving the
Performance of4.2BSD," In:Proceedings ofthe/984USENIX Summer Conference, USENIX
Association, Berkeley, CA, pp. 237-252 (1984).
[Levy and Silberschatz 1990] Levy, E., and Silberschatz, A.,"Distributed FileSystems: Concepts
andExamples," ACM Computing Surveys, Vol. 22,No.4,pp.321-374 (1990).
[Lin etal,1982]Lin,M.T.,Tsoy,D. P.,andLian, R. C.,"Design of aNetwork Operating System
fortheDistributed Double-Loop Computer Network (DDLCN)," Local Computer Networks,
North-Holland Co., IFIP ()982).
[Lockhart, Jr.1994JLockhart, Jr., H.W.,OSFDeE:Guide to Developing Distributed
Applications, IEEEComputer SocietyPress,LosAlamitos, CA(1994).
[Mockapetris 1984]Mockapetris, P. Y.,"TheDomain NameSystem," In:Proceedings IFIP 6.5,
International Symposium on Computer Messaging, Nottingham, England (May 1984).
[Mockapetris andDunlap 1988]Mockapetris, P. V., and Dunlap, K.1.,"Development ofthe
Domain NameSystem," In:Proceedings oftheSIGCOMM'88 Symposium on Communications
Architectures and Protocols, Stanford, CA,Association forComputing Machinery, New York,
NY,pp. ]23--133(]988).
[Mogul1986]Mogul,J.C.,"Representing Information AboutFiles,"Ph.D.Dissertation, Stanford
University, Computer ScienceTechnical Report,STAN-CS-86-1103 (March1986).
[Mullender andTanenbaum 1986]Mullender, S.J.,andTanenbaum, A.S.,"TheDesignofa
Capability BasedDistributed Operating System," The Computer Journal, Vol.29,No.4,pp.
289-300 (1986).
[Mullender etal,1990]Mullender, S.1.,VanRossurn,G., Tanenbaum, A. S., Van Renesse,R.,and
VanStaverene, H.,"Amoeba: ADistributed Operating Systemfor the1990s,"IEEE Computer,
Vol.23,No.5,pp.44-53(1990).562 Chap. 10 • Naming
[Needham 1993]Needham,R.M.,"Names," In:S. Mullender(Ed.), Distributed Systems, 2nded.,
Association for ComputingMachinery,New York,NY,pp.315-327 (1993).
[OppenandDalal 1983] Oppen, D. C.,and Dalal, Y.K.,"The Clearinghouse:A Decentralized
Agent for LocatingNamedObjects ina DistributedEnvironment," ACMTransactions on Office
Information Systems, Vol.1,No.3,pp.230-253 (1983).
[Peterson 1988] Peterson, L., "The Profile Naming Service," ACM Transactions on Computer
Systems, Vol.6,No.4,pp.341-364 (1988).
[Rashid1987]Rashid,R. F.,"Mach:ANewFoundationforMultiprocessorSystemsDevelopment,"
In:Proceedings ofCOMPCON'87-Digest ofPapers,IEEE Press,NewYork,NY,pp. 192-193
(1987).
[Rose1992] Rose, M. T., The Little Black Book: Mail Bonding with OSI Directory Services,
Prentice-Hall,EnglewoodCliffs, NJ (1992).
[Rosenberry et al. 1992] Rosenberry, W.,Kenney, D.,and Fisher, G., OSF DISTRIBUTED
COMPUTING ENVIRONMENT, Understanding DCE, O'Reilly&Associates, Sebastopol, CA
(1992).
[Rozieret al, 1988)Rozier,M.,Abrossimov, V.,Armand,F.,Boule, I.,Gien, M., Guillemont,M.,
Herrmann, F., Kaiser, C., Leonard, P, Langlois, S., and Neuhauser, W., "Chorus Distributed
Operating System," Computing Systems, Vol.1,pp.305-379 (1988).
[Saltzer 1982J Saltzer, 1. H.,"On the Naming and Binding of Network Destinations," In:
Proceedings ofIFIPffC6 International Symposium on Local Computer Networks, Florence,Italy,
pp. 311-317 (April 1982).
[Sandberg etale1985]Sandberg, R.,Goldberg, D., Kleinman, S., Walsh, D., and Lyon, B.,"Design
and Implementation of the SUN Network File System," In:Proceedings ofthe USENIX
Conference, Portland,OR, USENIXAssociation,Berkeley,CA, pp. 119-130 (1985).
[Schantz et al, 1986]Schantz,R.E.,Thomas,R.H.,andBono,G.,"TheArchitectureof theCronus
Distributed Operating System," In:Proceedings ofthe 6th International Conference on
Distributed Computing Systems, IEEE Press, New York,NY,pp.250-259 (1986).
[Schickler 1982JSchickler, P.,"NamingandAddressinginaComputerBasedMail Environment,"
IEEE Transactions on Communications, Vol.COM-30, No.1(1982).
(Schroeder etal,1984] Schroeder, R.,Birrell, A. D., and Needham, R.M., "Experience with
Grapevine:TheGrowthof aDistributed System," ACMTransactionson Computer Systems, Vol.
2,No.1,pp.3-23(1984).
[Schwartz et al, 1987]Schwartz, M.,Zahorjan, 1.,andNotkin,D.,"A NameService for Evolving
Heterogeneous Systems," In:Proceedings ofthe 11thACM Symposium on Operating Systems
Principles, Association for Computing Machinery, New York,NY,pp.52-62(November
1987).
[Sheltzer etal.1986]Sheltzer,A. B.,Lindell,R.,and Popek, G.1., "Name Service Locality and
Cache Design in a Distributed Operating System," In:Proceedings ofthe 6th International
Conference on Distributed Computing Systems, IEEE Press, New York,NY, pp. 515-522
(1986).
[Silberschatz andGalvin 1994]Silberschatz,A., and Galvin, P.B., Operating Systems, Concepts,
4th ed.,Addison-Wesley, Reading, MA (1994).Chap. 10 • Bibliography 563
[Sinhaet al, 1991a] Sinha,P.K.,Maekawa, M.,Shimizu,K.,Jia,X.,Ashihara, H.,Utsunomiya, N.,
Park,K.S., and Nakano, H.,"The GalaxyDistributedOperatingSystem," IEEE Computer, Vol.
24,No.8,pp. 34-41 (1991).
[Sinhaet al,1991b]Sinha,P. K.,Shimizu, K.,Utsunomiya,N., Nakano, H.,and Maekawa, M.,
"Network Transparent Object Naming and Locating in the Galaxy Distributed Operating
System," JournalofInformation Processing, Vol.14,No.3,pp.310-324 (1991).
[Sinhaet al.1992]Sinha,P.K.,Mackawa, M.,and Shimizu, K.,"Improving the Reliability of
Name Resolution Mechanism in Distributed Operating Systems," In: Proceedings ofthe 12th
International Conference onDistributed Computing Systems, Yokohama, Japan, pp. 589-596
(June1992).
[SuandPostel1982]Su,Z.,and Postel, 1.,"The Domain Naming Conventionfor Internet User
Applications," Network InformationCenter,SRI International, RFC 819 (August 1982).
[Terry1984]Terry,D. B.,"An Analysis of Naming Conventions for Distributed Computer
Systems," In: Proceedings ofthe 6th International Conference onDistributed Computing
Systems,IEEE Press, New York,NY,pp.502-508 (1984).
[Terry1986]Terry, D. B., "Structure-Free Name Management for Evolving Distributed
Environments,"In: Proceedings oftheA(:MSIGCOMM'84, Montreal,Quebec,Associationfor
Computing Machinery, New York, NY, pp.218-224 (June1986).
[TichyandRuan1984]Tichy,W. F.,and Ruan, Z.,"Towards aDistributed File System," In:
Proceedings of/heSummerUSENIX Conference, IJSENIXAssociation,Berkeley,CA,pp. 87-97
(June 1984).
[Tripathi etal,1987]Tripathi, A.,Ghonami, A.,and Schmitz, T.,"Object Management in the
NEXUS DistributedOperating System," In:Proceedings ofJEJ!.ECOMPCON'87, IEEEPress,
NewYork,NY,pp.50-53(February 1987).
[Walker etal.19831Walker,B.,Popek,G.,English, R.,Kline,C.,and Thiel, G.,HTheLOCUS
Distributed Operating System," In: Proceedings ofthe 9th ACM SIGOPS Symposium on
Operating SystemsPrinciples, Association forComputing Machinery, New York, NY, pp. 49-70
(1983).
[Watson 1981]Watson,R.,"Identifiers (Naming)in DistributedSystems,"In: B. W.Lampson,M.
Paul, and H.Siegert(Eds.),Lecture Notes in Computing Science: Distributed !iystems­
Architecture andImplementation, Springer-Verlag, NewYork,NY,pp.191-210 (1981).
[WelchandOusterhout 1986]Welch,B., andOusterhout, J. K.,"Prefix Tables: A Simple
Mechanism forLocatingFilesina DistributedSystem,"In: Proceedings ofthe 6thInternational
Conference onDistributed Computing Systems, IEEE Computer Society Press, Los Alamitos,
CA,pp. 184-189 (1986).
[Wiebe 1986JWiebe, D., "A Distributed Repository for Immutable Persistent Objects," In:
Proceedings ofoOPSLA'86,AssociationforComputingMachinery,New York,NY,pp.453-465
(1986).
POINTERS TOBIBLIOGRAPHIES ONTHEINTERNET
I could not find a bibliography dedicated only to Naming. However, the following
bibliographies contain references on the topics covered in this chapter:564
ftp:ftp.cs.umanitoba.calpub/bibliographies/Os/lMMD_IV.html
ftp:ftp.cs.umanitoba.calpub/bibliographieslMisc/misc.l.htmI
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedlrfc.htmlChap.10 •NamingCHAPTER11
Security
11.1 INTRODUOION
Computer systems store large amounts of information, some of which is highly
sensitive and valuable to their users. Users can trust the system and rely on it only if
the various resources and information of a computer system are protected against
destruction and unauthorized access. Obviously, the security requirements are different
for different computer systems depending on the environment in which they are
supposed to operate. For example, security requirements for systems meant to operate
in a military environment are different from those for systems that are meant to
operate in an educational environment. The security goals of a computer system are
decided by its security policies, and the methods used to achieve these goals are called
security mechanisms. While designing the security of a system, it is often useful to
distinguish between security policies and security mechanisms because security
policies can be decided independent of the available technology but security mecha­
nisms are influenced by the available technology. It may be difficult to implement the
desired security policies with a selected set of security mechanisms. But new security
mechanisms can be later added to the set to implement the desired security
policies.
565S66 Chap.11•Security
Irrespective of the operation environment, some of the common goals of computer
security are as follows [Mullender 1985]:
1. Secrecy. Information within the system must be accessible only to authorized
users.
2. Privacy. Misuse of information must be prevented. That is, a piece of information
given to a user should be used only for the purpose for which itwas given.
3. Authenticity. When a user receives some data, the user must be able to verify its
authenticity. That is, thedata arrived indeed fromits expected sender and not from
any other source.
4. Integrity. Information within the system must be protected against accidental
destruction or intentional corruption by an unauthorized user.
A total approach to computer security involves both external and internal
security. External security deals with securing the computer system against external
factors such as fires, floods, earthquakes, stolen disks/tapes, leaking out of stored
information by a person who has access to the information, and so on. For external
security, the commonly used methods include maintaining adequate backup copies of
stored information at places far away from the original information, using security guards
to allow theentry of only authorized persons into the computer center, allowing the access
to sensitive information to only trusted employees/users, and so on.
Internal security, on the other hand, mainly deals with the following two aspects:
1. User authentication. Once a user is allowed physical access to the computer
facility, the user'sidentification must be checked by the system before the user can
actually use the facility.
2. Access control. A computer system contains many resources and several types of
information. Obviously, not all resources and information are meant for all users.
Therefore, even when a user passes the authentication phase and is allowed to use the
computer facility, a way is needed to prohibit the user from accessing those resources/
information that he or she is not authorized toaccess. In fact, a secure system requires that
atany time a subject (person orprogram) should beallowed toaccess only those resources
that it currently needs to complete its task. This requirement is commonly referred to as
theneed-to-know principle or theprincipleofleast privilege.
We saw that the security needs of a computer system are intricately linked with that
system's environment, use, and implementation. Therefore, in addition to the two aspects
mentioned above, internal security in distributed systems has a third aspect called
communication security.
3. Communication security. In a distributed system, the communication channels
that are used to connect the computers are normally exposed to attackers who may try to
breach the security of the system by observing, modifying, or disrupting the
communications. Wireless networks are even more vulnerable to monitoring by intrudersSec.11.2•PotentialAttackstoComputer Systems 567
because anyone with a scanner can pluck the radio signals out of the air without being
detected. Communication security safeguards against unauthorized tampering of informa­
tion while it is being transmitted from one computer toanother through the
communication channels. Two other aspects of communication security are authenticity of
communicating entitiesandintegrityofmessages. That is, the senderof a message wants
to know that the message was received bythe intended receiver, and the receiver wants
to know that the message was sent by the genuine sender. Obviously, both the sender and
thereceiveralso want to be guaranteed that the contents of the message were not changed
while it was in transfer.
Providing both external and internal security is more difficult in distributed systems
than incentralized systems because of the lack of a single point ofcontrol and the use of
insecure networks for data communication. Although external security is as important as
internal security, the policies and mechanisms used at the operating system level for
computer security deal only with the internal security aspects. Therefore, this chapter
deals mainly with the commonly used mechanisms for providing different types of
internal security in distributed systems.
11.2POTENTIAL ATTACKSTOCOMPUTER SYSTEMS
The first step in the provision of appropriate computer security is to identify the
potential threats/attacks tocomputer systems. The term intruder orattacker is
commonly used to refer to a person or program trying to obtain unauthorized access
to data or a resource of a computer system. An intruder maybe a threat to computer
security in many ways that are broadly classified into two categories-passive attacks
and active attacks. A passiveattackdoes not cause any harm to the system being
threatened, whereas an activeattackdoes. Therefore, passive attacks are inherently
undetectable by the system and can only be dealt with by using preventive measures.
On the other hand, active attacks are combated by a combination of prevention,
detection, and recovery techniques. A description of these attacks and some other
related problems are presented below.
11.2.1PassiveAttacks
In passive attacks, an intruder somehow tries to steal unauthorized information from the
computer system without interfering with the normal functioning of the system. Some
commonly used methods of passive attack are described below:
1.Browsing. In this method, intruders attempt to read stored files, message packets
passing by on the network, other processes' memory, and so on, without modifying any
data. Access control mechanisms are used to prevent unauthorized reading of stored files
and other processes' memory contents, and message encryption is used to prevent
eavesdropping of messages transmitted over network links.568 Chap.11•Security
2.Leaking. In thismethod,anintruderuses anaccomplice (alegitimate user having
authority toaccesstheinformation tobestolen)who leaks the information to him or her.
Prevention ofleakingis adifficultproblem to solve and requirespreventing all types of
communication between theaccomplice and the intruder. The problemofensuring that it
isimpossible for apotential accomplice to leak any information to theoutsideworld is
calledtheconfinement problem [Lampson 1973]. As described later,leakingof
information between processes that in theory cannotcommunicate at all is relatively
straightforward. Therefore, theconfinement problem is in general unsolvable.
3.Inferencing, In this method, an intrudertries to draw some inference byclosely
observing andanalyzing thesystem's dataor theactivities carriedout by the system.For
example, ifinformation isencrypted toprotectunauthorized access, an intrudermay try
toderivetheencryption key byanalyzing severalpiecesofencrypted data. Since the
derivedkey can be used for stealinginformation from the system, it is valuable and may
be sold to otherintruders. Anotherexampleofinferencing is traffic analysisindistributed
systems. In this case, an intruderobserves when and where interprocess messages flow in
thesystem,and byanalyzing thefrequency ofmessage exchanges between various
communicating partners, theintruder tries to draw some inference. Forexample, in a
business environment, trafficanalysis mayprovideuseful clues to negotiations taking
placebetween different organizations.
4.Masquerading. In this method, an intruder masquerades as anauthorized user
orprogram inorderto gain access to unauthorized data orresources. Forinstance,
manysystemshavemechanisms for alJowing programs written by users to be used by
otherusers.Theseprograms canimproperly use the access rights ofanexecuting user
and leak information. Forexample, anintrudermay write an editorprogram that works
perfectly as aneditorbut also createsa copyoftheeditedfile to a special area
accessible to the intruder. This editorprogram is thencompiled and read into the bin
directory ofa user, whose files the intruderisinterested in. From then on, the intruder
gets acopyofall the files editedby the user. The user is ignorant ofthe theft being
madebecause theeditorprogram performs all his or her editingjobsin aperfectly
normalfashion.
Penetrating computer securityin thismanneris known as the Trojan horse attack.
Thatis, aTrojan horse program is aprogram thatconsistsofclandestine codeto do
nasty things in addition to its usual function but appearsto be benign. It is often offered
as a gift or sometimes for anominal price topreventsuspicion. A usernormally accepts
it into his or her system becauseofthe useful function performed by it.However, once
insidetheuser'scomputer, codehiddenin theprogram becomes activeandeither
executes malicious acts or createsa wayofsubverting systemsecurity so that
unauthorized personnel can gain accessto thesystemresources. Note that a Trojan
horseattackmayeitherbepassiveor active depending on theactivities performed by
theclandestine code. For example, if theclandestine code simply steals information,
then it is ofthepassivetype. But ifit doessomething moreharmful likedestroying/
corrupting files, then it is ofthe active type.
Anintrudercan also masquerade as a trusted serverto aclientrequesting a service
from the system.This action is knownasspoofing.Sec. 11.2 • Potential Attacks to Computer Systems
11.1.1 Actlv. Attacks569
Activeintruders are more malicious than passive intruders. Unlike passiveattacks, active
attacksinterfere with the normal functioning of the system and often have damaging
effects. The most common types of damage that active attacks cause are corrupting files,
destroying data,imitating hardware errors, slowing down the system, filling up memory
or disk space with garbage, causingthe system to crash, confounding areceiver into
accepting fabricated messages, anddenial/delay ofmessage delivery. Some commonly
used forms of active attacks are described below. In the following, the description of
viruses, worms, and logic bombs is based on the material presented in [Bowles and Pelaez
1992].
Viruses
Acomputer virusis a piece of code attached to a legitimate program that, when executed,
infectsotherprograms in the system by replicating andattaching itselfto them. In addition
to thisreplicating effect, a virus normally does some other damageto the system, such as
corrupting/erasing files.Therefore, due to its spreading nature, a virus can cause severe
damage to a system. Notice that virus attacks are active-type Trojan horse attacks.
A typical virus works as follows. The intruderwrites a new program that performs
someinteresting or useful function (such assomegame or utility) andattaches the virus toit
insuch a way that when the program isexecuted the viral code also gets executed. The
intrudernow uploads this infectedprogram to a public bulletin board system or sends it by
mail toother users of the system oroffers itforfree or for anominal charge onfloppy disks.
Now if anyone uses the infectedprogram, its viral code gets executed. When the viral code
oftheinfectedprogramexecutes,itrandomly selects an executable fileonthe hard disk and
checks to see ifitis already infected. Most viruses include astring of characters that acts as
amarkershowingthat theprogram has been infected. Ifthe selectedfileisalready infected,
the virus selects anotherexecutable file. When an uninfected program is found, the virus
infects it by attaching a copy of itselfto the end of that program and replacing the first
instruction of theprogram with ajumpto the viral code. When the viral code is finished
executing, itexecutes theinstruction that hadpreviously been first and then jumpsto the
secondinstruction so that the program nowperforms itsintended function. Notice that a
virus spreads becauseevery time an infected program isexecuted, it tries to infect more
programs. Also notice that avirus does not infect an already infectedfile inordertoprevent
anobjectfile from growing ever longer. This allows the virus to infect many programs
withoutnoticeably increasing disk space usage.
Recovery from a virus infection is a difficult task that often requires partial or
complete shutdown for long periods of time of the computer system under attack.
Therefore, it is always better to take necessary precautions topreventvirus problems.
Someprecautionary steps include (a) buying software only from respectable stores, (b)
refusing toacceptsoftware inunsealed packages or from untrusted sources, (c) avoiding
borrowing programs fromsomeone whose security standards are less rigorous than one's
own, and (d) avoiding uploading of freesoftware from public domain, bulletin boards, and
programs sent byelectronic mail.570 Chap.11•Security
When acomputer system suffers from virus infection, ithas to becured. The simplest
way to cure a computer from virus infection is to shut it down, purge its memory and all
its disks, and rebuild its files from scratch using the original manufacturer's copy.
Disinfection utilities may also be used to cure a computer from virus infection. These
utilities first identify the virus type with which the computer is infected by matching its
markeragainstthe markers ofwell-known viruses. Once the type is known, the original
programs are restored from their infectedversions by applying adetailed knowledge ofthe
infection method used by the virus. For example, in viruses that modify jumpinstructions
at thebeginning of the host program, recovering can be done simply by restoring the
originaljumpto the start ofthe host program code. However, notice that these disinfection
utilities can only cure specific known viruses. They cannot cure a newly encountered type
ofvirus. A good disinfection utility can normally cure several hundred types of viruses
and itspowercan be regularly improved by frequently updating it as new viruses are
discovered.
Notice that the longer a virus remains in a system, the more time it has to spread and
thetougherrecovery from it becomes. Therefore, it is important to detect a virus as soon
as possible. An effective method todetect viruses is to use a snapshot program and acheck
routine. The snapshot program is used to log all critical system information at the time of
the initial installation and the check routine is periodically executed to compare the
system's current state with the original snapshot. If signs of infection are detected, the
affected area of the computer is identified and the user is notified.
Curingadistributed system from virus infection is much more difficult because ifthe
infection is not removed from every workstation at the same time, reinfection will occur.
This is because an infected file on the network server can infect every workstation on the
network.
Worms
Worms are programs that spread from one computer to another ina network of computers.
Theyspreadby taking advantage ofthe way in which resources are shared on a computer
network and, in some cases, by exploiting flaws in the standard software installed on
network systems. A worm program may perform destructive activities after arrival at a
network node. Even when not directly destructive, worms often cripple a network by
subverting the operation of computers on the network to their own purposes,
monopolizing their resources, and saturating the communications links in a network.
Often, it is necessary to shut down the entire system (all computers of the network) to
recoverfrom a worm problem.
Toillustrate how a worm propagates in a network, the famous Internet Worm attack
byaCornellgraduate student, Robert Tappan Morris, on November 2, 1988, that infected
thousands ofUNIX machines all over the Internet is described here. This worm program
had two types of code, the bootstrap code and the code forming the main body of the
worm. The bootstrap code was compiled andexecuted on the system under attack. When
executed, the bootstrap code established acommunications link between its new host and
themachine from which it came, copied the main body of the worm to the new host, and
executed it.Once installed on a new host, the worm'sfirst few actions were to hide itsSec.11.2•PotentialAttackstoComputer Systems 571
existence. Forthis,itunlinked thebinaryversionofitself,killeditsparentprocess, read
its filesintomemory andencrypted them,anddeletedthe filescreatedduringitsentryinto
thesystem.Afterfinishing itshidingoperations, theworm'snextjobwas tolookintoits
host'sroutingtablestocollectinformation aboutotherhoststowhichitscurrenthostwas
connected. Usingthisinformation, it thenattempted tospreaditsbootstrap codetothose
machines bytryingthefollowing threemethods one by one:
1.Thefirstmethodwas to try to spawnaremoteshell on the targetmachine using
thershcommand ofUNIX.Thismethodsometimes worksbecause somemachines trust
othermachines andwillingly runrshwithout authenticating theremotemachine. If
successful, theremoteshelluploaded thewormprogram on thetargetmachine and
continued spreading to newmachines from there.
2.If the first method failed, the secondmethod was tried. Thismethod took
advantage ofa bug in the fingerprogram that runs as a daemonprocessateveryBSDsite.
Auseranywhere on theInternetcantype
toobtaingeneralinformation aboutapersonat aparticular site, such as the person's real
name,homeaddress, officeaddress, telephone number, and so on. Thefingerutilityuses
theClibraryfunction getsto read input data. Aproblem withgetsis that itreadstheentire
inputstringwithout checking forbufferoverflows. Thewormexploited this flaw and
calledfingerwith aspecially constructed 536-byte stringas aparameter. Theoverflow
causedan areaofthesystemstackto beoverwritten, allowing thewormto put its own
suitableinstructions (aprocedure toexecuteIbinlsh)on thestack.Nowwhen the finger
daemon returned fromtheprocedure it was in at the time it got the request,itreturned to
andexecuted theprocedure inside the 536-byte string on the stack instead ofreturning to
main.If thismethodsucceeded, thewormhad ashellrunningon thetargetmachine.
3.Ifthe first two methods failed,thewormtrieda thirdmethodthattakesadvantage
ofaloophole in theUNIXelectronic mailutilitysendmail. Thesendmail program has a
DEBUG option,whichallowsprogram testersto verify that mail has arrivedat a site
withouthavingtoinvokethemailer's addressresolution routines. Manyvendorsand site
administrators leavethedebugoptioncompiled intothesendmail codetofacilitate
configuring themailerforlocalconditions. Whatthewormdid was to execute the
sendmail program withtheDEBUG optionand then enactasequence ofcommands to
mail the bootstrap codeto thetargetmachine.
Onceestablished on a new machine, thewormtriedtobreakintouseraccounts by
exploiting theaccessibility oftheUNIXpassword fileandthetendency ofusers tochoose
common wordsastheirpasswords. Eachbrokenpassword allowed thewormto
masquerade as theusercorresponding to thatpassword andgainaccessto anyremote
machine wherethatuserhad anaccount.
Thewormwasdesigned to actintelligently topreventbeingspotted. Itperiodically
forkeditselfandkilleditsparent,so that its processID wasconstantly changing. This572 Chap. II • Security
prevented anyoneprocess from accumulating a large amount of CPU time that might
create suspicion or cause its scheduling priority to be degraded. Furthermore, after every
12 hours, the worm erased its record of the machines it had infected, so that already
infected hosts were put back on the list of potential targets. Whenever the worm gained
access to a new machine, it first checked to see ifthe machine already had a copy of the
worm. If so, the new copy exited, except one time in seven. The use of one in seven
possibly was to allow the worm to spread even on a machine on which the system
administrator might have started its own version of the worm to fool the real worm.
Although viruses and worms both replicate and spread themselves, the two differ in
the following aspects:
1. A virus is a program fragment whereas a worm is a complete program in itself.
2. Since a virus is a program fragment, it does not exist independently. It resides in
a host program, runs only when the host program runs, and depends on the host
program for its existence. On the other hand, a worm can exist and execute
independently.
3. A virus spreads from one program to another whereas a worm spreads from one
computer to another in a network.
LogicBombs
A logic bomb is a program that lies dormant until some trigger condition causes it to
explode.Onexplosion, it destroys data and spoils system software of the host computer.
A trigger condition may bean event such as accessing a particular data file, a program
being run a certain number of times, the passage of a given amount oftime, or the system
clock reaching some specific date (for instance, Friday the 13thorApril Fool'sDay). The
trigger condition isnormally selected sothat thelogic bombexplodes atthemoment when
it can do maximum damage to the system. Logic bombs can be embedded in a Trojan
horse or carried about by a virus.
ActiveAttacksAssociated with Message
Communications
In a distributed system, communication channels are used to carry information from one
node to another in the system in the form of messages. These communication channels
may be exposed to attackers who may try to breach the security of the system by
observing, modifying, deleting, inserting, delaying, redirecting, or replaying the messages
that travel through the communication channels. The commonly known active attacks
associated with message communications are of the following types:
1. Integrity attack. For secure communication, the integrity requirement specifies
that every message is received exactly as it was sent or a discrepancy is detected.
However, an intruder may change the contents of a message while itis traveling through
acommunication channel and the receiver may not be aware of this and accept itas the
original message.Sec.11.2•PotentialAttacksto Computer Systems 573
2.Authenticity attack.An intruder may illegally connect his or her own computer
system to a communication channel and impersonate alegal network site.The intruder can
then synthesize and insert bogus messages with valid addresses into the system so that
they are delivered as genuine messages. If an integrity attack is possible, an intruder may
also cause an authenticity attack by changing the protocol control information (addresses)
of the messages so that they are delivered to wrong destinations.
3.Denialattack.In this case, the intruder either completely blocks the communica­
tion path between two processes so that the two processes cannot communicate at all or
observes all messages exchanged between the two processes and prevents only selected
messages from delivery. That is, the intruder causes complete or partial denial of message
delivery.
4.Delayattack.Several messages have time value. Therefore, instead of using a
denial attack, an intruder may simply delay the delivery of message passing in an
association between two communicating processes to fulfill his or her motive.
5.Replayattack.In this case, an intruder retransmits old messages that are accepted
as new messages by their recipients.
Cryptography deals with the encryption of sensitive data to prevent its comprehen­
sion and is the only practical means for protecting information sent over an insecure
channel, be ittelephone line, microwave, satellite, or any other transmission media. This
is because an encrypted message provides no information regarding the original message,
hence guaranteeing secrecy; and an encrypted message, if tampered with, would not
decrypt into a legal message, hence guaranteeing integrity. Cryptography can also be used
for secure identification of communicating entities, hence guaranteeing authenticity.
Furthermore, encryption, inconjunction with protocols, can also beused toprevent denial,
delay, and replay of messages. For instance, replay of old messages can be countered by
using nonces or timestamps. A nonceis an information that is guaranteed to be fresh; that
is, it has not been used or appeared before. Therefore, a reply that contains some function
of a recently sent nonce should be considered timely because the reply could have been
generated only after the nonce was sent. Perfect random numbers are suitable for use as
nonces. In summary, the only way to prevent attacks associated with message
communications is by the application of cryptographic techniques.
In aclient-server model, a single server program may be shared by multiple clients. In
situations where programs are shared, a security problem is considerably more complex
than if only data objects are shared. One reason that we have already seen is a Trojan
horse. A Trojan horse is justone way in which a shared program could leak classified
information to other unclassified subjects. There may be several other ways in which a
shared program could leak confidential information to unauthorized subjects.
A program that cannot retain or leak confidential information is said to be
memorylessorconfined, and the prevention of such leakage is called the confinement574 Chap. II • Security
problem [Lampson 1973]. That is, the confinement problem deals with the problem of
eliminating every means by which an authorized subject can release any information
contained in the object to which it has access to some subjects that are not authorized to
access that information. According to Lampson, as long as a program does not have to
retain or output any information, confinement can be implemented by restricting the
access rights of the program. But if a program must retain or output information, access
control alone is not sufficient to ensure security.
Lampson identified the following kinds of channels that can be used by a program to
leak information:
1. Legitimate channels. Legitimate channels are those that the program uses to
convey the results of its computation, such as messages or printed output. The program
may hide additional information in these channels along withthe actual result. Some form
of encoding that is meaningful to the person or process receiving the result is used to
convey the additional information. For example, in a printed output, two different space
lengths that are not discernible to normal persons but visible if observed minutely may be
used between words to mean 0 and 1 bits. This type of printed output can be used to
convey additional information to a person who knows about the hidden bits between two
words.
2. Storage channels. Storage channels are those that utilize system storage such as
shared variables or files to leak information to other processes. Notice that when a
process(A)wants to leak information to another process (B)by using a storage
channel, it is not necessary that both processes must have access rights to the shared
object. For example, if the system provides a way of locking files, process Acan lock
some file to indicate a 1 and unlock it to indicate a O.It may be possible for process
Bto detect the status of a lock even on a file that Bcannot access. Similarly, in UNIX,
processAcould create a file to indicate a 1 and remove it to indicate a O.Even though
processBhas no permission to access the file created by A,it can use the accesssystem
call to see if the file exists.
3. Covert channels. Covert channels are paths that are not normally intended for
information transferat all but could beused to send some information. For example, a
process may use one of the following methods to leak information to some other process
that is carefully monitoring its activities [Tanenbaum 1992]:
• Bymodulating paging rate. For example, during a fixed time period, many page
faults caused bytheprocess may beused toconvey a l, and nopage faults fora O.
• Bymodulating CPU usage. For example, usage of CPUfor a fixed time period by
the process may be used to convey a l, and sleeping of the process for the same
period may be used to convey a O.
• Byacquiring and releasing dedicated resources. For example, the process may
acquire the resource to convey a 1 and release it to convey a O.
To solve the confinement problem, it is important to block all channels that a
program may use to communicate with other processes. However, finding all suchSec.11.3•Cryptography S7S
channels and trying to block them is extremely difficult. In practice, there is little that can
be done. Therefore, theconfinement problem is in general unsolvable.
11.3CRYPTOGRAPHY
Cryptography is a means of protecting privateinformation againstunauthorized access in
thosesituations where it is difficult to provide physical security. The basic idea behind this
securitytechnique is that if it is not. possibletopreventcopyingofinformation, it is better
toprevent comprehension.
11.3.18aslcConcepts andTerminologies
Two primitive operations employed bycryptography areencryption anddecryption.
Encryption (also called enciphering) is the process of transforming anintelligible
information (calledplaintext orcleartext) into anunintelligible form (called ciphertext).
Decryption (also called deciphering) is the process oftransforming theinformation back
fromciphertext to plaintext. When cryptography isemployed forprotecting information
transmitted throughcommunication channels, plaintext is also called a message.
Encryption isbasically amathematical function (encryption algorithm) having the
following form:
wherePis theplaintext to beencrypted, K,is anencryption key, and C is the resulting
ciphertext. Decryption of C isperformed by a matching function (decryption algorithm)
that has the following form:
P=D(C, Kd)
whereKdis thedecryption key. Note that the decryption functionDis the inverse of the
encryption function E.Therefore we have
To prevent the plaintext from being easily revealed, it must be possible to transform
a given plaintext into a large variety of possible ciphertexts selected by a specific
parameter. The keys K,andKdserve as this parameter. That is, the function parts remain
the same but the keys are changed as often as necessary.
The above described general structure of a cryptosystem is illustrated with an
example in Figure 11.1,where a message is encrypted for secure transmission over an
insecure channel from a sendernode to a receivernode.
11.3.2SasieRequirements
To bepractically useful, a cryptosystem must fulfill the following basic requirements:
I. It must be easy to use and its encryption anddecryption algorithms should be
efficient forcomputer application.576 Chap.11•Security
SendernodeCiphertext•
Insecure
channel
Receivernode
Fig. 11.1 General structure of a cryptosystem.
2. There are two methods to achieve security. In the first method, the encryption
algorithm is kept secret and is rather complex to make it difficult to guess. In the second
method, the encryption algorithm is made public but the keys are kept secret and they are
long enough to make it practically impossible to guess a key. The second method is
preferred for practically useful systems. That is, the security of the system should depend
only on the secrecy of the keys and not on the secrecy of the algorithms.
3. The system must be computationally (practically) secure. That is, the determina­
tion ofKdmust becomputationally infeasible for an attacker (also called a cryptanalyst).
Note that the strength of a cryptosystem is measured by the level of difficulty (usually
measured either by the time or number of elementary operations) of determining Kd.
Depending on the amount of information available to an intruder, in a cryptosystem,
attacks are mainly of three types-ciphertext only, known plaintext, and chosen plaintext
[Bright 1977].
Inciphertext-only attack, an intruder is able to intercept ciphertext and tries to derive
Kdfrom the ciphertext. A system whose security is not resistant to a ciphertext-only attack
isconsidered to be totally insecure and is useless.
Inknown-plaintext attack, ailintruder has considerable amount of both ciphertext and
corresponding plaintext and tries to derive Kdfrom them. A system that can resist a
known-plaintext attack is considered to be secure.
Inchosen-plaintext attack, an intruder has access to ciphertext forany plaintext of his
or her choice. The intruder tries to derive Kdby examining several ciphertexts for the
carefully thought plaintexts of his or her choice. It is most appropriate nowadays to
evaluatecryptosystems by their ability to withstand chosen-plaintext attacks.
Anotherimportant way by which a cryptosystem is demonstrated to besecure is the
testoftime.Ifno known successful attacks have been reported since a system is published
and in use for a significant amount of time (measured in years), the cryptosystem is
considered to probably provide pretty good security.
11.3.3Symmetric andAsymmetric Cryptosyst.ms
There are two broad classes of cryptosystems, symmetric and asymmetric. In a symmetric
cryptosystem, either both the encryption key (Ke)and decryption key (Kd)are the same or
one is easily derivable from the other. Usually, a common key (K)is used for bothSec. 11.3 • Cryptography 577
enciphering and deciphering. Forsecurity,it is important that the key of a symmetric
cryptosystembeeasilyalterableandmustalwaysbekeptsecret.Thisimpliesthatthekey
isknownonlytoauthorizedusers.Symmetriccryptosystems arealsoknownas shared-key
orprivate-key cryptosystems.
Symmetriccryptosystemsare useful in those situationswhere both encryptionand
decryption of information are performed by a trusted subsystem. For example, a
password-baseduserauthenticationsystemmayuse this schemefor savingpasswordsin
encrypted form. When a user declares a password, the operating system uses theencryption key for encrypting the password before storing it internally. At the time of
authentication, the operating system again uses the same key to decrypt the stored
passwordto compareit to the passwordsuppliedby the
user.
In anasymmetric cryptosystem, on the other hand, the decryptionkey (Kd)is not
equal to the encryption key (Ke) .Furthermore, it is computationally impractical to
deriveKdfromKe.Because of this property, onlyKdneeds to be kept secret and K,
is made publicly known. Asymmetric cryptosystems are also known as public-key
cryptosystems.
Public-keycryptosystemsarc computationally expensiveand henceare not suitable
forbulkdataencryption. Atypicaluseofapublic ..keycryptosystemindistributedsystems
is for establishing connection between two communicating entities (AandB)for the
exchangeofmessagesusingasymmetric cryptosystem. Letussuppose thatAandBwant
to establish a connection between themselves for initiating message transfersusing a.
symmetriccryptosystemwhosekey is K.Notethat it isinsecureto sendthe key Kover
a normalcommunicationchannel for the purposeof sharing it with AandB.Therefore,
apublic-keycryptosystemis first usedto establisha connectionbetween AandBin the
following manner:
• Entity Aposts the encryption key (Ke)of a public-key cryptosystem on, say,an
electronic bulletinboard,sothatitisobtainable byB.
• Entity BusesA'spublickey to encryptthe key Kand transmitsit to A.
• Entity Adecrypts B'smessage using the decryption key (Kd)of the public-key
cryptosystem. OnlyAcan decrypt this message because Kdis available only
withA.
• Now that Aalso has the key K,bothAandBcan safelycommunicatewitheach
other using the symmetriccryptosystemscheme.Any eavesdropperwould only
havethepublickey (Ke),theencryptedformof key K,andtheencryptedformof
the messagesbeingcommunicatedbetween AandB.
One pitfall here is that someone else could masquerade as AorB.This can be
overcomeby usingdigital signatures(describedlater in this chapter).
The relativeadvantagesanddisadvantagesof symmetricand asymmetric cryptosys­
ternsare as follows:
1. Symmetric cryptosystems require that both encryption and decryption of
information be performed by a trusted subsystem, whereas this is not necessary with
asymmetric cryptosystems. Therefore, general security policies need asymmetric
cryptosystems.578 Chap.11•Security
2. When employed for the security of messages in a communication system, a
symmetric cryptosystem requires a secure channel by which the sender can inform the
receiver of the key usedto encipher the messages. The encrypted messages may,however,
be transmitted through an insecure channel. On the other hand, in an asymmetric
cryptosystem, both the public-key and the messages can be transmitted through an
insecure channel. Therefore, there is no need for a special secure channel for key
transmission. Due to this reason, asymmetric cryptosystems are considered to be more
secure than symmetric cryptosystems.
3. In general, asymmetric cryptosystems are computationally much more expensive
than symmetric cryptosystems and are inefficient for bulk data encryption. Hence, in
practice, for data communications, asymmetric cryptosystems are often used only for
initialization/control functions, while symmetric cryptosystems are used for actual data
transfer.
The Data Encryption Standard (DES) cryptosystem [NBS 1977, Seberry and
Pieprzyk 1989] is the best known and most widely used symmetric cryptosystem today.
On the other hand, the Rivest-Shamir-Adleman (RSA) cryptosystem [Rivest et al. 1978,
Seberry and Pieprzyk 1989] is the first published and practically the most satisfactory
asymmetric cryptosystem today.
11.3.4 Key Distribution Problem
When cryptography isemployed for securecommunications indistributed systems, aneed
for key distribution arises because two communicating entities can securely communicate
only when they obtain matching keys for encryption and decryption of the transmitted
messages. A matching pair of keys held by two communicating entities forms an
independent, private logical channel between them. The key distribution problem deals
withhow to securely supply the keys necessary to create these logical channels. The key
distribution problem in symmetric and asymmetric cryptosystems are described below.
KeyDistribution inSymmetric Cryptosystems
When two users (persons or programs) of two different nodes want to communicate
securely by using a symmetric cryptosystem, they must first share the encryption!
decryption key.Forthis,thekey must betransmitted from oneof thetwo userstotheother
user. However, there is no special transmission medium for the key transfer and the key
must be transmitted using the same insecure physical medium by which all exchanged
messages are transmitted. This requires that the key must itself be encrypted before
transmission because ifthe key is compromised by an intruder while being transmitted
over the insecure medium, the intruder can decrypt all encrypted messages exchanged
between the two users. Therefore, a circularity exists in symmetric cryptosystems. This
circularity can only be broken through prior distribution of a small number of keys by
some secure means. The usual approach is to use a server process that performs the job
of akey distribution center (KDC). Each user in the system shares with the KDC a
prearranged pair of unique keys.Sec. 11.3 • Cryptography 579
The KDC is a generally trusted entity and is shared by all communicating users of the
system. On request by a user, it generates a new secret key to be used by the user to
communicate with another user. In actual implementation, there may be several KDCs in
the system. The three commonly used implementation approaches are as follows:
•Centralized approach
• Fully distributed approach
• Partially distributed approach
Below we describe how key distribution takes place in each approach between two
users who want to communicate securely with each other.
Centralized Approach. In this approach, a single centralized KDC is used that
maintains a table of secret keys for each user (see Fig. 11.2).A user'ssecret key is known
only to the user and KDe.Suppose that the secret keys of users AandBareKaandKb,
respectively, and that a secure logical communication channel is to be established for
exchanging encrypted messages between them. The following protocol was proposed in
[Needham and Schroeder 1978] for performing this task (see Fig. 11.2):
m1 m3ec=~m4===xv
m2 msIDaKa
lObKb
Table ofsecret keys
for each user
m1=(Ra,IDa,lOb)
where R a;:.;:code forthe request made by user A
IDa=identifier of userA
IDb=identifier of userB
m2=E ((Ra,IDa,Kab, C1),Ka}
whereKab=secret key generated bythe KDC.for secure
communications between usersAandB
C1=E((Kab,IDa),Kb)
whereKb=private key of user B
Ka::private key of userA
m3=C1
m4=C2=EifJr'Kab)
whereN,==a random numbergenerated byuserB
m5==C3= EifJt,Kab)
whereN,==f(Nr)andtisapreviously defined function
Fig. 11.2 The method of key distribution in thecentralized approach.580 Chap.11•Security
1. UserAsends arequestmessage(ml)to theKDCindicating that it wants to
establish asecurelogicalcommunication channelwith user B.Themessage contains a
codefor therequest(Ra),the useridentifier ofA(IDa),and the user identifier ofB(IDb).
Thismessage istransmitted from user Ato KDC in plaintext form.
2. Onreceiving ml'the KDC extracts from its table the keys KaandKb,which
correspond respectively to theuseridentifiers IDaandIDbin themessage. It thencreates
a secret.key Kabforsecurecommunications between usersAandB.ByusingkeyKb,the
KDCencrypts thepair(KabtIDa)togenerate aciphertext C1=E«Kab,IDa),Kb).Finally,
itsendsamessage(m2)to userAthatcontainsRa,IDa'Kabtand C1•Themessage m2is
encrypted with the key Kaso that only user Acandecryptit.
3. Onreceiving m2'userAdecryptsitwith itsprivatekeyKaandcheckswhetherRa
andIDaofthemessage match with the originals to getconfirmed thatm2is the reply for
mI.Ifso, userAkeeps the key Kabwith it for future use and sendsamessage m3to user
B.Thismessage contains theciphertext C1•Note that only user BcandecryptC1because
it wasgenerated using key Kb•
4. Onreceiving m3'userBdecrypts C1with itsprivatekeyKbandretrieves bothKab
andIDa.At this stage, both users AandBhave the same key Kabthat can be used for
secure communications between thembecause nootheruser has this key. At this point,
userBneedsto verify if user Ais also in possession ofthe keyKab.Therefore, userB
initiatesanauthentication procedure thatinvolves sendinganonceto userAandreceiving
areplythatcontains somefunctionoftherecently sent nonce. Forthis,userBgenerates
arandomnumberNr,encryptsN;by using the key Kabtogenerate aciphertext C2=E (Nn
Kab),and sends C 2to userAin amessage ms,TherandomnumberN,is used as a
nonce.
5. Onreceiving ms,userAdecrypts C2with the key KabandretrievesN;It then
transforms N,to a new value N,by apreviously definedfunction(f).UserAencryptsN,
byusingthe keyKabtogenerate aciphertext C3=E (NI,Kab),and sends C 3to userBin
amessage m«.
6. Onreceiving ms,userBdecrypts C3,retrieves Nt,andappliestheinverseof
functionftoNItocheckif the value obtained isN;Ifso, userBgetsconfirmed that a
securechannel can becreatedbetween usersAandBby using the key Kab.This is
sufficient toachieve mutualconfidence, and from now on, the exchange ofactual
messages encrypted with keyKabcan take placebetween usersAandB.
Thatthereis aproblem in theprotocol waspointedout byDenning and Sacco
[1981].Theyobserved thatduringthetransferofmessage m3'if anintrudercopiesC1
and by unspecified meanscameto know Kab,thatintruder can in future always
pretendtoBthat it was A.Thebasicproblem here is that Bneverhad thechanceto
offeranonceto the KDC and, therefore, has nomeansofdeducing thefreshness of
thequantity(Kab)thatcamefrom the KDC. Notethat only the KDC and Aknow that
Kabis fresh. One methodtocorrectthisproblem is to add a timestamp (T)to the
ciphertext C1,so that it becomesE«Kab,IDa'T),Kb).UserBdecrypts thismessageSec.11.3•Cryptography 581
and checks that Tis recent. This solution is adopted in the Kerberos system (described
later in this chapter).
Notice that in the centralized KDC approach, ifthere arenusers in the system, n
prearranged key pairs are needed to provide secure communications. The approach is
simple and easy to implement. However, it suffers from the drawbacks of poor reliability
andperformance bottleneck of the single KDC.That is,fresh key distributions cannot take
place if the node on which the KDC resides crashes, and the KDC may get overloaded in
a large system with too many users. Two other approaches described below may beused
to overcome these drawbacks of the centralized approach.
FullyDistributed Approach. In this approach, there is a KDC at each node of
the distributed system. The prior distribution of secret keys allows each KDC to
communicate securely with all other KDCs. That is, each KDC has a table of secret keys
having private keys of all other KDCs. Therefore, in a system having nnodes, each KDC
keepsn-lkeys, resulting in a total of n(n-l)/2 key pairs in the system.
Suppose that a secure logical communication channel is to be established between
userAof nodeN1and userBof nodeN2.Also suppose that K1andK2are the private keys
of the KDCs of nodes N1andN2,respectively. The desired connection can be established
in the following manner (see Fig. 1 I.3):
m,=(Ral10a,lOb)
whereRa=code forthe request made by user A
IDa=identifier of user A
lOb=identifier of userB
m2=(~,IDa,Kab)
whereKab=secret key generated by the KDC ofnode N1for
securecommunications between users Aand B
m3=~=E((~blIDa,lOb),K2)
whereK2=private key ofKDC of node N2
m4=(KablIDa)
ms=C2=E(N" Kab)
whereN,=a random numbergenerated by userB
m6=C3=EVVt,Kab)
whereNt=t(N,)andtisapreviously defined function
Fig.It.3The method of key distribution in the fully distributed approach.582 Chap.11•Security
1. UserAsends a request message (ml)to its local KDC. The message contains a
code for the request (Ra),the user identifier of A(IDa)'and the user identifier ofB (IDb).
It is assumed that all local communications are secure and hence local messages can be
securely transmitted in plaintext form.
2. On receiving rn),the KDC of node N)consults the name server to get the location
(N2)ofthe user having identifier IDb'It then extracts the private key (K2)of the KDC of
nodeN2from its table. Next, it creates a secret key Kabfor secure communications
between users AandB.By using key K2,itencrypts the triplet (KabtIDa'IDb)to generate
aciphertext C.=E«Kab,IDa'ID b),K2).Finally, it sends a message (m2)to userAthat
containsRa,IDa'Kaband a message (m3)to the KDC of node Nzthat contains C].
3. On receiving m2'userAchecks whether RaandIDaof the message match with
the originals to get confirmed that m2is the reply for mi.If so, user Akeeps the key Kab
with it for future use.
4. On the other hand, on receiving message m3'the KDCof node N2decrypts it with
its private key K2and forwards the pair (Kab tIDa)to the user with identifier JDbin the
form of message ms.
5. On receiving m4'userBinitiates an authentication procedure and authenticates
userAexactly in the same way as done in the centralized approach.
Notice that in this approach the number of prearranged key pairs needed to provide
securecommunications is independent of the number of users and depends only on the
number of nodes in the system. Another major advantage of this approach is that for
successful distribution of a key for secure communications between two users, only the
nodes of the two users must be properly functioning. Therefore, the approach is highly
reliable.
PartiallyDistributed Approach. In this approach, the nodes of the system are
partitioned into regions and, instead of having a KDC for each node, there is a KDC only
for each region that resides on one of the nodes of that region-.The prior distribution of
secret keys allows each KDC to communicate securely with each user of its own region
and with the KDCs of all other regions. That is, each KDC has a table of secret keys that
contains private keys of all users of its own region and of all other KDCs.
In this approach, the distribution of a key for the establishment of a secure logical
communication channel between two users AandBdepends on the locations of the two
users. If both the users AandBreside on nodes that belong to the same region, the key
isdistributed exactly in the same manner as is done in the centralized approach. In this
case, the KDC of that region plays the role ofthecentralized KDC. On the other hand, if
the users AandBreside on nodes belonging to different regions, the key distribution is
performed in a manner similar to that in the case of the fully distributed approach. The
only difference is that, in this case, messages m2andm4are also encrypted because they
aretransmitted from one node to another. That is, m2is encrypted with the private key of
userA,andm«is encrypted with the private key of user B.The complete process of key
distribution in this approach is shown in Figure 11.4. Notice that, in this approach, theSec.11.3•Cryptography
RegionR1
Let there be 10 nodesin the system that are partitioned into two regions
R1andR2as shown above. The KDCs of regions R1andR2are located
onnodesN1andN61respectively.
m1::(Ra,IDa,lOb)
whereRa=code for the request made by userA
IDa=identifier of userA
10b=identifier ofuserB
m2::C1=E((Ra,IDa,Kab),Ka)
whereKab=secret key generated by the KDC of region R1for
securecommunications between users AandB
Ka=private key for userA
m3=C2::E((Kab,IDa,lOb),K2)
whereK2 ::private key ofKDC of region R2
m«=C3=Eq<et»IDa),Kb)
where K b=private key of user B
ms=C4=EtN"Kab)
whereNr=a random numbergenerated by userB
m6=Cs=Ef/Vt,Kab)
whereN,=f(Nr)and f isa previously defined function.
Fig. 11.4 The methodof keydistribution in thepartially distributed approach.583
failure of the KDC of a particular region will only disrupt key distribution activities that
involve a user of that region. Key distribution involving users of other regions can still be
carriedout successfully. Therefore, the reliability of this approach lies in between the
reliabilities of thecentralized and the fully distributed approaches.
KeyDistribution in Asymmetric Cryptosystems
In anasymmetric cryptosystem only public keys are distributed. Since public keys need
not be kept secret, there is no problem of key transmission through an insecure physical
medium. Therefore, one might conclude that the key distribution problem does not exist
inasymmetric cryptosystems. However, this is not correct since the safety of an584 Chap.II •Security
asymmetric cryptosystem depends critically on the correct public key being selected by a
user.A user who receives a public key wants to besure that the received key is genuine.
Thus, in asymmetric cryptosystems, the key distribution process involves an authentica­
tionprocedure to prevent an intruderfrom generating a pair of keys and sending a public
key to another user for establishing a logical communication channel with that user. The
authentication procedure allows the two users of a logical communication channel to
identify themselves before starting the actual exchange of data.
The commonly used key distribution approach in asymmetric cryptosystems is to use
apublic-key manager(PKM) process that maintains a directory of public keys ofall users
in the system. There is a key pair (Pk,Sk)for the PKM also. The public key Pkis known
to all users and the secret key Skis known exclusively to the PKM. The protocol based on
this approach for establishing a logical communication channel between two users is
described below.
Let us assume that a logical communication channel is to be established between
usersAandB.Also assume that (Pa,Sa)is the key pair of user Aand(Ph' Sb)is the key
pairofuserB.The public keys PaandPbare stored with the PKM and the secret keys Sa
andSbare known exclusively to users AandB,respectively. The desired connection can
beestablished in the following manner (see Fig. 11.5):
1. UserAsends a request message (mJ)to the PKM indicating that it wants to
establish a secure logical communication channel with user B.The message contains a
code for the request (Ra),a timestamp (T.),the user identifier of A (IDa)' and the user
identifier ofB (IDb).This message is encrypted by using Pk•That is,m,contains the
ciphertext C}=E«Ra,T}, IDa, JD b),Pk).
2. On receiving mit the PKM decrypts C.by usingSk'It then extracts the public
keysPaandPbfrom its table that correspond respectively to the user identifiers IDaand
IDbof the message. Byusing key Pa,thePKM encrypts the triplet (Ra,T.,Ph)togenerate
aciphertext C2=E«Ra,TitPh),Pa).Finally, it sends C 2to userAin the form of a
message (m2)'
3. On receiving m2'userAdecrypts C 2by using Saand retrieves its contents. The
retrieved values of RaandT1are compared with the originals to get confirmed that m2is
the reply for m.and that it is not a replay of an old message. User Athen generates a
random number Na,encrypts thepair (IDa'Na)by using user B'spublic key Phtogenerate
aciphertext C3=E«IDa'Na),Pb),and sends C 3to userBin a message (m3)'
4. On receiving m3'userBdecrypts C3by using Sband retrieves its contents. By
seeingIDain the message, user Bknows that user Awants to establish a logical
communication channel with it.In order to get the authentic public key of user A,userB
contacts the PKM. For this, it sends a message (m4)to the PKM requesting for user A's
public key. The message contains a code for the request (Rb),a timestamp (T2),the user
identifier ofA (IDa)'and the user identifier ofB(IDb).This message isencrypted by using
r;That is, m4contains the ciphertext C4=E«Rb,T2,IDa' ID b),Pk).
5. On receiving ms,the PKM decrypts C 4by using Sk.It then extracts the public
keysPaandPhthatcorrespond respectively to the user identifiers IDaandIDbof theSec. 11.3 • Cryptography
Directoryof
publickeys
IDaPa
IDbPbS8S
P«=publickey of PKM
Sk=secret keyof PKM
Pa=publickey of user A
Sa=secretkeyof user APb=publickey of user B
Sb=secret keyof user B
IDa=useridentifier of A
lOb=useridentifier ofB
m1=C1=E((Ra,7;,IDa,lOb),Pk)
whereRa=code forthe request made by user A
T1=a timestamp
m2=C2=E ((Ra,T1,Pb),Pal
m3=C3=E((IDa,Na),Pb)
whereNa-=a random numbergenerated by user A
tru-=C4-=E((~,T2,IDa.lOb),Pk)
whereRb=code for the requestmade by user B
T2=atimestamp
m5=Cs=E ((Rb,T2,Pa),Pb)
m6=C6=E((Na,Nb),Pa)
whereNb=a random numbergenerated by userB
m7-=C7=ErJb,Pb)
Fig. 11.5 The methodofkeydistribution in anasymmetric cryptosystem.
message. By using key Pb'the PKM encrypts the triple (Rb,Tz,Pa)to generate a
ciphertext Cs=E«Rb,Tz,Pa),Pb)'Finally it sends C;to userBin the form of a
message (ms).
6. On receiving ms,userBdecrypts C sby using S/J,retrieves its contents, and
compares RbandTzwith the originals to get confirmed that ms is really the reply of
m«.UserBthen generates a random number Nb,encrypts the pair (Na,Nb)by using
the keyPato generate a ciphertext C 6=E«Na,Nb),Pa),and sends C6to userAin
a message (m6)'
7. On receiving m6'userAdecrypts C 6by using Sa'retrieves its contents, and
compares the received Nawith the original. If they match, user Abecomes sure that userS86 Chap.II •Security
Bisauthentic. UserAthenencryptsNbby using the key Pbtogenerate aciphertext C7=
E (Nb,Pb)and sends C7touserBin amessage (m7).
8.Onreceiving m-;userBdecrypts C7by using Sbandcompares thereceivedNb
with the original.Iftheymatch,userBalso gets confirmed thatuserAisauthentic. This
issufficient toachievemutualconfidence andallowsregularcommunication to start.
Notethat theprotocol paradigms described abovefor keydistribution insymmetric
andasymmetric cryptosystems illustrate basicdesignprinciples only.Arealisticprotocol
isnecessarily arefinement ofthesebasicparadigms.
11.4AUTHENTICATION
Authentication deals with the problem ofverifying theidentityofa user(personor
program) beforepermitting accessto therequested resource. Thatis, anauthentication
mechanism prohibits the use ofthesystem(or some resource ofthesystem) by
unauthorized users by verifying theidentityofa usermakingarequest.
Authentication basically involves identification andverification. Identification is the
processofclaiming acertainidentity by a user, while verification is theprocessof
verifying theuser'sclaimed identity. Thus,thecorrectness ofanauthentication process
reliesheavilyon theverification procedure employed.
The main types ofauthentication normally neededin adistributed systemare as
follows:
1. User logins authentication. It deals with verifying theidentityofa user by the
systemat the time oflogin.
2. One-way authentication ofcommunicating entities. It deals with verifying the
identityofoneofthe twocommunicating entitiesby theotherentity.
3. Two-way authentication ofcommunicating entities. It deals with mutual
authentication, whereby bothcommunicating entities verify each other's
identity.
Adescription oftheauthentication mechanisms that arecommonly used toperform
these types ofauthentication ispresented below. Note that the authentication protocol
paradigms described belowillustrate basicdesignprinciples only.Arealisticprotocol is
necessarily arefinement ofthese basic paradigms andaddresses weakerenvironment
assumptions, stronger postconditions, or both.
11.4.1Approaches toAuthentication
Thebasicapproaches toauthentication are asfollows [Shankar 1977,Woo and
Lam 1992]:
1.Proofby knowledge. In this approach, authentication involves verifying
something that can only be knownby anauthorized principal. Authentication ofa userSec.11.4•Authentication 587
based on the password supplied by him or her is an example ofproofbyknowledge.
Authentication methods based on the conceptofproofbyknowledge are again of two
types-direct demonstration method and challenge-response method. In the direct
demonstration method, a user claims his or her identity by supplying information (like
typing in a password) that theverifierchecksagainstprestored information. On theother
hand, in the challenge-response method, a user proves his or her identity by responding
correctly to the challenge questions asked by the verifier. For instance, when signing up
as a user, the user picks a function, for example, x+18.When the user logs in, the system
randomly selects and displays a number, say 105, in which case the user must type 123
forauthentication to be successful. For further securityimprovement, several functions
may be used by the same user. At the time of login, the function to be used will depend
on when the login is made. For example, a user may use seven different functions, one for
each day of the week. In anothervariation of this method, a list ofquestions such as what
is the name of your father, what is the name of your mother, what is the name of your
street on which your house is located, is maintained by the system. When signing up as
a user, the user has to reply to all these questions and the system stores the answers. At
login, the system asks one of these questions at random and verifies the answer supplied
by the user.
2.Proofbypossession. In thisapproach, a user proves his or her identity by
producing some item that can only be possessed by anauthorized principal. The system
isdesigned to verify the produced item toconfirmtheclaimedidentity. For example, a
plastic card with a magnetic strip on it that has a user identifier number written on it in
invisible, electronic form may be used as the item to be produced by the user. The user
inserts the card in a slot meant for this purpose in the system's terminal, which then
extracts the user identifier numberfrom the card and checksto see if the card produced
belongs to an authorized user. Obviously, security can be ensuredonlyifthe item to be
produced isunforgeable and safely guarded.
3.Proofbyproperty. In thisapproach, the system is designed to verify the identity
of a user by measuring SOInephysicalcharacteristics of the user that are hard to forge. The
measured property must be distinguishing, that is, unique among all possible users. For
example, a special device (known as a biometric device) may be attached to each terminal
of the system that verifies some physical characteristic of the user, such as the person's
appearance, fingerprints, hand geometry, voice, signature. In deciding the physical
characteristic to bemeasured, animportant factor to be considered isthat the scheme must
bephycologically acceptable to the user community. Biometric systems offer the greatest
degree of confidence that a user actually is who he or she claimsto be, but they are also
generally the most expensive toimplement. Moreover, they often have user acceptance
problems becauseusers see biometric devicesas unduly intrusive.
Of the three authentication approaches described above,proofbyknowledge and
possession can be applied to all types of authentication needs in a secure distributed
system, while proofbyproperty isgenerally limited to the authentication of human users
by a system equipped withspecialized measuring instruments. Moreover, in practice, a
system may use a combination of two or more of these authentication methods. For588 Chap.11• Security
example, the authentication mechanism used by automated cash-dispensing machines
usually employ a combination of the first two approaches. That is, a user is allowed to
withdraw money only if he or she produces a valid identification card and specifies the
correct password corresponding to the identification number on the card.
11.4.2Us.rloginAutMfttlcQtlon
As in centralized systems, a user gains access to a distributed system by logging in a host
in the system. User identity is established at login;and all subsequent user activities are
attributed to this identity. Correct user identification at the time oflogin is crucial to the
functioning of a secure system because all access-control decisions and accounting
functions are based on this identity. Although any of the three basic approaches to
authentication can beemployed for user login authentication, the proofby knowledge is
the most widely usedmethod. Inparticular, most systems employ thedirect demonstration
method based on passwords.
In the authentication scheme based on passwords, the system maintains a table of
authorized users' login names and their corresponding passwords. When a user wants to
log in, the system asks the user to type his or her name and password. If the password
supplied by the user matches the password stored in the system against his or her name,
it is assumed that the user is legitimate and login is permitted; otherwise it is refused.
To provide good security and be practically useful, a password-based authentication
system must have mechanisms for the following:
1.Keeping passwords secret
2. Making passwords difficult to guess
3. Limiting damages done by a compromised password
4. Identifying and discouraging unauthorized user logins
5. Single sign-on for using all resources in the system
The commonly used mechanisms for dealing with these issues are described
below.
Keeping Passwords Secret
A user is responsible for keeping his or her password secret outside the computer system
(external world). How to keep passwords secret in the external world is not of concern to
operating system designers except for the fact that while a password is being typed in, it
should not be displayed on the terminal, to prevent it from being seen byprying eyes near
the terminal. The main concern, however. is to prevent an intruder from obtaining
somebody's password by having access to the system's password table. The password
table is ofcourse protected and isaccessible only to theauthentication program. However,
there is a great chance that the password table is exposed by accident or that the system
administrator has access to the table. Therefore, instead of storing the names and
passwords in plaintext form, they are encrypted and stored inciphertext form in thetable.
In thiscase, instead ofdirectly using a user-specified name andpassword for table lookup,Sec.11.4•Authentication 589
they are first encrypted and then the results are used for table lookup. Notice that for
implementing this scheme, the main requirement is that even if both the encryption
function and the password table are known, it is impossible to find the original password.
That is, a noninvertible function is needed for encryption because in the scheme we never
need to decrypt a ciphertext. This is an example- ofthe use of one-way cipher. In
cryptography we use the function
C =E (P,K)
whereKis a key,Pis a plaintext, and C is the resulting ciphertext. A one-way cipher can
beimplemented byletting the plaintextPserve as the key to Esuch that
C=E (P,P)
In a one-way cipher, itis very difficult to invert the encryption function(E)even if
the intruder knows the key. Furthermore, if the key is not known (as in the case of
password security scheme in which a password itselfis used as the key), the inversion
becomes much more difficult because the intruder cannot know which functions (and how
many times of them) are used.
Tokeeppasswords secret in a distributed environment, itisimportant that passwords
should never be sent across the network in plain text form. Moreover, they should not be
stored on normal servers but should only be stored on trusted servers that are well
protected. Notice that due to these requirements, authentication of a user by simply
sending his or her password to anauthentication server for approval does not work in a
distributed environment. The Kerberos authentication system (described later in this
chapter) provides an interesting solution to this problem.
MakingPasswords Difficult to Guess
Use ofmechanisms to keeppasswords secret does not guarantee that the system's security
cannot be broken. It only says that it is difficult to obtain passwords. The intruder can
always use a trial-and-error method. Virtually, in case of passwords, break-ins usually
consist of guessing a user name and password combination. How successful an intruder
can be in guessing passwords is obvious from the study made by Morris and Thompson
[1979] of passwords on UNIX systems. They compiled a list of likely passwords that
contained first and last names of persons, names of cities and streets, words from a small
dictionary spelled correctly and backward, short strings of random characters, and license
plate numbers. These passwords were then encrypted using the known password
encryption algorithm to obtain a list of encrypted guessed passwords. Then another list of
encrypted passwords was prepared by using entries in password tables of various UNIX
systems. The entries in the two lists were then compared to find matching entries.
Surprisingly, it was found that over 86% of actual passwords had a match in the list of
guessed passwords.
Atest of only a limited set of potential strings tends to reveal most passwords
because there is a strong tendency for people to choose relatively short and simple
passwords that they can remember. Some techniques that maybeused to make the task
of guessing a password difficult are as follows:S90 Chap.11•Security
1.Longerpasswords. The length ofapassword determines the ease with which a
password canbefound by exhaustion. Forexample, athree-digit password provides 1000
variations whereas a four digit password provides 10,000 variations. Longerpasswords
are lesssusceptible toenumeration because the work involved in enumerating allpossible
passwords increases by increasing the length of the password. Use of longer passwords
can beenforced orencouraged byproviding apassword entryprogram that asks a user to
entera longer password if he or she enters a short one.
2.Salting the password table.Another technique to make the task of guessing
passwords difficult is to artificially lengthen passwords byassociating an n-bit random
numberwith each password when it is first entered. The random numberis changed
whenever the password is changed. Instead of juststoring the encrypted password in the
password table, the password and the random numberare first concatenated and then
encrypted together. This encrypted result is stored in the password table. In this scheme,
thepassword table has an additional field that contains the random number in its
unencrypted form. At the time of login, this random number is concatenated with the
enteredpassword, encrypted, and then compared with the stored encrypted value.
Guessing ofa password becomes difficult because ifanintrudersuspects that Tokyomight
be thepassword ofa user, it is no longer enough to justencryptTokyoandcompare the
encrypted result with the value stored in the password table. Rather, for each guess made,
theintruderhas totryout2nstrings, such as TokyoOOOO, TokyoOOOJ, Tokyo0002 ,and so
forth, for n =4. This increases the encryption andcomparison time foreachguess made.
UNIX uses this method with n =12.
3.System assistance in password selection. A password can be either system
generated oruserselected. User-selected passwords areofteneasy toguess.Asystem can be
designed toassist usersinusing passwords thataredifficult toguess.Thiscanbedone intwo
ways. One way is to store a list ofeasy-to-guess passwords within the system and to first
compare auser-selected password withtheentries inthe list. Ifa match isfound, thesystem
refuses to accept the selected password and asks the user to select another password
informing himor her that the selected password iseasy to guess. Another way of providing
systemassistance is tohave a password generator program that generates random, easy-to­
remember, meaningless words, such as mounce, bulbul, halchal, that can be used as
passwords. The user selects a password suggested by the system and uses it with his or her
own choice of a mixture of upper- and lowercase letters of that word, such as hAICHal.
Identifying and Discouraging Unauthorized User
Logins
Somemanagement techniques should be used to improve the security of a system against
unauthorized user logins. Three such techniques are as follows:
1. Threat monitoring. This technique detects security violations bychecking for
suspicious patterns of activity. For example, the system may count the number of incorrect
passwords given when a user is trying to log in, and after, say,three failed login attempts,
the system notifies security personnel by setting an alarm.Sec.11.4•Authentication 591
2.Auditlogs.In this technique, the system maintains a record of all logins. That is,
the time at which login wasdone, the duration of login, the accessed objects and the types
of accesses made, etc., are recorded for each login. When a user logs in successfully, the
system reports to the user some of the recorded information (such as time and duration)
of the previous login. This may be helpful for the user to detect possible break-ins. After
a security violation has been detected, the audit log can be used to detect which objects
were accessed by the intruder and the amount of damage done. This information can be
useful for recovery from the damages done by the intruder.
3. Baited traps. Intruders ITIayalso becaught by laying baited traps. Forexample, the
system may maintain some special login names with easy passwords, such as login name:
user, password: user. Whenever anyone logs in using any of these names, the system
security personnel are immediately notified.
SingleSign-on
In a distributed client-server environment, a user might have several client programs
running on his or her host node that access different server programs on remote nodes. In
such an environment, the servers must authenticate that the clients run on behalf of a
legitimate user. If a simple password-based authentication scheme is used, the user's
password must be presented each time a server wants to authenticate a client program
running on behalfof the user. This is curnbersome and inconvenient because a user will
certainly not want to enter a password each time he or she accesses a new service. This
is also not desirable from the point of view of transparency, which aims to provide a
virtual single system image. A simple way to solve this problem is to cache the user's
password on his or her host computer and use it from the cache every time a new service
is accessed. However, this solution does not work because it is dangerous to keep
passwords in cache from the point of view of keeping passwords secret. Once again, the
Kcrberos authentication system (described later in this chapter) provides an interesting
solution to this problem.
Limiting Damages DonebyaCompromised Password
It is suggested that a user should change his or her password frequently so that an intruder
who has been successful in guessing the current password will have to guess a new one
after the current password is changed by the user. In this way, the damage done by the
intruder can be reduced. The extreme form of this approach is the use of one-time
passwords. There are three different methods to implement the idea of one-time
passwords. In the first method, the user gets a book containing a list of passwords. For
each login, the user must use the next password in the list. Obviously, the user must keep
the password book in a secure place. In the second method, every time a user logs out, the
system asks toselect a new password for the next login and replaces theold password with
the new one. The user either remembers the new password or notes it down somewhere
for use at the time of next login.The third method relies on the use of a special equipment
such as smart cards or synchronized password generators. For example, a synchronized592 Chap.11•Security
password generator devicegenerates apseudorandom alphanumeric word ornumberthat
changeseveryminuteor so and is time synchronized to adatabase storedin thecomputer.
To log in, a user types in the word or numberdisplayed on the card at the time oflogin.
Thisresultsin aone-time password that isgoodonly at that particular pointin time and
for only one login. One such deviceis theSecureID fromSecurity Dynamics (Cambridge,
Massachusetts). Thismethodhas not been very successful thus far, primarily due to the
inconvenience and cost oftheadditional hardware required. Itrequires that all users
purchase thehardware device.However, it has the advantage thatonceset up, it is fairly
easytoadminister (asopposed to amanualpassword list thatrequires frequent updating
for all users).
11.4.3On••WayAuth.ntkatlon ofCommunicating Entltl.s
WhenanentityAwants to communicate withanotherentityB, Bmay like to verify the
identityofAbeforeallowingAtocommunicate with it. For example, aservermay be
designed to first verify the identityofanyclientthat wants to communicate with it. The
commonly usedauthentication protocols forone-way authentication ofcommunicating
entitiesaredescribed below.
Thefollowing description isbasedon thematerialpresented in [Woo and Lam 1992].
Sincetheauthentication protocol paradigms directlyusecryptosystems, theirbasicdesign
principles also follow closelythe type of cryptosystem used.Therefore, theprotocols can
bebroadlyclassified into two categories-those basedonsymmetric cryptosystems and
thosebasedonasymmetric cryptosystems. Authentication protocols ofbothcategories are
basedon theproof-by-knowledge principle.
Protocols Based on Symmetric Cryptosystems
In asymmetric cryptosystem, theknowledge ofthesharedkeyallowsanentitytoencrypt
ordecryptarbitrary messages. Without suchknowledge, it is notpossible for theentityto
encryptamessage or todecryptanencrypted message. Hence,inauthentication protocols
baseduponsymmetric cryptosystems, theverifierverifiestheidentityof aclaimant by
checking if theclaimant cancorrectly encryptamessage by using a key that the verifier
believes isknownonly to an entitywith the claimedidentity(outside theentitiesused in
theverification process).
Let usassumethat user Awantstocommunicate withuserBbutBwants to
authenticate Abeforestartingthecommunication. AlsoassumethatKis the key ofa
symmetric cryptosystem that issharedbetween usersAandB.Theauthentication protocol
for thisconsistsofthefollowing steps:
1.UserAencrypts itsidentifier (IDa)by using key Ktoobtainaciphertext Ct=E
(IDa' K). It thensendsamessagem,to userB,whichcontainsIDaandC,.
2. Onreceiving ml'userBdecrypts C)byusingkeyKandcompares theobtained
resultwithIDaofthemessage. Iftheymatch,userAisaccepted; otherwise it is
rejected.Sec. 11.4• Authentication 593
One major weakness of this protocol is its vulnerability to replays. That is, an
intruder could masquerade asAby recording the message mland later replay it to B.
Replay attacks can be countered by using nonces or timestamps. A nonce-based challenge­
response protocol that overcomes the problem of replay ofmessages works as follows (see
Fig. 11.6):
1.UserAsends its identifier (IDa)to userBinplaintext form in a message m.,
2. On receiving nu ,userBgenerates a random number N,and sends N,to userAin
plaintext form in a message m2'
3. On receiving m2'userAencryptsN,by using key Kto obtain a ciphertext C 1=
E (NnK).It then sends C1toBin a message m-;
4. On receiving ms,userBdecrypts C1by using key Kand compares the obtained
result with the original value of NrIf they are equal, user Ais accepted; otherwise
it is rejected.
m1=IDa=identifier of user A
m2=Nr=a random numbergrenerated by userB
m3=C1=EWr,K)
whereKis the symmetric key shared between users Aand B
Bdecrypts C1usingKand compares the result with original N,.
Ifthey are equal, A isaccepted, otherwise rejected.
I'-'ig.11.6One-way authentication protocol based on symmetric cryptosystem.
In this protocol, the freshness of N,(whose value is different for each conversation)
guarantees that an intruder cannot masquerade asAbyreplaying a recording of an old
authentication conversation betweenAandB.
Although the above-described protocol functions correctly, it is impractical for a
general large-scale system due to the following reasons:
1. Notice that the scheme requires that each user must store the secret key for every
otheruser it would ever want to authenticate. This may not be practically feasible
in a large system having too many users and in which the number of users keeps
changing frequently.
2. Thecompromise of one user can potentially compromise the entire system.594 Chap. )) • Security
Toovercome these problems, the use of a centralized authentication server(AS)was
proposed in [Needham and Schroeder 1978]. Each user in the system shares with the AS
aprearranged secret key. The AS is a generally trusted entity and is shared by all
communicating users of the system. When the AS is used, the authentication protocol
takes the form shown in Fig. 11.7(it has been assumed that KaandKbare the secret keys
of usersAandB,respectively, that are shared with the AS).
1114 m,~==a==m2~msm3IDaKa
lObKb
Tableofsecretkeys
foreachuserAS=authentication server
IDa=identifierofuser A
IDb=identifierofuser B
Ka=secretkeyofuser A
Kb=secretkeyofuser B
m,=IDa
m2=N,=a random numbergenerated by user8
m3=C1=EIN"Ka)
m4=C2=E«IDa,C1),Kb)
TheASretrievesN,by firstdecrypting C2withKband then decrypting
C,with«;
ms=C3=E'N"Kb)
Bdecrypts C3withKbandcompares the result with originalN,.
Iftheyare equal, then Aisaccepted, otherwise rejected.
Fig. 11.7 One-way authentication protocol based on symmetric cryptosystem and the
use of a centralized authentication server.
1. UserAsends its identifier (IDa)to userBinplaintext form in a message nu,
2. On receiving mJ, user Bgenerates a random number N,and sends N,to userAin
plaintext form in a message m2'
3. On receiving m2'userAencryptsN,by using its secret key Kato obtain a
ciphertext C1=E (NnKa).It then sends C 1toBin a message m«.
4. On receiving m3'userBencrypts the pair (IDa'C1)by using its secret key Kbto
generate a ciphertext C2=E«IDa'C1),Kb).It then sends C 2to the AS in a
message m4.
5. On receiving m4'theAS decrypts C 2with keyKband retrieves the pair (IDa'C)).
It then extracts from itsdatabase the key (Ka)thatcorresponds to IDaand decryptsSec. 11.4 • Authentication S9S
C1with keyKaandretrievesN;Next, itencryptsN,by using key Kbtogenerate
aciphertext C3=E (Nr,Kb).Finally, it sends C3toBin amessagems.
6. Onreceiving m«,userBdecrypts it by using its secretkeyKb,retrievesNnand
compares it with the originalvalueofNy-If they are equal,userAisaccepted;
otherwise itis rejected.
Ascompared to the previous protocol, the key distribution and storage problems are
greatlyalleviated because now each user needs to keep only one key. Moreover, the
system's security can be greatly improved simply by tightening security for the AS
becausethe risk of compromise is mostly shifted to the AS. The centralized AS, however,
suffers from the same drawbacks as thecentralized KDC.Thesedrawbacks can also be
solved by using fully/partially distributed ASs in a similarmannerasdescribed for the key
distribution problem inSection11.3.4.
Protocols Based on Asymmetric Cryptosystems
In anasymmetric cryptosystem, the public key of each user is published while the secret
key of each user is known only to the user and no one else. Hence, in authentication
protocols based upon asymmetric cryptosystems; the verifier verifies the identity of a
claimant bychecking if theclaimant cancorrectly encryptamessage by using the secret
key of the user whose identity is being claimed.
Let us assume that user Awants to communicate with user BbutBwants to
authenticate Abefore starting the communication. AlsoassumethatPaandSaare the
public and secret keys of user A,andPhandSbare the public and secret keys of user B.
Theauthentication protocol for this consistsof thefollowing steps (see Fig. 11.8):
1.UserAsends its identifier (II)ll)to userBinplaintext form in a message mi .
2. Onreceiving m,userBgenerates a random numberN,and sends N,to userAin
plaintext form in a message m-:
m3
m1=IDa==identifier of user A
m2==Nr==a random numbergenerated by userB
m3==C1==EtN"Sa)
whereSa=secret keyof user A
Bdecrypts C1by using the publickey ofuserAandcompares the result with
originalN;Iftheyare equal, A isaccepted, otherwise rejected.
Fig. 11.8 One-way authentication protocol based on asymmetric cryptosystem.S96 Chap.11•Security
3. Onreceiving m2'userAencryptsN,by using its secret key Sato obtain a
ciphertext C)=E(NnSa)'It then sends C 1toBin amessagem-,
4. Onreceiving m«,userBdecrypts C1by using the public key ofuserA (Pa)and
compares theobtained resultwith theoriginalvalueofNr:If they are equal,user
Aisaccepted; otherwise it is rejected.
As in the case ofprotocols baseduponsymmetric cryptosystems, in this case also a
centralized AS maybeused to greatly alleviate the keydistribution andstorageproblems.
In this case, the AS maintains adatabase ofallpublished public keys and each user in the
systemkeeps a copy ofthe public key. (Ps)ofthe AS. Whenthe AS is used, the
authentication protocol takes the following form (see Fig. 11.9):
1. UserAsends its identifier (IDa)to userBinplaintext form in a messagemi .
2. Onreceiving m),userBgenerates arandomnumberN,and sends N,to userAin
plaintext form in a message m2'
Database of
publickeysPa=publickey ofA
Sa=secret keyof A
Pb=publickey ofB
Sb=secret keyof B
Ps=publickey ofAS
Ss=secret keyofAS
IDa=identifier ofA
1Db=identifier ofB
m,=IDa
m2=Nr:arandomnumbergenerated byB
m3=C1=EttJr,Sa)
m4=(Rb,IDa)
whereRb=code forrequesting thepublickey ofauser
m5=C2=E((IDa,Pa),5s)
Bretrieves NlibYfirstdecrypting C2withPsandthendecrypting
C1withPa.T evalue of N robtained in this way is compared with
theoriginalvalue ofN;Iftheyare equal,thenAisaccepted, other­
wise rejected.
Fig. 11.9 One-way authentication protocol based on asymmetric cryptosystem and the
use of a centralized authentication server.Sec.11.4•Authentication 597
3. Onreceiving m2'userAencrypts N,byusing its secretkeySatoobtaina
ciphertext C1=E (N" Sa)' It then sends C 1toBin amessage m-;
4. Onreceiving m-,userBsends the pair(Rb,IDa)to the AS in plaintext form in a
messagems,whereRbis arequestcodeforrequesting thepublickeyofthe user whose
identifier isspecified in thesecondelementofthemessage.
5. Onreceiving m«,the ASextracts from its database thepublickey(Pa)ofthe
userwhoseidentifier isIDa.It thenencrypts thepair(IDa' Pa)by using its ownsecret
keyS,togenerate aciphertext C2=E«IDa' Pa),Ss)'Finally,itsendsC2toBin a
message m«.
6. Onreceiving m«,userBdecrypts C2byusingthepublickeyofthe AS(Ps)and
retrieves thepair(IDa' Pa).Now by usingthe keyPa,itdecrypts C1andcompares the
obtained resultwith the original valueofN,.If they are equal,userAisaccepted;
otherwise it isrejected.
Noticethat in this caseeachuserneedstokeeponly one publickey, thepublickey
ofthe AS.Alsonoticethat in the aboveprotocol it hasbeenassumed that theasymmetric
cryptosystem iscommutative. Thatis, thepublicandsecretkeysfunction ineitherorder.
Therefore, ifthepublickey is used for encryption, then the secretkey can be used for
decryption, whereasifthesecretkey is used for encryption, then the publickey can be
used for decryption.
11.4.4Two-Way Authentication ofCommunicating Entities
In adistributed system, tasks are oftendistributed overmultiple hoststoachieveahigher
throughput ormorebalanced utilization ofresources thancentralized systems. Correctness
ofsuchadistributed taskdepends onwhether peerprocesses participating in thetaskcan
correctly identifyeachother.Two-way authentication protocols allowbothcommunicat­
ingentities toverifyeachother's identity beforeestablishing asecurelogical
communication channel between them.
Obviously, mutualauthentication can beachieved byperforming one-way authenti­
cationtwice.Thatis, if two communicating usersAandBwanttoauthenticate each
other,Acan first authenticate Bbyperforming one-way authentication, and then Bean
authenticate Abyrepeating the same process, but with the rolesofAandBreversed.
However, this may turn out to be costlierthanaprotocol designed specially for two­
wayauthentication. Forexample, iftheprotocol ofFigure11.9 isrepeated twicefor
performing two-way authentication, a totalof10messages will berequired. However,
aprotocol formutualauthentication ofcommunicating entriesthatrequires onlyseven
messages and that is also basedupon an asymmetric cryptosystem and uses a
centralized AS isdescribed below. In the description, it hasbeenassumed that two users
AandBwanttoauthenticate each other. Here, PaandSaare thepublicandsecretkeys
ofuserA,andPbandSbare thepublicandsecretkeysofuserB.Moreover, P,and
Ssare thepublicandsecretkeysofthe AS. The authentication protocol consistsofthe
following steps(see Fig. 11.10):598 Chap.11• Security
Database of
publickeys
IDaPa
lObPb
Ps=public key ofAS
5s=secret keyofAS
Pa=public keyofuser A
5a=secret keyof user 8Pb=public key of user 8
Sb=secret keyofuser 8
IDa=useridentifierof A
lOb=useridentifierof8
m,=(Ra,IDa,lOb)
whereRa=code forthe request made by user A
m2=C1=E((/OJ,,Pb),Ss)
m3=C2=E((IDa,Na),Pb)
where N ais a random numbergenerated by userA
m«=C3=E((Rb,IDa,lOb,Na),Ps)
mS=(C4,C6)
whereC4=E «IDa,P a),5s)and
C6=E(Cs,Pb)
whereCs=(lOb,K,Na),5s)
whereKisa session key generated
by the ASfor users AandB.
m6=C7=E((Cs,Nb),Pa)
whereN»isa random numbergenerated by user8
m7=Ca=E(Vb,K)
Bdecrypts Cawith the session key Kandcompares the result with the
oriQinalvalue of Nb.Ifthet are equal, this issufficient toprove that the
10(;Jlcalcommunication channelestablished betweenAandBwith key
Klsanewlyestablished channel and issecure.
Fig. 11.10 Two-way authentication protocol based on asymmetric cryptosystem and
the use of a centralized authentication server.Sec.11.4•Authentication 599
1. UserAsendsarequestmessage (m})totheASindicatingthatitwantstoestablish
a securelogical communication channelwithuser B.Themessagecontainsacodeforthe
request(Ra),theidentifierofuser A(IDa)'andtheidentifierofuser B(IDb).Thismessage
is sent in plaintext form.
2.Onreceiving ml,theASextracts from its database the public key Phthat
corresponds to the user identifier IDbofthe message. Byusing its secret key Ss'theAS
encrypts the pair(IDb, Pb)togenerate aciphertext C.=E«IDb,Pb),Ss)'It then sends
C1toAinamessage m2'
3. Onreceiving m-;userAdecrypts C 1by using the public key of the AS (Ps)and
retrieves itscontents. ItthengeneratesarandomnumberNa,encrypts the pair(IDa' N a)
by using the public key of user B(Pb)togenerate aciphertext C2=E«IDa' N a),Ph),and
sendsC2toBinamessagem«.
4. Onreceiving m«,userBdecrypts C2by using itssecret key Sband retrieves its
contents. Itthen sends a message m4to theASrequesting for the public key of user Aand
a session key for the secure logical communication channel between AandB.The
message contains therequestcode(Rb),IDa'IDb,andNa.Before being sent, the message
isencrypted with the publickeyoftheAS(Ps)'That is, the message contains the
ciphertext C3=E«Rb,to;IDb,Na),Ps)'
5.Onreceiving ms,theASdecrypts C3with its secret key (Ss)and retrieves its
contents. It generates anewsession key KforAandB.Next itgenerates threeciphertexts:
C4=E «ID,l' P a), Ss),c,=E «ID b,K,Na), Ss),andC6=E(Cs,Pb)'Finally, it sends
C4andC6toBinamessage m«.
6. Onreceiving m«,userBdecrypts C4andC6withP,andSb'respectively, and
retrieves their contents. It then generates a random number Nband creates a ciphertext
C7=E«Cs,Nb),Pa).Finally,itsendsC7toA inamessage In6'Notice that Csisobtained
bydecrypting C6.
7. Onreceiving m6'userAfirstdecrypts C7by using its secret key Saand then
decrypts C«by using the public keyof theAS(Ps)'Now both users AandBhave the
sessionkeyK.UserAnextgenerates aciphertext ("'18=E (Nb,K)and sends C gtoBin a
message m7'
8. Onreceiving m-;userBdecrypts Cgby using the sessionkeyKandcompares the
result with the originalvalue ofNb.If they are equal, this is sufficient to prove that the
logicalcommunication channelestablished between A andBwith key Kis a newly
established channel and is secure. Both users AandBare now sure of each other's
identity.
Notice that although theauthentication protocol is based upon an asymmetric
cryptosystem, the actual communications between users AandB,after the secure logical
communication channel isestablished between them, take place byasymmetric
cryptosystem.600 Chap.11•Security
11.4.5(aseStudy:H.rberos Auth.ntkQtlon System
The need for secure authentication in distributed computing systems has led to the design
of authentication standards and systems for this purpose. For example, X.509 identifies
theCCITIX.500 directory authentication framework standard [Smart 1994], Kerberos is
a network authentication system developed at MIT [Neuman and Theodore 1994,
Stallings 1994], and SPX is an experimental authentication system developed by the
Digital Equipment Corporation [Khanna 1994]. Of several authentication systems
developed to date, the Kerberos system is the most popular one and is continuing to
evolve. It has beendeclared the Internet standard and has become the de facto standard for
remote authentication in networked client-server environments. Therefore, a description
of this system is presented here.
Kerberos was developed at MIT as part of its project Athena [Champine et al.
1990]. It is named after the three-headed dog of Greek mythology that guards the
entrance to Hades. Its design is based on the ideas of Needham and Schroeder [1978]
for key distribution and authentication that we have already seen in Sections 11.3.4 and
11.4.3, respectively. It is now available in both commercial and public-domain
implementations and is widely used at MIT and elsewhere to provide secure access to
resources in distributed environments. It is used by Transarc's AFS file system and is
the underlying component of the OSP'sDCE Security Server (described later in this
chapter). Several vendors, including DEC, Hewlett-Packard, and IBM, now offer
Kerberos implementations as part of their standard middleware offerings on commercial
UNIX and midrange server platforms. Version 5, the most recent version of Kerberos,
is described here.
Kerberos SystemArchitecture
The system architecture of Kerberos is shown in Figure 11.11.Itconsists of the following
basic components:
1. Kerberos server. The key component of a Kerberos system is a Kerberos server
that acts as a key distribution center. Each Kerberos server has an authentication database,
an authentication server, and a ticket-granting server.The authentication database has the
user ID and password of all users of the system. Moreover, the Kerberos server shares a
unique secret key with each server in the system. Therefore, the authentication database
also has the server ID and secret key for all servers in the system. The passwords and
secret keys are distributed physically or in some other secure manner as part of the
Kerberos installation. Kerberos uses the DES algorithm to generate the keys and encrypt
messages, but this is implemented as a separate module that can beeasily replaced by any
other suitable algorithm.
The authentication server performs the task of verifying user'sidentity at the time
of login without requiring the password to travel over the network. Kerberos has
single sign-on facility. Therefore, a user has to enter his or her password only once at
the time of login no matter how many different resources are accessed by the user
after that.Sec. 11.4 • Authentication
Kerberos servernode(KeyDistribution Center)601
Client node
109=ticket-granting server's identifier
10c=clienfsidentifier
IDs=applicationserver's identifier
N;=a nonce
Kc=clienfssecret key
Ks=application server's secret keyApplication
server node
Kg=ticket-granting server's secret key
K,=ticket-granting ticketsession key
K2=service-grant ingticket session key
Ts;=startingtimeof validityof ticket
Tei=endingtimeof validityof ticket
T;=a timestamp
m,=(l0c'N,)
m2=C2=E((N"K"G,l.Kc)'where G,=E((f0c' 109' Ts,'Te"K,),Kg)
m3=(IDs' NzC" C3),where C3=E((f0c'T,),K,)
m4=Cs=E((N2,K2,G4),K,),whereC4=E((IDc,IDs' TS2'Te2,K2),Ks)
ms=(C4'Ce),where Ce=E((Io;T2),K2)
me=C7=E(T3,K2),whereT3=T2+1
Fig. 11.11 Kcrberos authentication protocol.
Theticket-granting server performs the task of supplying tickets to clients for
permitting access to other servers inthe system.These tickets are used to establish secure
logicalcommunication channels between clients and servers by performing mutual
authentication.
Since the Kerberos server has valuable information in its authentication database
that must be kept secret, it is extremely important that it be installed on a carefully
protected and physically secure machine. Although there is no technical problem in
installing the Kerberos server on the same machine that has another application, it is
always better for security reasons to have a dedicated machine for the Kerberos server.
The number of users having access permission to this machine should be extremely
limited.602 Chap.II •Security
2. Client. The second component of a Kerberos system is comprised of client
processes that usually run on workstations located in effectively public places where
their consoles are available to whatever user happens to bephysically in front of
them. Therefore, they are completely untrusted. Users (on whose behalfclient
processes run) must first get their identification verified by the Kerberos server before
attempting to access any other server in the system. Once a user'sidentity has been
verified, each client process running on his or her behalf must obtain a ticket from the
ticket-granting server for communicating with a server that it wants to access.
3.Application server.The third component of a Kerberos system is the applica­
tion server, also known simply as the server. A server provides a specific type of
service to a client upon request only after verifying the authenticity of the client. A
server usually runs on a machine that is located in a moderately secure room.
Therefore, Kerberos ensures that a compromise of one server does not compromise
another server.
Kerberos Authentication Protocol
With the idea of the basic components and their functions, we will now see the Kerberos
protocol that explains how these components interact with each other to perform user
loginauthentication and mutual authentication of client and server processes. The protocol
is described below and is summarized in Figure 11.11.In the description, A,G, C, and S
standrespectively for the authentication server, the ticket-granting server, the client, and
the application server. Moreover, let Ka,Kg,andK,be the secret keys of A,G, andS,
respectively, and K,be the secret key of C(this key isgenerated from the user'spassword
by using a one-way function).
1. When a user logs on to a workstation by typing his or her login name, the login
program sends a request to theauthentication server for what is known as a ticket-granting
ticket in a message mi.Message m,contains the user'sID (login name) (JDe)and a nonce
N}that is used to check the validity of the reply. This message is sent in plaintext
form.
2. On receiving mit the authentication server extracts the password of this user
from the authentication database. It then generates a random number for use as a
session key (K.).After this, it creates a ticket-granting ticket that contains the user's
ID(IDc)'theticket-granting server'sID(IDg),the starting time for validity of the ticket
(~I)'the ending time for validity of the ticket (TeJ)(typically on the order of 8 hours),
and a copy of the sessionkey(K}).Making the ticket-granting ticket time sensitive
prevents an unauthorized user from capturing it and using it at a later time. Now it
encrypts this ticket by using the ticket-granting server'ssecret key ( Kg)to generate a
ciphertext C.=E«IDc'IDg,TsJ'Tel'K)),Kg).This encryption ensures that no one (not
even the client) can tamper with the ticket-granting ticket and only the Kerberos server
can decode it. Next it uses the client'ssecret key (Kc)(generated from the user's
password) to generate another ciphertext C2=E«NbKJ,C1),Kc).It then returns C 2
to the login program in a message m2.Sec. 11.4 • Authentication 603
3. Onreceiving m-,the login program promptsthe user for his or her password. The
enteredpassword is run through a one-way function that generates theclient'ssecret key
(Ke)from the password. Immediately afterobtaining Kc'thepassword isremoved from
thecomputer's memory to minimize the chance of password disclosure in the event of a
client crash. The login program then attempts to decryptC2by using Kc•If the user
supplied thecorrectpassword, C2issuccessfully decrypted and the login program obtains
the nonce, the sessionkey, and the encrypted ticket from the message. It checks the nonce
for validity of the reply and stores the session key and the encrypted ticket for subsequent
use when communicating with the ticket-granting server. When this has been done, the
client'ssecret key can also be erasedfrom memory, since the ticket now serves to
authenticate the user. A login session is then started for the user on the user's
workstation.
Notice that user authentication is done without requiring thepassword to travel over
the network. Moreover, if an intruderintercepts the reply message, it will be unable to
decryptitand thus be unable to obtain the session key and the ticket inside it.
4. Now when a clientprocess running on the client workstation onbehalfof the
authenticated user wants to access the application server, it requests the ticket-granting
server for a service-granting ticket that can be used to communicate with theapplication
server. For this, the client creates an authenticator thatcontains theclient'sID(IDe)and
atimestamp (T}).Itencrypts thisauthenticator by using the session key (K1)to obtain a
ciphertext C3=E«IDc'T1),K1).Unlike the ticket-granting ticket, which is reusable, this
authenticator isintended forone-time use and has a very short life span (typically on the
order of a few minutes). The client next sends the encrypted authenticator (C3),the
encrypted ticket-granting ticket«(',),the ID of the application server(IDs),and a nonce
(N2)to theticket-granting server in a message m«.
5. Onreceiving m«,theticket-granting serverdecrypts C.by using its secret key
(Kg)and makes sure that it has not expiredbycomparing Telwith the currenttime. It
extracts the sessionkey(KI )fromitand uses it to decryptC3to obtain IDeandT}.The
obtainedIDciscompared with the value of IDein theticket-granting ticket toauthenticate
the source of the request. On the other hand, T1is used to ascertain the freshness of the
request. If all verifications pass successfully, the ticket-granting server gets assured that
thesenderof the ticket is indeed the ticket'sreal owner.
Notice here that it is the authenticator and not the ticket-granting ticket that proves
theclient'sidentity. Therefore, the use of a ticket-granting ticket is merely a way to
distribute keys securely. Moreover, since the authenticator can be used only once and has
a very short life span, it is nearly impossible for anintruder to steal both the ticket­
granting ticket and an authenticator for later use. Each time a client applies to the ticket­
grantingserverfor a new service-granting ticket, it sends its reusableticket-granting ticket
plus a fresh authenticator. Also notice that the reusability of theticket-granting ticket
allowssupportof a single sign-on facility in which a user need not enter his or her
password every time it needs to access a new server.
Aftersuccessful authentication ofthe client, the ticket -granting servergenerates a
newrandomsession key (K2)and then creates a reusableservice-granting ticket for access
to therequested server. This ticket contains the client'sID(IDe)'theapplication server's604 Chap. II • Security
ID(IDs)'the starting time for validity of the ticket (1's2),the ending time for validity of
the ticket (4.2),and a copy of the new session key (K2).It then encrypts the service­
granting ticket with the secret key of the application server (Ks)to obtain a ciphertext C4=E«JDe,IDs,Ts2''Te2,K2),Ks)'This encryption ensures that no one (not even the client)
can tamper with the service-granting ticket and only the application server or the Kerberos
server can decode it. Next it uses the old session key (KI)to generate another ciphertext
Cs=E«N2,K2,C4),Kt).It then returns C sto the client in a message ms.
6. On receiving m4'the client decrypts C sby using the old session key (K1)and
obtains the nonce, the new session key,and the encrypted service-granting ticket. Itchecks
the nonce for validity of the reply and stores the new session key and the encrypted ticket
forsubsequent use when communicating with the application server. The client is now
ready to issue request messages to the application server. However, if mutual
authentication is desired, before proceeding with its transaction or request for service, the
client creates an authenticator that contains the client'sID(IDe)and atimestamp (T2).It
encrypts this authenticator by using the session key (K2)to obtain a ciphertext C6=
E«JDc'T2),K2).The client next sends to the application server, in a message ms, the
encrypted authenticator (C6),theencrypted service-granting ticket(C4),and a request that
the server reply with the value of the timestamp from the authenticator, incremented by 1,
andencrypted in the session key.
7. On receiving ms,the application server decrypts C 4by using its secret key (K...)
and extracts the copy ofthe session key (K2).It then uses itto decrypt C6to obtain
IDeandT2.Next, it increments T2by 1 and encrypts the obtained value (T3)with the
session key K2to obtain a ciphertext C7=E(T3,K2).It returns C 7to the client in a
message m6'
8. On receiving m6'the client decrypts C7by using the session key K2to obtainT3.
IfT3=T2+1,the client gets assured that the server isgenuine. This mutual authentication
procedure prevents any possibility of an intruder impersonating a server in attempt to gain
accessinformation from a client.
At the conclusion of this process, the client and server are assured of the
establishment ofa securecommunication channel in between them. They also now share
a session key (K2),which they can use (if required) to encrypt future messages.
Interrealm Authentication in Kerberos
In a system that crosses organizational boundaries, it is not appropriate for all users and
servers to be registered with a single Kerberos server.Therefore, in such an environment,
multiple Kerberos servers exist, each responsible for a subset ofthe users and servers in
the system. A subset of users and servers along with the Kerberos server with which they
areregistered is called a realmin Kerberos. In a typical implementation, networks of
clients and servers belonging todifferent organizations usually constitute different realms.
In such an environment, interrealm authentication facility is needed to allow a client to
securelyinteractwith a server belonging to a different realm. For this, a Kerberos serverSec.11.4•Authentication 60S
of one realm is registered (shares a secret key) with the Kerberos servers of all other
realms. The interrealm authentication protocol is shown in Figure 11.12and is described
below:
1. A client that wants to access a server in adifferent realm first makes a request for
aservice-granting ticket from its own ticket-granting server to access the ticket­
granting server of the other realm.
2. With the obtained service-granting ticket, the client then makes a request for
anotherservice-granting ticket from the ticket-granting server of the other realm
to access the application server of that realm.
RealmB
I
I
I
I
I
I
I
I
I
I
I
I
IIIII
I
I
I
I
I-------------------------------------------------------- --RealmA----------------------------------------------------------I
I
IIIII
I
ml=requestforticket-granting ticket
m2=reply form1
m3=requestforservice-granting ticket toaccess the remote ticket-granting server
m4=reply form3
ms=requestforservice-granting ticket toaccess the remote application server
me=reply forms
m-=accessrequest
Fig. 1l.12 lnterrealm authentication protocol of Kerberos.Chap.11•Security
3. With the newly obtained service-granting ticket, the client now sends its request
to the desired application serveroftheotherrealm. The remoteserverthen
chooseswhether to honortheclient'srequest.
In the above approach forinterrealm authentication, if it isdesired that each Kerberos
realm be able to operate with all otherKerberos realms, in a system having nrealms, there
must ben(n-l)/2 secure key exchanges. Therefore, thisapproach does not scale well. It
createsa lotofoverhead on thenetworkand the Kerberos servers themselves. Thus, it is
suggested that Kerberos implementations should use a few relatively large realms rather
than too many small realms. The latest version ofKerberos (Version 5) also supports
muJtihop interrealm authentication, allowing keys to be shared hierarchically [Neuman
andTheodore 1994].
Within a single realm, the Kerberos serveris a critical component for smooth
functioning. Therefore, toensurereliability of the Kerberos server, Kerberos supports
replication of the Kerberos server. When replicated, a simple master-slave technique is
used to keep the authentication databases ofall the replicas ofa Kerberos server
consistent. That is, all changesare only applied to the master copy by a single Kerberos
database management server(KDBMS) that runs only on the masterKerberos server's
machine. Administrative operations such as adding or deleting users or requests for
password changefrom users are handled by the KDBMS. Changes made to the master
Kerberos server'sauthentication database areperiodically propagated to theauthentica­
tiondatabases ofslave Kerberos servers.
SomeLimitations ofKerberos
For all its popularity, however, Kerberos is not a complete securitysolutionbecauseofthe
following limitations [Bellovin and Merritt 1990, Neumann andTheodore 1994]:
1. Kerberos is not effective againstpassword-guessing attacks. If a user choosesa
password that is easy to guess, an intruderguessing thatpassword canimpersonate the
user.Anotherway by which an intrudercan get to know a user'spassword is bymodifying
the login program (aTrojan horse) that resides on the user'sworkstation. In this case, also,
theintrudermay obtain sufficient information toimpersonate the user. To address these
limitations, it issuggested thatKerberos shouldbecombined with aone-time password
technique. Commercial products thatcombine aone-time password technique with
Kerberos are available.
2. The Kerberos protocol dependsupon loose synchronization ofclocksofthe nodes
presentin a system. It may not be very difficult to meet this requirement, but theproblem
is that the synchronization protocol used for this purposemustitselfbe secure against
securityattacks. A Kerberos protocol that does not rely on synchronized clocks has been
presented in [Kehne et al. 1992].
3.Another problem withKerberos is that it is difficult to decide the appropriate
lifetimeofthe tickets, which is generally limited to a few hours. For bettersecurity, it is
desirable that this lifetime should be short so that users who have been unregistered orSec. 11.5 • Access Control 607
downgraded will not be able to continuetouse theresources for a long time. However,
for usertransparency, thelifetimeshould be as long as the longestpossiblelogin session,
since the use ofanexpiredticketwillresult in the rejection ofservice requests. Once
rejected, the user must reauthenticate the login session and then requestnewservertickets
for all the services inuse.Interrupting anapplication at an arbitrary point for
reauthentication mightnot beacceptable incommercial environments.
4.Finally,client-server applications must bemodified to takeadvantage ofKerberos
authentication. ThisprocessiscalledKerberization. Kerberizing anapplication isthe most
difficult part of installing Kerberos. Many large organizations may find it almost
impossible toKerberize theirapplications and turn to other solutions. Fortunately, the
availability ofKerberized applications hasimproved with time and is expected to improve
further. More and more vendors are now producing newKerberized versionsoftheir
popularproducts.
11.5ACCESSCONTROL
Once a user or a processhas been authenticated, the next step in security is to devise ways
toprohibitthe user or the process from accessing thoseresources/information that he or
she or it is not authorized to access. This issue is called authorization and is dealt with by
using access control mechanisms. Access control mechanisms (also known as protection
mechanisms) used in distributed systems are basically the same as those used in
centralized systems. The main difference is that since all resources are centrally located in
acentralized system, access control can beperformed by a central authority. However, in
adistributed client-server environment, each server is responsible forcontrolling access to
its own resources.
Whentalkingabout access control in computer systems, it iscustomary to use the
following terms:
1.Objects.Anobjectis an entity to which access must be controlled. An object may
be anabstractentity, such as a process, a file, a database, a semaphore, a tree data
structure, or aphysical entity, such as a CPl],amemory segment, a printer, a card reader,
a tape drive, a site of a network.
Eachobjecthas aunique name that differentiates itfrom allother objects inthesystem.
An object is referenced by its unique name. In addition, associated with each objectis a
"type"thatdetermines thesetof operations that may be performed onit.For example, theset
ofoperations possible on objects belonging to the type "datafile" may be Open, Close,
Create,Delete,Read, andWrite,whereas for objects belonging to the type "program file,"
thesetofpossibleoperations maybeRead,Write, andExecute. Similarly, forobjects oftype
"semaphore," the setofpossibleoperations may beUpandDown,and for objects of type
"tapedrive,"the setofpossibleoperations may beRead,Write, andRewind.
2. Subjects. Asubjectis an active entity whose access to objects must be controlled.
That is, entities wishingto access and perform operations on objects and to which access
authorizations aregrantedare called subjects. Examples of subjects are processes and608 Chap.11•Security
users. Note that subjects are also objectssincethey too must be protected. Therefore, each
subjectalso has a unique name.
3. Protection rules. Protection rules define the possible ways in which subjects and
objectsareallowedto interact. Thatis,protection rules govern the subjects' access to
objects.Therefore, associated with each (subject, object) pair is an access right that
definesthesubsetofthe setofpossibleoperations for theobjecttype that the subjectmay
perform on the object. The complete setofaccess rights ofasystemdefines which
subjectscanperformwhatoperations on which objects. At any particular instanceoftime,
this setdefinestheprotection state ofthe system at that time.
The exact mannerin which the protection rules are imposed tocontrolthesubjects'
access to objectsdependson the access controlmodel used by the system. The following
accesscontrolmodels have been proposed in the literature:
1. The access matrix model [Lampson 1971, Graham and Denning 1972,Harrison et
al.1976]
2. Theinformation flowcontrolmodel[Denning 1976, Bell and LaPadula 1973]
3. The security kernel model [Ames et al. 1983, Rushby and Randell 1983]
Ofthese, the access matrix model is the most popularone and is widely used in
existing centralized anddistributed systems. The other two models are mainly of
theoretical interest. A description ofthe access control mechanisms based on the access
matrix model is presented below.
11.5.1Prot.ctlon Domains
We saw that the principle ofleast privilege requiresthat at any time a subject should be
able toaccessonly those objectsthat itcurrently requires to complete its task.Therefore,
from time to time, subjects may need to changethe set of access rights they have to
objects,depending on theparticular task that they have to do at any time. The conceptof
adomainiscommonly used toprovidethis type offlexibility of access control in a
security system.
Adomainis anabstractdefinition ofa setofaccess rights. It is definedas a set
of(object, rights) pairs. Each pair specifies anobjectand one or more operations that
can beperformed on the object. Each one oftheallowed operations is called a
right.
Asecuritysystem based on the conceptofdomaindefines a set ofdomains with each
domainhaving its own set of(object, rights) pairs. At any instance oftime, each process
executes in oneoftheprotection domainsofthe system. Therefore, at aparticular instance
oftime, the access rights ofaprocessare equal to the access rights definedin the domain
in which it is at that time. A processcan also switchfrom one domaintoanotherduring
execution.
Figure11.13shows an exampleofa system having three protection domainsD),D2,
D3•Thefollowing points may be observed from this example:Sec. 11.5 • Access Control 609
1.Domains need not be disjoint. That is, the same access rights may simultaneously
exist in two or more domains. For instance, access right (Semaphore-l, {Up, Down}) is
in bothdomainsD}andD2.This implies that a subjectineitherof the two domains can
perform UpandDownoperations onSemaphore-I,
2. The same objectcan exist in multiple domains withdifferent rights in each
domain. For instance, rights for f"'i[e-JandFile-2aredifferent inD}andD2,and rights
forTapelsrive-I aredifferent inD2andD3•Considering File-I,a subject in domainD}
canRead,Write,andExecute it, butasubjectindomainD2can only perform Read
andWriteoperations on it.Therefore, inordertoexecuteFile-I,a subject must be in
domain D1•
3. If an objectexists only in asingle domain, it can be accessed only by the
subjects in that domain. For instance, File-Scan only be accessed by the subjects in
domainD3•
(File-1, {Read, Write, Execute})
(File-2,{Read})
(File-3J{Read, Write, Execute})
(TapeDrive-1, {Read, Write, Rewind})
(File-1, {Read, Write})
(File-2, {Read, Write, Execute})
(TapeDrive-1 , {Read})
."ig.11.13 A system having three protection domains.
Since a domainis anabstractconcept, itsrealization and the rules for
domainswitching are highly system dependent. For instance, some ways of
realizing adomainmay be the following:
1. Each useras adomain.In this case, processes are assigned to domains
according to the identity ofthe user on whose behalfthey areexecuted.
Adomainswitching occurs when a user logs out and another user logs
in.
2. Each processas adomain.In this case, the access rights of a process are
limited to the access rights ofits own domain. A domain switching
occurs when one processsends amessage to another process and then
waits for a response.
3. Eachprocedure as adomain.In this case, each procedure has its own set
of access rights and a domainswitching occurs when a procedure calls
anotherprocedure during the courseofitsexecution.610 Chap.11•Security
In the protection scheme of UNIX, both the concepts of user-oriented domains
and procedure-oriented domains are employed. Let us first see the use of the concept
ofuser-oriented domains. In UNIX, a user-id (uid) and agroup-id(gid)are associated
with each user. A(uid,gid)pair identifies the list of objects and the types of
operations that can be performed on these objects. The domain of a process depends
on the user on whose behalfit is executed. Therefore, the domain of a process is
defined by its (uid,gid)pair. That is, two processes with the same (uid,gid)pair will
have exactly the same access rights and two processes with different tuid,gid)pairs
will have different access rights. In the latter case, several of the access rights may be
the same for the two processes. A process switches domains by acquiring a new uid
orgidby executing the setuidorsetgidcommands. Furthermore, it is also worth
mentioning here that the superuser in a UNIX system is not a person but a name for
a special domain within which the most privileged processes, needing access to all of
the objects in the system, may run.
Now let us see the use of the concept ofprocedure-oriented domains in UNIX. In
UNIX, all the procedures are grouped into two classes-user procedures and kernel
procedures. These .two classes form two domains called the user mode and thekernel
mode.A process running in the kernel mode has a different set of access rights as
compared to a process running in the user mode. For example, in the kernel mode, a
process can access all pages in the physical memory, the entire disk area, and all other
protected resources. In this two-domain architecture, when a user process does a system
call, it switches from the user mode to the kernel mode. Therefore, at a particular instance
of time, the domain of aprocess and hence its access rightsdepend on whether the process
is executing a user procedure or a kernel procedure at that time.
Multics [Schroeder et al. 1977] used a more generalized form of the procedure­
oriented domains. Unlike UNIX, which uses two domains (user mode and kernel mode),
the Multics architecture had the flexibility to support up to 64 domains. Each domain of
Multics was called a ring.As shown in Figure 11.14, the rings were concentric and the
procedures inthe innermost ring, theoperating system kernel, weremost powerful, having
maximum access rights. Moving outward from the innermost ring, the rings became
successively lesspowerful having fewer access rights. In fact, theaccessprivileges ofring
iwere a subset of those for ring j for all i>j when the ring numbers started from the
innermost ring andincreased foreach ring as wemovedoutward.That is,j<iimplied that
the procedures in ringj had more access rights than the procedures in ring i.A process
could operate in multipledomains (rings) during itslifetime.Adomain switching occurred
when a procedure in one domain (ring) made a call to a procedure in another domain
(ring). Obviously, domain switching was done in a controlled manner; otherwise, a
process could start executing in the innermost ring and no protection would be
provided.
11.5.2Acca.sMatrix
In the domain-based protection approach, the system must keep track of which rights on
which objects belong to a particular domain. In the access matrix model, this information
is represented as a matrix, called an access matrix, that has the following form:Sec.11.5• AccessControl
Ring0(most powerful)
Ring1
Ringn-1
Ringn(leastpowerful)611
Fig. 11.14 The ring architecture ofMulticsprotection domains.
1. The rows represent domains.
2. The columns represent objects.
3. Each entry in the access matrix consists of a set of access rights.
4. The(i,j)thentry of the access matrix defines the set of operations that a process,
executing in domain Di,can perform on object OJ<
At any instance of time, the protection stateofthe system is defined by the contents
of the access matrix. The access matrix of Figure 11.15 shows the protection state of the
system in Figure 11.13.
When an access matrix is used to represent the protection state of a system, the
following issues must be resolved:
1. How to decide the contents of the access matrix entries.
2. How to validate access to objects bysubjects.
3. How to allow subjects to switch domains in a controlled manner.
4. How to allow changes to the protection state of the system in a controlled
manner.
The normally used methods to handle these issues are described below.612 Chap.11•Security
~F1 F2 F3 81 T1
Domain(File-1) (File-2) (File-3) (Semaphore-1 ) (Tapedrive-1)
01 Read ReadUpWrite DownExecute
D2Read ReadUp Read
WriteWriteDown
Execute
Read Read
D3 Write Write
Execute Rewind
Fig. 11.15 The access matrix for the protection state of the system in Figure 11.13.
Deciding the Contents of the Access MatrixEntries
Policy decisions concerning which rights should beincluded in the (i,j)thentry are
system dependent. However, in general, the contents ofthe access matrix entries
corresponding touser-defined objects are decided by the users, whereas the contents
of the entries corresponding tosystem-defined objects are decided by the system. For
example, when a user creates a new object OJ'columnjis added to the access matrix
with suitable entries as decided by the user'sspecification ofaccess control for the
object.
Validating Access to ObjectsbySubjects
Given the access matrix, how can access to objects by subjects be allowed only in the
mannerpermitted by the protection state ofthe matrix? For this, an object monitor is
associated with each type of object, and every attempted access by a subject to an object
is validated in the following manner:
1. A subject Sin domain Dinitiatesraccess to object 0,whererbelongs to the set
ofoperations that may be performed onO.
2. Theprotection system forms the triple (D,r,0)and passes it to the object monitor
ofO.
3. The object monitor of0looks for the operation rin the(D, O)th entry of the
access matrix. Ifpresent, the access is permitted; otherwise, a protection violation
occurs.Sec.11.5• Access Control 613
Allowing Controlled DomainSwitching
Theprinciple of least privilege requires that a process should be allowed to switch from
one domain to another during its lifetime so that at any instance of time the process is
given only as many rights as are necessary for performing its task at that time. However,
domain switching by processes must be done in a controlled manner; otherwise, a process
may switch to a powerful domain and violate the protection policies of the system.
Domainswitching can becontrolled bytreating domains as objects on which the only
possible operation isswitch.Therefore, for allowing domain switching in a controlled
manner, the domains are also included among the objects of the access matrix.
Figure 11.16 shows the access matrix of Figure 11.15 with the three domains as
objects themselves. In the modified access matrix, domain switching from domain D;to
domainD,ispermitted if and only if the right switchis present in the (Di~Dj)thentry of
the access matrix. Thus in Figure 11.16, a process executing in domain D)can switch to
domainD2or to domain D3,a process executing in domain D2can switch only to domain
D3,and a process executing in domain D3cannot switch to any other domain.
!F1F2 F3 51 T1010203
Domain
Read Read Up SwitchSwitch01Write Down
Execute
ReadReadUp Read Switch
02WriteWrite Down
Execute
ReadRead
03Write Write
Execute Rewind
14'ig.11.16 The access matrix of Figure 11.15with the domains included as objects.
AllowingControlled Change to the Protection State
In a flexible design, the protection system should also allow the content of a domain to be
changed. However, this facility is not essential because if the content of a domain cannot
be changed, the same effect can be provided by creatinga new domain with the changed
contents and switching to that new domain when we want to change the domain contents.
Although not essential, the facility of allowing controlled change to the protection state is
normally provided in a protection system for greater flexibility.614 Chap.11•Security
In an access matrix model, this facility can be provided by treating the access matrix
itselfas an object to beprotected. In fact, sinceeach entry in the access matrixmay be
individually modified, each entry must be considered as an object to be protected. For
allowing controlled change, the possible rights defined for this new object are copy,
owner,andcontrol.To simplify the description, we will categorize the changes to be
allowed to the content of the access matrix entries into two types-allowing changes to
the column entries and allowing changes to the row entries.
Allowing Changes to the Column Entries. Thecopyandownerrights allow
a process to change the entries in a column. The ability to copy an access right from one
domain (row) to another is denoted by appending an asterisk (*)to the access right. For
example, Figure 11.17shows the access rights of only the first three objects (Fl,F2,and
F3)of the access matrix of Figure 11.15 with some copy rights. A process executing in
domainD,can copy the ReadandWriteoperations on F,to any other domain (any other
entry in column FJ) ,whereas a process executing in domain D2can copy the Read
operation on F)andReadandExecuteoperations on F2to any other domain. None of the
operations on F3can be copied to any other domain.
.:S:F1 ~ Fa
Domain
Read· Read
01 Write·
Execute
Read· Read*
02 Write Write
Execute·
Read
03Write
Execute
Fig. 11.17 An access matrix with copy rights.
The copy right may have the following three variants:
1. Transfer. In this case, when a right is copied from the (i.j)thentry to the (k,j)th
entry of the access matrix, it is removed from the (i,j)thentry.
2. Copy with propagation not allowed. In this case, when the right R*iscopied from
the(itj)thentry to the (k,j)thentry, only the right R(notR*)is created in the (k,
j)thentry.The implication of this is that a process executing in domain D,cannot
further copy the right R.Sec. ]1.5 • AccessControl 61S
3. Copy with propagation allowed.Inthiscase,whentheright R*iscopiedfromthe
(i,})thentry tothe (k,})thentry,theright R*iscreatedin the (k,j)thentry,sothat
a process executing in domain D,can further copy the right R*orR.
On the other hand, the ownerrightisused to allow the adding/deletingof rights to
column entries in a controlled manner.Iftheownerright is included in the (i,j)thentry
oftheaccessmatrix,aprocessexecutingindomain D;can addanddeleteanyrightinany
entryincolumn). Figure 11.18showstheaccessmatrixofFigure 11.17with ownerrights
includedforthethreeobjects.Inthefigure,domains D},D2,andD3havethe ownerrights
forobjects F1,F2,andF3,respectively. Therefore,a processexecutingindomain D}can
add and delete any valid right of F)in any entry in column F).Similarly, a process
executingin domain D2can add and delete any valid right of F2in any entry in column
F2,and a processexecutingindomain D]can add anddeleteany validrightof F3in any
entry in column F3.
Fig. 11.18 Anaccessmatrix with owner
rights.IsF1 ~ Fa
Domain
Read*Read
01Write*
Execute
Owner
Read* Read*
02 Write Write
Execute*
Owner
Read
03Write
Execute
Owner
Allowing Changes to the Row Entries. Thecontrolright, which is only
applicable to domain objects, is used to allow a process to change the entries in a row.
If the control right is present in the (D;,Dj)th entry of the access matrix, a process
executing in domain D;can remove any access right fromrowDj.For example,
Figure 11.19 shows the access matrix of Figure 11.16 with controlrights included. In
this figure, since the entries (DbD2)and(D},D3)havecontrolrights, a process
executing in domain D]can delete any right from rows D2andD3.Similarly, since
the entry (D2,D3)hascontrolright, a process executing in domain D2can delete any
right from row D3•616 Chap.J] •Security
~r, F2F351t,0102 03
Domain
01ReadRead Up SwitchSwitchWrite DownControlControlExecute
ReadReadUpRead Switch
02WriteWrite Down ControlExecute
Read Read
D3Write Write
Execute Rewind
Fig. 11.19 An access matrix with control rights.
Inpractice, an access matrix islargeand sparse. Most domains have noaccess atall tomost
objects,that is, most of the entries are empty. Therefore, a direct implementation ofan
access matrix as a two-dimensional matrix would beveryinefficient andexpensive
(wastage ofdisk space). Moreover, in distributed systems, subjects and objects may be
located on different sites, which further complicates theimplementation issue. The two
mostcommonly used methods that have gained popularity incontemporary distributed
systems for implementing anaccess matrix are access control lists (ACLs) and capabilities.
For instance, Andrew [Satyanarayanan 1989], Apollo [l.evine 1986], and Butler
[Dannenberg and Hibbard 1985] use ACLs and Accent [Rashid and Robertson 1981],
Amoeba[Mullender andTanenbaum 1986],andMach [Sansom etal. 1986]use capabilities.
These two methods are described below.
AccessControlLists
Inthis method, theaccess matrix is decomposed bycolumns, andeach columnofthe matrix
isimplemented as an access list for the object corresponding to that column. The empty
entriesofthe matrix are not stored in the access list. Therefore, for each object, a list of
orderedpairs(domain, rights)ismaintained, whichdefines alldomains withanonempty set
ofaccess rights for that object. Furtherdetails of the working and properties ofa security
system based onACLs are presented below.
AccessValidation. Whenever asubject indomain Dexecutes an operation ronan
object0,theaccess listforobject 0isfirst searched forthe listelement whose domain field
isD.Then therights field ofthis elementissearched for r.Iffound, the operation isallowed
tocontinue; otherwise, aprotection violation occurs.
In this method, the access list is checked on every access. This is a very desirable
feature from a security point of view. However, consulting the access Jiston every accessSec. 11.5 • Access Control 617
couldcausesubstantial overhead, especially when the accesslist islong. Thisdrawback can
beovercome bymaintaining acachefor theaccesslistentriesofonly the active domains.
Granting Rights. Accessrightrforobject0isgrantedtodomainD in the
following manner:
1. Theaccesslist forobject0is firstsearched for the list element whosedomain
field isD.
2. If found, rightrisaddedto the rights field ofthis listelement. Otherwise, a new
listelementisaddedto the access list for the objecto.Thedomainfield and rights
field of this list elementare set to Dandr,respectively.
Passing Rights. Access right rforobject0ispassed(propagated) from adomain
D1toanotherdomainD2in thefollowing manner:
1.Accesslist forobject0is firstchecked toensurethat DIpossesses eitherowner
right for object0orcopyright for accessrightr.
2. If D1possesses any of the above two rights, accessrightrforobject0isgranted
todomainD2inthemannerdescribed above.Otherwise, aprotection violation
occurs.
Rights Revocation. Accessrightrforobject0isrevokedfromdomainDsimply
bydeleting rfrom the rights set ofdomainDin theaccesslist foro.
For fileprotection, severalsystemsuseuser-oriented domains like that of UNIX in
which a(uid,gid)pair forms a domain.Revocation ofauser'saccessrightbecomes more
complicated in thesesystemsbecauseaccessrevocation requiresthedeletionoftheuser's
uid(ifpresent) from the accesslistoftheobjectinquestion and also the cancellation of
theuser'smembership from all the groups that belongto a domain that has access to that
object.In a large distributed system,theprocessofdiscovering allgroupsthatthe user
shouldberemoved from and performing the actual removal operation may take a
significant amountof time that may be unacceptable inemergencies. Theconceptof
negative rights is used to overcome thisproblem [Satyanarayanan 1989, 1990]. This
conceptisbasedon the idea that to revokeauser'saccessright to an object,the user can
be given negative rights on that object. Negative rightsindicatedenialofthespecified
rights, with denialoverriding possession incaseofconflict. With this extension, theACLs
maycontainnegative rights, so that it is possible toexpressfacts, such as every user of
adomainexceptuser-ianduser-jmay exercise. right ronobjectO.Theunionof all the
negative rightsspecified for a user subtracted from his or her positiverights gives his or
her actual total rights. Negative rights thus act as a mechanism for rapid and selective
revocation and areparticularly valuable in a large distributed system.
The main advantage ofthemethodofACLs is that for a givenobjectthe setof
domains from which itcan beaccessed can bedetermined efficiently. However, the main
drawback ofthemethodis that for a givendomainthe setofaccessrightscannotbe
determined efficiently.Objectidentifier618 Chap.11•Security
Capabilities
Rather than decomposing the access matrix by columns, in this method the access matrix
isdecomposed byrows, and each row is associated withitsdomain. Obviously, the empty
entries are discarded. Therefore, for each domain, a list of ordered pairs (object, rights) is
maintained, which defines all objects for which the domain possesses some access rights.
Each(object, rights) pair is called a capability and the list associated with a domain is
called acapability list.
A capability is used for the following two purposes:
• To uniquely identify an object
• To allow its holder to access the object itidentifies in one or more permission
modes
Therefore, as shown inFigure 11.20,acapability iscomposed oftwo basic parts-an
object identifier part and a rights information part,The object identifier part usually
contains apointer to the object and acts as aglobally unique system-oriented name for the
object. On the other hand, the rights information part is usually a set of bits that determine
which operations are allowed on the object with this capability. Further details of the
working and properties of asecurity system based on capabilities are presented below.For
ease of presentation, in the following description we will assume that each user/process
forms a domain of the system.
RightsinformationIFig.11.20The two basic parts ofa
~ ....L-.. ......J capability.
AccessValidation. Acapability isconsidered as an unforgeable ticket that allows
its holder to access the object (identified by its object identifier part) in one or more
permission modes (specified by its rights information part). A process that possesses a
capability can access the object identified by it in the modes permitted by it. There are
usually several capabilities for the same object. Each one confers different access rights
to its holders. The same capability held by different holders provides the same set of
access rights to all of them.
Since simple possession of a capability means that access is permitted in the modes
associated with thecapability, toexecute anoperation ron an object 0,aprocess executes
the operation r,specifying the capability for object 0as a parameter. When the monitor
for object 0receives the access request (with the capability), it need only verify that the
rights information part of the capability has permission for operation r.
Notice that in a capability-based security system, there is no need to search a list to
verify that access is allowed. Rather, the security system need only verify that the
capability supplied by aprocess is valid for thedesired operation on the object. Therefore,
once a process establishes the possession of a capability for an object, itcan access the
object in one of the modes allowed by the capability without any further check by theSec.11.5• AccessControl 619
security system.For these reasons, capability-based security systems aremoreefficient
thansecurity systems basedonACLs.Also noticethatinthecapability-based approach,
there is no checking ofuser identity. If this is required foraccessvalidation, someuser
authentication mechanism mustbe used.
Granting andPassingofRights. Inthecapability-based securityscheme, each
usermaintains a listofcapabilities thatidentifies allobjectsthattheusercanaccessand
theassociated accesspermissions. But how does a userget acapability in the first
place?
In acapability-based system,there are usuallyone ormoreobjectmanagers foreach
typeofobject.Arequesttocreateanobjector toperform someoperation on anobjectis
sent to one oftheobjectmanagers of thatobjecttype.Whena newobjectiscreated,the
objectmanager thatcreatestheobjectgenerates (as a part oftheobjectcreation process)
acapability with allrightsofaccessfor theobject.Thegenerated capability isreturned to
theownerfor use. Now the ownermay give the capability tootherusers with whomthe
objectis to be shared.However, theownermaywanttorestricttheaccessmodesin a
different mannerfordifferent users who share the object.Therefore, beforetheowner
gives the capability tootherusers, it may be necessary torestrictthecapability by
removing someoftherights.Theusual way to do t.hisis to haveafunction in theobject
manager forrestricting capabilities. Whencalled,thisfunction generates a newcapability
for theobjectwith only the desiredaccesspermissions andreturnsthenewlygenerated
capability to the caller. This capability is thengivento theusens)forwhomit was
generated.
Protecting Capabilities against Unauthorized Access. Toensurethat in a
capability-based securitysystemtheobjectsareprotected againstunauthorized access,the
following basicrequirements must be met:
1. Acapability mustuniquely identifyanobjectin theentiresystem.Evenafterthe
objectassociated with agivencapability isdeleted,it isimportant that thecapability is not
reusedbecausesomeusersmayretainobsolete capabilities. Useofanobsolete capability
shouldproduce anerrorinsteadofallowing accessto adifferent object.
2.Capabilities mustbeprotected fromusertampering. Forthis, it is necessary that
capabilities betreatedasunforgeable protected objectsthat are maintained by the
operating systemand only indirectly accessed by the users.
3.Guessing ofa validcapability shouldbeimpossible or at least very difficult. This
isbecause in thecapability-based schemethedegreeofprotection isprobabilistic and
proportional to thedifficulty ofguessing a validcapability.
Thefollowing methods arenormally used tomeettheserequirements:
1. Tagged architecture. In thismethod, eachobjecthas a tag to denoteitstypeas
eitheracapability or anordinary accessible datasuchasinteger,pointer,character, or
instruction. Tags are normally implemented inhardware byassociating a tag with units of
memory, usuallywords.In this case, each memory word has a tag field that tells whether620 Chap.11•Security
the word contains a capability or not. The tag field is not directly accessible by an
application program, and it can be modified only by programs running in the kernel mode
(i.e., the operating system). Although only one bit is necessary for the tag field to
distinguish between capabilities and other objects, tagged architecture machines typically
usenbits for the tag field to allow the software to distinguish among 2ndifferent types
ofobjects (memory contents).
2. Partitioned implementation. Another method to preserve the integrity of
capabilities is to store them separately from data in special segments that can only be
accessed by the operating system. One way to implement this is to partition the address
spaceofa user process into two parts-one accessible to the process and the other
accessible only totheoperating system. The former contains the process's normal data and
instructions, whereas the latter contains its capabilities.
3. Encryption ofsparse capabilities. The tagged and partitioned methods of
protecting capabilities from unauthorized access are oriented toward centralized computer
systems. These methods are not suitable for use in a distributed system because in a
distributed system the security mechanism used should allow capabilities to be safely
transferred from one node to another. The third method, which does not require
capabilities to bedistinguished from other objects either by separation or by tagging, is
particularly suited to distributed systems. In addition to preventing capabilities from user
tampering, this method also makes capabilities unique and difficult to guess.
In this method, a large name space that is sufficiently sparse is used for the
capabilities. Uniqueness is achieved by using the methods described in Section 10.4 for
the creation of unique system-oriented identifiers that form the object identifier part of the
capabilities, On the other hand, to make the capabilities difficult to guess or forge, the
rights information part of each capability is combined with an extra field containing a
random number, thereby rending the task of amalicious user wishingto generate any valid
capability so lengthy as to be impractical. Furthermore, the rights information part and the
random-number part are encrypted by the object manager before a capability is issued to
a user.The secret key is available only with the object manager. When a process presents
thecapability along with a request for object accessing, the object manager uses the key
to decrypt the encrypted part of the capability before using it. In this way, the rights
information part of acapability that confers restricted permissions cannot be forged by its
possessors to convert it to one with more permissions.
RightsAmplifICation. The concept of rights amplification was introduced in
Hydra [Cohen and Jefferson 1975]. We saw that in a capability-based system objects are
typed and recognize a set of predefined operations. The set of predefined operations for
an object type is known as auxiliary rightsin Hydra. In addition to the auxiliary rights,
each object type has a set of kernel rights, such asget,put,andaddtomanipulate the data
partofan object and load, store, append, delete, copy, andcreateto manipulate the
capability list part of an object. The kernel rights are implemented within the kernel and
aretransparent to the user processes.
A request to perform an operation on an object is sent to the object manager of that
object type. The request contains the capability for the object as a parameter. ThisSec.11.5 • AccessControl 621
capability mayincludean auxiliary right to invoke some operation on theobjectbut would
notincludeanyofthe kernel rights for the object. A problemarises here becausetheobject
manager isitselfanordinary program. It isessential that theobjectmanager be able to
invoke kernel operations inordertoperform therequested operation successfully. The
rightsamplification technique of Hydra solves this problemby giving a rights template to
objectmanagers that gives them more rights to an objectthan thecapability itselfallows.
Additional rights given to the object managers allow them to performkerneloperations on
the objects.
When aprocessPinvokes an operation r on anobject0,thecapability Csupplied
byPmay getamplified toCawhen the objectmanagerMstartsperforming theoperation
r on the object. This may be necessary in order to allow Mto access the storage segment
representing 0forperforming operation r on it. That is, Mis allowed to performkernel
operations on0directly, even though the calling processPcannot. After completion ofthe
operation ron0,thecapability Cafor0isrestoredto its original, unamplified state C.
This is a typical case in which the rights held by a processfor access to a protected
segment mustchangedynamically, depending on the task to be performed.
Notice that in the rights amplification scheme, the objectmanagers are treated as
"trustworthy" procedures and are allowed to performkerneloperations on the objects of
aspecified type, onbehalfof any process that holds an auxiliary right for an objectofthat
type.Therefore, the rights held by an object manager areindependent of and normally
exceedthe rights held by the subjects that access the object. However, an object manager
is not auniversally trustworthy procedure because it is not allowedto act on other types
of objects and cannotextendits rights to any other procedure.
RightsRevocation. In a security system based on ACLs, revocation of rights is
easybecausefor a given objectit ispossible to easily and efficiently determine which
subjects have what rights for the object. However, in a security system based on
capabilities, revocation of rights is a much more difficult problem because for a given
object it is difficulttodetermine which subjects have what rights for the object. This is
becausethecapabilities for an object may be stored in several capability lists that are
distributed throughout the system, and we must first find them before we can revoke them.
Somecommonly used methods for implementing revocation forcapabilities aredescribed
below.
1.Backpointers. One way is to keep track of all the capabilities for an object and
tochange/delete themselectively depending on the desired revocation of access rights. A
simplemethodto keep track ofall thecapabilities for anobjectis tomaintain a list of
pointers with the object, pointing to allcapabilities associated with the object. This
methodhas been used in the Multics system. The method is quite general but very costly
toimplement.
2.Indirection. Another approach is to use indirectaddressing. In this method each
capability points to an indirectobject(such as a table entry) rather than to the objectitself.
Theindirectobjectin turn points to the real object. Revocation isimplemented bydeleting
theindirectobjectto break the connection between the realobjectand thecapabilities for
it. When an access is attempted with acapability whoseindirectobject has been deleted,622 Chap. 11 • Security
access operation fails because the real object is unknown due to the broken connection. A
drawback of this method is that it does not allow selective revocation.
3. Useofkeys.In this method, in addition to the object identifier and rights
information fields, each capability has a field that contains a unique bit pattern. The
contents of this field is called a "key." A capability's key is defined when the capability
iscreatedand itcannot bemodified or inspected by aprocess owning that capability. Each
object has a masterkeyassociated with it that can bedynamically defined or changed with
a special set_keyoperation. Normally, only the owner of an object is given the right to
invoke the set_keyoperation for changing the master key of the object.
When a new capability for an object is created, the key field ofthecapability is set
to the current master key for the object. When an access isattempted with a capability, the
capability's key iscompared to the master key of thecorresponding object. If the two keys
match, access to the object is allowed; otherwise, a protection violation occurs.
Revocation involvesreplacement of the master key with a new value by using the set_key
operation, invalidating all previous capabilities for this object.
This revocation scheme is used in Amoeba, in which random numbers are used as
keys. A drawback ofthis scheme is that it does not allow selective revocation, since only
one master key is associated with each object. However, this drawback can be overcome
by associating a list of keys with each object.
HybridApproach
As compared to the capability-based scheme, thescheme based on ACLs is more suited
to theimplementation of security systems because ACLs correspond directly to the needs
of the users. When users create objects, they can specify which domains can access the
objects as well as the operations allowed. However, we saw that a security system based
on ACLs is normally less efficient than capability-based security systems because of the
need to search the access Jist on every access. To overcome the drawbacks of the two
schemes and to combine their advantages, most systems use a hybrid approach for
designing their security system.
In the hybrid approach, both ACLs and capabilities are employed along with the
concept of a session. A sessionis a logical concept of a period during which a process
accesses an object. When a process first tries to start a session for accessing an object,
itspecifies the access modes (types of operations) that it may perform on the object
during the session. The ACL of the object is searched for the types of operations
desired. If access is denied, a protection violation occurs. Otherwise, the system
creates a new capability for the object and attaches it to the process. After this, all
accesses to the object by this process during the session are made using the capability
so that an access control check can be performed efficiently. After the session is over,
thecapability is destroyed.
The UNIX file system employs this scheme, with a session being the period between
theopenandcloseoperations of a file by a process. Each file has an associated ACL.
When a process opens a file, its ACL ischecked for the mode specified in the open
command. If access in the specified mode is permitted, a new entry is allocated in a fileSec. 11.6• DigitalSignatures 623
table, the access mode is recorded in this entry, and an index to this entry is returned to
the process. All subsequent operations on the file are made by this process by specifying
the index into the file table. The entry in the file table points to the file. When the process
executes thecloseoperation on the file, the session is closedbydeleting the file table
entry. A new sessionmust be started after this if the process wants to access the same file
at some later time.
The file table is maintained by theoperating system, so that it cannotbecorrupted
by the user. Security isensuredbecause access is validated at the time a session is started
and a process can access only those files for which a session has been started but not yet
closed.
11.6DIGITALSIGNATURES
Message integrity, which guarantees that thecontents of a message were not changed
when it was in transfer, is also an important securityrequirement in adistributed system.
Theconceptof digital signature, which is based upon asymmetric cryptosystems, is the
mostcommonly used method to handle this issue.
Recall that in an asymmetric cryptosystem the secret key of a user is known only to
that user and no one else. Therefore, the sender of a message can use its secret key for
signing the message byencrypting itwith the key.That is, the sendercan uniquely "seal"
themessage with his or her own signature (secret key). The sealed message can be sent
to anyone with the corresponding public key. Using digital signatures assures the receiver
of themessage not only that the message contenthas not been manipulated but also that
themessage was indeed sent by the claimedsender. Thus, digital signatures areapplicable
to both user authentication and message integrity.
Adigitalsignature is basically a code, or a large number, that is unique for each
message and to each message originator. It is obtained byfirstprocessing the message
with a hash function (called a digestfunction) to obtain a small digest dependent on each
bit ofinformation in the message and then encrypting the digest by using the originator's
secret key.To avoid duplicity problems, a digest function (D)must have the property that
D(M)isdifferent fromD(M')for all possible pairs of MandM'.Rivest [1992] proposed
amessage digest function (known as ,WD5)for use in secure mail and other applications
on the Internet.
Toillustrate how the digest of a message can be obtained from the message, the
example given in [Adam 1992] is presented here. In this example, itisassumed that a
message is a digital string of O'sand I'8and is divided into blocks of64bits. The bitwise
Exclusive-OR of the first two blocks is performed to obtain a new block of 64 bits. The
newlyobtained block is again Exclusive-ORed with the third block of the message, again
resulting in a new block of 64 bits. This process is continued one by one with all the other
blocks of the message. The end result is a 64-bit digest that depends on each bit of data
in the whole message stream. In other words, to alter the message, even by 1 bit, would
alter the 64-bitdigest. Moreover, it should beessentially impossible to forge a message
that would result in the same digest.624 Chap.11•Security
Aprotocol based on a digital signature for ensuring message integrity works as
follows:
1. Asender(A)computes the digest (D)ofamessage(M).It thenencrypts the digest
D by using its secret key (Sa)toobtainaciphertext Cl=E(D, Sa). Asignedmessage is
thencreatedthatconsistsofthesender's identifier, the message Min itsplaintext form,
and theciphertext C,.The signed message, which has the form (IDa'CJ,M),is then sent
to a receiver.
2. Onreceiving the signed message, the receiverdecrypts Clby using the public key
ofthesendertorecoverthedigestD.It thencalculates a digest for M(by using the same
digestfunction) andcompares thecalculated digest· with the digestrecovered by
decrypting Cl'Ifthe two are equal, messageMisconsidered to becorrect;otherwise it
isconsidered incorrect.
Noticethat the protocol does not require a message to be hidden from unauthorized
users. Rather, it allows a message toberead openly byanyone who receivesorintercepts
it. But a forged message issuccessfully detected by the protocol.
Anapplication may require that the first receiverretransmit thesignedmessage to
anotherreceiver, which may have to subsequently retransmit it tootherreceivers. In
such asituation, it isimportant that each oftherecipients should be able to verify that
thesignedmessage indeedoriginated from the claimedoriginator and that its contents
were not changed by anyoftheintermediate recipients or by an intruder. Adigitally
signedmessage meetstheserequirements because it has the originator's identifier
included in it and the digest ofthe message can only be decrypted by using the
originator's public key.
In the actual implementation, a keydistribution server may be used that maintains a
database ofthe public keys ofall users. If the receiverofa digitally signed message does
not already have the public key ofthemessage originator, it can requestit from the key
distribution server. This avoids the need to send a new user'spublic key to all other user's
inthesystem. The new user'spublic key can be simply registered with the key distribution
server.
Privacy Enhanced Mail(PEM)scheme, designed for adding privacy to Internet
mailapplications, is a good example ofuseofcryptography and digital signature
techniques. PEMoffersconfidentiality, authentication, andmessage integrity. These
features are intended toprovide sufficient trust so that the general Internet user
population willfeelcomfortable using the Internet forbusiness correspondence and
sendingmessages thatcontainsensitive information. PEMiscompletely implemented
at theapplication level by end systemsso that it can be incorporated on asite-by-site
oruser-by-user basis. This approach imposes no special requirements on message
transfersystems atintermediate relaysites orendpoints. That is, network routers and
mail relays treat PEMmessages as anordinary piece of mail. How PEMprovides
privacytoelectronic mails is briefly described below. Readers interested in its detail
description may refer to [Linn 1993, Kent 1993b, Balenson 1993, Kaliski 1993, Kent
1993a].Sec.11.6•DigitalSignatures 625
PEM assumes that the network is not trusted but that each user of PEM trusts his or
her own local computer. Mail users obtain a public/secret key pair from a local PEM
program and publish their public keys with their mail addresses. The PEM program
maintains a database of the secret keys of its local users and the public keys of remote
users. Currently, the Rivest-Shamir-Adleman (RSA)algorithm is used to generate the
public/secret key pairs for users. PEMprovides the following types of facilities:
1.Confidentiality. Sending a message in encrypted form so that sensitive
information within it cannot be read by an int.ruder.
2. Message integrity. Sending a signed message so that the receiver can be ensured
that thecontents of the message were not changed.
Both facilities also possess an authentication feature because the encryption and
decryption of the message or the digital signature can only be done by a user having the
proper key.
Let us first see how PEMsends a secret message (M)for ensuring confidentiality:
I.ThePEMprogram of the sender'scomputer first generates a random secret key
(K)and encrypts the message (M)by using this key to obtain a ciphertext C.=E(M, K).
Currently, the DES algorithm is used for this purpose, but others may as well be used in
the future. The secret key (K)is thenencrypted by using the recipient's public key (say,
Pr)to obtain a ciphertext C2=E(K, Pr).NowC.andC2are sent to the recipient in a
message mI'
2. On receiving m.,the PEM program of the recipient's computer fetches the
recipient's secret key (Sr)from its database and decrypts C 2by usingS,to obtain K.Now
by usingK,it decrypts C Itoobtain the original message M,which it then stores in the
recipient's mailbox.
Notice that the PEM scheme retains the efficiency of symmetric cryptography for the
bulkencryption but avoids the need for a secure key distribution server.
Now let us see how PEM sends a signed message (M)for ensuring message
integrity:
1. The PEM program of the sender's computer computes the digest (D)of the
message(M)by using a message digest function. The digest (D)is thenencrypted by
using the sender'ssecret key (Ss)to obtain a ciphertext C1=(D, Ss).Thesender'sID, C1,
and M are then sent to the recipient in a message m.,
2. On receiving mi ,the PEM program of the recipient's computer fetches the
sender'spublic key (Ps)from its database and uses it to decrypt C1to obtain the digest D.
It then applies the same message digest function to Mandcompares the result with D.If
the two are equal, message Misconsidered to be correct; otherwise it is considered
incorrect. The message Mis then stored in the recipient's mailbox with a proper note from
the PEM program's side about the result of its integrity check.626
11.7DESIGNPRINCIPlESChap.11•Security
Based on their experience with Multics, Saltzer, and Schroeder [1975] identified some
design principles that can be used as a guide to designing secure systems. Although these
design principles were proposed for centralized systems, they hold good for distributed
systems as well [Kent 1981]. These and some other design principles are summarized
below. Designers of security components of a distributed operating system should use
them as basic guidelines.
1. Leastprivilege. The principle of least privilege (also known as the need-to-know
principle) states that any process should begiven only those access rights that enable it to
access, at any time, what it needs to accomplish its function and nothing more and nothing
less. That is, the security system must beflexible enough to allow the access rights of a
process to grow and shrink with its changing access requirements. This principle serves to
limit the damage when a system'ssecurity is broken. For example, if an editor isgiven the
right to access only the file that has to be edited, even if the editor has a Trojan horse, it
will not be able to access other files of the user and hence cannot do much damage.
2. Fail-safe defaults. Access rights should be acquired by explicit permission only
and the default should beno access. This principle requires that access control decisions
should be based on why an object should be accessible to a process rather than on why it
should not be accessible.
3. Open design. This principle requires that the design of the security mechanisms
should not be secret but should be public. It is a mistake on the part of a designer to
assume that the intruders will not know how the security mechanism of the system
works.
4. Built in to the system. This principle requires that security be designed into the
systems at their inception and be built in to the lowest layers of the systems. That is,security should not be treated as an add-on feature because security problems cannot be
resolved very effectively by patching the penetration holes detected in an existing
system.
5. Check for current authority. This principle requires that every access to every
object must be checked using an access control database for authority. This is necessary
to have immediate effect of revocation of previously given access rights. For instance, in
some file systems, a check for access permission is made only when a file is opened and
subsequent accesses tothe file are allowed without any check. Inthese systems, a user can
keep a file open for several days and continue to have access to its contents, even if the
owner of the file changes the access permission and revokes the user'sright to access its
contents.
6. Easy granting and revocation ofaccess rights. For greater flexibility, a security
system must allow access rights for an object to be granted or revoked dynamically.
It should bepossible to restrict some of the rights and to grant to a user only those
rights that are sufficient to accomplish its functions. On the other hand, a good securitySec. 11.8 • Case Study: DeESecurity Service 627
systemshouldallowimmediate revocation with the flexibility ofselective andpartial
revocation. Withselective revocation facility, it is possible torevokeaccessrightsto
anobjectonly from a selected groupofusersratherthan from all users who posses
accessrightsfor theobject.And with partialrevocation facility, only a subsetofthe
rightsgrantedto a user for an objectcan berevoked insteadofalwaysrevoking all its
rights for the object.
7.Nevertrustotherparties.Forproducing asecuredistributed system,thesystem
components must bedesigned with theassumption thatotherparties(peopleorprograms)
are nottrustworthy until they are demonstrated to betrustworthy. Forexample, clientsand
serversmustalwaysbedesigned to vieweachotherwithmutualsuspicion.
8.Alwaysensurefreshness ofmessages. To avoid security violations throughthe
replay of messages, thesecurityof adistributed systemmustbedesigned to always ensure
freshness ofmessages exchanged between twocommunicating entities.
9. Buildfirewalls. To limit the damagein case a system's securityiscompromised,
thesystemmust have firewalls builtinto it. One way to meet this requirement is to allow
onlyshort-lived passwords and keys in the system.Forexample, asharedsecretkey used
to build a logicalcommunication channelbetween aclientand aservershouldbe fairly
short-lived, perhapsbeingchanged witheverycommunication sessionbetween them.
10.Efficient, Thesecuritymechanisms usedmustexecuteefficiently and besimple
toimplement.
11.Convenient to use.To bepsychologically acceptable, the security mechanisms
must beconvenient to use.Otherwise, they are likely to be bypassed orincorrectly used
by the users.
12.Cost effective. It is often the case that securityneeds to be traded offwithother
goals of the system,such as performance or easeofuse.Therefore, indesigning the
securityof asystem,it isimportant tocomeup with t.heright set of trade-offs that take
intoaccountthelikelihood that thesystemwill becompromised with the cost of providing
the security, both in terms of money and personnel experience.
11.8CASESTUDY:DCESECURITY SERVICE
As acasestudyofhow the various securit.y concepts described in thischaptercan be
integrated toprovidesecurity in a single system,theDCESecurity Serviceisbriefly
described below.
InDeE,a user or a process(clientorserver)that needs to communicate securely is
calledaprincipal. Forconvenience ofaccesscontrol,principals areassigned membership
in one or more groupsandorganizations. Allprincipals of the same group or organization
have the same access rights. Groupsgenerally correspond to work groups or departments,
andorganizations typically includemultiple groupshavingsomecommon properties.
Typically, a principal is amember of oneorganization but may simultaneously be a
member ofmultiple groups.Eachprincipal has auniqueidentifier associated with it.628 Chap.II•Security
Together, a principal's identifier, group, and organization membership are known as the
principal's privilege attributes.
The main components of the DCE Security Service for a single cell are shown in
Figure 11.21. These components collectively provide authentication, authorization,
message integrity, and security administration services. Let us consider these services one
by one.
Security server node
Client nodePhysically
protected
Administrato r
Application server node
Fig. 11.21 Main components of DeESecurity Service for a single cell.
11.8.1Ruth.ntlcatlon InDCE
The DCE authentication service usesthe Kerberos system described inSection 11.4.5.The
authentication server,ticket-granting server, and authentication database of Kerberos are
respectively called authentication server, privilege server, and registry database in DCE.
The information registered in theregistry database includes each principal's secret key and
privilege attributes. The protocols for authenticating a user at the time of login and for
mutualauthentication of aclient and aserver arethe same asthatof Kerberos (the intercell
client-server authentication protocol in DCE is the same as the interrealm authentication
protocol of Kerberos).The only difference is that the service-granting ticket in DCE also
contains the group and organization membership information of aclient. This information
is used by the application server to verify the access rights of the client before providing
the requested service.Sec. 11.8 • Case Study: DCE Security Service 629
Theestablishment of a secure logical communication channel between a client and
a server by using the authentication protocol isknown as authenticated RPCinDeE.This
is because in DeEclients and servers communicate by using RPCs. Once authenticated
RPC has been established, it is up to the client and the server to determine how much
security is desired. That is, subsequent RPC messages mayormay not be encrypted
depending on the security needs of the application.
11.8.2Authorization inDCE
Authorization in DCE is based on ACLs. Associated with each application ·serveris an
ACL and an ACL manager. The ACL contains complete information about which
principals have what rights for the resources managed by the server. When a client's
request comes to the server, it extracts the client ~s ID and its group and organization
membership information from the received encrypted ticket. It then passes the client'sID,
membership, and the operation desired to the ACL manager. Using this information, the
ACL manager checks theACL to make adecision if theclient isauthorized to perform the
requested operation. It returns an access granted or denied reply to the server, after which
the server acts accordingly.
Note that in DCE groups are effective only within cells. Therefore, a principal
belonging to adifferent cell can begranted access based solely on its unique identifier, not
on group membership. That is,if access is to be granted to principals of remote cells, their
unique identifiers have to be entered in the ACL along with the access rights.
11.8.3Message IntegrityIn DCE
As already mentioned above, once authenticated RPC has been established, it is up to the
client and server to determine how much security is desired. Therefore, if message
integrity is desired, it can be ensured by the use of a digital signature technique. That is,
applications can ensure data integrity by including anencrypted digest of the message data
passed between clients and servers. The digest must be encrypted and decrypted by using
the session key that a client and a server share for secure communication between
them.
11.8.4S8curltyAdministration inDeE
The administrator, registry server, and ACL manager jointly perform security administra­
tion tasks. Two programs are used by the administrator for performing administration
tasks. One is the registry editor program and the other is the ACL editor program.
The registry editor program may be used by the system administrator to view, add,
delete, and modify information inthe registry database. Even system administrators do not
have direct access to the registry database, and they access the registry database only by
making requests to the registry server. This is much safer, for although an administrator
can change any password, he or she cannot obtain the password of any user.
On the other hand, the ACL editor program may be used by an application
administrator to view, add, delete, and modify entries in ACLs for applications or ACLs630 Chap.11•Security
for objects (resources) controlled by them. Once again, all requests for updates to ACLs
are sent to the ACL manager and not performed directly on ACLs.
In DCE, system administrators use organization membership to apply global security
policies, such as deciding the lifetime of tickets and passwords of different principals. For
example, the lifetime of tickets and passwords is kept smaller for principals of an
organization that handles highly sensitive information as compared to the lifetime of
tickets and passwords of principals of an organization that does not handle sensitive
information.
11.9SUMMARY
Computer security deals with protecting the various resources and information of a
computer system against destruction and unauthorized access. The main goals of
computer security are secrecy, privacy, authenticity, and integrity.
A total approach to computer security involves both external and internal security.
The three main aspects of internal security in distributed systems are authentication,
access control, and communication security.
An intruder is a person or program that tries to obtain unauthorized access to data or
aresource of a computer system.An intruder may bea threat to computer security in many
ways that are broadly classified into two categories-passive attacks and active attacks.
In passive attacks, an intruder somehow tries to steal unauthorized information from the
computer system without interfering with the normal functioning of the system. Some
commonly used methods of passive attack are browsing, leaking, inferencing, and
masquerading. On the other hand, active attacks interfere with the normal functioning of
the system and often have damaging effects. Some commonly used forms of active attacks
are viruses, worms, and logic bombs. Active attacks associated with message
communications are integrity attack, authenticity attack, denial attack, delay attack, and
replay attack.
Three kinds of channels that can be used by a program to leak information are
legitimate channels, storage channels, and convert channels. The confinement problem
deals with the problem of eliminating every means by which an authorized subject can
release any information contained in the object to whichit has access to some subjects that
are not authorized to access that information. The confinement problem is in general
unsolvable.
Cryptography is a means of protecting private information againstunauthorized
access in those situations where it is difficult to provide physical security. There are two
broad classes of cryptosystems-symmetric and asymmetric. When cryptography is
employed for secure communications in distributed systems, a need for key distribution
arises. The mechanisms and protocols for key distribution in symmetric and asymmetric
cryptosystems have been described in the chapter.
Anauthentication mechanism prohibits the useof the system (or some resource of the
system) by unauthorized users by verifying the identity of a user making a request. The
main types of authentication normally needed in a distributed system are user login
authentication, one-way authentication of communicating entities, and two-way authenti-Chap. 11 • Exercises 631
cation of communicating entities. The three basic approaches to authentication areproof
by knowledge, proofby possession, and proofbyproperty. The proof-by-knowledge
method based on passwords is the most widely used method for user login authentication.
For one-way and two-way authentication of communicating entities, the protocols based
oncryptosystems have been described in the chapter.The Kerberos authentication system
has also been described as a case study.
Access control deals with the ways that are used in a computer system to prohibit a
user (or a process) from accessing those resources/information that he or she is not
authorized to access. The three access control models proposed in the literature are the
access matrix model, the information flow control model, and the security kernel model.
Of these, the access matrix model is the most popular one and is widely used in existing
centralized and distributed systems.
In the access matrix model, the access rights of each subject to each object are
defined as entries ina matrix, called the access matrix. The two most widely used methods
that have gained popularity in contemporary distributed systems for implementing an
access matrix are ACLs and capabilities.
The concept of digital signatures, which is based upon asymmetric cryptosystems, is
the most commonly used method to handle the issue of message integrity in distributed
systems.
Some design principles that can be used as a guide to designing secure systems are
least privilege, fail-safe defaults, open design, security built into the system, checking for
current authority, easy to grant and revoke access rights, not to trust other parties, always
ensuring freshness of messages, building of firewalls, cost effective, efficient, convenient
to use, and right set of trade-offs.
EXERCISES
11.1. List some of the common goals of computer security.
11.2. What are the additional security problems that a distributed operating systemdesigner must
deal with as compared to the designer of an operating system for a centralized time-sharing
system? Can we ensure the same degree of security in a distributed system as we have in a
centralized time-sharing system? Give reasons for your answer.
11.3. What is the "need-to-know" principle in computer security? Think of some security problems
that may occur if this principle is not taken care of in the design of the security component
of acomputer system.
11.4.Differentiate between passive and active attacks. Which of the two is more harmful and
why?
11.5.What are some of the commonly used methods for passive attack? Comment on the relative
complexity of each of these methods from the point of view of the following:
(a) Anintruder
(b) Thedesigner of a security system
11.6. What is aTrojan horse program? Give anexample (inpseudocode) of both a passive type and
an active type Trojan horse program.632 Chap.11• Security
11.7. List necessaryprecautionsfor preventingacomputersystemfromvirusinfection.Howcan
an already infected computer system be cured of virus infection? Why is curing of a
distributed system from virus infection much more difficult than curing a centralized
system?
11.8. List the important differences between computer viruses and worms. How do they each
reproduce?Asecuritysystemistobedesignedthatpreventsvirusprogramsfromreplicating
in an uncontrolledmannerbut allowswormprogramsto berun.Suggesta suitablesecurity
schemefor this.
11.9. Whatarethecommontypesof activeattacksassociatedwithmessagecommunicationsin a
distributedsystem?Commenton therelativecomplexitiesofthesetypesofattacksfromthe
point of viewof the following:
(a) An intruder
(b) The designerof the securitysystemof a distributedsystem
11.10. What is a nonce?Give examplesof some itemsthat can be used as a nonce.
11.11. Whatisaconfinementproblemincomputersecurity?Explainwhythisproblemisingeneral
unsolvable.
11.12. List the different types of channels that may beused by a program to leak information.
Explainhowthesechannelsareusedtoleak information. Isitpossibletototallypreventthe
leakageof information?
11.13. Discusstherelativecomplexityofdesigningthesecuritycomponentofa systemthatallows
onlydataobjectstobesharedandasystemthatallowsbothdataobjectsandprogramobjects
tobeshared.
11.14. What is cryptography?What are someof its common usesin a distributedsystem?
11.15. What are some of the basic requirementsthata goodcryptosystemmust fulfill?
11.16. Differentiate among ciphertext-only, known-plaintext, and chosen-plaintext attacks with
respect to a cryptosystem.
11.17. Explain how symmetric and asymmetric cryptosystems work. Discuss their relative
advantagesand disadvantages. Whichof the twois moresuitableforeach of the following
cases (give reasons for your answer):
(a) Where both encryption and decryption of information are performed by a trusted
subsystem
(b) Wheredifferentsubjectsperformtheencryptionand decryptionof information
(c) Where bulkdata encryptionis involved
(d) For establishing connection between two communicating entities in a distributed
system
(e) For exchange of messages between two communicating entities in a distributed
system
11.18. What is a key distribution problem? How does itdiffer for symmetric and asymmetric
cryptosystems?
11.19. Describetwomethodsforsolvingthekeydistributionproblemforasymmetric cryptosystem
and discusstheir relativeadvantagesand disadvantages.Chap. 11 • Exercises 633
11.20.Describe a method for solving the key distribution problem for an asymmetric crypto­
system.
11.21.What are the commonly usedapproaches for user authentication incomputer systems?
Explain how a user is authenticated in each of these approaches.
11.22.Explain the password-based approach for user logins authentication. What are the problems
associated with this approach? Suggestsolutions to overcome these problems.
11.23.In adistributed system it is desired that a server process should serve any client that needs
its service only after verifying the identity of the client. Describe how to implement this
authentication requirement.
11.24.In the preceding exercise, suppose that both the clientand the server should verify each
other'sauthenticity before acommunication session can be started between them. Describe
how toimplement thisauthentication requirement.
11.25.Thepassword mechanism is used in a distributed system to authenticate users at login time.
State the most suitable locations (according to you) for storing the login program and the
password file in the following cases:
(a) Thedistributed system is based on the workstation-server model with each workstation
having a small hard disk of about 20 megabytes capacity.
(b) The distributed system is based on the workstation-server model. Some of the
workstations are diskless and others have a small hard disk of about 20 megabytes
capacity.
(c) Thedistributed system is based on the processor-pool model.
Assume that any user is free to use any of the user terminals or workstations.
11.26.What is an access matrix? Explain how the following issues can be handled in a security
system that uses access matrix for access control:
(a)Deciding the contents of the access matrix entries
(b) Validating access to objects by subjects
(c) Allowing subjects to switch domains in a controlled manner
11.27. What are the commonly used methods for implementing an access matrix? Explain their
relativeadvantages anddisadvantages.
11.28.What is a domain? State three different ways in which domains can be realized in the design
of the security component of anoperating system and explain how domain switching will be
done in each case. Explain how domains are formed and how domain switching takes place
in UNIX and Multics operating systems.
11.29. What is a capability? Answer the following questions for acapability-based security
system:
(a) When a subject accesses an object, how is the validation check made whether the subject
is allowed to access the object in the requested mode?
(b) How does a subject get a capability for an object? Consider both the case in which the
subject is the ownerof the object and another one in which the subject is not the owner
of the object.
(c) The owner of an object wants to share the object with another subject allowing it
restricted access rights to the object. How can this bemade possible?
(d) How can it be ensured that a capability is never reused for identifying some other object
in the system?
(e) How can capabilities be protected against unauthorized access?
(t)How can capabilities be made difficult to guess?
(g) How can capabilities be made difficult to forge?
(h) How can selective revocation of capabilities beperformed?634 Chap. I1 • Security
11.30.Answerthe following questions for anACL-based security system:
(a)When a subject accesses an object, how is the validation check made whetherthe subject
is allowed to access the object in the requested mode?
(b) How is access right for an object granted to a subject?
(c) The ownerofanobjectwants to share the object with anothersubject allowing it
restricted access rights to the object. How can this bemadepossible?
(d) How are ACLs protected against user tampering?
(e) How can an access right given to a subject berevoked?
11.31. In a distributed system, it is desired that servers should check the access right of clients for
every access request made. Explain how can this be implemented by using the following:
(a) Only ACLs
(b) Only capabilities
(c) Both ACLs and capabilities
Which approach is preferable and why?
11.32. A distributed operating system uses the ACL-based access control mechanism but does not
use the negative rights concept. What type of access control activity is difficult to perform
in this system? Why is this difficulty not faced in a centralized system that uses the ACL­
based access control mechanism?
11.33. A system has a large numberof users. In this system, it is desired that a file be accessible
to all except five users. Describe how this security requirement can be specified:
(a)If the system uses the ACL-based security scheme without negative rights facility
(b) If the system uses the ACL-based security scheme with negative rights facility
(c) If the system uses the capability-based security scheme
11.34. What is a digital signature? What are its uses in the security of a distributed system? Give
a method to create a digital signature. Describe how digital signature can be used for
ensuring message integrity in a distributed system.
11.35. What are the important design principles that should normally be used as a guideline to
designing securecomputer systems? Explain why these design principles are important.
BIBLIOGRAPHY
[Abrams et al,1995] Abrams, M.D.,Podell,H.J.,and Jajodia, S. (Eds.), Information Security: An
Integrated Collection ofEssays,IEEEComputer Society Press, Los Alamitos, CA (1995).
[Adam1992] Adam, 1. A.,"Cryptography =privacy," IEEE Spectrum, pp.29-35(August
1992).
[Ak11983] Akl,S.G.,"Digital Signatures: ATutorial Survey," IEEE Computer, Vol.16,No.2,pp.
15-24(1983).
[Ames et al, 1983] Ames, S. R.,Gasser,M.,and Schell, R. R.,"Security Kernel Design and
Implementation: AnIntroduction," IEEE Computer, Vol.16,No.7,pp.14-22(1983).
[Amoroso 1994] Amoroso, E., Fundamentals ofComputer Security Technology, Prentice-Hall,
Englewood Cliffs, NJ (1994).Chap. 11 • Bibliography 635
[Anderson 1994]Anderson, R.1.,"WhyCryptosystems Fail,"Communications oftheACM,Vol.
37, No.11,pp.32-40(1994).
[Balenson 1993]Balenson, D. M.,"Privacy Enhancement forInternetElectronic Mail.Algorithms,
Modes,andIdentifiers," InternetRFC1423 (Part 3)(1993).
[Baueret al. 1983] Bauer, R. K., Berson,T. A., and Feirtag,R. 1., "A Key Distribution Protocol
UsingEventMarkers," ACMTransactions onComputer Systems, Vol.1,No.3,pp.249-255
(1983).
[Bell and LaPadula 1973] Bell, D. E., and LaPadula, L. 1.,"Secure Computer Systems:
Mathematical Foundations," ESD-TR-278, I,ESO/AFSC, Hanscom AFB,Bedford, MA
(1973).
[Bellovinand Cheswick 1994]Bellovin, S. M., and Cheswick, W. R.,"Network Pirewalls," IEEE
Communications Magazine, pp.50-57(September 1994).
[Bellovin and Merritt 1990]Bellovin, S.M.,andMerritt, M., "Limitations of theKerberos
Authentication System," ACMComputer Communications Review,Vol. 20,No.5,pp.119-132
(1990).
[Bowlesand Pelaez ]992]Bowles,1.B., andPelaez,C. E.,"BadCode,"IEEESpectrum, pp.36-40
(August 1992).
[Bright1977]Bright,H. S.,"Cryptanalytic AttackandDefense: Ciphertext-Only, Known-Plaintext,
Chosen-Plaintext," Cryptolog ia,Vol.I,No.4,pp.366-370 (1977).
[Brown1994]Brown,P.W.,"DigitalSignatures: AreTheyLegal for Electronic Commerce?" IEEE
Communications Magazine, pp.76--80(September 1994).
[Burrows etal,1990]Burrows, M., Abadi, M., and Needham, R. M., "A Logic of Authentication,"
ACMTransactions onComputer Systems, Vol. 8,No.1,pp.18-36(1990).
[Champine etal,1990)Champine, G. A., Geer, Jr., D. E., and Ruh, W. N., "Project Athenaas a
Distributed Computer System," IEEEComputer, Vol. 23,No.9,pp.40-51(1990).
[Chess 1989J Chess,D. M.,"Computer Viruses and RelatedThreatstoComputer andNetwork
Integrity," Computer Networks andISDNSystems, Vol. 17, pp. 141-148 (1989).
[Clarkand HotTman 1994]Clark,P. C., and Hoffman, L. J.,"BITS:ASmartcard Protected
Operating System," Communications oftheACM,Vol. 37, No. 11,pp.66-70(1994).
[Cohen1987]Cohen,F.,"Computer Viruses: TheoryandExperiments," Computers andSecurity,
Vol.6,pp.22-35(1987).
[Cohen and Jefferson 1975]Cohen,E., andJefferson, D.,"Protection in theHydraOperating
System," In:Proceedings ofthe5hACMSymposium onOperating Systems Principles,
Association forComputing Machinery, New York, NY, pp. 141-160 (November 1975).
[Dannenberg andHibbard 1985]Dannenberg, R. B., and Hibbard, P. G., "A ButlerProcessfor
Resource SharingonSpiceMachines," ACMTransactions on Office Information Systems, Vol.3,
No.3,pp.234-252 (1985).
[Denning 1976]Denning, D. E., "A LatticeModel for SecureInformation Flow,"Communications
oftheACM,Vol. 19,No.5,pp.236-243 (1976).
[Denning and Sacco 1981]Denning, D. E., and Sacco,G. M.,"Timestamps in KeyDistribution
Protocols," Communications oftheACM,Vol. 24,No.8,pp.533-536 (1981).
[Dolevand Yao 1983]Dolev, D., and Yao,A. C., ,,'Onthe SecurityofPublicKeyProtocols," IEEE
Transactions onInformation Theory,Vol. IT-30, No.2,pp.198-208 (1983).636 Chap. 11 • Security
[Ganesan and Sandhu 1994] Ganesan, R., andSandhu, R.,"Securing Cyberspace," Communica­
tionsoftheACM, Vol. 37, No. 11,pp.29-11(1994).
[Glasgow et al. 1992] Glasgow, J., McEwan, G., andPananageden, P., "ALogicforReasoning
aboutSecurity," ACMTransactions on Computer Systems, Vol. 10, No.3,pp.265-310
(1992).
[Graham and Denning 1972] Graham, G. S., and Denning, P. J.,"Protection-Principles and
Practice," In:AFIPSProceedings ofthe Spring Joint Computer Conference, Vol.40, pp. 417-429
(1972).
[Harrison et al.1976]Harrison, M.A.,Ruzzo,W.L., and Ullman, J. D., "Protection inOperating
Systems," Communications ofthe ACM, Vol. 19,No.8,pp.461-471 (1976).
[Hellman 1978]Hellman,M.E., "AnOverview ofPublic-Key Cryptography," IEEE Transactions
on Computers, Vol. C-16, No.6,pp.24-32(1978).
[Hendry 1995] Hendry,M.,Practical Computer Network Security, ArtechHouse,Boston,MA
(1995).
[Hruska 1993]Hruska, J.,Computer Viruses and Anti-Virus Warfare, 2nd ed., Prentice-Hall,
Englewood Cliffs, NJ (1993).
[Hu1995] Hu, W., DeESecurity Programming, O'Reilly, Sebastopol, CA (1995).
[Huttetal.1995]Hutt, A. E., Bosworth, S., and Hoyt, D. B. (Eds.), Computer Security Handbook,
3rd ed., Wiley, New York, NY (1995).
[Kak1983]Kak, S.C.,"DataSecurity inComputer Networks," IEEE Computer, Vol. 16,No.2,pp.
8-10(1983).
[Kaliski 1993]Kaliski,B. S.,"Privacy Enhancement forInternetElectronic Mail. Key Certification
andRelatedServices," InternetRFC1424 (Part 4) (1993).
[Kehne et al,1992]Kehne,A.,Schonwalder, J., andLangenderfer, H.,"ANonce-Based Protocol
forMultiple Authentications," ACMOperating System Review, Vol. 26, No.4,pp.84-89
(1992).
[Kent 1981] Kent, S.T.,"Security inComputer Networks," Protocols and Techniquesfor Data
Communication Networks" Prentice-Hall, Englewood Cliffs, NJ, pp. 369-432 (1981).
[Kent 1993a] Kent, S.T.,"Internet PrivacyEnhanced Mail,"Communications oftheACM, Vol.36,
No.8,pp.48-60(1993).
[Kent 1993b] Kent, S.T.,"Privacy Enhancement forInternetElectronic Mail.Certificate Based
KeyManagement," InternetRFC1422(Part 2) (1993).
[Khanna 1994JKhanna, R. (Ed.), Distributed Computing: Implementation and Management
Strategies, Prentice-Hall, Englewood Cliffs, NJ (1994).
[Kluepfel 1994] Kluepfel, H. M., "Securing aGlobalVillage and Its Resources," IEEE
Communications Magazine, pp.82-89(September 1994).
[Lampson 1971] Lampson, B. W.,"Protection," In:Proceedings ofthe5th Princeton Symposium on
Information Sciences and Systems, Princeton University, Princeton, NJ, pp.437-443 (March
1971).
[Lampson 1973] Lampson, B. W., "A Note on the Confinement Problem," Communications ofthe
ACM,Vol. 6, No. 10, pp. 613-615 (1973).Chap. 11 • Bibliography 637
[Lampson 1993JLampson, B.W.,"Authentication inDistributed Systems," In: S.Mullender (Ed.),
Distributed Systems, 2nd ed., Association forComputing Machinery, New York, NY, pp.
543-580(1993).
[Lampson etal,1992]Lampson, B. W.,Abadi,M.,Burrows,M.,and Wobber, E., "Authentication
inDistributed Systems: TheoryandPractice," ACM Transactions on Computer Systems, Vol. 10,
No.4,pp.265-310 (1992).
[Levine 1986]Levine,P.,"TheApolloDomain Distributed FileSystem," Distributed Operating
Systems: Theory and Practice, NATOAdvanced StudyInstitute, Turkey,Springer-Verlag, New
York,NY(1986).
[Linn1993]Linn, 1., "Privacy Enhancement forInternetElectronic Mail.Message Encipherment
andAuthentication Procedures," InternetRFC 1421 (Part1)(1993).
[Lockhart, Jr.1994]Lockhart, Jr., H. W., OSF DCE: Guide to Developing Distributed
Applications, IEEEComputer SocietyPress, Los Alamitos, CA(1994).
[Milenkovic 1992]Milenkovic, M.,Operating Systems: Concepts and Design, 2nd ed., McGraw­
Hill, New York, NY (1992).
[Mitchell et ale1992]Mitchell, C. 1., Piper, F.,and Wild, P.,"DigitalSignatures," In:G.1.Simmons
(Ed.),Contemporary Cryptology, IEEE,NewYork, NY (1992).
[MorrisandThompson 1979]Morris,M.,andThompson, K.,"Password Security: ACase
History," Communications ofthe ACM, Vol. 22, No. 11, pp. 594-597 (1979).
[Mullender 1985]Mullender, S. J.,"Principles ofDistributed Operating SystemDesign," Ph.D.
Dissertation, Mathematisch Centrum, Amsterdam (1985).
[Mullender and'Ianenbaum 1984]Mullender, S. J., and Tanenbaum, A. S.,"Protection and
Resource ControlinDistributed Operating Systems," Computer Networks, Vol.8,pp.421-432
(1984).
[Mullender andTanenbaum 1986]Mullender, S.1., andTanenbaum, A. S.,"TheDesignof a
Capability-Based Distributed Operating System," Computer Journal, Vol.29,No.4,pp.289-300
(1986).
[NBS1977]National BureauofStandards, Federal Information Processing Standards, Publ. p.46,
Washington, DC(1977).
[Needham 1993] Needham, R. M.,"Cryptography andSecureChannels," In: S.Mullender (Ed.),
Distributed Systems, 2nd ed.,Association forComputing Machinery, New York,NY,pp. 531-541
(1993).
[Needham 1994]Needham, R. M.,"DenialofService:AnExample," Communications oftheACM,
Vol. 37, No. 11, pp. 42-46(1994).
[Needham andSchroeder 1978]Needham, R. M., and Schroeder, M. D.,"UsingEncryption for
Authentication in Large Networks ofComputers," Communications oftheACM, Vol.21, No. 12,
pp.993-999 (1978).
(Needham and Schroeder 1987]Needham, R. M., and Schroeder, M. D., "Authentication
Revisited," ACMOperating SystemReview,Vol. 21,No.1,p. 7(1987).638 Chap.11• Security
(Nessett 1983] Nessett, D. M., "A Systematic Methodology for Analyzing Security Threats to
Interprocess Communication in a Distributed System," IEEE Transactions on Communications,
Vol.COM-31, pp. 1055-1063 (1983).
[Nessett1987] Nessett, D. M., "Factors Affecting Distributed System Security," IEEE Transactions
on Software Engineering, Vol.SE-13, No.2,pp.233-248 (1987).
[Neuman and Theodore 1994] Neuman, B. C., and Theodore, T., "Kerberos: An Authentication
Service for Computer Networks," IEEE Communications Magazine, pp.33-38(September
1994).
[Otway and Rees 1987] Otway, D., and Rees, 0.,"Efficient and Timely Mutual Authentication,"
ACMOperating System Review, Vol.21, No. I, pp. 8-10(1987).
[Pfteeger 1989) Ptleeger, C. P., Security in Computing, Prentice-Hall, Englewood Cliffs, NJ
(1989).
[Rashid and Robertson 1981] Rashid, R. F., and Robertson, G. G., "Accent: A Communication
Oriented Network Operating System Kernel," In: Proceedings ofthe 8hACMSymposium on
Operating Systems Principles, Association for Computing Machinery, New York, NY (1981).
[Rivest1992)Rivest, R. L., "The MD5 Message-Digest Algorithm," Technical Report RFC 1321,
available for anonymous ftp from the Internet Network Information Center, Internet host:
nic.ddn.mil, directory/usr/pub/RFC (1992).
(Rivestetal. 1978] Rivest, R. L.,Shamir, A.,andAdleman, L.M., "A Method for Obtaining Digital
Signatures and Public-Key Cryptosystems," Communications ofthe ACM, Vol. 21,No.2,pp.
120-126 (1978).
[Rosenberry et al, 1992) Rosenberry, W., Kenney, D., and Fisher, G., OSF DISTRIBUTED
COMPUTING ENVIRONMENT, Understanding DCE, O'Reilly, Sebastopol, CA (1992).
[Rushby and Randell 1983) Rushby,J.M., and Randell, B., "A Distributed Secure System," IEEE
Computer, Vol. 16,No.7,pp.55-67(1983).
[Saltzer and Schroeder 1975]Saltzer, J. H., and Schroeder, M. N., "The Protection of Information
in Computer Systems," In: Proceedings ofthe IEEE, Vol.63, pp. 1278-1308 (1975).
[Sandhu and Samarati 1994]Sandhu, R. S., and Samarati, P., "Access Control: Principles and
Practice," IEEE Communications Magazine, pp.40-48(September 1994).
[Sansometal.1986] Sansom, R. D., Julin, D. P.,and Rashid; R. F.,"Extending a Capability Based
System into a Network Environment," Technical Report No. CMU-CS-86-115, Computer
Science Department, Carnegie-Mellon University, Pittsburgh, PA (1986).
[Satyanarayanan 1989]Satyanarayanan, M.•"Integrating Security in a Large Distributed System, n
ACMTransactions on Computer Systems, Vol.7,No.3,pp.247-280 (1989).
[Satyanarayan8n 1990]Satyanarayanan, M., "Scalable, Secure, and Highly Available Distributed
File Access," IEEE Computer, Vol.23,No.5,pp.9-21(1990).Chap.11 •Bibliography 639
[Schneier 1996]Schneier, B.,AppliedCryptography: Protocols, Algorithms, and Source Code in C,
2nded., Wiley, New York, NY(1996).
[Schroeder etal.1977]Schroeder, M. D.,Clark,D. D., and Saltzer,1. H.,"TheMULTICS Kernel
DesignProject," In:Proceedings ofthe 6thACMSymposium on Operating Systems Principles,
Association forComputing Machinery, NewYork, NY, pp.43-56(November 1977).
[Seberry andPieprzyk 1989]Seberry,1,andPieprzyk, 1.,Cryptography: An Introduction to
Computer Security, Prentice-Hall, Englewood Cliffs,NJ(1989).
[Shankar 1977]Shankar, K. S.,"TheTotalComputer Security Problem: AnOverview," IEEE
Computer, Vol. 10, pp. 50-62,71-73 (1977).
[Silberschatz andGalvin1994]Silberschatz, A., andGalvin,P.B.,Operating System Concepts, 4th
ed.,Addison-Wesley, Reading, MA(1994).
[Simmons 1992]Simmons, G.J.(Ed.),Contemporary Cryptology, IEEE,New York (1992).
[Simmons 1994]Simmons, G. 1.,"Cryptanalysis andProtocol Failures," Communications ofthe
ACM,Vol. 37, No. 11, pp. 56-65(1994).
[SinghalandShivaratri 1994]Singhal, M., andShivaratri, N.G.,Advanced Concepts in Operating
Systems, McGraw-Hill, New York (1994).
[Skardhamar 1996]Skardhamar, R.,VirusDetection and Elimination, Academic Press, San Diego,
CA(1996).
[Smart1994]Smart,R.K.,"TheX.509Extended FileSystem," In:Proceedings ofthe ISOC
Symposium on Network and Distributed System Security, InternetSociety, Reston,VA(February
1994).
[Stallings 1994]Stallings, W.,"Kerberos KeepstheEnterprise Secure," DataCommunications
Magazine, pp. 103--111 (October 1994).
[Stallings 1995]Stallings, W.,Network and Internetwork Security: Principles and Practice,
Prentice-Hall, Englewood Cliffs,NJ(1995).
[Stallings 1996]Stallings, W. (Ed.), Practical Cryptography for Data lnternetworks, IEEE
Computer SocietyPress,LosAlamitos, CA(1996).
[Steineretal.1988]Steiner,1.G.,Neuman, B.C., andSchiller, 1.I.,"Kerberos: AnAuthentication
ServiceforOpenNetwork Systems," In:Proceedings ofthe Winter 1988USENIX Conference,
USENIX, Berkeley, CA, pp. 191-202 (February 1988).
[TardoandAlagappan 1991] Tardo, J. 1., and Alagappan, K.,"SPX:GlobalAuthentication Using
PublicKeyCertificates," In:Proceedings ofthe IEEE Symposium on Research in Security and
Privacy,IEEEPress, New York, NY,pp.232-244 (1991).
[Tanenbaum 1987]Tanenbaum, A. S.,Operating Systems: Design and Implementation, Prentice­
Hall,Englewood Cliffs,NJ(1987).
[Tanenbaum 1992]Tanenbaum, A. S.,Modern Operating Systems, Prentice-Hall, Englewood
Cliffs,NJ (]992).640 Chap.11•Security
[Tanenbaum et al. 1986]Tanenbaum,A. S., Mullender,S. J., and vanRenesse,R., "Using Sparse
Capabilities in a Distributed Operating System," In: Proceedings ofthe 6th International
Conference on Distributed Computing Systems, IEEE Press, NewYork,NY, pp.558-563 (May
1986).
[lSaietal.1990]Tsai,C.,Gligor, V.D.,andChandersekaran,C.S.,"OntheIdentificationofCovert
StorageChannelsin SecureSystems," IEEE Transactions on Software Engineering, Vol.SE-16,
No.6,pp,569-580 (1990).
[Whiteet al, 1996]White,G. B., Fisch, E. A., and Pooch, U.W., Computer System and Network
Security,CRC, Boca Raton,FL (1996).
[Wobber et al, 1994] Wobber,E.,Abadi,M.,Burrows,M.,andLampson,B.,"Authenticationinthe
TaosOperatingSystem," ACMTransactions on Computer Systems, Vol.12,pp.3-32(1994).
[WooandLam1992]Woo,T. Y.C., and Lam, S. S., "Authenticationfor Distributed Systems,"
IEEE Computer, Vol.25,No.1,pp.39-52(1992).
[Worm 1989]"SpecialSectionon the InternetWorm," Communications ofthe ACM, Vol.32, No.
6,pp.677-710 (1989).
POINTERS TO81BlIOGRAPHIES ONTHEINTERNET
Bibliographies containing references onComputer Securitycan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslMisc/security.htm}
ftp:ftp.cs.umanitoba.calpublbibliographies/Misc/security.l.html
ftp:ftp.cs.umanitoba.calpublbibliographieslMisc/security.2.htm}
http:julmara.ce.chalmers.se/Security/sec_bib.html
http:www.telstra.com.au/pub/docs/security
A listofbooks on Security inComputer Networks can be found at:
http:www.crpht.lu/CNS/htmllPubServ/Securitylbibliography.html
Bibliography containing references on Cryptography can be found at:
http:mnementh.cs.adfa.oz.au/htbin/bib_lpb
(This is a gateway to the index into Lawries Cryptography Bibliography, which contains
references on various aspects of cryptography andcomputer security.)
An index of bibliographies containing references on Cryptography, InternetSecurity, and
Kerberos canbefound at:
http:www.comp.vuw.ac.nz/ .....sai/docsChap.11•PointerstoBibliographies on theInternet 641
COAST (Computer Operations, Audit, and Security Technology) is a multiple project,
multiple investigator laboratory in computer security research in the Computer Science
Department at Purdue University. A list of documents on various COAST projects, and
some other security-related papers by COAST personnel can be found at:
http:www.cs.purdue.edu/coast/coast-library.htmlCHAPTER12
CaseStudies
11.1 INTRODUmON
This chapter aims to consolidate the reader's understanding of the various concepts
described in the preceding chapters of this book by describing real distributed operating
systems.The systems described are Amoeba, V-System,Mach, and Chorus. The first two
are university research projects. The latter two also started as research projects but have
now been commercialized. These systems are still in various stages of development and
refinement. Therefore, an exhaustive and detailed description ofeach system has not been
presented. For each system, only the design goals, system architectures, and most
important and noteworthy aspects and features have been highlighted. Furthermore, the
order of presentation is not strictly chronological and does not reflect the relative
importance ofthesystems.The bibliography provides references forseveral other systems
that may be of interest to researchers performing research activities in the area of
distributed operating systems.
642Sec. 12.2 • Amoeba
12.2AMOEBA643
Amoeba is a microkernel-based distributed operating system developed at Vrije
University and the CenterforMathematics andComputer Science in Amsterdam, The
Netherlands. It was started in 1981 by Andrew S. Tanenbaum as a research project in
distributed and parallel computing. Since then, it has evolved over the years to acquire
several attractive features. The following description of Amoeba is based on
[Tanenbaum 1995, Coulouris eta1.1994,Mullender eta1.1990,Mullender and
Tanenbaum 1986].
12.2.1 Design GoalsandMainFeatures
Amoeba's design was influenced by the research and design goals given below.
Transparency
Providing a single-system image to the users was one of the main goals of Amoeba. The
most important design decision that was taken to achieve this goal was to use the
processor-pool model in which there is no concept of a "homemachine" and all resources
belong to the system as a whole.
ParallelProgramming Support
Although transparency is a useful feature for most users of a distributed system, some
users are interested in using the system as a testbed for experimenting with distributed and
parallelalgorithms, languages, tools, and applications. Amoeba supports such users by
making the underlying parallelism available to them. For this, the Orca language [Bat et
al. 1992] has been designed and implemented on Amoeba.
Capability-Based, Object-Oriented Approach
Anothermajor goal of Amoeba was to investigate the possibility of using the capability­
based,object-oriented approach for building an operational distributed system.'faachieve
this goal, objects and capabilities are used in a uniform way in the design of Amoeba. In
particular, the Amoeba software is based on objects, and objects are named and protected
by using capabilities.
Small-Kernel Approach
Anothergoal inAmoeba's design was to minimize the kernel size and enhance flexibility.
To achieve this goal, its design was based on the microkemel approach. That is, in
Amoeba, several of the standard services, such as a file service, are built outside the kernel
in user space. This helps in enhancing. flexibility because these services can be easily644 Chap. 12 • Case Studies
modified, and multiple versionsofaservice can besimultaneously runon thesamesystem
to suit the needs of different users.
HighPerformance
High performance wasalsoagoal inAmoeba.Three design decisions that were influenced
by this goal are the use ofthe processor-pool model, the use of multithreaded processes,
and the use ofa bullet file service that stores immutable files as contiguous byte strings
both on disk and in its cache.
HighReliability
Amoeba has also been designed to have a high degree of reliability.The following design
decisions helped in improving the overall reliability ofthe system:
1. Useofthe processor-pool model. In the processor-pool model, processors can
be dynamically added to the pool or removed from the pool.Therefore, when a few
processors crash, some jobs may have to be restarted and the computing power of the
system is temporarily lowered, but otherwise the system continues to function
normally, providing a high degree of fault tolerance.
2. Support for reliable interprocess communication. RPC is the basic IPC
mechanism inAmoeba. Amoeba's RPC supports at-most-once semantics, so that an RPC
is never carried out more than once, even in the face ofserver crashes and rapid
reboots.
3. Making the directory service reliable. The directory service, whose primary
function is to provide a mapping from human-oriented object names to system-defined
capabilities, is a critical component in Amoeba because almost every application
depends on it for finding the capabilities it needs. If the directory service stops,
everything else will also come to a halt. So that no single-site failure can bring it
down, it has been implemented in a fault-tolerant way by using the stable-storage
technique.
UNIXEmulation
Amoeba was developed from scratch rather than starting with an existing system (e.g.,
UNIX). The motivation behind this design approach was to experiment with new ideas
without having to worry about backward compatibility with any existing system.
However, the result of this design was that Amoeba's interface turned out to be quite
different from that of UNIX. Therefore, to avoid writing hundreds of utility and
application programs for Amoeba from scratch, a UNIX emulation package was later
added to Amoeba. This package, which is in the form of a library, allows most UNIX
programs to run on Amoeba with little or no modification. Further details of UNIXemulation in Amoeba can befound in [Mullender et al. 1990].Sec. 12.2 • Amoeba
12.1.2 System Architecture
Hardware Architecture64S
As Figure 12.1 shows, the Amoeba hardware consists of the following principal
components:
Processor
r--QQ~--- ..
LocalareanetworkWide-area
network
I
I
t
I
1 1
1 I' 1
Specialized servers
Fig. 12.1 Hardware architecture of theAmoeba system.
1.Processor pool.Amoeba is based on the processor-pool model. An Amoeba
system can have one or more processor pools. The CPUs in a pool belong to the system
as a whole and have no specific "owners." Therefore, a user does not log on to a specific
machine but tothe system asa whole.When a user has an application torun, theoperating
system dynamically allocates one or more CPUs from the pool to that application. When
theuser'sapplication completes, the CPUs are returned to the pool for allocation to other
work. If no CPU is free when a user has an application to run, the CPUs are time shared,
and a newly arrived job is assigned to the most lightly loaded CPU at that time. Amoeba
has been designed to support heterogeneity. Therefore, the CPUs in a pool can be of
different architectures.
2.Terminals. Terminals provide an interface to the users for accessing the system
resources. A terminal may either be an ordinary X terminal or a personal computer or
workstation running X windows. When a personal computer or a workstation is used as
a terminal, the processes that require intense user interaction (such as command
interpreters and editors) are executed at the terminals. Most applications, however, do not646 Chap.12 • Case Studies
interact much with the user and are run on one or more of the CPUs of a processor
pool.
3. Specialized servers. Specialized servers are machines for running dedicated
processes with unusual resource demands. For example, it is natural to run a file server
process on a machine having one or more disks and a print server process on a machine
having one or more printers. The main servers are directory, file, and block servers,
database servers, and boot servers.
4. Gateways. Gateways are used to link two or more Amoeba systems over wide­
area networks into a single, uniform system.
Software Architecture
The Amoeba software consists of the following principal components:
1. A microkernel. The microkernel that runs on all machines of an Amoeba system
provides low-level memory management support, manages processes containing multiple
threads, supports interprocess communication, and handles low-level I/O.
2. A collection ofservers. All other services (functions not included in the
microkernel) are provided by user-level processes called servers. Servers provide most of
the traditional operating system functionality. Servers are typically written by the systems
programmers, but users are free to write their own servers if they wish. Some standard
servers in Amoeba are the bullet server, which manages files; the directory server, which
handles naming of files and other objects; the replication server, which takes care of
automatic replication of objects; and the run server, which decides which process should
run on which processor. All standard servers have stub procedures in the library. To use
a server, a client normally justcalls the stub, which marshals the parameters, sends the
message, and blocks until the reply comes back. This mechanism hides all the
implementation details of a server from its clients.
Amoeba isan object-based system in which theentire software isstructured as objects. An
object is like an abstract data type that consists of some encapsulated data with certain
operations defined on it.Amoeba objects are passive in nature. That is, they cannot do
anything on their own. Therefore, each object is managed by a server process that
performs the operations defined on the objects it manages. Typical examples of objects
supported in this manner are files, directories, memory segments, screen windows,
processors, disks, and tape drives.
ObjectNaming and Protection
Each object in Amoeba is both identified and protected by a capability. As Figure 12.2
shows, a capability in Amoeba is composed of the following fields:Sec.12.2 • Amoeba
Number
of bits 48
FieldsIServerport24
ObjectnumberI8
Rights48
Check647
Fig. 12.2 An Arnoehacapability.
1.Serverport.This is a48-bit logical address that identifies the server that manages
the object referred to by the capability. InAmoeba, the only way a server can be accessed
is via its port. It may be noted here that a server port is a logical address that is associated
not with a specific machine but with a particular server (or a set of servers providing the
same service). Therefore, when a server is relocated on a new machine, it takes its server
port with it. A server can choose its own port address.
2.Objectnumber.A server typically manages several objects of the same type. For
example, a file server usually manages hundreds of files. The object number field is a
24-bit identifier used by the server to identify the specific objectin question from among
the objects managed by it. The server port and object number fields together uniquely
identify an object in the entire system.
3.Rights.This 8-bit field is a bitmap telling which of the allowed operations the
holder of this capability can perform on the object identified by the capability. The
meaning of this field is different for each object type since the legal operations themselves
also vary from one object type to another.
4. Check. This field is used for validating the capability. It contains a 48-bit number
that is used to protect the capability against forging.
Capabilities are managed entirely by user processes and are protected crypto­
graphically. In particular, to create an object, a client sends a request message to the
appropriate server. The server then creates the object and returns a capability to the client.
Thiscapability is called the ownercapability, and all its rights bits are initially on. When
creating the capability for the newly created object, the server picks a 48-bit random
number and stores it both in the check field of the capability and also in its own internal
table. The client must send this capability along with any request for an operation on this
object. Before performing the requested operation, the server compares the contents of the
check field in the capability with that stored in its internal table for validating the supplied
capability.
When the owner of an object wants to pass restricted access rights for the object to
other users, it sends a message tothe server requesting tocreate acapability with restricted
rights. This message, among other things, contains the owner capability for the object and
a bit mask for the new rights. The server EXCLUSIVE-DRs the new rights with the
original value of the check field from its internal table and then encrypts the obtained
result(x)by using a one-way function [y=!(x)],which has the property that given xit
is easy to find y,but given y,xcan only be found by an exhaustive search of all possible648 Chap. 12 • CaseStudies
values ofx.The server then creates a new capability whose server portand object number
fields have the same values as the owner capability for the object, the rights field contains
the new rights bits, and the check field contains the output of the one-way function. This
new capability is returned to the caller, which then sends it to another process for passing
to it restricted access rights for the object.
It maybenoted here that the capability-based naming scheme of Amoeba is fully
location transparent because to perform an operation on an object, it is not necessary to
know the location of the object or the location of the server that manages the object. The
protocol for talking to a server, whether local or remote, is identical in all cases. Thus a
client is entirely concerned with what it wants to do, not where objects are stored and
where servers run.
Thecapability-based protection scheme ofAmoeba has the advantage that it requires
almost no administrative overhead. However, notice that it is possible to create an object
in Amoeba and then lose its capability. Therefore, some mechanism is needed to identify
and destroy those objects that are no longer .accessible, For this, each server in Amoeba
periodically runs a garbage collector, which removes all objects that have not been used
inngarbage collection cycles. Furthermore, in an insecure environment, to keep
capabilities from getting disclosed to intruders on the network, additional cryptographic
measures (e.g., link encryption) will be necessary [Tanenbaum 1995].
Server-Locating Mechanism
To perform an operation on an object, a client process presents a capability for the object
to the system. The system must forward this request to the appropriate server for
performing theoperation on theobject. However, notice that,although the server portfield
in the capability specifies the server that manages the object, it does not carry any
information about the whereabouts of the associated server process. Therefore, a locating
mechanism is necessary to find the location of the appropriate server.
The mechanism used in Amoeba for locating a server is based on broadcast queries.
That is, for locating a server, a message "where are you" that contains the port address of
the server is broadcast on the network. The location of the server is known only after a
reply for the broadcast message is received from the server whose port address was
contained in the broadcast message. The reply message contains the network addressof
the server. The kernel doing the broadcasting records the (port, network address) pair in
a cache for future use. Therefore, broadcasting is done only when a server'sportis not
found in the cache.
Name Resolution Mechanism
Capabilities are low-level, system-oriented object names. They are hard for people to
remember and use. Therefore, objects inAmoeba also have human-oriented ASCII names.
The process of mapping a human-oriented object name to its system-oriented name
(capability) is known as name resolution. In Amoeba, directory servers are used to
perform the name resolution operations. Directory servers manage directory objects for
this purpose. In its simplest form, a directory is a set of (ASCII name, capability) pairs.Sec.12.2 • Amoeba 649
Lookup,enter,anddeletearethethreebasicoperationsallowedondirectoryobjects.The
firstoperationlooksup an object'sASCIInamein a directoryandreturnsits capability.
The other two operationsare meant for entering and deletingentries from a directory.
Sincedirectories themselves areobjects,adirectory cancontaincapabilities forother
directories, thusallowing users tobuildhierarchical directory trees and othermoregeneral
graphstructures [Mullender etale1990].
Thedirectory-based object-naming schemeofAmoeba is veryflexibleand can be
used toimplement sharingofobjectsinvariousdifferent ways. For instance, consider the
following examples:
1.Different users ofasharedobjectcan use their own suitableASCIInamesfor the
object. For this, eachuser can enterhis or her own (ASCIIname,capability) pairin a
directory. Note that the (ASCIIname,capability) pairsofdifferent users need not
necessarily beenteredinthe same directory. They can be placedintwo ormore directories to
createmultiple links to the object. Moreover, thecapabilities fordifferent users may have
different rights so that different users have different accesspermissions for theshared
object.
2.Objects sharedamonga group of users can be storedin adirectory whose
capability isgivenonly to the group members, makingthedirectory and hence the shared
objectsaccessible only to the group members. In this manner, a directory capability can
serve as a capability for many othercapabilities [Mullender eta1.1990].
3.Insteadofimplementing adirectory as atwo-column table, each row of whichis
an(ASCIIname,capability) pair,adirectory can beimplemented as an(n+l)-column
table with ASCII namesincolumn0andcapabilities incolumns1throughn[Mullender
et al. 1990]. In this generalized model, each of the ncapabilities ofanobjectforms a
different protection domain, havingdifferent accessrights for theobject. For example, a
directory may have one columnfortheownercapability, onefor theowner's group
capability, and one for public capability, tosimulate the UNIX protection scheme
[Mullender et al. 1990].
Amoeba designers felt that the directory serviceis acriticalcomponent in thesystem
becausealmostallapplications dependon it for finding the capabilities they need. If the
directory servicefails, the entiresystemwill stop functioning. Therefore, inorderthat no
single-site failurecan cause the directory serviceto fail, it has been implemented in a
fault-tolerant way. Inparticular, directory serverscomein pairs, each with its own array
ofcapability pairs (on different disks), to preventlossofinformation if the disk ofoneof
thedirectory serversisdamaged. The two serverscommunicate to keepsynchronized.
12.2.4ProcessManagement
Process Model
AprocessinAmoeba consistsofasegmented virtualaddressspaceand one or more
threads.Therefore, theprocessabstraction inAmoeba isrealizedby three kinds of basic
objects-process, segment, and thread. They are brieflydescribed below.650 Chap. 12 • Case Studies
1. Process. Aprocessisdefinedby its state. Each process has a processdescriptor
associated with it that defines its state at any instance of time. The four main parts of a
processdescriptor are the host descriptor, thecapabilities, thesegmentdescriptors, and the
threaddescriptors.
The host descriptor describes theprocessor type(s) suitable for runningthe process
and the memory requirements oftheprocess, Processor type(s) can be specified as a
particular CPUarchitecture, a groupofCPUs, or a predefined classofCPUs. The process
can be run only on a processor whoseprocessor type matches the processor type(s)
specified in theprocess's hostdescriptor and which has sufficient memory for running the
process.
Thecapabilities part mainly consistsofa process capability and a handlercapability.
Everyclientmanipulating the process must possess the process capability. On the other
hand, the handlercapability is needed to communicate the exit status oftheprocessto its
owner. That is, when the processterminates or is stunned (process states are explained
later), the handlercapability is used to do an RPC with the ownerprocessto report this
event.
Thesegmentdescriptors partdescribes thesegments ofthe process. It has a segment
descriptor for each segment in theprocess's address space. A segment's descriptor
contains information such as its virtual address, its length, and its access control.
The thread descriptors partdescribes the threads ofthe process. It has a thread
descriptor for each thread in the process. Among other things, a thread's descriptor
contains thethread'sprogram counterand stack pointer. The exactcontentsofa thread
descriptor-is CPU architecture dependent.
2.Segment. Asegmentis a named linear section of memory. A processcan have one
or more segments. The numberofsegments can keep changing during the lifetimeofthe
processas itexecutes.
To create a segment, a process makes a request to the kernel specifying the initial
sizeofthesegment andoptionally specifying asegment or a file whose contents
should be used as an initial value ofthe segment. The kernel then allocates the
necessary amountofmemory and returns to the requester acapability for the newly
createdsegment. This capability is used by the requester toperform anysubsequent
operation on the segment. The initial size of the segment maychangeduringprocess
execution.
Systemcalls are provided to allow processes to create, read, write, map, unmap,
and destroy their segments. Ofthese, the map and unmap operations can be used for
variousdifferent purposes. For instance, they can be used by a processto add new
segments to its address space by mapping them and to remove segments from its
addressspace by unmapping them. An unmapped segment remainsin memory (but is
not a part oftheaddress space ofanyprocess) and can be eitherread or written like
a file or can even be remapped to any part of the same process's address space or to
adifferent process's address space. For this, the unmap operation returns a capability
for the segment. Due to this feature, the map and unmap operations can also be used
forinterprocess communication; thesenderprocess unmaps a segment ofits address
space and passes the capability returned by the unmap operation to thereceiverSec. 12.2 • Amoeba 651
process, whichthenmapsthesegment to itsownaddress space.Finally, thesetwo
operations can also be usedto allow two or moreprocesses tooperateonshared
memory bysimultaneously mapping asegment into the address spacesofallthese
processes.
3. Thread. Aprocesshas one or morethreads, allofwhichsharetheprocess's
addressspace.Eachthreadhas its own stackandstackpointer,itsowncopyoftheCPU
registers, and itsownsetof"glocal" variables. Athread'sglocal variables areglobalto
all itsprocedures but are not accessible tootherthreads.Amoeba haslibraryprocedures
toallowthreadstocreateand use glocal variables.
Aprocesscancreatenewthreadsand canterminate existing threadsas itexecutes.
Hence,thenumberofthreadsin aprocesscan keep changing duringitslifetime. The
parameters to the call for creatinga newthreadspecifytheinitialprocedure to be run and
the sizeoftheinitialstack.
Threads aremanaged by thekernel,and apriority-based threads-scheduling scheme
is used in which kernelthreadshavehigherprioritythanuserthreads.
The three different mechanisms that may be used for threadssynchronization are
signals, mutexvariables, andcounting semaphores. Signals are used to send an
asynchronous interrupt from one threadtoanotherin thesameprocess. Mutexvariables
are likebinarysemaphores, and they have the samepurpose asdescribed inChapter 8.
Counting semaphores are useful for more generalsynchronization requirements that
cannotbehandled by using mutex variables.
InAmoeba, aprocesscreatesa new(child)processby firstmakingaCreateSegment
requestthreetimesfor the three segments (text, data, and stack)of thechildprocessand
gets back one capability for each segment. It thenperforms writeoperations for each
segment to fill each one with that segment's initialdata(this may not be done as a separate
step if the pointerto the initial data for each segment isprovided as aparameter in the
CreateSegment requests). Finally, the process does aMakeProcess requestwith the
capabilities ofthechild'ssegments asparameters. Makel'rocess createsthechildprocess
andreturnsacapability forit.Theparentprocesscontinues toexecuteinparallelwith the
newlycreatedchildprocess. It can use the childprocess's capability tosuspend, restart,
ordestroythechildprocess. Note that a process cancreateanarbitrary numberof
children, whichin turn can createtheirownchildren. Thisflexibility allowsthecreation
ofanarbitrarily large tree of processes.
At any time, a processis in one oftwostates-running orstunned(suspended). A
running processcan bestunnedbyexecuting alibraryprocedure calledstun,with the
capability of theprocessas aparameter. Aprocesscan bestunneddirectlyby itsparent
or by any otherprocessthat has a capability for theprocesswithrightsto stun it. For
example, aprocessbeinginteractively debugged switches between runningandstunned
states.For this, the parentgivestheprocess's capability to thedebugger process, which
can then changetheprocess's state as it likes duringinteractive debugging. Whena
processis in the stunnedstate, for all attempts tocommunicate with the process, the low­
levelcommunication protocols in thekernelrespond with amessage saying"thisprocess
isstunned."652 Chap.12 • Case Studies
Choosing a Processor for a New Process
In theprocessor-pool modelofAmoeba, when a new process has to be created,the system
mustchoosefrom the pool the most suitable processor forrunningthe process. There are
special servers called runservers to make this decision. Each run servermanages one or
moreprocessor pools. For simplicity, let us assume that each run servermanages only one
processor pool.
When the shell wants to run a program, it does an RPC, with the run serversending
to it theprocessdescriptors for theprogram and asking it to pick a processor for it from
the pool. The run serveruses the following method to select a processor forexecuting the
program:
1. Theprocessdescriptors containinformation about the CPU architectures on
which the corresponding process can run.Therefore, the runservertakes the intersection
of the CPU architectures in theprocessdescriptors and the CPU architectures in the
processor pool that it manages. To facilitate this, a processor pool isrepresented bya
directory calledapooldir,whichcontainssubdirectories for each of the CPU architectures
in the pool. The subdirectories containcapabilities foraccessing theprocessservers on
eachofthe CPUs in the pool. The processors that result from the intersection are chosen
aspossible candidates for running the process.
2. Next, the run serverchecksto see which of the selected processors have
sufficient memory forexecuting the program. For this, the run servermaintains a table
containing the speed, currentload, and amount of currently free memory for each
processor. The information in this table is continuously refreshed byexecuting a
libraryprocedure calledgetloadfor each processor in the pool. Thoseprocessors that
do not have enoughmemory for the program are removed from the set ofpossible
candidates.
3. Finally, for each oftheremaining processors, the run serverestimates the
computing powerthat theprocessor can devote to the new program. For this, it uses a
heuristic that takes as input the known total computing poweroftheprocessor and the
numberofcurrently active threads running on it.Theprocessor that can deliverthe
maximum computing poweris finally selectedas the most suitable candidate forexecuting
theprogram.
The runserverreturns the capability of theprocessserveroftheselectedprocessor
to the caller. The callerthen uses this capability to create the processon the selected
processor.
ProcessMigration Mechanism
Although Amoeba does not currently supportprocess migration, the designers have
thoughtabout it, and it has been mentioned in the literature that a processmigration
mechanism formigrating aprocessfrom its old node to a new node can be easily
implemented in the future in the following manner[Mullender et al. 1990]:Sec.12.2•Amoeba 653
1. At first, the process server at the old node of the migrant process will stun it.
2. It will then pass the process descriptor of the process to the process server at the
new node in a RunProcess request.
3. The process server atthe new node willthen fetch the address space of theprocess
from the old node bymaking a series of ReadSegment requests.
4. After this, it will start the process at the new node with a CreateProcess request.
With this, the process starts executing on its new node.
5. The process server of the new node then returns a "success" reply for the
RunProcess request made by the process server of the old node. On receiving this
reply, the process server at the old node will delete the process by making a
DeleteProcess request to the kernel. With this, the migration of the process will
complete.
Note that while the migration of a process is in progress, it is frozen (stunned) on its
old node. Therefore, processes communicating with the process will receive "this process
is stunned" replies to their attempts until the process on the old node is killed. They will
then get a "process not here" reply for their attempts to communicate with the deleted
process. As a result of this reply, a sender will start a locateoperation to find the process.
After it finds the process on its new node, it can resume communication with the process
in normal fashion.
Amoeba is designed to support multiple file systems at the same time. It has a built-in
standard file system, but those users who do not like it are free to write and use their own
file system. Therefore, in the same Amoeba system, files of different users may be
managed by different and incompatible file systems. The main reason for this flexibility
is that a file system in Amoeba runs as a collection of server processes. A description of
the standard file system of Amoeba is presented below.
The standard file system ofAmoeba iscomprised of thefollowing types of servers:
1. Bullet server. It deals with the storage and manipulation of files.
2.Directory server. It takes care of object naming (including files) and directory
management.
3.Replication server.It handles automatic replication of objects (including files)
managed by the directory server.
A description of t.hedirectory server has already been presented in Section 12.2.3.
Therefore, only the bullet server and the replication server are described below.
BulletServer
The bullet server is so called because itwas designed to bevery fast. In fact, high
performance and simple design were the two main goals in the design of the standard file
system of Amoeba. The following design decisions were made to achieve these goals:654 Chap. 12 • Case Studies
1. Useofimmutablefiles. A file cannot be modified once it has been createdexcept
to be deleted. Therefore, the bullet serversupports only three principal fileoperations­
read, create, anddelete.To modify an existingfile, a client makes a readrequestto the
bulletserverspecifying its capability. In reply to this request, the serversends to the client
theentirefile that is loaded into the client'smemory. The client now performs all the
modifications on the local copy ofthe file. It then makes a createrequestto the bullet
server,sendingapointerto the memory location thatcontains themodified file as a
parameter. The server creates a new file and returns a new capability to the client. Either
theoriginalfile canbeleft for use as a backup copy or the client can make a deleterequest
to the bullet server to destroy it.
Notice from the description above that for an immutable file a file modification
typically requiresa client to performthree RPCs (one each for read, create, anddelete
operations) with the bullet server. This makes file modifications complicated and slow. To
solve this problem, the bulletserversupports two kinds of files-uncommitted and
committed. Anuncommitted file is one that is in the process ofbeingcreatedand can be
directlymodified by sending modification requests (such as to change,insert, or delete
bytes) to the bullet server. When all the changes have been completed, the file can be
committed, at which point it becomes immutable. Notice that an uncommitted file is
transient in nature and hence cannotbe read. On the other hand, a committed file is
permanent in nature. It can beread but cannotbe modified becauseit isimmutable. A
createrequestmust specify whetherthe file is to becommitted immediately or not. In
eithercase, a copy of the file is made at the server and a capability for the file is returned
to the client.
2. Storing files as contiguous byte strings. The final size ofanimmutable file is
always known at creationtime because it cannot be modified after itscreation. Due to this
property, files in Amoeba are stored contiguously, both on the disk and in the main­
memorycache.Although thisstrategywastes space due to external fragmentation, both in
memory and on disk, it helps in achieving the goals ofhighperformance and simple
design. This is because a contiguously stored file can beread into memory in a single disk
operation and canbesent to users in a single RPC reply message. Furthermore, in this
strategy, a file can be simply represented by an initial address and length, which simplifies
theadministration ofstoragespace, both in memory and on disk.
As Figure 12.3 shows, the bullet servermaintains a file table that is entirelymemory
resident while the bullet serveris running. The entire file table is loaded into memory
when the bulletserveris loaded.
The file table has one entry for each file being managed by the bullet server. The
entriesareindexedby a file numberfield. Since the initial address and size are sufficient
torepresent a file, each entry ofthe file table also has the following three fields:
• A length field that has the file size.
• A disk address field that contains the initial address ofthe file on disk.
• Amemoryaddress field. If the file is currently present in the main-memory cache,
this field contains thestartingaddressofthe file in main memory.Sec. 12.2 • Amoeba
DiskDisk File Other Memory
address number Lengthfields address
0LO Null
L1
2L2 Null::n:nCD
3L3 CD
CN
Filesin
cache
Filetable
Bulletserver'smemory
.Fig.12.3 Bullet serverimplementation.6SS
Inadditionto these fields, there are otherfieldscontaining information that are used
foraccesscontrolandadministration purpose.
To read a file, a clientdoes an RPC with the bulletserver,sendingit thecapability
for the file. The serverthen extract.s the file numberfrom the objectnumberfieldofthe
capability and uses it to reach at the appropriate file table entry. Each file table entry also
has a field containing therandomnumberused in the checkfield of the capability. This
information is used to validatethecapability. If thecapability is found to be valid, the
serverfirstcheckstheinformation in thememory addressfieldofthe file table to see if
the file is currently presentin themain-memory cache. If not, the servernext uses the
information in the disk addressandlengthfields of the file table to fetch the entirefile
from the disk into the main-memory cache. Finally, it returnstheentirefile to the client
as a reply of the RPC message, The least recentlyused(LRU)schemeis used to manage
thecachespace.
If afile'scapability is lost,itwillremainforeverin thesystemas aninaccessible
file.Uncommitted andcommitted files are handleddifferently topreventthissituation.
For anuncommitted file, ifithas not been accessed for 10minutes, it is simply
deletedand thecorresponding entry in the file table is freed. If a requestforaccessing
thedeletedfile isreceived after the deletedfile'sentry is reusedforanotherfile, the
checkfield will detectthe fact that the file has changed, and the operation on the
already deleted file will berejected. Thisapproach is based on the designers'
assumption that files normally existin theuncommitted state for only a few
seconds.
Forcommitted files, agarbage collector is runperiodically, removing all files
that have not been used in ngarbage collection cycles.Thisidea isimplemented as
follows. The tiletable entry has a counterfield for each file that is initialized to a
predetermined constant MAX_I __IFETIME. Now the following two calls are made
periodically todetectandremovecommitted files that can neverbeaccessed:656 Chap. 12 • Case Studies
1. Age.Theagecall starts a new garbagecollection cycleanddecrements the value
ofthecounterfieldofeach file table entryby 1.Any file whose countervaluebecomes
zero isdeletedand thecorresponding disk space, cachespace(ifany), and file table entry
are freed.
2. Touch. Thetouchcallprevents those files from being removed that are in use.
Unlikeage,whichappliesto all files, touchis for a specificfile.Whencalledfor a
particular file, it resets the value ofthecounterfieldofthatfile'sentrytoMAX_
LIFETIME. Touchiscalledperiodically for all files listed in any directory, to keep them
fromgettingdeletedby theagecall.
Replication Server
Thereplication serverhandlesautomatic replication ofobjects(including files)managed by
thedirectory server. It alwayskeepsrunninginthebackground and uses the lazy replication
approach forcreating objectreplicas. It scans specified partsofthedirectory system
periodically tocheckifreplicacreationfor anyobjectin thedirectory systemis needed. In
particular, if there is a directory entry that is supposed tocontainncapabilities butcontains
only m (m<n),thenn-madditional copiesofthecorresponding objectmust becreated.
Therefore, when the replication serverfinds such a directory entry, itcontacts therelevant
serversandarranges for thecreationofadditional replicasofthecorresponding object.
Inaddition tocreating objectreplicas, thereplication serveris alsoresponsible for
garbage collection. Thatis, itperiodically makes a touchcall for each objectin the
directory systemtorefreshtheirlifetimeso that they win not be removed by thegarbage
collector. Periodically, it also sends the agemessage to the servers ofdifferent objecttypes
tocausethem to make the agecall todecrement the value ofthecounterfield for all their
objectsand toremovethoseobjectswhosecountervaluereacheszero.
12.2.6Int.rproc.ss Communlcetlon
BasicfPCMechanism
Amoeba uses the client-server model for operations on objects. Thatis,clientprocesses
sendrequeststoserverprocesses (objectmanagers) forcarrying outoperations on objects.
Aserveracceptsaclient'srequestmessage, carriesout therequested operation, and
returnsa reply to the client. Each standard serverisdefinedby a setofstubprocedures
thatclientscan call. The stub procedures precisely definetheservicesand their parameters
that the serverprovides. When a stub procedure iscalledby a client, it packs the
parameters into amessage andinvokesthe kernel primitives toactuallysend the message.
Thekernelprovides thefollowing three basic IPC primitives:
• transis used by a clientto send a requestmessage to aserverforgettingsome
workdone by the server.
•get_request is used by a servertoannounce itswillingness toacceptmessages
addressed to aspecificport.
•send_reply is usedbyaserverto send a reply to a client.Sec.12.2•Amoeba 657
Although these primitives are actually related to message passing, the procedural
interface provided by stub procedures makes the basic IPC mechanism appear as RPC
(Remote Procedure Call) to the programmers. Therefore, the basic IPC mechanism of
Amoeba is also referred to as RPC. This RPC mechanism has the following properties:
1. It supports only synchronous type ofcommunication. That is, after making a trans
call, a client thread blocks until the corresponding reply comes back from the called
server. Similarly, after making a get_request call, a server goes to sleep, waiting for an
incoming request message. The server is unblocked only when a request message
arrives.
2. Messages are unbuffered. Hence a message is simply discarded if its receiver is
not in a state ready to reeeive it. In this case, the sending kernel will time out and
retransmit the message. Flexibility is provided to the users to specify the maximum
duration for retransmissions, after which the kernel should give up and report failure.
3. It supports at-most-once semantics. That is, the system guarantees that an RPC
will never be carried out more than once, even if the server crashes and is rapidly
rebooted.
4. Stateless servers are used. Therefore, each RPC is completely self contained and
does not depend on any previous information stored in the server'smemories.
GroupCommunication
In addition to the RPC mechanism, Amoeba also supports group communication facility.
A group consists of multiple processes that cooperate to provide some service. Amoeba
uses the concept of closed groups. That is, the information regarding the size and the
memberprocesses of a group are not known to processes outside the group. Therefore, for
accessing a service provided by a group, a client process simply performs an RPC with
one of its members. That member then uses group communication within the group to
service the client'srequest in cooperation with other members of the group.
Processes can join and leave a group dynamically and can be members of multiple
groups at the same time. The system provides primitives for creating a new group,
allowing a process to dynamically join or leave agroup, sending a message to allmembers
of a group, and receiving a message from a group. The group communication mechanism
of Amoeba has the following properties:
1. It ensures ordereddelivery of messages. That is, if two processes send messages
to a group almost simultaneously, the system ensures that all group members will receive
the messages in the same order. A sequencer process is used for properly sequencing the
messages received by a group. The sequencer process is chosen byusing an election
algorithm.
2. It ensures reliable delivery of messages. That is, when a user process broadcasts
a message, the message is correctly delivered to all members of the group, even though
the hardware may lose packets. The basic mechanisms used to ensure reliable message658 Chap. 12 • Case Studies
delivery are timeout-based retransmissions for retransmitting lost messages; use of unique
message identifiers to detect duplicate messages; and the use of a history buffer to store
messages for which acknowledgments have not yet been received.
3. It can withstand the loss of an arbitrary collection of kprocessors (including the
sequencer), where k(the degree of resilience) is specified bythe user as a parameter in the
primitive for creating a group [Tanenbaum 1995]. The larger is the value of k,the more
redundancy is required, and the slower the group communication becomes. Therefore, the
user must carefully choose the value of k.
Further details of the group communication facility of Amoeba may be found in
[Kaashoek and Tanenbaum 1991].
Low-Level Communication Protocols
Both RPC and the group communication facilities of Amoeba use a custom protocol,
called FLIP (Fast Local Internet Protocol), for actual message transmission. The details of
FLIP have already been presented in Chapter 2 and hence win not be repeated here.
FLIP is used in Amoeba for achieving high performance. However, there are
occasions when Amoeba users need to use the standard TCP/IP instead of FLIP. For
instance, TCP/IP must be used to communicate with X terminals, to send and receive
mails to non-Amoeba machines, and to interact with other Amoeba systems via the
Internet [Tanenbaum 1995]. To facilitate communications of these types, Amoeba has a
TCP/IPserver. For TCP/IP-based communications, a client performs an RPC with the
TCPIIP server giving it a TCP/IP address. The TCPIIP server establishes a connection
withthe desired process and returns a capability to the client process. This capability
allows the client to use the established connection. Once the connection is established,
subsequent RPCs between the two processes can be done without the Amoeba process
having to know that TCP/IPis being used.
Communication Security
Ensuring Genuine Clients. Amoeba has two levels of protection to ensure the
genuinenessofaclient -portsforprotectingaccesstoserversandcapabilities forprotecting
access toindividualobjects[Mullenderetal. 1990].Thatis,theknowledge ofa server'sport
and thepossessionofa validcapability istaken bythesystem assufficientevidence thatthe
senderhas arighttocommunicate with the serverand to performoperations allowedbythe
capability on the object identified by the capability. The ports used by an ordinary user
process will,ingeneral, beknown only to theprocesses that have theright tocommunicate
withthe user process. However,the portof a server process providing some public service,
such as a file server, will be known to all users. Therefore, for public servers, capabilities
serveas thebasic mechanismtoensure the genuineness of aclient.
Ensuring Genuine Servers. Since ports for public servers are known to all
users, it is easy for anintruder to impersonate a serverjustby doing a getrequest on the
server'sport. A one-way encryption technique is used in Amoeba to solve this problem.Sec. 12.3 • V-System 659
In thisapproach, each port is defined as a pair of ports, get-portandput-port, related by
put-port=F(get-port). The function Fis apubliclyknown one-way encryption function.
Therefore, it is easy to compute put-portfor a given get-port, but finding get-portfor a
givenput-portis notpractically feasible. Here, Fneed not be the same one-way function
as that used for protecting capabilities since the two concepts are unrelated.
As a part of its creationprocess, a serverchooses a get-portthat it keeps secret with
it.Itcomputes thecorresponding put-portand makes it publiclyknown. When the server
is ready to accept client requests, it makes a get_request (get-port, ...)call. The kernel
computes thecorresponding put-port and stores it in a table of ports being listened to.
When a client wants to send a message to the server, it makes a trans(put-port, ...)call.
The kernel of the client machine then sends a message containing put-port ina header field
to the server. On the server side, the kernel compares theput-portin the message header
to the put-ports in its table for a match and then forwards the message to the corresponding
server.
This scheme ensuresthat only genuine servers can receive client requests because
get-ports never appear on the network and cannotbederivedfrom the publicly known put­
ports.
12.3V-SYSTEM
V-System is a microkernel-based distributed operating system designed for a clusterof
workstations connected by ahigh-performance network. It started as a research project on
distributed systems at Stanford University under the direction of David Cheriton. It is
basically an outgrowth of theexperience acquired with anearliersystem called Thoth
[Cheriton et al. 1979]. Its development wasmotivated bythe growing availability and
functionality of relatively low-cost, high-performance workstations and local area
networks.
V-System has been in active use at Stanford University for the last several years. The
V-System environment. at Stanford mainly consistsof acollection of powerful Sun and
VAXworkstations connected by Ethernet. V-System is also distributed under license by
Stanford and is in use at several other universities, research laboratories, and companies.
The following description of V-System is based on [Cheriton 1984, 1987, 1988, Cheriton
et al. 1990, Berglund 1986].
12.3.1DesignGoalsQndMainFeatures
V-System's design was influenced by the research and design goals mentioned below.
High-Performance Communication
V-System designers were of the opinion that high performance ofinterprocess
communication is necessary in a distributed system for betterperformance andsimpler
design of resulting application systems and also for true network transparency. In a system
with fast communication facility, better performance ofapplication systems is obvious.Chap. 12 • Case Studies
Simplerdesignofapplication systems·is due to the reasonthat there is no need to highly
optimize the useofcommunication topreventperformance degradation. Finally, true
network transparency can beachieved because fastcommunication allowsresource
accessing withoutconcernforlocation.
Fastinterprocess communication in V-System is achieved by thefollowing [Cheriton
1988]:
1.Usingrelatively simpleand basic interprocess communication primitives
2. Using a transport protocol calledVMTP(Versatile Message Transaction Protocol)
that iscarefully designed tosupporttheseprimitives
3.Optimizing for theperformance-critical common cases
4.Internally structuring the kernel for efficient communication
Uniform Interface and Protocol
. V-System designers were also oftheopinionthat theprotocols andinterfaces, not the
software modules, define the system. That is, a device-andnetwork-independent uniform
interface andprotocol canbedefined to build an open-system architecture. Thus,
V-System designers mainlyfocusedtheir work on designing theprotocols andinterfaces.
The result was a set ofprotocols for data transport, naming,110,remoteexecution,
migration, and so on, which provides a basis for standardization.
Relatively Small Kernel
Anotherimportant design goal ofV-System was to have a relatively small kernel that can
provideasoftware backplane fordistributed systemsanalogous to what a good hardware
backplane provides forhardware systemsand toimplement the restofthesystemat a user
level in a machine- andnetwork-independent fashion.Consequently, mostofthe facilities
found in traditional operating systems, such as a file system, resource management, and
protection, areprovided in V-System by serversoutsidethe kernel.
HighPerformance
Highperformance was also an important goal in V-System becausethedesigners were of
theopinionthat no one will use a slow system, independent ofitselegance. Someofthe
important techniques used in the design ofV-System for high performance are as
follows:
1.Makingtheinterprocess communication fast byalreadymentioned methods
2.Allowing application programs to make use ofconcurrency by using multi­
threaded processes
3.Maintaining a name prefix cachefor each program forefficient resolution of
objectnamesSec.12.3•V-System 661
4. Using the problem-oriented approach for shared-memory coherence that imple­
ments a relaxed form of consistency to improve performance, with the potential
inconsistencies handled in an application-specific fashion
Network Transparency
Similarto otherdistributed operating systems, network transparency was also a goal in
V-System. To achieve this goal, the naming facility of V-System was based on a three­
level model, structured as character-string names, object identifiers, and entity
identifiers.
Supportfor Conventional Programming Models
Another goal in V-System design was to provide support for conventional programming
models so that applications programmers can access the system services through a set of
procedural interfaces. To achieve this goal, each system-provided service procedure is
made a part of one of the runtime libraries of V-System. When an application process
invokes a procedure for accessing some system service, if possible, the invoked procedure
itself performs the requested operation. Otherwise, ituses the kernel-provided interprocess
communication tocommunicate with the proper service module(s) of V-Systemto get the
operation performed. In either case, it is the invoked procedure that returns a reply to the
application process, and hence the actual mechanism used to perform the operation is
transparent to the application process.
UNIXEmulation
A relatively new goal of V-System was to provide binary compatibility with a UNIX
system so that existing UNIX programs can be run on V-System. For this, a UNIX
emulation package was later added to V-System. Its details can be found in [Cheriton et
a1.1990].
12.3.2SystemArchitecture
Hardware Architecture
As Figure 12.4 shows, the hardware architecture of V-System consists of a collection of
workstations interconnected by acommunications network, such as an Ethernet. The
workstations are broadly classified into the following categories:
1. User machines. A workstation belonging to this category supports an interactive
user. It has most of the processing resources for its user in addition to display, keyboard,
and mouse.
2. Server machines. A workstation belonging to this category functions as a
dedicated server providing services such as file service, print service, authentication
service, and other kinds of services. Each workstation of this category may provide one662 Chap. 12 • Case Studies
User
machines
Communication network
Fig.12.4 Hardware architecture of the V-System.
or more types of services. For instance, a workstation with secondary storage may run the
V-System file server software and exclusively offer file service. The kernel'sinterprocess
communication makes this service and others available in a network -transparent fashion
to all workstations on the network.
Software Architecture
From a software point of view, V-System architecture mainly consists of the following
layers (Fig. 12.5):
1. The kernel layer. The V-System kernel forms the lowest layer of the software
architecture. To keep it small, the kernel is designed using a minimalist philosophy. That
is, only those facilities that are justsufficient and powerful enough to build all other
system functions and features are placed in the kernel. Hence, the kernel performs only
such functions as management of lightweight processes, management ofaddress spaces,
andinterprocess communication. A separate copy of the kernel executes on each
workstation, and all of them cooperate to provide a single system image at the application
process level.
2. Service modules layer. The modules at this layer use the basic access to hardware
resources provided by the kernel for implementing various types of services for the users.
For instance, the file server module at this layer implements a UNIX-like file system using
the raw disk access supported by the kernel. Some other service modules of this layer are
a pipe server that implements UNIX-like pipes, an Internet server that implements theSec. 12.3 • V-System
Application code
Runtimelibraries
Servicemodules
User
space663
Fig. 12.5 Software architecture of the V-System.
TCPIIP suite, a printerserver that supports spooling of print jobs, and a display server that
implements multiwindow facilities using a bitmapdisplay. In this way, V-System allows
manytraditional kernel-based functions to be implemented as user-level server
processes.
3. Runtime libraries. This layer implements conventional language or applica­
tion-to-operating-system interface. Most V-System applications andcommands are
written in terms of these conventional interfaces and are unaware of the distributed
nature of the underlying system. Therefore, the software at this layer causes
V-System to appearto theapplications programmers as a set of procedural interfaces
that provide access to the system services. It also allows many programs that
originated innondistributed systems to be ported to V-System with little or no
modification bysimply linking the original source with the runtime libraries at this
layer.
4. Application code layer. This layer contains the code for the application
programs.
11.3.3ObjectNaming
Theobject-naming facility of V-System is based on a three-level modelstructured as
character-string names, object identifiers, and entity identifiers. The usage and
management of the names and the method of locating an object given its name are
described below.664 Chap. 12 • Case Studies
Character-String Names
Character-string names are human-oriented names that are mainly used for naming
permanent objects such as files. In V-System, each object is managed by an object
manager that usually implements and manages several objectsofthe same kind. For
example, a filemanager implements andmanages several files. Each objectmanager
maintains one or more directories for its own set ofobjects. A directory entrycontains an
object'scharacter-string name and a pointerto the object. Each directory forms acontext
ofthe name space ofcharacter-string names.Therefore, character-string names are always
interpreted in somecontext,and each object manager manages its owncontexts.
Each object manager picks a unique global name for a contextthat itmanages and
addsitselfto thename-handling (process) group. Acontextname acts as a name prefix
for thecharacter-string names defined in that context. Because all character-string names
areinterpreted relative to some context, a(context name, character-string name)pair
forms aqualified name that can beused for uniquely identifying an object. Both the parts
ofaqualified name may eitherform ahierarchical or a flat name space.
To access an object, a client processspecifies the qualified nameofthe object. The
appropriate objectmanager is then located by multicasting the name along with the access
requestto all the object managers in thename-handling group. Each objectmanager
extractsthecontextname part ofthequalified name to check if the named objectbelongs
to acontextmanaged by it. Only the appropriate objectmanager thenperforms the
requested accessoperation on the named object and responds to the client.
To reduce the numberofmulticast queriesmentioned above, each processmaintains
a name prefix cache that has context-name-to-object-manager bindings. The cache is
initialized on process initiation to avoidstart-upnamecachemisses.Furthermore, an on­
use update mechanism is used for the consistency ofname prefix caches.
The name management approach described above takes advantage ofthe fact that a
nameisgenerally only mapped as part ofanoperation on thecorresponding object.
V-System designers mentioned that, in general, integrating naming with object
management in this way has following advantages [Cheriton and Mann 1989]:
1. It leads to efficiency becausewhen an operation on anobjectisrequested by
specifying its name, both the name resolution operation and therequested operation on the
objectcan becompleted in a single set ofmessage exchange, Thiscontrasts with those
systemsthat useseparate name servers, in which case one set ofmessage exchange is
neededfor name resolution to locate the object(itsmanager) and then anotherset of
message exchange is needed for performing the desired operation on the object.
2. It leads to consistent reliability ofboth the name resolution andobject-accessing
operations. That is, in this scheme, an object'sname can always be resolved when the
object(its manager) is available for use. This contrasts with those systems that use
separatename servers, in which case it is quite likely that an objectisavailable for use but
cannotbeaccessed because the name serveris down.
3. It leads to simplerdesignbecausetheavailability ofallinformation ofan object
(names,properties, data, etc.) in one servermakes it easiertomaintain their consistency.Sec.12.3•V-System 66S
For example, when an object is deleted, all its related information can be deleted without
the need to communicate with any other server.
4. The design also allows the automatic application of the security mechanism for
communicating with the object manager and controlling access to information to the
naming operations as well.
ObjectIdentifiers
Object identifiers are system-oriented names. They are used to identify transient objects
such as open files, address spaces, and contexts or directories to avoid the overhead of
character-string name handling and lookup each time an object is accessed. For example,
a process uses the character-string name of a file at the time of opening it for use, when
the system assigns an object identifier to the opened file and returns the object identifier
to the process. The process uses the object identifier to refer to the file in subsequent
operations on it.
Anobjectidentifier isstructuredasa (manager-id, local-object-ids pair.Themanager­
ididentifies the object manager that implements the object, and the local-object-id
identifiestheobject among alltheobjects managedbythisobject manager.The manager-id
part of an object identifier is used to efficiently send a client'srequest to thecorrect object
manager for operation on the object. On the other hand, the local-object-id part is used by
the object manager to perform the requested operation on the correct object.
Note that the life of anobject (transient object) identified by an object identifier must
not exceed the lifetime of the embedded manager-ide This is because the manager-id of
an object manager is invalidated when the corresponding process crashes (an object
manager is assigned a new manager-id on reboot).
When an object manager is replicated or distributed across multiple nodes, the
process group mechanism (described later) is used to identify the entire group of server
instances, implementing the object manager, by a single group identifier. In this case, a
particular server of the group can be addressed by using the coresident addressing
(qualifier) facility of the group addressing mechanism (described later).
EntityIdentifiers
Entity identifiers are used to identify processes, process groups, and transport-level
communication endpoints. Therefore, manager-id andgroup-id are basically entity
identifiers.
Entity identifiers are fixed-length (64-bit) binary values that are host address
independent (host addresses are network or internetwork dependent). Hence, when a
process migrates from one host to another, there is no need to change its process-ide The
mapping of an object'sidentifier to its host address is done by the kernel. For this, the
kernel uses a cache of such mappings along with a multicast mechanism to query other
kernels for mappings not found in the cache. When an entity identifier is used to identify
a process group, the entity identifier contains an embedded subfield that, when hashed to
a base multicast address, generates the multicast host address for the group.666 Chap.]2 • Case Studies
11.3.4ProcessManagement
The three basic abstractions used in V-Systemfor process management are process, team,
andteam space, whichrespectively correspond to theconcepts of"thread," "process," and
"aprocess's address space" presented in this book. To avoid any confusion, in the
description that follows, the terms thread, process, andaddress space willbeused instead
ofprocess, team, andteam space, except in V-System calls.
InV-System, process management activities are mainly performed by two
modules- thekernel process serverand theprogram manager. Each node of the system
has these two modules. The kernel process server executes inside the kernel, whereas the
program manager executes in the user space. One of the goals ofV-System designers was
to minimize the kernel process management activities so that the kernel can be kept as
small as possible. Therefore, the kernel process server performs only the basic low-level
process management functions and the rest are performed by the user-level program
manager. The role of these two modules in process creation, destruction, scheduling,
migration, and so on, are described below.
ProcessCreation andTermination
Threads and processes are dynamically created and destroyed by using the primitives
Createl'rocess, Create'Ieam, andDestroyProcess. When a thread iscreated, itiscreated as
partofthe same process as that of its creator. When a thread is destroyed, all the threads
created by itare also destroyed. Creation ofa process is similar to the creation of a thread,
except that in this case the newly created thread is created as a separate process and not
as a part of itsparent process. Also notice that there is no explicit operation for destroying
aprocess because aprocess isautomatically destroyed when the last thread in thatprocess
is destroyed.
To minimize the kernel'sjob in the process creation activity, V-System separates
process initiation from address space creation and initialization. Therefore, as far as
the kernel process server is concerned, creation of a new process simply involves
allocating and initializing a new process descriptor. The address space allocation and
initialization is performed by using V-System's virtual memory system, which is
described below.
In V-System,an address space is a range of addresses, called regions,bound to some
portion of -anopen file or a uniform input output (VID) object. (A VIDobject corresponds
to an open file in conventional systems.) Accessing a memory address that falls within a
region corresponds to accessing the corresponding data in the open file bound to the
region. The kernelmemoryservermodule manages the physical memory as a cache of
pages from open files. A page fault occurs when a portion of a region that corresponds to
an uncached portion of the bound object is accessed. To handle a page fault, the kernel
maps from the virtual address to a block in the bound VIO or open file and then either
locates that blockinthekernel page frame cache orelse causes the faulting process tosend
aread request requesting the data block to the server implementing the open file. File-like
read/write access may also be performed on address spaces by using the standard VID
interface.Sec.12.3•V-System 667
Creation andinitialization of address space of a process becomes a simple task by
using the virtual memory system. For this, an address space descriptor is allocated and the
program file of the process is bound to tbis address space. Now as the process references
portions of this address space, the program file pages are transferred and mapped into the
address space dynamically on demand. Hence, the V-System kernel has no special
mechanism for program loading.
Thekernel'sjob in process termination activity is simplified in the following manner.
In V-System, most operating system resources such as open files are managed by user­
level server modules. Therefore, there are few resources at the kernel level to reclaim
when a process terminates. Furthermore, when a process terminates, the kernel does not
inform the concerned servers because each server is responsible for keeping track of the
resources it has allocated to a client process and for checking periodically whether the
client.exists, reclaiming the resource if not. For example, the file server has a garbage
collector process that closes files that are associated with processes that do not exist any
more.
RemoteProgram Execution
In V-System, one of the following primitives may be used at the command interpreter
level to execute a program on a remote machine [Theimer eta1.19851:
•<program-name> <arguments> @<machine-name>
•<program-name> <arguments> @*
In the former case, the specified program is executed on the specified machine, but
in the latter case, the system becomes responsible for selecting an appropriate machine for
executing the specified program. The selection of an appropriate machine is done bythe
methoddescribed below.
In V-System, the program managers of all the nodes are grouped into a well-known
program manager (process) group. When a user uses the latter primitive for making a
request for remote program execution, the processor allocation module on the user's
machine multicasts a "remoteprogram execution request" message tothe program manager
group. Only program managers whose machines have permission from their users for
remote program execution and sufficient amounts of processor and memory resources
available repl ytothis message.Theprocessor allocation module then usesapolicy toselect
the most appropriate machine from the replies received. In the current policy, the machine
whoseprogram manager responds firstisselected sincethisisgenerally theleastloadedone
and also because this policy issimple and inexpensive toimplement.
Except for the selection of aprogram manager, remote program execution isthe same
as local program execution because processes in V-System are provided with a network­
transparent execution environment. Furthermore, the kernel and the program manager of
a machine provide identical services to both locally originated programs and remote
programs executing on this machine.
Initiation of a program execution (either local or remote) involves sending a
request to the appropriate program manager (of the local or remote machine) to createChap.12 • Case Studies
a new address space and load the image file of the specified program into this address
space. The program manager, in cooperation with the kernel processserverand kernel
memory server, sets up the address space and creates an initial process that awaits reply
from its creator. The program manager then turns over control of the newly created
processto therequester byforwarding the newly createdprocessto it. The requester
initializes the new program space with program arguments, default110, and various
"environment variables." Finally, it starts the execution of theprogram byreplying to
its initial process.
Note that a program can beexecuted remotely only ifit does not requirelow-level
access to the hardware devices of the machine on which it originated. That is, the
program should not access such hardware devices as disks, frame buffers, network
interfaces, and serial lines by directly accessing a device serverofitsoriginating
node.
Process Scheduling
In V-System, processes are scheduled using a priority discipline. Tosimplify the task
of the kernel, two-level scheduling is used to allocate the processor ofa node to the
processes assigned to that node. Akernel-level scheduler provides a very simple and
efficient priority-based scheduling. It simply takes the highest priority process in the
ready state and allocates it to the processor. On the otherhand, a process-level
scheduler that runs outside the kernel manipulates priorities toeffectively implement
time slicing among interactive andbackground processes. V-System gives special
treatment to real-time processes byreserving anumberofhigh-priority levels for
them.
ProcessMigration
ProcessMigration Policy. In V-System, a process may be selectedformigration
eitherby the system or on explicitrequestby a user. In the former case, processes are
selectedformigration betweenprocessors by aperiodically invokedkernelprocedure that
attempts tobalancetheprocessing load across the processors. On the otherhand, in the
latter case, all the processes corresponding to aprogram aremigrated togetherby invoking
[Theimer etale1985]
migrateprog I-n][<program~name>]
Theselection of anappropriate destination node for a migrantprocess(or group of
processes) is done in exactly the same manneras is done for selecting amachine for
remoteexecution of aprogram when the meta machine name"*,,is specified. The
processes ofthe specified program are not migrated if an appropriate destination node
cannotbefound for the program. However, if the "-n"optionis present, the processes of
theprogram aredestroyed if theycannotbe migrated. Furthermore, if theprogram name
is notspecified, an attempt is made to migratetheprocesses of allremoteprograms that
areexecuting on this node.Sec.12.3•V-System
ProcessMigration Mechanisms.669
1.Addressspacetransfermechanism. V-System uses the pretransfer mechanism for
address space transmission. This mechanism is described in Chapter8.
2.Message-forwarding mechanism. The three types of messages (type 1,type 2, and
type 3) to be forwarded to the migrant process's destination node are described in Chapter
8. V-System uses the mechanism of resending the message to forward messages ofall
three types. This mechanism is described in Chapter8.
3.Mechanism forhandling coprocesses. V-Systern ensures that when a parent
process migrates, its children processes will be migrated along with it. Therefore, the
method of disallowing separation of parent and child processes is used in V-System's
process migration to handle coprocesses.
Exception Handling
In V-System, all exceptions are handled bya user-level server process called the exception
server.When an exception condition occurs, the kernel causes the faulting process to send
a message describing its problem to the exception server. The exception server then takes
over and initiates necessary actions to deal with the problem by using the facilities of the
kernel and otherhigher level servers. The main advantage of this approach is that it allows
theimplementation of a powerful, flexible, and network-transparent exception-handling
mechanism with very little kernel complexity [Cheriton 1988].
12.3.5DeviceManagement
In V-System, most of the device management activities are performed by user-level server
processes. However, some device support must be provided in the kernel because device
interrupts go to the kernel, some device control operations are privileged, and kernel
controlofsome device operations is required for kernel integrity [Cheriton 1988].
Therefore, the V-System kernel has a kernel device server module designed to provide
efficient, reliable, machine-independent, and secure access to a wide variety of devices.
The kernel device server provides only minimum device support for a particular device
and hasdevice-independent code that interfaces between the user-level processes and the
driver modules for the individual devices.
Theinterface provided by the kernel device server is called the UfOinterface. It
allows client processes to use the standard 110 runtime support for device 110. It also
allows the user-level server processes to implement extended abstractions of devices for
application programmers. For example, the kernel device server provides access to each
disk drive as a raw block device, and the user-level file server implements files using this
basic interface. Similarly, for network connections, the kernel device server provides a
block interface to the Ethernet, providing the ability to read and write raw Ethernet
packets, and the user-level Internet server implements TCPIIP, UDP, and X.25
protocols.670 Chap. 12 • Case Studies
Device1/0isaccomplished bycreatinga VIO object that is viewed as a sequence of
data blocks that are read or written. The VIO interface defines the syntax and semantics
ofread, write, query, and modify operations that can be performed on VIO objects. With
thesupported operations and the use of a block-oriented data access model, the VIO
interface is general enough to handle awide variety ofdevices such as disk, tape, printer,
network interface, serial line, terminal, and even a mouse.
11.3.6Int.rproc8ss Communication
Interprocess communication isanimportant facilityprovided by the V-System kernel.
Specialcare has been taken in the design ofinterprocess communication facility to
providefastexchange ofmessages between client and server processes usingRPC-like
semantics. The three basic forms ofinterprocess communication provided by the kernel
arecommunication forfixed-length message transfer,communication forpassingaccess
to a data segment, and multicast communication. These are described below.
Fixed-Length Message Transfer
This form ofcommunication is used by processes to send, receive, and reply to requests
by using fixed-length messages. The three primitives provided for thispurposeareSend,
Receive, andReply.TheSendprimitive is used by a client processto pass the equivalent
of aprocedure argument. On the otherhand, the Receive,andReplyprimitives are used
respectively bya serverprocessto receive a client'srequest and to return the result ofa
request execution to the client. All messages are exchanged ina strictly synchronous
manner,Thatis, the process that has sent a message is blocked awaiting for the reply until
themessage it sent has been received and replied to by the receiving process. On the other
hand, after replying to aclient'srequest, a serverperforms a Receiveand blocks waiting
for amessage to be sent by a client. All these messages are offixed length (32 bytes).
PassingAccessto a DataSegment
In this form ofcommunication, aprocessuses theSendprimitive to send a pseudopointer
to oneofitsmemory segments (acontiguous rangeofaddresses) in afixed-length
message to areceiverprocess. The segmentsize and access modes are also specified in the
message. On receiving thismessage, therecipient processcan access this segment for
readingand/orwriting,depending on the access mode specified in themessage, while the
senderisawaiting reply from the recipient. Such reads and writes are handledby kernel
primitives CopyFrom andCopyTo(Fig. 12.6). The receivercanexecutetheseprimitives
several times before replying. Furthermore, thereceiver may forward the message to
anotherprocess, passingto it the segment access and the right to reply. The senderis
blockeduntil itreceives areply for the message that it sent.This facility allows parameters
tobepassedbyreference.
Thecommunication semantics forexchange ofmessages in the two forms of
communication described above isillustrated in Figure 12.6. Notice that in both cases the
senderandreceiverinteractin a strictly synchronous manner. Moreover, the receivercanSec. 12.3 • V-System
Sender
process
Send
I
IReceiver
process
IReceive
I
I
I
I
I
I
I671
Time
Blocked state
ExecutingstateCopyto
Copyfrom
Reply
Fig. 12.6 Communication semantics for exchange of messages in the V-System.
receive and queue multiple messages and can reply to a message when it wants. This
flexibility allows writing of applications that need sophisticated scheduling of message
handling and replies.
Multicast Communication
The third form of interprocess communication in V-System provides group (one-to-many)
communication facility. V-System supports the notion of a process group (or simply a
group), which is a set of processes identified by a group identifier. A process can
simultaneously belong to multiple groups and can freely join or leave groups.
Any process, including one that is not a member of a group, can send a message to a
group by specifying a group identifier inst.eadof a process identifier in theparameter for
Send.After sending, the sender may block or continue executing depending on whetherit
selects toreceive zero, one, ormore thanone reply message for themessage thatithas sent.672 Chap. 12 • Case Studies
The zero..reply case is used for making an unreliable multicastto the group because the
senderprocessdoesnotblockafter sendingthe message.Thesingle..replycase is usedfor
reliablemessagedeliverytoatleastonememberofthegroupbecausethesenderisblocked
until it receives one reply message. Further replies are simply discarded without any
indication of how manyother processesreceivedthe messageor replied it. Finally,in the
case in whichthe senderselectsto receivenreplies (n>1),allthereply messagesstarting
fromthesecondmessageanduptothenthmessagearequeuedinthekernelforthesenderto
retrieve until the start of the next messagetransaction,that is, the next Send.A primitive
GetReply isprovidedtoallowthesendertoreceivesubsequentrepliesthatarequeuedinthe
kernel.The sendingprocessdecideshowlongtowaitforthereplymessages.
In a group Send,a message can also have a qualifier, indicating that the message
should only be delivered to those members of the destination group that are coresident
withtheprocessspecifiedinthequalifier.Forexample,tosuspendaprocess P,a message
containing a request for suspend can be sent to the group of process managers with the
coresident qualifier specifying process P,thereby delivering the request message to only
the manager in charge of process P,not the entire group. The kernel simply routes the
request to the host address for process P.Notice that a qualifier need not always identify
a single process but may also be a process group identifier,in whichcase the message is
delivered to all members of the destination group that are coresident with the group
specified by the qualifier.
The multicastcommunicationfacilityis usedinY..Systemina numberof ways,such
as to transmit clock synchronizationinformationto the time servers in the kernel of each
node,torequestas wellasdistributeloadinformationas partofthedistributedscheduling
mechanism, and in the replicated file update protocol.
The kernel of Y..System has been carefully structured to minimize the cost of
communicationoperations.ForhandlingIPC,thekernelconsistsoftwo modules-a local
IPCmoduleandanetworkIPC module.Whenasenderprocessmakesa Sendcall to send
a message to a receiver process, the call is trapped into the kernel and processed by the
localIPCmoduleifthereceiverprocessislocal.Otherwise,itisprocessedbythenetwork
fPC module using the YMTP to communicate with the remote kernel and the remote
receiver process. It may be noted here that fast IPC in Y ..Systemis achieved not only by
using relatively simpleand basic IPC primitives but also due to the use of YMTP,which
is optimized for request..response behavior. YMTP supports multicast, datagrams,
forwarding, streaming, security, and priority of messages. The details of YMTP have
already been presented in Chapter 2 and hence will not be repeated here.
11.3.7V-System Servers
We saw that the V-Systemkernel provides only minimum functionality that serves as a
basic framework for implementing many traditional kernel..based functions as user ..level
serverprocesses.Thisallowstheuserstodesignandimplementtheirownserverprocesses
fortheirapplications.However,thereareseveralservicesthatarecommonlyusedbymost
applications.V-Systemprovidesserversforsuchservicessothattheusersneednotdesign
theirown serversfortheseservices.The servicesprovidedbysomeof the mostimportant
V-Systemservers are briefly described below.Sec.12.3•V-System 673
Program Manager
Theprogram manager (also known as the team server) performs most of the process
management activities. It performs jobs that are normally performed by the kernel in
traditional time-sharing operating systems, such as process creation andtermination,
processscheduling, andmaintaining resourceconsumption statistics for various processes.
It alsomanipulates priorities of processes to efficiently implement time slicing among
interactive, background, and guest processes (those that originated on some other node but
are being executed on this node). In addition, it serves as a user-level exception handler
and invokes an interactive debugger on faulting programs. Moreover, the program
managers of different nodes cooperate for implementing automatic load-balancing facility
and for process migration activities.
FileServer
The file server performs most of the file management activities performed by the kernel
in traditional operating systems. In particular, it provides an abstraction of the physical
storage devices by allowing the users to store and access data from these devices in the
form of read and write operations on files. The file server usually runs on a dedicated
server machine with mass disk storage. Since most workstations in V-Systemare diskless,
the file server also provides file access facility for clients on the network.
The file server is multithreaded for efficiency, so that when one thread blocks waiting
for a disk block, some other thread can be executed. Furthermore, all threads belonging
to the file server process share acommon buffer cache, which is used to keep heavily used
blocks in main memory.
InternetServer
The Internet server implements the TCP/IPsuite on top of the basic network interface
deviceprovided by the kernel device server. It has a multithreaded, modular structure for
efficiency and flexibility. Moreover, for better performance, itmakes direct use of several
kernel facilities such as real-time scheduling, accurate timing, and fast IPC. 'Itis not
permanently configured in the standard system and is loaded only when required.
PrinterServer
Theprinterserver spools print files. In general, print files are submitted to the printer
server byusing the IPC facility and VIO interface of V-System.However, when the printer
server runs an instance of the Internet server, print files can also be submitted by using
TCPconnections.
DisplayServer
The display server implements multiwindow facilities using a bitmap display. It also
provides a high-level graphics representation at the client interface, allowing commonly
usedoperations to beperformed local to the display server, rather than relying on674 Chap.12 • Case Studies
application facilities. For instance, the display server supportsmultiple views, zooming,
and redraw,makingthese facilities available for all applications.
11.4MACH
Mach is a microkemel-basedoperating systemdevelopedat Carnegie-MellonUniversity
(CMU)undertheleadershipof RichardRashidand withthesupportof DARPA,the u.s.
Departmentof DefenseAdvancedResearchProjects Agency.It is based on a previously
developed operating system at CMU called Accent [Rashid and Robertson 1981].
Therefore, many of the basic concepts in Mach are basedon Accent work. However,as
comparedtoAccent,Machhasmanyimprovedfeatures,includingfinergrainedparallelism
by the use of threads, multiprocessor support, a better interprocess communication
mechanism,andamoreflexibleandefficientmemorymanagementscheme.
The first versionof Mach wasreleased in 1986for the DEC VAXcomputer family,
includingthe VAX11n84, afour-CPU multiprocessor. By 1987,versionsfortheIBMRT
PC,SUN3,PERQ,Sequent,andEncoremachineswerealsoavailable.Atthistime,Mach
was mainly considered to be an operating system for shared-memory multiprocessor
systems, rather than a distributed operating system for a collection of machines
interconnectedbya network.This wasbecausemostof themachinesrunningMach were
tightlycoupled shared-memorymultiprocessorsystems.Anextendedversion(Mach 2.5)
was later released that was also suitable for loosely coupled distributed-memory
multiprocessorsystems.Thisversionalsoprovidedcompatibilitywiththe4.2BSDUNIX
byincluding mostofthe4.2 BSD UNIX into the Mach kernel. Due to the presence ofa
largeamountof BSD UNIXcode in the kernel,the Mach2.5 kernelwasquite largeand
monolithic.In 1989,a newversion(Mach3.0) wasreleasedin whichall the BSDUNIX
code was removedfromthe kernel and put in the user space.Therefore, Mach 3.0 has a
microkernelthat consists of pure Mach.
In 1989,the Open Software Foundation(OSF), a consortiumof computer vendors,
selected Mach as the basis of its first operating system, called OSF/l.OSF has such
important companies as IBM, DEC, and Hewlett-Packard as its members. The NeXT
workstationalso uses Mach as its operating system.
The following description of Mach is based on [Rashid 1987,Accetta et al. 1986,
Jones and Rashid 1986, Black 1990, Fitzgerald and Rashid 1986, Rashid et al. 1988,
Coulouris et al. 1994,Tanenbaum 1995,Silberschatzand Galvin 1994].
11.4.1 Design Goals and MainFeatures
Mach's design was influencedby the researchand design goals described below.
Open-System Architecture
One of the main goals of Mach was to design an open system thatcould provide a base
for buildingnewoperatingsystemsandemulatingexistingones.Toachievethisgoal,the
design philosophyused in Mach was to have a minimalmicrokernelthat would provideSec.12.4 • Mach 675
a small set ofbasicabstractions sufficient forderiving otherfunctionality andto
implement manytraditional kernel-based functions asuser-level servers. With this
approach, it isbothpossible andrationaltothinkoftraditional operating systemssuch as
UNIXandMS-DOS not asoperating systemkernelsbut asapplication programs­
serversor a setofserversthat can provideclientprograms withspecificprogramming
abstractions. Notethat themicrokemel-based designofMachallowsmultiple emulators
to be run simultaneously. Thismakesitpossible to runprograms writtenfordifferent
operating systems such as UNIX and MS-DOS on thesamemachine at thesametime.
Compatibility with BSD UNIX
Fromthe very beginning, animportant goalofMachwas toprovidefullcompatibility
withBSDUNIXsystems so that it couldreceivewideacceptance in theresearch and
academic communities. Thisgoal was initiallyachieved bycombining Mach and the 4.2
BSDUNIXintoasinglekernel.Although thisdesignguaranteed absolute compatibility
with the 4.2 BSDUNIX,it led to a large kernel.Theopen-system designstrategywaslater
employed, and all the BSD UNIXcodewasremoved from the kerneland put in the user
space.Thisredesign reducedtheMachkerneltoaminimal microkernel consisting ofpure
Machthatcouldbeusedas a base for emulating not only BSDUNIXbut also other
existing operating systems anddesigning newoperating systems on it.
Network Transparency
Similarto anyotherdistributed operating system,network transparency was also a goal
inMach.Toachieve this goal, a higherlevelnetworkwide namingsystemis used in
Mach.Itisimplemented byuser-level serverscallednetwork message servers thatare
involved intransparent sendingofmessages between twoprocesses that arelocatedon
different nodesofthesystem.Thisfacilityallowstransparent accesstonetworkwide
resources.
FlexibleMemory Management
Another important goalofMachwas tosupportapowerful andflexible memory
management system.Toachievethisgoal,Machprovides anelaborate virtual-memory
systemthat isimplemented intermsoffixed-size pages.Someoftheattractive features
ofMach'smemory management systemare asfollows:
1.Itclearlyseparates themachine-independent partsofthememory management
systemfrom the machine-dependent parts,makingthememory management systemfar
moreportable thanin.othersystems.
2.It isintegrated with the communication system,allowing therealization offast
local IPC.
3. It has a copy-on-write mechanism forefficient sharingofdatabetween twoor
moreprocesses. In thismechanism, dataarephysically copiedonlywhenthey are676 Chap. 12 • Case Studies
changed. Hence, it provides the potential to eliminate much data movement between the
kernel, block 110devices, clients, and servers.
4. It has an inheritance mechanism that allows a parent process to declare which
regions of memory are to beinherited by its children and which are to be read-writable.
This mechanism provides for various sharing policies to enforce protection between the
parent and its children processes.
5. Ithasan externalmemorymanager concept, whichallows the implementation and
use of multiple user-level memory managers for handling different memory managers.
Each user-level memory manager can implement its own semantics and paging algorithm
suitable to the object it is backing. The external memory manager concept also lends itself
well to implementing a page-based distributed shared-memory system.
Flexible IPC
Another goal of Mach was to provide a flexible IPC system that can allow processes to
communicate in a reliable and efficient manner. To achieve this goal, Mach uses a
message-based IPC that is based on ports, which are kernel objects that hold messages.
This IPC system has the following features:
1. It supports both synchronous and asynchronous message passing.
2. It guarantees reliable and sequenced delivery of messages.
3. It ensures secure message communication by using a capability-based access
control mechanism for controlling access to ports. Allmessages are sent to and
received from ports.
4. It supports network transparency by allowing a sender to send a message to a
receiver on another node without the necessity to know the receiver's location.
5. When both the sender and receiver of a message are located on the same node of
the system, it provides a way to transfer bulk data without doing any copying.
6. It supports heterogeneity by translating data types from one machine's
representation to another's when the data is transferred between two machines of
different types.
HighPerformance
High performance was also a goal of Mach. However, the use of the microkemel-based
design approach in Mach is subject to a performance penalty because message passing
between serving processes and the microkernel requires context switches, slowing down
the system. Some of the important techniques used in the design of Mach to obtain high
performance are as follows:
1. Use of multithreaded processes to take advantage of fine-grained parallelism for
multiprocessing.Sec.12.4• Mach 677
2. Use of hand-off thread scheduling policy for fast local IPC. For example, aclient
can "hand off'to a server and a server can "hand back" at the completion of a local IPC.
With this approach, although the context switch is unavoidable, the path through the
scheduler isoptimized or avoided.
3. Use of copy-on-write mechanism to minimize the copying of data. Notice that the
largest CPU cost of many operations in a traditional kernel is the copying of data (in and
out of buffers, for instance). Mach'scopy-on-write mechanism can be used to greatly
reduce the data-copying cost.
4. Use of a transparent shared library in the user space to perform server work
in the client address space. In Mach, many kernel activities areeffectively moved out
of the kernel directlyinto theclient'saddress space by being placed in a transparent
shared library. With this approach, to the extentpossible, the requirements of a server
areimplemented in the library, thus avoiding the need for either a message or a
kernel trap.
SimpleProgrammer Interface
Another goal of Mach was to provide a simple interface to the programmers. To achieve
this goal, Mach provides an interface generator calledMachInterface Generator (MIG).
MIG is basically a compiler that generates stub procedures from a service definition. The
stub procedures for all services are placed in a transparent shared library. It is these
procedures that are described in the manuals and called by application programs. This
approach allows the application programmers to use a service by simply making a
procedure call, rather than making a system call or writing code for sending and receiving
messages.
11.4.2SystemArchitecture
As Figure 12.7 shows, the Mach system architecture mainly consists of the following
layers:
1. Themicrokernel layer.The lowest layer is the minimal microkernel that is
replicated on each node of the system. It is minimal because it consists of a small set of
basic abstractions that are just sufficient and powerful enough to derive all other
functionality and features. In particular, this layer is concerned with IPC, memory
management, process management, and I/O services. To carry out these functions, it
supports five basic abstractions-tasks, threads, memory objects, ports, and messages.
Tasks and threads are abstractions for process management, memory objects is an
abstraction used in memory management, and ports and messages are abstractions for
interprocess communication.
2.User-level serverlayer.In Mach, many traditional kernel-based functions are
implemented as user-level servers. These servers form the next layer of the overall system
architecture. The servers at this layer may be broadly classified into two categories-678 Chap.12 • Case Studies
Application code
Transparent sharedlibrary
User
space
OS-n 05-15erv~rsspecificto~her
operating sys~ms emulated~usingMach
,.....----,File
serverGeneric
servers
Fig. 12.7 Mach system architecture.
generic and specific. Generic servers provide services of general interest. For instance,
there may begeneric servers for services such as user authentication, distributed file
management, transparent naming of objects, network protocols, and device allocation. On
the other hand, specific servers are used to provide particular behavior in a node. For
instance, a set of specific servers may be used to deliver the functionality of an existing
operating system, suchas UNIX.As shown in Figure 12.7,multiple setsof specific servers
may be used at a single node to emulate the functionality of different operating systems
at the same node.
3. Transparent shared-library layer. This layer contains the stub procedures
generated by MIG for all services, so that the application programmers can use a service
bysimply making a procedure call, rather than making a system call or writing code for
sending and receiving messages.
4. Application code layer. This layer contains the code for the application
programs.
11.4.3ProcessManagement
BasicAbstractions
The two basic abstractions used for process management in Mach are task and thread,
which basically correspond to theconcepts of "process" and "thread" presented inChapter
8. That is, a taskis an execution environment and athreadis the basic unit of execution.
Resources are allocated to and owned by a task, and all threads of a task share itsSec. 12.4 • Mach 679
resources. Toavoid any confusion, the term "process" will be used instead of "task" in the
following description of Mach.
Process and ThreadStates
At any instance of time, a thread may be in one of the following states:
1.Running. Athread that is in the running state either is executing on some
processor or is eligible for execution and waiting in the run queue for the allocation of a
processor to it.A thread that is blocked within the kernel (for example, while waiting for
a page fault to be satisfied) is also considered to be in the running state.
2.Suspended. A thread that is in the suspended state is neither executing on a
processor nor waiting in the run queue for processor allocation. The thread will not
execute until itis returned to the running state.
Similar to a thread, a process can also bein the running or suspended state.A process
can be running or suspended, independent of the state of its threads. However, the state of
a process affects all threads of that process. Therefore, if a process is suspended, its
threads cannot execute, irrespective of their current state. That is, a thread can execute
only when both it and its process are in the running state.
Processes and threads can be suspended and resumed under program control. For
this, each process and each thread has a suspendcounter associated with it.Primitives
process_suspend andthread_suspend are provided to increment a suspend counter and
process_resume andthread_resume to decrement it.When the suspend counter of a thread
(or process) is positive, it is suspended, and when itbecomes zero, its state becomes
running. This mechanism allows multiple suspend calls to beexecuted on a thread (or
process), andonly when an equal number of resume calls occur is the thread (or process)
resumed. Therefore, using a counter provides greater flexibility than using a bit and helps
avoid race conditions.
Operations on Processes and l'hreads
Each process owns a processportand each thread owns a thread port. These ports provide
the mechanism to operate on processes and threads. In particular, an operation on a thread
(or process) is invoked by sending a message to the thread port (or process port) of the
thread (or process). Access to a process port indirectly permits access to all threads within
that process, but not vice versa.
Processmanagement primitives provided in Mach include those for creating a
process, killing a process, suspending or resuming a process, controlling which threads of
a process can run on which processor or group of processors, setting the priority of a
process for scheduling of its current and future threads, getting a list of all threads in a
process, and getting statistical information about a process.
In Mach, threads are managed by the kernel. That is, thread creation and destruction
are done by the kernel and involve updating kernel data structures. The basic kernel680 Chap. 12 • Case Studies
interface provides a varietyofprimitives foroperations on threads. They providethe basic
mechanisms forhandling multiple activities within a single address space. However,
ratherthan making programmers work with these low-level primitives, Machprovides
manyhigherlevelinterfaces forprogramming in C and other languages. One such
interface is the C-threadspackage that is briefly described below.
TheC-threads Package
TheC-threads package allows the programmers to use the kernel threadprimitives in a
simpleandconvenient manner.Although it does not provide the full powerofthe kernel
interface, it is good enough for the averageprogrammers. Inparticular, it hasroutinesfor
directlycontrolling threads, for enforcing mutualexclusion forcriticalsectionsofthreads,
and forgeneralsynchronization ofthreads.
Theroutinesfor direct thread manipulation are given below:
• cthread forkis used to createa new thread in the same addressspaceas thecalling
thread. The thread executes concurrently with its parent thread. However, instead
ofexecuting theparent'scode, itexecutes aprocedure that isspecified as an input
parameter to this routine.
•cthreadexit is used to terminate thecallingthread. This routine is calledbya
thread when it has finished doing its work.
•cthreadjoin is used to cause the callingthread to suspend itselfuntil a specific
childthreadterminates.
•cthread_detach is used to announce that aparticular thread will neverbecthread_
joined(waitedfor). If that thread evercallscthreadexit, its stack and otherstate
information isimmediately deleted. Normally, this cleanuptakes place afterthe
parenthas done asuccessful cthreadjoin.
•cthreadyield is used by athread to voluntarily relinquish the CPU to the
scheduler when it has nothingto do. The scheduler can then schedule another
thread to run on that CPU.
Since all the threads ofaprocessshare acommon address space, the execution of
criticalregionsby thethreadsmust be mutually exclusive in time. In Mach, the mutex­
variabletechnique is used for this purpose; theassociated C-threads packageroutinesare
given below:
•mutex_alloc is used to dynamically create a mutex variable.
•mutexfreeis used to deallocate a mutex variable.
•mutex_lock is used to lock a mutex variable. If the mutex variable is already
locked,the thread keepstrying to lock it until it succeeds. Noticethat adeadlock
willresultif a thread with a lock tries to lock the same mutex variable. The
C-threads package does not guarantee bounded waiting. Rather, it is dependent on
thehardware instructions used toimplement the mutex routines.
•mutex_unlock is used to unlocka mutex variable.Sec.12.4•Mach 681
Finally, the condition-variables technique is used in Mach for general synchroniza­
tion of threads; the associated C-threads package routines are given below. Recall from
Chapter8 that acondition variable is associated with a mutex variable:
•condition_alioe is used to dynamically allocate a condition variable.
• condition freeis used to delete a condition variable that was previously
allocated.
• condition waitis used to unlock the mutex variable associated with the condition
variable and block the calling thread.
•condition_signal isused to indicate to a thread blocked on acondition variable that
the event being waited for may have occurred. The associated mutex variable is
then locked, and the thread starts executing in the critical region. Note that a
condition_signal does not guarantee that the condition still holds when the
unblocked thread finally returns from its condition_wait call, so the awakened
thread must keep executing the condition wait routine in a loop until it is
unblocked and the condition holds.
Threads Scheduling
Thethreads-scheduling scheme of Mach is illustrated in Figure 12.8. It uses the concept
ofprocessor sets,in which all the processors of the system are grouped into disjoint sets
by software. Depending on thecomputation needsofa thread and workload on each
31 _
Globalrunqueue
count=6,hint=O
oI
I
I
I
I
I
I
I
I
I
I,
I
I31 31
: Localrun Localrun
: queuefor queuefor
I CPU·4 CPU-5
I counteo count=3
" hint:::O I
,-----------------------~-,~,------------------------~,( \
I 0t------1
I
(,------------------------~,; \
: Priority0 ~
: (high) I
I
I
I
II
I
: Threads having
I priority=6
: Priority 31"'-'___.__I
: (low) Globalrunqueue
I counts7Ihint::1
I
I
I
I
:0 0 0,
I
I
I
I
I
I
I,
I
I
:31 31 31
ILocalrun Localrun Localrun
: queuefor queuefor queuefor
ICPU·1 CPU-2 CPU·3
Icount=O count-n count-z
" hint=2 I
,-------------------------~~
Processor set 1 Processor set 2
Fig. 12.8 Threads scheduling in Mach.682 Chap. 12 • Case Studies
processor set, each thread is assigned to one of the processor sets by software. Thus each
processor set has a collection of CPUs and a collection of threads. For the purpose of
scheduling, the CPUs and the threads of a processor set are totally independent of all other
processor sets. That is, the scheduling algorithm is mainly concerned with assigning the
threadsofa processor set to the CPUs of the processor set in a fair and efficient manner.
For fairness and efficiency, the scheduling algorithm uses a priority-based scheme with
dynamically variable quantum size. Its details are given below.
In Mach, each thread has an associated priority from 0 to 31,with 0 being the highest
priority and 31being the lowest priority. Moreover, as Figure 12.8shows, associated with
each CPU is a local run queue and associated with each processor set is a global run
queue.Each of these queues is an array of 32queues, with each queue corresponding to
priorities 0-31.Both the local and global run queues have two variables associated with
them-a count and a hint. The count variable contains the number of threads on all the
32queuesofthat run queue, and the hint variable contains the number of the queue out
of the 32 queues that currently has the highest priority thread. The hint variable allows the
search for the highest priority thread to be performed efficiently by avoiding the checking
of higher priority empty queues. In addition to these two variables, each global run queue
has a mutex variable associated with it that is used to lock the queue to ensure that only
one CPU at a time manipulates it.
The global run queue of a processor set holds those threads that can be assigned to
any of the CPUs of the processor set. On the other hand, each local run queue holds those
threads that are permanently bound to the corresponding CPU. For instance, a thread that
is adevice driver for a device connected toan individual CPU must run only on that CPU.
Putting such a thread on the global run queue is incorrect because in that case it may be
picked up for execution by some other CPU of the same processor set. With respect to a
particular CPU, threads in its local run queue have higher priority than the threads in the
global run queue of its processor set.
With this arrangement of queues and threads in a processor set, the basic scheduling
algorithm works as follows:
1. When the state of a thread with priority nbecomes running, it is put at the end of
queue n of eitherthe local run queue of a particular CPU (if it is permanently bound to
that CPU) or the global run queue. Notice that a thread that is not in the running state is
not present on any run queue.
2. When a thread that is currently running on a CPU blocks, exits, yields, or uses
up its quantum, the CPU first inspects its local run queue for the highest priority thread.
For this, it first checks the count variable. If it is nonzero, it takes the value of the hint
variable and begins searching the queue for the highest priority thread, starting at the
queuespecified by the hint. If the local run queue is empty (the value of its count
variable is found to be zero), the CPU searches the global run queue in the same
manner. However, this time it first locks the global run queue before starting the search
operation.
3.Ifno runnable thread is found on either queue, a special idle thread is run until
some thread becomes ready to run.Sec. 12.4 • Mach 683
4. Ontheotherhand,iftheCPUfindsarunnablethread,it runsthethreadforone
quantum. Whenthe quantumfinishes,acheckismadetoseeif anyotherthreadshaving
higherorequal prioritythanthejust-run threadhavebecomerunnable.Thecheck involves
searching both the local and global run queues.If such a thread is found, the CPU is taken
away from the currentthread and assigned to that thread, and the currentthreadis put at
the endofitspriorityqueuein theappropriate run queue. Otherwise, the same threadis
run foranotherquantum.
Inadditiontothe basic scheduling algorithm described above,Mach'sscheduling
schemehasseveralotherimportant features:
1. Toprovidehighefficiency when the systemis lightly loaded and good response
time to small jobswhen the systemisheavilyloaded, the size of the time quantum is
variedinversely with the total numberofthreads that are runnable.
2.Threadsmay also be scheduled preemptively. Forexample, ifthequantum size is
suddenly reduced due tosuddenincrease in the load of a processor set, thecurrently
runningthread(that was given the previously valid long quantum size) can be preempted
before it has fully utilizeditsallocated quantum. This feature allows fair CPU utilization
in asituation inwhichthesystemloadsuddenly increases. Athreadmay also relinquish
the CPU voluntarily beforethequantum expiresifitcurrently has no use for the CPU
(e.g., the cthreadyield routine).
3. The priority valueofa thread is dynamically changed toprevent the
monopolization ofaCPUby ahigh-priority thread. This feature allows fair utilization of
theavailable computing powerby all threads.
4.Handoff scheduling facility may be used to bypass the run queues and to directly
switchthe CPU to the threadspecified bythecurrently runningthread.
5. On a multiprocessor, Mach can also be configured to do affinity scheduling.
Furtherdetailsofthethreads-scheduling schemeofMach can be found in [Black
1990].
Exception Handling
Theexception-handling facilityofMachclassifies the uses ofexceptions into the
following categories:
1.Forerrorhandling
2. Fordebugging
The twoclassesofexceptions arehandledindifferent ways.Exceptions oftheformer
class are handledon aper-thread basis,whereasexceptions ofthe latter class are handled
by asingleexception handlerthat has a specialport,calledtheexception port, associated
with it.Whenanexception occurs,the kernel sends a message describing theexceptionChap. 12 • Case Studies
to the appropriate exception handler. The two types of exceptions are handled differently
because it makes little sense to try to debug only one thread or to have exceptions from
multiple threads invoking multiple debuggers.
In debugging, the exception-handling facilities of a process are inherited by its
children processes, allowing a debugger to manipulate an entire tree of processes. On the
other hand, in error handling, no exception-handling facility of a process is inherited by
its children processes, and the default assumption is that a process has no exception­
handling facility.
In Mach, if exceptions of both types occur simultaneously, error handlers take
precedence over debuggers. This is because error handlers are normally part of the process
and.therefore should execute normally even in the presence of a debugger.
12.4.4 Memory Management
Virtual-Memory Management
InMach, thememory ismodeledasalinearvirtualaddress spacesupported bypaging. Each
process has its own virtual address space within which its threads execute. The virtual
address space ofa process is generally sparse, consisting of holes of unallocated space
between sections ofthevirtualaddress spaceinuse.Thisisbecause Machmakes noattempt
tocompress theaddress space toremove theholesof unallocated memory thatappear inthe
address space as new items are mapped or removed from theaddress space.
The commonly used approach to maintain the virtual address space for each process
istokeep a linear page table from 0tothehighest usedpage in thekernel. Since the virtual
address space of a process in Mach is sparse, for a reasonable page size, this approach
would require excessive amounts of memory for fairly large page tables, making it
expensive. To overcome this problem, the concept of regionsis used in Mach, which is a
contiguous area of anaddress space represented asabaseaddress andasize.Aregion must
be aligned on a page boundary. The size of the table used to maintain the virtual address
space of a process is kept manageable by keeping information about only currently
allocated regions in it. A virtual address is valid only ifit falls in an allocated region.
Accessing an address that is in an unallocated region (unused virtual address space) will
result in a trap, which, however, can be caught by the process if itso desires.
Mach provides a number of calls for manipulating virtual address spaces. For
instance, the vm_allocate call allocates a new region of virtual memory. The caller can
specifyeitherboth a base address and a size or only a size. In the former case, the system
allocates the indicated region, whereas in the latter case, the system finds and allocates a
suitable region and returns its base address to the caller. The vm_deallocate call removes
a region from a process's address space and makes itno longer valid for the process. The
vm_read andvmwrite calls allow a process to access the virtual memory of another
process. The vm_copy call causes a memory region to be copied onto a new region. In
addition to these calls, there are other cansthat may be used for such purposes as to
control access protection of a region of memory, tocontrol inheritance of memory regions
by a child process from its parent process when new processes are created, and to get
information about a region in a process's address space.Sec.12.4 • Mach 685
External MemoryManagers
In traditional operating systems, management of secondary storage (such as a disk) is
usually based around a kernel-supplied file system that determines the paging scheme,
sharing semantics, and other implementation details of the corresponding objects (such as
file). The schemes built into the system for managing such objects may be suitable for a
large variety of objects but may not be the best for all types of objects. Therefore, Mach's
memorymanagement system is designed in such a way that it allows users to implement
and use their own special-purpose memory managers, having their own object
management scheme, for objects with special requirements. These special-purpose, user­
level memory managers are called external memory managers.
Forthe realization of the idea of external memory managers, an important abstraction
used in the memory management system of Mach is the memory object. A memory object
is an abstract object that represents a collection of data on which a set of operations are
defined (for example, read and write). Itcan be mapped into an unused portion of the
virtual address space of a process, forming a new region.
Memory objects are created and managed by external memory managers.As Figure
12.9 shows, for every memory object that is mapped in a process's address space, there
is an external memory manager that controls it. The Mach kernel simply acts as a cache
manager for these memory objects. It maintains a cache of memory-resident pages of all
mapped objects, as in other virtual-memory implementations. However. since theexternal
memory managers are user-level processes, it is possible to have different memory
managers for handling different classes of memory objects. This provides the flexibility to
have different sets of operations, different sharing semantics, and different rules about
what becomes of objects after they are mapped out for different classes of memory
objects. This flexibility also allows user-written memory managers to have their own
paging scheme for the memory objects they manage. Each memory manager can
Sparse address
space ofaprocess
(unmapped areas
are shaded)Mapped-in
memory
objectsExternal
memory
managersBacking
storage
Fig. 12.9 External memory managers and memory objects.686 Chap.12 • Case Studies
determine on its own where to store pages that are not in memory and whether to write
back any changed pages to secondary storage when a memory object is destroyed. Note
that memory objects are independent of the kernel in the sense that no assumptions are
made by Mach as to the content or importance of memory objects.
To make it possible for users to write and use their own memory managers, Mach
provides a well-defined interface between the kernel and the memory managers. This
interface takes the form of a communication protocol that consists of a set of message
types thatcan beexchanged between thekerneland thememory managers.These message
types can be classified into two categories-those that the kernel sends to memory
managers and those that memory managers sendtothekernel. Someexamples of those the
kernel sends to memory managers are as follows:
•memory_object_init. This message is sent when a memory object is to be mapped
for the first time. When a memory manager receives this message, it initializes
itself. The message contains the control and name ports (these port types are
described later) for the memory object being mapped. These ports are used later
by the memory manager to send messages to the kernel in connection with the
memory object.
•memory_object_data_request. This message is sent to a memory manager to
request data of a memory object managed by it when a page fault occurs on the
memory object. The message contains the range of the desired data.
•memory_object_data_write. This message issent whenthekernel needs to remove
one or more dirty pages of a memory object from resident memory, for instance,
due to page aging. The updated data to be written on the secondary storage is
included in the message.
•memory_object_da ta_unlock. This message is sent to request the memory
manager of a memory object to unlock a locked page of the object so that it can
be used for another process.
•memory_object_lock_completed. This message is sent to a memory manager in
reply to its memory_object_data_lock request (described below) made to the
kernel.
•memory_object_terminate. This message is sent to a memory manager to inform
it that the memory object named in the message is no longer in use and can be
removed from memory.
Some examples of message types the memory managers send to the kernel are as
follows:
•memory_object_set_attributes. This message is sent in response to the memory;
object_init message received from the kernel. It indicates to the kernel that the
memory manager is now ready to accept requests for the newly mapped-in
object.
•memory_object_data-provided. This message is sent in response to the memory_
object_data_request message to return the requested page to the kernel.Sec. 12.4 • Mach 687
•memory_object_data_unavailable. This message is sent in response to the
memory_objecl_data_request message when the requested data is not available.
•memory_object_data_lock. This message is sent to makea request to the kernel to
change the protection mode on pages. The message contains a lock_value that
specifies the new protection mode (read, write, execute) on the data specified in
the message.
•memory_object_data_clean. This message is sent by a memory manager to make
a request to the kernel to send it the pages specified in the message so that they
can be made clean by writing them to disk.
•memory_object_data_cache. This message is sent to tell the kernel whether it may
retain cached data of the memory objecteven when no process has it mapped in
to its address space.
•memory_object_destroy. This message is sent to tell the kernel that a certain
memory object is no longer needed and its information in the kernel can be
destroyed.
All messages from the kernel to the memory managers are sent asynchronously
because it is not reasonable for the kernel to block any of its threads waiting for a user
process that may not reply. The messages are exchanged between the kernel and the
memory managers by using the port-based interprocess communication mechanism of
Mach(described later). For this, the following types of ports are used:
1.Objectport.Every memory object has an object port associated with it. This port
iscreated by the memory manager that manages the object. Itis used by the memory
manager for receiving messages from the kernel about page faults and other events
relating t.othe object.
2.Control port. For each memory object, a control port is created by the kernel. It
is used by the kernel to receive messages related to the object from the memory manager
of the object.
3.Name port. For each memory object, the kernel also creates a name port. It is used
as a kind of name to identify the object. Name ports are not used for receiving messages
but rather are used as a point of reference. For example, each region of an address space
may be treated as an object, in which case the kernel has a name port for each region. Now
when a thread gives an address to the kernel asking it which region the address belongs
to, the kernel returns the name port of that region as an answer. Notice that all addresses
belonging to the same region will be identified by the same name port.
Now let us look at how a memory manager and the kernel interact to manage a
memoryobjectand to satisfy user access requests for data in the memory object. The call
vm_mapprovided in Mach (along with other calls for manipulating virtual address spaces)
is used to map a memory object into the virtual address space of the calling process. When
a thread needs access to data in a memory object, it makes a vm_map call. If this is the
firstvmmap call on the memory object, the kernel creates the control and name ports forChap.12 • Case Studies
the memory object and sends a memory_object_init message to the object port included in
thevm_map call. The memory manager that manages the memory object provides this
objectportas a part of its support of the object. In reply, the memory manager sends a
memory_object_set_attributes message telling the kernel what the object'sattributes are.
Initially, all the pages of the object are marked as unreadable/unwriteable, so that the first
access to the object will result in a trap. The thread that made the vm_map call is now
unblocked and allowed to execute.
When the thread attempts to read/write some data of the memory object, a page fault
occurs, and the kernel sends a memory_object_data_request message to the memory
manager via the object port of the memory object. On receiving this message, the memory
manager fetches the page by whatever method is appropriate for the concerned object and
returns a pointer to the page in the memory_object_data-provided message or returns an
appropriate error to the kernel. The kernel then maps the page into the faulting thread's
address space and unblocks the thread allowing it to continue with its execution.
In addition to the user-written specialized memory managers, there is a default
memory manager provided by the Mach system. This memory manager is needed for
several reasons, such as for taking care of the system's own memory needs, for managing
those regions of an address space that do not have a memory manager assigned to them,
and for managing a memory object in the default manner when the specialized memory
manager of that object crashes due to a bug in it. The default memory manager has an
interface identical to that of user-written memory managers. However, it uses the standard
file system to store data that must be written to disk. Unlike UNIX, which uses a separate
swap area, thedefault memory manager uses a temporary file for swap space. Notice that
when a process makes the vm_allocate call to allocate a region of virtual address space,
it is in fact mapping an object managed by the default memory manager that provides
zero-filled pages in response to the call.
To ensure that there is always sufficient free-page frames, Mach also provides a
pageoutdaemonthat is a part of the kernel. It runs as a thread within the kernel and uses
a first-in, first-out (FIFO) algorithm to select victims for page replacement. It wakes up
from time totime and checks the number of free-page frames. Ifthere are notenough free­
page frames, it selects one or more pages to be replaced. Ifapage selected for replacement
is dirty, it is sent to the memory manager in charge of the page'sobject in a memory_
object_data_write message. On receiving this message, the memory manager writes the
page to disk and informs the kernel when it is done.
Memory Sharing
The use of threads in Mach automatically allows the threads of aprocess to share the same
address space. Therefore, no special mechanism is needed to share memory among the
threads of a single process. However, for sharing memory among two or more processes,
Mach provides the three mechanisms described below.
Copy-on-Write Sharing. Wehave seen that each process in Mach, including the
kernel, has its own paged address space managed by the kernel. Therefore, two
processes of the same node can share a memory region by having entries for theSec.12.4• Mach 689
memory region in the page tables of both processes. This technique is used in the
copy-on-write memory-sharing mechanism. In this mechanism, two or more processes
share common memory pages by having entries for these pages in the page table of
each of these processes and making them read-only. The sharing continues until one of
the processes attempts to write into its own logical copy of a shared page; this causes
an actual copy of the page to be created for that process, so that it has its own version
of the page that is marked writable in the page table of the process. Other processes
that were sharing that page continue to use the old version of the page in the read­
only mode.
Controlled Inheritance ofAddress Space. This mechanism allows selective
memory sharing at the time of process creation. As in UNIX, a new process in Mach is
basically created as a copy of an existing process. However, Mach'sprocess creation
mechanism is different from that of UNIX in the following aspects:
1. In UNIX, the child process is always a clone of the process that executes the fork
system call, but in Mach the child process can be a clone of a different process called the
prototype.
2. In UNIX, the child process inherits the entire address space of its parent process,
but Mach allows controlled inheritance of address space. For controlled inheritance of
address spaces, Mach allows a process to assign one of the following three inheritance
attributes to each region in its address space:
(a)No access. A region with this attribute is not inherited by the child process. That
is,itis not a part of the child'saddress space.
(b)Shared access. A region with this attribute is shared between the prototype
process and the child. That is, the pages in the region are present in the address
spaces of both the prototype and child processes. Changes made byeither process
are visible to the other process.
(c)Copy access. A region with this attribute is copied and mapped into the child's
address space. The forksystem call of UNIX can be simulated by using this
option. However, in Mach, the region is not copied when thechild iscreated, but
thecopy-on-write mechanism is used for efficiency.
Distributed Shared Memory. Mach does not provide a direct mechanism for
sharing memory among processes on separate machines that do not have any common
shared memory. However, the external memory manager concept of Mach allows users
toimplement their own distributed shared-memory system. For example, to implement
apage-based distributed shared-memory system, a new memory object, the shared
page, can be defined. To manage these objects, one or more special memory managers
can be implemented. The memory managers could be as simple or as complicated as
needed, depending on which coherence protocol and data-locating mechanism, among
those described in Chapter5, are used in the implementation.690 Chap. 12 • Case Studies
12.4.5Int.rproc8ss Communication
BasicAbstractions
The two basic abstractions used for interprocess communication in Mach are ports and
messages. A portin Mach is a one-way communication channel, logically a bounded
message queue. A message is a typed collection of data objects. To communicate with
anotherprocess, a process sends a message to a port associated with the receiverprocess.
The message is queued at the port until the receiver retrieves it from the port. The sender
andreceivermust have permission to access the port. This permission takes the form of
acapability. For instance, a sender must have acapability with sendright for a port tosend
a message to the port, and a receiver needs a capability with receiveright to retrieve
messages from the port. Ports support reliable, sequenced, message streams in the sense
that the system guarantees the delivery of messages sent to a port in the order sent.
Management ofPorts
Ports are managed andprotected bythekernel.They arekepttrack ofonaper-process basis
rather than per thread. Therefore, all ports created by the threads of a process are unique
within theprocess. The kernel keeps norecord of which thread created which port.
Protection is ensured by keeping ports information safely inside the kernel, where
user processes cannot modify it. Furthermore, the threads of a process can send or receive
messages from a port only if the process possesses the appropriate port capability. A port
capability consists of a port identifier (pointer to the port) and a rights field telling what
access the holder of the capability has to the port. The three types of rights that may be
defined on aport are send,sendonce, andreceive.Acapability with sendright allows the
holder to send messages to the specified port any number of times. The sendonce right
allows the capability holder to send only one message to the port, after which the kernel
destroys the capability (this mechanism is useful for request-reply protocols). The receive
right allows the capability holder to read messages from the port. At any instance of time,
there can be only one process with receiveright to a port, but many processes may
simultaneously havesendright. A process having a port capability with receiveright may
send that capability in a message to another process. However, by doing so, the sender
loses its receiveright for the port and the receiver gains that right. For each process, the
kernel maintains a capability list that contains complete information about what rights the
process possesses for different ports. Since ports are kept track of on a per-process basis,
all the threads in a process are equally considered holders of the process's port
capabilities.
When a process holding a port capability with receiveright exits or is killed, the port
can no longer beused and is therefore destroyed by the kernel, even if it contains any
undelivered messages. The kernel then searches for all the sendcapabilities of theport and
marks them asdead.Any attempt tosend a message withacapability that has been marked
as deadbythe kernel fails, and the kernel returns an appropriate error code to the sender.
On the other hand, when there are no processes having a capability with sendright for a
port,the kernel (optionally) sends a message to the process having receiveright capability
for the port, notifying it that there are no senders left.Sec.12.4 • Mach 691
'The message queue associated with a port is of finite length and may become full.
Several options are provided for handling problems associated with message transmission
to a full queue. For instance, if a queue is full, a sender may abort the send, block until
a slot becomes available in the queue, or have the kernel deliverthe message for it. In the
latter case, the kernel acts as a single-message queue and cannotaccept any message from
the sender until it has delivered the already queued message ofthe sender.
Mach provides the facility to group a number of ports into a port set. A port may
belong to at most one port set at a time. It is possible to only receive messages from a port
set; sending messages to a port set is not possible. Furthermore, a port that belongs to a
port setcannotbe used directly to receive messages. This is because all messages sent to
any port in a port set are queued in a common queue, the port set'squeue. When a receive
is performed on a port set, the kernel returns oile message from the port set'squeue. If the
queueisempty, one of the options described above may beselected to handle this
problem. The facility to create a port set is particula.rlyuseful for writing server processes
that can service requests coming in on multiple ports, such as for a server that supports
multiple objects. Such a server can maintain a different port for each of the many objects
that it supports and get messages for any of them without having to dedicate a thread to
each one.
Message Passing
The basic interprocess communication mechanism involves the sender process sending
a message to a port and the receiver process receiving it from the same port. Messages
may be sent and received either synchronously or asynchronously. An RPC mechanism
is alsoimplemented in which the sender blocks after sending a message until a reply
comes back.
Amessage consists of a fixed-length header and a variable number of typed data
objects. The header contains such information ascapability name for the destination port,
capability name for the reply port to which return messages should be sent, message size,
and several types of options such as whether synchronous, asynchronous, or RPC type
communication is desired, what to do if the sendorreceivecannot complete successfully,
and what to do if the message queue at the port is full.
The data part of a message consists of a variable number of typed data objects. Each
dataobjectmay berepresented either as an in-line data or anout-of-line data. In the
formerrepresentation, the data object is included in the body of the message, whereas in
the latter representation, the message body contains a pointer to thedata object. Associated
with each data objectin the message is a descriptor that contains such information as the
type of data objectand its size. This information is needed so that the receiver can unpack
the data correctly. It is also useful to do conversions between machines, when the source
anddestination machines have different internal representations. Adata field of a message
may also contain a port capability when a process wants to send a capability to another
process.
The facility to use out-of-line data representation in a message body provides the
means to transfer the entire address space of a process in a single message.
Furthermore, when both the sender and receiver processes are on the same node,692 Chap. 12 • Case Studies
Mach uses the copy-on-write mechanism to transfer out-of-line data from the sender to
the receiver. That is, instead of copying the data physically from the sender's address
space to the receiver's address space, the kernel simply updates the receiver's page
table by placing information about all the pages of the data object in it and making
them copy-on-write. Depending on the bit in the descriptor for the data object, the
region corresponding to the data object is either removed from the sender's address
space (by deleting the corresponding entries from the sender's page table) or kept
there. In the latter case, a page of the data is physically copied in the receiver's
address space when the receiver attempts to write on it, and the corresponding entry
in thereceiver's page table is appropriately updated. This is done to ensure that any
modifications do not affect the original version of the data that the sender is still
using.
With the use of copy-on-write mechanism, message passing becomes very efficient
because no copying of data is required in most cases. In essence, message passing is
implemented by using "thevirtual-memory management mechanism.
Networkwide IPC
For networkwide IPC, Mach uses user-level servers called network message servers and
networkports that are ports for receiving messages from other nodes of the system. There
is a network message server at each node of the system. All the network message servers
work together to handle internode messages in a transparent manner.The three mainjobs
performed by network message servers are as follows:
1. Making the networkwide IPC mechanism network transparent.
2. Supporting heterogeneity by translating message data from the sender'scomputer
format to the receiver's computer format. The type information in the descriptor
for each data object in the message is used for this purpose.
3. Performing authentication of other network message servers to prevent message
data from falling into the hands of unauthorized users.
Processes of a node automatically inherit sendright to a port created by the local
network message server for receiving messages from local processes. The network
message server of a node allows local processes to register network ports with it, and the
network message servers of all the nodes communicate with each other to maintain a
distributed database of all network ports in the system. A process can gain sendright to
a network portby asking its local network message server to look up a name in its
database or by receiving a portcapability in a message.
The basic method by which a message is sent from a process PIonnodeAto a
processP2on nodeBis illustrated in Figure 12.10. It involves the following steps:
1. Process PI prepares the header and body ofthe message to be sent and
executes the messagesend system call for sending the message, just as in the case of
a local IPC.Sec.12.4• Mach
NodeA NodeS693
Kernel
3
Communication networkKernel
Fig. 12.10 Networkwide IPCmechanism in Mach.
2. The system call causes a trap to the kernel. The kernel extracts the receiver's port
number from the message header, and after determining that this port is nonlocal, it
forwards the message to the local network message server.
3. The network message server of node Athen consults the database of network ports
to find out the node to which the message should be forwarded. It then constructs a
network message containing the message of process PIand sends it across the network to
the network message server of node B.In some cases, the message between the two
network message servers is encrypted for security.
4. The network message server of node Blooks up the network port number
contained in the message and maps it to its equivalent local portnumber by using a
mapping table that it maintains. When needed, it also translates message data from the
representation of the computer at node A to its own computer representation. It then
executes the message_send system call for sending this message to the extracted local
port.
5. The system call causes a trap to the kernel. The kernel extracts the receiver's port
number from the message header, and after determining that this port is local with process
P2havingreceiveright for it, it provides the message to process P2when it executes a
messagereceive call. In this way, the message is transferred from the sender to the
receiver in a transparent manner.
Notice that since network message servers are user-level processes, they can be
designed by the users to allow for a flexible choice of data type representations, the
amount or type of security to be used on a network, and the use of a specific protocol
depending on the network to which they are attached. However, this flexibility isachieved694 Chap.12 • CaseStudies
at the cost of performance because pure kernel implementation (which most other
distributed systems use) has better performance than the approach having user-level
servers forward internode messages.
11.4.6UNIXEmulation
Mach emulates 4.3B5D UNIX. The basic approach used for UNIX emulation in Mach is
briefly described below. Its further details can be found in [Golub et at1990].
As shown in Figure 12.11, the two software components used for UNIX emulation
in Mach are the UNIX emulation library andUNIX server. The UNIX emulation library
is linked as a distinct region into every process emulating a UNIX process. This region is
inherited from /etc/initby all UNIX processes when they are forked off. The execsystem
call has been changed so that itdoes not replace the emulation library but justthe user
program part oftheprocess's address space. The UNIX server, which contains a large
amount of UNIX code, has the routines corresponding to the UNIX system calls. It is
implemented as a collection of C threads.
Application code
layerT
3
KernelUser-level server's+yer
Microkernel layer"----_----------J-L
1Traptothekernel
2UNIXemulation librarygets control
3RPetotheUNIXserver
4Systemcallperformed
5Replyreturned
6Controlgivenbacktotheuser programpartofUNIXprocess
Fig.12.11 UNIX emulation in Mach.
Thetrampoline mechanism [Tanenbaum 1995] is used to invoke the code in the
emulation library.In this mechanism, the code in the emulation library is not directly
invokedbyuser applications, but the emulation library gets control from the kernel whenSec. 12.4 • Mach 695
a system call causes a trap to the kernel. For this, Mach provides a call named task_set_
emulation, which assigns the address of a handlerin theemulation library to a given
system call number. At the time of system initialization, this iscalledfor eachUNIX
system call so that all of them get registered in a system call redirection tablemaintained
by the kernel.
With this setup, when a UNIX process makes a system call and traps to the
kernel, the kernel uses the system call redirection table and immediately transfers
control back to the emulation library of the same process. When the emulation library
gets control, it examines the machine registers to determine which system call was
invoked (note that at this time all machine registers have the same values that they
had at the time of the trap). The emulation library then packs the system call number
and necessary parameters into a message and does an RPC with the UNIX server. On
receiving the RPC message, the UNIX server' extracts the system call number and
parameters from it, carries out the system call, and sends back a reply to the
emulation library. On receiving the reply, the emulation library directly transfers
control to the user program without going through the kernel. The entire process is
summarized in Figure 12.11.
12.4.7Mach Interface Generator
Aprogrammer can write applications for the Mach system by directly using the
system call interface (several system calls of Mach were described in the sections
above). However, working at the system call level makes many programming tasks
tedious and repetitive. For instance, any client program that requests for a service
from a server process must have code to create and send messages to the server and
to wait to receive a reply. Similarly, any server program that provides service to client
processes must have code to accept messages, unpack them, dispatch them to the
proper routine, and reply after the routine finishes processing the data. A pro­
grammer's task can be greatly simplified by providing stub procedures (procedures
that generate most of the repetitive code) for all services and placing them in a
transparent shared library. With this approach, an application programmer can use a
service by simply making a procedure call, rather than making a system call or
writing code for sending and receiving messages. To facilitate this, Mach provides an
interface specification language and compiler called Mach Interface Generator (MIG).
MIGgenerates stub procedures from a service definition.
The MIG language allows interfaces between cooperating computing entities to be
specified andmaintained independent of specific languages or machine architectures. On
the other hand, the MIG compiler translates these specifications into interface code for
each of the programming languages supported within the Mach environment, including C,
C()MMON LISP,Ada, and Pascal. The interface code generated by thecompiler has code
forcommunication, runtime support for type checking, type conversions, synchronization,
and exception handling.
Over the years, MIG has proved to be a valuable tool because of the following main
advantages:Chap. 12 • Case Studies
1. It eases the task ofprogramming distributed applications byrelieving the
programmers fromconcerns aboutmessage data formats, operating systempeculiarities,
andspecificsynchronization details.
2. Itimproves cooperation between programmers working in different languages by
allowing bothclientand servers to be written in any of the languages supported within the
Machenvironment. The MIG compiler automatically takes care ofdifferences inlanguage
syntax, type representations, record field layout, procedure callsemantics, andexception­
handling semantics.
3. Itenhances systemstandardization byproviding a uniform message-level
interface between processes.
4. Itreducesthe costofreprogramming interfaces inmultiple languages whenever
aprogram interface ischanged.
11.5CHORUS
Chorusis amicrokernel-based distributed operating system that started as a research
projectin 1979 at INRIA (Institute National de Recherche enInformatique et
Autornatique), agovernment-funded laboratory in France. Until now Chorushas passed
through four majorversions (Versions 0-3).Version 0 (1979-1982) wasdesigned to
modeldistributed applications as acollection ofcommunicating processes calledactors.
Version 1 (1982-1984) was aimed at portingthe design ofVersion 0 from a shared­
memory multiprocessor system to a distributed-memory multiprocessor system. It also
hadadditional features of structured messages and some supportfor fault tolerance. The
main goal ofVersion 2 (1984-1986) was to add the UNIX source code compatibility
feature to the system so that existing UNIXprograms could be run on Chorusafter
recompiJation. In 1986, the Chorus team left INRIA and formed a new company, named
ChorusSystems, to make Chorus a commercial product. They started Version 3 in 1987,
with the main goal ofchanging the research system into a commercial product. For this,
the first goal was to providebinarycompatibility with UNIX so that UNIX programs
couldbe run on Choruswithout the need to recompile them. Many key concepts from
otherdistributed operating systems were also included in Version 3. In particular, a
message-based interprocess communication mechanism wasborrowed from V-System;
someoftheconcepts offastinterprocess communication, distributed virtual memory, and
externalpagerswereborrowed from Mach; and the idea ofusingcapabilities for global
namingandprotection wasborrowed from Amoeba. Version 3 also has RPC facility,
support forreal-time operations, and amultithreading feature. It is available as a
commercial productfor a wide range of hardware, such as the Intel 80x86family, the
Motorola 68000and88000families, and the Inmos Transputer.
ThedetailsofVersion 3 are presented below. The following description ofChorus is
based on [Pountain 1994, Armand et al. 1986, Rozieret al. 1988, Guillemont 1982,
Abrossimov et al. 1992, Batlivala et al. 1992, Lea et al. 1991, Lea et al. 1993, Tanenbaum
1995,Coulouris et al. 1994].Sec.12.5•Chorus
12.5.1hsl9nGoalsQndMain Faaturas
Chorus's design was influenced by the research and design goals given below.
UNIXEmulation andEnhancements697
One of the main goals of Chorus was to provide a UNIX compatibility feature so that
existing UNIX programs could berun on Chorus. This was not an initial goal but waslater
realized to be important for the commercial success of the system. Therefore, Version 2
of Chorus was designed to provide UNIX source code compatibility. Toachieve this goal,
the original kernel of Chorus was redesigned and converted to a microkernel by moving
as much functionality as possible from it to user address space. Then several processes
were added in the user address space to do UNIX emulation. Later, in Version3, a UNIX
emulation subsystem, called ChoruslMiX (MiX stands for Modular UNIX), was built on
top of the Chorus microkernel to provide binary compatibility with UNIX System V.The
microkernel of Version2 was further refined by moving out the part added to itfor source
code UNIX emulation and placing this part in the new UNIX emulation subsystem. A
4.3BSD UNIX emulation is also being currently implemented.
In addition to UNIX emulation, Chorus design also provides UNIX enhancements to
allow users of the lJNIXemulation t.ouse enhanced facilities provided by Chorus from
within UNIX processes. Twosuchenhancements are the use of multiple threads ina single
process and the ability to create a new process at a remote node.
Open-System Architecture
Another important feature of Chorus is its microkernel support, which provides a base for
building new operating systems and emulating existing ones in a modular way.With this
feature, multiple operating system interfaces, such as UNIX System V,BSD UNIX, OS/2,
and MS-DOS, can simultaneously exist on the same machine. Therefore, it will be
possible to run several existing applications that now are run on different machines on a
single machine.
Efficient and Flexible Communication
The basic communication paradigm used in Chorus is message passing. Since message
passing has a reputation of being less efficient than shared memory, Chorus's designers
have made great efforts to optimize the IPC system. The IPC system also provides a high
degree of flexibility in handling different types of communications. This IPC system has
the following features:
1. It provides both asynchronous message passing and request/reply type
interactions.
2. IthasRPC facility that provides at-most-once semantics. It also has lightweight
RPC facility for communication between two kernel processes.698 Chap.12 • Case Studies
3. It has group communication facility with the flexibility to choose whether a
message should besent to all members, to anyone member, to a particular
member, or to anyonemember with the restriction that the member should not be
on a specified node.
4. It ensures secure message communication by using a capability-based access
control mechanism that is similar to the one used in Amoeba.
5. When both the sender and receiver of a message are located on the same node, it
usesMach'scopy-on-write mechanism to transfer bulk data without doing any
copying.
Transparency
Chorus provides two types of transparency-network transparency and service reconfi­
guration transparency. Network transparency is implemented by the use of a single global
name space and user-level servers called network managers that are similar to Mach's
network message servers. On the other hand, service reconfiguration transparency, which
allows services to bereconfigured dynamically without being noticed by the users
interacting with them, is implemented by supporting port group and port migration
facilities. Note thatChorus is notperfectly network transparent because some system calls
work only for local cases.
FlexibleMemory Management
Two of the main facilities provided in Chorus for flexible memory management are
support for multiple user-level memory managers and support for paged distributed shared
memory. The former facility is implemented by using Mach-style external pagers, which
are called mappers in Chorus.
Supportfor Real-Time Applications
Another important goal of Chorus was to support real-time applications. To achieve this
goal, Chorus provides for flexible allocation of thread priorities and also allows for
customized thread-scheduling policies. Moreover, real-time programs can partly run inthe
kernel mode and can have direct access to the microkernel without any in-between
software.
Object-Oriented Programming Interface
Arelatively new goal of Chorus is toprovide system-level support for fine-grained object­
oriented languages and applications and to do so in such a way that new object-oriented
programs and old UNIX programs can berun on the same machine without interfering. To
achieve this goal, Chorus designers have designed a subsystem, called Chorus Object­
Oriented Layer (COOL), on top of the Chorus microkernel.Sec.12.5• Chorus 699
12.5.2 System Architecture
AsshowninFigure12.12, the Chorussystemarchitecture mainlyconsistsofthefollowing
layers:
1. Themicrokemel layer.The lowest layer is the microkernellayer, which is called
the"nucleus" inChorus.This layer is presenton each node ofthe system. It consistsof
fourcomponents, threeofwhich are machine independent and one is machine dependent.
Themachine-dependent part, called the supervisor, manages the raw hardware and
catchestraps,exceptions, andinterrupts. It alsohandlescontextswitching. This part has
to berewritten for each new hardware to which Chorusis ported. Of the three machine­
independent components, one is for processand thread management, one is for virtual­
memory management, and one is for handling interprocess communications, The four
components ofthe kernel are constructed in amodular way so that anyonecan bechanged
withoutaffecting the others.
Applicationcode layer
(applications,utilities,and libraries)
Subsystemlayer User
space
Object-oriented Other subsystems
subsystem
(calledCOOL)
Supervisor (machinedependent)~1T
System UNIX System V
processes of subsystem .
SUbSY+ (CalledChO~~MIX)
Kernel
processes of
subsystems
--L....----------------------4 Kernel
space
."ig.12.12Chorus system architecture.
2. The subsystem layer. Themicrokemel layerprovides a base for building new
operating systemsandemulating existingones in a modular way. Each such newly built
oremulated systemiscalledasubsystem, and all these subsystems together form the
subsystem layeron topofthemicrokernel layer. A subsystem presents awell-defined
interface to its users. For example, one such subsystem is the UNIX System-V
emulator, calledMiX,whichprovides UNIXinterface and allows UNIXprograms to700 Chap. 12 • Case Studies
be run on Chorus. Another such subsystem is the object-oriented subsystem, called
COOL, which provides system-level support for fine-grained object-oriented languages
and applications.
Each subsystem is a collection of Chorus processes. These processes are of two
types-kernel processes andsystem processes. Kernel processes run in the kernel mode
and system processes run in the user mode. Kernelprocesses can call one another and can
invoke the microkerneI for obtaining services. On the other hand, system processes can
send messages to each other and to kernel processes and can also make calls to the
microkernel.
The basic idea behind using kernel processes in the subsystem layer was to provide
a way to extend the functionality of the microkemel without permanently increasing its
size and complexity.This is achieved by providing the flexibility to dynamically load and
remove kernel processes during system execution. With this facility, it is possible to
dynamically configure the system software to match the hardware components of a
particular node of the system without having to recompile or relink the microkernel. For
instance, a disk server, implemented as a kernel process, need not beloaded on diskless
workstations.
The kernel processes share the address space withthe microkemel. Hence, they must
berelocated after being loaded.
3. Application code layer. The layer above the subsystem layer is the application
code layer. This layer contains user processes that include applications, utilities, and
libraries. The user processes of this layer and the system processes ofthe subsystem layer
share the user address space.
Auserprocess cannot make direct calls to the microkernel. It can only make system
calls offered by the subsystem that it is using.Toensure this, the microkernel keeps track
of which user process isusing which subsystem anddisallows a user process from making
system calls offered by other subsystems. However, real-time processes have special
privilege in the sense that they can run as system processes rather than as user processes.
This allows them to make direct access to the microkernel without any software in the
way.
11.5.3K.yAbstractions
The key abstractions used in the design of Chorus are as follows:
1.Actor.An"actor'tin Chorus corresponds to the concept of a "process" presented
in this book. It provides an execution environment for one or more threads and has an
address space and a collection of ports used to send and receive messages. To avoid any
confusion, in the description that follows, the term "process" will be used instead of
"actor," except in Chorus system calls.
2.Thread.A "thread" in Chorus is the same as the concept of a "thread" presented
in this book. In Chorus, threads are managed by the kernel. That is, their creation,
destruction, and scheduling are done by the kernel and involve updating kernel data
structures.Sec. 12.5 • Chorus 701
3. Region. Eachprocesshas an address space that consistsof one or more regions.
A region isan area of contiguous virtual address that is associated with some piece ofdata,
such as a program or a file. Regions of a processdo not overlap. Only those portions of
an address space that are occupied by the regions are accessible by thethreadsof the
owningprocess.In paged virtual-memory systems, a region is alignedon a page boundary
andconsistsofone or more pages.
4.Segment. Asegmentis acontiguous sequence of bytesidentified andprotected by
a capability. To make the bytes of a segment accessible to the threads ofaprocess, the
segment ismappedon to a region of the process's address space. A segment can be
simultaneously mappedinto multiple regions that may even be in different address spaces.
Once mapped, the threadsaccess the segment's bytes simply by reading and writing
addresses in the region. Note that to map a segmenton to a region, itis notnecessary that
thesegmentbeexactlythe same size as the region. If the segmentis larger than the region,
only a portion of the segmentequal in size tothe region will be accessible. An inaccessible
portion of the segment can be made accessible byremapping this portion on to the region.
On the other hand, if the segment issmallerthan the region, the result of readingan
unmapped addressdepends on the mapper (mappers aresimilartoMach'sexternal
memory managers and aredescribed later). The mappermay bedesigned to raise an
exception, return 0, or extend the segment in this case. Another way to access the bytes
of asegment withoutthe need to map it on to a region is to use traditional system calls
that are used for I/O operations on files.
5. Port. A port is a unidirectional communication channel, logically a bounded
message queue. Each port belongsto a single process and only one process can read its
messages. To communicate withanotherprocess, a process sends a message to a port of
thereceiverprocess. The message is queued at the port until the receiverretrieves it from
the port. Asin Mach, ports can be migrated between processes and can also be grouped
together to form port groups.
6.Message. In Chorus, the basic communication paradigm ismessage passing.
Hence, two processes communicate with each otherbyexchanging messages between
them. Amessage isaddressed to a port of the receiving process. A message has a header,
anoptionalfixed part (of 64 bytes), and an optional variable-sized body (of maximum 64
kilobytes). For the kernel, both the fixed part:and the body are untyped byte arrays.
Therefore, thesemantics of thecontents of a message can be decided by user
applications.
7. User identifier (UJ).In Chorus, most kernel resources, such as ports and
processes, areassigned a 64-bit UI that is guaranteed to be globally unique within a
systemin its entire lifetime. For uniqueness, UIsare formed of three fields-(a) the IDof
themachine (node) on which the tJI was created,(b) an epoch numberthat isincremented
each time the systemis rebooted, and (c) a counterthat is valid in the epoch. The first field
of a VI is used as a hint by the object-locating mechanism to locate the corresponding
object(resource). The VIs may be freely passed in messages and files from one process
to another.702 Chap.12 • Case Studies
8.Local identifier (LI). The systemwide unique VIsare long and expensive to use.
Therefore, for efficiency,resources (such as threads and ports) within a single process are
identified by LIs, which are 32-bit integers. The LIs are validonly within the process that
uses them.
9.Capability. Capabilities are used both as resource identifiers and for restricting
access to resources. They are mainly used for identifying resources managed by a
subsystem, but in some cases they are also used to identify resources managed by the
kernel. A capability consists of the following two fields-(a) a 64-bit VI that is
normally the identifier of the port to which messages are sent to request operations on
the object and (b) a 64-bit key. The key has two fields. The first field serves as an
index into a resource table to identify a resource from among multiple resources
accessed via the same port. The second field contains a random number that makes it
difficult to guess a valid capability. Processes can send capabilities to other processes
or store them in files.
10. Protection identifier (PI). For authentication purposes, each process in Chorus
has a PI associated with it.A PI is a bit string having no semantics associated with it. By
default, a process's PI is that of the process that created it but can bechanged by kernel
or system processes. When a process receives a message, itcan request the kernel to
specify the PI of the process that sent the message. This mechanism can be used in the
design of a server process to implement access control for the resources that it manages.
For instance, to emulate UNIX protection semantics, the equivalent of a UNIX user
identifier (UID)can be associated with each process, and then the Chorus PIs can be used
to implement the UIDs.
Of the key abstractions described in Section 12.5.3, the two basic abstractions used for
process management are process (actor) and thread.
Types of Processes
In Chorus, processes are classified into the following types:
1. Kernel processes. All kernel processes reside in the kernel space and share the
same address space with each other and with the microkernel. They execute in the kernelmode. They are trusted, which means that they are allowed to make direct calls to the
microkemel. They are also privileged, which means that they are allowed to execute I/O
and other protected instructions for making direct access to system resources. For high
performance, Chorus provides the facility of lightweight RPC, whichkernel processes can
use tocommunicate with each other. This communication facility is not available to the
other two types of processes.
2. System processes. System processes reside in the user space and execute in the
user mode. Each system process has its own address space. These processes are notSec. 12.5 • Chorus 703
privileged buttrusted.That is, they can make directcalls to the microkernel butcannot
executeprivileged instructions meantfordirectaccess to systemresources.
3. Userprocesses. Userprocesses reside in the user space and executein the user
mode.Eachuserprocesshas its own addressspace.Theseprocesses areneitherprivileged
nor trusted. Therefore, they are the least powerful ones.
Theproperties of the three types of processes inChorusaresummarized inFigure
12.13.
Process Space Execution Private Privileged Trusted
type mode address
space
KernelKernel No Yes Yesprocess Kernel
SystemUser User Yes No Yesprocess
User User User Yes No Noprocess
Fig. 12.13 The three types of processes inChorus.
Process and ThreadStates
InChorus,aprocessmay be in one ofthefollowing states:
1.Active.Aprocessis in the active state when its threads can change states and can
bescheduled to run.
2. Stopped. Aprocessis in the stoppedstate when it is frozen. All the threads ofa
stoppedprocessare in the stoppedstate.
On theotherhand, a thread may be inoneofthefollowing states:
l.Active.A thread in the active state is eitherexecuting on some processor or
eligible forexecuting andwaitingin the run queue for the allocation ofa
processor toit.
2.Waiting. When a thread blocks and has to wait for some event to occur, the thread
is put in the waiting state until the eventoccurs.
3. Suspended. A thread that isinthesuspended state isneitherexecuting on a
processor norwaitingfor aneventto occur. It has been intentionally suspended by
eitheranotherthreadoritselfbyissuinga.kernel call to suspendthe thread.
4. Stopped. Allthreadsof aprocessenterthestoppedstate when the process's state
changesfrom active to stopped. Note that a thread may simultaneously be in any
oneofthe first three states and the fourth state.704 Chap.12 • Case Studies
The following system calls affect process and thread states:
•actorCreate is used to create a new process. The process type (kernel, system, or
user) and the initial state of the process can be specified as parameters. The
process's capability is returned to the caller.
• actorStop is usedtochange the state of a process from active to stopped. The state
of all the threads of this process is changed to stopped.
• actorStart is used to change a process's state from stopped to active. All the
threads of this process resume their original states from the stopped state.
•threadCreate is used to create a thread. The initial state, priority, and so on, are
specified as parameters.
•threadSuspend is used to suspend a thread.
•threadkesume is used to restart a suspended thread.
Threads Synchronization
Since all the threads of a process share a common address space, the execution of critical
regions by the threads must bemutually exclusive in time. The two mechanisms used in
Chorus for this purpose are the mutex variable technique and the counting-semaphore
technique. The mutex variable technique (described inChapter 8) is used only for mutual
exclusion. It has the advantage that operations that do not cause the caller to block can be
carried out entirely in the caller'sspace without the need for a kernel call. On the other
hand, the counting-semaphore technique is used in Chorus for general synchronization of
threads. In this technique, system calls are provided for performing UP and DOWN
operations on the counting semaphore to increment or decrement its value. The system
calls provided for threads synchronization in Chorus are as follows:
•mutexlnit is used to initialize a mutex variable.
• mutexGet is used to perform a lock operation on a mutex variable.
• mutexRel is used to perform an unlock operation on a mutex variable.
• semlnit is used to initialize a counting semaphore.
• semPis used to perform a DOWN operation on a counting semaphore.
• semVis used to perform an UP operation on a counting semaphore.
Threads Scheduling
In Chorus, threads are scheduled by the kernel according to individual kernel priorities
that canbedynamically changed. Each process is assigned a priority and each thread is
also assigned a relative priority within its process. The absolute priority of a thread is the
sum of its own priority and the priority of its process. A separate queue of active threads
is maintained for each absolute priority level. When a CPU becomes free, the first thread
of the highest priority nonempty queue is allocated to it for execution.Sec.12.5• Chorus 70S
We have seen that Chorusprovides supportforreal-time applications. For this, a
threshold prioritylevel is used to divide the activethreadsinto two groups,anddifferent
scheduling algorithms are used for scheduling ofthreadsin these two groups.Thatis,
threadsthatbelongto aqueuehavinglowerprioritythan the threshold prioritylevel are
timesliced andconsume CPU time on a quantum basisin around-robin mode. On the
otherhand, athreadthatbelongsto aqueuehavinghigherprioritythan the threshold
prioritylevel,oncerun, will continue torununtileitheritvoluntarily releasesitsCPUor
anevenhigherprioritythreadbecomes active to run. This mechanism isconsidered to be
goodenoughforhandling mostreal-time applications.
Thesystemcalls for dynamically changing thepriorities are as follows:
•actorPriority is used to eitherread orchangethepriorityvalue of a process.
•threadPriority is used to eitherread orchangetherelativepriorityvalueofa
thread.
Exception Handling
InChorus,there is a single exception handlerkernelthread,and each processmay also
have its own exception handlerthread.Whenanexception occurs,anattemptis first made
tohandleit by using the kernel exception handlerthread.Ifthis fails, the kernelsuspends
the thread that causedtheexception and sends a message to theexception handlerthread
of the same process. The faulting thread is killedby thekernelif thismethodalso
fails.
12.5.5M8moryManag_ment
RegionsandSegments Management
Ofthe keyabstractions described inSection12.5.3, the two basic abstractions used for
memory management are region and segment. They have alreadybeendescribed in
Section12.5.3, and hence only the systemcallssupported inChorusfortheirmanagement
and use are presented here. Only the important ones (not all) are given below.
•rgnAliocate is used to allocatearegionin aprocess's addressspace and set its
properties. Theprocess '8capability, startingaddressof the region, size ofthe
region,andvariousinitialization optionsarespecified asparameters.
•rgnlnitis used to allocatearegion and to initialize it with the contentsofasegment
whosecapability isspecified asaparameter. Severalothercalls that are similarto
rgnlnitbut fill the allocated region in different ways are also provided.
•rgnSetProtect is used to changetheprotection status(read, write, executebits)
associated with a region. Itis also used to make aregionaccessible only to the
kernel.
•rgnStatis used to get the size and otherinformation about a region.
• rgnFree is used to free the space allocated to aregion,which can then be used for
allocation to new regions.706 Chap. 12 • Case Studies
• sgRead is used to read data from a segment. Theportionofthe data to be read is
specified by anoffsetandnumberofbytes as parameters. Thebufferaddress to
whichdata is to be copiedis alsospecified as aparameter.
• sgWriteis used to write data to a segment. Theportionto be written is specified
by anoffsetandnumberofbytes as parameters. Thebufferaddress from which
datais to becopiedis alsospecified as aparameter.
Mappers
Mappers ofChorusare very similartoexternal memory managers ofMach. For every
segment that ismappedto a region, there is a mappertocontrolit. Asinglemappermay
controlmultiple segments. The kernel acts as a cachemanager for themappedsegments.
That is, the virtual-memory component ofeach kernel maintains a pagecacheofmemory­
residentpagesand keeps track ofwhich page belongsto which segment. It also keeps
trackofwhichofthecachedpages are dirty and which are clean. When a page is selected
forreplacement tocreatespace for a new page in the cache, the kernel simply discards it
if it isclean;otherwise it is sent to the appropriate mapperto be written back to the
corresponding segment. On theotherhand, when a page fault occurs,the kernel first
checksifthe page is presentin the cache. If not, it makes a requestto theappropriate
mapperto send the page and suspends the faulting thread until the page is received. The
mapperthen fetches the page from the segment's storagelocationif the page is not already
presentin itsaddressspace. The mappernotifiesthe kernel when the page becomes
available with it. The kernel then acceptsthe page from the mapper, updates the memory
management unit(MMU)page tables, and resumes the faulting thread.
Somemapper-related systemcallsprovided inChorusare as follows:
•MpCreate is used by the kernel or a program torequestamapperto swap out a
segment and toallocatedisk space for it. In response to this call, the mapper
allocates a newsegment on disk and returnsacapability foritto the caller.
•MpRelease is used to requestamappertoreleaseapreviously createdsegment.
•MpPullln is used by the kernel to make a requestto themapperfor some data from
asegment that itcontrols.
•MpPushOut is used by the kernel to send some data ofasegment to amapperthat
controlsthatsegment. This is needed when the kernel wants to replace a dirty page
ofthesegment from its cache.
Distributed SharedMemory
Thedistributed shared-memory mechanism supported inChorusmay becharacterized as
follows (see Chapter5 for details ofthesecharacteristics):
1. It uses page size as block size. To facilitate this,segments are split up into
fragments ofone or more pages.
2. It uses the replicated, migrating blocks(RMB)strategy.Sec.12.5•Chorus 707
3. To simplify the memory coherence problem, itclassifies fragments into two
types-read only and read-write. Replication ofread-write fragments is not
performed. Therefore, onlyread-only fragments arereplicated andread-write
fragments have only one copy in the entiresystem.
4.It uses the dynamic distributed-server algorithm for datalocating.
12.5.6Interprocess Communication
Ofthe keyabstractions described inSection12.5.3, the two basic abstractions used for
interprocess communication aremessage and port. Messages are sent to and received from
ports, and ports are createdanddeleteddynamically byprocesses. The system calls for
creating anddeleting ports are as follows:
• portCreate is used for creating a new port. The capability ofthe port is returned
to the caller, which can be sent tootherprocesses to allow them to send messages
to the port.
• portDelete is used to deletea port.
SendingandReceiving of Messages
Chorusprovides the following communication operations to allow threadsto send and
receivemessages in a flexiblemanner:
1.Asynchronous send.ThesystemcallipcSend is used to asynchronously send a
message to a port. Thereis noguarantee ofsuccessful message delivery and no
notification is made to the senderin caseofcommunication failure. This type of
communication facility can be used by users to build arbitrary communication patternson
top of the basic communication facility of Chorus.
2. Receive. Thesystemcallipckeceive is used to receive a message. Two optionsare
available in this case. In the first one, a threadcanspecifywhich port it wants to receive
on. In the second one, a processcanspecifythat it wants to receivefromanyoneof the
ports that it owns. The receiveoperation ofthesecondoption can be made more selective
by using the following mechanisms:
(a) Bydisabling some of the ports by using portDisable systemcall, in which case
onlyenabledports are eligibletosatisfythe request. A disabled port may be
enabledby using the portEnable systemcall. Ports can be enabledanddisabled
dynamically.
(b) Byassigning priorities to ports, in which case if more than one enabledport has
a message, the enabledporthavingthehighestpriorityisselectedtoreceivethe
message. Priorities of ports can be changed dynamically.
If no message is available when the ipcReceive systemcall is made, the callingthread
issuspended until amessage arrivesor auser-specified timerexpires.708 Chap. 12 • Case Studies
Chorus uses the copy-on-write mechanism of Mach for efficiency. Therefore, when
a message isreceived, its body iscopied to the receiver process's address space only ifthe
sender and receiver processes are on different machines. If the two are on the same
machine, the message body is simply mapped to a region of the receiver process's address
space, and a page of the message body is copied only when the receiver modifies it.
3. RPC. The third type of communication operation supported in Chorus is RPC,
which allows request/reply type interactions. The system call for initiating an RPC is
ipcCali.The process making this call isautomatically blocked untileither the reply comes
in or the RPC timer expires, at which time the sender is unblocked. At-most-once
semantics is supported for RPCs.
GroupCommunication
Groupcommunication facility is supported in Chorus by allowing multiple ports to be
grouped together to form a portgroup.The system calls provided for this purpose are as
follows:
• grpAlloc is usedtocreate anempty port group. The capability of the newlycreated
port group is returned to the caller. Using this capability, the caller or any other
process that subsequently acquires the capability can add or delete ports from the
port group.
•grpPortlnsert is used to add a new port to an existing port group.
•grpPortRemove is used to delete a port from a port group.
A sender sending a message to a port group has the flexibility to select one of the
following addressing modes:
1. Broadcast mode. In this case, the message is sent to all ports in the group. This
mode of communication is useful in such cases as sending a file update to all servers
having a replica of the file or for requesting an operation upon a resource that is managed
by some member of a group of servers, but it is not known which member. In the former
example, all members of the group take action on receiving the message, and in the latter
example, only the member that manages the resource takes action and the other members
simply discard the message.
Note that the broadcast mode of communication does not provide message-ordering
guarantees. If this is required, it must be implemented by the user.
2. Functional mode. In this case, the message is sent to only one port in the group
that is selected by the system. This mode of communication is useful in such cases as
where a service is performed identically by a number of servers and a client does notcare
which server provides the service and may not want to be bothered with the knowledge
of the identity of the particular one assigned. In such cases, the client simply sends a
request to the group of servers providing the service, and the system selects the most
suitable server at that time for servicing the client'srequest.Sec.12.5•Chorus 709
An interesting application of the functional mode of communication is to provide
reconfigurable services in a system. For instance, all servers providing some service can
be grouped together to form a single port group. Now clients send their requests to the
group in the functional mode without having to know which servers are available at that
time to provide the service. This transparency feature allows new upgraded servers to be
added to the group and removal of old servers from the group without disrupting the
services and without the clients even being aware that the system has been
reconfigured.
3. Selective functional mode. In this case also the message is sent to only one port
in the group, but the port is selected by the caller and not by the system. A practical use
ofthismode ofcommunication is in load balancing. An overloaded node may first use the
broadcast communication mode to get the current loads of all other nodes. From the
replies received, it selects the most lightly loaded node. It then uses the selective
functional mode of communication to transfer some of its load to the selected node.
The three modes of group communication aresummarized in Figure 12.14.Note that
in all three modes messages are sent to port groups by using the asynchronous send and
hence the communication is unreliable.
Fig. 12.14 Group communication
modes in Chorus.Communication Message Member
mode sentto selectedby
Broadcast All members -
Functional Onemember System
SelectiveOnemember Callerfunctional
Port Migration
In Chorus, a system call named portMigrate maybeused to remove a port from one
process and to move it to another process. When a port is moved, all the messages
currently initare moved along with it.Asone would expect, ports remain members ofport
groups when they migrate.
The port migration facility allows the responsibility of providing some service to be
dynamically transferred from one server to another without being noticed by the clients
who are currently interacting with the server for that service. An interesting application of
this facility is for supporting maintenance transparency. For example, a server on a
machine that is going down for maintenance can migrate its ports to another server on a
different machine thatprovides the same services. Client requests continue tobe processed
consistently without any disruption. In this way, server machines can go down for
maintenance and come up later without being noticed by their clients.710 Chap. 12 • Case Studies
Networkwide IPe
For networkwide IPC, Chorus uses networkmanagers that are similar to Mach's network
message servers. There is a network manager process at each node of the system, and all
the network managers work together to extend the communication facilities of the kernel
transparently across a network.
When a thread sends a message to a port, the kernel of that machine looks up the
port'sVI in a list of local ports. If it is not found in the list, the kernel forwards the port's
VI to the local network manager. The local network manager then communicates with
other network managers to get the location of the port.Once the port has been located,
messages sent to theport thereafter aredelivered directly toa port ofthe network manager
of the node on which the message port is located. The network manager of that node then
forwards the message to the local port to which the message was sent.
12.5.7UNIXEmulation andExt&nslons
UNIXEmulation Approach
Chorus designers have built a subsystem called ChoruslMiX (Modular UNIX) for
providing binarycompatibility with UNIX System V. The basic approach used for
designing this UNIX emulation subsystem is briefly described below. Further details can
be found in [Gien and Grob 1992, Armand et al. 1989].
The ChoruslMiX .subsystem primarily consists of the following processes (see Fig.
12.15):
UNIX
process I
Userprocesses
StreamsUNIXemulation
manager subsystem 4
OfPC
managerOObject
manager
3
5Process
manager
Microkernel'--------------------*--
1Traptothe kernel
2Processmanagergetscontrol
3APetoasuitaolemanager
4Systemcallperformed
5Replyreturned
6BlockedUNIXprocessrestarted
Fig. 12.15 UNIXemulation in Chorus.Sec.12.5• Chorus 711
1. Process manager. This process is the main component of the emulation
subsystem. It catches all system call interrupts and, if necessary, communicates with other
processes of the subsystem to handle system calls. In addition, it performs jobsrelated to
processmanagement (including creation and termination of processes), signal handling,
and resource naming.
2. Object manager. This process mainly performs file management activities and
may also contain the disk driver. It also acts as a mapper for the files itcontrols.
3. Streams manager. This process manages pipes, sockets and networking, and
stream devices such as keyboard, display, mouse, tape devices, and so on.
4. Interprocess communication manager. This process handles system calls related
to System V messages, semaphores, and shared memory.
Of these four processes, the process manager contains a large amount of newly
written code, while others mostly contain UNIX code itself. Moreover, only the process
manager is needed atall nodes having the UNIXemulation subsystem; theother processes
are optional and are loaded only where needed. For example, the object manager is not
loaded on diskless nodes.
The four processes may be run either in the kernel mode or in the user mode.
However, for performance and security reasons, currently they all are run in the kernel
mode.
The process manager has multiple threads. Other managers initially start with one
thread and additional threads are created as requests come in.
When the system is booted, it inspects its environment and accordingly loads only
thoseoptional processes thatareneeded.Aspartoftheirinitialization, eachoftheseoptional
processes send a message to the process manager announcing their ports and telling what
systemcalls theycanhandle.Ontheother hand,theprocess manager informsthekernel that
it wants to handle trap numbers that UNIXuses for making system calls. The kernel
maintains atable containing theaddress of aroutine foreach emulated system call.
With this setup, when a UNIX process makes a system call and traps to the kernel,
the thread in the process that handles the corresponding system call automatically gets
back control from the kernel. If the system call can be completely handled locally, the
process manager performs the requested system call itself. Otherwise, depending on the
system call, the process manager does an RPC to either the object manager, streams
manager, or interprocess communication manager. The contacted manager process
performs the requested system call and sends a reply back to the process manager, which
then sets up the proper return value and restarts the blocked UNIX process. The entire
process is summarized inFigure 12.15.In the example shown in the figure, the system call
is handled by the streams manager.
Comparison withMach'sUNIXEmulationApproach
The relative advantages and disadvantages of theapproaches taken inMach and in Chorus
for supporting UNIXemulation are as follows [Coulouris et al. 1994]:712 Chap.12 • Case Studies
1. Modularity. Chorus design provides better modularity than Mach design because
theemulation subsystem uses different server processes to provide different UNIX
facilities, as opposed to Mach in which a single UNIX server process is used to provide
all UNIX facilities. Since the four manager processes of Chorus do not share any variable
or other memory and they communicate exclusively by RPC, any ofthem can be
reimplemented independently of the others, provided the interfaces are not changed.
2.System state management. Since Mach uses a single UNIX serverprocess as
compared to multiple server processes in Chorus, it is easier to manage the system state
in Mach. This is because in Chorus the system state relevant to a single emulated UNIX
process is distributed across several server processes that may even be on different
machines. If this state is replicated for performance, a mechanism and extra
communication overhead will be needed to keep this state consistent. On the other hand,
if the state is distributed but not replicated, functionality can be affected because different
servers may fail independently of each other. These problems are not associated with
Mach'sapproach because a process's state is confined only to the emulation library'sdata
and the single UNIX server process.
3.Protection. In Mach, when a process executes a UNIX system call and traps tothe
kernel, control ispassed backtotheemulation librarythatresides intheaddress spaceofthe
process. Therefore, if the process has buggy code that interferes with the data in the
emulation library,thismaygiverise tononstandard failuremodescausing trouble. Sincethe
approach used inChorus completely isolates system data structures from user processes, it
avoids such problems and provides better protection tothe system than Mach'sapproach.
Further details of the differences between the approaches taken by Mach and Chorus
for UNIX emulation can be found in [Dean and Armand 1992].
Extensions to UNIX
In addition to UNIX emulation, Chorus also provides many extensions to UNIX to allow
UNIX processes to use standard Chorus properties that are not available in UNIX. Some
of the most important ones are as follows:
1.Threads. This extension allows UNIX processes to create and destroy new threads
using the Chorus threads package.
2.Remote process creation. This extension allows a UNIX process to create a new
process on a remote node. In the system call for process creation, it can be specified that
the new process is to be created, not on the local node, but on the specified remote node.
The new process starts on the local node when forked off, but when it does an execsystem
call, it is started on the specified remote node.
3. Group communication. The same group communication facility as that of Chorus
can also be enjoyed by UNIX processes. This is because user processes using the UNIX
subsystem can create ports and port groups and send and receive messages in the same
manner as Chorus processes.Sec.12.5•Chorus 713
4.Memory model.UNIX processes can also enjoy the flexibility of the memory
model supported in Chorus. That is, user processes using the UNIX subsystem can create
regions and map segments on to them in the same manner as Chorus processes.
12.5.8Th.COOLSubsyst.m
In addition to the ChoruslMiX subsystem, another subsystem developed for Chorus is
ChorusObject-Oriented Layer(COOL). Its main goal is to provide system-level support
for fine-grained object-oriented languages and applications inChorus. The basic approach
used for designing this subsystem is briefly described below. Its further details can be
found in [Lea et al. 1991, 1993].
The COOL (COOL-2, the second version) subsystem that sits on top of the Chorus
microkernel is structured into the following layers (see Fig. 12.16):
T
COOLSUbSYICOOLuserprograms
Language runtimelayer
,.......... ~......................................................................................
Genericruntimelayer(objects)
............................................................
COOL-baselayer (cluster)
MicrokernelUserprogram
Language
runtimesystem
Generic
..................... runtimesystem
Fig. 12.16 The implementation structure and layers of COOL subsystem of Chorus.
1.COOL-base layer.This layer provides a system can interface that presents the
illusion of a new object-oriented microkernel to user applications. It deals with
abstractions called clusters, which are places where objects exist. A cluster holds a
group of related objects, such as objects belonging to the same class. The decision
regarding which objects belong to which cluster is made by the upper layers of
software.
From the memory model viewpoint, clusters are collections of Chorus regions
backed by segments. Therefore, a cluster can be simultaneously mapped into the address
spaces of multiple processes, possibly on different machines. However, clusters are not
replicated and there is only one physical copy of each cluster at anytime. Requests
corresponding to remote clusters are serviced either byforwarding the request to the
machine that currently holds thecluster for remote invocation or by migrating the cluster
to the requesting machine for local invocation. In this manner, the COOL base layer
manages clusters, mapping them into multiple address spaces to produce distributed714 Chap. 12 • Case Studies
clusterspaces that are visible to all COOL processes without regard to where they are
running.
2. Generic runtime (GRDlayer.This layer provides support forfiner grained objects
within clusters. In particular, it provides necessary operations for creating and deleting
objects, for mapping them into and out of address spaces, and for invoking their methods.
It also provides support for a single-level persistent object store, interobject communica­
tions based on Chorus RPC, and protection of objects during application execution.
3. Language runtimelayer. Programmers mayusedifferent object-oriented program­
ming languages, suchas C++,Smalltalk, and Eiffel, to define their objects. The language­
specific runtimelayermapstheobject modelsofseveralsuch programming languages onto
the GRT's abstractions. It uses preprocessors to generate an up-call table for every type of
object created at the GRT level. This mechanism isused to build a standard interface
between the generic runtime layer and the language-dependent runtime layer.The generic
runtime layer uses this interface to make calls to the language runtime system to obtain
language-specific,information about the semantics of certain operations. For example. it
couldfindouthowtoconvert in-memory objectpointers topersistent pointers forstorageor
how to handle methoddispatch. This mechanism enables COOL tosupport many different
object-oriented programming languages withreasonable efficiency.
Ofthe three layers, the COOL-base layer is implemented as a Chorus process that
runs in the subsystems layer of Chorus. On the other hand, the software in the generic
runtime layer is linked with every COOL program, and the appropriate software of the
language-specific runtime layer (depending on the language in which aCOOL program is
written) is linked with the COOL program. Therefore, the language runtime and the
generic runtime systems reside in the user program's address space.
11.6 ACOMPARISON OFAMOESA, V-SYSTEM, MACH,
ANDCHORUS
Each of the four distributed operating systems (Amoeba, V-System, Mach, and Chorus)
described above have their own strengths and weaknesses that is mainly due to the goals
setbytheir designers and their evolution histories. Amoeba and V-System were designed
from scratch as distributed operating systems for loosely coupled distributed memory
multiprocessors. From the beginning till now, they have remained university research
projects. On the other hand, Mach started as a university research project to build an
operating system for tightly coupled shared-memory multiprocessors and was later
extended for loosely coupled distributed-memory multiprocessors. It was later selected for
commercialization. Finally,Chorus also started as a research project to build a distributed
operating system for loosely coupled distributed-memory systems, but its design goals
were changed as it evolved from a research project to a commercial system. The
consequences of the design goals and evolution histories of these systems are visible in
their strengths and weaknesses. To make these differences clearer, let us look at the
important aspects of all these four systems together.Sec.12.6• AComparison ofAmoeba,V-System, Mach,andChorus
11.6.1SystemModel715
Amoeba is based on the processor-pool model whereas V-System, Mach, and Chorus are
based on the workstation-server model. Therefore in Amoeba, a user does not log on to a
specific machine but to the system as a whole and the selection of CPU (or CPUs) for
running a user'sjobis done automatically by the operating system. In general, a user is
not aware of on which CPU his or her job is being processed.
On the other hand, in V-System, Mach, and Chorus, a user logs on to a specific
machine (called his or her home machine) on which most of his or her jobs are run by
default. Users can request for remote execution oftheir jobs in these systems. Moreover,
V-System also provides automatic load-balancing facility due to which a user'sjobs may
get processed remotely without his or her knowledge. But in any case, all three systems
have the concept of local and remote processing of jobs. This concept does not exist in
Amoeba.
12.6.2Kernel
All four systems are based on the microkernel model, in which the kernel is minimal and
other functionality and features are supported by user-level servers. However, the
complexity of the microkernel and the kernel interface of the four systems differ based on
the flexibility offered bythem.The microkernels ofAmoeba and V-Systemare simple and
have very few system calls. Mach's microkernel is very complex with too many system
calls. This is mainly because it attempts to provide greater flexibility in the sense that the
same thing can be done in two or three different ways, and the users have the option to
select the most convenient or efficient way for a particular circumstance. Chorus's
microkernel has fewer system calls than Mach'sbut more than Amoeba's or V-System's.
Therefore, itscomplexity ismoderate.
12.6.3ProcessManagement
Abstractions corresponding to a process in Amoeba, V-System, Mach, and Chorus are
process, team, task, and actor, respectively. All four systems support multithreaded
processes and in all four threads are managed and scheduled by the kernel.
Mach and Chorus have the flexibility to run the threads of the same process in
parallel on different CPUs. This flexibility is not available in Amoeba and V-System.
Hence, in these systems, a CPU is time shared by the threads ofa process and run in
pseudo-parallel.
Amoeba does not provide any type of user control over thread scheduling.
V-System and Chorus allow processes to set priorities of their threads. Mach provides
maximum flexibility in this case because, in addition to allowing threads priorities to
bedynamically changed, it also provides the facility of handoffscheduling. This facility
may be used bya thread to hand off the CPU to another thread of its choice when it
has finished using the CPU.
Amoeba and V-System support automatic load-balancing facility to spread the
workload uniformly over all the machines in the system. Mach and Chorus do not have716 Chap.12 • Case Studies
this facility and by default a user'sjobs are executed on his or her home machine. Only
on explicit request can a user'sjobberun remotely.
V-System also has process migration facility. The other three systems do not have
this facility.
11.6.4Int.rproc.ss Communication
Amoeba, V-System, Mach, and Chorus all provide RPC facility for interprocess
communication. Mach and Chorus also provide the facility to send messages asynch­
ronously. Mach packages all forms of message passing in a single system call, whereas
Chorus provides alternative calls. The attempt of Mach to package all forms of message
passing in a single system call makes its communication interface very complex because
of the large number of parameters and options used in the system call to handle all
possible different cases.
Chorus makes use of lightweight RPC facility for efficient communication between
local kernel processes. The other three systems do not use lightweight RPC.
In Amoeba and V-System, messages consist of a fixed-size header and an optional
out-of-line block of data of variable size. In Chorus, messages consist of a fixed-size
header, an optional fixed-size in-line data of 64 bytes, and an optional variable-size in-line
data of a maximum 64 kilobytes. Mach provides maximum flexibility in this case by
allowing multiple variable-size out-of-line blocks of data in a single message.
Mach'smessages can be either simple or complex. The contents of simple messages
arecontiguous sequenceofbytes, whereascomplex messagescontain typeddata. Complex
messages maybeusedtotransmit capabilities. Onthe other hand,Amoeba, V-System,and
Chorus usesimple untypedmessages thatcontain acontiguous sequence of bytes.
Messages are addressed to ports in Mach and Chorus, to processes in Amoeba, and
to manager IDs inV-System.A manager ID in V-Systemmay either be a process or a port
identifier. All four systems use the mechanism of hint cache plus broadcasting to locate
ports or processes.
In local IPC, Mach and Chorus use the copy-on-write mechanism to pass out-of-line
data. Amoeba and V-Systemdo not use this mechanism. Therefore, local IPC is faster in
Mach and Chorus than in Amoeba or V-System.
Amoeba, V-System, and Chorus support group communication, but Mach does not.
The group communication facility of Amoeba provides reliable, ordered broadcast
facility; that of Chorus provides unreliable, unordered broadcast facility; and that of
V...System provides unordered broadcast facility with the flexibility given to the users to
choose the degree of reliability.
In Amoeba and V-System, networkwide IPC is handled by the kernel. On the other
hand, in Mach and Chorus, user-level network servers are used for networkwide fPC.
Therefore, internode IPC is faster in Amoeba and V-System than in Mach or Chorus.
On the network, all four systems provide support for conventional TCPII~In
addition, Amoeba supports FLIP, and V-System supports VMTP. These protocols,
although not standard and widely used, have been specifically designed for the needs of
distributed operating systems and are faster than conventional network protocols for
typical RPC usage.Sec.12.6• AComparison ofAmoeba,V-System, Mach,andChorus 717
Amoeba has a very simple memory management scheme without support for the virtual­
memory (demand paging) mechanism.Therefore, when anAmoeba process runs, itsentire
address space is present in memory. This scheme is simple to implement and has the
advantage of high performance. However, it requires that the machines have extremely
large memories. A process whose address space is larger than the memory of the machine
having the largest memory size among all machines in the system cannot be run on that
system. In contrast, V-System, Mach, and Chorus provide support for a paged virtual­memory mechanism. Therefore, any process can be run on these systems no matter how
large its address space is.
The virtual-memory management schemes of Mach and Chorus are very powerful
and flexible because they allow pages to
beshared between multiple processes in various
ways. For example, the copy-on-write sharing mechanism allows efficient sharing of
pages among multiple processes of a single node, and the external pager mechanism
allows virtual memory to be shared even among processes that run on different
machines.
Amoeba, V-System, Mach, and Chorus all provide support for distributed
shared memory. Amoeba supports an object-based distributed shared memory in
which variable-size objects are shared by replicating them on all machines using
them. Read operations on an object are performed locally, while write operations on
it are performed using the reliable broadcast protocol of Amoeba. On the other
hand, V-System, Mach, and Chorus support page-based distributed shared memory.
Like Amoeba, V-System allows both read-only and writable pages to be replicated.
However, V-System uses problem-oriented approach for solving the memory coher­
ence problem. On the other hand, to solve the memory coherence problem, Mach
and Chorus allow only read-only pages to be replicated and there is only one copy
of writable pages in the entire system. Due to replication of writable objects and
the use of write-all protocol for memory coherence, updates in Amoeba's scheme
are more expensive than in V-System's, Mach's, or Chorus's schemes. However,
unlikeAmoeba's scheme, Mach's and Chorus's schemes suffer from thrashing
problem. Thrashing can occur if a writable page is heavily accessed from two
machines.
Amoeba's file management scheme is very different from those of V-System,Mach, and
Chorus. Amoeba uses the immutable file model, whereas V-System, Mach, and Chorus
use the mutable file model.Therefore, afilecannot beoverwritten inAmoeba andupdates
are performed by creating new file versions. In V-System, Mach, and Chorus, a file is
modified by overwriting the same file.
InAmoeba, an entire file isalways stored contiguously both in memory and on disk.
This provides efficient accesses to files but leads to the external fragmentation problem.
In V-System, Mach, and Chorus, a file need not be stored contiguously. Storage space is
allocated in units of fixed-size blocks or variable-size segments.718 Chap. 12 • Case Studies
All four systemsusethe data-caching model for remote file accessing. However,in
Amoebathe unitofcaching isafile,whereasintheotherthreesystemstheunitofcaching
isablock.
Since Amoeba uses the immutable file model, it supports immutable shared file
semantics. On the otherhand, the file-sharingsemanticsof V-System, Mach, and Chorus
depend on the semanticssupported by the user-levelfile server being used.
Amoeba also supportsautomaticreplicationof files.The other three systems do not
have this facility.
11.6.7SfaCurity
InAmoebaandChorus,resourcesare namedandprotectedbycapabilities.Therefore, the
capability-based accesscontrol mechanismis usedtocontrolaccess to resources in these
two systems. In Mach, the access control mechanism is based on port rights (port
capabilities).That is,Machserversgenerallymanagemanyports,one for every resource,
andonlyprocessesthatownappropriateportrightsforaportcanaccessthecorresponding
resource. Finally,in V-System, the accesscontrol mechanismis basedonACLs managed
by resource managers.
Capabilities inAmoebaand Chorus are managedin user space, but port capabilities
in Mach are managedby the kernel.Amoebacapabilitiesare protected by usingone-way
encryptionfunctions.Chorusalsoprovidesprotectionidentifiersthatmaybeusedtoknow
the actual sender of a message.
Chorus and V-System provide support for real-time applications.Amoeba and Mach do
not provide any special facility for real-time applications.
All four systems provide support for UNIX emulation. However, while V-System,
Mach, and Chorus support binary compatibility, Amoeba supports source code
compatibility with UNIX.
Chorusalsoprovidessystem-levelsupportfor fine-grainedobject-orientedlanguages
and applications.The other three systems do not currently provide this facility.
Figure 12.17presents a summary of the comparison of the four systems presented
above.
11.7SUMMARY
Thischapterhaspresentedadescriptionof fourdistributedoperatingsystemstorelatethe
various concepts describedin the precedingchapters of this book to real systems.These
systems are Amoeba, V-System, Mach, and Chorus. The design goals, system
architectures, and the most important and noteworthy aspects of these systems were
covered in sufficient detail to consolidate the reader's understanding of the design
principles of distributed operating systems. A comparison of the four systems was also
presented.~
~.
~
N;...
'-I
>o
03
""0
~::l.
CI')
0:=
0...,
>38
$"
~c.n-e
CI')
0
~
~
~?"
~:=c..
Q
02:n
Q
:=g.
c
~0.
0:=
:=
('P
~
't'
~n
....,J'-'
....
\CFeature Amoeba V-Svstem Mach Chorus
System model Processorpool Workstation-server Workstation-server Workstation-server
Kernel model Microkernel Microkernel Microkemel Microkernel
Kernelcomplexity interms of Simple (few system Simple (few system Very complex (too Fairly complex
system call interface calls) calls) many system calls) (many system calls)
Processabstraction Process Team Task Actor
Supports multiplethreads in aYes Yes Yes Yessingle process?
Canthreadsof a process run on No No Yes YesdifferentCPUs?
Threadsare managed and Kernel Kernel Kernel Kernelscheduled by
Supports user control overNoYes (priority assign- Yes (priority asslqn- Yes (priority assign-
threadsscheduling ment) ment and handoff ment)
schedufna)
Automatic load balancing facility? Yes Yes No No
Processmigration facility? No Yes No No
Basic IPC mechanisms RPC RPe RPC and asynchro- RPeand asynchro-
nous send nous send
Useslightweight APC? No No NoYes, forcommunica-
tion between local
kemel processes
Message body Singlevariable-size Singlevariable-size MUltiplevariable-size An optional fixed·
out-of-line block of out-of-line block of out..ot-line blocks ot size in-line data and
data data data an optional variable-
size in-line data of
maximum 64K bytes....a
~
~"...
~.........
>
(')e.g
§.
tf)
8
~
J
~en<een
<Dp
:c
~F
~
Q..
~2
~
Q
::IC.i
e::I
~
"0
~
(JQ
~Feature Amoeba V-System Mach Chorus
Typed/untyped messages? Untyped Untyped Maybetyped/untyped Untyped
Messages addressed to ProcessesManager-IDs (maybeaPorts Portsprocessor a port 10)
Mechanism used forlocating HintC8che and broad- Hintcacheand broad- Hintcacheand broad- Hint cacheand broad-
portsorprocesses casting casting casting casting
Usescopy-on-write mechanism No No Yes Yes
forlocalIPC?
Groupcommunication facility Reliable,ordered Unordered broadcast None Unreliable, unordered
broadcast facility facilitywithflexibility broadcast facility
tochoosethe degree of
reliability
Network-wide fPCsupported by Kemel Kernel User-level network User-level network
servers servers
Supported networkprotocols TCPIIPand FLIP TCPIIPand VMTP TCPIIP TCP/IP
Supports virtualmemoryNo Yes Yes Yesmechanism?
Supports copy-on-write sharingforNo No Yes Yes
objectssharedbyprocesses onthe
samenode?
Usesexternalpagermechanism? No No Yes Yes
Provides supportfordistributed Yes(object-based) Yes(page-based) Yes(page-based) Yes(page-based)
sharedmemory?
Coherence protocolused for Write-all Problem-specific Read-only replication Read-only replication
distributed sharedmemory updates
Filemodel Immutable files Mutablefiles Mutable files Mutablefiles
Anentirefile has to bestored Yes No No No
contiguously?....;a
N
~~
ciQ-
..­
N;..
......
>-
("Jo3"0
~:1-
~:;
e-.
>­3
~0"
~
~en-e
tnS-
F
3:
~o?"
~::s
0..
o::ro2:nFeature Amoeba V-Svstem Mach Chorus
Remotefile-accessing model Data-caching model Data-caching model Data-caching model Data-caching model
Unit of data transfer File Block Block Btock
File-sharing semantics Immutable shared-files Depends on the user- Depends on the user- Depends on the user-
semantics levelfile server levelfile server level file server
Automatic file replication? Yes No No No
Accesscontrol mechanismResources capabilities ACLs managed by Port rights (portResource capabilities
that areencrypted usingresource managers capabifities) andprotection iden-
one-way functions tifiers
Supportfor real-time applicationS? No Yes No Yes
UNIX emulation Source code compa- Binarycompatibility Binarycompatibility Binarycompatibility
tibilitv
Supportforobject-orientedNo No No Yes
languages and applicationS?722 Chap. 12 • Case Studies
From the description of these systems, it can be concluded that microkemel-based
distributed operating systems with open-system architecture are going to dominate in
future. For commercial success, it is important for any newly developed distributed
operating system to provide binary compatibility with UNIX. Features such as process
migration and load balancing are still restricted to research projects. This is mainly
because, with the current state of the art,these features are expensive to implement and
use and have not yet proved to give promising results. Therefore, more research work
needs to be carried out in these areas.
EXERCISES
12.1.What is an "open distributed system"? What is the most important factor in the design of a
distributed operating system that influences this characteristic of the system?
12.2.Based on the description of Amoeba, V-System, Mach, and Chorus, what trend are modern
distributed operating systems following for kernel design? What are the main reasons for
using this approach? Are there any disadvantages in using this approach?
12.3.Name the main hardware and software components of Amoeba and describe their
functions.
12.4.Answer the following questions for the capability-based object-naming mechanism of
Amoeba:
(a) How does a subject get a capability for an object? Consider both the case in which the
subject is the owner of the object and the case in which the subject is not the owner of
the object.
(b) How are capabilities protected against unauthorized access?
(c) How are capabilities made difficult to forge?
(d) When a subject accesses an object, how is the validation check made if the subject is
allowed to access the object in the requested mode?
(e) Howcan theownerofanobject who wants toshare theobject withanother subject allow
restricted access rights to the subject for its object?
12.5.In acapability-based system, an object whose capability is lost can never beaccessed but
will remain forever in the system. How is this situation prevented in Amoeba?
12.6.Describe the process model of Amoeba.
12.7.What is a glocal variable in Amoeba? Why is it used?
12.8.In the processor-pool model of Amoeba, explain how a processor is selected from the pool
for executing a new process.
12.9.Describe the policy used in Amoeba for object replication.
12.10.Amoeba uses the immutable file model. However, in a file system that uses the immutable
file model, every time a file is modified, a new version of the file is created and the old
version is deleted. This makes file modifications slow and complicated, especially for a file
that is frequently modified. Explain how Amoeba solves this problem.
12.11.Describe the group communication facility of Amoeba.
12.12.Explain how the following are ensured in Amoeba:
(a) Only genuine clients can request services from a server.
(b) Only genuine servers can receive client requests.Chap. 12 • Exercises 723
12.13. Name the main hardware and software components of V-System and describe their
functions.
12.14.V-Systemintegrates object-naming and object management mechanisms. What advantages
does this approach have in the design of a distributed operating system?
12.15. Describe the mechanisms used in V-System to minimize the kernel's job in process
management activities.
12.16.Describe the UIO interface of V-System. Explain how this facility simplifies device
management activities.
12.17. Describe the multicast communication facilityof V-System. Mentionsome of the practical
applications of this facility in the design of V-System.
12.18. In V-System,the sender actionsof sendinga requestand receiving aresponsearecombined
intoa single Sendprimitive.Whatadvaritagesdoesthisapproachprovide?Woulditnothave
been better and simpler to have two calls, Send request andGet_reply, one for sending a
request and one for receiving aresponse?
12.19.Explainhowthecopy-on-writemechanismofMachprovidesthepotentialtoeliminatemuch
data movement inthe system.
12.20. InMach, manykernelactivitiesare movedoutofthekerneldirectly into theclient's address
space by being placed in a transparent shared library. What advantages does this design
provides?
12.21.To keep track of the state (suspended/running) of a thread (or process), Mach uses a
"suspended" counter that is associated with each thread (or process). Since there are only
two possible states (suspendedand running), asinglebit wouldhave beensufficientfor this
purpose. Explain the reason for the use of a counter instead of a bit for this purpose.
12.22. Describe how threads of a process are synchronized in Mach.
12.23.Answer the following questions for the threads-schedulingscheme of Mach:
(a) What is theuse ofa"hint" variable?
(b)What is the use ofa "count" variable?
(c)What is the need to have two run queuesinstead of a single run queue for each
CPU?
(d) What happens if there are no threads waiting to be executed on either of the two
queues?
(c)Howisitensuredthatthesystemwillprovidehighefficiencywhenlightlyloaded,while
providing good response to short requests even when heavily.loaded?
(f)How is the monopolization ofa CPU by a high-prioritythread prevented?
(g) How is fair CPt]utilization ensured in a situation in which the system load suddenly
increases?
(h) Why is a global runqueue locked before beingsearched for a ready-to-runthread but a
local run queue is not locked before being searched?
12.24. A commonly used approach to maintainthe virtualaddressspace of each processis to keep
a linear page table from zero to the highest used page in the kernel. Explain why this
approach is not used.in Mach. Describe the approach used in Mach for maintaining the
virtual address space of each process.
12.25.Whatisanexternal memorymanagerinMach?flow is itrealized?Describehowanexternal
memory managerand the kernel interactwitheachother to managea memoryobjectand to
satisfy user access requests for data in the memoryobject.724 Chap. 12 • Case Studies
12.26.Describe how theexternalmemory manager conceptof Mach can be used to implement the
distributed shared memory facility.
12.27.Describe thecopy-on-write andcontrolled inheritance mechanisms used in Mach for
memory sharing. Give an example toillustrate the practical use of each ofthese
mechanisms.
12.28.Answerthefollowing questions for theport-based IPCmechanism of Mach:
(a) Why are ports kept track of on a per-process basis rather than on a per-thread basis?
(b) Anapplication requiresthat asenderbeallowedto send messages to aport only ntimes.
How can this be realized?
(c)Whathappens when a process having a port capability withreceiveright sends that
capability in amessage toanotherprocess?
(d) How are ports protected?
(e) What happens when a process holdinga portcapability withreceiveright exits or is
killed?
(f)Whathappens if a sender sends a message to a port whose receiverprocesshas been
killed?
(g) What happens if a message arrives at a port whose queue is full?
(h) What is a port-set? Give apractical use of this facility.
(i) Why is message sendingto aport-setnotallowed?
(j)Why can a port that belongs to a port-setnot be used directly to receive messages?
12.29.Differentiate between in-line data and out-of-line data in the message-passing mechanism of
Mach.Describe howout-of-line data aretransferred from a sender to a receiver.
12.30.In Mach, explainhowmessages areexchanged transparently between two processes that are
locatedondifferent nodes.
12.31.Whatis the role of MIG in Mach?Explain how it simplifies the job of application
programmers.
12.32.InMach'sUNIXemulation, system calls related to file VOhave been implemented
differently than the basic approach described in this chapter. Find out how file 110system
calls are implemented and the reason for using a different approach forimplementing
them.
12.33.Describe howChorusprovides supportforreal-time applications.
12.34.Chorusallowsservers(subsystem processes) to reside eitherina shared kernel addressspace
or inprivateuseraddressspaces.Discusstherelativeadvantages anddisadvantages of this
featureofChorus.
12.35.ExplainhowChorusprovides theflexibility todynamically configure the system software to
match the hardware components of aparticular node of the system.
12.36.Whatare thevarioussecuritymechanisms provided inChorus? What type of securitydoes
eachofthesemechanisms provide?
12.37.Explainwhythreetypes of processes are used in Chorus.
12.38.Describe thethreads-scheduling scheme of Chorus. What are its advantages and
disadvantages?
12.39.Differentiate between broadcast, functional, andselective functional modes of communica-
tion inChorus.Give a practical use of each of these modes of communication.
12.40.Explainthe portmigration facility of Chorus.How does it help?
12.41.What is a port groupinChorus? Give two practical uses of this facility.
12.42.Explainhow UNIX processes can becreatedon aremotenode in Chorus.Chap.12 •Bibliography 725
12.43.Discusstherelativeadvantages anddisadvantages of theapproaches takenby Machand
ChorusforUNIXemulation.
12.44.Explainhowobject-oriented facilityissupported inChorus.Can thisfacilitybeprovided
along with UNIX emulation facility on the same machine?Give reasons for your answer.
818llOGRAPHY
[Abrossimov et al, 1992] Abrossimov,A.,Armand,F.,andOrtega,M.,"A DistributedConsistency
Server for the CHORUS System," In: Proceedings ofthe USENIX SEDMS III Symposium on
Experience with Distributed and Multiprocessor Systems, USENIXAssociation,Berkeley,CA,
pp. 129-148 (1992).
[Accetta et al,1986]Accetta, M., Baron,R., Golub, {J.,Rashid,R.,Tevanian,A., and Young,M.,
"Mach:ANewKernelFoundationfor UNIXDevelopment,"In: Proceedings oftheSummer1986
USENIX Technical Conference, USENIXAssociation,Berkeley,CA, pp. 93-112 (July 1986).
[Almes et al, 1985] Almes,G.T.,Black,A. ~,Lazowska, E.D.,andNoe, 1.D.,uTheEdenSystem:
ATechnical Review," IEEETransactions on Software Engineering, Vol.SE-ll,No.1,pp.43-59
(January 1985).
[Andrews et al, 1987] Andrews, G. R.,Schlichting,R. D., Hayes, R.,and Purdin,T. D. M.,"The
Design of the Saguaro Distributed Operating System," IEEE Transactions on Software
Engineering, Vol.SE-I3, No. I, pp. 104-118 (1987).
[Armand etal,1986]Armand, F., Gien, M., GuilJemont, M., and Leonard, P., "Towards a
Distributed UNIX System-The CHORUS Approach," In: Proceedings oftheAutumn1986
EUUG Conference, USENIXAssociation, Berkeley, CA, pp.4]3-431 (September 1986).
[Armand etal,1989]Armand,F.,Gien,M.,Herrman, E,and Rozier, M.,"Distributing UNIX
BringsItBack to Its Original Virtues," In: Proceedings ofthe Workshop on Experiences with
Building Distributed and Multiprocessor Systems,pp. 153-174 (October 1989).
[Babaoglu 1990] Babaoglu, 0.,"Fault-TolerantComputing Basedon Mach," Operating Systems
Review,Vol.24,No.1,pp.27-39(1990).
[Bal et al, 1992] Bal,H.E.,Kaashoek, F.,andTanenbaum, A.S., "Orca: ALanguagefor Parallel
ProgrammingofDistributedSystems," IEE'ETransactionson Software Engineering, Vol.SE-18,
No.3,pp.190-205 (1992).
[BaninoandFabre1982]Banino,1.S.,andFabre, 1.C.,"DistributedCoupledActors:ACHORUS
Proposal for Reliability," In: Proceedings ofthe 3rd International Conference on Distributed
Computing Systems, IEEE Press, New York,NY,p. 7 (October 1982).
[Baninoet al, 1985J Banino,1.S.,Fabre,1.C.,Guillemont,M.,Morisset,G.,andZimmermann,H.,
"Some Fault TolerantAspects ofthe CHORUS DistributeSystem," In: Proceedings ofthe 5th
International Conference on Distributed Computing Systems, IEEE Press,NewYork,NY (May
1985).
[Baronet al, 1985] Baron,R.,Rashid,R.,Siegel,E.,Tevanian,A.)and Young,M.,"Mach-I: An
OperatingEnvironmentforLarge-ScaleMultiprocessorApplications," IEEE Software, Vol.2,pp.
65-67(1985).
[Batlivala et al,1992]Batlivala,N.,Gleeson,B.,Hamrick,1.,Lumdal,S.,Price, D.,Soddy,1.,and
Abrossimov, V.,"Experience with SVR4 over CHORUS," In:Proceedings ofthe USENIX
Workshopon Microkernels and Other KernelArchitectures, USENIXAssociation,Berkeley,CA,
pp. 223-241 (1992).726 Chap.12 • CaseStudies
[Berglund 1986] Berglund,E. J.,"AnIntroduction to theV-System," IEEE MICRO, pp.35-52
(August ]986).
[Beveret ale 1993] Bever,M., Geihs, K.,Heuser,L., Muhlhauser,M., andSchill,A.,"Distributed
Systems,OSF DCE, and Beyond," In:A. Schill(Ed.), oce-ts« OSF Distributed Computing
Environment, Springer-Verlag, Berlin,pp. 1-20 (1993).
[Black 1990] Black, D. L., "Scheduling Support for Concurrency and Parallelism in the Mach
Operating System," IEEE Computer, Vol.23,No.5,pp.35-43(1990).
[Blacketal, 1992]Black,D. L., Golub,D. B.,Julin, D. P.,Rashid,R. F.,Draves,R. P.,Dean,R.
W.,Forin,A"Barrera, J., Tokuda, H.,Malan, G., and Bohman, D.,"Microkernel Operating
SystemArchitectureandMach," I~:Proceedings ofthe USENIX WorkshoponMicrokernels and
Other Kernel Architectures, VSENIXAssociation,Berkeley,CA, pp. 11-30 (1992).
[Boykinet al.1993] Boykin,J.,Kirschen,D.,Langerman,A.,and LoVerso,S.,Programming under
Mach,Addison-Wesley, Reading,MA (1993).
[Boykinand Langerman 1990)Boykin,J.,and Langerman,A., "Mach/4.3BSD: A Conservative
Approachto Parallelization," Computing Systems Journal, Vol.3, pp. 69-99 (1990).
[Champine et al. 1990]Champine,G. A.,Geer,Jr., D. E.~andRuh,W.N., "ProjectAthenaas a
DistributedComputerSystem," IEEE Computer, pp.40-50(September ]990).
-[Cheriton 1984]Cheriton,D. R.,"The Vkernel:A SoftwareBasefor Distributed Systems," IEEE
Software, Vol.1,No.2,pp.19-42(April 1984).
[Cheriton 1987]Cheriton,D. R., "UIO:A UniformI/O Interfacefor Distributed Systems," ACM
Transactions on Computer Systems, Vol.5,No.I,pp.12-46(1987).
[Cheriton 1988]Cheriton,D. R., "The V DistributedSystem," Communications ofthe ACM, Vol.
31,No.3,pp.314-333 (1988).©ACM,Inc., 1988.
[Cheriton and Mann 1989]Cheriton, D. R., and Mann,T. P., "Decentralizing a GlobalNaming
Service for Improved Performance and Fault Tolerance," ACMTransactions on Computer
Systems, Vol.7,No.2,pp. 147-183 (1989).
[Cheriton et al. 1979]Cheriton, D.R., Malcolm, M.A., Melen,L. S., and Sager,G. R.,"Thoth, a
Portable Real-Time Operating System," Communications ofthe ACM, Vol.22,No.2,pp.
105-115 (February 1979).
[Cheriton et al. 1990]Cheriton,D., Whitehead, G.,and Sznyter, E.,"BinaryEmulationof UNIX
UsingtheVKernel,"In: Proceedings ofthe Summer USENIX Conference, USENIXAssociation,
Berkeley,CA, pp. 73-85(1990).
[Coulouris et al. 1994] Coulouris, G. F.,Dollimore, J., and Kindberg, T.,Distributed Systems
Concepts and Design, 2nd ed.,Addison-Wesley, Reading,MA (1994).
[Dasgupta et al, 1991] Dasgupta, P,LeBlanc, R. J., Ahamad, M.,andRamachandran, V.,"The
Clouds DistributedOperating System," IEEE Computer, Vol.24, No. 11, pp.34-44(1991).
[DeanandArmand1992)Dean,R.,andArmand, F.,"DataMovementinKemelizedSystems,"In:
Proceedings ofthe USENIX Workshop on Microkemels, USENIX Association, Berkeley, CA
(1992).
(Dougliset al,1991]Douglis,F.,Ousterhout,J. K., Kaashoek, M. F.,andTanenbaum, A. S., "A
ComparisonofTwoDistributedSystems:AmoebaandSprite," Computing Systems Journal, Vol.
4,pp.353-384 (1991).
[Draves1990] Draves, R. P.,"A Revised fPC Interface," In: Proceedings ofthe USENIX Mach
Workshop, VSENIXAssociation, Berkeley, CA, pp. 101-121 (October 1990).
[Dravesetat. 1989]Draves,R.P.,Jones,M.B.,andThompson,M.R., HMIG-TheMachInterface
Generator," Technical Report, Departmentof Computer Science, CarnegieMellon University
(1989).Chap.12 •Bibliography 727
[DutY1990]Duff,T.,"Rc-AShellforPlan 9andUNIXSystems," In:Proceedings oftheSummer
1990UKUUGConference, USENIXAssociation, Berkeley, CA, pp.21-33(July1990).
[Finkelet al. 1989] Finkel,R.,Scott,M.L.,Kalsow, W.K.,Artsy, Y.,andChang,H. Y.,"Experience
withCharlotte:Simplicityand Function in aDistributedOperatingSystem," IEEETransactions
onSoftwareEngineering, Vol.SE-15,No.6,pp.676-685 (1989).
[Fitzgerald and Rashid 1986]Fitzgerald, R.,and Rashid, R. F.,"The Integration of Virtual
Memory Management and Interprocess Communication in Accent," ACMTransactions on
Computer Systems, Vol.4,No.2,pp.]47-177 (1986).
[Gien and Grob 1992]Gien, M., and Grob, L., "MicrokernelBasedOperating Systems:Moving
UNIX on to Modern System Architectures," In: Proceedings oftheUniForum'92 Conference,
USENIXAssociation,Berkeley,CA, pp. 43-55(1992).
[Golub et al, 1990] Golub, D., Dean, R., Forin, A., and Rashid, R., "UNIX as an Application
Program," In: Proceedings ofthe Summer 1990 USENIXConference, USENIX Association,
Berkeley,CA, pp. 87-95(June1990).
[Guillemont 1982]Guillemont, M., "The CHORUS DistributedComputing System: Design and
Implementation,"In: Proceedings oftheInternational Symposium onLocalComputer Networks,
pp. 207-223 (April 1982).
[JonesandRashid1986]Jones, M. B., and Rashid, R. F, "Mach and Matchmaker: Kernel and
LanguageSupport for Object-Oriented Distributed Systems," In: Proceedings ofOOPSLA'86,
Associationfor Computing Machinery,New York, NY,pp.67-77(September 1986).
[Kaashoek andTanenbaum 1991]Kaashoek,M. F.,andTanenbaum, A.S.,"GroupCommunica­
tion in the Amoeba Distributed Operating System," In: Proceedings ofthe 11thInternational
Conference on Distributed Computing Systems,IEEE Press,New York,NY,pp.222-230 (May
1991).
[Keefeeet al.1985]Keefee,D.,Tomlinson, G. M.,Wand,I.C., andWeilings, A.1.,PULSE:An
Ada-Based Distributed Operating System,Academic Press, San Diego, CA (1985).
[Leaet al, 1991] Lea.R.,Amara),P., andJacquemot, C.,"COOL-2:An Object-OrientedSupport
PlatformBuiltAbovetheChorusMicrokernel,"In: Proceedings oftheInternational Workshop on
Object-Oriented Systems,pp.51-55(1991).
[Lea et ale1993]Lea, R., Jacquemot, C., and Pillevesse, E.,"COOL: System Support for
DistributedProgramming," Communications oftheACM, Vol. 36,No.9,pp.37-46(September
1993).
[Levine1987]Levine,P.H.,"The DOMAIN System," In: Proceedings of the 2ndACM SIGOPS
Workshop onMakingDistributedSystems Work,Operating SystemsReview,Vol.21,No.1,pp.
49-84(1987).
[Milleretal. 1987J Miller,B.P.,Presotto, D. L., and Powell, M. L.,"DEMOSIMP: The
Developmentof a DistributedOperatingSystem," Software-i-Practice andExperience, Vol.17,
No.4,pp.277-290 (1987).
[Milojcic 1994]Milojcic, D. S.,LoadDistribution, Implementation for the Mach Microkernel,
VerlagVieweg,Wiesbaden(1994).
[Morriset al, 1986] Morris,J.H.,Satyanarayanan, M.,Conner,M.H.,Howard,J. H.,Rosenthal,
D. S. H., and Smith, F. D., "Andrew: A Distributed Personal Computing Environment,"
Communications oftheACM, Vol.29,No.3,pp.]84-201 (]986).728 Chap. 12 • CaseStudies
[Mullender and Thnenbaum 1986] Mullender, S. L, and Tanenbaum,A. S., "The Designof a
Capability-BasedDistributed Operating System," TheComputer Journal, Vol.29,No.4,pp.
289-299 (1986).
[Mullender et al, 1990] Mullender,S. 1.,VanRossum, G.,Tanenbaum, A.S.,Van Renesse,R.,and
VanStaverene,H., "Amoeba:A DistributedOperatingSystemfor the 19908," IEEE Computer,
Vol.23,No.5,pp.44-53(1990).
[Needham and Herbert1982]Needham,R. M., and Herbert,A. J., TheCambridge Distributed
Computing System,Addison..Wes)ey,Reading,MA (1982).
[Nelsonand Leach 1984] Nelson,D.L,andLeach,P. J.,"TheArchitectureand Applications ofthe
ApolloDOMAIN," IEEEComputer Graphics andApplications (April 1984).
[Orman et al, 1993]Orman,H.,Menze,E.,O'Malley, S., and Peterson, L.,"A FastandGeneral
ImplementationofMachIPCin aNetwork,"In: Proceedings ofthe 3rdUSENIX Mach Workshop,
USENIXAssociation,Berkeley,CA (April 1993).
[Ousterhout et al. 1988] Ousterhout, J.K.,Cherenson,A. R., Douglis,F., Nelson,M.N.,and
Welch,B. B.,"The Sprite Network Operating System," IEEEComputer, Vol.21,No.2,pp.
23-36(1988).
[Pikeet al. 1990] Pike,R.,Presotto,D.,Thompson, K.,andTrickey,H.,"Plan 9 from BeJlLabs,"
In:Proceedings oftheSummer 1990 UKUUG (UK Unix Users Group)Conference, USENIX
Association,Berkeley,CA, pp. 1-9(July 1990).
[Popekand Walker 1985] Popek,G.,and Walker,B.,TheLOCUSDistributed System Architecture,
MITPress,Cambridge,MA (1985).
[Pountain 1994] Pountain,D., "The ChorusMicrokernel," BYTE,pp. 131-136 (January 1994).
[Presotto et al. 1991]Presotto,D.,Pike,R.,Thompson, K.,andTrickey,H.,"Plan9,A Distributed
System,"In: Proceedings ofthe Spring 1991EurOpen Conference, EurOpen, Hertfordshire, UK,
pp.43-50(May 1991).
[Rashid1986]Rashid,R.F.,"FromRIGtoAccenttoMach:TheEvolutionofaNetwork Operating
System," In: Proceedings ofthe Fall Joint Computer Conference, AFIPS, pp. 1128-1137
(November 1986).
[Rashid1987]Rashid,R.F.,"Mach:ANewFoundationforMultiprocessorSystems Development,"
In:Proceedings ofCOMPCON'87-Digest ofPapers,IEEEPress,New York,NY,pp.192-193
(1987).
[Rashid and Robertson 1981] Rashid, R. F., and Robertson, G., "Accent: A Communication
Oriented Network Operating System Kernel," In: Proceedings ofthe 8thACMSymposium on
Operating SystemsPrinciples, AssociationforComputing Machinery, NewYork,NY,pp.64-75
(December 1981).
[Rashidet ale1988]Rashid,R.,Tevanian,A., Young,M.,Golub,D.,Baron,R.,Black,D., Bolosky,
W.J.,andChew,1., "Machine-Independent VirtualMemoryManagementforPaged Uniprocessor
and Multiprocessor Architecture," IEEE Transactions on Computers, Vol.C-37,No.8,pp.
869-908 (1988).
[Rozier and Legatheaux 1986] Rozier, M., and Legatheaux, J.M., "The Chorus Distributed
Operating System: Some Design Issues," In: Y.Parker et at(Eds.),Distributed Operating
Systems: Theory and Practice, NATOASISeries,Vol.F28, Springer-Verlag, NewYork,NY,pp.
261-289 (1986).
[Rozier et al. 1988] Rozier,M., Abrossimov, V.,Armand,F.,Boule,I., Gien,M., Guillernont, M.,
Herrmann, F., Kaiser,C., Leonard, P., Langlois, S., and Neuhauser,W., "Chorus Distributed
OperatingSystem," Computing SystemsJournal, Vol.1,No.4,pp.305-379 (1988).Chap. 12 • Bibliography 729
[Satyanarayanan etal,1990]Satyanarayanan, M.,Kistler,J.1.,Kumar,P.,Okasaki,M.E.,Siegel,
E.H.,and Steere,D. C.,"Coda:AHighlyAvailableFile Systemfor a Distributed Workstation
Environment," IEEE Transactions on Computers, Vol.39,No.4,pp.447-459 (1990).
[Schantz etal,1986]Schantz,R.E.,Thomas,R. H.,andBono,G., "TheArchitectureoftheCronus
Distributed Operating System," In: Proceedings ofthe 6th International Conference on
Distributed Computing Systems, IEEEPress,NewYork,NY,pp. 250-259 (1986).
[Schroeder et al. 1984] Schroeder, M.D.,Birrell,A. D., and Needham, R.M.,"Experiencewith
Grapevine:TheGrowthofaDistributedSystem," ACMTransactions on Computer Systems,Vol.
2,No.1,pp.3-23(1984).
[Shrivastava etal.1991]Shrivastava,S.,Dixon,G.N.,and Parrington, G.D.,"AnOverviewofthe
Arjuna DistributedProgrammingSystem," IEEE Software, pp. 66-73 (January 1991).
[Silberschatz andGalvin1994]Silberschatz,A., and Galvin,P.B., Operating Systems Concepts,
4thed.,Addison-Wesley. Reading,MA (1994).
[Sinha et al. 1991] Sinha,P K.,Maekawa,M.,Shimizu, K.,Jia,X.,Ashihara,H.,Utsunomiya, N.,
Park,K.S.,andNakano,H.,"The GalaxyDistributedOperatingSystem," IEEE'Computer, Vol.
24,No.8,pp. 34-41 (1991).
[Sinha et al,1994]Sinha,PK.,Maekawa,M., Shimizu.K, Jia,X.,Ashihara, H.,Utsunomiya, N.,
Park,K.S., and Nakano, H.,"TheArchitecturalOverviewof theGalaxyDistributedOperating
System,"In:T.L.Casavantand M.Singhal(Eds.), Readings in Distributed Computing Systems,
IEEEComputerSocietyPress,LosAlamitos,CA, pp. 327-345 (1994).
[Swinehart et at. 1986] Swinehart, D., etal., "A Structural Viewof the Cedar Programming
Environment," ACMTransactions on Programming Languages and Systems, Vol.8,No.4,pp.
419-490 (1986).
[Tanenbaum 1995]Tanenbaum, A.S.,Distributed Operating Systems, Prentice-Hall, Englewood
Cliffs, NJ (1995).
(Tanenbaum andVan Renesse 1985] Tanenbaum, A.S., andVanRenesse,R.,"Distributed
OperatingSystems," ACM Computing Surveys, Vol.17,No.4,pp.419-470 (1985).
[Tanenbaum et al.1990]Tanenbaum, A. S.,Van Renesse, R., Staveren, H.Van,Sharp,G. 1.,
Mullender,S. 1.,Jansen,1.,andVanRossum, G., "Experienceswith the Amoeba Distributed
OperatingSystem." Communications ofthe ACM, Vol.33,pp.46-63(1990).
[Theimer etal.1985]Theimer, M. M., Lantz, K.A., and Cheriton,D. R., "Preernptable Remote
Execution Facilities for the V-System," In:Proceedings oftheJOihACMSymposium on
Operating Systems Principles, AssociationforComputing Machinery, NewYork,NY,pp.2-12
(December 1985).
[Tokuda et al, 1990] Tokuda,H.,Nakajima, T., and Rao, P.,"Real-Time Mach: Towards a
Predictable Real-Time System," In: Proceedings ofthe USENIX Mach Workshop, USENIX
Association, Berkeley, CA,pp.73-82(October 1990).
[Tripathi 1989]Tripathi,A. R.,"AnOverviewoftheNexusDistributedOperatingSystemDesign,"
IEE'E Transactions on Software Engineering, Vol.SE-15,No.6,pp.686-695 (1989).
[Wilkes and Needham 1980]Wilkes, M. V.,and Needham, R. M., "The Cambridge Model
DistributedSystem," Operating Systems Review, Vol.14,No.1,pp.21-29 (1980).
[Zimmermann et al, 1981] Zimmermann, H., Banino, J.S.,Caristan, A., Guillemont, M., and
Morisset,G.,"BasicConceptsfortheSupportofDistributed Systems:TheCHORUSApproach,"
In:Proceedings ofthe 2ndInternational Conference on Distributed Computing Systems, IEEE
Press, New York,NY,pp.60-66(1981).730 Chap.12 • Case Studies
POINTERS TO818UOGRAPHIES ONTHEINTERNET
Bibliographies containing references onAmoebacan be found at:
http:www.cs.vu.nVvakgroepen/cs/amoeba...:papers.html
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedlamoeba.html
I could not find a bibliography dedicated only to the V-System. However, the following
bibliographies contain references on this system:
http:www-dsg.stanford.edulPublications.html
ftp:ftp.cs.umanitoba.calpublbibliographies/OsIIMMD_IV.html
ftp:ftp.cs.umanitoba.calpublbibliographies/Os/os.html
Bibliographies containing references onMachcan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographies/DistributedlMach.html
http:www.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html
A list of books dealing with Machcan be found at:
http:www.cs.cmu.edu/afs/cs/project/mach/public/www/doclbooks.html
Bibliographies containing references onReal Time Mach can be found at:
http:www.cs.cmu.edu/afs/cs/project/mach/public/www/doc/rtmach.html
http:www.cs.cmu.edu/afs/cs/project/art-6/www/publications.html
Bibliography containing references onMach-US (anoperating systemdeveloped as part
of theeMUMach project) can be found at:
http:www.cs.cmu.edu/afs/cs.cmu.edu/project/machlpublic/www/projects/mach_us.html
Bibliography containing references onChoruscan be found at:
ftp:ftp.cs.umanitoba.calpublbibliographieslDistributedlchorus.htmlIndex
A
Abbreviation, 505-06
ABCAST protocol, 150-151
Absolute ordering semantics, 148-49
Accent,389
Accesscontrol,475, 566, 607-23
AccessControlList (ACL), 475, 545,
616-17, 629
Access matrix, 610-15
Access rights, 608, 626
Accesssynchronization, 234
ACIDproperties, 453
Acknowledgement message, 26
Actor,696, 700
Address Resolution Protocol (ARP),76
Address space,387
transfermechanisms, 387-90
Advanced Peer-to-Peer Networking (APPN),
73Affinityscheduling, 406
Aggregate, 476
Agora, 268
Alewife, 266
Alias,505-06
All-or-nothing property, 453
Alto,4
Amoeba, 11,390-91,429,512,515,
643-59,714-21
Andrew File System (AFS), 429, 439-40,
474, 476
ApolloDomain File System,430
Application layer,69
protocols, 78-79
Archie,88
ARPANET, 4, 88
ASN.lnotation, 549
Assignment edge, 308
731732
Asynchronous transfer mode (ATM), 4-5,
48,91-104
At-least-once semantics, 135, 186
ATM-MAC layer, 101-02
Atomic transactions, 25, 453-74,483
Atomicity property, 453
concurrency atomicity, 453
failure atomicity, 453
Attack
active attack, 567, 569-73
authenticity attack, 573
chosen-plaintext attack, 576
ciphertext-only attack, 576
delay attack, 573
denial attack, 573
integrity attack, 572
known-plaintext attack, 576
passive attack, 567-68
replay attack, 573
Trojan horse attack, 568
Attacker, 567
Authentication, 586-607, 628-29
authentication server, 594, 596, 600
Kerberos authentication system,589, 591,
600-607
one-way authentication ofcommunicating
entities,592-97
two-way authentication of communicating
entities,597-99
user authentication, 566
user logins authentication, 588-92
Authenticity, 566
Authority attributes, 502
Authorization, 607
in DCE, 629
Automatic job sequencing, 3
Autonomy, 17-18
Availability, 15,422,424-25,441,447
8
Back-off algorithm, 56, 202
Bandwidth management, 102-03
Barrier, 242, 260
Batch processing, 3Index
Best-effort delivery semantics, 77
Binding, 193, 218
changing bindings, 196-97
multiple simultaneous bindings, 197
Binding agent, 194-95
Binding time, 195-96
Biometric system, 587
Blast protocol, 139
Block service, 422
Blocks,233-34
Bridge,84-85
Broadband Integrated Services Digital
Network (B-ISDN), 48
Broadcast
broadcast address, 142-43
broadcast mode, 708
broadcast-when-idle policy, 370
broadcasting, 246-47,253, 512-15
Brouter, 85
Browsing, 567
4.3BSD UNIX IPC mechanism, 153-57
Buffering, 122-25
finite-bound buffer, 124-25
multiple-message buffer,124-25
null buffer, 122-23
single-message buffer, 124
unbounded-capacity buffer, ·124
Bulletin-board semantics, 143-44
Byzantine failures, 23-24
(
Cache consistency problem, 428
Cache inheritance, 543
Cache location, 433-35
Cache manager, 477
Cache validation, 438-40
Call buffering approach, 208-10
Call-by-move, 184
Call-by-object-reference, 184
Call-by-reference, 183-84
Call-by-value, 183Call-by-visit, 184
Call semantics, 184-87,218
Callback policy, 440Index
Cambridge FileServer,430, 432
Capability, 544-45, 618-22, 646-47, 702
ownercapability, 647
Capability list, 618
Carrier,52
CarrierSenseMultiple Accesswith
Collision Detection (CSMAlCD),
52-54
Cascaded aborting, 467
Causalordering, 292
semantics, 151-53
CBCAST protocol, 152-53
CedarFileSystem(CFS),427
CellDirectory Service(CDS),546,
550-55
Cell loss priority(CLP)field, 97
Cellswitching, 91, 93
Cells,91, 93, 95
Centralprocessing unit(CPU)utilization,
360
Centralized algorithm, 31
Centralized entity,30-31
Centralized-server algorithm, 247,254
Centralized system,12
Challenge-response method, 587
Chandy-Misra-Hass (CMH)algorithm,
329-30
Charlotte, 392
Chorus,515,696-721
Chorus/MiX (Modular UNIX),697, 710
ChorusObject-Oriented Layer(COOL),
700,713-14
Cipher,one-way cipher,589
Ciphertext, 575
Clearinghouse, 502, 551
Cleartext, 575
Client-server-based communication, 79
Client-server bindingseebinding
Client-server model,9-10
Clocks
driftingofclocks,284-85
externally synchronized clocks,285
internally synchronized clocks,285
logicalclocks,293-97
Clockskew, 286733
Clocksynchronization, 283-92
Clocktick,284
Cloning, 476,481-82
Cluster,713
Clustering
algorithmic clustering, 526-28
attribute clustering, 528-30
syntactic clustering, 528
Clustering condition, 526
Collision detection, 52
Collision interval, 52
Collision window,52
Common Management Information Protocol
(CMIP), 87-88
Communication
asynchronous, 121
broadcast, 141
flow-controlled, 124-25
group,139-53
local, 116
many-to-many, 147-53
many-to-one, 140, 147
multicast, 141,671-72
one-to-many, 140-47
one-to-one, 139
point-to-point, 139
remote,116
synchronous, 12)
unicast,139
unsuccessful, 124
Communication domain, 153
Communication properties, 154
Communication protocols, 64-83
forRPCs,187-91
Computer network, 46-113
Computer-supported cooperative working
(CSCW), 13
Concurrency control,464-71
optimistic concurrency control,469-70
Concurrent events,292
Condition variable, 405
Confidentiality, 625
Confinement problem, 568,573-75
Connection-oriented protocol, 67
Connectionless protocol, 67734
Consistency models, 238-62
causal consistency, 239-40
lazy-release consistency, 243
pipelined random-access memory
(PRAM) consistency, 240
processor consistency, 240-41
release consistency, 242-43, 259-62
sequential consistency, 238-39
protocols for implementing, 244-58
strict consistency, 238
weak consistency, 241
Consistency property, 453
Consistent ordering semantics, 149-51
Constant bit rate (CBR), 91-93
Context, 504, 526-28
current context, 506
current working context, 506
metacontext, 538
Context binding, 531
Context distribution, 532-40
Controlled retransmission mechanism, 53
Controller, 325
Coordinated Universal Time (UTC), 285
Coordinator, 332
Coprocesses, 392-93
Copy-on-write mechanism, 692
Copy-on-write sharing, 688-89
Copy sharing, 114
Covert channel, 574
Critical section/region, 297, 404
Cronus, 514
Cryptanalyst, 576
Cryptography, 33, 573, 575-86
Cryptosystem
asymmetric cryptosystem, 576-78,583-86
DEScryptosystem, 578
private-key cryptosystem, 577
public-key cryptosystem, 577
RSAcryptosystem, 578
shared..key cryptosystem, 577
symmetric cryptosystem, 576-83
Customer Information Control System
(CICS),483
Cutset, 352, 354
Cycle, 307Index
D
Dash, 266Data caching, 233
Data Encryption Standard (DES), 578
Data integrity, 425Data-link layer, 67
protocols,
74-76
Data transfer models, 429-30
block-level transfer model, 429-30
byte-level transfer model, 430
file-level transfer model, 429
page-level transfer model, 429
record-level transfer model, 430
Datagram, 76, 125
Deadlock, 305-32,468-69
avoidance, 313-16
callback deadlock, 20 I
communication deadlock, 312
detection, 320-30
handling, 312-32
modeling, 307-11
necessary conditions for, 307, 310-11
phantom deadlock, 321, 323
prevention, 316-19
recovery from, 330-32
resource deadlock, 312
sufficient conditions for, 310-11
Decentralized algorithm, 31
Decipher, 575
Decoding of message data, ] 26-27
Decryption, 575
Delayed-write scheme, 437-38
DEMOSIMP, 388, 391-92
Deserializing, 393
Digest function, 623
Digital signature, 623-25
Directdemonstration method, 587
Directed graph, 307
Directory, 531
Directory Information Base (DIB), 549
Directory Information Tree (DIT), 549
Directory service, 423
Disinfection utility, 570
Disk service, 422
Distinguished name (ON), 549Index
Distributed Computing Environment (DeE),
34-38,475
cells,37-38
components, 36-37
creation of,35-36
definition of,35
Directory Service,546-56
Distributed FileSystem(DFS),475-84
Distribute TimeService(DTS),
290-92
Remote Procedure Call(RPC),221-22
Security Service,627-30
technologies, 34
threads,410-14
Distributed computing systems. 1-3
evolution, 3-5
models,5-12
Distributed control,25
Distributed Double-Loop Computer
Network (DOLeN), 533
Distributed dynamic scheduling algorithms,
cooperative versusnoncooperative,
358
Distributed fileservice(DFS),36,475-84
Distributed filesystem,421-95
Distributed Management Environment
(DME),87-88
Distributed operating system,16-19
designissues,19-34
Distributed SharedMemory (DSM),
231-81,706-07
advantages, 270-72
blocksizeselection, 235-·37
designandimplementation issues,
234-35
generalarchitecture, 233-34
heterogeneous, 267-70
structure ofsharedmemory space,
237-38
Distributed SharedVirtualMemory
(DSVM),232
Distributed system,2,19
Distributed timeserviceCOTS),290-92
Distributed transaction service,471-73
Domain, 79,205, 501, 533, 608735
Domain name,79
Domain Name/Naming Service/System
(DNS),78-79,502-04, 533, 547,
549-50
DOMAIN system,515
Duplicate request,136
Dynamic distributed-server algorithm, 249,
256
Dynamic scheduling algorithms, centralized
versusdistributed, 357-58
E
Eagerobjectmovement mechanism, 261
Earlyreplyapproach, 208
Election algorithms, 332-36
bullyalgorithm, 333-36
ringalgorithm, 335-36
E-mail(electronic mail),89
Encina,483
Encipher, 575
Encoding ofmessage data,126-27
Encryption, 575
Endpoint, 222
Episode, 477
Ethernet, 53,56-7
Eventordering, 292-97
Exactly-once semantics, 136-38,186-87
Exception handling, 198, 219, 683-84,705
Expanding ringbroadcast (ERB),513
Extensibility, 15
eXternal DataRepresentation (XDR),69, 393
External memory manager, 685-88
F
Fail-safe defaults, 626
Fail-stop failure,23
Failurehandling, 130-39
Falsesharing,236,467-68,480
FastLocalInternet Protocol (FLIP),80,
82-83
Fault,23
Faultavoidance, 24
Faultdetection andrecovery, 25-26
Faulttolerance, 24-25,350,447-53,482,
498736
Fault tolerance capability, 18
Fiber Distributed Data Interface (FOOl), 86
File, 421
File accessing models, 427-30,477
data-caching model, 428
remote service model, 428
File attributes, 426-27
File caching, 433-40,481
File exporter, 477
File group, 533
File models, 426-27
immutable file, 427
mutable file, 427
structured filet 426-27
unstructured file, 426-27
File replication, 440-47,481
File service, 423, 454
true file service, 423
File sharing semantics, 430-33,478-81
immutable shared-files semantics, 432
session semantics, 432
transaction-like semantics, 432-33
UNIX semantics, 430-31
Filesystem,421
File transfer, 17
File transfer protocol (fTP),69, 78
File versions approach, 460-63
Fileset, 476
Fileset location server, 478
Fileset server, 478
Fine-grain parallelism, 30
Fixed distributed..server algorithm, 247, 254
Flavors, 219Flexibility, 15-16,
26-29
Forward location pointer, 514
Fragment, 82
Frame, 56, 67Freezing time, 383
Functional mode, 708
G
Galaxy, 526, 537, 542-43
Gateway,86
Generic flow control (GFC) field, 97
Generic runtime (GRT) layer, 714Index
Global Directory Agent (GOA), 554-55
Global Directory Service (GDS), 546
Global Name Service (GNS)t 520-22
Glocal variable, 651
Gopher,88
Granularity, 235-37t467-68
Grapevine, 502
Group
closedgroup,141
open group, 141
Group addressing, 142
Group communication, 79-80,146-47,
657-59t708-09,712
Groupmanagement, 141
Group naming, 498
Groupserver,141
Groupwaret 13
Guarded command, 147
H
Handoff scheduling, 406
Happened-before relation, 151, 292-93
Header error control (HEe)field, 97
Heterogeneity, 32,83-84,203-04t235,
267-70,393-96,425
High-low policy, 361
Hint,535-36
Hint cache, 514-15
Home machine, 6,10-11
Host, 46
Host number, 74
Hydra,620-21
I
Idempotency, 136-39
Identification, 586
Identifier, 499, 509
protection identifier, 702
IEEE 802 LAN reference model, 71-73
IEEE Token Ring, 57-58
Incremental growth, 15
Inferencing, 568
Information Management System (IMS),483
Informationsharingamongdistributed users, 13
Inherently distributed application, 13Index
Integrity, 566
Interactivejob,3
Interconnection technologies, 84-86
Interface Definition Language (IDL),174,
212-16,221
Interface name,193-94
Internet,88-91
Internetaddress,74
InternetControlMessage Protocol (ICMP),
76-77
InternetProtocol (IP),67, 73-79
Internetworking, 83-91
Interoperability, 100-102
Interprocess communication (IPC),114,
118-19,656-59,690-94,707-10,
716
Interrupt, 120
Intruder, 567
IPaddress,74
IPoverATM,100, 102
ISOIOSI reference model,65-71
l'I'C File System,437
IVY,237, 244, 266
J
Jacketroutine,409-10,412
Jamming signal,53
K
k-faulttolerant,24
Kerberization, 607
Kerberos, 589, 591, 600-607
Kernel,18,27, 715
microkernel, 27-29
monolithic kernel,27-29
Kernel-mode, 610
Keydistribution center(KDC),578-83
Keydistribution problem, 578-86
Knot,307
L
Language runtimelayer,714
Last-of-many callsemantics, 186
Last-one semantics, 136,185-86
Latency/bandwidth tradeoff, 103-04737
Layered protocols, 64
Leaking, 568
Legitimate channel, 574
Linda,237,267
Link,391-92
Loadbalancing, 348,355-67
Loadestimation policies,359-60,368
Loadleveling, 355
Loadsharing,348, 367-71
Localareanetwork(LAN), 4, 47-58
emulation overATM,100-102
Locating, 245-49, 253-58, 49~512-15
Location independency, 497
Location policies,362-64,368-69
Locking, 465-70
granularity oflocking,467-68
intention-to- writelocks,465-67
two-phase lockingprotocol, 467
type-specific locking,465
LOCUS, 388, 393, 430, 526, 533, 542-43
Logicbombs,572
Logicalhost,392
Longhaulnetwork, 47
Loosely-coupled system,1-2
M
~ach,410, 515, 674-96,714-21
MachInterface Generator (MIG),695-96
Machine, 3,46
Mailbox, 125
Mapper,706
Marshaling, 177-78,218
Masquerading, 568
Maximum transferunit(MTU),76, 125
May-becallsemantics, 185
Medium accesscontrolprotocols, 51-55
Memory block,233-34
Memory coherence, 234
Memory management, 684-89,705-07, 717
Memory object,685
Memory sharing,688-89
Mercury communication system,209
Mermaid, 267-69
Message, 115,136--39, 575,690,701
Message forwarding mechanisms, 390-92738
Message integrity, 623--25, 629
Message passing, 114-66,691-92
Message structure, 118-19
Melber, 237
Metropolitan Area Network (~1AN),48
Midway, 237, 267
Migration limitingpolicies, 367
Minicomputer, 4
Minicomputer model, 5
Mirage,265-66
Modification propagation, 435-38
Mosaic, 88
Mount protocol, 523-25
auto mounting, 523-24
manualmounting, 523
staticmounting, 523
Multiaccess branching bus network, 49
Multiaccess bus network, 48
Multicache consistency, 435-40, 543-44
Multicast
atomicmulticast, 145-46
buffered multicast, 143
unbuffered multicast, 143
Multicast address, 142
Multicast Backbone (MBooe), 74
Multicast communication, 141,671-72
all-reliable, 145
m-out-of-n-reliable, 145
l-reliable, 144
O-reliable, 144
Multicopy update protocols
available-copies protocol, 444
majority-consensus protocol, 446
primary-copy protocol, 444
quorum-based protocol, 445-46
read-all-write-any protocol, 446
read-any-write-all protocol, 443-44, 446
read-only replication, 443
weighted-voting protocol, 446-47
Multics, 610, 626
Multidatagram message, 125, 139
Multihomed host, 76
Multimedia application, 5
Multiprogramming, 3
Munin, 237, 259-62, 265, 267Mutex variable, 404-05
fast mutex variable, 411
nonrecursive mutex variable, 411
recursive mutex variable, 411
Mutual exclusion, 297-305
N
Name,499-500
absolute name, 506-08
attribute-based name,508-09
compound name, 501
descriptive name,508-09
flat name, 501
generic name, 508group name, 508
hierarchical name, 502
high-level name, 500
human-oriented name, 500,
515-40
low-level name, 500
multicast name, 508
nickname, 506
primitive name, 501
qualified name, 504
relative name, 506-08
simple name, 501source-routing name, 509
system-oriented name, 500,
509-12
Name agent, 503-04
Name cache, 541-44
directory cache, 542
full-name cache, 542
prefix cache, 542
Name prefix, 534-35
Name resolution, 505, 532-40, 553
Name server, 130,502-03
authoritative name server, 502
Name service, 423
Name space, 500-502
flat name space, 501
partitioned name space, 501-02
single global name space, 526
Naming,496-564, 663-65
and security, 544-46
group naming, 498
uniform naming convention, 497IndexIndex
Need-to-know principle, 566, 626
Negative right, 617
NetBIOS, 73
Net number, 74
Network File System(NFS), 428, 430, 451,
475, 478, 481, 522, 524, 526
Network layer, 67
protocols, 76-77
Network management, 80,86-88
Network manager, 710
Network message server, 692
Network operating system,16-18
Network system,18
Network TimeProtocol (NTP),290
Network weight,82
Networkwide IPC,692-94, 710
NEXUS system, 515
Node,3,46
home node, 391, 393
processnode,308
resource node, 308
Nonce,573
o
Objectaccessing, 512
Objectlocating, 512-15
Octet,74
Off-lineprocessing, 3
On-lineshopping, 90
On-linetransaction processing (OLTP), 483
On-useconsistency control,541, 544
One-copy /single-copy semantics, 239
Opendistributed system, 15
Operating system, 16
OpticalCarrierleveln (OC-n), 95-96
Orca, 267, 643
Ordered message delivery, J47-52
Original sharing, 114
Orphan call, 186
Orphanextermination, 186
p
Packet, 52, 125
Packetswitching exchange (PSE), 59Parallelprocessing system, 2
Password, 588-92
one-time password, 591
Password generator, 591
Path, 307
Payloadtypeidentifier (PTI) field, 97
Performance, 29-30,424,498
Permanence property, 453
Physical layer,66-7,94-96
protocols, 74
Plaintext, 575
Poll-when-idle policy, 371
Polling,120,365-66
Port, 125, 690, 701
control port, 687
name port, 687
network port, 692
objectport, 687
process port, 679
thread port, 679
Port group, 708
Portmigration, 709
Port number, 77
Port set, 691
Portmapper, 218, 220
POSIX,410,413
Presentation layer,68-69
Prctransferring (precopying), 388-89
Principal, 627
Principle of leastprivilege, 566, 626
Priorityassignment policies, 366
Privacy, 566
PrivacyEnhanced Mail (PEM), 624-25
Privilege attributes, 628
Probable owner, 249
Process, 114,650,678-79
heavyweight process, 399
lightweight process,399
local process, 358
remote process, 358
Processaddressing, 127-30
explicitaddressing, 127
functional addressing, 127
implicitaddressing, 127
link-based addressing, 128-29739740
Process descriptor, 650
Process group, 671
Processmanagement, 381-420,649-53,
666-69,702-5,715-16
Processmigration, 272,381-98
flow ofexecution in,382
heterogeneous systems in, 393-96
mechanisms, 384-93
nonpreemptive process migration, 370,
382
preemptive process migration, 369, 382
Process state, 387
Process transfer policies, 360-62,368
Processor allocation, 381
Processor-pool model,10-11, 645
Progress property, 321
Promise data type, 209
Proofbyknowledge, 586-87
Proofbypossession, 587
Proofby property, 587
Protection domain, 608-10
Protection rule, 608
Protection state, 608, 611,613
Protocol, 64
Protocol family, 65
Protocol stack, 65
Protocol suite, 65
Public key manager (PKM),584
Pup name service, 533
R
Reachable set, 307
Read-ahead mechanism, 478
Read quorum, 445
Receiver
nonselective, 147
selective, 147
Receiver-initiative policy,369-70
Recovery techniques, 459-64
Redundancy techniques, 24
Redundant pages,389
Region,684, 701, 705
Relative distinguished name (RDN), 549
Reliability, 14-15,23-6,425, 441
Remote File Server(RFS), 433Index
Remoteprocedure call (RPC), 36,167-230
asynchronous RPC,188,220
authenticated RPC,629
batch-mode RPC,203, 220
broadcast RPC, 202, 220
callback RPC, 199-201,220
communication protocols for RPCs,
187-91
complicated RPC,191-92
DCE RPC, 221-22
heterogeneous RPC (HRPC), 203-4
lightweight RPC (LRPC), 204-8
protocol specification, 212
RPC Language (RPCL), 212-13
RPC messages, 174-77
call messages, 175
reply messages, 175-77
simple RPC, 189
special types of RPC, 199-203, 220
Sun RPC, 212-21
transparency of RPC, 170-1
Transport Independent RPC (TI-RPC), 220
Remote process creation, 712
Repeater, 49
Replacement strategy,235,262-64
Replica,422,440,498-99
first-class replica, 441
naming, 442
second-class replica, 441
Replication control,442-43.
explicit replication, 443
implicitllazy replication, 443
Replication server, 478, 481
Request edge, 308
Request (R) protocol, 188-89
Request/reply (RR) protocol, 189
Request/repl y/acknowledge-repl y(RRA)
protocol, 190-91
Request-response protocol,9
Research Storage System (RSS), 430
Resource
local, 3
nonpreemptable, 306
preemptable, 318
remote, 3Index
Resource allocation graph,308-10
Resource management, 347-80
Resource sharing, 13
Response time,14
Retransmission slot time, 53
ReverseAddress Resolution Protocol
(RARP),76
Ringnetwork, 50-51
Rivesi-Shamir-Adlernan (RSA)
cryptosystem, 578, 625
rlogin, 69
Robustness, 447
Router, 85
Routingtechniques, 61-64
adaptive routing,63
deterministic routing, 63
dynamic routing,63-64
hop-by-hop routing,62
hybridrouting, 63
sourcerouting,62
staticrouting,63
rpcd, 222
rpcgen,214
RPCRuntime, 171, 173
RS232-C,67
Run server, 10, 652
5
Safesequence, 313
Safe state, 313
Safetyproperty, 321
Scalability, 30-3I,350,424, 441, 497
Schedule, 458
SDD-ldatabase system,471
Secrecy, 566
Security, 33,80,198-99,219,425,544-46,
565-641,718
communication security, 566--67
external security, 566
internalsecurity, 566
Security bit, 82
Segment, 650-51, 701, 705
Selective functional mode, 709
Selective repeattechnique, 139741
Selective retransmission mechanism, 81
Semantic transparency, 170
Send-to-all semantics, 143-44
Sender-initiative policy,369-70
Sequencer, 149
Serial Line InternetProtocol (SLIP),74
Serializability conflict, 461
Serializability property, 453
Serializing, 393
Seriallyequivalent, 453, 458
Server, 8
Servercreation semantics, 181-83
instance-per-call server,181-82
instance-per-session server, 182
persistent server,182-83
Serverimplementation, 178-81
Serverlocating, 194-95
Servermanagement, 178-83
Servernaming, 193
Service, 9
Serviceparadigm, 449-53
Session, 432, 449, 622
Sessionlayer, 68
Shadow blockstechnique, 462-63
Signalhandling, 407, 413
Simple. and Efficient Adaptation Layer
(SEAL),99
SimpleMailTransfer Protocol (SMTP), 78
SimpleNetwork Management Protocol
(SNMP), 87-88
Single-datagram messages, 125
Singlesign-on, 591
Site,3,46
monitorsite, 50
originsite, 391, 393
Skulking, 551
Slottedringprotocol, 55
Smartcard, 591
Socket,154
Spoofing, 568
Sprite,388,391,430,437,439, 526, 533,
542-43
Stablestorage,448-49
Start-up misses, 543
Starvation, 298, 319, 332, 469742
Stateinformation exchange policies,
364-66, 370-71
Stateful server, 26, 178-79,449-50
Stateless server,25-26,180-81,450-51
Stop-and-wait protocol, 139
Storagechannel, 574
Storage service, 422
Store-and-forward communication, 61
Stub, 171
client stub, 171-72
serverstub, 171, 173
Stubgeneration, 174,212-16
Subnetnumber, 74
SunOS, 410
Superuser, 610
Supervisor, 699
Switching techniques, 60-61
circuitswitching, 60-61
packetswitching, 61
Symbolic link, 505
Synchronization, 120-22,282-346
blocking type, 120
clocksynchronization, 283-92
nonblocking type,120
Synchronization variable, 241
Synchronous DigitalHierarchy (5DH),96
Synchronous OpticalNETwork (SONET), 95
Synchronous Transport Signal level n
(STS-n),95
Synonym, 506
Syntactic transparency, 170
System failures, 23
inconsistency due to,454-55
System image, 16-17
SystemNetwork Architecture (SNA), 73, 84
T
TIsignal, 95
T3 signal, 95
Taggedrepresentation, 126
Taskassignment, 348,351-55
Team, 666
TELNET protocol, 78
Thrashing, 235-36, 264-65
processor thrashing, 349-50Index
Threads, 381, 398-414,651,678-83,700,712
creation, 403
models for organizing, 401-3
motivations for using, 399-401
scheduling, 406,412-13, 681-83,704-5
synchronization, 404-5,411-12,704
termination, 403-4
Threadspackage, 36, 403
CThreadspackage, 410, 680-1
DeEThreads, 410-14
design,403-7
GNUThreads, 410
implementing, 407-10
lightweight processes package, 410
P-Threads, 410
Threshold policy, 360
Throughput, 14
Tightly-coupled system, 1
Time provider, 285
Time server, 287
active time server, 287-88
passive time server, 287
Timeout-based retransmission, 26, 131, 211
Timesharing system, 3
Timestamp, 470-71, 511
Token, 54, 303
Token manager, 477-78
Token-passing approach, 303-5
Token ring protocol, 54-55
Totalordering of events, 297
Trampoline mechanism, 694
Transaction, 25, 332, 432, 453-74
nestedtransaction, 473-74
subtransaction, 473-74
Transparency, 17, 19,79,383,698
accesstransparency, 20, 424
concurrency transparency, 22
failuretransparency, 21
formsoftransparency, 19-23
locationtransparency, 20, 497
migration transparency, 22
naming transparency, 20, 424
performance transparency, 23
replication transparency, 21, 424, 442,
498Index
scaling transparency, 23
structure transparency, 423
transparency of RPC, 170-71
Transparent Computing Facility (TCF), 391
Transport Control Protocol (TCP), 68, 77
Transport laye~67-68
protocols, 77~78
TrivialFileTransfer Protocol (T~lP),78
Trojan horse program, 568
Tuple space, 237
Twin page, 261
Two-phase multi-server commitprotocol,
472-73
U
Unique identifier, 500, 509, 511-12
Universal Directory Service (UDS), 502
Universally Unique Identifier (VUID), 221
UNIX,27,32,33,570-71,712
UNIX emulation, 644, 661, 694-95, 697,
710-12
UNIX United, 520
Untagged representation, 126
User Datagram Protocol (UDP), 68, 77
User mobility, 20,422,424,497
User-mode, 610
DUCPnamespace,509
V
Variable bit rate (VBR), 91, 92
Verification, 586
Versatile Message Transfer Protocol
(VMTP), 80-82
Victim,332
Videoconferencing, 91
Virtual channel identifier(Vel)field, 97
Virtual-memory management, 684743
Virtual path identifier (VPI)field,97
Virtual uniprocessor, 17, 20
Viruses,569-70, 572
Volatile storage, 448
V-system, 10, 389-93~ 515, 526, 542-43,
659-74,714-21
W
Wait-die scheme, 319
Wait-for-graph (WFG),311,320-29
Wait-wound scheme, 319
WideAreaInformation Servers (WAIS),
88-89
Wide area network (WAN), 4, 47, 59-64
Workstation, 4
diskful, 8
diskless,8
Workstation model,6-8
Workstation-server model,8-10
World Wide Web (WWW), 88-89
Worms,570-72
Write-ahead log approach, 463-64
Write-invalidate protocol, 250-51
Write quorum, 445
Write-through scheme, 437
Write-update protocol, 251-52
X
X.SOOprotocol, 69,546,548-9
X.400protocol, 69
X.25 protocol, 67
Xerox Networking System (XNS),73
X/Open Directory Server (XDS), 556
X/Open Object Management (XOM), 556
Z
Zone,533-36DISTRIBUTED SYSTEMS
Second EditionAbout theAuthors
Andrew S.Tanenbaum hasanS.B.degree fromM.LT. andaPh.D. fromtheUniversity
ofCalifornia atBerkeley. Heiscurrently aProfessor ofComputer Science attheVrije
Universiteit inAmsterdam, TheNetherlands, where heheads theComputer Systems
Group. Until stepping down inJan.2005, for12years hehadbeenDean oftheAdvanced
School forComputing andImaging, aninteruniversity graduate school doing research on
advanced parallel, distributed, andimaging systems.
Inthepast.hehasdone research oncompilers, operating systems, networking, and
local-area distributed systems. Hiscurrent research focuses primarily oncomputer secu-
rity,especially inoperating systems, networks, andlarge wide-area distributed systems.
Together, allthese research projects haveledtoover125refereed papers injournals and
conference proceedings andfivebooks, which havebeentranslated into21languages.
Prof. Tanenbaum hasalsoproduced aconsiderable volume ofsoftware. Hewasthe
principal architect oftheAmsterdam Compiler Kit,atoolkit forwriting portable com-
pilers, aswellasofMINIX, asmall UNIX clone aimed atveryhighreliability. Itisavail-
ableforfreeatwww.minix3.org.This system provided theinspiration andbaseonwhich
Linux wasdeveloped. Hewasalsooneofthechiefdesigners ofAmoeba andGlobe.
HisPh.D. students have gone ontogreater glory aftergetting their degrees. Heis
veryproud ofthem. Inthisrespect heresembles amother hen.
Prof.Tanenbaum isaFellow oftheACM, aFellow ofthetheIEEE, andamember of
theRoyal Netherlands Academy ofArtsandSciences. Heisalsowinner ofthe1994
ACM KarlV.Karlstrom Outstanding Educator Award, winner ofthe1997ACM/SIGCSE
Award forOutstanding Contributions toComputer Science Education, andwinner ofthe
2002 Texty award forexcellence intextbooks. In2004hewasnamed asoneofthefive
newAcademy Professors bytheRoyal Academy. Hishome pageisatwww.cs.vu.nl/r-ast.
Maarten vanSteen isaprofessor attheVrije Universiteit, Amsterdam, where heteaches
operating systems, computer networks, anddistributed systems. Hehasalsogiven various
highly successful courses oncomputer systems related subjects toICTprofessionals from
industry andgovernmental organizations.
Prof. vanSteen studied Applied Mathematics atTwente University andreceived a
Ph.D. fromLeiden University inComputer Science. After hisgraduate studies hewentto
work foranindustrial research laboratory where heeventually became head oftheCom-
puter Systems Group, concentrating onprogramming support forparallel applications.
After fiveyears ofstruggling simultaneously doresearch andmanagement, hedecided
toreturn toacademia, firstasanassistant professor inComputer Science attheErasmus
University Rotterdam, andlaterasanassistant professor inAndrew Tanenbaum's group at
theVrije Universiteit Amsterdam. Going back touniversity wastheright decision; his
wifethinks so,too.
Hiscurrent research concentrates onlarge-scale distributed systems. Partofhis
research focuses onWeb-based systems, inparticular adaptive distribution andreplication
inGlobule, acontent delivery network ofwhich hiscolleague Guillaume Pierre isthechief
designer. Another subject ofextensive research isfullydecentralized (gossip-based) peer-
to-peer systems ofwhich results havebeenincluded inTribler, aBitTorrent application
developed incollaboration withcolleagues fromtheTechnical University ofDelft.DISTRIBUTED SYSTEMS
Second Edition '
Andrew S.Tanenbaum
Maarten Van Steen
Upper Saddle River, NJ07458LibraryofCongress Ca.aloging-in.Public:ation Data
Tanenbaum. Andrew S.
Distributed systems: principles andparadigms IAndrew S.Tanenbaum, Maarten VanSteen.
p.em.
Includes bibliographical references andindex.
ISBN 0-13-239227-5
1.Electronic dataprocessing--Distributed processing. 2.Distributed operating systems (Computers) I.Steen,
Maarten van. II.Title.
QA76.9.D5T36 2006
005.4'476--dc22
2006024063
VicePresident andEditorial Director. ECS: Marcia J.Horton
Executive Editor: Tracy Dunkelberger
Editorial Assistant: Christianna Lee
Associtate Editor: Carole Stivder
Executive Managing Editor: 'Vince O'Brien
Managing Editor: Csmille Tremecoste
Production Editor: Craig Little
Director ofCreative Services: PaulBelfanti
Creative Director: JuanLopez
ArtDirector: Heather Scott
Cover Designer: Tamara Newnam
ArtEditor: Xiaohong Zhu
Manufacturing Manager, ESM: Alexis Heydt-Long
Manufacturing Buyer: LisaMcDowell
Executive Marketing Manager: Robin O'Brien
Marketing Assistant: Mack Patterson
©2007Pearson Education. Inc.
Pearson Prentice Hall
Pearson Education, Inc.
Upper Saddle River, NJ07458
Allrights reserved. Nopartofthisbook maybereproduced inanyformorbyanymeans, without permission in
writing fromthepublisher.
Pearson Prentice Hall~ isatrademark ofPearson Education, Inc.
Theauthor andpublisher ofthisbook haveusedtheirbestefforts inpreparing thisbook. These efforts include the
development, research, andtesting ofthetheories andprograms todetermine theireffectiveness. Theauthor and
publisher make nowarranty ofanykind, expressed orimplied, withregard tothese programs orthedocumentation
contained inthisbook. Theauthor andpublisher shallnotbeliable inanyevent forincidental orconsequential
damages inconnection with,orarising outof,thefurnishing, performance, oruseofthese programs.
Printed intheUnited States ofAmerica
10987654321
ISBN:0-13-239227-5
Pearson Education Ltd.,London
Pearson Education Australia Pty.Ltd.,Sydney
Pearson Education Singapore, Pte.Ltd.
Pearson Education North AsiaLtd.,Hong Kong
Pearson Education Canada, Inc.,Toronto
Pearson Educaci6n deMexico, S.A.deC.V.
Pearson Education-Japan, Tokyo
Pearson Education Malaysia, Pte.Ltd.
Pearson Education, Inc.,Upper Saddle River, NewJerseyToSuzanne, Barbara, Marvin, andthememory ofBram andSweetie 1t
-AST
ToMarielle, Max, andElke
-MvSCONTENTS
PREFACE xvii
1INTRODUCTION 1
1.1 DEFINITION OFADISTRIBUTED SYSTEM 2
1.2 GOALS 3
1.2.1Making Resources Accessible 3
1.2.2Distribution Transparency 4
1.2.3Openness 7
1.2.4Scalability 9
1.2.5Pitfalls 16
1.3 TYPES OFDISTRIBUTED SYSTEMS 17
1.3.1Distributed Computing Systems 17
1.3.2Distributed Information Systems 20
1.3.3Distributed Pervasive Systems 24
1.4 SUMMARY 30
2ARCHITECTURES 33
2.1 ARCHITECTURAL STYLES 34
2.2 SYSTEM ARCHITECTURES 36
2.2.1 Centralized Architectures 36
2.2.2 Decentralized Architectures 43
2.2.3 Hybrid Architectures 52
2.3 ARCHITECTURES VERSUS MIDDLEW ARE 54
2.3.1 Interceptors 55
2.3.2 General Approaches toAdaptive Software 57
2.3.3 Discussion 58
viiviii CONTENTS
2.4 SELF-MANAGEMENT INDISTRIBUTED SYSTEMS 59
2.4.1 TheFeedback Control Model 60
2.4.2 Example: Systems Monitoring withAstrolabe 61
2.4.3 Example: Differentiating Replication Strategies inGlobule 63
2.4.4 Example: Automatic Component Repair Management inJade 65
2.5 SUMMARY 66
3PROCESSES 69
3.1 THREADS 70
3.1.1 Introduction toThreads 70
3.1.2 Threads inDistributed Systems 75
3.2 VIRTUALIZATION 79
3.2.1 TheRoleofVirtualization inDistributed Systems 79
3.2.2 Architectures ofVirtual Machines 80
3.3 CLIENTS 82
3.3.1 Networked UserInterfaces 82
3.3.2 Client-Side Software forDistribution Transparency 87
3.4 SERVERS 88
3.4.1 General Design Issues 88
3.4.2 Server Clusters 92
3.4.3 Managing Server Clusters 98
3.5 CODE MIGRATION 103-
3.5.1 Approaches toCode Migration 103
3.5.2 Migration andLocal Resources 107
3.5.3 Migration inHeterogeneous Systems 110
3.6 SUMMARY 112
-4COMMUNICATION 115
4.1 FUNDAMENTALS 116
4.1.1 Layered Protocols 116
4.1.2 Types ofCommunication 124
4.2 REMOTE PROCEDURE CALL 125
4.2.1 Basic RPCOperation 126
4.2.2 Parameter Passing 130CONTENTS ix
4.2.3 Asynchronous RPC 134
4.2.4 Example: DCERPC 135
4.3 MESSAGE-ORIENTED COMMUNICATION 140
4.3.1 Message-Oriented Transient Communication 141
4.3.2 Message-Oriented Persistent Communication 145
4.3.3 Example: ffiM's WebSphere Message-Queuing System 152
4.4 STREAM-ORIENTED COMMUNICATION 157
,4.4.1 Support forContinuous Media 158
4.4.2 Streams andQuality ofService 160
4.4.3 Stream Synchronization 163
4.5 MULTICAST COMMUNICATION 166
4.5.1Application-Level Multicasting 166
4.5.2 Gossip-Based DataDissemination 170
4.6 SUMMARY 175
5NAMING 179
5.1 NAMES, IDENTIFIERS, AND ADDRESSES 180
5.2 FLAT NAMING 182
5.2.1 Simple Solutions 183
5.2.2 Home-Based Approaches 1?6
5.2.3 Distributed Hash Tables 188
5.2.4 Hierarchical Approaches 191
5.3 STRUCTURED NAMING 195
5.3.1 Name Spaces 195
5.3.2 Name Resolution 198
5.3.3 TheImplementation ofaName Space 202
5.3.4 Example: TheDomain Name System 209
5.4 ATTRIBUTE-BASED NAMING 217
5.4.1 Directory Services 217
5.4.2 Hierarchical Implementations: LDAP 218
5.4.3 Decentralized Implementations 222
5.5 SUMMARYx CONTENTS
6SYNCHRONIZATION 231
6.1 CLOCK SYNCHRONIZATION 232
6.1.1 Physical Clocks 233
6.1.2 Global Positioning System 236
6.1.3 Clock Synchronization Algorithms 238
6.2 LOGICAL CLOCKS 244
6.2.1 Lamport's Logical Clocks 244
6.2.2 Vector Clocks 248
6.3 MUTUAL EXCLUSION 252
6.3.1 Overview 252
6.3.2 ACentralized Algorithm 253
6.3.3 ADecentralized Algorithm 254
6.3.4 ADistributed Algorithm 255
6.3.5 AToken RingAlgorithm 258
6.3.6 AComparison oftheFourAlgorithms 259
6.4 GLOBAL POSITIONING OFNODES 260
6.5 ELECTION ALGORITHMS 263
6.5.1 Traditional Election Algorithms 264
6.5.2 Elections inWireless Environments 267
6.5.3 Elections inLarge-Scale Systems 269
6.6 SUMMARY 270
7CONSISTENCY AND REPLICATION 273-
7.1 INTRODUCTION 274
7.1.1 Reasons forReplication 274
7.1.2 Replication asScaling Technique 275
7.2 DATA-CENTRIC CONSISTENCY MODELS 276
7.2.1 Continuous Consistency 277
7.2.2 Consistent Ordering ofOperations 281
7.3 CLIENT -CENTRIC CONSISTENCY MODELS 288
7.3.1 Eventual Consistency 289
7.3.2 Monotonic Reads 291
7.3.3 Monotonic Writes 292
7.3.4 ReadYourWrites 294
7.3.5 Writes Follow Reads 295CONTENTS
7AREPLICA MAi'iAGEMENT 296
704.1 Replica-Server Placement 296
704.2 Content Replication andPlacement 298
704.3 Content Distribution 302
7.5 CONSISTENCY PROTOCOLS 306
7.5.1 Continuous Consistency 306
7.5.2 Primary-Based Protocols 308
7.5.3Replicated-Write Protocols 311
7.5ACache-Coherence Protocols 313
7.5.5Implementing Client-Centric Consistency 315
7.6 SUMMARY 317
8FAULT TOLERANCE
8.1 INTRODUCTION TOFAULT TOLERANCE 322
8.1.1Basic Concepts 322
8.1.2Failure Models 324
8.1.3Failure Masking byRedundancy 326
8.2 PROCESS RESILIENCE 328
8.2.1Design Issues 328
8.2.2 Failure Masking andReplication 330
8.2.3Agreement inFaulty Systems 331
8.204 Failure Detection 335
8.3 RELIABLE CLIENT-SERVER COMMUNICATION 336
8.3.1Point-to-Point Communication 337
8.3.2RPCSemantics inthePresence ofFailures 337
804 RELIABLE GROUP COMMUNICATION 343
804.1Basic Reliable-Multicasting Schemes 343
804.2 Scalability inReliable Multicasting 345
804.3 Atomic Multicast 348
8.5 DlSTRIBUTED COMMIT 355
8.5.1Two-Phase Commit 355
8.5.2Three-Phase Commit 360
8.6 RECOVERY 363
8.6.1 Introduction 363
8.6.2Checkpointing 366xi
321xii CONTENTS
8.6.3Message Logging 369
8.6.4Recovery-Oriented Computing 372
8.7 SUMMARY 373
9SECURITY 377
9.1 INTRODUCTION TOSECURITY 378
9.1.1 Security Threats, Policies, andMechanisms 378
9.1.2 Design Issues 384
9.1.3 Cryptography 389
9.2 SECURE CHANNELS 396
9.2.1 Authentication 397
9.2.2 Message Integrity andConfidentiality 405
9.2.3 Secure Group Communication 408
9.2.4 Example: Kerberos 411
9.3 ACCESS CONTROL 413
9.3.1 General Issues inAccess Control 414
9.3.2 Firewalls 418
9.3.3 Secure Mobile Code 420
9.3.4Denial ofService 427
9.4 SECURITY MANAGEMENT 428
9.4.1 KeyManagement 428
9.4.2 Secure Group Management 433
9.4.3 Authorization Management 434
9.5 SUMMARY 439
10DISTRIBUTED OBJECT-BASED SYSTEMS 443
10.1 ARCHITECTURE 443
10.1.1 Distributed Objects 444
10.1.2 Example: Enterprise JavaBeans 446
10.1.3 Example: Globe Distributed Shared Objects 448
10.2 PROCESSES 451
10.2.1 Object Servers 451
10.2.2 Example: TheIceRuntime System 454CONTENTS xiii
10.3 COMMUNICATION 456
10.3.1 Binding aClient toanObject 456
10.3.2 Static versus Dynamic Remote Method Invocations 458
10.3.3 Parameter Passing 460
10.3.4 Example: JavaRMI 461
10.3.5 Object-Based Messaging 464
10.4 NAMING 466
10.4.1 CORBA Object References 467
10.4.2 Globe Object References 469
10.5 SYNCHRONIZATION 470
10.6 CONSISTENCY ANDREPLICATION 472
10.6.1 EntryConsistency 472
10.6.2 Replicated Invocations 475
10.7 FAULT TOLERANCE 477
10.7.1 Example: Fault-Tolerant CORBA 477
10.7.2 Example: Fault-Tolerant Java 480
10.8 SECURITY 481
10.8.1 Example: Globe 482
10.8.2 Security forRemote Objects 486
10.9 SUMMARY 487
11DISTRIBUTED FILE SYSTEMS 491
11.1 ARCHITECTURE 491
11.1.1 Client-Server Architectures 491
11.1.2 Cluster-Based Distributed FileSystems 496
11.1.3 Symmetric Architectures 499
11.2 PROCESSES 501
11.3 COMMUNICATION 502
11.3.1 RPCs inNFS 502
11.3.2 TheRPC2 Subsystem 503
11.3.3 File-Oriented Communication inPlan9505
11.4 NAMING 506
11.4.1 Naming inNFS 506
11.4.2 Constructing aGlobal Name Space 512xiv CONTENTS
11.5 SYNCHRONIZATION 513
]].5.]Semantics ofFileSharing 513
]1.5.2FileLocking 5]6
]1.5.3Sharing FilesinCoda 518
]1.6CONSISTENCY ANDREPLICATION 5]9
11.6.1 Client-Side Caching 520
11.6.2Server-Side Replication 524
11.6.3 Replication inPeer-to-Peer FileSystems 526
11.6.4 FileReplication inGridSystems 528
11.7 FAULT TOLERANCE 529
11.7.1 Handling Byzantine Failures 529
11.7.2 HighAvailability inPeer-to-Peer Systems 531
11.8 SECURITY 532
11.8.] Security inNFS 533
11.8.2 Decentralized Authentication 536
1].8.3Secure Peer-to-Peer File-Sharing Systems 539
11.9 SUMMARY 541
12DISTRIBUTED WEB-BASED SYSTEMS 545
12.1 ARCHITECTURE 546
12.1.1 Traditional Web-Based Systems 546
12.1.2 WebServices 551
12.2 PROCESSES 554
12.2.1 Clients 554
12.2.2 TheApache WebServer 556
12.2.3 WebServer Clusters 558
12.3 COMMUNICATION 560
12.3.1 Hypertext Transfer Protocol 560
12.3.2 Simple Object Access Protocol 566
12.4 NAMING 567
12.5 SYNCHRONIZATION 569
12.6 CONSISTENCY ANDREPLICATION 570
12.6.1 WebProxy Caching 571
12.6.2 Replication forWebHosting Systems 573
12.6.3 Replication ofWebApplications 579CONTENTS xv
12.7 FAULT TOLERANCE 582
12.8 SECURITY 584
12.9 SUMMARY 585
13DISTRIBUTED COORDINATION-BASED 589
SYSTEMS -
13.1 INTRODUCTION TOCOORDINATION MODELS -589
13.2 ARCHITECTURES 591
13.2.1Overall Approach 592
13.2.2 Traditional Architectures 593
13.2.3 Peer-to-Peer Architectures 596
13.2.4 Mobility and'Coordination 599
13.3 PROCESSES 601
13.4 COMMUNICATION 601
13.4.1 Content-Based Routing 601
13.4.2 Supporting Composite Subscriptions 603
13.5 NAMING 604
13.5.1 Describing Composite Events 604
13.5.2 Matching Events andSubscriptions 606
13.6 SYNCHRONIZATION 607
13.7 CONSISTENCY AND REPLICATION 607
13.7.1 Static Approaches 608
13.7.2 Dynamic Replication 611
13.8 FAULT TOLERANCE 613
13.8.1 Reliable Publish-Subscribe Communication 613
13.8.2 Fault Tolerance inShared Dataspaces 616
13.9 SECURITY 617
13.9.1 Confidentiality 618
13.9.2 Secure Shared Dataspaces 620
13.10 SUMMARY 621xvi CONTENTS
14SUGGESTIONS FOR FURTHER READING 623
AND BIBLIOGRAPHY
]4.1SUGGESTIONS FORFURTHER READING 623
14.1.1 Introduction andGeneral Works 623
]4.1.2 Architectures 624
14.1.3 Processes 625
14.1.4 Communication 626
14.1.5 Naming 626
14.1.6 Synchronization 627
14.1.7 Consistency andReplication 628
14.1.8 FaultTolerance 629
14.1.9 Security 630
14.1.10 Distributed Object-Based Systems 631
14.1.11 Distributed FileSystems 632
14.1.12 Distributed Web-Based Systems 632
14.1.13 Distributed Coordination-Based Systems 633
14,2 ALPHABETICAL BIBLIOGRAPHY 634
INDEX 669PREFACE
Distributed systems formarapidly changing fieldofcomputer science. Since
theprevious edition ofthisbook, exciting newtopics haveemerged suchaspeer-
to-peer computing andsensor networks, while others havebecome much more
mature, likeWebservices andWebapplications ingeneral. Changes suchasthese
required thatwerevised ouroriginal texttobringitup-to-date.
Thissecond edition reflects amajor revision incomparison totheprevious
one.Wehaveadded aseparate chapter onarchitectures reflecting theprogress
thathasbeenmadeonorganizing distributed systems. Another major difference is
thatthere isnowmuch more material ondecentralized systems, inparticular
peer-to-peer computing. Notonlydowediscuss thebasictechniques, wealsopay
attention totheirapplications, suchasfilesharing, information dissemination,
content-delivery networks, andpublish/subscribe systems.
Nexttothesetwomajor subjects, newsubjects arediscussed throughout the
book. Forexample, wehaveadded material onsensor networks, virtualization,
server clusters, andGridcomputing. Special attention ispaidtoself-management
ofdistributed systems, anincreasingly important topic assystems continue to
scale.
Ofcourse, wehavealsomodernized thematerial where appropriate. For
example, when discussing consistency andreplication, wenowfocus oncon-
sistency models thataremoreappropriate formodem distributed systems rather
thantheoriginal models, which weretailored tohigh-performance distributed
computing. Likewise, wehaveadded material onmodem distributed algorithms,
including GPS-based clocksynchronization andlocalization algorithms.
xviixviii PREFACE
Although unusual. wehavenevertheless beenabletoreduce thetotalnumber
ofpages. Thisreduction ispartly caused bydiscarding subjects suchasdistributed
garbage collection andelectronic payment protocols, andalsoreorganizing the
lastfourchapters.
Asintheprevious edition, thebook isdivided intotwoparts. Principles of
distributed systems arediscussed inchapters 2-9,whereas overall approaches to
howdistributed applications should bedeveloped (theparadigms) arediscussed in
chapters 10-13. Unlike theprevious edition, however, wehavedecided nottodis-
cusscomplete casestudies intheparadigm chapters. Instead, each principle is
nowexplained through arepresentative case. Forexample, object invocations are
nowdiscussed asacommunication principle inChap. 10onobject-based distri-
buted systems. Thisapproach allowed ustocondense thematerial, butalsoto
make itmore enjoyable toreadandstudy.
Ofcourse. wecontinue todraw extensively frompractice toexplain what dis-
tributed systems areallabout. Various aspects ofreal-life systems suchasWeb-
Sphere MQ,DNS, GPS, Apache, CORBA, Ice,NFS, Akamai, TIBlRendezvous.
Jini,andmany more arediscussed throughout thebook. These examples illustrate
thethinlinebetween theory andpractice, which makes distributed systems such
anexciting field.
Anumber ofpeople havecontributed tothisbook invarious ways. Wewould
especially liketothank D.Robert Adams, Arno Bakker, Coskun Bayrak, Jacques
Chassin deKergommeaux, Randy Chow, Michel Chaudron, Puneet Singh
Chawla, Fabio Costa, Cong Du,DickEpema, Kevin Fenwick, Chandan aGamage.
AliGhodsi, Giorgio Ingargiola, Mark Jelasity, Ahmed Kamel, Gregory Kapfham-
mer,Jeroen Ketema, Onno Kubbe, Patricia Lago, Steve MacDonald, Michael J.
McCarthy, M.Tamer Ozsu, Guillaume Pierre, AviShahar, Swaminathan Sivasu-
bramanian, Chintan Shah, Ruud Stegers, PaulTymann, Craig E.Wills, Reuven
Yagel, andDakai Zhuforreading parts ofthemanuscript, helping identifying
mistakes intheprevious edition, andoffering useful comments.
Finally, wewould liketothank ourfamilies. Suzanne hasbeen through this
process seventeen times now. That's alotoftimes formebutalsoforher.Not
oncehasshesaid:"Enough isenough" although surely thethought hasoccurred
toher.Thank you. Barbara andMarvin nowhave amuch better ideaofwhat
professors doforaliving andknow thedifference between agood textbook anda
badone. They arenowaninspiration tometotrytoproduce more good ones
thanbadones(AST).
Because Itookasabbatical leave toupdate thebook, thewhole business of
writing wasalsomuch more enjoyable forMarielle, Sheisbeginning togetused
toit,butcontinues toremain supportive while alerting mewhen itisindeed time
toredirect attention tomore important issues. lowe hermany thanks. Max and
Elkebynowhaveamuch better ideaofwhatwriting abook means, butcompared
towhattheyarereading themselves, finditdifficult tounderstand what issoexci-
tingabout thesestrange things called distributed systems. Ican'tblame them (MvS).1
INTRODUCTION
,Computer systems areundergoing arevolution. From 1945,when themodem
c;omputer erabegan, untilabout 1985,computers werelargeandexpensive. Even
minicomputers costatleasttensofthousands ofdollars each. Asaresult, most
organizations hadonlyahandful ofcomputers, andforlackofawaytoconnect
them, theseoperated independently fromoneanother.
Starting around thethemid-1980s, however, twoadvances intechnology
began tochange thatsituation. Thefirstwasthedevelopment ofpowerful micro-
processors. Initially, these were8-bitmachines, butsoon16-,32-,and64-bit
CPUsbecame common. Many ofthesehadthecomputing power ofamainframe
(i.e.,large) computer, butforafraction oftheprice.
Theamount ofimprovement thathasoccurred incomputer technology inthe
pasthalfcentury istrulystaggering andtotally unprecedented inotherindustries.
Fromamachine thatcost10million dollars andexecuted 1instruction persecond.
wehavecome tomachines thatcost1000dollars andareabletoexecute 1billion
instructions persecond, aprice/performance gainof1013.Ifcarshadimproved at
thisrateinthesametimeperiod, aRollsRoyce would nowcost1dollar andgeta
billion miles pergallon. (Unfortunately, itwould probably alsohavea200-page
manual telling howtoopenthedoor.)
Thesecond development wastheinvention ofhigh-speed computer networks.
Local-area networks orLANsallow hundreds ofmachines within abuilding to
beconnected insuchawaythatsmall amounts ofinformation canbetransferred
between machines inafewmicroseconds orso.Larger amounts ofdatacanbe
12 INTRODUCTION CHAP. ]
moved between machines atratesof100million to10billion bits/sec. Wide-area
networks orWANsallow miJIions ofmachines allovertheearthtobeconnected
atspeeds varying from64Kbps(kilobits persecond) togigabits persecond.
Theresult ofthesetechnologies isthatitisnownotonlyfeasible, buteasy,to
puttogether computing systems composed oflargenumbers ofcomputers con-
nected byahigh-speed network. They areusually caned computer networks or
distributed systems, incontrast totheprevious centralized systems (orsingle-
processor systems) consisting ofasingle computer, itsperipherals, andperhaps
someremote terminals.
1.1DEFINITION OFADISTRIBUTED SYSTEM
Various definitions ofdistributed systems havebeengiven intheliterature,
noneofthemsatisfactory, andnoneoftheminagreement withanyoftheothers.
Forourpurposes itissufficient togivealoosecharacterization:
Adistributed system isacollection ofindependent computers that
appears toitsusers asasingle coherent system.
Thisdefinition hasseveral important aspects. Thefirstoneisthatadistributed
system consists ofcomponents (i.e.,computers) thatareautonomous. Asecond
aspect isthatusers(betheypeople orprograms) thinktheyaredealing withasin-
glesystem. Thismeans thatonewayortheothertheautonomous components
needtocollaborate. Howtoestablish thiscollaboration liesattheheartofdevel-
oping distributed systems. Notethatnoassumptions aremadeconcerning thetype
ofcomputers. Inprinciple, evenwithin asingle system, theycould range from
high-performance mainframe computers tosmallnodes insensor networks. Like-
wise,noassumptions aremade onthewaythatcomputers areinterconnected. We
willreturn totheseaspects laterinthischapter.
Instead ofgoing further withdefinitions, itisperhaps moreuseful toconcen-
trateonimportant characteristics ofdistributed systems. Oneimportant charac-
teristic isthatdifferences between thevarious computers andtheways inwhich
theycommunicate aremostly hidden fromusers. Thesameholds fortheinternal
organization ofthedistributed system. Another important characteristic isthat
users andapplications caninteract withadistributed system inaconsistent and
uniform way,regardless ofwhere andwheninteraction takesplace.
Inprinciple, distributed systems should alsoberelatively easytoexpand or
scale. Thischaracteristic isadirect consequence ofhaving independent com-
puters, butatthesametime,hiding howthesecomputers actually takepartinthe
system asawhole. Adistributed system willnormally becontinuously available,
although perhaps somepartsmaybetemporarily outoforder. Users andapplica-
tionsshould notnotice thatpartsarebeing replaced orfixed, orthatnewpartsare
added toservemoreusersorapplications ..SEC. 1.1 DEFINITION OFADISTRIBUTED SYSTEM 3
Inorder tosupport heterogeneous computers andnetworks while offering a
single-system view,distributed systems areoftenorganized bymeans ofalayerof
software-that is,logically placed between ahigher-level layerconsisting ofusers
andapplications, andalayerunderneath consisting ofoperating systems andbasic
communication facilities, asshown inFig.1-1Accordingly, suchadistributed
system issometimes called middleware.
Figure I-I.Adistributed system organized asmiddleware. Themiddleware
layer extends overmultiple machines, andoffers eachapplication thesame in-
terface.
Fig.1-1shows fournetworked computers andthreeapplications, ofwhich ap-
plication Bisdistributed across computers 2and3.Eachapplication isoffered the
sameinterface. Thedistributed system provides themeans forcomponents ofa
single distributed application tocommunicate witheachother, butalsotoletdif-
ferent applications communicate. Atthesametime,ithides, asbestandreason-
ableaspossible, thedifferences inhardware andoperating systems fromeachap-
plication.
1.2GOALS
Justbecause itispossible tobuilddistributed systems doesnotnecessarily
mean thatitisagoodidea.Afterall,withcurrent technology itisalsopossible to
putfourfloppy diskdrives onapersonal computer. Itisjustthatdoing sowould
bepointless. Inthissection wediscuss fourimportant goalsthatshould bemetto
make building adistributed system worth theeffort. Adistributed system should
make resources easily accessible; itshould reasonably hidethefactthatresources
aredistributed across anetwork; itshould beopen;anditshould bescalable.
1.2.1 Making Resources Accessible
Themaingoalofadistributed system istomakeiteasyfortheusers(andap-
plications) toaccess remote resources, andtosharetheminacontrolled andeffi-
cientway.Resources canbejustabout anything, buttypical examples include4 INTRODUCTION CHAP. 1
things likeprinters, computers, storage facilities, data,files,Webpages, andnet-
works, tonamejustafew.There aremanyreasons forwanting toshareresources.
Oneobvious reason isthatofeconomics. Forexample, itischeaper toletaprinter
beshared byseveral usersinasmaJloffice thanhaving tobuyandmaintain asep-
arateprinter foreachuser.Likewise, itmakes economic sense tosharecostly re-
sources suchassupercomputers, high-performance storage systems, imagesetters,
andotherexpensive peripherals.
Connecting users andresources alsomakes iteasier tocollaborate andex-
change information, asisclearly illustrated bythesuccess oftheInternet withits
simple protocols forexchanging files,mail. documents, audio, andvideo. The
connectivity oftheInternet isnowleading tonumerous virtual organizations in
which geographicaJJy widely-dispersed groups ofpeople worktogether bymeans
ofgroupware, thatis,software forcoJJaborative editing, teleconferencing, andso
on.Likewise, theInternet connectivity hasenabled electronic commerce allowing
ustobuyandsellallkinds ofgoods without actually having togotoastoreor
evenleavehome.
However, asconnectivity andsharing increase, security isbecoming increas-
ingly important. Incurrent practice, systems provide littleprotection against
eavesdropping orintrusion oncommunication. Passwords andother sensitive in-
formation areoftensentascJeartext (i.e.,unencrypted) through thenetwork, or
stored atservers thatwecanonlyhopearetrustworthy. Inthissense, thereis
much roomforimprovement. Forexample, itiscurrently possible toordergoods
bymerely supplying acredit cardnumber. Rarely isproofrequired thatthecusto-
merownsthecard.Inthefuture, placing orders thiswaymaybepossible onlyif
youcanactually prove thatyouphysicaJJy possess thecardbyinserting itintoa
cardreader.
Another security problem isthatoftracking communication tobuild upa
preference profile ofaspecific user(Wang etaI.,1998). Suchtracking explicitly
violates privacy, especially ifitisdonewithout notifying theuser.Arelated prob-
lemisthatincreased connectivity canalsoleadtounwanted communication, such
aselectronic junkmail,oftencalled spam. Insuchcases, whatwemayneedisto
protect ourselves using special information filters thatselect incoming messages
based ontheircontent.
1.2.2 Distribution Transparency
Animportant goalofadistributed system istohidethefactthatitsprocesses
andresources arephysically distributed across multiple computers. Adistributed
system thatisabletopresent itselftousersandapplications asifitwereonlya
single computer system issaidtobetransparent. Letusfirsttakealookatwhat
kinds oftransparency existindistributed systems. Afterthatwewilladdress the
moregeneral question whether transparency isalways required.SEC. 1.2 GOALS 5
Types ofTransparency
Theconcept oftransparency canbeapplied toseveral aspects ofadistributed
system, themostimportant onesshown inFig.1-2.
Figure 1-2.Different forms oftransparency inadistributed system (ISO, 1995).
Access transparency dealswithhiding differences indatarepresentation and
thewaythatresources canbeaccessed byusers. Atabasiclevel, wewishtohide
differences inmachine architectures, butmoreimportant isthatwereach agree-
mentonhowdataistoberepresented bydifferent machines andoperating sys-
tems.Forexample, adistributed system mayhavecomputer systems thatrundif-
ferent operating systems, eachhaving theirownfile-naming conventions. Differ-
ences innaming conventions, aswellashowfilescanbemanipulated, should all
behidden fromusersandapplications.
Animportant group oftransparency typeshastodowiththelocation ofare-
source. Location transparency refers tothefactthatuserscannot tellwhere are-
source isphysically located inthesystem. Naming plays animportant rolein
achieving location transparency. Inparticular, location transparency canbe
achieved byassigning onlylogical names toresources, thatis,names inwhich the
location ofaresource isnotsecretly encoded. Anexample ofasuchanameisthe
URLhttp://www.prenhall.com/index.html. which givesnoclueabout thelocation
ofPrentice Hall's mainWebserver. TheURLalsogives noclueastowhether
index.html hasalways beenatitscurrent location orwasrecently moved there.
Distributed systems inwhich resources canbemoved without affecting howthose
resources canbeaccessed aresaidtoprovide migration transparency. Even
stronger isthesituation inwhich resources canberelocated while theyarebeing
accessed without theuserorapplication noticing anything. Insuchcases, thesys-
temissaidtosupport relocation transparency. Anexample ofrelocation trans-
parency iswhen mobile users cancontinue tousetheirwireless laptops while
moving fromplacetoplacewithout everbeing (temporarily) disconnected.
Asweshallsee,replication playsaveryimportant roleindistributed systems.
Forexample, resources maybereplicated toincrease availability ortoimprove6 INTRODUCTION CHAP. 1
performance byplacing acopyclose totheplace where itisaccessed. Replica-
tiontransparency deals withhiding thefactthatseveral copies ofaresource
exist.Tohidereplication fromusers, itisnecessary thatallreplicas havethesame
name. Consequently, asystem thatsupports replication transparency should gen-
erally support location transparency aswell,because itwould otherwise beimpos-
sibletorefertoreplicas atdifferent locations.
Wealready mentioned thatanimportant goalofdistributed systems istoal-
lowsharing ofresources. Inmany cases, sharing resources isdoneinacoopera-
tiveway,asinthecaseofcommunication. However. therearealsomany ex-
amples ofcompetitive sharing ofresources. Forexample, twoindependent users
mayeachhavestored theirfilesonthesamefileserver ormaybeaccessing the
sametables inashared database. Insuchcases, itisimportant thateachuserdoes
notnotice thattheotherismaking useofthesameresource. Thisphenomenon is
called concurrency transparency. Animportant issueisthatconcurrent access
toashared resource leaves thatresource inaconsistent state.Consistency canbe
achieved through locking mechanisms, bywhich users are,inturn,given ex-
clusive access tothedesired resource. Amorerefined mechanism istomake use
oftransactions, butasweshallseeinlaterchapters, transactions arequitedifficult
toimplement indistributed systems.
Apopular alternative definition ofadistributed system, duetoLeslie Lam-
port,is"You know youhaveonewhen thecrash ofacomputer you've never
heard ofstopsyoufromgetting anyworkdone." Thisdescription putsthefinger
onanother important issueofdistributed systems design: dealing withfailures.
Making adistributed system failure transparent means thatauserdoesnotno-
ticethataresource (hehaspossibly never heard of)failstoworkproperly, and
thatthesystem subsequently recovers fromthatfailure. Masking failures isoneof
thehardest issues indistributed systems andisevenimpossible when certain
apparently realistic assumptions aremade, aswewilldiscuss inChap. 8.The
maindifficulty inmasking failures liesintheinability todistinguish between a
deadresource andapainfully slowresource. Forexample, whencontacting abusy
Webserver, abrowser willeventually timeoutandreport thattheWebpageis
unavailable ..Atthatpoint, theusercannot conclude thattheserver isreally down.
Degree ofTransparency
Although distribution transparency isgenerally considered preferable forany
distributed system, therearesituations inwhich attempting tocompletely hideall
distribution aspects fromusersisnotagoodidea.Anexample isrequesting your
electronic newspaper toappear inyourmailbox before 7A.M. localtime,asusual,
while youarecurrently attheother endoftheworld living inadifferent time
zone.Yourmorning paper willnotbethemorning paper youareusedto.
Likewise, awide-area distributed system thatconnects aprocess inSanFran-
ciscotoaprocess inAmsterdam cannot beexpected tohidethefactthatMotherSEC. 1.2 GOALS 7
Nature willnotallow ittosendamessage fromoneprocess totheotherinless
thanabout 35milliseconds. Inpractice ittakesseveral hundreds ofmilliseconds
usingacomputer network. Signal transmission isnotonlylimited bythespeed of
light.butalsobylimited processing capacities oftheintermediate switches.
There isalsoatrade-off between ahighdegree oftransparency andtheper-
formance ofasystem. Forexample, many Internet applications repeatedly tryto
contact aserver before finally giving up.Consequently, attempting tomaskatran-
sientserver failure before trying another onemayslowdown thesystem asa
whole. Insuchacase,itmayhavebeenbetter togiveupearlier, oratleastletthe
usercancel theattempts tomake contact
Another example iswhere weneedtoguarantee thatseveral replicas, located
ondifferent continents, needtobeconsistent allthetime.Inotherwords, ifone
copyischanged, thatchange should bepropagated toallcopies before allowing
anyotheroperation. Itisclearthatasingle update operation maynoweventake
seconds tocomplete, something thatcannot behidden fromusers.
Finally, therearesituations inwhich itisnotatallobvious thathiding distri-
bution isagoodidea.Asdistributed systems areexpanding todevices thatpeople
carry around, andwhere theverynotion oflocation andcontext awareness is
becoming increasingly important, itmaybebesttoactually expose distribution
rather thantrying tohideit.Thisdistribution exposure willbecome moreevident
whenwediscuss embedded andubiquitous distributed systems laterinthischap-
ter.Asasimple example, consider anoffice worker whowants toprintafilefrom
hernotebook computer. Itisbetter tosendtheprintjobtoabusynearby printer,
rather thantoanidleoneatcorporate headquarters inadifferent country.
There arealsootherarguments against distribution transparency. Recognizing
thatfulldistribution transparency issimply impossible, weshould askourselves
whether itisevenwisetopretend thatwecanachieve it.Itmaybemuch better to
make distribution explicit sothattheuserandapplication developer arenever
tricked intobelieving thatthereissuchathingastransparency. Theresult willbe
thatuserswillmuch better understand the(sometimes unexpected) behavior ofa
distributed system, andarethusmuch better prepared todealwiththisbehavior.
Theconclusion isthataiming fordistribution transparency maybeanicegoal
whendesigning andimplementing distributed systems, butthatitshould becon-
sidered together withother issues suchasperformance andcomprehensibility.
Thepricefornotbeingabletoachieve fulltransparency maybesurprisingly high.
1.2.3Openness
Another important goalofdistributed systems isopenness. Anopendistrib-
utedsystem isasystem thatoffers services according tostandard rulesthat
describe thesyntax andsemantics ofthose services. Forexample, incomputer
networks, standard rulesgovern theformat, contents, andmeaning ofmessages
sentandreceived. Suchrulesareformalized inprotocols. Indistributed systems,8 INTRODUCTION CHAP.]
services aregenerally specified through interfaces, which areoftendescribed in
anInterface Definition Language (IDL). Interface definitions written inanIDL
nearly always capture onlythesyntax ofservices. Inotherwords, theyspecify
precisely thenames ofthefunctions thatareavailable together withtypes ofthe
parameters, return values, possible exceptions thatcanberaised, andsoon.The
hardpartisspecifying precisely whatthose services do,thatis,thesemantics of
interfaces. Inpractice, suchspecifications arealways giveninaninformal wayby
means ofnatural language.
Ifproperly specified, aninterface definition allows anarbitrary process that
needs acertain interface totalktoanother process thatprovides thatinterface. It
alsoallows twoindependent parties tobuildcompletely different implementations
ofthose interfaces, leading totwoseparate distributed systems thatoperate in
exactly thesameway.Proper specifications arecomplete andneutral. Complete
means thateverything thatisnecessary tomake animplementation hasindeed
beenspecified. However, many interface definitions arenotatallcomplete. so
thatitisnecessary foradeveloper toaddimplementation-specific details. Justas
important isthefactthatspecifications donotprescribe whatanimplementation
should looklike:theyshould beneutral. Completeness andneutrality areimpor-
tantforinteroperability andportability (Blair andStefani, 1998). Interoperabil-
itycharacterizes theextent bywhich twoimplementations ofsystems orcom-
ponents fromdifferent manufacturers canco-exist andworktogether bymerely
relying oneachother's services asspecified byacommon standard. Portability
characterizes towhatextent anapplication developed foradistributed system A
canbeexecuted. without modification, onadifferent distributed system Bthat
implements thesameinterfaces asA.
Another important goalforanopendistributed system isthatitshould beeasy
toconfigure thesystem outofdifferent components (possibly fromdifferent de-
velopers). Also,itshould beeasytoaddnewcomponents orreplace existing ones
without affecting thosecomponents thatstayinplace. Inotherwords, anopendis-
tributed system should alsobeextensible. Forexample, inanextensible system,
itshould berelatively easytoaddpartsthatrunonadifferent operating system. or
eventoreplace anentire filesystem. Asmany ofusknow fromdailypractice,
attaining suchflexibility iseasier saidthandone.
Separating Policy fromMechanism
Toachieve flexibility inopendistributed systems, itiscrucial thatthesystem
isorganized asacollection ofrelatively smallandeasily replaceable oradaptable
components. Thisimplies thatweshould provide definitions notonlyforthe
highest-level interfaces, thatis,those seen"byusers andapplications, butalso
definitions forinterfaces tointernal partspJthesystem anddescribe howthose
partsinteract. Thisapproach isrelatively new.Many olderandevencontemporary
systems areconstructed using amonolithic approach inwhich components areSEC. 1.2 GOALS 9
onlylogically separated butimplemented asone.hugeprogram. Thisapproach
makes ithardtoreplace oradapt acomponent without affecting theentire system.
Monolithic systems thustendtobeclosed instead ofopen.
Theneedforchanging adistributed system isoftencaused byacomponent
thatdoesnotprovide theoptimal policy foraspecific userorapplication. Asan
example, consider caching intheWorIdWide Web. Browsers generally allow
userstoadapttheircaching policy byspecifying thesizeofthecache, andwheth-
eracached document should always bechecked forconsistency, orperhaps only
oncepersession. However, theusercannot influence othercaching parameters,
suchashowlongadocument mayremain inthecache, orwhich document should
beremoved whenthecache fillsup.Also,itisimpossible tomake caching deci-
sionsbased onthecontent ofadocument. Forinstance, ausermaywanttocache
railroad timetables, knowing thatthesehardly change, butnever information on
current traffic conditions onthehighways.
What weneedisaseparation between policy andmechanism. Inthecaseof
Webcaching, forexample, abrowser should ideally provide facilities foronly
storing documents, andatthesametimeallow userstodecide which documents
arestored andforhowlong.Inpractice, thiscanbeimplemented byoffering a
richsetofparameters thattheusercanset(dynamically). Evenbetter isthata
usercanimplement hisownpolicy intheformofacomponent thatcanbe
plugged intothebrowser. Ofcourse, thatcomponent musthaveaninterface that
thebrowser canunderstand sothatitcancallprocedures ofthatinterface.
1.2.4Scalability
Worldwide connectivity through theInternet israpidly becoming ascommon
asbeing abletosendapostcard toanyone anywhere around theworld. Withthis
inmind, scalability isoneofthemostimportant design goals fordevelopers of
distributed systems.
Scalability ofasystem canbemeasured along atleastthreedifferent dimen-
sions(Neuman, 1994). First, asystem canbescalable withrespect toitssize,
meaning thatwecaneasily addmoreusersandresources tothesystem. Second, a
geographically scalable system isoneinwhich theusersandresources mayliefar
apart. Third, asystem canbeadministratively scalable, /~~aning thatitcanstillbe
easytomanage evenifitspans many independent administrative organizations.
Unfortunately, asystem thatisscalable inoneormoreofthesedimensions often
exhibits somelossofperformance asthesystem scales up.
Scalability Problems
When asystem needs toscale, verydifferent typesofproblems needtobe
solved.Letusfirstconsider scaling withrespect tosize.Ifmoreusersorresources
needtobesupported, weareoftenconfronted withthelimitations ofcentralized10 INTRODUCTION CHAP. 1
services, data,andalgorithms (seeFig.1-3).Forexample, many services arecen-
tralized inthesense thattheyareimplemented bymeans ofonlyasingle server
running onaspecific machine inthedistributed system. Theproblem withthis
scheme isobvious: theserver canbecome abottleneck asthenumber ofusersand
applications grows. Evenifwehavevirtually unlimited processing andstorage ca-
pacity, communication withthatserver willeventually prohibit further growth.
Unfortunately. using onlyasingle server issometimes unavoidable. Imagine
thatwehaveaservice formanaging highly confidential information suchasmedi-
calrecords, bankaccounts. andsoon.Insuchcases, itmaybebesttoimplement
thatservice bymeans ofasingle server inahighly secured separate room, and
protected fromotherpartsofthedistributed system through special network com-
ponents. Copying theserver toseveral locations toenhance performance maybe
outofthequestion asitwould maketheservice lesssecure.
Figure 1-3.Examples ofscalability limitations.
Justasbadascentralized services arecentralized data.Howshould wekeep
trackofthetelephone numbers andaddresses of50million people? Suppose that
eachdatarecord could befitinto50characters. Asingle 2.5-gigabyte diskparti-
tionwould provide enough storage. Buthereagain, having asingle database
would undoubtedly saturate allthecommunication linesintoandoutofit.Like-
wise, imagine howtheInternet would workifitsDomain Name System (DNS)
wasstillimplemented asasingle table. DNSmaintains information onmillions of
computers worldwide andforms anessential service forlocating Webservers. If
eachrequest toresolve aURLhadtobeforwarded tothatoneandonlyDNS
server, itisdearthatnoonewould beusing theWeb(which, bytheway,would
solvetheproblem).
Finally, centralized algorithms arealsoabadidea.Inalargedistributed sys-
tem,anenormous number ofmessages havetoberouted overmany lines. From a
theoretical pointofview, theoptimal waytodothisiscollect complete informa-
tionabout theloadonallmachines andlines, andthenrunanalgorithm tocom-
putealltheoptimal routes. Thisinformation canthenbespread around thesystem
toimprove therouting.
.Thetrouble isthatcollecting andtransporting alltheinputandoutput infor-
mation would againbeabadideabecause thesemessages would overload partof
thenetwork. Infact,anyalgorithm thatoperates bycollecting information from
allthesites,sends ittoasingle machine forprocessing, andthendistributes theSEC. 1.2 GOALS 11
results should generally beavoided. Only decentralized algorithms should be
used.These algorithms generally havethefollowing characteristics, which distin-
zuishthemfromcentralized algorithms:e
1.Nomachine hascomplete information aboutthesystem state.
2.Machines makedecisions based onlyonlocalinformation,
3.Failure ofonemachine doesnotruinthealgorithm.
4.There isnoimplicit assumption thataglobal clockexists.
Thefirstthreefollow fromwhatwehavesaidsofar.Thelastisperhaps lessobvi-
ousbutalsoimportant. Anyalgorithm thatstartsoutwith:"Atprecisely 12:00:00
allmachines shallnotethesizeoftheiroutput queue" willfailbecause itis
impossible togetalltheclocks exactly synchronized. Algorithms should takeinto
account thelackofexactclock synchronization. Thelarger thesystem, thelarger
theuncertainty. Onasingle LAN, withconsiderable effort itmaybepossible to
getallclocks synchronized down toafewmicroseconds, butdoing thisnationally
orinternationally istricky.
Geographical scalability hasitsownproblems. Oneofthemainreasons why
itiscurrently hardtoscaleexisting distributed systems thatweredesigned for
local-area networks isthattheyarebased onsynchronous communication. In
thisformofcommunication, apartyrequesting service, generally referred toasa
client, blocks untilareplyissentback. Thisapproach generally works finein
LANs where communication between twomachines isgenerally atworst afew
hundred microseconds. However, inawide-area system, weneedtotakeintoac-
count thatinterprocess communication maybehundreds ofmilliseconds, three
orders ofmagnitude slower. Building interactive applications using synchronous
communication inwide-area systems requires agreatdealofcare(andnotalittle
patience).
Another problem thathinders geographical scalability isthatcommunication
inwide-area networks isinherently unreliable, andvirtually always point-to-point.
Incontrast, local-area networks generally provide highly reliable communication
facilities based onbroadcasting, making itmuch easier todevelop distributed sys-
tems.Forexample, consider theproblem oflocating aservice. Inalocal-area sys-
tem,aprocess cansimply broadcast amessage toeve\)' machine, asking ifitis
running theservice itneeds. Onlythosemachines thatHavethatservice respond,
eachproviding itsnetwork address inthereplymessage. Suchalocation scheme
isunthinkable inawide-area system: justimagine whatwould happen ifwetried
tolocate aservice thiswayintheInternet. Instead, special location services need
tobedesigned, which mayneedtoscaleworldwide andbecapable ofservicing a
billion users. Wereturn tosuchservices inChap. 5.
Geographical scalability isstrongly related totheproblems ofcentralized
solutions thathinder sizescalability. Ifwehaveasystem withmany centralized12 INTRODUCTION CHAP. 1
components, itisclear thatgeographical scalability willbelimited duetotheper-
formance andreliability problems resulting fromwide-area communication. Inad-
dition, centralized components nowleadtoawaste ofnetwork resources. Imagine
thatasingle mailserver isusedforanentire country. Thiswould mean thatsend-
ingane-mail toyourneighbor would firsthavetogotothecentral mailserver,
which maybehundreds ofmiles away. Clearly, thisisnotthewaytogo.
Finally, adifficult, andinmany cases openquestion ishowtoscale adistrib-
utedsystem across multiple, independent administrative domains. Amajor prob-
lemthatneeds tobesolved isthatofconflicting policies withrespect toresource
usage (andpayment), management, andsecurity.
Forexample, many components ofadistributed system thatreside within a
single domain canoften betrusted byusers thatoperate within thatsame domain.
Insuchcases, system administration mayhave tested andcertified applications,
andmayhavetaken special measures toensure thatsuchcomponents cannot be
tampered with. Inessence, theusers trusttheirsystem administrators. However,
thistrustdoesnotexpand naturally across domain boundaries.
Ifadistributed system expands intoanother domain, twotypes ofsecurity
measures needtobetaken. Firstofall,thedistributed system hastoprotect itself
against malicious attacks fromthenewdomain. Forexample, users from thenew
domain mayhaveonlyreadaccess tothefilesystem initsoriginal domain. Like-
wise, facilities suchasexpensive image setters orhigh-performance computers
maynotbemade available toforeign users. Second, thenewdomain hastopro-
tectitself against malicious attacks fromthedistributed system. Atypical example
isthatofdownloading programs suchasapplets inWebbrowsers. Basically, the
newdomain doesnotknow behavior what toexpect fromsuchforeign code, and
maytherefore decide toseverely limittheaccess rights forsuchcode. Theprob-
lem,asweshallseeinChap. 9,ishowtoenforce those limitations.
Scaling Techniques
Having discussed some ofthescalability problems brings ustothequestion of
howthose problems cangenerally besolved. Inmostcases, scalability problems
indistributed systems appear asperformance problems caused bylimited capacity
ofservers andnetwork. There arenowbasically onlythreetechniques forscaling:
hiding communication latencies, distribution, andreplication [seealsoNeuman
(1994) ]. ~___
Hiding communication latencies isimportant toachieve geographical scala-
bility. Thebasic ideaissimple: trytoavoid waiting forresponses toremote (and
potentially distant) service requests asmuch aspossible. Forexample, when aser-
vicehasbeenrequested ataremote machine, analternative towaiting forareply
fromtheserver istodoother useful work attherequester's side.Essentially, what
thismeans isconstructing therequesting application insuchawaythatituses
onlyasynchronous communication. When areply comes in,theapplication isSEC. 1.2 GOALS 13
interrupted andaspecial handler iscalled tocomplete thepreviously-issued re-
quest. Asynchronous communication canoftenbeusedinbatch-processing sys-
temsandparallel applications, inwhich moreorlessindependent taskscanbe
scheduled forexecution while another taskiswaiting forcommunication tocom-
plete. Alternatively, anewthread ofcontrol canbestarted toperforrnthe request.
Although itblocks waiting forthereply, otherthreads intheprocess cancontinue.
However, therearemany applications thatcannot makeeffective useofasyn-
chronous communication. Forexample, ininteractive applications when auser
sends arequest hewillgenerally havenothing better todothantowaitforthe
answer. Insuchcases, amuchbetter solution istoreduce theoverall communica-
tion,forexample, bymoving partofthecomputation thatisnormally doneatthe
server totheclient process requesting theservice. Atypical casewhere thisap-
proach works isaccessing databases using forms. Filling informs canbedoneby
sending aseparate message foreachfield, andwaiting foranacknowledgment
fromtheserver, asshown inFig.1-4(a). Forexample, theserver maycheck for
syntactic errors before accepting anentry. Amuch better solution istoshipthe
codeforfilling intheform, andpossibly checking theentries, totheclient, and
havetheclient return acompleted form, asshown inFig.1-4(b). Thisapproach
ofshipping codeisnowwidely supported bytheWebintheformofJavaapplets
andJavascript.
Figure 1-4.Thedifference between letting (a)aserver or(b)aclient check
forms astheyarebeing filled.
Another important scaling technique isdistribution. Distribution involves
taking acomponent, splitting itintosmaller parts, andsubsequently spreading14 INTRODUCTION CHAP. 1
thosepartsacross thesystem. Anexcellent example ofdistribution istheInternet
Domain Name System (DNS). TheDNSname space ishierarchically organized
intoatreeofdomains, which aredivided intononoverlapping zones,asshown in
Fig.1-5.Thenames ineachzonearehandled byasingle name server. Without
going intotoomany details, onecanthinkofeachpathname, being thename ofa
hostintheInternet, andthusassociated withanetwork address ofthathost.Basi-
cally, resolving aname means returning thenetwork address oftheassociated
host.Consider, forexample, thename nl.vu.cs.flits. Toresolve thisname, itis
firstpassed totheserver ofzone21(seeFig.1-5)which returns theaddress ofthe
server forzone22,towhich therestofname, vu.cs.flits, canbehanded. The
server for22willreturn theaddress oftheserver forzone23,which iscapable of
handling thelastpartofthename andwillreturn theaddress oftheassociated
host.
Figure 1-5.Anexample ofdividing theDNSname space intozones.
Thisexample illustrates howthenaming service, asprovided byDNS, isdis-
tributed across several machines, thusavoiding thatasingle server hastodeal
withallrequests fornameresolution.
Asanother example, consider theWorld Wide Web. Tomostusers, theWeb
appears tobeanenormous document-based information system inwhich each
document hasitsownunique name intheformofaURL. Conceptually, itmay
evenappear asifthereisonlyasingle server. However, theWebisphysically
distributed across alargenumber ofservers, eachhandling anumber ofWebdoc-
uments. Thename oftheserver handling adocument isencoded intothatdocu-
ment's URL. Itisonlybecause ofthisdistribution ofdocuments thattheWebhas
beencapable ofscaling toitscurrent size.
Considering thatscalability problems oftenappear intheformofperformance
degradation, itisgenerally agoodideatoactually replicate components across aSEC. 1.2 GOALS 15
distributed system. Replication notonlyincreases availability, butalsohelps to
balance theloadbetween components leading tobetter performance. Also, ingeo-
!!I1lphically widely-dispersed systems, having acopynearby canhidemuch ofthe
~omrnunication latency problems mentioned before.
Caching isaspecial formofreplication, although thedistinction between the
twoisoften hardtomake orevenartificial. Asinthecaseofreplication, caching
results inmaking acopyofaresource, generally intheproximity oftheclient ac-
cessing thatresource. However, incontrast toreplication, caching isadecision
made bytheclient ofaresource, andnotbytheowner ofaresource. Also, cach-
inghappens ondemand whereas replication isoften planned inadvance.
There isoneserious drawback tocaching andreplication thatmayadversely
affect scalability. Because wenowhavemultiple copies ofaresource, modifying
onecopy makes thatcopy different from theothers. Consequently, caching and
replication leads toconsistency problems.
Towhat extent inconsistencies canbetolerated depends highly ontheusage
ofaresource. Forexample, many Webusers fmditacceptable thattheirbrowser
returns acached document ofwhich thevalidity hasnotbeenchecked forthelast
fewminutes. However, there arealsomany cases inwhich strong consistency
guarantees needtobemet,suchasinthecaseofelectronic stock exchanges and
auctions. Theproblem withstrong consistency isthatanupdate mustbeimmedi-
ately propagated toallother copies. Moreover, iftwoupdates happen concur-
rently, itisoften alsorequired thateachcopyisupdated inthesame order. Situa-
tions such asthese generally require some global synchronization mechanism.
Unfortunately, suchmechanisms areextremely hardorevenimpossible toimple-
ment inascalable way,assheinsists thatphotons andelectrical signals obey a
speed limitof187miles/msec (thespeed oflight). Consequently, scaling byrepli-
cation mayintroduce other, inherently nonscalable solutions. Wereturn toreplica-
tionandconsistency inChap. 7.
When considering these scaling techniques, onecould argue thatsizescalabil-
ityistheleastproblematic fromatechnical point ofview. Inmany cases, simply
increasing thecapacity ofamachine willthesavetheday(atleasttemporarily
andperhaps atsignificant costs). Geographical scalability isamuch tougher prob-
lemasMother Nature isgetting inourway. Nevertheless, practice shows that
combining distribution, replication, andcaching techniques withdifferent forms
ofconsistency willoften prove sufficient inmany cases. Finally, administrative
scalability seems tobethemostdifficult one,rartly alsobecause weneedtosolve
nontechnical problems (e.g., politics oforganizations andhuman collaboration).
Nevertheless, progress hasbeenmade inthisarea,bysimply ignoring administra-
tivedomains. Theintroduction andnowwidespread useofpeer-to-peer technol-
ogydemonstrates what canbeachieved ifendusers simply takeovercontrol
(Aberer andHauswirth, 2005; Luaetal.,2005; andOram, 2001). However, letit
beclear thatpeer-to-peer technology canatbestbeonlyapartial solution tosolv-
ingadministrative scalability. Eventually, itwillhavetobedealtwith.16CHAP. 1
1.2.5Pitfalls
Itshould beclearbynowthatdeveloping distributed systems canbeaformid-
abletask.Aswewillseemany times throughout thisbook, there aresomany
issues toconsider atthesametimethatitseems thatonlycomplexity canbethe
result. Nevertheless, byfollowing anumber ofdesign principles, distributed sys-
temscanbedeveloped thatstrongly adhere tothegoalswesetoutinthischapter.
Many principles follow thebasicrulesofdecent software engineering andwiJInot
berepeated here.
However, distributed systems differ fromtraditional software because com-
ponents aredispersed across anetwork. Nottaking thisdispersion intoaccount
during design timeiswhatmakes somany systems needlessly complex andre-
sultsinmistakes thatneedtobepatched lateron.Peter Deutsch, thenatSun
Microsystems, formulated thesemistakes asthefollowing falseassumptions that
everyone makes whendeveloping adistributed application forthefirsttime:
1.Thenetwork isreliable.
2.Thenetwork issecure.
3.Thenetwork ishomogeneous.
4.Thetopology doesnotchange.
5.Latency iszero.
6.Bandwidth isinfinite.
7.Transport costiszero.
8.There isoneadministrator.
Notehowtheseassumptions relate toproperties thatareunique todistributed sys-
tems:reliability, security, heterogeneity, andtopology ofthenetwork; latency and
bandwidth; transport costs; andfinally administrative domains. When developing
nondistributed applications, many oftheseissues willmostlikely notshowup.
Most oftheprinciples wediscuss inthisbookrelate immediately tothese
assumptions. Inallcases, wewillbediscussing solutions toproblems, thatare
caused bythefactthatoneormoreassumptions arefalse. Forexample, reliable
networks simply donotexist, leading totheimpossibility ofachieving failure
transparency. Wedevote anentire chapter todealwiththefactthatnetworked
communication isinherently insecure. Wehavealready argued thatdistributed
systems needtotakeheterogeneity intoaccount. Inasimilar vein,when discuss-
ingreplication forsolving scalability problems, weareessentially tackling latency
andbandwidth problems. Wewillalsotouch uponmanagement issues atvarious
points throughout thisbook, dealing withthefalseassumptions ofzero-cost tran-
sportation andasingle administrative domain.;'\';";-L:':'~
INTRODUCTIONSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 17
1.3TYPES OFDISTRIBUTED SYSTEMS
Before starting todiscuss theprinciples ofdistributed systems, letusfirsttake
acloser lookatthevarious typesofdistributed systems. Inthefollowing wemake
adistinction between distributed computing systems, distributed information sys-
tems,anddistributed embedded systems.
1.3.1Distributed Computing Systems
Animportant classofdistributed systems istheoneusedforhigh-perfor-
mance computing tasks. Roughly speaking, onecanmake adistinction between
twosubgroups. Incluster computing theunderlying hardware consists ofacol-
lection ofsimilar workstations orPCs,closely connected bymeans ofahigh-
speedlocal-area network. Inaddition, eachnoderunsthesameoperating system.
Thesituation becomes quitedifferent inthecaseofgridcomputing. This
subgroup consists ofdistributed systems thatareoftenconstructed asafederation
ofcomputer systems, where eachsystem mayfallunder adifferent administrative
domain, andmaybeverydifferent when itcomes tohardware, software, and
deployed network technology.
Cluster Computing Systems
Cluster computing systems became popular whentheprice/performance ratio
ofpersonal computers andworkstations improved. Atacertain point, itbecame
financially andtechnically attractive tobuildasupercomputer usingoff-the-shelf
technology bysimply hooking upacollection ofrelatively simple computers ina
high-speed network. Invirtually allcases, cluster computing isusedforparallel
programming inwhich asingle (compute intensive) program isruninparallel on
multiple machines.
Figure 1-6.Anexample ofacluster computing system.18 INTRODUCTION CHAP.]
Onewell-known example ofacluster computer isformed byLinux-based
Beowulf clusters, ofwhich thegeneral configuration isshown inFig.1-6.Each
cluster consists ofacollection ofcompute nodes thatarecontrolled andaccessed
bymeans ofasingle master node. Themaster typically handles theallocation of
nodes toaparticular parallel program, maintains abatchqueue ofsubmitted jobs,
andprovides aninterface fortheusersofthesystem. Assuch,themaster actually
runsthemiddleware needed fortheexecution ofprograms andmanagement ofthe
cluster, while thecompute nodes oftenneednothing elsebutastandard operating
system.
Animportant partofthismiddleware isformed bythelibraries forexecuting
parallel programs. Aswewilldiscuss inChap. 4,many ofthese libraries effec-
tively provide onlyadvanced message-based communication facilities, butarenot
capable ofhandling faulty processes, security, etc.
Asanalternative tothishierarchical organization, asymmetric approach is
followed intheMOSIX system (Amar etat,2004). MOSIX attempts toprovide
asingle-system image ofacluster, meaning thattoaprocess acluster computer
offers theultimate distribution transparency byappearing tobeasingle computer.
Aswementioned, providing suchanimage under allcircumstances isimpossible.
InthecaseofMOSIX, thehighdegree oftransparency isprovided byallowing
processes todynamically andpreemptively migrate between thenodes thatmake
upthecluster. Process migration allows ausertostartanapplication onanynode
(referred toasthehome node), afterwhich itcantransparently move toother
nodes, forexample, tomake efficient useofresources. Wewillreturn toprocess
migration inChap. 3.
GridComputing Systems
Acharacteristic feature ofcluster computing isitshomogeneity. Inmost
cases, thecomputers inacluster arelargely thesame, theyallhavethesameoper-
atingsystem, andareallconnected through thesamenetwork. Incontrast, grid
computing systems haveahighdegree ofheterogeneity: noassumptions aremade
concerning hardware, operating systems, networks, administrative domains, secu-
ritypolicies, etc.
Akeyissueinagridcomputing system isthatresources fromdifferent organ-
izations arebrought together toallow thecollaboration ofagroup ofpeople or
institutions. Suchacollaboration isrealized intheformofavirtual organization.
Thepeople belonging tothesamevirtual organization haveaccess rights tothere-
sources thatareprovided tothatorganization. Typically, resources consist of
compute servers (including supercomputers, possibly implemented ascluster com-
puters), storage facilities, anddatabases. Inaddition, special networked devices
suchastelescopes, sensors, etc.,canbeprovided aswell.
Given itsnature, much ofthesoftware forrealizing gridcomputing evolves
around providing access toresources fromdifferent administrative domains, andSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 19
toonlythoseusersandapplications thatbelong toaspecific virtual organization.
Forthisreason, focus isoftenonarchitectural issues. Anarchitecture proposed by
Foster etal.(2001). isshown inFig.1-7
Figure 1-7.Alayered architecture forgridcomputing systems.
Thearchitecture consists offourlayers. Thelowest fabric layerprovides in-
terfaces tolocalresources ataspecific site.Notethattheseinterfaces aretailored
toallow sharing ofresources within avirtual organization. Typically, theywill
provide functions forquerying thestateandcapabilities ofaresource, along with
functions foractual resource management (e.g.,locking resources).
Theconnectivity layer consists ofcommunication protocols forsupporting
gridtransactions thatspantheusage ofmultiple resources. Forexample, protocols
areneeded totransfer databetween resources, ortosimply access aresource from
aremote location. Inaddition, theconnectivity layerwillcontain security proto-
colstoauthenticate usersandresources. Notethatinmany caseshuman usersare
notauthenticated; instead, programs acting onbehalf oftheusers areauthenti-
cated. Inthissense, delegating rights fromausertoprograms isanimportant
function thatneeds tobesupported intheconnectivity layer. Wereturn exten-
sively todelegation whendiscussing security indistributed systems.
Theresource layerisresponsible formanaging asingle resource. Itusesthe
functions provided bytheconnectivity layerandcallsdirectly theinterfaces made
available bythefabric layer. Forexample, thislayer willofferfunctions for
obtaining configuration information onaspecific resource, or,ingeneral, toper-
formspecific operations suchascreating aprocess orreading data.Theresource
layeristhusseentoberesponsible foraccess control, andhence willrelyonthe
authentication performed aspartoftheconnectivity layer.
Thenextlayerinthehierarchy isthecollective layer. Itdealswithhandling
access tomultiple resources andtypically consists ofservices forresource
discovery, allocation andscheduling oftasksontomultiple resources, datarepli-
cation, andsoon.Unlike theconnectivity andresource layer, which consist ofa
relatively small, standard collection ofprotocols, thecollective layermayconsist
ofmanydifferent protocols formanydifferent purposes, reflecting thebroad spec-
trumofservices itmayoffertoavirtual organization.20 INTRODUCTION CHAP. ]
Finally, theapplication layer consists oftheapplications thatoperate within a
virtual organization andwhich makeuseofthegridcomputing environment.
Typically thecollective, connectivity, andresource layerformtheheart of
whatcould becalled agridmiddleware layer. These layers jointly provide access
toandmanagement ofresources thatarepotentially dispersed across multiple
sites.Animportant observation fromamiddleware perspective isthatwithgrid
computing thenotion ofasite(oradministrative unit)iscommon. Thisprevalence
isemphasized bythegradual shifttoward aservice-oriented architecture in
which sitesofferaccess tothevarious layers through acollection ofVv'ebservices
(Joseph etal..2004). This,bynow,hasledtothedefinition ofanalternative ar-
chitecture known astheOpen GridServices Architecture (OGSA). Thisarchi-
tecture consists ofvarious layers andmany components, making itrather com-
plex.Complexity seems tobethefateofanystandardization process. Details on
OGSA canbefound inFoster etal.(2005).
1.3.2 Distributed Information Systems
Another important classofdistributed systems isfound inorganizations that
wereconfronted withawealth ofnetworked applications, butforwhich interoper-
ability turned outtobeapainful experience. Many oftheexisting middleware
solutions aretheresult ofworking withaninfrastructure inwhich itwaseasier to
integrate applications intoanenterprise-wide information system (Bernstein,
1996;andAlonso etal.,2004).
Wecandistinguish several levels atwhich integration tookplace. Inmany
cases, anetworked application simply consisted ofaserver running thatapplica-
tion(often including adatabase) andmaking itavailable toremote programs, call-
edclients. Suchclients could sendarequest totheserver forexecuting aspecific
operation, afterwhich aresponse would besentback. Integration atthelowest
levelwould allowclients towrapanumber ofrequests, possibly fordifferent ser-
vers,intoasingle larger request andhaveitexecuted asadistributed transac-
tion.Thekeyideawasthatall,ornoneoftherequests would beexecuted.
Asapplications became moresophisticated andweregradually separated into
independent components (notably distinguishing database components fromproc-
essing components), itbecame clearthatintegration should alsotakeplace bylet-
tingapplications communicate directly witheachother. Thishasnowledtoa
hugeindustry thatconcentrates onenterprise application integration (EAl). In
thefollowing, weconcentrate onthesetwoforms ofdistributed systems.
Transaction Processing Systems
Toclarify ourdiscussion, letusconcentrate ondatabase applications. Inprac-
tice,operations onadatabase areusually carried outintheformoftransactions.
Programming using transactions requires special primitives thatmusteither beSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 21
supplied bytheunderlying distributed system orbythelanguage runtime system.
Typical examples oftransaction primitives areshown inFig.1-8.Theexactlist
ofprimitives depends onwhatkinds ofobjects arebeing usedinthetransaction
(Gray andReuter, 1993). Inamailsystem, theremight beprimitives tosend,
receive, andforward mail.Inanaccounting system, theymight bequitedifferent.
READ andWRITE aretypical examples, however. Ordinary statements, procedure
calls, andsoon,arealsoallowed inside atransaction. Inparticular, wemention
thatremote procedure calls(RPCs), thatis,procedure callstoremote servers, are
often alsoencapsulated inatransaction, leading towhatisknown asatran-
sactional RPC. Wediscuss RPCs extensively inChap. 4.
Figure 1-8.Example primitives fortransactions.
BEGIN_ TRANSACTION andEND_TRANSACTION areusedtodelimit the
scope ofatransaction. Theoperations between themformthebodyofthetran-
saction. Thecharacteristic feature ofatransaction iseither alloftheseoperations
areexecuted ornoneareexecuted. These maybesystem calls,library procedures,
orbracketing statements inalanguage, depending ontheimplementation.
Thisall-or-nothing property oftransactions isoneofthefourcharacteristic
properties thattransactions have.Morespecifically, transactions are:
1.Atomic: Totheoutside world, thetransaction happens indivisibly.
2.Consistent: Thetransaction doesnotviolate system invariants.
3.Isolated: Concurrent transactions donotinterfere witheachother.
4.Durable: Onceatransaction commits, thechanges arepermanent.
These properties areoftenreferred tobytheirinitial letters: ACID.
Thefirstkeyproperty exhibited byalltransactions isthattheyareatomic.
Thisproperty ensures thateachtransaction either happens completely, ornotat
all,andifithappens, ithappens inasingle indivisible, instantaneous action.
While atransaction isinprogress, otherprocesses (whether ornottheyarethem-
selves involved intransactions) cannot seeanyoftheintermediate states.
Thesecond property saysthattheyareconsistent. What thismeans isthatif
thesystem hascertain invariants thatmustalways hold,iftheyheldbefore the
transaction, theywillholdafterward too.Forexample. inabanking system, akey22 INTRODUCTION CHAP. 1
invariant isthelawofconservation ofmoney. After every internal transfer, the
amount ofmoney inthebankmustbethesameasitwasbefore thetransfer, but
forabriefmoment during thetransaction, thisinvariant maybeviolated. Thevio-
lation isnotvisible outside thetransaction, however.
Thethirdproperty saysthattransactions areisolated orserializable. What it
means isthatiftwoormoretransactions arerunning atthesametime,toeachof
themandtootherprocesses, thefinalresult looks asthough alltransactions ian
sequentially insome(system dependent) order.
Thefourth property saysthattransactions aredurable. Itrefers tothefact
thatonceatransaction commits, nomatter whathappens, thetransaction goesfor-
wardandtheresults become permanent. Nofailure afterthecommit canundothe
results orcause themtobelost.(Durability isdiscussed extensively inChap. 8.)
Sofar,transactions havebeendefined onasingle database. Anested tran-
saction isconstructed fromanumber ofsubtransactions, asshown inFig.1-9.
Thetop-level transaction mayforkoffchildren thatruninparallel withoneanoth-
er,ondifferent machines, togainperformance orsimplify programming. Eachof
thesechildren mayalsoexecute oneormoresubtransactions, orforkoffitsown
children.
Figure 1-9.Anested transaction.
Subtransactions giverisetoasubtle, butimportant, problem. Imagine thata
transaction starts several subtransactions inparallel, andoneofthese commits.
making itsresults visible totheparent transaction. After further computation, the
parent aborts, restoring theentire system tothestateithadbefore thetop-level
transaction started. Consequently, theresults ofthesubtransaction thatcommitted
mustnevertheless beundone. Thusthepermanence referred toabove applies only
totop-level transactions.
Since transactions canbenested arbitrarily deeply, considerable administra-
tionisneeded togeteverything right. Thesemantics areclear, however. When
anytransaction orsubtransaction starts, itisconceptually given aprivate copyof
alldataintheentire system forittomanipulate asitwishes. Ifitaborts, itsprivate
universe justvanishes, asifithadnever existed. Ifitcommits, itsprivate universe
replaces theparent's universe. Thusifasubtransaction commits andthenlateraSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 23
newsubtransaction isstarted, thesecond oneseestheresults produced bythefirst
one.Likewise, ifanenclosing (higher-level) transaction aborts, allitsunderlying
subtransactions havetobeaborted aswell.
Nested transactions areimportant indistributed systems, fortheyprovide a
natural wayofdistributing atransaction across multiple machines. Theyfollow a
logical division oftheworkoftheoriginal transaction. Forexample, atransaction
forplanning atripbywhich threedifferent flights needtobereserved canbelogi-
callysplitupintothree subtransactions. Eachofthese subtransactions canbe
managed separately andindependent oftheothertwo.
Intheearlydaysofenterprise middleware systems, thecomponent thathand-
leddistributed (ornested) transactions formed thecoreforintegrating applications
attheserver ordatabase level. Thiscomponent wascalled atransaction proc-
essing monitor orTPmonitor forshort. Itsmaintaskwastoallow anapplication
toaccess multiple server/databases byoffering itatransactional programming
model, asshown inFig.1-10.
Figure 1-10. TheroleofaTPmonitor indistributed systems.
Enterprise Application Integration
Asmentioned, themore applications became decoupled fromthedatabases
theywerebuiltupon, themoreevident itbecame thatfacilities wereneeded to
integrate applications independent fromtheirdatabases. Inparticular, application
components should beabletocommunicate directly witheachotherandnotmere-
lybymeans oftherequest/reply behavior thatwassupported bytransaction proc-
essing systems.
Thisneedforinterapplication communication ledtomany different communi-
cation models, which wewilldiscuss indetail inthisbook(andforwhich reason
weshallkeepitbrieffornow). Themainideawasthatexisting applications could
directly exchange information, asshown inFig.1-11.24 INTRODUCTION CHAP. 1
Figure 1-11. MiddJeware asacommunication facilitator inenterprise applica-
tionintegration.
Several types ofcommunication middleware exist. Withremote procedure
calls(RPC), anapplication component caneffectively sendarequest toanother
application component bydoing alocalprocedure call,which results inthere-
questbeing packaged asamessage andsenttothecallee. Likewise, theresult will
besentbackandreturned totheapplication astheresult oftheprocedure call.
Asthepopularity ofobject technology increased, techniques weredeveloped
toallow callstoremote objects, leading towhatisknown asremote method
invocations (RMI). AnRMIisessentially thesameasanRPC,except thatitop-
erates onobjects instead ofapplications.
RPCandRMIhavethedisadvantage thatthecaller andcallee bothneedtobe
upandrunning atthetimeofcommunication. Inaddition, theyneedtoknow ex-
actlyhowtorefertoeachother. Thistightcoupling isoftenexperienced asaseri-
ousdrawback, andhasledtowhatisknown asmessage-oriented middleware, or
simply MOM. Inthiscase,applications simply sendmessages tological contact
points, oftendescribed bymeans ofasubject. Likewise, applications canindicate
theirinterest foraspecific typeofmessage, afterwhich thecommunication mid-
dleware willtakecarethatthose messages aredelivered tothose applications.
These so-called publish/subscribe systems form animportant andexpanding
classofdistributed systems. Wewilldiscuss thematlength inChap. 13.
1.3.3 Distributed Pervasive Systems
Thedistributed systems wehavebeendiscussing sofararelargely charac-
terized bytheirstability: nodes arefixedandhaveamoreorlesspermanent and
high-quality connection toanetwork. Toacertain extent, thisstability hasbeen
realized through thevarious techniques thatarediscussed inthisbookandwhich
aimatachieving distribution transparency. Forexample, thewealth oftechniquesSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 25
formasking failures andrecovery willgivetheimpression thatonlyoccasionally
things maygowrong. Likewise, wehavebeenabletohideaspects related tothe
actual network location ofanode, effectively allowing usersandapplications to
believe thatnodes stayput.
However, matters havebecome verydifferent withtheintroduction ofmobile
andembedded computing devices. Wearenowconfronted withdistributed sys-
temsinwhich instability isthedefault behavior. Thedevices inthese, whatwe
refertoasdistributed pervasive systems, areoftencharacterized bybeing small,
battery-powered, mobile, andhaving onlyawireless connection, although notall
thesecharacteristics apply toalldevices. Moreover, thesecharacteristics neednot
necessarily beinterpreted asrestrictive, asisillustrated bythepossibilities of
modem smart phones (Roussos etaI.,2005).
Asitsname suggests, adistributed pervasive system ispartofoursurround-
ings(andassuch,isgenerally inherently distributed). Animportant feature isthe
general lackofhuman administrative control. Atbest,devices canbeconfigured
bytheirowners, butotherwise theyneedtoautomatically discover theirenviron-
mentand"nestle in"asbestaspossible. Thisnestling inhasbeenmademorepre-
cisebyGrimm etal.(2004) byformulating thefollowing threerequirements for
pervasive applications:
1.Embrace contextual changes.
2.Encourage adhoccomposition.
3.Recognize sharing asthedefault.
Embracing contextual changes means thatadevice mustbecontinuously be
aware ofthefactthatitsenvironment maychange allthetime.Oneofthesim-
plestchanges isdiscovering thatanetwork isnolonger available, forexample,
because auserismoving between basestations. Insuchacase,theapplication
should react, possibly byautomatically connecting toanother network, ortaking
otherappropriate actions.
Encouraging adhoccomposition refers tothefactthatmany devices inper-
vasive systems willbeusedinverydifferent waysbydifferent users. Asaresult,
itshould beeasytoconfigure thesuiteofapplications running onadevice, either
bytheuserorthrough automated (butcontrolled) interposition.
Oneveryimportant aspect ofpervasive systems isthatdevices generally join
thesystem inorder toaccess (andpossibly provide) information. Thiscallsfor
means toeasily read,store, manage, andshareinformation. Inlightoftheinter-
mittent andchanging connectivity ofdevices, thespace where accessible informa-
tionresides willmostlikely change allthetime.
Mascolo etal.(2004) aswellasNiemela andLatvakoski (2004) cametosimi-
larconclusions: inthepresence ofmobility, devices should support easyandap-
plication-dependent adaptation totheirlocalenvironment. Theyshould beableto26 INTRODUCTION CHAP. 1
efficiently discover services andreactaccordingly. Itshould beclearfromthese
requirements thatdistribution transparency isnotreally inplace inpervasive sys-
tems. Infact,distribution ofdata,processes, andcontrol isinherent tothese sys-
tems,forwhich reason itmaybebetter justtosimply expose itrather thantrying
tohideit.Letusnowtakealookatsomeconcrete examples ofpervasive systems.
Home Systems
Anincreasingly popular typeofpervasive system, butwhich mayperhaps be
theleastconstrained, aresystems builtaround home networks. These systems
generally consist ofoneormorepersonal computers, butmoreimportantly inte-
gratetypical consumer electronics suchasTVs,audio andvideo equipment. gam-
ingdevices, (smart) phones, PDAs, andotherpersonal wearables intoasingle sys-
tem.Inaddition, wecanexpect thatallkinds ofdevices suchaskitchen appli-
ances, surveillance cameras, clocks, controllers forlighting, andsoon,willallbe
hooked upintoasingle distributed system.
From asystem's perspective thereareseveral challenges thatneedtobead-
dressed before pervasive home systems become reality. Animportant oneisthat
suchasystem should becompletely self-configuring andself-managing. Itcannot
beexpected thatendusersarewilling andabletokeepadistributed home system
upandrunning ifitscomponents areprone toerrors (asisthecasewithmany of
today's devices.) Much hasalready beenaccomplished through theUniversal
PlugandPlay(UPnP) standards bywhich devices automatically obtain IPad-
dresses, candiscover eachother, etc.(DPnP Forum, 2003). However, more is
needed. Forexample, itisunclear howsoftware andfirmware indevices canbe
easily updated without manual intervention, orwhen updates dotakeplace, that
compatibility withotherdevices isnotviolated.
Another pressing issueismanaging whatisknown asa"personal space."
Recognizing thatahome system consists ofmany shared aswellaspersonal de-
vices, andthatthedatainahome system isalsosubject tosharing restrictions,
much attention ispaidtorealizing suchpersonal spaces. Forexample, partof
Alice's personal space mayconsist ofheragenda, family photo's, adiary. music
andvideos thatshebought, etc.These personal assets should bestored insucha
waythatAlice .hasaccess tothemwhenever appropriate. Moreover. partsofthis
personal space should be(temporarily) accessible toothers, forexample. when
sheneeds tomakeabusiness appointment.
Fortunately, things maybecome simpler. Ithaslongbeenthought thattheper-
sonalspaces related tohome systems wereinherently distributed across thevari-
ousdevices. Obviously, suchadispersion caneasily leadtosignificant synchroni-
zation problems. However, problems maybealleviated duetotherapid increase
inthecapacity ofharddisks, along withadecrease intheirsize.Configuring a
multi-terabyte storage unitforapersonal computer isnotreally aproblem. Atthe
sametime,portable harddisks having acapacity ofhundreds ofgigabytes areSEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 27
being placed inside relatively small portable media players. With these continu-
ously increasing capacities, wemayseepervasive home systems adopt anarchi-
tecture inwhich asingle machine actsasamaster (andishidden away somewhere
inthebasement nexttothecentral heating), andallother fixed devices simply
provide aconvenient interface forhumans. Personal devices willthenbecram-
medwithdaily needed information, butwillnever runoutofstorage.
However, having enough storage doesnotsolve theproblem ofmanaging per-
sonal spaces. Being abletostorehugeamounts ofdatashifts theproblem tostor-
ingrelevant dataandbeing abletofinditlater. Increasingly wewillseepervasive
systems, likehome networks, equipped withwhatarecalled recommenders, pro-
grams thatconsult what other users havestored inorder toidentify. similar taste,
andfromthatsubsequently derive which content toplace inone's personal space.
Aninteresting observation isthattheamount ofinformation thatrecommender
programs needtodotheirwork isoften small enough toallow them toberunon
PDAs (Miller etal.,2004).
Electronic Health Care Systems
Another important andupcoming classofpervasive systems arethose related
to(personal) electronic health care.Withtheincreasing costofmedical treatment,
newdevices arebeing developed tomonitor thewell-being ofindividuals andto
automatically contact physicians when needed. Inmany ofthese systems, amajor
goalistoprevent people frombeing hospitalized.
Personal health caresystems areoften equipped withvarious sensors organ-
izedina(preferably wireless) body-area network (BAN). Animportant issue is
thatsuchanetwork should atworst onlyminimally hinder aperson. Tothisend,
thenetwork should beabletooperate while aperson ismoving, withnostrings
(i.e.,wires) attached toimmobile devices.
Thisrequirement leads totwoobvious organizations, asshown inFig.1-12.
Inthefirstone,acentral hubispartoftheBAN andcollects dataasneeded. From
timetotime, thisdataisthenoffloaded toalarger storage device. Theadvantage
ofthisscheme isthatthehubcanalsomanage theBAN. Inthesecond scenario,
theBAN iscontinuously hooked uptoanexternal network, again through awire-
lessconnection, towhich itsends monitored data. Separate techniques willneed
tobedeployed formanaging theBAN. Ofcourse, further connections toaphysi-
cianorother people mayexistaswell.
From adistributed system's perspective weareimmediately confronted with
questions suchas:
1.Where andhowshould monitored databestored?
2.Howcanweprevent lossofcrucial data?
3.What infrastructure isneeded togenerate andpropagate alerts?Figure 1-12. Monitoring aperson inapervasive electronic health caresystem,
using (a)alocalhubor(b)acontinuous wireless connection.
4.Howcanphysicians provide online feedback?
5.Howcanextreme robustness ofthemonitoring system berealized?
6.Whatarethesecurity issues andhowcantheproper policies be
enforced?
Unlike home systems, wecannot expect thearchitecture ofpervasive health care
systems tomove toward single-server systems andhavethemonitoring devices
operate withminimal functionality. Onthecontrary: forreasons ofefficiency, de-
vicesandbody-area networks willberequired tosupport in-network dataproc-
essing, meaning thatmonitoring datawill,forexample, havetobeaggregated be-
forepermanently storing itorsending ittoaphysician. Unlike thecasefordistrib-
utedinformation systems, thereisyetnoclearanswer tothesequestions.
Sensor Networks
Ourlastexample ofpervasive systems issensor networks. These networks in
many cases formpartoftheenabling technology forpervasiveness andwesee
thatmany solutions forsensor networks return inpervasive applications. What
makes sensor networks interesting fromadistributed system's perspective isthat
invirtually allcasestheyareusedforprocessing information. Inthissense, they
domorethanjustprovide communication services. which iswhattraditional com-
puter networks areallabout. Akyildiz etal.(2002) provide anoverview froma
networking perspective. Amoresystems-oriented introduction tosensor networks
isgiven byZhaoandGuibas (2004). Strongly related aremesh networks which
essentially formacollection of(fixed) nodes thatcommunicate through wireless
links. These networks mayformthebasisformany medium-scale distributed sys-
tems.Anoverview isprovided inAkyildiz etal.(2005).CHAP. 1 INTRODUCTION 28SEC. 1.3 TYPES OFDISTRIBUTED SYSTEMS 29
Asensor network typically consists oftenstohundreds orthousands ofrela-
tively small nodes, eachequipped withasensing device. Mostsensor networks
usewireless communication, andthenodes areoftenbattery powered. Their lim-
itedresources, restricted communication capabilities, andconstrained power con-
sumption demand thatefficiency behighonthelistofdesign criteria.
Therelation withdistributed systems canbemadeclearbyconsidering sensor
networks asdistributed databases. Thisviewisquitecommon andeasytounder-
standwhen realizing thatmany sensor networks aredeployed formeasurement
andsurveillance applications (Bonnet etaI.,2002). Inthesecases, anoperator
would liketoextract information from(apartof)thenetwork bysimply issuing
queries suchas"What isthenorthbound traffic loadonHighway I?"Such
queries resemble thoseoftraditional databases. Inthiscase,theanswer willprob-
ablyneedtobeprovided through collaboration ofmany sensors located around
Highway 1,while leaving othersensors untouched.
Toorganize asensor network asadistributed database, thereareessentially
twoextremes, asshown inFig.1-13. First,sensors donotcooperate butsimply
sendtheirdatatoacentralized database located attheoperator's site.Theother
extreme istoforward queries torelevant sensors andtoleteachcompute an
answer, requiring theoperator tosensibly aggregate thereturned answers.
Neither ofthesesolutions isveryattractive. Thefirstonerequires thatsensors
sendalltheirmeasured datathrough thenetwork, which maywaste network re-
sources andenergy. Thesecond solution mayalsobewasteful asitdiscards the
aggregation capabilities ofsensors which would allow much lessdatatobere-
turned totheoperator. What isneeded arefacilities forin-network dataproc-
essing, aswealsoencountered inpervasive health caresystems.
In-network processing canbedoneinnumerous ways. Oneobvious oneisto
forward aquery toallsensor nodes along atreeencompassing allnodes andto
subsequently aggregate theresults astheyarepropagated backtotheroot,where
theinitiator islocated. Aggregation willtakeplacewhere twoormorebranches of
thetreecometotogether. Assimple asthisscheme maysound, itintroduces diffi-
cultquestions:
1.Howdowe(dynamically) setupanefficient treeinasensor network?
2.Howdoesaggregation ofresults takeplace? Canitbecontrolled?
3.Whathappens whennetwork linksfail?
These questions havebeenpartly addressed inTinyDB, which' implements ade-
clarative(database) interface towireless sensor networks. Inessence, TinyDB can
useanytree-based routing algorithm. Anintermediate nodewillcollect andag-
gregate theresults fromitschildren, along withitsownfindings, andsendthat
toward theroot.Tomakematters efficient, queries spanaperiod oftimeallowing30 INTRODUCTION CHAP. 1
Figure 1-13. Organizing asensor network database, while storing andproc-
essing data(a)onlyattheoperator's siteor(b)onlyatthesensors.
forcareful scheduling ofoperations sothatnetwork resources andenergy are
optimally consumed. Details canbefound inMadden etal.(2005).
However, when queries canbeinitiated fromdifferent points inthenetwork,
using single-rooted treessuchasinTinyDB maynotbeefficient enough. Asan
alternative, sensor networks maybeequipped withspecial nodes where results are
forwarded to,aswellasthequeries related tothoseresults. Togiveasimple ex-
ample, queries andresults related temperature readings arecollected atadifferent
location thanthoserelated tohumidity measurements. Thisapproach corresponds
directly tothenotion ofpublish/subscribe systems, which wewilldiscuss exten-
sively inChap. 13.
1.4SUMMARY
Distributed systems consist ofautonomous computers thatwork together to
givetheappearance ofasingle coherent system. Oneimportant advantage isthat
theymake iteasier tointegrate different applications running ondifferent com-
puters intoasingle system. Another advantage isthatwhen properly designed,SEC. 1.4 SUMMARY 31
distributed systems scalewellwithrespect tothesizeoftheunderlying network.
These advantages oftencome atthecostofmorecomplex software, degradation
ofperformance, andalsooften weaker security. Nevertheless, thereisconsid-
erable interest worldwide inbuilding andinstalling distributed systems.
Distributed systems oftenaimathiding many oftheintricacies related tothe
distribution ofprocesses, data,andcontrol. However, thisdistribution transpar-
encynotonlycomes ataperformance price, butinpractical situations itcannever
befullyachieved. Thefactthattrade-offs needtobemadebetween achieving var-
iousforms ofdistribution transparency isinherent tothedesign ofdistributed sys-
tems,andcaneasily complicate theirunderstanding. -
Matters arefurther complicated bythefactthatmany developers initially
make assumptions about theunderlying network thatarefundamentally wrong.
Later, when assumptions aredropped, itmayturnouttobedifficult tomask
unwanted behavior. Atypical example isassuming thatnetwork latency isnotsig-
nificant. Later, when porting anexisting system toawide-area network, hiding
latencies maydeeply affect thesystem's original design. Other pitfalls include
assuming thatthenetwork isreliable, static, secure, andhomogeneous.
Different typesofdistributed systems existwhich canbeclassified asbeing
oriented toward supporting computations, information processing, andpervasive-
ness.Distributed computing systems aretypically deployed forhigh-performance
applications oftenoriginating fromthefieldofparallel computing. Ahugeclass
ofdistributed canbefound intraditional office environments where weseedata-
bases playing animportant role.Typically, transaction processing systems are
deployed intheseenvironments. Finally, anemerging classofdistributed systems
iswhere components aresmallandthesystem iscomposed inanadhocfashion,
butmostofallisnolonger managed through asystem administrator. Thislast
classistypically represented byubiquitous computing environments.
PROBLEMS
1.Analternative definition foradistributed system isthatofacollection ofindependent
computers providing theviewofbeing asingle system, thatis,itiscompletely hidden
from users thatthere even multiple computers. Give anexample where thisview
would come inveryhandy.
2.What istheroleofmiddleware inadistributed system?
3.Many networked systems areorganized interms ofabackoffice andafrontoffice.
How doesorganizations match withthecoherent viewwedemand foradistributed
~~m? -
4.Explain whatismeant by(distribution) transparency, andgiveexamples ofdifferent
types oftransparency.32 INTRODUCTION CHAP. 1
5.Why isitsometimes sohardtohidetheoccurrence andrecovery from failures ina
distributed system?
6.Why isitnotalways agoodideatoaimatimplementing thehighest degree oftrans-
parency possible?
7.What isanopendistributed system andwhatbenefits doesopenness provide?
8.Describe precisely whatismeant byascalable system.
9.Scalability canbeachieved byapplying different techniques. What arethese tech-
niques?
10.Explain whatismeant byavirtual organization andgiveahintonhowsuchorganiza-
tionscould beimplemented.
11.When atransaction isaborted. wehavesaidthattheworld isrestored toitsprevious
state. asthough thetransaction hadnever happened. Welied.Giveanexample where
resetting theworld isimpossible.
12.Executing nested transactions requires some form ofcoordination. Explain what a
coordinator should actually do.
13.Weargued thatdistribution transparency maynotbeinplace forpervasive systems.
Thisstatement isnottrueforalltypes oftransparencies. Giveanexample.
14.Wealready gave some examples ofdistributed pervasive systems: home systems.
electronic health-care systems. andsensor networks. Extend thislistwithmore ex-
amples.
15.(Lab assignment) Sketch adesign forahome system consisting ofaseparate media
server thatwillallow fortheattachment ofawireless client. Thelatter isconnected to
(analog) audio/video equipment andtransforms thedigital media streams toanalog
output. Theserver runsonaseparate machine. possibly connected totheInternet. but
hasnokeyboard and/or monitor connected.2
ARCHITECTURES
Distributed systems areoften complex pieces ofsoftware ofwhich thecom-
ponents arebydefinition dispersed across multiple machines. Tomaster their
complexity, itiscrucial thatthese systems areproperly organized. There aredif-
ferent ways onhowtoviewtheorganization ofadistributed system, butanobvi-
ousoneistomake adistinction between thelogical organization ofthecollection
ofsoftware components andontheother handtheactual physical realization.
Theorganization ofdistributed systems ismostly about thesoftware com-
ponents thatconstitute thesystem. These software architectures tellushowthe
various software components aretobeorganized andhowtheyshould interact. In
thischapter wewillfirstpayattention tosome commonly applied approaches
toward organizing (distributed) computer systems.
Theactual realization ofadistributed system requires thatweinstantiate and
place software components onrealmachines. There aremany different choices
thatcanbemade indoing so.Thefinalinstantiation ofasoftware architecture is
alsoreferred toasasystem architecture. Inthischapter wewilllookintotradi-
tional centralized architectures inwhich asingle server implements most ofthe
software components (andthusfunctionality), while remote clients canaccess that
server using simple communication means. Inaddition, weconsider decentralized
architectures inwhich machines more orlessplayequal roles, aswellashybrid
organizations.
Asweexplained inChap. I,animportant goalofdistributed systems isto
separate applications from underlying platforms byproviding amiddleware layer.
3334 ARCHITECTURES CHAP. 2
Adopting suchalayer isanimportant architectural decision, anditsmain purpose
istoprovide distribution transparency. However, trade-offs need tobemade to
achieve transparency, which hasledtovarious techniques tomake middleware
adaptive. Wediscuss some ofthemore commonly applied onesinthischapter, as
theyaffect theorganization ofthemiddleware itself.
Adaptability indistributed systems canalsobeachieved byhaving thesystem
monitor itsownbehavior andtaking appropriate measures when needed. This'in-
sighthasledtoaclass ofwhatarenowreferred toasautonomic systems. These
distributed systems arefrequently organized intheform offeedback control
loops. which formanimportant architectural element during asystem's design. In
thischapter, wedevote asection toautonomic distributed systems.
2.1ARCHITECTURAL STYLES
Westartourdiscussion onarchitectures byfirstconsidering thelogical organ-
ization ofdistributed systems intosoftware components, alsoreferred toassoft-
ware architecture (Bass etal.,2003). Research onsoftware architectures has
matured considerably anditisnowcommonly accepted thatdesigning oradopting
anarchitecture iscrucial forthesuccessful development oflarge systems.
Forourdiscussion, thenotion ofanarchitectural style isimportant. Such a
style isformulated interms ofcomponents, thewaythatcomponents arecon-
nected toeachother, thedataexchanged between components. andfinally how
these elements arejointly configured intoasystem. Acomponent isamodular
unitwithwell-defined required andprovided interfaces thatisreplaceable within
itsenvironment (OMG, 2004b). Asweshalldiscuss below, theimportant issue
about acomponent fordistributed systems isthatitcanbereplaced, provided we
respect itsinterfaces. Asomewhat more difficult concept tograsp isthatofacon-
nector, which isgenerally described asamechanism thatmediates communica-
tion,coordination, orcooperation among components (Mehta etal.,2000; and
Shaw andClements, 1997). Forexample, aconnector canbeformed bythefacili-
tiesfor(remote) procedure calls, message passing, orstreaming data.
Using components andconnectors, wecancome tovarious configurations,
which, intumhavebeenclassified intoarchitectural styles. Several styles haveby
nowbeenidentified, ofwhich themostimportant onesfordistributed systems are:
1.Layered architectures
2.Object-based architectures
3.Data-centered architectures
4.Event-based architectures
Thebasic ideaforthelayered styleissimple: components areorganized ina
layered fashion where acomponent atlayer L;isallowed tocallcomponents atSEC. 2.1 ARCHITECTURAL STYLES 35
theunderlying layerLi:«,butnottheotherwayaround, asshown inFig.2-I(a).
Thismodel hasbeenwidely adopted bythenetworking community; webriefly
review itinChap. 4.Ankeyobservation isthatcontrol generally flows fromlayer
tolayer: requests godown thehierarchy whereas theresults flowupward.
Afarlooser organization isfollowed inobject-based architectures, which
areillustrated inFig.2-1(b).Inessence, eachobject corresponds towhatwehave
defined asacomponent, andthesecomponents areconnected through a(remote)
procedure callmechanism. Notsurprisingly, thissoftware architecture matches
theclient-server system architecture wedescribed above. Thelayered andobject-
based architectures stillformthemostimportant styles forlargesoftware systems
(BassetaI.,2003).
Figure 2-1.The(a)layered and(b)object-based architectural style.
Data-centered architectures evolve around theideathatprocesses commun-
icatethrough acommon (passive oractive) repository. Itcanbeargued thatfor
distributed systems thesearchitectures areasimportant asthelayered andobject-
based architectures. Forexample, awealth ofnetworked applications havebeen
developed thatrelyonashared distributed filesystem inwhich virtually allcom-
munication takes place through files.Likewise, Web-based distributed systems,
which wediscuss extensively inChap. 12,arelargely data-centric: processes
communicate through theuseofshared Web-based dataservices.
Inevent-based architectures, processes essentially communicate through the
propagation ofevents, which optionally alsocarrydata,asshown inFig.2-2(a).
Fordistributed systems, event propagation hasgenerally beenassociated with
whatareknown aspublish/subscribe systems (Eugster etaI.,2003). Thebasic
ideaisthatprocesses publish events afterwhich themiddleware ensures thatonly
those processes thatsubscribed tothose events willreceive them. Themain
advantage ofevent-based systems isthatprocesses areloosely coupled. Inprinci-
ple,theyneednotexplicitly refertoeachother. Thisisalsoreferred toasbeing
decoupled inspace, orreferentially decoupled.36 ARCHITECTURES CHAP. 2
Figure 2-2.The(a)event-based and(b)shared data-space architectural style.
Event-based architectures canbecombined withdata-centered architectures,
yielding whatisalsoknown asshared dataspaces. Theessence ofshared data
spaces isthatprocesses arenowalsodecoupled intime:theyneednotbothbeac-
tivewhen communication takesplace. Furthermore, many shared dataspaces use
aSQL-like interface totheshared repository inthatsense thatdatacanbeac-
cessed using adescription rather thananexplicit reference, asisthecasewith
files.Wedevote Chap. 13tothisarchitectural style.
What makes thesesoftware architectures important fordistributed systems is
thattheyallaimatachieving (atareasonable level) distribution transparency.
However, aswehaveargued, distribution transparency requires making trade-offs
between performance, faulttolerance, ease-of-programming, andsoon.Asthere
isnosingle solution thatwillmeettherequirements forallpossible distributed ap-
plications, researchers haveabandoned theideathatasingle distributed system
canbeusedtocover 90%ofallpossible cases.
2.2SYSTEM ARCHITECTURES
Nowthatwehavebriefly discussed somecommon architectural styles, letus
takealookathowmany distributed systems areactually organized byconsidering
where software components areplaced. Deciding onsoftware components, their
interaction, andtheirplacement leads10aninstance ofasoftware architecture,
alsocalled asystem architecture (Bass etaI.,2003). Wewilldiscuss centralized
anddecentralized organizations, aswenasvarious hybrid forms.
2.2.1 Centralized Architectures
Despite thelackofconsensus onmany distributed systems issues, thereisone
issuethatmany researchers andpractitioners agree upon: thinking interms ofcli-
entsthatrequest services fromservers helpsusunderstand andmanage thecom-
plexity ofdistributed systems andthatisagoodthing.SEC. 2.2 SYSTEM ARCHITECTURES 37
Inthebasicclient-server model, processes inadistributed system aredivided
intotwo(possibly overlapping) groups. Aserver isaprocess implementing aspe-
cificservice, forexample, afilesystem service oradatabase service. Aclient isa
process thatrequests aservice fromaserver bysending itarequest andsubse-
quently waiting fortheserver's reply. Thisclient-server interaction, alsoknown
asrequest-reply behavior isshown inFig.2-3
Figure 2-3.General interaction between aclient andaserver.
Communication between aclient andaserver canbeimplemented bymeans
ofasimple connectionless protocol when theunderlying network isfairlyreliable
asinmany local-area networks. Inthesecases, whenaclient requests aservice, it
simply packages amessage fortheserver, identifying theservice itwants, along
withthenecessary inputdata.Themessage isthensenttotheserver. Thelatter, in
turn,willalways waitforanincoming request, subsequently process it,andpack-
agetheresults inareplymessage thatisthensenttotheclient.
Usingaconnectionless protocol hastheobvious advantage ofbeing efficient.
Aslongasmessages donotgetlostorcorrupted, therequest/reply protocol just
sketched works fine.Unfortunately, making theprotocol resistant tooccasional
transmission failures isnottrivial. Theonlythingwecandoispossibly letthecli-
entresend therequest whennoreplymessage comes in.Theproblem, however, is
thattheclient cannot detect whether theoriginal request message waslost,orthat
transmission ofthereplyfailed. Ifthereply waslost,thenresending arequest
mayresult inperforming theoperation twice. Iftheoperation wassomething like
"transfer $10,000 frommybankaccount," thenclearly, itwould havebeenbetter
thatwesimply reported anerrorinstead. Ontheotherhand, iftheoperation was
"tellmehowmuch money Ihaveleft,"itwould beperfectly acceptable toresend
therequest. When anoperation canberepeated multiple times without harm, itis
saidtobeidempotent. Since somerequests areidempotent andothers arenotit
should beclearthatthereisnosingle solution fordealing withlostmessages. We
deferadetailed discussion onhandling transmission failures toChap. 8.
Asanalternative, many client-server systems useareliable connection-
oriented protocol. Although thissolution isnotentirely appropriate inalocal-area
network duetorelatively lowperformance, itworks perfectly tineinwide-area
systems inwhich communication isinherently unreliable. Forexample, virtually
allInternet application protocols arebased onreliable TCPIIPconnections. Inthis38 ARCHITECTURES CHAP. 2
case, whenever aclient requests aservice, itfirstsetsupaconnection tothe
server before sending therequest. Theserver generally usesthatsameconnection
tosendthereplymessage, afterwhich theconnection istorndown. Thetrouble is
thatsetting upandtearing downaconnection isrelatively costly, especially when
therequest andreplymessages aresmaIl.
Application Layering
Theclient-server model hasbeensubject tomany debates andcontroversies
overtheyears. Oneofthemainissues washowtodrawacleardistinction be-
tween aclient andaserver. Notsurprisingly, thereisoftennocleardistinction.
Forexample, aserver foradistributed database maycontinuously actasaclient
because itisforwarding requests todifferent fileservers responsible forimple-
menting thedatabase tables. Insuchacase,thedatabase server itselfessentially
doesnomorethanprocess queries.
However, considering thatmanyclient-server applications aretargeted toward
supporting useraccess todatabases, manypeople haveadvocated adistinction be-
tween thefollowing threelevels, essentially following thelayered architectural
stylewediscussed previously:
1.Theuser-interface level
2.Theprocessing level
3.Thedatalevel
Theuser-interface levelcontains allthatisnecessary todirectly interface withthe
user,suchasdisplay management. Theprocessing leveltypically contains theap-
plications. Thedatalevelmanages theactual datathatisbeing actedon.
Clients typically implement theuser-interface level. Thislevelconsists ofthe
programs thatallow endusers tointeract withapplications. There isaconsid-
erable difference inhowsophisticated user-interface programs are.
Thesimplest user-interface program isnothing morethanacharacter-based
screen. Suchaninterface hasbeentypically usedinmainframe environments. In
those cases where themainframe controls allinteraction, including thekeyboard
andmonitor, onecanhardly speak ofaclient-server environment. However, in
many cases, theuser's terminal doessomelocalprocessing suchasechoing typed
keystrokes, orsupporting form-like interfaces inwhich acomplete entryistobe
edited before sending ittothemaincomputer.
Nowadays, eveninmainframe environments, weseemoreadvanced userin-
terfaces. Typically, theclient machine offers atleastagraphical display inwhich
pop-up orpull-down menus areused,andofwhich many ofthescreen controls
arehandled through amouse instead ofthekeyboard. Typical examples ofsuch
interfaces include theX-Windows interfaces asusedinmanyUNIX environments,
andearlier interfaces developed forMS-DOS PCsandApple Macintoshes.SEC. 2.2 SYSTEM ARCHITECTURES 39
Modern userinterfaces offerconsiderably morefunctionality byallowing ap-
plications toshareasingle graphical window, andtousethatwindow toexchange
datathrough useractions. Forexample, todelete afile,itisusually possible to
move theiconrepresenting thatfiletoaniconrepresenting atrashcan.Likewise,
manywordprocessors allow ausertomove textinadocument toanother position
byusingonlythemouse. Wereturn touserinterfaces inChap. 3.
Many client-server applications canbeconstructed fromroughly threedif-
ferent pieces: apartthathandles interaction withauser,apartthatoperates ona
database orfilesystem, andamiddle partthatgenerally contains thecorefunc-
tionality ofanapplication. Thismiddle partislogically placed attheprocessing
level.Incontrast touserinterfaces anddatabases, therearenotmanyaspects com-
montotheprocessing level. Therefore, weshallgiveseveral examples tomake
thislevelclearer.
Asafirstexample, consider anInternet search engine. Ignoring allthe
animated banners, images, andotherfancy window dressing, theuserinterface of
asearch engine isverysimple: ausertypesinastring ofkeywords andissubse-
quently presented withalistoftitlesofWebpages. Thebackendisformed bya
hugedatabase ofWebpages thathavebeenprefetched andindexed. Thecoreof
thesearch engine isaprogram thattransforms theuser's string ofkeywords into
oneormore database queries. Itsubsequently ranks theresults intoalist,and
transforms thatlistintoaseries ofHTML pages. Within theclient-server model,
thisinformation retrieval partistypically placed attheprocessing level. Fig.2-4
shows thisorganization.
Figure 2-4.Thesimplified organization ofanInternet search engine intothreedifferent
layers.
Asasecond example, consider adecision support system forastockbroker-
age.Analogous toasearch engine, suchasystem canbedivided intoafrontend40 ARCHITECTURES CHAP. 2
implementing theuserinterface, abackendforaccessing adatabase withthe
financial data,andtheanalysis programs between thesetwo.Analysis offinancial
datamayrequire sophisticated methods andtechniques fromstatistics andartifi-
cialintelligence. Insomecases, thecoreofafinancial decision support system
mayevenneedtobeexecuted onhigh-performance computers inordertoachieve
thethroughput andresponsiveness thatisexpected fromitsusers.
Asalastexample, consider atypical desktop package, consisting ofaword
processor, aspreadsheet application, communication facilities, andsoon.Such
"office" suites aregenerally integrated through acommon userinterface thatsup-
portscompound documents, andoperates onfilesfromtheuser's home directory.
(Inanoffice environment, thishome directory isoftenplaced onaremote file
server.) Inthisexample, theprocessing levelconsists ofarelatively largecollec-
tionofprograms, eachhaving rather simple processing capabilities.
Thedatalevelintheclient-server model contains theprograms thatmaintain
theactual dataonwhich theapplications operate. Animportant property ofthis
levelisthatdataareoftenpersistent, thatis,evenifnoapplication isrunning,
datawillbestored somewhere fornextuse.Initssimplest form, thedatalevel
consists ofafilesystem, butitismorecommon touseafull-fledged database. In
theclient-server model, thedatalevelistypically implemented attheserver side.
Besides merely storing data,thedatalevelisgenerally alsoresponsible for
keeping dataconsistent across different applications. When databases arebeing
used, maintaining consistency means thatmetadata suchastable descriptions,
entry constraints andapplication-specific metadata arealsostored atthislevel.
Forexample, inthecaseofabank, wemaywanttogenerate anotification when a
customer's credit carddebtreaches acertain value. Thistypeofinformation can
bemaintained through adatabase trigger thatactivates ahandler forthattrigger at
theappropriate moment.
Inmostbusiness-oriented environments, thedatalevelisorganized asarela-
tional database. Dataindependence iscrucial here..Thedataareorganized inde-
pendent oftheapplications insuchawaythatchanges inthatorganization donot
affect applications, andneither dotheapplications affect thedataorganization.
Using relational databases intheclient-server model helpsseparate theprocessing
levelfromthedatalevel,asprocessing anddataareconsidered independent.
However, relational databases arenotalways theidealchoice. Acharac-
teristic feature ofmany applications isthattheyoperate oncomplex datatypes
thataremoreeasily modeled interms ofobjects thaninterms ofrelations. Exam-
plesofsuchdatatypesrange fromsimple polygons andcircles torepresentations
ofaircraft designs, asisthecasewithcomputer-aided design (CAD) systems.
Inthosecaseswhere dataoperations aremoreeasily expressed interms ofob-
jectmanipulations, itmakes sensetoimplement thedatalevelbymeans ofanob-
ject-oriented orobject-relational database. Notably thelatter typehasgained
popularity asthese databases build upon thewidely dispersed relational data
model, while offering theadvantages thatobject-orientation gives.SEC. 2.2 SYSTEM ARCHITECTURES 41
lVlultitiered Architectures
Thedistinction intothreelogical levels asdiscussed sofar,suggests anumber
ofpossibilities forphysically distributing aclient-server application across several
machines. Thesimplest organization istohaveonlytwotypesofmachines:
1.Aclient machine containing onlytheprograms implementing (part
of)theuser-interface level
2.Aserver machine containing therest,thatistheprograms imple-
menting theprocessing anddatalevel
Inthisorganization everything ishandled bytheserver while theclient isessen-
tiallynomore thanadumb terminal, possibly withapretty graphical interface.
There aremany otherpossibilities, ofwhich weexplore some ofthemorecom-
mononesinthissection.
Oneapproach fororganizing theclients andservers istodistribute thepro-
grams intheapplication layers oftheprevious section across different machines,
asshown inFig.2-5[seealsoUmar (1997); andJingetal.(1999)]. Asafirst
step,wemake adistinction between onlytwokinds ofmachines: client machines
andserver machines, leading towhatisalsoreferred toasa(physically) two-
tiered architecture.
Figure 2-5.Alternative client-server organizations (a)-(e).
Onepossible organization istohaveonlytheterminal-dependent partofthe
userinterface ontheclient machine, asshown inFig.2-5(a), andgivetheapplica-
tionsremote control overthepresentation oftheirdata.Analternative istoplace
theentire user-interface software ontheclient side,asshown inFig.2-5(b). In
suchcases, weessentially divide theapplication intoagraphical frontend,which
communicates withtherestoftheapplication (residing attheserver) through an42 ARCHITECTURES CHAP. 2
application-specific protocol. Inthismodel, thefrontend(theclient software)
doesnoprocessing otherthannecessary forpresenting theapplication's interface.
Continuing alongthislineofreasoning, wemayalsomovepartoftheapplica-
tiontothefrontend,asshown inFig.2-5(c). Anexample where thismakes sense
iswhere theapplication makes useofaformthatneeds tobefilledinentirely be-
foreitcanbeprocessed. Thefrontendcanthencheck thecorrectness andconsis-
tency oftheform,andwhere necessary interact withtheuser.Another example of
theorganization ofFig.2:.5(c), isthatofawordprocessor inwhich thebasicedit-
ingfunctions execute ontheclient sidewhere theyoperate onlocally cached, or
in-memory data.butwhere theadvanced support toolssuchaschecking thespel-
lingandgrammar execute ontheserver side.
Inmany client-server environments, theorganizations shown inFig.2-5(d)
andFig.2-5(e) areparticularly popular. These organizations areusedwhere the
client machine isaPCorworkstation, connected through anetwork toadistrib-
utedfilesystem ordatabase. Essentially, mostoftheapplication isrunning onthe
client machine, butalloperations onfilesordatabase entries gototheserver. For
example, many banking applications runonanend-user's machine where theuser
prepares transactions andsuch.Oncefinished, theapplication contacts thedata-
baseonthebank's server anduploads thetransactions forfurther processing.
Fig.2-5(e) represents thesituation where theclient's localdiskcontains partof
thedata.Forexample, when browsing theWeb, aclient cangradually build a
hugecache onlocaldiskofmostrecent inspected Webpages.
Wenotethatforafewyearstherehasbeenastrong trendtomove awayfrom
theconfigurations shown inFig.2-5(d) andFig.2-5(e) inthose casethatclient
software isplaced atend-user machines. Inthese cases, mostoftheprocessing
anddatastorage ishandled attheserver side.Thereason forthisissimple: al-
though client machines doalot,theyarealsomoreproblematic tomanage. Hav-
ingmore functionality ontheclient machine makes client-side software more
prone toerrors andmore dependent ontheclient's underlying platform (i.e.,
operating system andresources). From asystem's management perspective, hav-
ingwhatarecalled fatclients isnotoptimal. Instead thethinclients asrepres-
ented bytheorganizations shown inFig.2-5(a)-(c) aremuch easier, perhaps at
thecostoflesssophisticated userinterfaces andclient-perceived performance.
Notethatthistrenddoesnotimply thatwenolonger needdistributed systems.
Onthecontrary, whatweareseeing isthatserver-side solutions arebecoming
increasingly moredistributed asasingle server isbeing replaced bymultiple ser-
versrunning ondifferent machines. Inparticular, when distinguishing onlyclient
andserver machines aswehavedonesofar,wemissthepointthataserver may
sometimes needtoactasaclient, asshown inFig.2-6,leading toa(physically)
three-tiered architecture.
Inthisarchitecture, programs thatformpartoftheprocessing levelreside ona
separate server, butmayadditionally bepartly distributed across theclient and
server machines. Atypical example ofwhere athree-tiered architecture isusedisSEC. 2.2
Figure 2-6.Anexample ofaserver acting asclient.
intransaction processing. Aswediscussed inChap. 1,aseparate process, called
thetransaction processing monitor, coordinates alltransactions across possibly
different dataservers. /
Another, butverydifferent example where weoftenseeathree-tiered archi-
tecture isintheorganization ofWebsites.Inthiscase,aWebserver actsasan
entrypointtoasite,passing requests toanapplication server where theactual
processing takesplace. Thisapplication server, intum,interacts withadatabase
server. Forexample, anapplication server mayberesponsible forrunning the
codetoinspect theavailable inventory ofsomegoods asoffered byanelectronic
bookstore. Todoso,itmayneedtointeract withadatabase containing theraw
inventory data.WewillcomebacktoWebsiteorganization inChap. 12.
2.2.2 Decentralized Architectures
Multitiered client-server architectures areadirect consequence ofdividing ap-
plications intoauser-interface, processing components, andadatalevel. Thedif-
ferent tierscorrespond directly withthelogical organization ofapplications. In
many business environments, distributed processing isequivalent toorganizing a
client-server application asamultitiered architecture. Werefertothistypeofdis-
tribution asvertical distribution. Thecharacteristic feature ofvertical distribu-
tionisthatitisachieved byplacing logically different components ondifferent
machines. Thetermisrelated totheconcept ofvertical fragmentation asusedin
distributed relational databases, where itmeans thattables aresplitcolumn-wise,
andsubsequently distributed across multiple machines (Oszu andValduriez,
1999).
Again, fromasystem management perspective, having avertical distribution
canhelp:functions arelogically andphysically splitacross multiple machines,
where eachmachine istailored toaspecific group offunctions. However, vertical
distribution isonlyonewayoforganizing client-server applications. Inmodem
architectures, itisoftenthedistribution oftheclients andtheservers thatcounts,43 SYSTEM ARCHITECTURES44 ARCHITECTURES CHAP. 2
which werefertoashorizontal distribution. Inthistypeofdistribution, aclient
orserver maybephysically splitupintologically equivalent parts, buteachpartis
operating onitsownshare ofthecomplete dataset,thusbalancing theload. In
thissection wewilltakealookataclass ofmodern system architectures thatsup-
porthorizontal distribution, known aspeer-to-peer systems.
From ahigh-level perspective, theprocesses thatconstitute apeer-to-peer sys-
temareallequal. Thismeans thatthefunctions thatneedtobecarried outare
represented byevery process thatconstitutes thedistributed system. Asaconse-
quence, much oftheinteraction between processes issymmetric: each process
willactasaclient andaserver atthesame time(which isalsoreferred toasact-
ingasaservent).
Given thissymmetric behavior, peer-to-peer architectures evolve around the
question howtoorganize theprocesses inanoverlay network, thatis,anetwork
inwhich thenodes areformed bytheprocesses andthelinks represent thepos-
siblecommunication channels (which areusually realized a§TCPconnections). In
general, aprocess cannot communicate directly withanarbitrary other process,
butisrequired tosendmessages through theavailable communication channels.
Twotypes ofoverlay networks exist: those thatarestructured andthose thatare
not.These twotypes aresurveyed extensively inLuaeta1.(2005) along with
numerous examples. Aberer eta1.(2005) provide areference architecture that
allows foramore formal comparison ofthedifferent types ofpeer-to-peer sys-
tems. Asurvey taken from theperspective ofcontent distribution isprovided by
Androutsellis- Theotokis andSpinellis (2004).
Structured Peer-to-Peer Architectures
Inastructured peer-to-peer architecture, theoverlay network isconstructed
using adeterministic procedure. Byfarthemost-used procedure istoorganize the
processes through adistributed hash table (DHT). InaDHT-based system, data
items areassigned arandom keyfromalarge identifier space, suchasa128-bit or
160-bit identifier. Likewise, nodes inthesystem arealsoassigned arandom num-
berfrom thesame identifier space. Thecruxofevery DHT-based system isthen
toimplement anefficient anddeterministic scheme thatuniquely maps thekeyof
adataitemtotheidentifier ofanode based onsome distance metric (Balakrish-
nan.2003). Most importantly, when looking upadataitem, thenetwork address
ofthenode responsible forthatdataitemisreturned. Effectively, thisisaccom-
plished byrouting arequest foradataitemtotheresponsible node.
Forexample, intheChord system (Stoica etal.,2003) thenodes arelogically
organized inaringsuchthatadataitemwithkeykismapped tothenode withthe
smallest identifier id~k.Thisnode isreferred toasthesuccessor ofkeykand
denoted assucc(k), asshown inFig.2-7.Toactually lookupthedataitem, anap-
plication running onanarbitrary node would thencallthefunction LOOKUP(k)SEC. 2.2 SYSTEM ARCHITECTURES 45
which would subsequently return thenetwork address ofsucc(k). Atthatpoint,
theapplication cancontact thenodetoobtain acopyofthedataitem.
Figure 2-7.Themapping ofdataitems ontonodes inChord.
Wewillnotgointoalgorithms forlooking upakeynow,butdeferthatdis-
cussion untilChap. 5where wedescribe details ofvarious naming systems.
Instead, letusconcentrate onhownodes organize themselves intoanoverlay net-
work, or,inotherwords, membership management. Inthefollowing, itisim-
portant torealize thatlooking upakeydoesnotfollow thelogical organization of
nodes intheringfromFig.2-7.Rather, eachnodewillmaintain shortcuts toother
nodes insuchawaythatlookups cangenerally bedoneinO(log (N) number of
steps, where Nisthenumber ofnodes participating intheoverlay.
Nowconsider Chord again. When anodewants tojointhesystem, itstarts
withgenerating arandom identifier id.Notethatiftheidentifier space islarge
enough, thenprovided therandom number generator isofgoodquality, theproba-
bility.ofgenerating anidentifier thatisalready assigned toanactual nodeisclose
tozero.Then, thenodecansimply doalookup onid,which willreturn thenet-
work address ofsucciid). Atthatpoint, thejoining nodecansimply contact
succiid) anditspredecessor andinsert itselfinthering.Ofcourse, thisscheme re-
quires thateachnodealsostores information onitspredecessor. Insertion also
yields thateachdataitemwhose keyisnowassociated withnodeid,istransferred
fromsucciid).
Leaving isjustassimple: nodeidinforms itsdeparture toitspredecessor and
successor, andtransfers itsdataitemstosucc(id).
Similar approaches arefollowed inotherDHT-based systems. Asanexample,
consider theContentAddressable Network (CAN), described inRatnasamy et
a1.(2001). CAN deploys ad-dimensional Cartesian coordinate space, which is
completely partitioned among allallthenodes thatparticipate inthesystem. ForARCHITECTURES
purpose ofillustration. letusconsider onlythe2-dimensional case, ofwhich an
example isshown inFig.2-8.
Figure 2-8.(a)Themapping ofdataitems ontonodes inCAN. (b)Splitting a
region when anodejoins.
Fig.2-8(a) shows how thetwo-dimensional space [0,l]x[O, 1]isdivided
among sixnodes. Each node hasanassociated region. Every dataiteminCAN
willbeassigned aunique point inthisspace, afterwhich itisalsoclear which
node isresponsible forthatdata(ignoring dataitems thatfallontheborder of
multiple regions, forwhich adeterministic assignment ruleisused).
When anodePwants tojoinaCAN system, itpicks anarbitrary point from
thecoordinate space andsubsequently looks upthenode Qinwhose region that
point falls. This lookup isaccomplished through positioned-based routing. of
which thedetails aredeferred untillaterchapters. Node Qthensplits itsregion
intotwohalves, asshown inFig.2-8(b). andonehalfisassigned tothenode P.
Nodes keeptrack oftheirneighbors, thatis,nodes responsible foradjacent region.
When splitting aregion, thejoining nodePcaneasily come toknow whoitsnew
neighbors arebyasking nodeP.AsinChord, thedataitems forwhich node Pis
nowresponsible aretransferred fromnodeQ.
Leaving isabitmore problematic inCAN. Assume thatinFig.2-8.thenode
withcoordinate (0.6,0.7)leaves. Itsregion willbeassigned tooneofitsneigh-
bors, saythenodeat(0.9,0.9), butitisclear thatsimply merging itandobtaining
arectangle cannot bedone. Inthiscase,thenodeat(0.9,0.9) willsimply takecare
ofthatregion andinform theoldneighbors ofthisfact.Obviously. thismaylead
tolesssymmetric partitioning ofthecoordinate space, forwhich reason aback-
ground process isperiodically started torepartition theentire space.CHAP. 2 46SEC. 2.2 SYSTEM ARCHITECTURES 47
Unstructured Peer-to- PeerArchitectures
Unstructured peer-to-peer systems largely relyonrandomized algorithms for
constructing anoverlay network. Themainideaisthateachnodemaintains alist
ofneighbors, butthatthislistisconstructed inamoreorlessrandom way.Like-
wise,dataitems areassumed toberandomly placed onnodes. Asaconsequence,
whenanodeneeds tolocate aspecific dataitem,theonlythingitcaneffectively
doisflood thenetwork withasearch query (Risson andMoors, 2006). Wewill
return tosearching inunstructured overlay networks inChap. 5,andfornowcon-
centrate onmembership management.
Oneofthegoalsofmany unstructured peer-to-peer systems istoconstruct an
overlay network thatresembles arandom graph. Thebasicmodel isthateach
nodemaintains alistofcneighbors, where, ideally, eachoftheseneighbors rep-
resents arandomly chosen livenodefromthecurrent setofnodes. Thelistof
neighbors isalsoreferred toasapartial view. There aremany waystoconstruct
suchapartial view. Jelasity etal.(2004, 2005a) havedeveloped aframework that
captures many different algorithms foroverlay construction toallow forevalua-
tionsandcomparison. Inthisframework, itisassumed thatnodes regularly
exchange entries fromtheirpartial view. Eachentryidentifies another nodeinthe
network, andhasanassociated agethatindicates howoldthereference tothat
nodeis.Twothreads areused,asshown inFig.2-9.
Theactive thread takestheinitiative tocommunicate withanother node. It
selects thatnodefromitscurrent partial view. Assuming thatentries needtobe
pushed totheselected peer,itcontinues byconstructing abuffer containing c/2+I
entries, including anentryidentifying itself. Theotherentries aretaken fromthe
current partial view.
W\nenocel~a\~O inpuUmode it~l\\~a\.\1mQ'ieSp~il~e \"'i~ID fue~e\e'\:..~\\
peer.Thatpeer,inthemeantime, willalsohaveconstructed abuffer bymeans the
passive thread shown inFig.2-9(b), whose activities strongly resemble thatofthe
active thread.
Thecrucial pointistheconstruction ofanewpartial view. Thisview,forini-
tiating aswellasforthecontacted peer,willcontain exactly, centries, partof
which willcome fromreceived buffer. Inessence, therearetwowaystoconstruct
thenewview. First,thetwonodes maydecide todiscard theentries thattheyhad
senttoeachother. Effectively, thismeans thattheywillswap partoftheiroriginal
views. Thesecond approach istodiscard asmany oldentries aspossible. Ingen-
eral,itturnsoutthatthetwoapproaches arecomplementary [seeJelasity etal.
(2005a) forthedetails]. Itturnsoutthatmany membership management protocols
forunstructured overlays fitthisframework. There areanumber ofinteresting
observations tomake.
First, letusassume thatwhen anodewants tojoinitcontacts anarbitrary
othernode, possibly fromalistofwell-known access points. Thisaccess pointis
justaregular member oftheoverlay, except thatwecanassume ittobehighly48 ARCHITECTURES CHAP. 2
Actions byactive thread (periodically repeated):
select apeer Pfrom thecurrent partial view;
ifPUSH_MODE {
mybuffer =[(MyAddress, 0)];
permute partial view;
move Holdest entries totheend;
append first c/2entries tomybuffer;
send mybuffer toP;
}else {
send trigger toP;
}
ifPULL_MODE {
receive P'sbuffer;
}
construct anew partial view from thecurrent one and P'sbuffer;
increment theage ofevery entry inthenew partial view;
(a)
Actions bypassive thread:
receive buffer from anyprocess Q;
ifPULL_MODE {
mybuffer =[(MyAddress, 0)];
permute partial view;
move Holdest entries totheend;
append firstc/2entries tomybuffer;
send mybuffer toP;
}
construct anew partial view from thecurrent one and P'sbuffer;
increment theage ofevery entry inthenew partial view;
(b)
Figure 2-9.(a)Thestepstaken bytheactive thread. (b)Thestepstakebythe
passive thread.
available. Inthiscase,itturnsoutthatprotocols thatuseonlypush mode oronly
pullmode canfairly easily leadtodisconnected overlays. Inotherwords, groups
ofnodes willbecome isolated andwillnever beabletoreach every othernodein
thenetwork. Clearly, thisisanundesirable feature, forwhich reason itmakes
moresensetoletnodes actually exchange entries.
Second, leaving thenetwork turnsouttobeaverysimple operation provided
thenodes exchange partial views onaregular basis. Inthiscase,anodecansim-
plydepart without informing anyother node. What willhappen isthatwhen a
nodePselects oneofitsapparent neighbors, saynodeQ,anddiscovers thatQno
longer responds, itsimply removes theentryfromitspartial viewtoselect another
peer.Itturnsoutthatwhen constructing anewpartial view, anodefollows theSEC. 2.2 SYSTEM ARCHITECTURES 49
policy todiscard asmany oldentries aspossible, departed nodes willrapidly be
forgotten. Inotherwords, entries referring todeparted nodes willautomatically be
quickly removed frompartial views.
However, thereisapricetopaywhen thisstrategy isfollowed. Toexplain,
consider foranodePthesetofnodes thathaveanentryintheirpartial viewthat
refers toP.Technically, thisisknown astheindegree ofanode.Thehigher node
P'sindegree is,thehigher theprobability thatsomeothernodewilldecide tocon-
tactP.Inotherwords, thereisadanger thatPwillbecome apopular node,which
could easily bring itintoanimbalanced position regarding workload. Systemati-
callydiscarding oldentries turnsouttopromote nodes tooneshaving ahighinde-
gree.There areothertrade-offs inaddition, forwhich werefertoJelasity etal.
(2005a).
Topology Management ofOverlay Networks
Although itwould seemthatstructured andunstructured peer-to-peer systems
formstrictindependent classes, this'needactually notbecase[seealsoCastro et
al.(2005)]. Onekeyobservation isthatbycarefully exchanging andselecting en-
triesfrompartial views, itispossible toconstruct andmaintain specific topologies
ofoverlay networks. Thistopology management isachieved byadopting atwo-
layered approach, asshown inFig.2-10.
Figure 2·10. Atwo-layered approach forconstructing andmaintaining specific
overlay topologies using techniques fromunstructured peer-to-peer systems.
Thelowest layerconstitutes anunstructured peer-to-peer system inwhich
nodes periodically exchange entries oftheirpartial views withtheaimtomaintain
anaccurate random graph. Accuracy inthiscaserefers tothefactthatthepartial
viewshould befilledwithentries referring torandomly selected livenodes.
Thelowest layerpasses itspartial viewtothehigher layer, where anaddi-
tional selection ofentries takesplace. Thisthenleadstoasecond listofneighbors
corresponding tothedesired topology. Jelasity andBabaoglu (2005) propose to
usearanking function bywhich nodes areordered according tosomecriterion
relative toagiven node. Asimple ranking function istoorder asetofnodes by
increasing distance fromagiven nodeP.Inthatcase,nodePwillgradually build50 ARCHITECTURES CHAP. 2
upalistofitsnearest neighbors, provided thelowest layercontinues topassran-
domly selected nodes.
Asanillustration, consider alogical gridofsizeNxNwithanodeplaced on
eachpointofthegrid.Every nodeisrequired tomaintain alistofcnearest neigh-
bors,where thedistance between anodeat(aJ.a2)and(b1,b2)isdefined as
dl+d2, withd;=min(N-1ai-bil, lai-bil). Ifthelowest layerperiodically exe-
cutestheprotocol asoutlined inFig.2-9,thetopology thatwillevolve isatorus,
shown inFig.2-11. •..
Figure 2-11. Generating aspecific overlay network using atwo-layered
unstructured peer-to-peer system [adapted withpermission fromJelasity andBa-
baoglu (2005)].
Ofcourse, completely different ranking functions canbeused.Notably those
thatarerelated tocapturing thesemantic proximity ofthedataitems asstored at
apeernodeareinteresting. Thisproximity allows fortheconstruction ofseman-
ticoverlay networks thatallow forhighly efficient search algorithms inunstruc-
turedpeer-to-peer systems. Wewillreturn tothesesystems inChap. 5when we
discuss attribute-based naming.
Superpeers
Notably inunstructured peer-to-peer systems, locating relevant dataitems can
become problematic asthenetwork grows. Thereason forthisscalability problem
issimple: asthereisnodeterministic wayofrouting alookup request toaspecific
dataitem,essentially theonlytechnique anodecanresort toisflooding there-
quest. There arevarious waysinwhich flooding canbedammed, aswewilldis-
cussinChap. 5,butasanalternative many peer-to-peer systems haveproposed to
makeuseofspecial nodes thatmaintain anindexofdataitems.
There areothersituations inwhich abandoning thesymmetric nature ofpeer-
to-peer systems issensible. Consider acollaboration ofnodes thatofferresourcesSEC. 2.2 SYSTEM ARCHITECTURES 51
toeachother. Forexample, inacollaborative content delivery network (CDN),
nodes mayofferstorage forhosting copies ofWebpages allowing Webclients to
access pages nearby, andthustoaccess themquickly. InthiscaseanodePmay
needtoseekforresources inaspecific partofthenetwork. Inthatcase,making
useofabroker thatcollects resource usage foranumber ofnodes thatareineach
other's proximity willallow toquickly select anodewithsufficient resources.
Nodes suchasthosemaintaining anindex oracting asabroker aregenerally
referred toassuperpeers. Astheirnamesuggests, superpeers areoftenalsoorg-
anizedin apeer-to-peer network, leading toahierarchical organization asex-
plained inYangandGarcia-Molina (2003). Asimple example ofsuchanorgani-
zation isshown inFig.2-12. Inthisorganization, every regular peeris connected
asaclient toasuperpeer. Allcommunication fromandtoaregular peerproceeds
through thatpeer's associated superpeer.
Figure 2-12. Ahierarchical organization ofnodes intoasuperpeer network.
Inmany cases, theclient-superpeer relation isfixed: whenever aregular peer
joinsthenetwork, itattaches tooneofthesuperpeers andremains attached untilit
leaves thenetwork. Obviously, itisexpected thatsuperpeers arelong-lived proc-
esseswithahighavailability. Tocompensate forpotential unstable behavior ofa
superpeer, backup schemes canbedeployed, suchaspairing every superpeer with
another oneandrequiring clients toattach toboth.
Having afixedassociation withasuperpeer maynotalways bethebestsolu-
tion.Forexample, inthecaseoffile-sharing networks, itmaybebetter foraclient
toattach toasuperpeer thatmaintains anindex offilesthattheclient isgenerally
interested in.Inthatcase,chances arebigger thatwhen aclient islooking fora
specific file,itssuperpeer willknow where tofindit.Garbacki etal.(2005) des-
cribearelatively simple scheme inwhich theclient-superpeer relation canchange
asclients discover better superpeers toassociate with.Inparticular, asuperpeer
returning theresult ofalookup operation isgiven preference overothersuper-
peers.,
Aswehaveseen,peer-to-peer networks offeraflexible means fornodes to
joinandleavethenetwork. However, withsuperpeer networks anewproblem is
introduced, namely howtoselect thenodes thatareeligible tobecome superpeer.52 ARCHITECTURES CHAP. 2
Thisproblem isclosely related totheleader-election problem, which wediscuss
inChap. 6,whenwereturn toelecting superpeers inapeer-to-peer network.
2.2.3 Hybrid Architectures
Sofar,wehavefocused onclient-server architectures andanumber ofpeer-
to-peer architectures. Many distributed systems combine architectural features, as
wealready came across insuperpeer networks. Inthissection wetakealookat
some specific classes ofdistributed systems inwhich client-server solutions are
combined withdecentralized architectures.
Edge-Server Systems
Animportant classofdistributed systems thatisorganized according toa
hybrid architecture isformed byedge-server systems. These systems aredeploy-
edontheInternet where servers areplaced "attheedge" ofthenetwork. This
edgeisformed bytheboundary between enterprise networks andtheactual Inter-
net,forexample, asprovided byanInternet Service Provider (ISP). Likewise,
where endusersathome connect totheInternet through theirISP,theISPcanbe
considered asresiding attheedgeoftheInternet. Thisleadstoageneral organiza-
tionasshown inFig.2-13.
Figure 2-13. Viewing theInternet asconsisting ofacollection ofedgeservers.
Endusers, orclients ingeneral, connect totheInternet bymeans ofanedge
server. Theedgeserver's mainpurpose istoservecontent, possibly afterapplying
filtering andtranscoding functions. More interesting isthefactthatacollection of
edgeservers canbeusedtooptimize content andapplication distribution. The
basicmodel isthatforaspecific organization, oneedgeserver actsasanorigin
server fromwhich allcontent originates. Thatserver canuseotheredgeservers
forreplicating Webpages andsuch(LeffetaI.,2004: Nayate etaI.,2004; and
Rabinovich andSpatscheck, 2002). Wewillreturn toedge-server systems in
Chap. 12whenwediscuss Web-based solutions.SEC. 2.2 SYSTEM ARCHITECTURES 53
Collaborative Distributed Systems
Hybrid structures arenotably deployed incollaborative distributed systems.
Themainissueinmany ofthese systems tofirstgetstarted, forwhich oftena
traditional client-server scheme isdeployed. Onceanodehasjoined thesystem, it
canuseafullydecentralized scheme forcollaboration.
Tomake matters concrete, letusfirstconsider theBitTorrent file-sharing sys-
tem(Cohen, 2003). BitTorrent isapeer-to-peer filedownloading system. Itsprin-
cipalworking isshown inFig.2-14Thebasicideaisthatwhen anenduseris
looking forafile,hedownloads chunks ofthefilefromother users untilthe
downloaded chunks canbeassembled together yielding thecomplete file.Anim-
portant design goalwastoensure collaboration. Inmostfile-sharing systems, a
significant fraction ofparticipants merely download filesbutotherwise contribute
closetonothing (Adar andHuberman, 2000; Saroiu etal.,2003; andYangetal.,
2005). Tothisend,afilecanbedownloaded onlywhenthedownloading client is
providing content tosomeone else.Wewillreturn tothis"tit-for-tat" behavior
shortly.
Figure 2-14. Theprincipal working ofBitTorrent [adapted with permission
fromPouwelse etal.(2004)].
Todownload ame,auserneeds toaccess aglobal directory, which isjustone
ofafewwell-known Websites.Suchadirectory contains references towhatare
called .torrent files.A.torrent filecontains theinformation thatisneeded to
download aspecific file.Inparticular, itrefers towhatisknown asatracker,
which isaserver thatiskeeping anaccurate account ofactive nodes thathave
(chunks) oftherequested file.Anactive nodeisonethatiscurrently downloading
another file.Obviously, therewillbemany different trackers, although (therewill
generally beonlyasingle tracker perfile(orcollection offiles).
Oncethenodes havebeenidentified fromwhere chunks canbedownloaded,
thedownloading nodeeffectively becomes active. Atthatpoint, itwillbeforced
tohelpothers, forexample byproviding chunks ofthefileitisdownloading that
others donotyethave.Thisenforcement comes fromaverysimple rule:ifnodeP
notices thatnodeQisdownloading morethanitisuploading, Pcandecide to54 ARCHITECTURES CHAP. 2
decrease therateatwhich itsends datatoQ.Thisscheme works wellprovided P
hassomething todownload fromQ.Forthisreason, nodes areoftensupplied with
references tomany othernodes putting theminabetter position totradedata.
Clearly, BitTorrent combines centralized withdecentralized solutions. Asit
turnsout,thebottleneck ofthesystem is,notsurprisingly, formed bythetrackers.
Asanother example, consider theGlobule collaborative content distribution
network (Pierre andvanSteen, 2006). Globule strongly resembles theedge-
server architecture mentioned above. Inthiscase,instead ofedgeservers, end
users(butalsoorganizations) voluntarily provide enhanced Webservers thatare
capable ofcollaborating inthereplication ofWebpages. Initssimplest form,
eachsuchserver hasthefollowing components:
1.Acomponent thatcanredirect client requests tootherservers.
2.Acomponent foranalyzing access patterns.
3.Acomponent formanaging thereplication ofWebpages.
Theserver provided byAlice istheWebserver thatnormally handles thetraffic
forAlice's Websiteandiscalled theorigin server forthatsite.Itcollaborates
withotherservers, forexample, theoneprovided byBob,tohostthepages from
Bob's site.Inthissense, Globule isadecentralized distributed system. Requests
forAlice's Websiteareinitially forwarded toherserver, atwhich pointtheymay
beredirected tooneoftheotherservers. Distributed redirection isalsosupported.
However, Globule alsohasacentralized component intheformofitsbroker.
Thebroker isresponsible forregistering servers, andmaking theseservers known
toothers. Servers communicate withthebroker completely analogous towhatone
would expect inaclient-server system. Forreasons ofavailability, thebroker can
bereplicated, butasweshalllaterinthisbook, thistypeofreplication iswidely
applied inordertoachieve reliable client-server computing.
2.3ARCHITECTURES VERSUS MIDDLEW ARE
When considering thearchitectural issues wehavediscussed sofar,aquestion
thatcomes tomind iswhere middleware fitsin.Aswediscussed inChap. 1,
middleware forms alayer between applications anddistributed platforms. as
shown inFig.1-1.Animportant purpose istoprovide adegree ofdistribution
transparency, thatis,toacertain extent hiding thedistribution of-data, processing,
andcontrol fromapplications.
What iscomonly seeninpractice isthatmiddleware systems actually follow a
specific architectural sytle. Forexample, many middleware solutions havead-
opted anobject-based architectural style, suchasCORBA (OMG. 2004a). Oth-
ers,likeTIB/Rendezvous (TIBCO, 2005) provide middleware thatfollows theSEC. 2.3 ARCHITECTURES VERSUS MIDDLEWARE 55
event-based architectural style. Inlaterchapters, wewillcome across moreex-
amples ofarchitectural styles.
Having middleware molded according toaspecific architectural stylehasthe
benefit thatdesigning applications maybecome simpler. However, anobvious
drawback isthatthemiddleware maynolonger beoptimal forwhatanapplication
developer hadinmind. Forexample, COREA initially offered onlyobjects that
could beinvoked byremote clients. Later, itwasfeltthathaving onlythisformof
interaction wastoorestrictive, sothatotherinteraction patterns suchasmessaging
wereadded. Obviously, adding newfeatures caneasily leadtobloated middle-
waresolutions.
Inaddition, although middleware ismeant toprovide distribution trans-
parency, itisgenerally feltthatspecific solutions should beadaptable toapplica-
tionrequirements. Onesolution tothisproblem istomake several versions ofa
middle waresystem, where eachversion istailored toaspecific classofapplica-
tions. Anapproach thatisgenerally considered better istomake middle waresys-
temssuchthattheyareeasytoconfigure, adapt, andcustomize asneeded byan
application. Asaresult, systems arenowbeing developed inwhich astricter
separation between policies andmechanisms isbeing made. Thishasledtosever-
almechanisms bywhich thebehavior ofmiddleware canbemodified (Sadjadi
andMcKinley, 2003). Letustakealookatsomeofthecommonly followed ap-
proaches.
2.3.1Interceptors
Conceptually, aninterceptor isnothing butasoftware construct thatwill
break theusualflowofcontrol andallow other(application specific) codetobe
executed. Tomakeinterceptors generic mayrequire asubstantial implementation
effort, asillustrated inSchmidt etal.(2000), anditisunclear whether insuch
cases generality should bepreferred overrestricted applicability andsimplicity.
Also, inmany cases having onlylimited interception facilities willimprove
management ofthesoftware andthedistributed system asawhole.
Tomake matters concrete, consider interception assupported inmany object-
based distributed systems. Thebasicideaissimple: anobject Acancallamethod
thatbelongs toanobject B,while thelatterresides onadifferent machine thanA.
Asweexplain indetail laterinthebook, sucharemote-object invocation iscar-
riedasathree-step approach:
1.Object Aisoffered alocalinterface thatisexactly thesameasthein-
terface offered byobject B.Asimply callsthemethod available in'
thatinterface.
2.ThecallbyAistransformed intoageneric object invocation, made
possible through ageneral object-invocation interface offered bythe
middleware atthemachine where Aresides.56 ARCHITECTURES CHAP. 2
3.Finally, thegeneric object invocation istransformed intoamessage
thatissentthrough thetransport-level network interface asoffered
byA'slocaloperating system.
Thisscheme isshown inFig.2-15.
Figure 2-15. Using interceptors tohandle remote-object invocations.
Afterthefirststep,thecallB.do_something(value) istransformed intoagen-
ericcallsuchasinvoke(B, &do_something, value) withareference toB'smethod
andtheparameters thatgoalong withthecall.Nowimagine thatobject Bisrepli-
cated. Inthatcase,eachreplica should actually beinvoked. Thisisaclearpoint
where interception canhelp.Whattherequest-level interceptor willdoissimply
callinvoke(B, &do_something, value) foreachofthereplicas. Thebeauty ofthis
anisthattheobject Aneednotbeaware ofthereplication ofB,butalsotheob-
jectmiddleware neednothavespecial components thatdealwiththisreplicated
call.Onlytherequest-level interceptor, which maybeadded tothemiddleware
needs toknow aboutB'sreplication.
Intheend,acalltoaremote object willhavetobesentoverthenetwork. In
practice, thismeans thatthemessaging interface asoffered bythelocaloperating
system willneedtobeinvoked. Atthatlevel, amessage-level interceptor may
assistintransferring theinvocation tothetarget object. Forexample, imagine that
theparameter value actually corresponds toahugearray ofdata.Inthatcase,it
maybewisetofragment thedataintosmaller partstohaveitassembled again atSEC. 2.3 ARCHITECTURES VERSUS MIDDLEWARE 57
thedestination. Suchafragmentation mayimprove performance orreliability.
Again, themiddleware neednotbeaware ofthisfragmentation; thelower-level
interceptor willtransparently handle therestofthecommunication withthelocal
operating system.
2.3.2GeneralApproaches toAdaptive Software
What interceptors actually offerisameans toadaptthemiddleware. Theneed
foradaptation comes fromthefactthattheenvironment inwhich distributed ap-
plications areexecuted changes continuously. Changes include those resulting
frommobility, astrong variance inthequality-of-service ofnetworks, failing
hardware, andbattery drainage, amongst others. Rather thanmaking applications
responsible forreacting tochanges, thistaskisplaced inthemiddleware.
These strong influences fromtheenvironment havebrought many designers
ofmiddleware toconsider theconstruction ofadaptive software. However, adap-
tivesoftware hasnotbeenassuccessful asanticipated. Asmany researchers and
developers consider ittobeanimportant aspect ofmodern distributed systems, let
usbriefly paysomeattention toit.McKinley etal.(2004) distinguish threebasic
techniques tocometosoftware adaptation:
1.Separation ofconcerns
2.Computational reflection
3.Component-based design
Separating concerns relates tothetraditional wayofmodularizing systems:
separate thepartsthatimplement functionality fromthosethattakecareofother
things (known asextrafunctionalities) suchasreliability, performance, security,
etc.Onecanargue thatdeveloping middleware fordistributed applications is
largely about handling extrafunctionalities independent fromapplications. The
main problem isthatwecannot easily separate these extra functionalities by
means ofmodularization. Forexample, simply putting security intoaseparate
module isnotgoing towork. Likewise, itishardtoimagine howfaulttolerance
canbeisolated intoaseparate boxandsoldasanindependent service. Separating
andsubsequently weaving thesecross-cutting concerns intoa(distributed) system
isthemajor theme addressed byaspect-oriented software development (Filman
etal.,2005). However, aspect orientation hasnotyetbeensuccessfully applied to
developing large-scale distributed systems, anditcanbeexpected thatthereis
stillalongwaytogobefore itreaches thatstage.
Computational reflection refers totheability ofaprogram toinspect itself
and,ifnecessary, adapt itsbehavior (Konetal.,2002). Reflection hasbeenbuilt
intoprogramming languages, including Java, andoffers apowerful facility for
runtime modifications. Inaddition, somemiddle waresystems provide themeans58 ARCHITECTURES CHAP. 2
toapply reflective techniques. However, justasinthecaseofaspect orientation,
reflective middleware hasyettoprove itselfasapowerful tooltomanage the
complexity oflarge-scale distributed systems. Asmentioned byBlairetal.(2004),
applying reflection toabroad domain ofapplications isyettobedone.
Finally, component-based design supports adaptation through composition. A
system mayeither beconfigured statically atdesign time,ordynamically atrun-
time.Thelatterrequires support forlatebinding, atechnique thathasbeensuc-
cessfully applied inprogramming language environments, butalsoforoperating
systems where modules canbeloaded andunloaded atwill.Research isnowwell
underway toallow automatically selection ofthebestimplementation ofacom-
ponent during runtime (Yellin, 2003), butagain, theprocess remains complex for
distributed systems, especially whenconsidering thatreplacement ofonecompon-
entrequires knowning whattheeffect ofthatreplacement onother components
willbe.Inmany cases, components arelessindependent asonemaythink.
2.3.3 Discussion
Software architectures fordistributed systems, notably found asmiddleware,
arebulky andcomplex. Inlargepart,thisbulkiness andcomplexity arises from
theneedtobegeneral inthesensethatdistribution transparency needs tobepro-
vided. Atthesametimeapplications havespecific extra-functional requirements
thatconflict withaiming atfullyachieving thistransparency. These conflicting
requirements forgenerality andspecialization haveresulted inmiddleware solu-
tionsthatarehighly flexible. Thepricetopay,however, iscomplexity. Forex-
ample, Zhang andJacobsen (2004) report a50%increase inthesizeofaparticu-
larsoftware product injustfouryears sinceitsintroduction, whereas thetotal
number offilesforthatproduct hadtripled during thesameperiod. Obviously,
thisisnotanencouraging direction topursue.
Considering thatvirtually alllargesoftware systems arenowadays required to
execute inanetworked environment, wecanaskourselves whether thecomplex-
ityofdistributed systems issimply aninherent feature ofattempting tomake dis-
tribution transparent. Ofcourse, issues suchasopenness areequally important,
buttheneed forflexibility hasnever been soprevalent asinthecaseof
middleware.
Coyler etal.(2003) argue thatwhatisneeded isastronger focus on(external)
simplicity, asimpler waytoconstruct middleware bycomponents, andapplication
independence. Whether anyofthetechniques mentioned above forms thesolution
issubject todebate. Inparticular, noneoftheproposed techniques sofarhave
found massive adoption, norhavetheybeensuccessfully applied tQlarge-scale
systems.
Theunderlying assumption isthatweneedadaptive software inthesense that
thesoftware should beallowed tochange astheenvironment changes. However,
oneshould question whether adapting toachanging environment isagoodreasonSEC. 2.3 ARCHITECTURES VERSUS MIDDLEW ARE 59
toadopt changing thesoftware. Faulty hardware, security attacks, energy drain-
age,andsoon,allseemtobeenvironmental influences thatcan(andshould) be
anticipated bysoftware.
Thestrongest, andcertainly mostvalid, argument forsupporting adaptive
software isthatmany distributed systems cannot beshutdown. Thisconstraint
callsforsolutions toreplace andupgrade components onthefly,butisnotclear
whether anyofthesolutions proposed above arethebestonestotackle this
maintenance problem.
What thenremains isthatdistributed systems should beabletoreact to
changes intheirenvironment by,forexample, switching policies forallocating re-
sources. Allthesoftware components toenable suchanadaptation willalready be
inplace. Itisthealgorithms contained inthesecomponents andwhich dictate the
behavior thatchange theirsettings. Thechallenge istoletsuchreactive behavior
takeplace without human intervention. Thisapproach isseentoworkbetter when
discussing thephysical organization ofdistributed systems when decisions are
taken about where components areplaced, forexample. Wediscuss suchsystem
architectural issues next.
2.4SELF-MANAGEMENT INDISTRIBUTED SYSTEMS
Distributed systems-and notably theirassociated middle ware-need topro-
videgeneral solutions toward shielding undesirable features inherent tonetwork-
ingsothattheycansupport asmany applications aspossible. Ontheotherhand,
fulldistribution transparency isnotwhatmost applications actually want, re-
sulting inapplication-specific solutions thatneedtobesupported aswell.We
haveargued that,forthisreason, distributed systems should beadaptive, butnot-
ablywhen itcomes toadapting theirexecution behavior andnotthesoftware
components theycomprise.
When adaptation needs tobedoneautomatically, weseeastrong interplay
between system architectures andsoftware architectures. Ontheonehand, we
needtoorganize thecomponents ofadistributed system suchthatmonitoring and
adjustments canbedone, while ontheotherhandweneedtodecide where the
processes aretobeexecuted thathandle theadaptation.
Inthissection wepayexplicit attention toorganizing distributed systems as
high-level feedback-control systems allowing automatic adaptations tochanges.
Thisphenomenon isalsoknown asautonomic computing (Kephart, 2003) or
self..starsystems (Babaoglu etal.,2005). Thelatternameindicates thevariety by
which automatic adaptations arebeing captured: self-managing, self-healing,
self-configuring, self-optimizing, andsoon.Weresort simply tousingthename
self-managing systems ascoverage ofitsmany variants.60 ARCHITECTURES CHAP. 2
2.4.1 TheFeedback Control Model
There aremany different views onself-managing systems, butwhat most
haveincommon (either explicitly orimplicitly) istheassumption thatadaptations
takeplacebymeans ofoneormorefeedback control loops. Accordingly, sys-
temsthatareorganized bymeans ofsuchloops arereferred toasfeedback COl)-
trolsystems. Feedback control hassincelongbeenapplied invarious engineer-
ingfields, anditsmathematical foundations aregradually alsofinding theirwayin
computing systems (Hellerstein etal.,2004; andDiaoetal.,2005). Forself-
managing systems, thearchitectural issues areinitially themostinteresting. The
basicideabehind thisorganization isquitesimple, asshown inFig.2-16.
Figure 2-16. Thelogical organization ofafeedback control system.
Thecoreofafeedback control system isformed bythecomponents thatneed
tobemanaged. These components areassumed tobedriven through controllable
inputparameters, buttheirbehavior maybeinfluenced byallkinds ofuncontrol-
lable input, alsoknown asdisturbance ornoiseinput. Although disturbance will
oftencome fromtheenvironment inwhich adistributed system isexecuting, it
maywellbethecasethatunanticipated component interaction causes unexpected
behavior.
There areessentially threeelements thatformthefeedback control loop.First,
thesystem itselfneeds tobemonitored, which requires thatvarious aspects ofthe
system needtobemeasured. Inmany cases, measuring behavior iseasier said
thandone. Forexample, round-trip delays intheInternet mayvarywildly, and
alsodepend onwhatexactly isbeing measured. Insuchcases, accurately estimat-
ingadelaymaybedifficult indeed. Matters arefurther complicated when anode
Aneeds toestimate thelatency between twoothercompletely different nodes B
andC,without being abletointrude oneither twonodes. Forreasons asthis,a
feedback control loopgenerally contains alogical metric estimation component.SEC. 2.4 SELF-MANAGEMENT INDISTRIBUTED SYSTEMS 61
Another partofthefeedback control loopanalyzes themeasurements and
compares thesetoreference values. Thisfeedback analysis component forms the
heartofthecontrol loop,asitwillcontain thealgorithms thatdecide onpossible
adaptations.
Thelastgroup ofcomponents consist ofvarious mechanisms todirectly influ-
encethebehavior ofthesystem. There canbemany different mechanisms: plac-
ingreplicas, changing scheduling priorities, switching services, moving datafor
reasons" ofavailability, redirecting requests todifferent servers, etc.Theanalysis
component willneedtobeaware ofthesemechanisms andtheir(expected) effect
onsystem behavior. Therefore, itwilltrigger oneorseveral mechanisms, tosub-
sequently laterobserve theeffect.
Aninteresting observation isthatthefeedback control loopalsofitstheman-
ualmanagement ofsystems. Themaindifference isthattheanalysis component is
replaced byhuman administrators. However, inordertoproperly manage anydis-
tributed system, these administrators willneeddecent monitoring equipment as
wellasdecent mechanisms tocontrol thebehavior ofthesystem. Itshould be
clearthatproperly analyzing measured dataandtriggering thecorrect actions
makes thedevelopment ofself-managing systems sodifficult.
Itshould bestressed thatFig.2-16shows thelogical organization ofaself-
managing system, andassuchcorresponds towhatwehaveseenwhendiscussing
software architectures. However, thephysical organization maybeverydifferent.
Forexample, theanalysis component maybefullydistributed across thesystem.
Likewise, taking performance measurements areusually doneateachmachine
thatispartofthedistributed system. Letusnowtakealookatafewconcrete ex-
amples onhowtomonitor, analyze, andcorrect distributed systems inanauto-
matic fashion. These examples willalsoillustrate thisdistinction between logical
andphysical organization.
2.4.2 Example: Systems Monitoring withAstrolabe
Asourfirstexample, weconsider Astrolabe (VanRenesse etaI.,2003), which
isasystem thatcansupport general monitoring ofverylargedistributed systems.
Inthecontext ofself-managing systems, Astrolabe istobepositioned asageneral
toolforobserving systems behavior. Itsoutput canbeusedtofeedintoananalysis
component fordeciding oncorrective actions.
Astrolabe organizes alargecollection ofhostsintoahierarchy ofzones. The
lowest-level zones consist ofjustasingle host,which aresubsequently grouped
intozones ofincreasing size.Thetop-level zonecovers allhosts. Every hostruns
anAstrolabe process, called anagent, thatcollects information onthezones in
which thathostiscontained. Theagentalsocommunicates withotheragents with
theaimtospread zoneinformation across theentire system.
Eachhostmaintains asetofattributes forcollecting localinformation. For
example, ahostmaykeeptrackofspecific filesitstores, itsresource usage, and62 ARCHITECTURES CHAP. 2
soon.Onlytheattributes asmaintained directly byhosts, thatis,atthelowest
levelofthehierarchy arewritable. Eachzonecanalsohaveacollection ofattri-
butes, butthevalues oftheseattributes arecomputed fromthevalues oflower
levelzones.
Consider thefollowing simple example shown inFig.2-17withthreehosts,
A,B,andCgrouped intoazone.Eachmachine keeps trackofitsIPaddress, CPU
load,available freememory. andthenumber ofactive processes. Eachofthese
attributes canbedirectly written using localinformation fromeachhost.Atthe
zonelevel, onlyaggregated information canbecollected, suchastheaverage
CPUload,ortheaverage number ofactive processes.
Figure 2-17. Datacollection andinformation aggregation inAstrolabe.
Fig.2-17shows howtheinformation asgathered byeachmachine canbe
viewed asarecord inadatabase, andthattheserecords jointly formarelation
(table). Thisrepresentation isdoneonpurpose: itisthewaythatAstrolabe views
allthecollected data.However, perzoneinformation canonlybecomputed from
thebasicrecords asmaintained byhosts.
Aggregated information isobtained byprogrammable aggregation functions,
which areverysimilar tofunctions available intherelational database language
SQL. Forexample, assuming thatthehostinformation fromFig.2-17ismain-
tained inalocaltablecalled hostinfo, wecould collect theaverage number of
processes forthezonecontaining machines A,B,andC,through thesimple SQL
query
SELECT AVG(procs) ASaV9_procs FROM hostinfo
Combined withafewenhancements toSQL, itisnothardtoimagine thatmore
informative queries canbeformulated.
Queries suchasthesearecontinuously evaluated byeachagent running on
eachhost.Obviously, thisispossible onlyifzoneinformation ispropagated toallSEC. 2.4 SELF-MANAGEMENT INDISTRffiUTED SYSTEMS 63
nodes thatcomprise Astrolabe. Tothisend,anagentrunning onahostisresponsi-
bleforcomputing partsofthetables ofitsassociated zones. Records forwhich it
holdsnocomputational responsibility areoccasionally senttoitthrough asimple,
yeteffective exchange procedure known asgossiping. Gossiping protocols will
bediscussed indetail inChap. 4.Likewise, anagentwillpasscomputed results to
otheragents aswell.
Theresult ofthisinformation exchange isthateventually, allagents that
needed toassistinobtaining someaggregated information willseethesameresult
(provided thatnochanges occur inthemeantime).
2.4.3 Example: Differentiating Replication Strategies inGlobule
LetusnowtakealookatGlobule, acollaborative content distribution net-
work (Pierre andvanSteen, 2006). Globule relies onend-user servers being
placed intheInternet, andthattheseservers collaborate tooptimize performance
through replication ofWebpages. Tothisend,eachorigin server (i.e.,theserver
responsible forhandling updates ofaspecific Website),keeps trackofaccess pat-
ternsonaper-page basis. Access patterns areexpressed asreadandwriteopera-
tionsforapage, eachoperation being timestamped andlogged bytheorigin
server forthatpage.
Initssimplest form, Globule assumes thattheInternet canbeviewed asan
edge-server system asweexplained before. Inparticular, itassumes thatrequests
canalways bepassed through anappropriate edgeserver, asshown inFig.2-18.
Thissimple model allows anorigin server toseewhatwould havehappened ifit
hadplaced areplica onaspecific edgeserver. Ontheonehand, placing areplica
closer toclients would improve client-perceived latency, butthiswillinduce
traffic between theorigin server andthatedgeserver inorder tokeepareplica
consistent withtheoriginal page.
Figure 2-18. Theedge-server model assumed byGlobule.
When anorigin server receives arequest forapage, itrecords theIPaddress
fromwhere therequest originated, andlooks uptheISPorenterprise network64 ARCHITECTURES CHAP. 2
associated withthatrequest using theWHOIS Internet service (Deutsch etaI.,
1995). Theorigin server thenlooks forthenearest existing replica server that
could actasedgeserver forthatclient, andsubsequently computes thelatency to
thatserver along withthemaximal bandwidth. Initssimplest configuration, Glo-
buleassumes thatthelatency between thereplica server andtherequesting user
machine isnegligible, andlikewise thatbandwidth between thetwoisplentiful.
Onceenough requests forapagehavebeencollected, theorigin server per-
forms asimple "what-if analysis." Suchananalysis boilsdown toevaluating sev-
eralreplication policies, where apolicy describes where aspecific pageisrepli-
cated to,andhowthatpageiskeptconsistent. Eachreplication policy incurs a
costthatcanbeexpressed asasimple linear function:
cost=(W1 xm1)+(w2xm2)+ ...+(wnxmn)
where mk denotes aperformance metric andWkistheweight indicating howim-
portant thatmetric is.Typical performance metrics aretheaggregated delays be-
tween aclient andareplica server whenreturning copies ofWebpages, thetotal
consumed bandwidth between theorigin server andareplica server forkeeping a
replica consistent, andthenumber ofstalecopies thatare(allowed tobe)returned
toaclient (Pierre etaI.,2002).
Forexample, assume thatthetypical delaybetween thetimeaclient Cissues
arequest andwhen thatpageisreturned fromthebestreplica server isdems.
Notethatwhatthebestreplica server is,isdetermined byareplication policy. Let
m1denote theaggregated delay overagiven timeperiod, thatis,m1=Lde.If
theorigin server wants tooptimize client-perceived latency, itwillchoose arela-
tively highvalue forWi-Asaconsequence, onlythose policies thatactually
minimize m1willshowtohaverelatively lowcosts.
InGlobule, anorigin server regularly evaluates afewtensofreplication pol-
icesusing atrace-driven simulation, foreachWebpageseparately. From these
simulations, abestpolicy isselected andsubsequently enforced. Thismayimply
thatnewreplicas areinstalled atdifferent edgeservers, orthatadifferent wayof
keeping replicas consistent ischosen. Thecollecting oftraces, theevaluation of
replication policies, andtheenforcement ofaselected policy isalldoneautomati-
cally.
There areanumber ofsubtle issues thatneedtobedealtwith.Foronething,
itisunclear howmany requests needtobecollected before anevaluation ofthe
current policy cantakeplace. Toexplain, suppose thatattimeT;theorigin server
selects policy pforthenextperiod until'Ii+I' Thisselection takesplace based on
aseries ofpastrequests thatwereissued between 'Ii-1and'Ii.Ofcourse, inhind-
sightattime'1i+I, theserver maycome totheconclusion thatitshould have
selected policy p*given theactual requests thatwereissued between 'Iiand'Ii+I.
Ifp*isdifferent fromp,thentheselection ofpat'Iiwaswrong.
Asitturnsout,thepercentage ofwrong predictions isdependent onthelength
oftheseries ofrequests (called thetracelength) thatareusedtopredict andselectSEC. 2.4 SELF-MANAGEMENT INDISTRIBUTED SYSTEMS65
Figure 2-19. Thedependency between prediction accuracy andtracelength.
anextpolicy. Thisdependency issketched inFig.2-19. What isseenisthatthe
errorinpredicting thebestpolicy goesupifthetraceisnotlongenough. Thisis
easily explained bythefactthatweneedenough requests todoaproper evalua-
tion.However, theerroralsoincreases ifweusetoomany requests. Thereason
forthisisthataverylongtracelength captures somany changes inaccess pat-
ternsthatpredicting thebestpolicy tofollow becomes difficult, ifnotimpossible.
Thisphenomenon iswellknown andisanalogous totrying topredict theweather
fortomorrow bylooking atwhathappened during theimmediately preceding 100
years. Amuch better prediction canbemade byjustlooking onlyattherecent
past.
Finding theoptimal tracelength canbedoneautomatically aswell.Weleave
itasanexercise tosketch asolution tothisproblem.
2.404 Example: Automatic Component Repair Management inJade
When maintaining clusters ofcomputers, eachrunning sophisticated servers,
itbecomes important toalleviate management problems. Oneapproach thatcan
beapplied toservers thatarebuiltusingacomponent-based approach, istodetect
component failures andhavethemautomatically replaced. TheJadesystem fol-
lowsthisapproach (Bouchenak etal.,2005). Wedescribe itbriefly inthissec-
tion.
JadeisbuiltontheFractal component model, aJavaimplementation ofa
framework thatallows components tobeadded andremoved atruntime (Bruneton
etal.,2004). Acomponent inFractal canhavetwotypesofinterfaces. Aserver
interface isusedtocallmethods thatareimplemented bythatcomponent. Acli-
entinterface isusedbyacomponent tocallothercomponents. Components are
connected toeachotherbybinding interfaces. Forexample, aclient interface of
component C1canbebound totheserver interface ofcomponent C2'Aprimitive
binding means thatacalltoaclient interface directly leadstocalling thebounded66 ARCHITECTURES CHAP. 2
server interface. Inthecaseofcomposite binding, thecallmayproceed through
oneormoreothercomponents, forexample, because theclient andserver inter-
facedidnotmatch andsomekindofconversion isneeded. Another reason maybe
thattheconnected components lieondifferent machines.
Jadeusesthenotion ofarepair management domain. Suchadomain con-
sistsofanumber ofnodes, where eachnoderepresents aserver along withthe
components thatareexecuted bythatserver. There isaseparate nodemanager
which isresponsible foradding andremoving nodes fromthedomain. Thenode
manager maybereplicated forassuring highavailability.
Eachnodeisequipped withfailure detectors, which monitor thehealth ofa
nodeoroneofitscomponents andreport anyfailures tothenodemanager. Typi-
cally, thesedetectors consider exceptional changes inthestateofcomponent, the
usage ofresources, andtheactual failure ofacomponent. Notethatthelattermay
actually meanthatamachine hascrashed.
When afailure hasbeendetected, arepair procedure isstarted. Suchaproce-
dureisdriven byarepair policy, partly executed bythenodemanager. Policies
arestated explicitly andarecarried outdepending onthedetected failure. Forex-
ample, suppose anodefailure hasbeendetected. Inthatcase,therepair policy
mayprescribe thatthefollowing stepsaretobecarried out:
1.Terminate every binding between acomponent onanonfaulty node,
andacomponent onthenodethatjustfailed.
2.Request thenodemanager tostartandaddanewnodetothedomain.
3.Configure thenewnodewithexactly thesamecomponents asthose
onthecrashed node.
4.Re-establish allthebindings thatwerepreviously terminated.
Inthisexample, therepair policy issimple andwillonlyworkwhen nocru-
cialdatahasbeenlost(thecrashed components aresaidtobestateless).
Theapproach followed byJadeisanexample ofself-management: uponthe
detection ofafailure, arepair policy isautomatically executed tobringthesystem
asawhole intoastateinwhich itwasbefore thecrash. Being acomponent-based
system, thisautomatic repair requires specific support toallow components tobe
added andremoved atruntime. Ingeneral, turning legacy applications intoself-
managing systems isnotpossible.
2.5SUMMARY
Distributed systems canbeorganized inmany different ways. Wecanmake a
distinction between software architecture andsystem architecture. Thelattercon-
siders where thecomponents thatconstitute adistributed system areplaced acrossSEC. 2.5 SUMMARY 67
thevarious machines. Theformer ismore concerned about thelogical organiza-
tionofthesoftware: howdocomponents interact, itwhatways cantheybestruc-
tured, howcantheybemade independent, andsoon.
Akeyideawhen talking about architectures isarchitectural style. Astyle
reflects thebasic principle thatisfollowed inorganizing theinteraction between
thesoftware components comprising adistributed system. Important styles
include layering, object orientation, event orientation, anddata-space orientation.
There aremany different organizations ofdistributed systems. Animportant
class iswhere machines aredivided intoclients andservers. Aclient sends are-
quest toaserver, whowillthenproduce aresult thatisreturned totheclient. The
client-server architecture reflects thetraditional wayofmodularizing software in
which amodule callsthefunctions available inanother module. Byplacing dif-
ferent components ondifferent machines, weobtain anatural physical distribution
offunctions across acollection ofmachines.
Client-server architectures areoften highly centralized. Indecentralized archi-
tectures weoften seeanequal roleplayed bytheprocesses thatconstitute adis-
tributed system, alsoknown aspeer-to-peer systems. Inpeer-to-peer systems, the
processes areorganized intoanoverlay network, which isalogical network in
which every process hasalocal listofother peers thatitcancommunicate with.
Theoverlay network canbestructured, inwhich casedeterministic schemes can
bedeployed forrouting messages between processes. Inunstructured networks,
thelistofpeers ismore orlessrandom, implying thatsearch algorithms needtobe
deployed forlocating dataorother processes.
Asanalternative, self-managing distributed systems have been developed.
These systems, toanextent, merge ideas from system andsoftware architectures.
Self-managing systems canbegenerally organized asfeedback-control loops.
Such loops contain amonitoring component bythebehavior ofthedistributed sys-
temismeasured, ananalysis component toseewhether anything needs tobe
adjusted, andacollection ofvarious instruments forchanging thebehavior.
Feedback -control loops canbeintegrated intodistributed systems atnumerous
places. Much research isstillneeded before acommon understanding howsuch
loops suchbedeveloped anddeployedis reached.
PROBLEMS
1.Ifaclient andaserver areplaced farapart, wemayseenetwork latency dominating
overall performance. Howcanwetackle thisproblem?
2.Whatisathree-tiered client-server architecture?
3.Whatisthedifference between avertical distribution andahorizontal distribution?68 ARCHITECTURES CHAP. 2
4.Consider achain ofprocesses PhP2,...,Pnimplementing amultitiered client-server
architecture. Process Piisclient ofprocess Pi+J, andPiwillreturn areply toPi-I only
afterreceiving areply fromPi+1• What arethemainproblems withthisorganization
when taking alookattherequest-reply performance atprocess PI?
5.Inastructured overlay network, messages arerouted according tothetopology ofthe
overlay. What isanimportant disadvantage ofthisapproach?
6.Consider theCAN network fromFig.2-8.Howwould youroute amessage fromthe
nodewithcoordinates (0.2,0.3) totheonewithcoordinates (0.9,0.6)?
7.Considering thatanode inCAN knows thecoordinates ofitsimmediate neighbors, a
reasonable routing policy would betoforward amessage totheclosest nodetoward
thedestination. Howgoodisthispolicy?
8.Consider anunstructured overlay network inwhich eachnode randomly chooses c
neighbors. IfPandQarebothneighbors ofR,whatistheprobability thattheyare
alsoneighbors ofeachother?
9.Consider again anunstructured overlay network inwhich every node randomly
chooses cneighbors. Tosearch forafile,anodefloods arequest toitsneighbors and
requests those toflood therequest oncemore. Howmany nodes willbereached?
10.Notevery nodeinapeer-to-peer network should become superpeer. What arereason-
ablerequirements thatasuperpeer should meet?
11.Consider aBitTorrent system inwhich each node hasanoutgoing linkwith a
bandwidth capacity Bout andanincoming linkwithbandwidth capacity Bin' Some of
these nodes (called seeds) voluntarily offerfilestobedownloaded byothers. What is
themaximum download capacity ofaBitTorrent client ifweassume thatitcancon-
tactatmostoneseedatatime?
12.Giveacompelling (technical) argument whythetit-for-tat policy asusedinBitTorrent
isfarfromoptimal forfilesharing intheInternet.
13.Wegavetwoexamples ofusing interceptors inadaptive middleware. What other ex-
amples come tomind?
14.Towhat extent areinterceptors dependent onthemiddle ware where they are
deployed?
15.Modem carsarestuffed withelectronic devices. Give some examples offeedback
control systems incars.
16.Giveanexample ofaself-managing system inwhich theanalysis component iscom-
pletely distributed orevenhidden.
17.Sketch asolution toautomatically determine thebesttracelength forpredicting repli-
cation policies inGlobule.
18.(Lab assignment) Using existing software, design andimplement aBitTorrent-based
system fordistributing filestomany clients fromasingle, powerful server. Matters are
simplified byusing astandard Webserver thatcanoperate astracker.3
PROCESSES
Inthischapter, wetakeacloser lookathowthedifferent typesofprocesses
playa crucial roleindistributed systems. Theconcept ofaprocess originates from
thefieldofoperating systems where itisgenerally defined asaprogram inexecu-
tion.From anoperating-system perspective, themanagement andscheduling of
processes areperhaps themostimportant issues todealwith.However, when it
comes todistributed systems, otherissues tumouttobeequally ormoreimpor-
tant.
Forexample, toefficiently organize client-server systems, itisoften con-
venient tomake useofmultithreading techniques. Aswediscuss inthefirstsec-
tion,amaincontribution ofthreads indistributed systems isthattheyallow clients
andservers tobeconstructed suchthatcommunication andlocalprocessing can
overlap, resulting inahighlevelofperformance.
Inrecent years, theconcept ofvirtualization hasgained popularity. Virtualiza-
tionallows anapplication, andpossibly alsoitscomplete environment including
theoperating system, torunconcurrently withotherapplications, buthighly in-
dependent oftheunderlying hardware andplatforms, leading toahighdegree of
portability. Moreover, virtualization helpsinisolating failures caused byerrors or
security problems. Itisanimportant concept fordistributed systems, andwepay
attention toitinaseparate section.
Asweargued inChap. 2,client-server organizations areimportant indistrib-
utedsystems. Inthischapter, wetakeacloser lookattypical organizations ofboth
clients andservers. Wealsopayattention togeneral design issues forservers.
6970 PROCESSES CHAP. 3
Animportant issue, especially inwide-area distributed systems, ismoving
processes between different machines. Process migration ormore specifically,
codemigration, canhelpinachieving scalability, butcanalsohelptodynamically
configure clients andservers. Whatisactually meant bycodemigration andwhat
itsimplications areisalsodiscussed inthischapter.
3.1THREADS
Although processes formabuilding block indistributed systems, practice
indicates thatthegranularity ofprocesses asprovided bytheoperating systems on
which distributed systems arebuiltisnotsufficient. Instead, itturnsoutthathav-
ingafinergranularity intheformofmultiple threads ofcontrol perprocess makes
itmuch easier tobuilddistributed applications andtoattain better performance. In
thissection, wetakeacloser lookattheroleofthreads indistributed systems and
explain whytheyaresoimportant. Moreonthreads andhowtheycanbeusedto
buildapplications canbefound inLewis andBerg(998) andStevens (1999).
3.1.1Introduction toThreads
Tounderstand theroleofthreads indistributed systems, itisimportant to
understand whataprocess is,andhowprocesses andthreads relate. Toexecute a
program, anoperating system creates anumber ofvirtual processors, eachonefor
running adifferent program. Tokeeptrackofthesevirtual processors, theoperat-
ingsystem hasaprocess table,containing entries tostoreCPUregister values,
memory maps, openfiles,accounting information. privileges, etc.Aprocess is
oftendefined asaprogram inexecution, thatis,aprogram thatiscurrently being
executed ononeoftheoperating system's virtual processors. Animportant issue
isthattheoperating system takesgreatcaretoensure thatindependent processes
cannot maliciously orinadvertently affect thecorrectness ofeachother's behav-
ior.Inotherwords, thefactthatmultiple processes maybeconcurrently sharing
thesameCPUandotherhardware resources ismade transparent. Usually, theop-
erating system requires hardware support toenforce thisseparation.
Thisconcurrency transparency comes atarelatively highprice. Forexample,
eachtimeaprocess iscreated, theoperating system mustcreate acomplete
independent address space. Allocation canmeaninitializing memory segments by,
forexample, zeroing adatasegment, copying theassociated program intoatext
segment, andsetting upastackfortemporary data.Likewise, switching theCPU
between twoprocesses mayberelatively expensive aswell.Apart fromsaving the
CPUcontext (which consists ofregister values, program counter, stackpointer,
etc.), theoperating system willalsohavetomodify registers ofthememory
management unit(MMU) andinvalidate address translation caches suchasinthe
translation lookaside buffer (TLB). Inaddition, iftheoperating system supportsSEC. 3.1 THREADS 71
moreprocesses thanitcansimultaneously holdinmainmemory, itmayhaveto
swapprocesses between mainmemory anddiskbefore theactual switch cantake
place.
Likeaprocess, athread executes itsownpiece ofcode, independently from
otherthreads. However, incontrast toprocesses, noattempt ismadetoachieve a
highdegree ofconcurrency transparency ifthiswould result inperformance de-
gradation. Therefore, athread system generally maintains onlytheminimum in-
formation toallow aCPUtobeshared byseveral threads. Inparticular, athread
context often consists ofnothing morethantheCPUcontext, along withsome
otherinformation forthread management. Forexample, athread system maykeep
trackofthefactthatathread iscurrently blocked onamutex variable, soasnotto
select itforexecution. Information thatisnotstrictly necessary tomanage multi-
plethreads isgenerally ignored. Forthisreason, protecting dataagainst inap-
propriate access bythreads within asingle process isleftentirely toapplication
developers.
There aretwoimportant implications ofthisapproach. Firstofall,theperfor-
mance ofamultithreaded application needhardly everbeworse thanthatofits
single-threaded counterpart. Infact,inmany cases, multithreading leadstoaper-
formance gain.Second, because threads arenotautomatically protected against
eachotherthewayprocesses are,development ofmultithreaded applications re-
quires additional intellectual effort. Proper design andkeeping things simple, as
usual, helpalot.Unfortunately, current practice doesnotdemonstrate thatthis
principle isequally wellunderstood.
Thread Usage inNondistributed Systems
Before discussing theroleofthreads indistributed systems, letusfirstconsid-
ertheirusage intraditional, nondistributed systems. There areseveral benefits to
multithreaded processes thathaveincreased thepopularity ofusing thread sys-
tems.
i'nemost1:m-poron\ \)e'i\'tl\\ \.~'m.'t~ \'i.\)\\\ ~\~\ \\\.~\ \.~~~\.~¥,t~-t.N~d ~t()C-
ess.~l1.~~~'l:~~ a.l:1lQ.c.kiu.~ &'!&tem callisexecuted. tileQrocess asawriore is
MocKea'. 10Illustrate, corrsrirer Jff <1flfllic«ti<Jt7 s~k cZScZs~e.2dshc>e! prOgE.wlJ, a,mj
asscattc tkat« «sercootioUOllS)Y.:md lZ;!cEacJ)ve)y w..avts JD!'.b.ange values, Anim-
portant property ofaspreadsheet program isthatItmaintains theruncnonai
dependencies between different cells, oftenfromdifferent spreadsheets. There-
fore,whenever acellismodified, alldependent cellsareautomatically updated.
When auserchanges thevalue inasingle cell,suchamodification cantrigger a
largeseries ofcomputations. Ifthereisonlyasingle thread ofcontrol, computa-
tioncannot proceed whiletheprogram iswaiting forinput. Likewise, itisnoteasy
toprovide inputwhile dependencies arebeing calculated. Theeasysolution isto
haveatleasttwothreads ofcontrol: oneforhandling interaction withtheuserandPROCESSES
oneforupdating thespreadsheet. Inthemean time,athirdthread could beused
forbacking upthespreadsheet todiskwhiletheothertwoaredoing theirwork.
Another advantage ofmultithreading isthatitbecomes possible toexploit
parallelism when executing theprogram onamultiprocessor system. Inthatcase,
eachthread isassigned toadifferent CPUwhile shared dataarestored inshared
mainmemory. When properly designed, suchparallelism canbetransparent: the
process willrunequally wellonauniprocessor system, albeit slower. Multi-
threading forparallelism isbecoming increasingly important withtheavailability
ofrelatively cheap multiprocessor workstations. Suchcomputer systems aretypi-
callyusedforrunning servers inclient-server applications.
Multithreading isalsouseful inthecontext oflargeapplications. Suchappli-
cations areoftendeveloped asacollection ofcooperating programs, eachtobe
executed byaseparate process. Thisapproach istypical foraUNIX environment.
Cooperation between programs isimplemented bymeans ofinterprocess commu-
nication (IPC) mechanisms. ForUNIX systems, these mechanisms typically in-
clude (named) pipes, message queues, andshared memory segments [seealso
Stevens andRago (2005)]. Themajor drawback ofallIPCmechanisms isthat
communication often requires extensive context switching, shown atthree dif-
ferent points inFig.3-1.
Figure 3-1.Context switching astheresult ofIPC.
Because IPCrequires kernel intervention, aprocess willgenerally firsthave
toswitch fromusermode tokernel mode, shown asS1inFig.3-1.Thisrequires
changing thememory mapintheMMU, aswellasflushing theTLB. Within the
kernel, aprocess context switch takesplace (52inthefigure), afterwhich the
otherpartycanbeactivated byswitching fromkernel mode tousermode again
(53inFig.3-1). Thelatter switch again requires changing theMMU mapand
flushing theTLB.
Instead ofusingprocesses, anapplication canalsobeconstructed suchthatdif-
ferent partsareexecuted byseparate threads. Communication between thosepartsCHAP. 372SEC. 3.1 THREADS 73
isentirely dealtwithbyusing shared data.Thread switching cansometimes be
doneentirely inuserspace, although inotherimplementations, thekernel isaware
ofthreads andschedules them. Theeffect canbeadramatic improvement inper-
formance.
Finally, thereisalsoapuresoftware engineering reason tousethreads: many
applications aresimply easier tostructure asacollection ofcooperating threads.
Think ofapplications thatneedtoperform several (more orlessindependent)
tasks. Forexample, inthecaseofawordprocessor, separate threads canbeused
forhandling userinput, spelling andgrammar checking, document layout, index
generation, etc.
ThreadImplementation
Threads areoftenprovided intheformofathread package. Suchapackage
contains operations tocreate anddestroy threads aswellasoperations onsyn-
chronization variables suchasmutexes andcondition variables. There arebasi-
callytwoapproaches toimplement athread package. Thefirstapproach istocon-
struct athread library thatisexecuted entirely inusermode. Thesecond approach
istohavethekernel beaware ofthreads andschedule them.
Auser-level thread library hasanumber ofadvantages. First, itischeap to
create anddestroy threads. Because allthread administration iskeptintheuser's
address space, thepriceofcreating athread isprimarily determined bythecost
forallocating memory tosetupathread stack. Analogously, destroying athread
mainly involves freeing memory forthestack, which isnolonger used.Bothoper-
ations arecheap.
Asecond advantage ofuser-level threads isthatswitching thread context can
oftenbedoneinjustafewinstructions. Basically, onlythevalues oftheCPUreg-
isters needtobestored andsubsequently reloaded withthepreviously stored
values ofthethread towhich itisbeing switched. There isnoneedtochange
memory maps, flushtheTLB, doCPUaccounting, andsoon.Switching thread
context isdonewhen twothreads needtosynchronize, forexample, when enter-
ingasection ofshared data.
However, amajor drawback ofuser-level threads isthatinvocation ofa
blocking system callwillimmediately blocktheentire process towhich thethread
belongs, andthusalsoalltheother threads inthatprocess. Asweexplained,
threads areparticularly useful tostructure largeapplications intopartsthatcould
belogically executed atthesametime.Inthatcase,blocking onI/Oshould not
prevent otherpartstobeexecuted inthemeantime. Forsuchapplications, user-
levelthreads areofnohelp.
These problems canbemostly circumvented byimplementing threads inthe
operating system's kernel. Unfortunately, thereisahighpricetopay:every thread
operation (creation, deletion, synchronization, etc.),willhavetobecarried outby74 PROCESSES CHAP. 3
thekernel. requiring asystem call.Switching thread contexts maynowbecome as
expensive asswitching process contexts. Asaresult, mostoftheperformance
benefits ofusingthreads instead ofprocesses thendisappears.
Asolution liesinahybrid formofuser-level andkernel-level threads, gener-
allyreferred toaslightweight processes (LWP). AnLWPrunsinthecontext of
asingle (heavy-weight) process, andtherecanbeseveral LWPsperprocess. In
addition tohaving LWPs, asystem alsooffers auser-level thread package. offer-
ingapplications theusual operations forcreating anddestroying threads. Inaddi-
tion.thepackage provides facilities forthread synchronization. suchasmutexes
andcondition variables. Theimportant issueisthatthethread package isimple-
mented entirely inuserspace. Inotherwords. alloperations onthreads arecarried
outwithout intervention ofthekernel.
Figure 3-2.Combining kernel-level lightweight processes anduser-level threads.
Thethread package canbeshared bymultiple LWPs, asshown inFig.3-2.
Thismeans thateachLWPcanberunning itsown(user-level) thread. Multi-
threaded applications areconstructed bycreating threads, andsubsequently as-
signing eachthread toanLWP.Assigning athread toanLWPisnormally impli-
citandhidden fromtheprogrammer.
Thecombination of(user-level) threads andL\VPsworks asfollows. The
thread package hasasingle routine toschedule thenextthread. When creating an
LWP(which isdonebymeans ofasystem call),theLWPisgiven itsownstack,
andisinstructed toexecute thescheduling routine insearch ofathread toexecute.
Ifthereareseveral LWPs, theneachofthemexecutes thescheduler. Thethread
table, which isusedtokeeptrackofthecurrent setofthreads, isthusshared by
theLWPs.Protecting thistabletoguarantee mutually exclusive access isdoneby
means ofmutexes thatareimplemented entirely inuserspace. Inother words,
synchronization between LWPsdoesnotrequire anykernel support.
When anLWPfinds arunnable thread, itswitches context tothatthread.
Meanwhile, otherLWPsmaybelooking forotherrunnable threads aswell.IfaSEC. 3.1 THREADS 75
thread needs toblock onamutex orcondition variable, itdoesthenecessary
administration andeventually callsthescheduling routine. 'When another runnable
thread hasbeenfound, acontext switch ismade tothatthread. Thebeauty ofall
thisisthattheLWPexecuting thethread neednotbeinformed: thecontext switch
isimplemented completely inuserspace andappears totheLWPasnormal pro-
gramcode.
Nowletusseewhathappens when athread doesablocking system call.In
thatcase,execution changes fromusermode tokernel mode. butstillcontinues in
thecontext ofthecurrent LWP.Atthepointwhere thecurrent LWPcannolonger
continue, theoperating system maydecide toswitch context toanother LWP,
which alsoimplies thatacontext switch ismadebacktousermode. Theselected
LWPwillsimply continue where ithadpreviously leftoff.
There areseveral advantages tousingLWPsincombination withauser-level
thread package. First,creating, destroying, andsynchronizing threads isrelatively
cheap andinvolves nokernel intervention atall.Second, provided thataprocess
hasenough LWPs, ablocking system callwillnotsuspend theentire process.
Third, thereisnoneedforanapplication toknow about theLWPs.Allitseesare
user-level threads. Fourth, LWPs canbeeasily usedinmultiprocessing environ-
ments, byexecuting different LWPsondifferent CPUs. Thismultiprocessing can
behidden entirely fromtheapplication. Theonlydrawback oflightweight proc-
essesincombination withuser-level threads isthatwestillneedtocreate anddes-
troyLWPs, which isjustasexpensive aswithkernel-level threads. However,
creating anddestroying LWPsneeds tobedoneonlyoccasionally, andisoften
fullycontrolled bytheoperating system.
Analternative, butsimilar approach tolightweight processes, istomake use
ofscheduler activations (Anderson etal.,1991). Themostessential difference
between scheduler activations andLWPsisthatwhenathread blocks onasystem
call,thekernel doesanupcall tothethread package, effectively calling the
scheduler routine toselect thenextrunnable thread. Thesame procedure isre-
peated when athread isunblocked. Theadvantage ofthisapproach isthatitsaves
management ofLWPsbythekernel. However, theuseofupcalls isconsidered
lesselegant, asitviolates thestructure oflayered systems, inwhich callsonlyto
thenextlower-level layerarepermitted.
3.1.2 Threads inDistributed Systems
Animportant property ofthreads isthattheycanprovide aconvenient means
ofallowing blocking system callswithout blocking theentire process inwhich the
thread isrunning. Thisproperty makes threads particularly attractive touseindis-
tributed systems asitmakes itmuch easier toexpress communication intheform
ofmaintaining multiple logical connections atthesametime. Weillustrate this
pointbytaking acloser lookatmultithreaded clients andservers, respectively.76 PROCESSES CHAP.3
Multithreaded Clients
Toestablish ahighdegree ofdistribution transparency, distributed systems
thatoperate inwide-area networks mayneedtoconceal longinterprocess mes-
sagepropagation times. Theround-trip delayinawide-area network caneasily be
intheorderofhundreds ofmilliseconds. orsometimes evenseconds.
Theusualwaytohidecommunication latencies istoinitiate communication
andimmediately proceed withsomething else.Atypical example where thishap-
pensisinWebbrowsers. Inmany cases, aWebdocument consists ofanHTML
filecontaining plaintextalong withacollection ofimages, icons, etc.Tofetch
eachelement ofaWebdocument, thebrowser hastosetupaTCPIIP connection,
readtheincoming data,andpassittoadisplay component. Setting upaconnec-
tionaswellasreading incoming dataareinherently blocking operations. When
dealing withlong-haul communication, wealsohavethedisadvantage thatthe
timeforeachoperation tocomplete mayberelatively long.
AWebbrowser oftenstartswithfetching theHTML pageandsubsequently
displays it.Tohidecommunication latencies asmuch aspossible, somebrowsers
startdisplaying datawhile itisstillcoming in.While thetextismade available to
theuser,including thefacilities forscrolling andsuch,thebrowser continues with
fetching otherfilesthatmake upthepage, suchastheimages. Thelatteraredis-
played astheyarebrought in.Theuserneedthusnotwaituntilallthecomponents
oftheentire pagearefetched before thepageismade available.
Ineffect, itisseenthattheWebbrowser isdoing anumber oftaskssimul-
taneously. Asitturnsout,developing thebrowser asamultithreaded client simpli-
fiesmatters considerably. AssoonasthemainHTML filehasbeenfetched, sepa-
ratethreads canbeactivated totakecareoffetching theotherparts. Eachthread
setsupaseparate connection totheserver andpullsinthedata.Setting upacon-
nection andreading datafromtheserver canbeprogrammed using thestandard
(blocking) system calls, assuming thatablocking calldoesnotsuspend theentire
process. Asisalsoillustrated inStevens (1998), thecodeforeachthread isthe
sameand,above all,simple. Meanwhile, theusernotices onlydelays inthedis-
playofimages andsuch,butcanotherwise browse through thedocument.
There isanother important benefit tousing multithreaded Webbrowsers in
which several connections canbeopened simultaneously. Intheprevious ex-
ample, several connections weresetuptothesameserver. Ifthatserver isheavily
loaded, orjustplain slow, norealperformance improvements willbenoticed
compared topulling inthefilesthatmakeupthepagestrictly oneaftertheother.
However, inmany cases, Webservers havebeenreplicated across multiple
machines, where eachserver provides exactly thesame setofWebdocuments.
Thereplicated servers arelocated atthesamesite,andareknown under thesame
name. When arequest foraWebpagecomes in,therequest isforwarded toone
oftheservers, often using around-robin strategy orsome other load-balancing
technique (Katzetal.,1994). When usingamultithreaded client, connections maySEC. 3.1 THREADS 77
besetuptodifferent replicas, allowing datatobetransferred inparallel, effec-
tively establishing thattheentire Webdocument isfullydisplayed inamuch
shorter timethanwithanonreplicated server. Thisapproach ispossible onlyifthe
client canhandle trulyparallel streams ofincoming data.Threads areidealforthis
purpose.
~ultithreaded Servers
Although thereareimportant benefits tomultithreaded clients, aswehave
seen,themainuseofmultithreading indistributed systems isfound attheserver
side.Practice shows thatmultithreading notonlysimplifies server codeconsid-
erably, butalsomakes itmuch easier todevelop servers thatexploit parallelism to
attain highperformance, evenonuniprocessor systems. However, nowthatmulti-
processor computers arewidely available asgeneral-purpose workstations, multi-
threading forparallelism isevenmoreuseful.
Tounderstand thebenefits ofthreads forwriting server code, consider the
organization ofafileserver thatoccasionally hastoblock waiting forthedisk.
Thefileserver normally waitsforanincoming request forafileoperation, subse-
quently carries outtherequest, andthensends backthereply. Onepossible, and
particularly popular organization isshown inFig.3-3.Hereonethread, the
dispatcher, readsincoming requests forafileoperation. Therequests aresentby
clients toawell-known endpointforthisserver. Afterexamining therequest, the
server chooses anidle(i.e.,blocked) workerthreadandhands ittherequest.
Figure 3-3.Amultithreaded server organized inadispatcher/worker model.
Theworker proceeds byperforming ablocking readonthelocal filesystem,
which maycause thethread tobesuspended untilthedataarefetched fromdisk.
Ifthethread issuspended, another thread isselected tobeexecuted. Forexample,
thedispatcher maybeselected toacquire more work. Alternatively, another
worker thread canbeselected thatisnowreadytorun.78 CHAP. 3 PROCESSES
Nowconsider howthefileserver might havebeenwritten intheabsence of
threads. Onepossibility istohaveitoperate asasingle thread. Themainloopof
thefileserver getsarequest, examines it,andcarries itouttocompletion before
getting thenextone.While waiting forthedisk,theserver isidleanddoesnot
process anyotherrequests. Consequently, requests fromother clients cannot be
handled. Inaddition, ifthefileserver isrunning onadedicated machine, asis
commonly thecase,theCPUissimply idlewhile thefileserver iswaiting forthe
disk.Thenetresult isthatmany fewer requests/sec canbeprocessed. Thus
threads gainconsiderable performance, buteachthread isprogrammed sequen-
tially, intheusualway.
Sofarwehaveseentwopossible designs: amultithreaded fileserver anda
single-threaded fileserver. Suppose thatthreads arenotavailable butthesystem
designers findtheperformance lossduetosingle threading unacceptable. Athird
possibility istoruntheserver asabigfinite-state machine. When arequest comes
in,theoneandonlythread examines it.Ifitcanbesatisfied fromthecache, fine,
butifnot,amessage mustbesenttothedisk.
However, instead ofblocking, itrecords thestateofthecurrent request ina
tableandthengoesandgetsthenextmessage. Thenextmessage mayeither bea
request fornewworkorareplyfromthediskabout aprevious operation. Ifitis
newwork, thatworkisstarted. Ifitisareplyfromthedisk,therelevant informa-
tionisfetched fromthetableandthereplyprocessed andsubsequently senttothe
client. Inthisscheme, theserver willhavetomake useofnonblocking callsto
send andreceive.
Inthisdesign, the"sequential process" model thatwehadinthefirsttwo
casesislost.Thestateofthecomputation mustbeexplicitly saved andrestored in
thetableforevery message sentandreceived. Ineffect, wearesimulating threads
andtheirstacks thehardway.Theprocess isbeing operated asafinite-state ma-
chinethatgetsaneventandthenreacts toit,depending onwhatisinit.
Figure 3-4.Three waystoconstruct aserver.
Itshould nowbeclearwhatthreads havetooffer. Theymake itpossible to
retain theideaofsequential processes thatmake blocking system calls(e.g.,an
RPCtotalktothedisk)andstillachieve parallelism. Blocking system callsmake
programming easier andparallelism improves performance. Thesingle-threaded
server retains theeaseandsimplicity ofblocking system calls,butgivesupsomeSEC. 3.1 THREADS 79
amount ofperformance. Thefinite-state machine approach achieves highperfor-
mance through parallelism, butusesnonblocking calls, thusishardtoprogram.
These models aresummarized inFig.3-4.
3.2VIRTUALIZATION
Threads andprocesses canbeseenasawaytodomorethings atthesame
time.Ineffect, theyallowusbuild(pieces of)programs thatappear tobeexecuted
simultaneously. Onasingle-processor computer, thissimultaneous execution is,
ofcourse, anillusion. Asthereisonlyasingle CPU, onlyaninstruction froma
single thread orprocess willbeexecuted atatime.Byrapidly switching between
threads andprocesses, theillusion ofparallelism iscreated.
Thisseparation between having asingle CPUandbeing abletopretend there
aremorecanbeextended tootherresources aswell,leading towhatisknown as
resource virtualization. Thisvirtualization hasbeenapplied formany decades,
buthasreceived renewed interest as(distributed) computer systems havebecome
more commonplace andcomplex, leading tothesituation thatapplication soft-
wareismostly always outliving itsunderlying systems software andhardware. In
thissection, wepaysomeattention totheroleofvirtualization anddiscuss howit
canberealized.
3.2.1 TheRoleofVirtualization inDistributed Systems
Inpractice, every (distributed) computer system offers aprogramming inter-
facetohigher levelsoftware, asshown inFig.3-5(a). There aremany different
typesofinterfaces, ranging fromthebasicinstruction setasoffered byaCPUto
thevastcollection ofapplication programming interfaces thatareshipped with
manycurrent middleware systems. Initsessence, virtualization dealswithextend-
ingorreplacing anexisting interface soastomimic thebehavior ofanother sys-
tem,asshown inFig.3-5(b). Wewillcome todiscuss technical details onvir-
tualization shortly, butletusfirstconcentrate onwhyvirtualization isimportant
fordistributed systems.
Oneofthemostimportant reasons forintroducing virtualization inthe1970s,
wastoallow legacy software torunonexpensive mainframe hardware. Thesoft-
warenotonlyincluded various applications, butinfactalsotheoperating systems
theyweredeveloped for.Thisapproach toward supporting legacy software has
beensuccessfully applied ontheIBM370mainframes (andtheirsuccessors) that
offered avirtual machine towhich different operating systems hadbeenported.
Ashardware became cheaper, computers became more powerful, andthe
number ofdifferent operating system flavors wasreducing, virtualization became
lessofanissue. However, matters havechanged again sincethelate1990s for
several reasons, which wewillnowdiscuss.80 PROCESSES CHAP. 3
Figure 3-5.(a)General organization between aprogram, interface, andsystem.
(b)General organization ofvirtualizing system Aontopofsystem B.
First,while hardware andlow-level systems software change reasonably fast,
software athigher levels ofabstraction (e.g.,middleware andapplications), are
muchmorestable. Inotherwords, wearefacing thesituation thatlegacy software
cannot bemaintained inthesamepaceastheplatforms itrelies on.Virtualization
canhelpherebyporting thelegacy interfaces tothenewplatforms andthusim-
mediately opening upthelatterforlargeclasses ofexisting programs.
Equally important isthefactthatnetworking hasbecome completely per-
vasive. Itishardtoimagine thatamodern computer isnotconnected toanet-
work. Inpractice, thisconnectivity requires thatsystem administrators maintain a
largeandheterogeneous collection ofserver computers, eachonerunning very
different applications, which canbeaccessed byclients. Atthesametimethevar-
iousresources should beeasily accessible totheseapplications. Virtualization can
helpalot:thediversity ofplatforms andmachines canbereduced byessentially
letting eachapplication runonitsownvirtual machine, possibly including the
related libraries andoperating system, which, inturn,runonacommon platform.
Thislasttypeofvirtualization provides ahighdegree ofportability andflexi-
bility. Forexample, inorder torealize content delivery networks thatcaneasily
support replication ofdynamic content, Awadallah andRosenblum (2002) argue
thatmanagement becomes much easier ifedgeservers would support virtuali-
zation, allowing acomplete site,including itsenvironment tobedynamically
copied. Aswewilldiscuss later, itisprimarily suchportability arguments that
makevirtualization animportant mechanism fordistributed systems.
3.2.2Architectures ofVirtualMachines
There aremany different waysinwhich virtualization canberealized inprac-
tice.Anoverview ofthese various approaches isdescribed bySmith andNair
(2005). Tounderstand thedifferences invirtualization, itisimportant torealizeSEC. 3.2 VIRTUALIZATION 81
thatcomputer systems generally offerfourdifferent types ofinterfaces, atfour
different levels:
1.Aninterface between thehardware andsoftware, consisting ofma-
chine instructions thatcanbeinvoked byanyprogram.
2.Aninterface between thehardware andsoftware, consisting ofma-
chine instructions thatcanbeinvoked onlybyprivileged programs,
suchasanoperating system.
3.Aninterface consisting ofsystem callsasoffered byanoperating
system.
4.Aninterface consisting oflibrary calls, generally forming whatis
known asanapplication programming interface (API). Inmany
cases, theaforementioned system callsarehidden byanAPI.
These different types areshown inFig.3-6.Theessence ofvirtualization isto
mimic thebehavior oftheseinterfaces.
Figure 3-6.Various interfaces offered bycomputer systems.
Virtualization cantakeplaceintwodifferent ways. First,wecanbuildarun-
timesystem thatessentially provides anabstract instruction setthatistobeused
forexecuting applications. Instructions canbeinterpreted (asisthecaseforthe
Javaruntime environment), butcould alsobeemulated asisdoneforrunning
Windows applications onUNIX platforms. Notethatinthelattercase,theemula-
torwillalsohavetomimic thebehavior ofsystem calls, which hasproven tobe
generally farfromtrivial. Thistypeofvirtualization leadstowhatSmith andNair
(2005) callaprocess virtual machine, stressing thatvirtualization isdoneessen-
tiallyonlyforasingle process.
Analternative approach toward virtualization istoprovide asystem thatis
essentially implemented asalayercompletely shielding theoriginal hardware, but
offering thecomplete instruction setofthatsame(orotherhardware) asaninter-
face.Crucial isthefactthatthisinterface canbeoffered simultaneously todif-
ferent programs. Asaresult, itisnowpossible tohavemultiple, anddifferent82 PROCESSES CHAP. 3
operating systems runindependently andconcurrently onthesameplatform. The
layerisgenerally referred toasavirtualmachine monitor(VMM). Typical ex-
amples ofthisapproach areVMware (Sugerman etal.,200I)andXen(Barham et
at,2003). These twodifferent approaches areshown inFig.3-7.
Figure 3-7.(a)Aprocess virtual machine, withmultiple instances of(applica-
tion,runtime) combinations. (b)Avirtual machine monitor. withmultiple in-
stances of(applications, operating system) combinations.
Asargued byRosenblum andGarfinkel (2005), VMMs willbecome increas-
inglyimportant inthecontext ofreliability andsecurity for(distributed) systems.
Astheyallow fortheisolation ofacomplete application anditsenvironment, a
failure caused byanerrororsecurity attack neednolonger affect acomplete ma-
chine. Inaddition, aswealsomentioned before, portability isgreatly improved as
VMMs provide afurther decoupling between hardware andsoftware, allowing a
complete environment tobemoved fromonemachine toanother.
3.3CLIENTS
Intheprevious chapters wediscussed theclient-server modeL therolesofcli-
entsandservers, andthewaystheyinteract. Letusnowtakeacloser lookatthe
anatomy ofclients andservers, respectively. Westartinthissection withadiscus-
sionofclients. Servers arediscussed inthenextsection.
3.3.1Networked UserInterfaces
Amajor taskofclient machines istoprovide themeans foruserstointeract
withremote servers. There areroughly twowaysinwhich thisinteraction canbe
supported. First,foreachremote service theclient machine willhaveaseparate
counterpart thatcancontact theservice overthenetwork. Atypical example isan
agenda running onauser's PDAthatneeds tosynchronize witharemote, possiblySEC. 3.3 CLIENTS 83
shared agenda. Inthiscase, anapplication-level protocol willhandle thesyn-
chronization, asshown inFig.3-8(a).
Figure 3-8.(a)Anetworked application withitsownprotocol. (b)Ageneral
solution toallow access toremote applications.
Asecond solution istoprovide direct access toremote services byonlyoffer-
ingaconvenient userinterface. Effectively, thismeans thattheclient machine is
usedonlyasaterminal withnoneedforlocalstorage, leading toanapplication-
neutral solution asshown inFig.3-8(b). Inthecaseofnetworked userinterfaces,
everything isprocessed andstored attheserver. Thisthin-client approach is
receiving moreattention asInternet connectivity increases, andhand-held devices
arebecoming moresophisticated. Asweargued intheprevious chapter, thin-cli-
entsolutions arealsopopular astheyeasethetaskofsystem management. Letus
takealookathownetworked userinterfaces canbesupported.
Example: TheXWindow System
Perhaps oneoftheoldest andstillwidely-used networked userinterfaces is
theXWindow system. TheXWindow System, generally referred tosimply as
X,isusedtocontrol bit-mapped terminals, which include amonitor, keyboard,
andapointing device suchasamouse. Inasense, Xcanbeviewed asthatpartof
anoperating system thatcontrols theterminal. Theheartofthesystem isformed
bywhatweshallcalltheXkernel. Itcontains alltheterminal-specific device
drivers, andassuch,isgenerally highly hardware dependent.
TheXkernel offers arelatively low-level interface forcontrolling thescreen,
butalsoforcapturing events fromthekeyboard andmouse. Thisinterface ismade
available toapplications asalibrary called Xlib. Thisgeneral organization is
shown inFig.3-9.
Theinteresting aspect ofXisthattheXkernel andtheXapplications need
notnecessarily reside onthesamemachine. Inparticular, Xprovides theXproto-
col,which isanapplication-level communication protocol bywhich aninstance of
Xlib canexchange dataandevents withtheXkernel. Forexample, Xlib cansend84 PROCESSES CHAP. 3
Figure 3-9.Thebasic organization oftheXWindow System.
requests totheXkernel forcreating orkilling awindow, setting colors, anddefin-
ingthetypeofcursor todisplay, among many otherrequests. Inturn,theXkernel
willreacttolocalevents suchaskeyboard andmouse inputbysending event
packets backtoXlib.
Several applications cancommunicate atthesame timewiththeXkernel.
There isonespecific application thatisgiven special rights, known asthewin-
dowmanager. Thisapplication candictate the"look andfeel"ofthedisplay as
itappears totheuser.Forexample, thewindow manager canprescribe howeach
window isdecorated withextrabuttons, howwindows aretobeplaced onthedis-
play,andso.Other applications willhavetoadhere totheserules.
Itisinteresting tonotehowtheXwindow system actually fitsintoclient-
server computing. Fromwhatwehavedescribed sofar,itshould beclearthatthe
Xkernel receives requests tomanipulate thedisplay. Itgetstheserequests from
(possibly remote) applications. Inthissense, theXkernel actsasaserver, while
theapplications playtheroleofclients. Thisterminology hasbeenadopted byX,
andalthough strictly speaking iscorrect, itcaneasily leadtoconfusion.
Thin-Client Network Computing
Obviously, applications manipulate adisplay using thespecific display com-
mands asoffered byX.These commands aregenerally sentoverthenetwork
where theyaresubsequently executed bytheXkernel. Byitsnature, applications
written forXshould preferably separate application logic from user-interface
commands. Unfortunately, thisisoftennotthecase.Asreported byLaiandNieh
(2002), itturnsoutthatmuch oftheapplication logic anduserinteraction are
tightly coupled, meaning thatanapplication willsendmanyrequests totheXker-
nelforwhich itwillexpect aresponse before being abletomake anextstep.ThisSEC. 3.3 CLIENTS
synchronous behavior mayadversely affect performance when operating overa
wide-area network withlonglatencies.
There areseveral solutions tothisproblem. Oneistore-engineer theimple-
mentation oftheXprotocol, asisdonewithNX(Pinzari, 2003). Animportant
partofthisworkconcentrates onbandwidth reduction bycompressing Xmes-
sages. First,messages areconsidered toconsist ofafixedpart,which istreated as
anidentifier, andavariable part.Inmany cases, multiple messages willhavethe
sameidentifier inwhich casetheywilloftencontain similar data.Thisproperty
canbeusedtosendonlythedifferences between messages having thesameiden-
tifier.
Boththesending andreceiving sidemaintain alocalcache ofwhich theen-
triescanbelooked upusing theidentifier ofamessage. When amessage issent,
itisfirstlooked upinthelocalcache. Iffound, thismeans thataprevious mes-
sagewiththesameidentifier butpossibly different datahadbeensent.Inthat
case,differential encoding isusedtosendonlythedifferences between thetwo.
Atthereceiving side,themessage isalsolooked upinthelocalcache, afterwhich
decoding through thedifferences cantakeplace. Inthecache miss, standard
compression techniques areused, which generally already leads tofactor four
improvement inbandwidth. Overall, thistechnique hasreported bandwidth reduc-
tionsuptoafactor 1000,which allows Xtoalsorunthrough low-bandwidth links
ofonly9600kbps.
Animportant sideeffect ofcaching messages isthatthesender andreceiver
haveshared information onwhatthecurrent status ofthedisplay is.Forexample,
theapplication canrequest geometric information onvarious objects bysimply re-
questing lookups inthelocalcache. Having thisshared information alonealready
reduces thenumber ofmessages required tokeeptheapplication andthedisplay
synchronized.
Despite theseimprovements, Xstillrequires having adisplay server running.
Thismaybeasking alot,especially ifthedisplay issomething assimple asacell
phone. Onesolution tokeeping thesoftware atthedisplay verysimple istoletall
theprocessing takeplaceattheapplication side.Effectively, thismeans thatthe
entire display iscontrolled uptothepixellevelattheapplication side.Changes in
thebitmap arethensentoverthenetwork tothedisplay, where theyareim-
mediately transferred tothelocalframe buffer.
Thisapproach requires sophisticated compression techniques inorder to
prevent bandwidth availability tobecome aproblem. Forexample, consider dis-
playing avideo stream atarateof30frames persecond ona320x240screen.
Suchascreen sizeiscommon formany PDAs. Ifeachpixelisencoded by24bits,
thenwithout compression wewould needabandwidth ofapproximately 53Mbps.
Compression isclearly needed insuchacase,andmany techniques arecurrently
being deployed. Note, however, thatcompression requires decompression atthe
receiver, which, inturn,maybecomputationally expensive without hardware sup-
port.Hardware support canbeprovided, butthisraises thedevices cost.86 PROCESSES CHAP. 3
Thedrawback ofsending rawpixeldataincomparison tohigher-level proto-
colssuchasXisthatitisimpossible tomakeanyuseofapplication semantics, as
theseareeffectively lostatthatlevel. Baratto eta1.(2005) propose adifferent
technique. Intheirsolution, referred toasTHINC, theyprovide afewhigh-level
display commands thatoperate atthelevelofthe video device drivers. These com-
mands arethusdevice dependent, morepowerful thanrawpixeloperations, but
lesspowerful compared towhataprotocol suchasXoffers. Theresult isthatdis-
playservers canbemuch simpler, which isgoodforCPUusage, while atthe
sametimeapplication-dependent optimizations canbeusedtoreduce bandwidth
andsynchronization.
InTHINC, display requests fromtheapplication areintercepted andtransla-
tedintothelower levelcommands. Byintercepting application requests, THINe
canmakeuseofapplication semantics todecide whatcombination oflower level
commands canbeusedbest.Translated commands arenotimmediately sentout
tothedisplay, butareinstead queued. Bybatching several commands itispos-
sibletoaggregate display commands intoasingle one,leading tofewer messages.
Forexample, when anewcommand fordrawing inaparticular region ofthe
screen effectively overwrites whataprevious (andstillqueued) command would
haveestablished, thelatterneednotbesentouttothedisplay. Finally, instead of
letting thedisplay askforrefreshments, THINC always pushes updates asthey
come available. Thispushapproach saves latency asthere isnoneedforan
update request tobesentoutbythedisplay.
Asitturnsout,theapproach followed byTHINC provides better overall per-
formance, although verymuch inlinewiththatshown byNX.Details onperfor-
mance comparison canbefound inBaratto eta1.(2005).
Compound Documents
Modem userinterfaces doalotmorethansystems suchasXoritssimple ap-
plications. Inparticular, many userinterfaces allow applications toshareasingle
graphical window, andtousethatwindow toexchange datathrough useractions.
Additional actions thatcanbeperformed bytheuserinclude whataregenerally
called drag-and-drop operations, andin-place editing, respectively.
Atypical example ofdrag-and-drop functionality ismoving aniconrepres-
enting afileAtoaniconrepresenting atrashcan,resulting inthefilebeing
deleted. Inthiscase,theuserinterface willneedtodomore thanjustarrange
iconsonthedisplay: itwillhavetopassthename ofthefileAtotheapplication
associated withthetrashcanassoonasA'siconhasbeenmoved above thatofthe
trashcanapplication. Other examples easily cometomind.
In-place editing canbestbeillustrated bymeans ofadocument containing
textandgraphics. Imagine thatthedocument isbeing displayed within astandard
wordprocessor. Assoonastheuserplaces themouse above animage, theuserin-
terface passes thatinformation toadrawing program toallow theusertomodifySEC. 3.3 CLIENTS87
theimage. Forexample, theusermayhaverotated theimage, which mayeffect
theplacement oftheimage inthedocument. Theuserinterface therefore findsout
whatthenewheight andwidth oftheimage are,andpasses thisinformation tothe
wordprocessor. Thelatter, intum,canthenautomatically update thepagelayout
ofthedocument.
Thekeyideabehind theseuserinterfaces isthenotion ofacompound docu-
ment, which canbedefined asacollection ofdocuments, possibly ofverydif-
ferent kinds(liketext,images, spreadsheets, etc.),which areseamlessly integrated
attheuser-interface level. Auserinterface thatcanhandle compound documents
hides thefactthatdifferent applications operate ondifferent partsofthedocu-
ment. Totheuser,allpartsareintegrated inaseamless way.When changing one
partaffects otherparts, theuserinterface cantakeappropriate measures, forex-
ample, bynotifying therelevant applications.
Analogous tothesituation described fortheXWindow System, theapplica-
tionsassociated withacompound document donothavetoexecute ontheclient's
machine. However, itshould beclearthatuserinterfaces thatsupport compound
documents mayhavetodoalotmoreprocessing thanthosethatdonot.
3.3.2 Client-Side Software forDistribution Transparency
Client software comprises morethanjustuserinterfaces. Inmany cases, parts
oftheprocessing anddatalevelinaclient-server application areexecuted onthe
client sideaswell.Aspecial classisformed byembedded client software, suchas
forautomatic tellermachines (ATMs), cashregisters, barcode readers, TVset-top
boxes, etc.Inthesecases, theuserinterface isarelatively small partoftheclient
software, incontrast tothelocalprocessing andcommunication facilities.
Besides theuserinterface andotherapplication-related software, client soft-
warecomprises components forachieving distribution transparency. Ideally, acli-
entshould notbeaware thatitiscommunicating withremote processes. Incon-
trast,distribution isoften lesstransparent toservers forreasons ofperformance
andcorrectness. Forexample, inChap. 6wewillshow thatreplicated servers
sometimes needtocommunicate inorder toestablish thatoperations areper-
formed inaspecific orderateachreplica.
Access transparency isgenerally handled through thegeneration ofaclient
stubfromaninterface definition ofwhattheserver hastooffer. Thestubprovides
thesameinterface asavailable attheserver, buthidesthepossible differences in
machine architectures, aswellastheactual communication.
There aredifferent waystohandle location, migration, andrelocation tran-
sparency. Using aconvenient naming system iscrucial, asweshallalsoseeinthe
nextchapter. Inmany cases, cooperation withclient-side software isalsoimpor-
tant.Forexample, when aclient isalready bound toaserver, theclient canbe
directly informed whentheserver changes location. Inthiscase,theclient's mid-
dleware canhidetheserver's current geographical location fromtheuser,and88 PROCESSES CHAP. 3
alsotransparently rebind totheserver ifnecessary. Atworst, theclient's applica-
tionmaynotice atemporary lossofperformance.
Inasimilar way,many distributed systems implement replication transpar-
encybymeans ofclient-side solutions. Forexample, imagine adistributed system
withreplicated servers, Suchreplication canbeachieved byforwarding arequest
toeachreplica, asshown inFig.3-10. Client-side software cantransparently col-
lectallresponses andpassasingle response totheclient application.
Figure 3-10. Transparent replication ofaserver using aclient-side solution.
Finally, consider failure transparency. Masking communication failures witha
server istypically donethrough client middleware. Forexample, client middle-
warecanbeconfigured torepeatedly attempt toconnect toaserver, orperhaps try
another server afterseveral attempts. There areevensituations inwhich theclient
middleware returns dataithadcached during aprevious session, asissometimes
donebyWebbrowsers thatfailtoconnect toaserver.
Concurrency transparency canbehandled through special intermediate ser-
vers,notably transaction monitors, andrequires lesssupport fromclient software.
Likewise, persistence transparency isoftencompletely handled attheserver.
3.4SERVERS
Letusnowtakeacloser lookattheorganization ofservers. Inthefollowing
pages, wefirstconcentrate onanumber ofgeneral design issues forservers, tobe
followed byadiscussion ofserver clusters.
3.4.1 General Design Issues
Aserver isaprocess implementing aspecific service onbehalf ofacollection
ofclients. Inessence, eachserver isorganized inthesameway:itwaits foran
incoming request fromaclient andsubsequently ensures thattherequest istaken
careof,afterwhich itwaitsforthenextincoming request.SEC. 3.4 SERVERS 89
There areseveral waystoorganize servers. Inthecaseofaniterative server,
theserver itselfhandles therequest and,ifnecessary, returns aresponse tothere-
questing client. Aconcurrent server doesnothandle therequest itself, butpasses
ittoaseparate thread oranother process, afterwhich itimmediately waitsforthe
nextincoming request. Amultithreaded server isanexample ofaconcurrent
server. Analternative implementation ofaconcurrent server istoforkanewproc-
essforeachnewincoming request. Thisapproach isfollowed inmany UNIX sys-
tems.Thethread orprocess thathandles therequest isresponsible forreturning a
response totherequesting client.
Another issueiswhere clients contact aserver. Inallcases, clients sendre-
quests toanendpoint, alsocalled aport,atthemachine where theserver isrun-
ning.Eachserver listens toaspecific endpoint. Howdoclients know theend
pointofaservice? Oneapproach istoglobally assign endpoints forwell-known
services. Forexample, servers thathandle Internet FTPrequests always listen to
TCPport21.Likewise, anHTTP server fortheWorld Wide Webwillalways
listen toTCPport80.These endpoints havebeenassigned bytheInternet
Assigned Numbers Authority (lANA), andaredocumented inReynolds andPos-
tel(1994). Withassigned endpoints, theclient onlyneeds tofindthenetwork ad-
dress ofthemachine where theserver isrunning. Asweexplain inthenext
chapter, name services canbeusedforthatpurpose.
There aremany services thatdonotrequire apreassigned endpoint. Forex-
ample, atime-of-day server mayuseanendpointthatisdynamically assigned to
it9Yitslocaloperating system. Inthatcase,aclient willfirsthavetolookupthe
endpoint. Onesolution istohaveaspecial daemon running oneachmachine that
runsservers. Thedaemon keeps trackofthecurrent endpointofeachservice im-
plemented byaco-located server. Thedaemon itselflistens toawell-known end
point. Aclient willfirstcontact thedaemon, request theendpoint, andthenc~m-
tactthespecific server, asshown inFig.3-11(a).
Itiscommon toassociate anendpointwithaspecific service. However, actu-
allyimplementing eachservice bymeans ofaseparate server maybeawaste of
resources. Forexample, inatypical UNIX system, itiscommon tohavelotsof
servers running simultaneously, withmostofthempassively waiting untilaclient
request comes in.Instead ofhaving tokeeptrackofsomany passive processes, it
isoftenmoreefficient tohaveasingle superserver listening toeachendpointas-
sociated withaspecific service, asshown inFig.3-1l(b). Thisistheapproach
taken, forexample, withtheinetd daemon inUNIX. Inetd listens toanumber of
well-known portsforInternet services. When arequest comes in,thedaemon
forksaprocess totakefurther careoftherequest. Thatprocess willexitafteritis
finished.
Another issuethatneeds tobetaken intoaccount when designing aserver is
whether andhowaserver canbeinterrupted. Forexample, consider auserwho
hasjustdecided toupload ahugefiletoanFTPserver. Then, suddenly realizing
thatitisthewrong file,hewants tointerrupt theserver tocancel further data90 PROCESSES CHAP. 3
Figure 3-11. (a)Client-to-server binding using adaemon. (b)Client-to-server
binding using asuperserver.
transmission. There areseveral ways todothis.Oneapproach thatworks onlytoo
wellinthecurrent Internet (andissometimes theonlyalternative) isfortheuser
toabruptly exittheclient application (which willautomatically break theconnec-
tiontotheserver), immediately restart it,andpretend nothing happened. Theser-
verwilleventually teardown theoldconnection, thinking theclient hasprobably
crashed.
Amuch better approach forhandling communication interrupts istodevelop
theclient andserver suchthatitispossible tosendout-of-band data, which is
datathatis·tobeprocessed bytheserver before anyother datafrom thatclient.
Onesolution istolettheserver listen toaseparate control endpoint towhich the
client sends out-of-band data,while atthesame timelistening (with alower prior-
ity)totheendpoint through which thenormal datapasses. Another solution isto
send out-of-band dataacross thesame connection through which theclient is
sending theoriginal request. InTCP, forexample, itispossible totransmit urgent
data. When urgent dataarereceived attheserver, thelatter isinterrupted (e.g.•
through asignal inUNIX systems), afterwhich itcaninspect thedataandhandle
them accordingly.
Afinal, important design issue, iswhether ornottheserver isstateless. A
stateless server does notkeep information onthestate ofitsclients, andcan
change itsownstatewithout having toinform anyclient (Birman, 2005). AWebSEC. 3.4 SERVERS 91
server, forexample, isstateless. Itmerely responds toincoming HTTP requests,
which canbeeither foruploading afiletotheserver or(most often) forfetching a
file.When therequest hasbeenprocessed, theWebserver forgets theclient com-
pletely. Likewise, thecollection offilesthataWebserver manages (possibly in
cooperation withafileserver), canbechanged without clients having tobein-
formed. .
Notethatinmany stateless designs, theserver actually doesmaintain infor-
mation onitsclients, butcrucial isthefactthatifthisinformation islost,itwill
notleadtoadisruption oftheservice offered bytheserver. Forexample, aWeb
server generally logsallclient requests. Thisinformation isuseful, forexample, to
decide whether certain documents should bereplicated, andwhere theyshould be
replicated to.Clearly, thereisnopenalty otherthanperhaps intheformofsubop-
timalperformance ifthelogislost.
Aparticular formofastateless design iswhere theserver maintains whatis
known assoftstate. Inthiscase,theserver promises tomaintain stateonbehalf
oftheclient, butonlyforalimited time.After thattimehasexpired, theserver
fallsbacktodefault behavior, thereby discarding anyinformation itkepton
account oftheassociated client. Anexample ofthistypeofstateisaserver
promising tokeepaclient informed about updates, butonlyforalimited time.
After that,theclient isrequired topolltheserver forupdates. Soft-state ap-
proaches originate fromprotocol design incomputer networks, butcanbeequally
applied toserver design (Clark, 1989;andLuietal.,2004).
Incontrast, astateful server generally maintains persistent information onits
clients. Thismeans thattheinformation needs tobeexplicitly deleted bythe
server. Atypical example isafileserver thatallows aclient tokeepalocalcopy
ofafile,evenforperforming update operations. Suchaserver would maintain a
tablecontaining (client, file) entries. Suchatableallows theserver tokeeptrack
ofwhich client currently hastheupdate permissions onwhich file,andthuspossi-
blyalsothemostrecent version ofthatfile.
Thisapproach canimprove theperformance ofreadandwriteoperations as
perceived bytheclient. Performance improvement overstateless servers isoften
animportant benefit ofstateful designs. However, theexample alsoillustrates the
major drawback ofstateful servers. Iftheserver crashes, ithastorecover itstable
of(client, file) entries, orotherwise itcannot guarantee thatithasprocessed the
mostrecent updates onafile.Ingeneral, astateful server needs torecover itsen-
tirestateasitwasjustbefore thecrash. Aswediscuss inChap. 8,enabling
recovery canintroduce considerable complexity. Inastateless design, nospecial
measures needtobetaken atallforacrashed server torecover. Itsimply starts
running again, andwaitsforclient requests tocomein.
Lingetal.(2004) argue thatoneshould actually make adistinction between
(temporary) session stateandpermanent state.Theexample above istypical for
session state: itisassociated withaseries ofoperations byasingle userand
should bemaintained forasometime,butnotindefinitely. Asitturnsout,session92 PROCESSES CHAP. 3
stateisoften maintained inthree-tiered client-server architectures, where theap-
plication server actually needs toaccess adatabase server through aseries of
queries before being abletorespond totherequesting client. Theissue hereisthat
norealharm isdoneifsession stateislost,provided thattheclient cansimply re-
issue theoriginal request. Thisobservation allows forsimpler andlessreliable
storage ofstate.
What remains forpermanent stateistypically information maintained indata-
bases, such ascustomer information, keys associated withpurchased software,
etc.However, formostdistributed systems, maintaining session statealready im-
plies astateful design requiring special measures when failures dohappen and
making explicit assumptions about thedurability ofstatestored attheserver. We
willreturn tothese matters extensively when discussing faulttolerance.
When designing aserver, thechoice forastateless orstateful design should
notaffect theservices provided bytheserver. Forexample, iffileshave tobe
opened before theycanbereadfrom, orwritten to,thenastateless server should
onewayortheother mimic thisbehavior. Acommon solution, which wediscuss
inmore detail inChap. 11.isthattheserver responds toareadorwrite request by
firstopening thereferred file,thendoestheactual readorwrite operation, andim-
mediately closes thefileagain.
Inother cases, aserver maywant tokeep arecord onaclient's behavior so
thatitcanmore effectively respond toitsrequests. Forexample, Web servers
sometimes offerthepossibility toimmediately direct aclient tohisfavorite pages.
Thisapproach ispossible onlyiftheserver hashistory information onthatclient.
When theserver cannot maintain state, acommon solution isthentolettheclient
sendalong additional information onitsprevious accesses. InthecaseoftheWeb,
thisinformation isoften transparently stored bytheclient's browser inwhat is
called acookie, which isasmall piece ofdatacontaining client-specific informa-
tionthatisofinterest totheserver. Cookies arenever executed byabrowser; they
aremerely stored.
Thefirsttimeaclient accesses aserver, thelatter sends acookie along with
therequested Web pages back tothebrowser, after which thebrowser safely
tucks thecookie away. Each subsequent timetheclient accesses theserver, its
cookie forthatserver issentalong withtherequest. Although inprinciple, thisap-
proach works fine, thefactthatcookies aresentback forsafekeeping bythe
browser isoften hidden entirely fromusers. Somuch forprivacy. Unlike most of
grandma's cookies, these cookies should staywhere theyarebaked.
3.4.2ServerClusters
InChap. 1webriefly discussed cluster computing asoneofthemany appear-
ances ofdistributed systems. Wenowtakeacloser lookattheorganization of
server clusters, along withthesalient design issues.SEC. 3.4 SERVERS
General Organization93
Simply put,aserver cluster isnothing elsebutacollection ofmachines con-
nected through anetwork, where eachmachine runsoneormore servers. The
server clusters thatweconsider here,aretheonesinwhich themachines arecon-
nected through alocal-area network, often offering highbandwidth andlow
latency.
Inmostcases, aserver cluster islogically organized intothreetiers,asshown
inFig.3-12. Thefirsttierconsists ofa(logical) switch through which client re-
quests arerouted. Suchaswitch canvarywidely. Forexample, transport-layer
switches accept incoming TCPconnection requests andpassrequests ontooneof
servers inthecluster, aswediscuss below. Acompletely different example isa
Webserver thataccepts incoming HTTP requests, butthatpartly passes requests
toapplication servers forfurther processing onlytolatercollect results andreturn
anHTTP response.
Figure 3-12. Thegeneral organization ofathree-tiered server cluster.
Asinanymultitiered client-server architecture, many server clusters alsocon-
tainservers dedicated toapplication processing. Incluster computing, theseare
typically servers running onhigh-performance hardware dedicated todelivering
compute power. However, inthecaseofenterprise server clusters, itmaybethe
casethatapplications needonlyrunonrelatively low-end machines, asthere-
quired compute power isnotthebottleneck, butaccess tostorage is.
Thisbrings usthethirdtier,which consists ofdata-processing servers, notably
fileanddatabase servers. Again, depending ontheusage oftheserver cluster,
theseservers mayberunning anspecialized machines, configured forhigh-speed
diskaccess andhaving largeserver-side datacaches.
Ofcourse, notallserver clusters willfollow thisstrictseparation. Itisfre-
quently thecasethateachmachine isequipped withitsownlocalstorage, often94 PROCESSES CHAP. 3
integrating application anddataprocessing inasingle server leading toatwo-
tiered architecture. Forexample, when dealing withstreaming media bymeans of
aserver cluster, itiscommon todeploy atwo-tiered system architecture, where
eachmachine actsasadedicated media server (Steinmetz andNahrstedt, 2004).
When aserver cluster offers multiple services, itmayhappen thatdifferent
machines rundifferent application servers. Asaconsequence, theswitch will
havetobeabletodistinguish services orotherwise itcannot forward requests to
theproper machines. Asitturnsout,many second-tier machines runonlyasingle
application. Thislimitation comes fromdependencies onavailable software and
hardware, butalsothatdifferent applications areoftenmanaged bydifferent ad-
ministrators. Thelatterdonotliketointerfere witheachother's machines.
Asaconsequence, wemayfindthatcertain machines aretemporarily idle,
while others arereceiving anoverload ofrequests. What would beuseful isto
temporarily migrate services toidlemachines. Asolution proposed inAwadallah
andRosenblum (2004), istousevirtual machines allowing arelative easymigra-
tionofcodetorealmachines. Wewillreturn tocodemigration laterinthis
chapter.
Letustakeacloser lookatthefirsttier,consisting oftheswitch. Animpor-
tantdesign goalforserver clusters istohidethefactthattherearemultiple ser-
vers.Inotherwords, client applications running onremote machines should have
noneedtoknow anything about theinternal organization ofthecluster. Thisac-
cesstransparency isinvariably offered bymeans ofasingle access point, inturn
implemented through somekindofhardware switch suchasadedicated machine.
Theswitch forms theentrypointfortheserver cluster, offering asingle net-
workaddress. Forscalability andavailability, aserver cluster mayhavemultiple
access points, where eachaccess point isthenrealized byaseparate dedicated
machine. Weconsider onlythecaseofasingle access point.
Astandard wayofaccessing aserver cluster istosetupaTCPconnection
overwhich application-level requests arethensentaspartofasession. Asession
endsbytearing downtheconnection. Inthecaseoftransport-layer switches, the
switch accepts incoming TCPconnection requests, andhands offsuchconnec-
tionstooneoftheservers (Hunt etal,1997; andPaietal.,1998). Theprinciple
working ofwhatiscommonly known asTCPhandoff isshown inFig.3-13.
When theswitch receives aTCPconnection request, itsubsequently identifies
thebestserver forhandling thatrequest, andforwards therequest packet tothat
server. Theserver, inturn,willsendanacknowledgment backtotherequesting
client. butinserting theswitch's IPaddress asthesource fieldoftheheader ofthe
IPpacket carrying theTCPsegment. Notethatthisspoofing isnecessary forthe
client tocontinue executing theTCPprotocol: itisexpecting ananswer backfrom
theswitch, notfromsomearbitrary server itishasnever heard ofbefore. Clearly,
aTCP-handoff implementation requires operating-system levelmodifications.
Itcanalready beseenthattheswitch canplayanimportant roleindistributing
theloadamong thevarious servers. Bydeciding where toforward arequest to,theSEC. 3.4 SERVERS 95
Figure 3-13. Theprinciple ofTCP handoff.
switch alsodecides which server istohandle further processing oftherequest.
Thesimplest load-balancing policy thattheswitch canfollow isround robin: each
timeitpicksthenextserver fromitslisttoforward arequest to.
More advanced server selection criteria canbedeployed aswell.Forexample,
assume multiple services areoffered bytheserver cluster. Iftheswitch candistin-
guishthoseservices when arequest comes in,itcanthentakeinformed decisions
onwhere toforward therequest to.Thisserver selection canstilltakeplaceatthe
transport level, provided services aredistinguished bymeans ofaportnumber.
Onestepfurther istohavetheswitch actually inspect thepayload oftheincoming
request. Thismethod canbeapplied onlyifitisknown whatthatpayload canlook
like.Forexample, inthecaseofWebservers, theswitch caneventually expect an
HTTP request, based onwhich itcanthendecide whoistoprocess it.Wewillre-
turntosuchcontent-aware request distribution when wediscuss Web-based
systems inChap. 12.
Distributed Servers
Theserver clusters discussed sofararegenerally rather statically configured.
Inthese clusters, there isoften anseparate administration machine thatkeeps
track ofavailable servers, andpasses thisinformation toother machines as
appropriate, suchastheswitch.
Aswementioned, mostserver clusters offerasingle access point. When that
pointfails,thecluster becomes unavailable. Toeliminate thispotential problem,
several access points canbeprovided, ofwhich theaddresses aremade publicly
available. Forexample, theDomain Name System (DNS) canreturn several ad-
dresses, allbelonging tothesamehostname. Thisapproach stillrequires clients
tomake several attempts ifoneoftheaddresses fails.Moreover, thisdoesnot
solvetheproblem ofrequiring staticaccess points.96 PROCESSES CHAP. 3
Having stability, likealong-living access point, isadesirable feature froma
client's andaserver's perspective. Ontheotherhand, italsodesirable tohavea
highdegree offlexibility inconfiguring aserver cluster, including theswitch.
Thisobservation hasleadtoadesign ofadistributed server which effectively is
nothing butapossibly dynamically changing setofmachines, withalsopossibly
varying access points, butwhich nevertheless- appears totheoutside world asa
single. powerful machine. Thedesign ofsuchadistributed server isgiven inSzy-
maniak etal.(2005). Wedescribe itbriefly here.
Thebasicideabehind adistributed server isthatclients benefit fromarobust,
high-performing, stable server. These properties canoftenbeprovided byhigh-
endmainframes, ofwhich somehaveanacclaimed mean timebetween failure of
morethan40years. However, bygrouping simpler machines transparently intoa
cluster, andnotrelying ontheavailability ofasingle machine, itmaybepossible
toachieve abetter degree ofstability thanbyeachcomponent individually. For
example, suchacluster could bedynamically configured fromend-user machines,
asinthecaseofacollaborative distributed system.
Letusconcentrate onhowastable access pointcanbeachieved insuchasys-
tem.Themainideaistomake useofavailable networking services, notably
mobility support forIPversion 6(MIPv6). InMIPv6, amobile nodeisassumed to
haveahome network where itnormally resides andforwhich ithasanassoci-
atedstable address, known asitshome address (HoA). Thishome network hasa
special router attached, known asthehome agent, which willtakecareoftraffic
tothemobile nodewhen itisaway. Tothisend,whenamobile nodeattaches toa
foreign network, itwillreceive atemporary care-of address (CoA) where itcan
bereached. Thiscare-of address isreported tothenode's home agent whowill
thenseetoitthatalltraffic isforwarded tothemobile node. Notethatapplica-
tionscommunicating withthemobile nodewillonlyseetheaddress associated
withthenode's home network. Theywillnever seethecare-of address.
Thisprinciple canbeusedtoofferastable address ofadistributed server. In
thiscase,asingle unique contact address isinitially assigned totheserver clus-
ter.Thecontact address willbetheserver's life-time address tobeusedinall
communication withtheoutside world. Atanytime,onenodeinthedistributed
server willoperate asanaccess pointusingthatcontact address, butthisrolecan
easily betaken overbyanother node. What happens isthattheaccess point
records itsownaddress asthecare-of address atthehome agent associated with
thedistributed server. Atthatpoint, alltraffic willbedirected totheaccess point,
whowillthentakecareindistributing requests among thecurrently participating
nodes. Iftheaccess pointfails,asimple fail-over mechanism comes intoplace by
which another access pointreports anewcare-of address.
Thissimple configuration would make thehome agent aswellastheaccess
pointapotential bottleneck asalltraffic would flowthrough thesetwomachines.
Thissituation canbeavoided byusinganMIPv6 feature known asrouteoptimize-
tion.Route optimization works asfollows. Whenever amobile nodewithhomeSEC. 3.4 SERVERS 97
address HA reports itscurrent care-of address, sayCA, thehorne agent canfor-
wardCAtoaclient. Thelatter willthenlocally storethepair(HA, CAY· From
thatmoment on,communication willbedirectly forwarded toCA. Although the
application attheclient sidecanstillusethehorne address, theunderlying support
software forMIPv6 willtranslate thataddress toCAandusethatinstead.
Figure 3-14. Route optimization inadistributed server.
Route optimization canbeusedtomake different clients believe theyare
communicating withasingle server, where, infact,eachclient iscommunicating
withadifferent member nodeofthedistributed server, asshown inFig.3-14. To
thisend,when anaccess pointofadistributed server forwards arequest fromcli-
entC1to,saynodeS1(withaddress CA1)'itpasses enough information toS1to
letitinitiate theroute optimization procedure bywhich eventually theclient is
made tobelieve thatthecare-of address isCAr-Thiswillallow C1tostorethe
pair(HA, CA1)'During thisprocedure, theaccess point(aswellasthehorne.
agent) tunnel mostofthetraffic between C1andSr-Thiswillprevent thehorne
agentfrombelieving thatthecare-of address haschanged, sothatitwillcontinue
tocommunicate withtheaccess point.
Ofcourse, while thisrouteoptimization procedure istaking place, requests
fromotherclients maystillcornein.These remain inapending stateattheaccess
pointuntiltheycanbeforwarded. Therequest fromanother client C2maythenbe
forwarded tomember nodeS2(withaddress CA2),allowing thelattertoletclient98 PROCESSES CHAP. 3
Czstorethepair(HA, CA2). Asaresult, different clients willbedirectly com-
municating withdifferent members ofthedistributed server, where eachclient ap-
plication stillhastheillusion thatthisserver hasaddress HA. Thehome agent
continues tocommunicate withtheaccess pointtalking tothecontact address.
3.4.3Managing ServerClusters
Aserver cluster should appear totheoutside world asasingle computer, asis
indeed oftenthecase.However, when itcomes tomanaging acluster, thesitua-
tionchanges dramatically. Several attempts havebeenmade toeasethemanage-
mentofserver clusters aswediscuss next.
Common Approaches
Byfarthemostcommon approach tomanaging aserver cluster istoextend
thetraditional managing functions ofasingle computer tothatofacluster. Inits
mostprimitive form, thismeans thatanadministrator canlogintoanodefroma
remote client andexecute localmanaging commands tomonitor, install, and
change components.
Somewhat moreadvanced istohidethefactthatyouneedtologinintoanode
andinstead provide aninterface atanadministration machine thatallows tocol-
lectinformation fromoneormoreservers, upgrade components, addandremove
nodes, etc.Themainadvantage ofthelatterapproach isthatcollective operations,
which operate onagroup ofservers, canbemoreeasily provided. Thistypeof
managing server clusters iswidely applied inpractice, exemplified bymanage-
mentsoftware suchasCluster Systems Management fromIBM(Hochstetler and
Beringer, 2004).
However, assoonasclusters growbeyond several tensofnodes, thistypeof
management isnotthewaytogo.Many datacenters needtomanage thousands of
servers, organized intomany clusters butalloperating collaboratively. Doing this
bymeans ofcentralized administration servers issimply outofthequestion.
Moreover, itcanbeeasily seenthatverylargeclusters needcontinuous repair
management (including upgrades). Tosimplify matters, ifpistheprobability that
aserver iscurrently faulty, andweassume thatfaults areindependent, thenfora
cluster ofNservers tooperate without asingle server being faulty is(l_p)N. With
p=O.OOl andN=1000, thereisonlya36percent chance thatalltheservers are
correctly functioning.
Asitturnsout,support forverylargeserver clusters isalmost always adhoc.
There arevarious rulesofthumb thatshould beconsidered (Brewer, 2001), but
there isnosystematic approach todealing withmassive systems management.
Cluster management isstillverymuch initsinfancy, although itcanbeexpected
thattheself-managing solutions asdiscussed intheprevious chapter willeventu-
allyfindtheirwayinthisarea,aftermoreexperience withthemhasbeengained.SEC. 3.4 SERVERS 99
Example: PlanetLab
Letusnowtakeacloser lookatasomewhat unusual cluster server. PlanetLab
isacollaborative distributed system inwhich different organizations eachdonate
oneormore computers, adding uptoatotalofhundreds ofnodes. Together, these
computers form al-tier server cluster, where access, processing, andstorage can
alltakeplace oneachnode individually. Management ofPlanetLab isbyneces-
sityalmost entirely distributed. Before weexplain itsbasic principles, letusfirst
describe themain architectural features (Peterson etal.,2005).
InPlanetLab, anorganization donates oneormore nodes, where eachnodeis
easiest thought ofasjustasingle computer, although itcould alsobeitself aclus-
terofmachines. Each nodeisorganized asshown inFig.3-15. There aretwoim-
portant components (Bavier etal.,2004). Thefirstoneisthevirtual machine
monitor (VMM), which isanenhanced Linux operating system. Theenhance-
ments mainly comprise adjustments forsupporting thesecond component, namely
vservers. A(Linux) vserver canbestbethought ofasaseparate environment in
which agroup ofprocesses run.Processes fromdifferent vservers arecompletely
independent. They cannot directly share anyresources suchasfiles, main memo-
ry,andnetwork connections asisnormally thecasewithprocesses running ontop
ofanoperating systems. Instead, avserver provides anenvironment consisting of
itsowncollection ofsoftware packages, programs, andnetworking facilities. For
example, avserver mayprovide anenvironment inwhich aprocess willnotice
thatitcanmake useofPython 1.5.2incombination withanolder Apache Web
server, sayhttpd 1.3.1. Incontrast, another vserver maysupport thelatest ver-
sions ofPython andhttpd. Inthissense, calling avserver a"server" isabitofa
misnomer asitreally onlyisolates groups ofprocesses fromeachother. Wereturn
tovservers briefly below.
Figure 3-15. Thebasicorganization ofaPlanetLab node.
TheLinux VMM ensures thatvservers areseparated: processes indifferent
vservers areexecuted concurrently andindependently, eachmaking useonlyof100 PROCESSES CHAP. 3
thesoftware packages andprograms available intheirownenvironment. Theiso-
lation between processes indifferent vservers isstrict. Forexample, twoproc-
essesindifferent vservers mayhavethesameuserill,butthisdoesnotimply that
theystemfromthesameuser.Thisseparation considerably easessupporting users
fromdifferent organizations thatwanttousePlanetLab as,forexample, atestbed
toexperiment withcompletely different distributed systems andapplications.
Tosupport suchexperimentations, PlanetLab introduces thenotion ofaslice,
which isasetofvservers, eachvserver running onadifferent node. Aslicecan
thusbethought ofasavirtual server cluster, implemented bymeans ofacollec-
tionofvirtual machines. Thevirtual machines inPlanetLab runontopofthe
Linux operating system, which hasbeenextended withanumber ofkernel mod-
ules
There areseveral issues thatmake management ofPlanetLab aspecial prob-
lem.Three salient onesare:
1.Nodes belong todifferent organizations. Eachorganization should be
allowed tospecify whoisallowed torunapplications ontheirnodes,
andrestrict resource usage appropriately.
2.There arevarious monitoring toolsavailable, buttheyallassume a
veryspecific combination ofhardware andsoftware. Moreover, they
arealltailored tobeusedwithin asingle organization.
3.Programs fromdifferent slices butrunning onthesamenodeshould
notinterfere witheachother. Thisproblem issimilar toprocess
independence inoperating systems.
Letustakealookateachoftheseissues inmoredetail.
Central tomanaging PlanetLab resources isthenodemanager. Each node
hassuchamanager, implemented bymeans ofaseparate vserver, whose onlytask
istocreate othervservers onthenodeitmanages andtocontrol resource alloca-
tion.Thenodemanager doesnotmake anypolicy decisions; itismerely amech-
anism toprovide theessential ingredients togetaprogram running onagiven
node.
Keeping trackofresources isdonebymeans ofaresource specification, or
rspee forshort. Anrspee specifies atimeinterval during which certain resources
havebeenallocated. Resources include diskspace, filedescriptors, inbound and
outbound network bandwidth, transport-level endpoints, mainmemory, andCPU
usage. Anrspee isidentified through aglobally unique 128-bit identifier known as
aresource capability (reap). Given anreap, thenodemanager canlookuptheas-
sociated rspee inalocaltable.
Resources arebound toslices. Inotherwords, inorder tomake useofre-
sources, itisnecessary tocreate aslice.Eachsliceisassociated withaservice
provider, which canbestbeseenasanentity having anaccount onPlanetLab.SEC. 3.4 SERVERS 101
Every slicecanthenbeidentified byaiprincipal.sid, slice.uag) pair,where the
principal.iid identifies theprovider andslice.stag isanidentifier chosen bythe
provider.
Tocreate anewslice, eachnodewillrunaslicecreation service (SCS),
which, intum,cancontact thenodemanager requesting ittocreate avserver and
toallocate resources. Thenodemanager itselfcannot becontacted directly overa
network, allowing ittoconcentrate onlyonlocalresource management. Intum,
theSCSwillnotaccept slice-creation requests fromjustanybody. Onlyspecific
sliceauthorities areeligible forrequesting thecreation ofaslice. Each slice
authority willhaveaccess rights toacollection ofnodes. Thesimplest model is
thatthereisonlyasingle sliceauthority thatisallowed torequest .slicecreation
onallnodes.
Tocomplete thepicture, aservice provider willcontact asliceauthority and
request ittocreate asliceacross acollection ofnodes. Theservice provider will
beknown tothesliceauthority, forexample, because ithasbeenpreviously
authenticated andsubsequently registered asaPlanetLab user.Inpractice, Planet-
Labusers contact asliceauthority bymeans ofaWeb-based service. Further
details canbefound inChunandSpalink (2003).
Whatthisprocedure reveals isthatmanaging PlanetLab isdonethrough inter-
mediaries. Oneimportant classofsuchintermediaries isformed bysliceauthori-
ties.Suchauthorities haveobtained credentials atnodes tocreate slides. Obtain-
ingthesecredentials hasbeenachieved out-of-band, essentially bycontacting sys-
tefnadministrators atvarious sites.Obviously, thisisatime-consuming process
which notbecarried outbyendusers(or,inPlanetLab terminology; service pro-
viders).
Besides sliceauthorities, therearealsomanagement authorities. Where aslice
authority concentrates onlyonmanaging slices, amanagement authority isre-
sponsible forkeeping aneyeonnodes. Inparticular, itensures thatthenodes
under itsregime runthebasicPlanetLab software andabidetotherulessetoutby
PlanetLab. Service providers trustthatamanagement authority provides nodes
thatwillbehave properly.
Figure 3-16. Themanagement relationships between various PlanetLab entities.102 PROCESSES CHAP. 3
Thisorganization leads tothemanagement structure shown inFig.3-16.
described interms oftrustrelationships inPeterson etat(2005). Therelations
areasfollows:
1.Anodeowner putsitsnodeunder theregime ofamanagement
authority, possibly restricting usage where appropriate.
2.Amanagement authority provides thenecessary software toadda
nodetoPlanetLab.
3.Aservice provider registers itself withamanagement authority.
trusting ittoprovide well-behaving nodes.
4.Aservice provider contacts asliceauthority tocreate asliceona
collection ofnodes.
5.Thesliceauthority needs toauthenticate theservice provider.
6.Anodeowner provides aslicecreation service forasliceauthority to
create slices. Itessentially delegates resource management tothe
sliceauthority.
7.Amanagement authority delegates thecreation ofslices toaslice
authority.
These relationships cover theproblem ofdelegating nodes inacontrolled way
suchthatanodeowner canrelyonadecent andsecure management. Thesecond
issuethatneeds tobehandled ismonitoring. Whatisneeded isaunified approach
toallowuserstoseehowwelltheirprograms arebehaving within aspecific slice.
PlanetLab follows asimple approach. Every nodeisequipped withacollec-
tionofsensors, eachsensor being capable ofreporting information suchasCPU
usage, diskactivity, andsoon.Sensors canbearbitrarily complex, buttheimpor-
tantissueisthat,theyalways report information onaper-node basis. Thisinforma-
tionismade available bymeans ofaWebserver: every sensor isaccessible
through simple HTTP requests (Bavier etat,2004).
Admittedly, thisapproach tomonitoring isstillrather primitive, butitshould
beseenasabasisforadvanced 'monitoring schemes. Forexample, there is,in
principle, noreason whyAstrolabe, which wediscussed inChap. 2,cannot be
usedforaggregated sensor readings across multiple nodes.
Finally, tocome toourthirdmanagement issue, namely theprotection ofpro-
grams against eachother, PlanetLab usesLinux virtual servers (called vservers) to
isolate slices. Asmentioned, themainideaofavserver istorunapplications in
thereownenvironment, which includes allfilesthatarenormally shared across a
single machine. Suchaseparation canbeachieved relatively easybymeans ofthe
UNIX chroot command, which effectively changes therootofthefilesystem from
where applications willlookforfiles. Onlythesuperuser canexecute chroot.SEC. 3.4 SERVERS 103
Ofcourse, moreisneeded. Linux virtual servers notonlyseparate thefilesys-
tem,butalsonormally shared information onprocesses, network addresses, mem-
oryusage, andso011.Asaconsequence, aphysical machine isactually partitioned
intomultiple units, eachunitcorresponding toafull-fledged Linux environment,
isolated fromtheotherparts. Anoverview ofLinux virtual servers canbefound
inPotzletal.(2005).
3.5CODE MIGRATION
Sofar,wehavebeenmainly concerned withdistributed systems inwhich
communication islimited topassing data.However, therearesituations inwhich
passing programs, sometimes evenwhile theyarebeing executed, simplifies the
design ofadistributed system. Inthissection, wetakeadetailed lookatwhat
codemigration actually is.Westartbyconsidering different approaches tocode
migration, followed byadiscussion onhowtodealwiththelocalresources thata
migrating program uses.Aparticularly hardproblem ismigrating codeinhetero-
geneous systems, which isalsodiscussed.
3.5.1 Approaches toCode Migration
Before taking alookatthedifferent forms ofcodemigration, letusfirstcon-
siderwhyitmaybeuseful tomigrate code.
Reasons forMigrating Code
Traditionally, codemigration indistributed systems tookplaceintheformof
process migration inwhich anentire process wasmoved fromonemachine to
another (Milojicic etal.,2000). Moving arunning process toadifferent machine
isacostly andintricate task,andtherehadbetter beagoodreason fordoing so.
Thatreason hasalways beenperformance. Thebasicideaisthatoverall system
performance canbeimproved ifprocesses aremoved fromheavily-loaded to
lightly-loaded machines. Load isoften expressed interms oftheCPUqueue
length orCPUutilization, butotherperformance indicators areusedaswell.
Loaddistribution algorithms bywhich decisions aremade concerning theal-
location andredistribution oftaskswithrespect toasetofprocessors, playanim-
portant roleincompute-intensive systems. However, inmany modem distributed
systems, optimizing computing capacity islessanissuethan,forexample, trying
tominimize communication. Moreover, duetotheheterogeneity oftheunderlying
platforms andcomputer networks, performance improvement through codemigra-
tionisoftenbased onqualitative reasoning instead ofmathematical models.
Consider, asanexample, aclient-server system inwhich theserver manages a
hugedatabase. Ifaclient application needs toperform many database operations104 PROCESSES CHAP. 3
involving largequantities ofdata,itmaybebetter toshippartoftheclient appli-
cation totheserver andsendonlytheresults across thenetwork. Otherwise, the
network maybeswamped withthetransfer ofdatafromtheserver totheclient. In
thiscase,codemigration isbased ontheassumption thatitgenerally makes sense
toprocess dataclosetowhere thosedatareside.
Thissamereason canbeusedformigrating partsoftheserver totheclient.
Forexample, inmanyinteractive database applications, clients needtofillinforms
thataresubsequently translated intoaseries ofdatabase operations. Processing
theformattheclient side,andsending onlythecompleted formtotheserver, can
sometimes avoid thatarelatively largenumber ofsmall messages needtocross
thenetwork. Theresult isthattheclient perceives better performance, while atthe
sametimetheserver spends lesstimeonformprocessing andcommunication.
Support forcodemigration canalsohelpimprove performance byexploiting
parallelism, butwithout theusualintricacies related toparallel programming. A
typical example issearching forinformation intheWeb.Itisrelatively simple to
implement asearch query intheformofasmallmobile program, called amobile
agent, thatmoves fromsitetosite.Bymaking several copies ofsuchaprogram,
andsending eachofftodifferent sites,wemaybeabletoachieve alinear speed-
upcompared tousingjustasingle program instance.
Besides improving performance, thereareotherreasons forsupporting code
migration aswell.Themostimportant oneisthatofflexibility. Thetraditional ap-
proach tobuilding distributed applications istopartition theapplication intodif-
ferent parts, anddecide inadvance where eachpartshould beexecuted. Thisap-
proach, forexample, hasledtothedifferent multitiered client-server applications
discussed inChap. 2.
However, ifcodecanmove between different machines, itbecomes possible
todynamically configure distributed systems. Forexample, suppose aserver
implements astandardized interface toafilesystem. Toallow remote clients to
access thefilesystem, theserver makes useofaproprietary protocol. Normally,
theclient-side implementation ofthefilesystem interface, which isbased onthat
protocol, would needtobelinked withtheclient application. Thisapproach re-
quires thatthesoftware bereadily available totheclient atthetimetheclient ap-
plication isbeing developed.
Analternative istolettheserver provide theclient's implementation no
sooner thanisstrictly necessary, thatis,when theclient binds totheserver. At
thatpoint, theclient dynamically downloads theimplementation, goesthrough the
necessary initialization steps, andsubsequently invokes theserver. Thisprinciple
isshown inFig.3-17. Thismodel ofdynamically moving codefromaremote site
doesrequire thattheprotocol fordownloading andinitializing code isstan-
dardized. Also,itisnecessary thatthedownloaded codecanbeexecuted onthe
client's machine. Different solutions arediscussed below andinlaterchapters.
Theimportant advantage ofthismodel ofdynamically downloading client-
sidesoftware isthatclients neednothaveallthesoftware preinstalled totalktoSEC. 3.5 CODE MIGRA nON 105
Figure 3-17. Theprinciple ofdynamically configuring aclient tocommunicate
toaserver. Theclient firstfetches thenecessary software, andtheninvokes the
server.
servers. Instead, thesoftware canbemoved inasnecessary, andlikewise, dis-
carded when nolonger needed. Another advantage isthataslongasinterfaces are
standardized, wecanchange theclient-server protocol anditsimplementation as
oftenaswelike.Changes willnotaffect existing client applications thatrelyon
theserver. There are,ofcourse, alsodisadvantages. Themostserious one,which
wediscuss inChap. 9,hastodowithsecurity. Blindly trusting thatthedown-
loaded codeimplements onlytheadvertised interface while accessing yourunpro-
tected harddiskanddoesnotsendthejuiciest partstoheaven-knows-who may
notalways besuchagoodidea.
Models forCode Migration
Although codemigration suggests thatwemove onlycodebetween machines,
thetermactually covers amuch richer area.Traditionally, communication indis-
tributed systems isconcerned withexchanging databetween processes. Code
migration inthebroadest sense dealswithmoving programs between machines,
withtheintention tohavethoseprograms beexecuted atthetarget. Insomecases,
asinprocess migration, theexecution status ofaprogram, pending signals, and
otherpartsoftheenvironment mustbemoved aswell.
Togetabetter understanding ofthedifferent models forcodemigration, we
useaframework described inFuggetta etal.(1998). Inthisframework, aprocess
consists ofthreesegments. Thecodesegment isthepartthatcontains thesetofin-
structions thatmake uptheprogram thatisbeing executed. Theresource segment
contains references toexternal resources needed. bytheprocess, suchasfiles,
printers, devices, otherprocesses, andsoon.Finally, anexecution segment isused
tostorethecurrent execution stateofaprocess, consisting ofprivate data,the
stack, and,ofcourse, theprogram counter.106 PROCESSES CHAP. 3
Thebareminimum forcodemigration istoprovide onlyweak mobility. In
thismodel, itispossible totransfer onlythecodesegment, along withperhaps
someinitialization data.Acharacteristic feature ofweakmobility isthatatrans-
ferred program isalways started fromoneofseveral predefined starting positions.
Thisiswhathappens, forexample, withJavaapplets, which always startexecu-
tionfromthebeginning. Thebenefit ofthisapproach isitssimplicity. Weak
mobility requires onlythatthetarget machine canexecute thatcode, which essen":
tiallyboilsdown tomaking thecodeportable. Wereturn tothesematters when
discussing migration inheterogeneous systems.
Incontrast toweakmobility, insystems thatsupport strong mobility theex-
ecution segment canbetransferred aswell.Thecharacteristic feature ofstrong
mobility isthatarunning process canbestopped, subsequently moved toanother
machine, andthenresume execution where itleftoff.Clearly, strong mobility is
much moregeneral thanweakmobility, butalsomuch harder toimplement.
Irrespective ofwhether mobility isweakorstrong, afurther distinction canbe
made between sender-initiated andreceiver-initiated migration. Insender-
initiated migration, migration isinitiated atthemachine where thecodecurrently
resides orisbeing executed. Typically, sender-initiated migration isdonewhen
uploading programs toacompute server. Another example issending asearch
program across theInternet toaWebdatabase server toperform thequeries at
thatserver. Inreceiver-initiated migration, theinitiative forcodemigration is
takenbythetarget machine. Javaapplets areanexample ofthisapproach.
Receiver-initiated migration issimpler thansender-initiated migration. In
many cases, codemigration occurs between aclient andaserver, where theclient
takestheinitiative formigration. Securely uploading codetoaserver, asisdone
insender-initiated migration, often requires thattheclient haspreviously been
registered andauthenticated atthatserver. Inotherwords, theserver isrequired to
know allitsclients, thereason being isthattheclient willpresumably wantaccess
totheserver's resources suchasitsdisk.Protecting suchresources isessential. In
contrast, downloading codeasinthereceiver-initiated case,canoften bedone
anonymously. Moreover, theserver isgenerally notinterested intheclient's re-
sources. Instead, codemigration totheclient isdoneonlyforimproving client-
sideperformance. Tothatend,onlyalimited number ofresources needtobepro-
tected, suchasmemory andnetwork connections. Wereturn tosecure code
migration extensively inChap. 9.
Inthecaseofweakmobility, italsomakes adifference ifthemigrated codeis
executed bythetarget process, orwhether aseparate process isstarted. Forex-
ample, Javaapplets aresimply downloaded byaWebbrowser andareexecuted in
thebrowser's address space. Thebenefit ofthisapproach isthatthereisnoneed
tostartaseparate process, thereby avoiding communication atthetarget machine.
Themaindrawback isthatthetarget process needs tobeprotected against mali-
ciousorinadvertent codeexecutions. Asimple solution istolettheoperating sys-
temtakecareofthatbycreating aseparate process toexecute themigrated code.SEC. 3.5 CODE MIGRATION 107
Notethatthissolution doesnotsolve theresource-access problems mentioned
above. Theystillhavetobedealtwith.
Instead ofmoving arunning process, alsoreferred toasprocess migration,
strong mobility canalsobesupported byremote cloning. Incontrast toprocess
migration, cloning yields anexact copyoftheoriginal process, butnowrunning
onadifferent machine. Thecloned process isexecuted inparallel totheoriginal
process. InUNIX systems, remote cloning takesplacebyforking offachildproc-
essandletting thatchildcontinue onaremote machine. Thebenefit ofcloning is
thatthemodel closely resembles theonethatisalready usedinmany applications.
Theonlydifference isthatthecloned process isexecuted onadifferent machine.
Inthissense, migration bycloning isasimple waytoimprove distribution tran-
sparency.
Thevarious alternatives forcodemigration aresummarized inFig.3-18.
Figure 3-18. Alternatives forcodemigration.
3.5.2 Migration andLocal Resources
Sofar,onlythemigration ofthecodeandexecution segment hasbeentaken
intoaccount. Theresource segment requires some special attention. What often
makes codemigration sodifficult isthattheresource segment cannot always be
simply transferred along withtheothersegments without being changed. Forex-
ample, suppose aprocess holds areference toaspecific TCPportthrough which
itwascommunicating withother(remote) processes. Suchareference isheldin
itsresource segment. When theprocess moves toanother location, itwillhaveto
giveuptheportandrequest anewoneatthedestination. Inothercases, trans-
ferring areference neednotbeaproblem. Forexample, areference toafileby108 PROCESSES CHAP. 3
means ofanabsolute URLwillremain validirrespective ofthemachine where
theprocess thatholdstheURLresides.
Tounderstand theimplications thatcodemigration hasontheresource seg-
ment, Fuggetta etal.(1998) distinguish threetypes ofprocess-to-resource bind-
ings.Thestrongest binding iswhen aprocess refers toaresource byitsidentifier.
Inthatcase,theprocess requires precisely thereferenced resource, andnothing
else.Anexample ofsuchabinding byidentifier iswhen aprocess usesaVRL
torefertoaspecific Websiteorwhenitrefers toanFrPserver bymeans ofthat
server's Internet address. Inthesamelineofreasoning, references tolocalcom-
munication endpoints alsoleadtoabinding byidentifier.
Aweaker formofprocess-to-resource binding iswhen onlythevalue ofare-
source isneeded. Inthatcase,theexecution oftheprocess would notbeaffected
ifanother resource would provide thatsamevalue. Atypical example ofbinding
byvalue iswhen aprogram relies onstandard libraries, suchasthose forpro-
gramming inCorJava.Suchlibraries should always belocally available, buttheir
exact location inthelocalfilesystem maydiffer between sites.Notthespecific
files,buttheircontent isimportant fortheproper execution oftheprocess.
Finally, theweakest formofbinding iswhenaprocess indicates itneeds only
aresource ofaspecific type.Thisbinding bytypeisexemplified byreferences to
localdevices, suchasmonitors, printers, andsoon.
When migrating code, weoftenneedtochange thereferences toresources,
butcannot affect thekindofprocess-to-resource binding. If,andexactly howa
reference should bechanged, depends onwhether thatresource canbemoved
along withthecodetothetarget machine. More specifically, weneedtoconsider
theresource-to-machine bindings, anddistinguish thefollowing cases. Unat-
tached resources canbeeasily moved between different machines, andaretypi-
cally(data) filesassociated onlywiththeprogram thatistobemigrated. Incon-
trast,moving orcopying afastened resource maybepossible, butonlyatrela-
tively highcosts. Typical examples offastened resources arelocaldatabases and
complete Websites.Although suchresources are,intheory, notdependent on
theircurrent machine, itisofteninfeasible tomove themtoanother environment.
Finally, fixed resources areintimately bound toaspecific machine orenviron-
mentandcannot bemoved. Fixed resources areoftenlocaldevices. Another ex-
ample ofafixedresource isalocalcommunication endpoint.
Combining threetypesofprocess-to-resource bindings, andthreetypes ofre-
source-to-machine bindings, leadstoninecombinations thatweneedtoconsider
whenmigrating code.These ninecombinations areshown inFig.3-19.
Letusfirstconsider thepossibilities whenaprocess isbound toaresource by
identifier. When theresource isunattached, itisgenerally besttomove italong
withthemigrating code. However, when theresource isshared byother proc-
esses, analternative istoestablish aglobal reference, thatis,areference thatcan
crossmachine boundaries. Anexample ofsuchareference isaURL. When the
resource isfastened orfixed, thebestsolution isalsotocreate aglobal reference.SEC. 3.5 CODE MIGRATION 109
Figure 3-19. Actions tobetaken withrespect tothereferences tolo-
calresources when migrating codetoanother machine.
Itisimportant torealize thatestablishing aglobal reference maybemorethan
justmaking useofURLs, andthattheuseofsuchareference issometimes prohi-
bitively expensive. Consider, forexample, aprogram thatgenerates high-quality
images foradedicated multimedia workstation. Fabricating high-quality images
inrealtimeisacompute-intensive task,forwhich reason theprogram maybe
moved toahigh-performance compute server. Establishing aglobal reference to
themultimedia workstation means setting upacommunication pathbetween the
compute server andtheworkstation. Inaddition, thereissignificant processing
involved atboththeserver andtheworkstation tomeetthebandwidth require-
ments oftransferring theimages. Thenetresult maybethatmoving theprogram
tothecompute server isnotsuchagoodidea,onlybecause thecostoftheglobal
reference istoohigh.
Another example ofwhere establishing aglobal reference isnotalways that
easyiswhenmigrating aprocess thatismaking useofalocalcommunication end
point. Inthatcase,wearedealing withafixedresource towhich theprocess is
bound bytheidentifier. There arebasically twosolutions. Onesolution istolet
theprocess setupaconnection tothesource machine afterithasmigrated and
install aseparate process atthesource machine thatsimply forwards allincoming
messages. Themaindrawback ofthisapproach isthatwhenever thesource ma-
chine malfunctions, communication withthemigrated process mayfail.Thealter-
native solution istohaveallprocesses thatcommunicated withthemigrating
process, change theirglobal reference, andsendmessages tothenewcommunica-
tionendpointatthetarget machine.
Thesituation isdifferent whendealing withbindings byvalue. Consider first
afixed resource. Thecombination ofafixed resource andbinding byvalue
occurs, forexample, when aprocess assumes thatmemory canbeshared between
processes. Establishing aglobal reference inthiscasewould meanthatweneedto
implement adistributed formofshared memory. Inmany cases, thisisnotreally a
viable orefficient solution.110 PROCESSES CHAP. 3
Fastened resources thatarereferred tobytheirvalue, aretypically runtime
libraries. Normally, copies ofsuchresources arereadily available onthetarget
machine, orshould otherwise becopied before codemigration takesplace. Estab-
lishing aglobal reference isabetter alternative whenhugeamounts ofdataareto
becopied, asmaybethecasewithdictionaries andthesauruses intextprocessing
systems.
Theeasiest caseiswhendealing withunattached resources. Thebestsolution
istocopy(ormove) theresource tothenewdestination, unless itisshared bya
number ofprocesses. Inthelattercase,establishing aglobal reference istheonly
option.
Thelastcasedealswithbindings bytype.Irrespective oftheresource-to-ma-
chine binding. theobvious solution istorebind theprocess toalocally available
resource ofthesametype.Onlywhen sucharesource isnotavailable, willwe
needtocopyormovetheoriginal onetothenewdestination, orestablish aglobal
reference.
3.5.3 Migration inHeterogeneous Systems
Sofar,wehavetacitly assumed thatthemigrated codecanbeeasily executed
atthetarget machine. Thisassumption isinorderwhen dealing withhomogene-
oussystems. Ingeneral, however, distributed systems areconstructed onahetero-
geneous collection ofplatforms, eachhaving theirownoperating system andma-
chine architecture. Migration insuchsystems requires thateachplatform issup-
ported, thatis,thatthecodesegment canbeexecuted oneachplatform. Also, we
needtoensure thattheexecution segment canbeproperly represented ateach
platform. .
Theproblems coming fromheterogeneity areinmany respects thesame as
thoseofportability. Notsurprisingly, solutions arealsoverysimilar. Forexample,
attheendofthe1970s, asimple solution toalleviate many oftheproblems of
porting Pascal todifferent machines wastogenerate machine-independent inter-
mediate codeforanabstract virtual machine (Barron, 1981). Thatmachine, of
course, would needtobeimplemented onmanyplatforms, butitwould thenallow
Pascal programs toberunanywhere. Although thissimple ideawaswidely used
forsome years, itnever really caught onasthegeneral solution toportability
problems forotherlanguages, notably C.
About 25years later, code migration inheterogeneous systems isbeing
attacked byscripting languages andhighly portable languages suchasJava. In
essence, thesesolutions adopt thesameapproach aswasdoneforporting Pascal.
Allsuchsolutions haveincommon thattheyrelyona(process) virtual machine
thateither directly interprets source code(asinthecaseofscripting languages), or
otherwise interprets intermediate codegenerated byacompiler (asinJava). Being
intherightplaceattherighttimeisalsoimportant forlanguage developers.SEC. 3.5 CODE MIGRATION 111
Recent developments havestarted toweaken thedependency onprogramming
languages. Inparticular, solutions havebeenproposed notonlytomigrate proc-
esses, buttomigrate entire computing environments. Thebasicideaistocompart-
mentalize theoverall environment andtoprovide processes inthesameparttheir
ownviewontheircomputing environment.
Ifthecompartmentalization isdoneproperly, itbecomes possible todecouple
apartfromtheunderlying system andactually migrate ittoanother machine. In
thisway,migration would actually provide aformofstrong mobility forproc-
esses, astheycanthenbemoved atanypointduring theirexecution, andcontinue
where theyleftoffwhen migration completes. Moreover, many oftheintricacies
related tomigrating processes while theyhavebindings tolocalresources maybe
solved, asthesebindings areinmany casessimply preserved. Thelocalresources,
namely, areoftenpartoftheenvironment thatisbeing migrated.
There areseveral reasons forwanting tomigrate entire environments, but
perhaps themostimportant oneisthatitallows continuation ofoperation while a
machine needs tobeshutdown. Forexample, inaserver cluster, thesystems
administrator maydecide toshutdown orreplace amachine, butwillnothaveto
stopallitsrunning processes. Instead, itcantemporarily freeze anenvironment,
move ittoanother machine (where itsitsnexttoother, existing environments),
andsimply unfreeze itagain. Clearly, thisisanextremely powerful waytoman-
agelong-running compute environments andtheirprocesses.
Letusconsider onespecific example ofmigrating virtual machines, asdis-
cussed inClark etal.(2005). Inthiscase,theauthors concentrated onreal-time
migration ofavirtualized operating system, typically something thatwould be
convenient inacluster ofservers where atightcoupling isachieved through asin-
gle,shared local-area network. Under these circumstances, migration involves
twomajor problems: migrating theentire memory image andmigrating bindings
tolocalresources.
Astothefirstproblem, thereare,inprinciple, threewaystohandle migration
(which canbecombined):
1.Pushing memory pages tothenewmachine andresending theones
thatarelatermodified during themigration process.
2.Stopping thecurrent virtual machine; migrate memory, andstartthe
newvirtual machine.
3.Letting thenewvirtual machine pullinnewpages asneeded, thatis,
letprocesses startonthenewvirtual machine immediately andcopy
memory pages ondemand.
Thesecond option mayleadtounacceptable downtime ifthemigrating virtual
machine isrunning aliveservice, thatis,onethatoffers continuous service. On
theotherhand,apureon-demand approach asrepresented bythethirdoption may112 PROCESSES CHAP. 3
extensively prolong themigration period, butmayalsoleadtopoorperformance
because ittakesalongtimebefore theworking setofthemigrated processes has
beenmoved tothenewmachine.
Asanalternative, Clark etal.(2005) propose touseapre-copy approach
which combines thefirstoption, along withabriefstop-and-copy phase asrepres-
ented bythesecond option. Asitturnsout,thiscombination canleadtoservice
downtimes of200msorless.
Concerning localresources, matters aresimplified when dealing onlywitha
cluster server. First,because thereisasingle network, theonlythingthatneeds to
bedoneistoannounce thenewnetwork-to-MAC address binding, sothatclients
cancontact themigrated processes atthecorrect network interface. Finally, ifit
canbeassumed thatstorage isprovided asaseparate tier(likeweshowed in
Fig.3-12), thenmigrating binding tofilesissimilarly simple.
Theoverall effect isthat,instead ofmigrating processes, wenowactually see
thatanentire operating system canbemoved between machines.
3.6SUMMARY
Processes playafundamental roleindistributed systems astheyformabasis
forcommunication between different machines. Animportant issueishowproc-
essesareinternally organized and,inparticular, whether ornottheysupport mul-
tiplethreads ofcontrol. Threads indistributed systems areparticularly useful to
continue usingtheCPUwhen ablocking I/Ooperation isperformed. Inthisway,
itbecomes possible tobuildhighly-efficient servers thatrunmultiple threads in
parallel, ofwhich several maybeblocking towaituntildiskI/Oornetwork com-
munication completes.
Organizing adistributed application interms ofclients andservers hasproven
tobeuseful. Client processes generally implement userinterfaces, which may
range fromverysimple displays toadvanced interfaces thatcanhandle compound
documents. Client software isfurthermore aimed atachieving distribution tran-
sparency byhiding details concerning thecommunication withservers, where
those servers arecurrently located, andwhether ornotservers arereplicated. In
addition, client software ispartly responsible forhiding failures andrecovery
fromfailures.
Servers areoftenmoreintricate thanclients, butarenevertheless subject to
onlyarelatively fewdesign issues. Forexample, servers caneither beiterative or
concurrent, implement oneormore services, andcanbestateless orstateful.
Other design issues dealwithaddressing services andmechanisms tointerrupt a
server afteraservice request hasbeenissued andispossibly already being proc-
essed.
Special attention needs tobepaidwhen organizing servers intoacluster. A
common objective ishidetheinternals ofacluster fromtheoutside world. ThisSEC. 3.6 SUMMARY 113
means thattheorganization ofthecluster should beshielded fromapplications.
Tothisend,mostclusters useasingle entrypointthatcanhandoffmessages to
servers inthecluster. Achallenging problem istotransparently replace thissingle
entrypointbyafullydistributed solution.
Animportant topicfordistributed systems isthemigration ofcodebetween
different machines. Twoimportant reasons tosupport codemigration areincreas-
ingperformance andflexibility. When communication isexpensive, wecansome-
timesreduce communication byshipping computations fromtheserver tothecli-
ent,andlettheclient doasmuch localprocessing aspossible. Flexibility is
increased ifaclient candynamically download software needed tocommunicate
withaspecific server. Thedownloaded software canbespecifically targeted to
thatserver, without forcing theclient tohaveitpreinstalled.
Codemigration brings along problems related tousage oflocalresources for
which itisrequired thateither resources aremigrated aswell,newbindings to
localresources atthetarget machine areestablished, orforwhich systemwide net-
workreferences areused.Another problem isthatcodemigration requires thatwe
takeheterogeneity intoaccount. Current practice indicates thatthebestsolution to
handle heterogeneity istousevirtual machines. These cantakeeither theformof
process virtual machines asinthecaseof,forexample, Java,orthrough usingvir-
tualmachine monitors thateffectively allow themigration ofacollection ofproc-
essesalong withtheirunderlying operating system.
PROBLEMS
1.Inthisproblem youaretocompare reading afileusing asingle-threaded fileserver
andamultithreaded server. Ittakes 15msec togetarequest forwork, dispatch it,and
dotherestofthenecessary processing, assuming thatthedataneeded areinacache in
mainmemory. Ifadiskoperation isneeded, asisthecaseone-third ofthetime, anad-
ditional 75msec isrequired, during which timethethread sleeps. How many re-
quests/sec cantheserver handle ifitissingle threaded? Ifitismultithreaded?
2.Would itmake sense tolimitthenumber ofthreads inaserver process?
3.Inthetext,wedescribed amultithreaded tileserver, showing whyitisbetter thana
single-threaded server andafinite-state machine server. Arethere anycircumstances
inwhich asingle-threaded server might bebetter? Giveanexample.
4.Statically associating onlyasingle thread withalightweight process isnotsucha
goodidea.Whynot?
5.Having onlyasingle lightweight process perprocess isalsonotsuchagood idea.
Whynot?
6.Describe asimple scheme inwhich there areasmany lightweight processes asthere
arerunnable threads.114 PROCESSES CHAP. 3
7.Xdesignates auser's terminal ashosting theserver, while theapplication isreferred
toastheclient. Does thismake sense?
8.TheXprotocol suffers fromscalability problems. Howcanthese problems betackled?
9.Proxies cansupport replication transparency byinvoking eachreplica, asexplained in
thetext.Can(theserver sideof)anapplication besubject toareplicated calls?
10.Constructing aconcurrent server byspawning aprocess hassome advantages and
disadvantages compared tomultithreaded servers. Mention afew.
11.Sketch thedesign ofamultithreaded server thatsupports multiple protocols using
sockets asitstransport-level interface totheunderlying operating system.
12.Howcanweprevent anapplication fromcircumventing awindow manager, andthus
being abletocompletely messupascreen?
13.Isaserver thatmaintains aTCP/IP connection toaclient stateful orstateless?
14.Imagine aWebserver thatmaintains atableinwhich client IPaddresses aremapped
tothemostrecently accessed Webpages. When aclient connects totheserver, the
server looks uptheclient initstable, andiffound, returns theregistered page. Isthis
server stateful orstateless?
15.Strong mobility inUNIX systems could besupported byallowing aprocess toforka
childonaremote machine. Explain howthiswould work.
16.InFig.3-18itissuggested thatstrong mobility cannot becombined withexecuting
migrated codeinatarget process. Giveacounterexample.
17.Consider aprocess Pthatrequires access tofileFwhich islocally available onthe
machine where Piscurrently running. When Pmoves toanother machine, itstillre-
quires access toF.Ifthefile-to-machine binding isfixed, howcould thesystemwide
reference toFbeimplemented?
18.Describe indetail howTCl'packets flowinthecaseofTCPhandoff, along withthe
information onsource anddestination addresses inthevarious headers.4
COMMUNICATION
Interprocess communication isattheheartofalldistributed systems. Itmakes
nosense tostudy distributed systems without carefully examining thewaysthat
processes ondifferent machines canexchange information. Communication in
distributed systems isalways based onlow-level message passing asoffered by
theunderlying network. Expressing communication through message passing is
harder thanusingprimitives based onshared memory, asavailable fornondistrib-
utedplatforms. Modem distributed systems often consist ofthousands oreven
millions ofprocesses scattered across anetwork withunreliable communication
suchastheInternet. Unless theprimitive communication facilities ofcomputer
networks arereplaced bysomething else,development oflarge-scale distributed
applications isextremely difficult.
Inthischapter, westartbydiscussing therulesthatcommunicating processes
mustadhere to,known asprotocols, andconcentrate onstructuring thoseproto-
colsintheformoflayers. Wethenlookatthreewidely-used models forcommu-
nication: Remote Procedure Call(RPC), Message-Oriented Middleware (MOM),
anddatastreaming. Wealsodiscuss thegeneral problem ofsending datatomulti-
plereceivers, called multicasting.
Ourfirstmodel forcommunication indistributed systems istheremote proce-
durecall(RPC). AnRPCaimsathiding mostoftheintricacies ofmessage pass-
ing,andisidealforclient-server applications.
Inmany distributed applications, communication doesnotfollow therather
strictpattern ofclient-server interaction. Inthosecases, itturnsoutthatthinking
115116 COMMUNICATION CHAP. 4
interms ofmessages ismoreappropriate. However, thelow-level communication
facilities ofcomputer networks areinmany waysnotsuitable duetotheirlackof
distribution transparency. Analternative istouseahigh-level message-queuing
model, inwhich communication proceeds much thesame asinelectronic maiI
systems. Message-oriented middleware (MOM) isasubject important enough to
warrant asection ofitsown.
Withtheadvent ofmultimedia distributed systems, itbecame apparent that
many systems werelacking support forcommunication ofcontinuous media, such
asaudio andvideo. What isneeded isthenotion ofastream thatcansupport the
continuous flowofmessages, subject tovarious timing constraints. Streams are
discussed inaseparate section.
Finally, since ourunderstanding ofsetting upmulticast facilities hasim-
proved, novel andelegant solutions fordatadissemination haveemerged. Wepay
separate attention tothissubject inthelastsection ofthischapter.
4.1FUNDAMENTALS
Before westartourdiscussion oncommunication indistributed systems, we
firstrecapitulate someofthefundamental issues related tocommunication. Inthe
nextsection webriefly discuss network communication protocols, astheseform
thebasisforanydistributed system. After that,wetakeadifferent approach by
classifying thedifferent types ofcommunication thatoccurs indistributed sys-
tems.
4.1.1Layered Protocols
Duetotheabsence ofshared memory, allcommunication indistributed sys-
temsisbased onsending andreceiving (lowlevel) messages. When process A
wants tocommunicate withprocess B,itfirstbuilds amessage initsownaddress
space. Then.itexecutes asystem callthatcauses theoperating system tosendthe
message overthenetwork toB.Although thisbasicideasounds simple enough,
inordertoprevent chaos, AandBhavetoagree onthemeaning ofthebitsbeing
sent.IfAsends abrilliant newnovel written inFrench andencoded inIBM's
EBCDIC character code, andBexpects theinventory ofasupermarket written in
English andencoded inASCII, communication willbelessthanoptimal.
Many different agreements areneeded. Howmany voltsshould beusedto
signal aO-bit,andhowmany voltsforaI-bit? Howdoesthereceiver know which
isthelastbitofthemessage? Howcanitdetect ifamessage hasbeendamaged or
lost,andwhatshould itdoifitfindsout?Howlongarenumbers, strings, and
otherdataitems, andhowaretheyrepresented? Inshort, agreements areneeded at
avariety oflevels, varying fromthelow-level details ofbittransmission tothe
high-level details ofhowinformation istobeexpressed.SEC. 4.1 FUNDAMENTALS 117
Tomake iteasier todealwiththenumerous levels andissues involved in
communication, theInternational Standards Organization (ISO) developed arefer-
encemodel thatclearly identifies thevarious levels involved, givesthemstandard
names, andpoints outwhich levelshould dowhich job.Thismodel iscalled the
Open Systems Interconnection Reference Model (DayandZimmerman, 1983),
usually abbreviated asISOOSIorsometimes justtheOSImodel. Itshould be
emphasized thattheprotocols thatweredeveloped aspartoftheOSImodel were
never widely usedandareessentially deadnow.However, theunderlying model
itselfhasproved tobequiteuseful forunderstanding computer networks. Al-
though wedonotintend togiveafulldescription ofthismodel andallofitsim-
plications here,ashortintroduction willbehelpful. Formoredetails, seeTanen-
baum (2003).
TheOSImodel isdesigned toallow opensystems tocommunicate. Anopen
system isonethatisprepared tocommunicate withanyotheropensystem byus-
ingstandard rulesthatgovern theformat, contents, andmeaning ofthemessages
sentandreceived. These rulesareformalized inwhatarecalled protocols. To
allow agroup ofcomputers tocommunicate overanetwork, theymustallagree
ontheprotocols tobeused.Adistinction ismade between twogeneral typesof
protocols. Withconnection oriented protocols, before exchanging datathesender
andreceiver firstexplicitly establish aconnection, andpossibly negotiate thepro-
tocoltheywilluse.When theyaredone, theymustrelease (terminate) thecon-
nection. Thetelephone isaconnection-oriented communication system. With
connectionless protocols, nosetupinadvance isneeded. Thesender justtransmits
thefirstmessage whenitisready. Dropping aletterinamailbox isanexample of
connectionless communication. With computers, bothconnection-oriented and
connectionless communication arecommon.
IntheOSImodel, communication isdivided upintoseven levels orlayers, as
shown inFig.4-1.Eachlayerdealswithonespecific aspect ofthecommunica-
tion.Inthisway,theproblem canbedivided upintomanageable pieces, eachof
which canbesolved independent oftheothers. Eachlayerprovides aninterface to
theoneabove it.Theinterface consists ofasetofoperations thattogether define
theservice thelayerisprepared toofferitsusers.
When process Aonmachine 1wants tocommunicate withprocess Bonma-
chine 2,itbuilds amessage andpasses themessage totheapplication layeronits
machine. Thislayermight bealibrary procedure, forexample, butitcould alsobe
implemented insomeotherway(e.g.,inside theoperating system, onanexternal
network processor, etc.).Theapplication layersoftware thenaddsaheader tothe
frontofthemessage andpasses theresulting message across thelayer6/7inter-
facetothepresentation layer. Thepresentation layerintumaddsitsownheader
andpasses theresult down tothesession layer, andsoon.Some layers addnot
onlyaheader tothefront, butalsoatrailer totheend.When ithitsthebottom,
thephysical layeractually transmits themessage (which bynowmight lookas
shown inFig.4-2)byputting itontothephysical transmission medium.118 COMMUNICATION
Figure 4-2.Atypical message asitappears onthenetwork.CHAP. 4
When themessage arrives atmachine 2,itispassed upward, witheachlayer
stripping offandexamining itsownheader. Finally, themessage arrives atthere-
ceiver, process B,which mayreplytoitusingthereverse path.Theinformation in
thelayernheader isusedforthelayernprotocol.
Asanexample ofwhylayered protocols areimportant, consider communica-
tionbetween twocompanies, Zippy Airlines anditscaterer, Mushy Meals, Inc.
Every month, theheadofpassenger service atZippy askshersecretary tocontact
thesalesmanager's secretary atMushy toorder100,000 boxes ofrubber chicken.
Traditionally, theorders wentviathepostoffice. However, asthepostal service
deteriorated, atsomepointthetwosecretaries decided toabandon itandcommun-
icatebye-mail. Theycould dothiswithout bothering theirbosses, sincetheirpro-
tocoldealswiththephysical transmission oftheorders, nottheircontents.SEC. 4.1 FUNDAMENTALS 119
Similarly, theheadofpassenger service candecide todroptherubber chicken
andgoforMushy's newspecial, prime ribofgoat,without thatdecision affecting
thesecretaries. Thethingtonotice isthatwehavetwolayers here,thebosses and
thesecretaries. Eachlayerhasitsownprotocol (subjects ofdiscussion andtech-
nology) thatcanbechanged independently oftheotherone.Itisprecisely this
independence thatmakes layered protocols attractive. Eachonecanbechanged as
technology improves, without theotheronesbeing affected.
IntheOSImodel, therearenottwolayers, butseven, aswesawinFig.4-1.
Thecollection ofprotocols usedinaparticular system iscalled aprotocol suite
orprotocol stack. Itisimportant todistinguish areference model fromitsactual
protocols. Aswementioned, theOSIprotocols werenever popular. Incontrast,
protocols developed fortheInternet, suchasTCPandIP,aremostly used.Inthe
following sections, wewillbriefly examine eachoftheOSIlayers inturn,starting
atthebottom. However, instead ofgiving examples ofOSIprotocols, where
appropriate, wewillpointoutsomeoftheInternet protocols usedineachlayer.
Lower-Level Protocols
Westartwithdiscussing thethreelowest layers oftheOSIprotocol suite.
Together, theselayers implement thebasicfunctions thatencompass acomputer
network.
Thephysical layerisconcerned withtransmitting theOsandIs.Howmany
voltstousefor0and1,howmany bitspersecond canbesent,andwhether
transmission cantakeplaceinbothdirections simultaneously arekeyissues inthe
physical layer. Inaddition, thesizeandshape ofthenetwork connector (plug), as
wellasthenumber ofpinsandmeaning ofeachareofconcern here.
Thephysical layerprotocol dealswithstandardizing theelectrical, mechani-
cal,andsignaling interfaces sothatwhen onemachine sends a0bititisactually
received asa0bitandnota1bit.Many physical layerstandards havebeendevel-
oped(fordifferent media), forexample, theRS-232-C standard forserialcommu-
nication lines.
Thephysical layerjustsends bits.Aslongasnoerrors occur, alliswell.
However, realcommunication networks aresubject toerrors, sosomemechanism
isneeded todetect andcorrect them. Thismechanism isthemaintaskofthedata
linklayer. What itdoesistogroup thebitsintounits, sometimes called frames,
andseethateachframe iscorrectly received.
Thedatalinklayerdoesitsworkbyputting aspecial bitpattern onthestart
andendofeachframe tomarkthem, aswellascomputing achecksum byadding
upallthebytes intheframe inacertain way.Thedatalinklayerappends the
checksum totheframe. When theframe arrives, thereceiver recomputes the
checksum fromthedataandcompares theresult tothechecksum following the
frame. Ifthetwoagree, theframe isconsidered correct andisaccepted. Itthey120 COMMUNlCATION CHAP. 4
disagree. thereceiver asksthesender toretransmit it.Frames areassigned se-
quence numbers (intheheader), soeveryone cantellwhich iswhich.
OnaLAN, thereisusually noneedforthesender tolocate thereceiver. Itjust
putsthemessage outonthenetwork andthereceiver takesitoff.Awide-area net-
work, however, consists ofalargenumber ofmachines, eachwithsomenumber
oflinestoothermachines, rather likealarge-scale mapshowing major citiesand
roads connecting them. Foramessage togetfromthesender tothereceiverit
mayhavetomakeanumber ofhops,ateachonechoosing anoutgoing linetouse.
Thequestion ofhowtochoose thebestpathiscalled routing, andisessentially
theprimary taskofthenetwork layer.
Theproblem iscomplicated bythefactthattheshortest route isnotalways
thebestroute. Whatreally matters istheamount ofdelay onagiven route, which,
intum,isrelated totheamount oftraffic andthenumber ofmessages queued up
fortransmission overthevarious lines.Thedelaycanthuschange overthecourse
oftime.Some routing algorithms trytoadapttochanging loads, whereas others
arecontent tomakedecisions based onlong-term averages.
Atpresent, themostwidely usednetwork protocol istheconnectionless IP
(Internet Protocol), which ispartoftheInternet protocol suite. AnIPpacket
(thetechnical termforamessage inthenetwork layer) canbesentwithout any
setup. EachIPpacket isrouted toitsdestination independent ofallothers. No
internal pathisselected andremembered.
Transport Protocols
Thetransport layerforms thelastpartofwhatcould becalled abasicnetwork
protocol stack, inthesense thatitimplements allthose services thatarenotpro-
vided attheinterface ofthenetwork layer, butwhich arereasonably needed to
buildnetwork applications. Inotherwords, thetransport layerturnstheunderlying
network intosomething thatanapplication developer canuse.
Packets canbelostonthewayfromthesender tothereceiver. Although some
applications canhandle theirownerrorrecovery, others prefer areliable connec-
tion.Thejobofthetransport layeristoprovide thisservice. Theideaisthatthe
application layershould beabletodeliver amessage tothetransport layerwith
theexpectation thatitwillbedelivered without loss.
Upon receiving amessage fromtheapplication layer, thetransport layer
breaks itintopieces small enough fortransmission, assigns eachoneasequence
number, andthensends themall.Thediscussion inthetransport layerheader con-
cernswhich packets havebeensent,which havebeenreceived, howmany more
thereceiver hasroomtoaccept, which should beretransmitted, andsimilar topics.
Reliable transport connections (which bydefinition areconnection oriented)
canbebuiltontopofconnection-oriented orconnectionless network services. In
theformer caseallthepackets willarrive inthecorrect sequence (iftheyarrive at
all),butinthelattercaseitispossible foronepacket totakeadifferent routeandSEC. 4.1 FUNDAMENTALS 121
arrive earlier thanthepacket sentbefore it.Itisuptothetransport layersoftware
toputeverything backinordertomaintain theillusion thatatransport connection
islikeabigtube-you putmessages intoitandtheycome outundamaged andin
thesameorder inwhich theywentin.Providing thisend-to-end communication
behavior isanimportant aspect ofthetransport layer.
TheInternet transport protocol iscalled TCP(Transmission Control Proto-
col)andisdescribed indetail inComer (2006). Thecombination TCPIIP isnow
usedasadefacto standard fornetwork communication. TheInternet protocol
suitealsosupports aconnectionless transport protocol called UDP (Universal
Datagram Protocol), which isessentially justIPwithsomeminor additions. User
programs thatdonotneedaconnection-oriented protocol normally useUDP.
Additional transport protocols areregularly proposed. Forexample, tosupport
real-time datatransfer, theReal-time Transport Protocol (RTP) hasbeende-
fined. RTPisaframework protocol inthesense thatitspecifies packet formats
forreal-time datawithout providing theactual mechanisms forguaranteeing data
delivery. Inaddition, itspecifies aprotocol formonitoring andcontrolling data
transfer ofRTPpackets (Schulzrinne etal.,2003).
Higher- Level Protocols
Above thetransport layer, OSIdistinguished threeadditional layers. Inprac-
tice,onlytheapplication layeriseverused.Infact,intheInternet protocol suite,
everything above thetransport layerisgrouped together. Inthefaceofmiddle-
waresystems, weshallseeinthissection thatneither theOSInortheInternet ap-
proach isreally appropriate.
Thesession layerisessentially anenhanced version ofthetransport layer. It
provides dialog control, tokeeptrackofwhich partyiscurrently talking, andit
provides synchronization facilities. Thelatterareuseful toallow userstoinsert
checkpoints intolongtransfers, sothatintheeventofacrash, itisnecessary togo
backonlytothelastcheckpoint, rather thanallthewaybacktothebeginning. In
practice, fewapplications areinterested inthesession layeranditisrarely sup-
ported. Itisnotevenpresent intheInternet protocol suite. However, inthecon-
textofdeveloping middle waresolutions, theconcept ofasession anditsrelated
protocols hasturned outtobequiterelevant, notably when defining higher-level
communication protocols.
Unlike thelower layers, which areconcerned withgetting thebitsfromthe
sender tothereceiver reliably andefficiently, thepresentation layerisconcerned
withthemeaning ofthebits.Mostmessages donotconsist ofrandom bitstrings,
butmore structured information suchaspeople's names, addresses, amounts of
money, andsoon.Inthepresentation layeritispossible todefine records contain-
ingfields liketheseandthenhavethesender notify thereceiver thatamessage
contains aparticular record inacertain format. Thismakes iteasier formachines
withdifferent internal representations tocommunicate witheachother.122 COMMUNICATION CHAP. 4
TheOSIapplication layerwasoriginally intended tocontain acollection of
standard network applications suchasthoseforelectronic mail,filetransfer, and
terminal emulation. Bynow,ithasbecome thecontainer forallapplications and
protocols thatinonewayortheotherdonotfitintooneoftheunderlying layers.
Fromtheperspective oftheOSIreference model, virtually alldistributed systems
arejustapplications.
Whatismissing inthismodel isacleardistinction between applications, ap-
plication-specific protocols, andgeneral-purpose protocols. Forexample, the
Internet FileTransfer Protocol (FTP) (Postel andReynolds, 1985; andHorowitz
andLunt, 1997) defines aprotocol fortransferring filesbetween aclient andser-
vermachine. Theprotocol should notbeconfused withtheftpprogram, which is
anend-user application fortransferring filesandwhich also(notentirely bycoin-
cidence) happens toimplement theInternet FrP.
Another example ofatypical application-specific protocol istheHyperText
Transfer Protocol (HTTP) (Fielding etaI.,1999), which isdesigned toremotely
manage andhandle thetransfer ofWebpages. Theprotocol isimplemented by
applications suchasWebbrowsers andWebservers. However, HTTP isnowalso
usedbysystems thatarenotintrinsically tiedtotheWeb.Forexample, Java's ob-
ject-invocation mechanism usesHTTP torequest theinvocation ofremote objects
thatareprotected byafirewall (SunMicrosystems, 2004b).
There arealsomany general-purpose protocols thatareuseful tomany appli-
cations, butwhich cannot bequalified astransport protocols. Inmany cases, such
protocols fallintothecategory ofmiddleware protocols, which wediscuss next.
Middleware Protocols
Middleware isanapplication thatlogically lives(mostly) intheapplication
layer, butwhich contains many general-purpose protocols thatwarrant theirown
layers, independent ofother, more specific applications. Adistinction canbe
made between high-level communication protocols andprotocols forestablishing
various middleware services.
There arenumerous protocols tosupport avariety ofmiddleware services. For
example, aswediscuss inChap. 9,therearevarious waystoestablish authentica-
tion,thatis,provide proof ofaclaimed identity. Authentication protocols arenot
closely tiedtoanyspecific application, butinstead, canbeintegrated intoamid-
dleware system asageneral service. Likewise, authorization protocols bywhich
authenticated usersandprocesses aregranted access onlytothose resources for
which theyhaveauthorization. tendtohaveageneral, application-independent
nature.
Asanother example, weshallconsider anumber ofdistributed commit proto-
colsinChap. 8.Commit protocols establish thatinagroup ofprocesses either all
processes carryoutaparticular operation, orthattheoperation isnotcarried out
atall.Thisphenomenon isalsoreferred toasatomicity andiswidely applied inSEC. 4.1 FUNDAMENTALS 123
transactions. Asweshallsee,besides transactions, otherapplications, likefault-
tolerant ones,canalsotakeadvantage ofdistributed commit protocols.
Asalastexample, consider adistributed locking protocol bywhich aresource
canbeprotected against simultaneous access byacollection ofprocesses thatare
distributed across multiple machines. Weshallcomeacross anumber ofsuchpro-
tocols inChap. 6.Again, thisisanexample ofaprotocol thatcanbeusedto
implement ageneral middle wareservice, butwhich, atthesametime,ishighly
independent ofanyspecific application.
Middleware communication protocols support high-level communication ser-
vices. Forexample, inthenexttwosections weshalldiscuss protocols thatallow
aprocess tocallaprocedure orinvoke anobject onaremote machine inahighly
transparent way.Likewise, therearehigh-level communication services forset-
tingandsynchronizing streams fortransferring real-time data,suchasneeded for
multimedia applications. Asalastexample, somemiddle waresystems offerreli-
ablemulticast services thatscaletothousands ofreceivers spread across awide-
areanetwork.
Some ofthemiddleware communication protocols could equally wellbelong
inthetransport layer, buttheremaybespecific reasons tokeepthematahigher
level. Forexample, reliable multicasting services thatguarantee scalability canbe
implemented onlyifapplication requirements aretaken intoaccount. Conse-
quently, amiddleware system mayofferdifferent (tunable) protocols, eachintum
iraplernented usingdifferent transport protocols, butoffering asingle interface.
Figure 4-3.Anadapted reference model fornetworked communication.
Taking thisapproach tolayering leadstoaslightly adapted reference model
forcommunication, asshown inFig.4-3.Compared totheOSImodel, theses-
sionandpresentation layerhavebeenreplaced byasingle middle warelayerthat
contains application-independent protocols. These protocols donotbelong inthe
lower layers wejustdiscussed. Theoriginal transport services mayalsobeoffered124 COMMUNICATION CHAP. 4
asamiddleware service, without being modified. Thisapproach issomewhat an-
alogous tooffering UDPatthetransport level. Likewise, middleware communica-
tionservices mayinclude message-passing services comparable tothose offered
bythetransport layer.
Intheremainder ofthischapter, weconcentrate onfourhigh-level middle-
warecommunication services: remote procedure calls,message queuing services,
support forcommunication ofcontinuous media through streams, andmulticast-
ing.Before doing so,thereareothergeneral criteria fordistinguishing (middle-
ware) communication which wediscuss next.
4.1.2 Types ofCommunication
Tounderstand thevarious alternatives incommunication thatmiddleware can
offertoapplications, weviewthemiddleware asanadditional service inclient-
server computing, asshown inFig.4-4.Consider, forexample anelectronic mail
system. Inprinciple, thecoreofthemaildelivery system canbeseenasa
middleware communication service. Eachhostrunsauseragentallowing usersto
compose, send,andreceive e-mail. Asending useragentpasses suchmailtothe
maildelivery system, expecting it,intum,toeventually deliver themailtothe
intended recipient. Likewise, theuseragent atthereceiver's sideconnects tothe
maildelivery system toseewhether anymailhascomein.Ifso,themessages are
transferred totheuseragentsothattheycanbedisplayed andreadbytheuser.
Figure 4-4.Viewing middleware asanintermediate (distributed) service inap-
plication-level communication.
Anelectronic mailsystem isatypical example inwhich communication is
persistent. Withpersistent communication, amessage thathasbeensubmitted
fortransmission isstored bythecommunication middleware aslongasittakesto
deliver ittothereceiver. Inthiscase,themiddleware willstorethemessage at
oneorseveral ofthestorage facilities shown inFig.4-4.Asaconsequence, itisSEC. 4.1 FUNDAMENTALS 125
notnecessary forthesending application tocontinue execution aftersubmitting
themessage. Likewise, thereceiving application neednotbeexecuting when the
message issubmitted.
Incontrast, withtransient communication, amessage isstored bythecom-
munication system onlyaslongasthesending andreceiving application areexe-
cuting. Moreprecisely, interms ofFig.4-4,themiddleware cannot deliver ames-
sageduetoatransmission interrupt, orbecause therecipient iscurrently not
active, itwillsimply bediscarded. Typically, alltransport-level communication
services offeronlytransient communication. Inthiscase,thecommunication sys-
temconsists traditional store-and-forward routers. Ifarouter cannot deliver a
message tothenextoneorthedestination host,itwillsimply dropthemessage.
Besides being persistent ortransient, communication canalsobeasynchro-
nousorsynchronous. Thecharacteristic feature ofasynchronous communication
isthatasender continues immediately afterithassubmitted itsmessage for
transmission. Thismeans thatthemessage is(temporarily) stored immediately by
themiddleware uponsubmission. Withsynchronous communication, thesender
isblocked untilitsrequest isknown tobeaccepted. There areessentially three
points where synchronization cantakeplace. First, thesender maybeblocked
untilthemiddle warenotifies thatitwilltakeovertransmission oftherequest.
Second, thesender maysynchronize untilitsrequest hasbeendelivered tothe
intended recipient. Third, synchronization maytakeplace byletting thesender
waituntilitsrequest hasbeenfullyprocessed, thatis,upthetimethatthereci-
pientreturns aresponse.
Various combinations ofpersistence andsynchronization occur inpractice.
Popular onesarepersistence incombination withsynchronization atrequest sub-
mission, which isacommon scheme formany message-queuing systems, which
wediscuss laterinthischapter. Likewise, transient communication withsyn-
chronization aftertherequest hasbeenfullyprocessed isalsowidely used.This
scheme corresponds withremote procedure calls,which wealsodiscuss below.
Besides persistence andsynchronization, weshould alsomake adistinction
between discrete andstreaming communication. Theexamples sofarallfallinthe
category ofdiscrete communication: theparties communicate bymessages, each
message forming acomplete unitofinformation. Incontrast, streaming involves
sending multiple messages, oneaftertheother, where themessages arerelated to
eachotherbytheordertheyaresent,orbecause thereisatemporal relationship.
Wereturn tostreaming communication extensively below.
4.2REMOTE PROCEDURE CALL
Many distributed systems havebeenbased onexplicit message exchange be-
tween processes. However, theprocedures send andreceive donotconceal com-
munication atall,which isimportant toachieve access transparency indistributed126 COMMUNICA nON CHAP.4
systems. Thisproblem haslongbeenknown, butlittlewasdone about ituntila
paper byBirrell andNelson (1984) introduced acompletely different wayofhan-
dling communication. Although theideaisrefreshingly simple (once someone has
thought ofit).theimplications areoften subtle. Inthissection wewillexamine
theconcept, itsimplementation, itsstrengths, anditsweaknesses.
Inanutshell, what Birrell andNelson suggested wasallowing programs to
callprocedures located onother machines. When aprocess onmachine Acalls'a
procedure onmachine B,thecalling process onAissuspended, andexecution of
thecalled procedure takes place onB.Information canbetransported from the
caller tothecallee intheparameters andcancome backintheprocedure result.
Nomessage passing atallisvisible totheprogrammer. Thismethod isknown as
RemoteProcedure Call,oroftenjustRPC.
While thebasic ideasounds simple andelegant, subtle problems exist. To
startwith, because thecalling andcalled procedures runondifferent machines,
theyexecute indifferent address spaces, which causes complications. Parameters
andresults alsohavetobepassed, which canbecomplicated, especially ifthema-
chines arenotidentical. Finally, either orbothmachines cancrash andeachofthe
possible failures causes different problems. Still,mostofthese canbedealt with,
andRPCisawidely-used technique thatunderlies many distributed systems.
4.2.1BasicRPCOperation
Wefirststartwithdiscussing conventional procedure calls, andthenexplain
howthecallitself canbesplitintoaclient andserver partthatareeachexecuted
ondifferent machines.
Conventional Procedure Call
Tounderstand howRPCworks, itisimportant firsttofullyunderstand howa
conventional (i.e.,single machine) procedure callworks. Consider acallinClike
count =tead(td, but, nbytes);
where fdisan.integer indicating afile,bufisanarray ofcharacters intowhich
dataareread, andnbytes isanother integer telling howmany bytes toread. Ifthe
callismade fromthemain program, thestack willbeasshown inFig.4-5(a) be-
forethecall.Tomake thecall,thecaller pushes theparameters ontothestack in
order, lastonefirst,asshown inFig.4-5(b). (Thereason thatCcompilers push
theparameters inreverse order hastodowithprintj--by doing so,print! canal-
ways locate itsfirstparameter, theformat string.) After thereadprocedure has
finished running, itputsthereturn value inaregister, removes thereturn address,
andtransfers control back tothecaller. Thecaller thenremoves theparameters
fromthestack, returning thestack totheoriginal stateithadbefore thecall.SEC. 4.2 REMOTE PROCEDURE CALL 127
Figure 4-5.(a)Parameter passing inalocalprocedure call:thestack before the
calltoread. (b)Thestackwhile thecalled procedure isactive.
Several things areworth noting. Forone,inC,parameters canbecall-by-
value orcall-by-reference. Avalue parameter, suchasfdornbytes, issimply
copied tothestackasshown inFig.4-5(b). Tothecalled procedure, avalue pa-
rameter isjustaninitialized localvariable. Thecalled procedure maymodify it,
butsuchchanges donotaffect theoriginal valueatthecalling side.
Areference parameter inCisapointer toavariable (i.e.,theaddress ofthe
variable), rather thanthevalueofthevariable. Inthecalltoread.thesecond pa-
rameter isareference parameter because arrays arealways passed byreference in
C.What isactually pushed ontothestackistheaddress ofthecharacter array. If
thecalled procedure usesthisparameter tostoresomething intothecharacter
array, itdoesmodify thearrayinthecalling procedure. Thedifference between
call-by-value andcall-by-reference isquiteimportant forRPC,asweshallsee.
Oneotherparameter passing mechanism alsoexists, although itisnotusedin
C.Itiscalled call-by-copy/restore. Itconsists ofhaving thevariable copied to
thestack bythecaller, asincall-by-value, andthencopied backafterthecall,
overwriting thecaller's original value. Under mostconditions, thisachieves
exactly thesameeffect ascall-by-reference, butinsome situations. suchasthe
sameparameter being present multiple times intheparameter list.thesemantics
aredifferent. Thecall-by-copy/restore mechanism isnotusedinmanylanguages.
Thedecision ofwhich parameter passing mechanism touseisnormally made
bythelanguage designers andisafixedproperty ofthelanguage. Sometimes it
depends onthedatatypebeing passed. InC,forexample, integers andother
scalar typesarealways passed byvalue, whereas arrays arealways passed byref-
erence, aswehaveseen.Some Adacompilers usecopy/restore forinoutparame-
ters,butothers usecall-by-reference. Thelanguage definition permits either
choice, which makes thesemantics abitfuzzy.128 COMMUN1CATION CHAP. 4
Client andServer Stubs
Theideabehind RPCistomakearemote procedure calllookasmuch aspos-
siblelikealocalone.Inotherwords, wewantRPCtobetransparent-the calling
procedure should notbeaware thatthecalled procedure isexecuting onadif-
ferent machine orviceversa. Suppose thataprogram needs toreadsome data
fromafile.Theprogrammer putsacalltoreadinthecodetogetthedata.Ina
traditional (single-processor) system, thereadroutine isextracted fromthelibrary
bythelinker andinserted intotheobject program. Itisashortprocedure, which is
generally implemented bycalling anequivalent readsystem call.Inotherwords,
thereadprocedure isakindofinterface between theusercodeandthelocal
operating system.
Eventhough readdoesasystem call,itiscalled intheusual way,bypushing
theparameters ontothestack, asshown inFig.4-5(b). Thustheprogrammer does
notknowthatreadisactually doing something fishy.
RPCachieves itstransparency inananalogous way.When readisactually a
remote procedure (e.g.,onethatwillrunonthefileserver's machine), adifferent
version ofread,called aclient stub,isputintothelibrary. Liketheoriginal one,
it,too,iscalled using thecalling sequence ofFig.4-5(b). Alsoliketheoriginal
one,ittoo,doesacalltothelocaloperating system. Onlyunlike theoriginal one,
itdoesnotasktheoperating system togiveitdata.Instead, itpacks theparame-
tersintoamessage andrequests thatmessage tobesenttotheserver asillustrated
inFig.4-6.Following thecalltosend, theclient stubcallsreceive, blocking it-
selfuntilthereplycomes back.
Figure 4-6.Principle ofRPCbetween aclient andserver program.
When themessage arrives attheserver, theserver's operating system passes
ituptoaserver stub. Aserver stubistheserver-side equivalent ofaclient stub:
itisapieceofcodethattransforms requests coming inoverthenetwork intolocal
procedure calls.Typically theserver stubwillhavecalled receive andbeblocked
waiting forincoming messages. Theserver stubunpacks theparameters fromthe
message andthencallstheserver procedure intheusualway(i.e.,asinFig.4-5).
From theserver's point ofview, itisasthough itisbeing called directly bytheSEC. 4.2 REMOTE PROCEDURE CALL 129
client-the parameters andreturn address areallonthestackwhere theybelong
andnothing seems unusual. Theserver performs itsworkandthenreturns there-
sulttothecaller intheusualway.Forexample, inthecaseofread, theserver will
fillthebuffer, pointed tobythesecond parameter, withthedata.Thisbuffer will
beinternal totheserver stub.
When theserver stubgetscontrol backafterthecallhascompleted, itpacks
theresult (thebuffer) inamessage andcallssend toreturn ittotheclient. After
that,theserver stubusually doesacalltoreceive again, towaitforthenext
incoming request.
When themessage getsbacktotheclient machine, theclient's operating sys-
temseesthatitisaddressed totheclient process (oractually theclient stub,but
theoperating system cannot seethedifference). Themessage iscopied tothe
waiting buffer andtheclient process unblocked. Theclient stubinspects themes-
sage,unpacks theresult, copies ittoitscaller, andreturns intheusualway.When
thecaller getscontrol following thecalltoread, allitknows isthatitsdataare
available. Ithasnoideathattheworkwasdoneremotely instead ofbythelocal
operating system.
Thisblissful ignorance onthepartoftheclient isthebeauty ofthewhole
scheme. Asfarasitisconcerned, remote services areaccessed bymaking ordi-
nary(i.e.,local) procedure calls,notbycalling send andreceive. Allthedetails
ofthemessage passing arehidden awayinthetwolibrary procedures, justasthe
details ofactually making system callsarehidden awayintraditional libraries.
Tosummarize, aremote procedure calloccurs inthefollowing steps:
1.Theclient procedure callstheclient stubinthenormal way.
2.Theclient stubbuilds amessage andcallsthelocaloperating system.
3.Theclient's assends themessage totheremote as.
4.Theremote asgivesthemessage totheserver stub.
5.Theserver stubunpacks theparameters andcallstheserver.
6.Theserver doestheworkandreturns theresult tothestub.
7.Theserver stubpacks itinamessage andcallsitslocalas.
8.Theserver's assendsthemessage totheclient's as.
9.Theclient's asgivesthemessage totheclient stub.
10.Thestubunpacks theresultandreturns totheclient.
Theneteffect ofallthesestepsistoconvert thelocalcallbytheclient procedure
totheclient stub,toalocalcalltotheserver procedure without either client or
server being aware oftheintermediate stepsortheexistence ofthenetwork.130 COMMUNICATION CHAP. 4
4.2.2 Parameter Passing
Thefunction oftheclient stubistotakeitsparameters, packthem intoames-
sage, andsendthem totheserver stub.While thissounds straightforward, itisnot
quite assimple asitatfirstappears. Inthissection wewilllookatsome ofthe
issues concerned withparameter passing inRPCsystems.
Passing Value Parameters
Packing parameters intoamessage iscalled parameter marshaling. Asa
verysimple example, consider aremote procedure, add(i, j),thattakes twointeger
parameters iandjandreturns theirarithmetic sumasaresult. (Asapractical
matter, onewould notnormally make suchasimple procedure remote duetothe
overhead, butasanexample itwilldo.)Thecalltoadd,isshown intheleft-hand
portion (intheclient process) inFig.4-7.Theclient stubtakes itstwoparameters
andputsthem inamessage asindicated, Italsoputsthename ornumber ofthe
procedure tobecalled inthemessage because theserver might support several
different calls, andithastobetoldwhich oneisrequired.
Figure 4-7.Thestepsinvolved inadoing aremote computation through RPC.
When themessage arrives attheserver, thestubexamines themessage tosee
which procedure isneeded andthenmakes theappropriate call.Iftheserver also
supports other remote procedures, theserver stubmight haveaswitch statement
inittoselect theprocedure tobecalled, depending onthefirstfieldofthemes-
sage. Theactual callfromthestubtotheserver looks liketheoriginal client call,
except thattheparameters arevariables initialized fromtheincoming message.
When theserver hasfinished, theserver stubgains control again. Ittakes the
result sentback bytheserver andpacks itintoamessage. Thismessage issentSEC. 4.2 REMOTE PROCEDURE CALL131
backbacktotheclient stub. which unpacks ittoextract theresult andreturns the
value tothewaiting client procedure.
Aslongastheclient andserver machines areidentical andalltheparameters
andresults arescalar types. suchasintegers, characters, andBooleans, thismodel
works fine.However, inalarge distributed system, itiscommon thatmultiple ma-
chine types arepresent. Each machine often hasitsownrepresentation fornum-
bers, characters, andother dataitems. Forexample, IRM mainframes usethe
EBCDIC character code, whereas IBMpersonal computers useASCII. Asacon-
sequence, itisnotpossible topassacharacter parameter from anIBMPCclient
toanIBMmainframe server using thesimple scheme ofFig.4-7:theserver will
interpret thecharacter incorrectly.
Similar problems canoccur withtherepresentation ofintegers (one's comple-
ment versus two's complement) andfloating-point numbers. Inaddition, aneven
more annoying problem exists because some machines, suchastheIntelPentium,
number theirbytes from right toleft,whereas others, suchastheSunSPARC,
number them theother way. TheIntel format iscalled little endian andthe
SPARC format iscalled bigendian, afterthepoliticians inGulliver's Travels
whowent towaroverwhich endofaneggtobreak (Cohen, 1981). Asanex-
ample, consider aprocedure withtwoparameters, aninteger andafour-character
string. Each parameter requires one32-bit word. Fig.4-8(a) shows whatthepa-
rameter portion ofamessage builtbyaclient stubonanIntelPentium might look
like,Thefirstword contains theinteger parameter, 5inthiscase, andthesecond
contains thestring "JILL."
Figure 4-8.(a)Theoriginal message onthePentium. (b)Themessage afterre-
ceiptontheSPARe. (c)Themessage afterbeing inverted. Thelittlenumbers in
boxes indicate theaddress ofeachbyte.
Since messages aretransferred byteforbyte(actually, bitforbit)overthenet-
work, thefirstbytesentisthefirstbytetoarrive. InFig.4-8(b) weshow whatthe
message ofFig.4-8(a) would looklikeifreceived byaSPARC, which numbers
itsbytes withbyte0attheleft(high-order byte) instead ofattheright(low-order
byte) asdoalltheIntelchips. When theserver stubreads theparameters atad-
dresses 0and4,respectively, itwillfindaninteger equal to83,886,080 (5x224)
andastring "JILL".
Oneobvious, butunfortunately incorrect, approach istosimply invert the
bytes ofeachword aftertheyarereceived, leading toFig.4-8(c). Nowtheinteger132 COMMUNICATION CHAP. 4
is5andthestring is"LLIJ". Theproblem hereisthatintegers arereversed bythe
different byteordering, butstrings arenot.Without additional information about
whatisastring andwhatisaninteger, thereisnowaytorepair thedamage.
PassingReference Parameters
Wenowcome toadifficult problem: Howarepointers, oringeneral, refer-
ences passed? Theanswer is:onlywiththegreatest ofdifficulty, ifatall.
Remember thatapointer ismeaningful onlywithin theaddress space oftheproc-
essinwhich itisbeing used.Getting backtoourreadexample discussed earlier,
ifthesecond parameter (theaddress ofthebuffer) happens tobe1000onthecli-
ent,onecannot justpassthenumber 1000totheserver andexpect ittowork.
Address 1000ontheserver might beinthemiddle oftheprogram text.
Onesolution isjusttoforbid pointers andreference parameters ingeneral.
However, thesearesoimportant thatthissolution ishighly undesirable. Infact,it
isnotnecessary either. Inthereadexample, theclient stubknows thatthesecond
parameter points toanarrayofcharacters. Suppose, forthemoment, thatitalso
knows howbigthearrayis.Onestrategy thenbecomes apparent: copythearray
intothemessage andsendittotheserver. Theserver stubcanthencalltheserver
withapointer tothisarray, eventhough thispointer hasadifferent numerical val-
uethanthesecond parameter ofreadhas.Changes theserver makes using the
pointer (e.g., storing dataintoit)directly affect themessage buffer inside the
server stub.When theserver finishes, theoriginal message canbesentbacktothe
client stub,which thencopies itbacktotheclient. Ineffect, call-by-reference has
beenreplaced bycopy/restore. Although thisisnotalways identical, itfrequently
isgoodenough.
Oneoptimization makes thismechanism twice asefficient. Ifthestubsknow
whether thebuffer isaninputparameter oranoutput parameter totheserver, one
ofthecopies canbeeliminated. Ifthearrayisinputtotheserver (e.g.,inacallto
write) itneednotbecopied back.Ifitisoutput, itneednotbesentoverinthefirst
place.
Asafinalcomment, itisworth noting thatalthough wecannowhandle point-
erstosimple arrays andstructures, westillcannot handle themostgeneral caseof
apointer toanarbitrary datastructure suchasacomplex graph. Some systems
attempt todealwiththiscasebyactually passing thepointer totheserver stuband
generating special codeintheserver procedure forusing pointers. Forexample, a
request maybesentbacktotheclient toprovide thereferenced data.
Parameter Specification andStubGeneration
From whatwehaveexplained sofar,itisclearthathiding aremote procedure
callrequires thatthecaller andthecallee agree ontheformat ofthemessages
theyexchange, andthattheyfollow thesamestepswhenitcomes to,forexample,SEC. 4.2 REMOTEPROCEDURE CALL 133
passing complex datastructures. Inotherwords, bothsidesinanRPCshould fol-
lowthesameprotocol ortheRPCwillnotworkcorrectly.
Asasimple example, consider theprocedure ofFig.4-9(a). Ithasthreepa-
rameters, acharacter, afloating-point number, andanarray offiveintegers.
Assuming awordisfourbytes, theRPCprotocol might prescribe thatweshould
transmit acharacter intherightmost byteofaword(leaving thenext3bytes
empty), afloatasawhole word, andanarrayasagroup ofwords equal tothe
arraylength, preceded byawordgiving thelength, asshown inFig.4-9(b). Thus
given theserules, theclient stubforfoobar knows thatitmustusetheformat of
Fig.4-9(b), andtheserver stubknows thatincoming messages forfoobar will
havetheformat ofFig.4-9(b).
Figure 4-9.(a)Aprocedure. (b)Thecorresponding message.
Defining themessage format isoneaspect ofanRPCprotocol, butitisnot
sufficient. What wealsoneedistheclient andtheserver toagree ontherepres-
entation ofsimple datastructures, suchasintegers, characters, Booleans, etc.For
example, theprotocol could prescribe thatintegers arerepresented intwo's com-
plement, characters in16-bit Unicode, andfloats intheIEEE standard #754for-
mat,witheverything stored inlittleendian. Withthisadditional information, mes-
sagescanbeunambiguously interpreted.
Withtheencoding rulesnowpinned down tothelastbit,theonlythingthat
remains tobedoneisthatthecaller andcallee agree ontheactual exchange of
messages. Forexample, itmaybedecided touseaconnection-oriented transport
service suchasTCPIIP. Analternative istouseanunreliable datagram service
andlettheclient andserver implement anerrorcontrol scheme aspartoftheRPC
protocol. Inpractice, several variants exist.
Once theRPCprotocol hasbeenfullydefined, theclient andserver stubs
needtobeimplemented. Fortunately, stubsforthesame protocol butdifferent
procedures normally differ onlyintheirinterface totheapplications. Aninterface
consists ofacollection ofprocedures thatcanbecalled byaclient, andwhich are
implemented byaserver. Aninterface isusually available inthesameprograming134 COMMUNICA nON CHAP. 4
language astheoneinwhich theclient orserver iswritten (although thisisstrictly
speaking, notnecessary). Tosimplify matters, interfaces areoften specified by
means ofanInterface Definition Language (IDL). Aninterface specified in
suchanIDListhensubsequently compiled intoaclient stubandaserver stub,
along withtheappropriate compile-time orrun-time interfaces.
Practice shows thatusing aninterface definition language considerably sim-
plifies client-server applications based onRPCs. Because itiseasytofullygen-
erateclient andserver stubs, allRPC-based middleware systems offeranIDLto
support application development. Insomecases, usingtheIDLisevenmandatory,
asweshallseeinlaterchapters.
4.2.3 Asynchronous RPC
Asinconventional procedure calls, when aclient callsaremote procedure,
theclient willblock untilareplyisreturned. Thisstrictrequest-reply behavior is
unnecessary whenthereisnoresult toreturn, andonlyleadstoblocking theclient
while itcould haveproceeded andhavedoneuseful workjustafterrequesting the
remote procedure tobecalled. Examples ofwhere thereisoftennoneedtowait
forareplyinclude: transferring money fromoneaccount toanother, adding en-
triesintoadatabase, starting remote services, batchprocessing, andsoon.
Tosupport suchsituations, RPCsystems mayprovide facilities forwhatare
called asynchronous RPCs, bywhich aclient immediately continues afterissu-
ingtheRPCrequest. Withasynchronous RPCs, theserver immediately sends a
reply backtotheclient themoment theRPCrequest isreceived, afterwhich it
callstherequested procedure. Thereplyactsasanacknowledgment totheclient
thattheserver isgoing toprocess theRPC. Theclient willcontinue without
further blocking assoonasithasreceived theserver's acknowledgment. Fig.4-
1O(b)shows howclient andserver interact inthecaseofasynchronous RPCs. For
comparison, Fig.4-10(a) shows thenormal request-reply behavior.
Asynchronous RPCs canalsobeuseful when areplywillbereturned butthe
client isnotprepared towaitforitanddonothing inthemeantime. Forexample,
aclient maywanttoprefetch thenetwork addresses ofasetofhosts thatit
expects tocontact soon.While anaming service iscollecting those addresses, the
client maywanttodootherthings. Insuchcases, itmakes sense toorganize the
communication between theclient andserver through twoasynchronous RPCs, as
shown inFig.4-11. Theclient firstcallstheserver tohandoveralistofhost
names thatshould belooked up,andcontinues whentheserver hasacknowledged
thereceipt ofthatlist.Thesecond callisdonebytheserver, whocallstheclient
tohandovertheaddresses itfound. Combining twoasynchronous RPCs issome-
times alsoreferred toasadeferred synchronous RPC.
Itshould benoted thatvariants ofasynchronous RPCs existinwhich thecli-
entcontinues executing immediately aftersending therequest totheserver. InSEC. 4.2 REMOTE PROCEDURE CALL 135
Figure 4-10. (a)Theinteraction between client andserver inatraditional RPc.
(b)Theinteraction using asynchronous RPc.
Figure 4-11. Aclient andserver interacting through twoasynchronous RPCs.
other words, theclient doesnotwaitforanacknowledgment oftheserver's ac-
ceptance oftherequest. WerefertosuchRPCs asone-way RPCs. Theproblem
withthisapproach isthatwhen reliability isnotguaranteed, theclient cannot
know forsurewhether ornotitsrequest willbeprocessed. Wereturn tothese
matters inChap. 8.Likewise, inthecaseofdeferred synchronous RPC,theclient
maypolltheserver toseewhether theresults areavailable yetinstead ofletting
theserver calling backtheclient.
4.2.4Example: DCERPC
Remote procedure callshavebeenwidely adopted asthebasisofmiddleware
anddistributed systems ingeneral. Inthissection, wetakeacloser lookatone
specific RPCsystem: theDistributed Computing Environment (DeE), which
wasdeveloped bytheOpen Software Foundation (OSF), nowcalled TheOpen
Group. DCERPCisnotaspopular assomeotherRPCsystems, notably SunRPC.
However, DCERPCisnevertheless representative ofotherRPCsystems, andits136 COMMUNICATION CHAP. 4
specifications havebeenadopted inMicrosoft's basesystem fordistributed com-
puting, DCOM(Eddon andEddon, ]998). Westartwithabriefintroduction to
DCE, afterwhich weconsider theprincipal workings ofDCERPC.Detailed tech-
nicalinformation onhowtodevelop RPC-based applications canbefound in
Stevens (l999).
Introduction toDCE
DCEisatruemiddleware system inthatitisdesigned toexecute asalayerof
abstraction between existing (network) operating systems anddistributed applica-
tions. Initially designed forUNIX, ithasnowbeenported toallmajor operating
systems including VMS andWindows variants, aswellasdesktop operating sys-
tems.Theideaisthatthecustomer cantakeacollection ofexisting machines, add
theDCEsoftware, andthenbeabletorundistributed applications, allwithout dis-
turbing existing (nondistributed) applications. Although mostoftheDCEpackage
runsinuserspace, insomeconfigurations apiece(partofthedistributed filesys-
tem)mustbeadded tothekernel. TheOpen Group itselfonlysellssource code,
which vendors integrate intotheirsystems.
Theprogramming model underlying allofDCEistheclient-server model,
which wasextensively discussed intheprevious chapter. Userprocesses actas
clients toaccess remote services provided byserver processes. Some oftheseser-
vicesarepartofDCEitself, butothers belong totheapplications andarewritten
bytheapplications programmers. Allcommunication between clients andservers
takesplacebymeans ofRPCs.
There areanumber ofservices thatformpartofDCEitself. Thedistributed
fileservice isaworldwide filesystem thatprovides atransparent. wayofac-
cessing anyfileinthesystem inthesameway.Itcaneither bebuiltontopofthe
hosts' native filesystems orusedinstead ofthem. Thedirectory service isused
tokeeptrackofthelocation ofallresources inthesystem. These resources in-
clude machines, printers, servers, data,andmuch more, andtheymaybedistrib-
utedgeographically overtheentire world. Thedirectory service allows aprocess
toaskforaresource andnothavetobeconcerned about where itis,unless the
process cares. Thesecurity service allows resources ofallkinds tobeprotected,
soaccess canberestricted toauthorized persons. Finally, thedistributed time
service isaservice thatattempts tokeepclocks onthedifferent machines globally
synchronized. Asweshallseeinlaterchapters, having somenotion ofglobal time
makes itmuch easier toensure consistency inadistributed system.
Goals ofDCERPC
Thegoals oftheDCE RPC system arerelatively traditional. First and
foremost, theRPCsystem makes itpossible foraclient toaccess aremote service
bysimply calling alocalprocedure. Thisinterface makes itpossible forclientSEC. 4.2 REMOTE PROCEDURE CALL 137
(i.e.,application) programs tobewritten inasimple way,familiar tomostpro-
grammers. Italsomakes iteasytohavelargevolumes ofexisting coderunina
distributed environment withfew,ifany,changes.
ItisuptotheRPCsystem tohideallthedetails fromtheclients, and,tosome
extent, fromtheservers aswell.Tostartwith,theRPCsystem canautomatically
locate thecorrect server, andsubsequently setupthecommunication between cli-
entandserver software (generally called binding). Itcanalsohandle themes-
sagetransport inbothdirections, fragmenting andreassembling themasneeded
(e.g.,ifoneoftheparameters isalargearray). Finally, theRPCsystem canauto-
matically handle datatypeconversions between theclient andtheserver, evenif
theyrunondifferent architectures andhaveadifferent byteordering;
Asaconsequence oftheRPCsystem's ability tohidethedetails, clients and
servers arehighly independent ofoneanother. Aclient canbewritten inJavaand
aserver inC,orviceversa. Aclient andserver canrunondifferent hardware plat-
forms andusedifferent operating systems. Ayariety ofnetwork protocols and
datarepresentations arealsosupported, allwithout anyintervention fromthecli-
entorserver.
Writing aClient andaServer
TheDCERPCsystem consists ofanumber ofcomponents, including lan-
guages, libraries, daemons, andutility programs, among others. Together these
make itpossible towriteclients andservers. Inthissection wewilldescribe the
pieces andhowtheyfittogether. Theentire process ofwriting andusing anRPC
client andserver issummarized inFig.4-12.
Inaclient-server system, thegluethatholds everything together istheinter-
facedefinition, asspecified intheInterface Definition Language, orIDL. It
permits procedure declarations inaformclosely resembling function prototypes
inANSI C.IDLfilescanalsocontain typedefinitions, constant declarations, and
otherinformation needed tocorrectly marshal parameters andunmarshal results.
Ideally, theinterface definition should alsocontain aformal definition ofwhatthe
procedures do,butsuchadefinition isbeyond thecurrent stateoftheart,sothe
interface definition justdefines thesyntax ofthecalls,nottheirsemantics. Atbest
thewriter canaddafewcomments describing whattheprocedures do.
Acrucial element inevery IDLfileisaglobally unique identifier forthe
specified interface. Theclient sends thisidentifier inthefirstRPCmessage and
theserver verifies thatitiscorrect. Inthisway,ifaclient inadvertently triesto
bindtothewrong server, oreventoanolderversion oftherightserver, theserver
willdetect theerrorandthebinding willnottakeplace.
Interface definitions andunique identifiers areclosely related inDCE. As
illustrated inFig.4-12,thefirststepinwriting aclient/server application isusual-
lycalling theuuidgen program, asking ittogenerate aprototype IDLfilecontain-
inganinterface identifier guaranteed never tobeusedagain inanyinterface138 COMMUNlCATION CHAP. 4
Figure 4-12. Thestepsinwriting aclient andaserver inDeE RPC.
generated anywhere byuuidgen. Uniqueness isensured byencoding initthelo-
cation andtimeofcreation. Itconsists ofa128-bit binary number represented in
theIDLfileasanASCII string inhexadecimal.
Thenextstepisediting theIDLfile,filling inthenames oftheremote proce-
dures andtheirparameters. Itisworth noting thatRPCisnottotally transpar-
ent-for example, theclient andserver cannot share global variables-but the
IDLrulesmakeitimpossible toexpress constructs thatarenotsupported.
When theIDLfileiscomplete, theIDLcompiler iscalled toprocess it.The
output oftheIDLcompiler consists ofthreefiles:
1.Aheader file(e.g.,interface.h, inCterms).
2.Theclient stub.
3.Theserver stub.
Theheader filecontains theunique identifier, typedefinitions, constant defini-
tions, andfunction prototypes. Itshould beincluded (using #include) inboththe
client andserver code.Theclient stubcontains theactual procedures thatthecli-
entprogram willcall.These procedures aretheonesresponsible forcollecting andSEC. 4.2 REMOTEPROCEDURE CALL 139
packing theparameters intotheoutgoing message andthencalling theruntime
system tosendit.Theclient stubalsohandles unpacking thereplyandreturning
values totheclient. Theserver stubcontains theprocedures called bytheruntime
system ontheserver machine whenanincoming message arrives. These, intum,
calltheactual server procedures thatdothework.
Thenextstepisfortheapplication writer towritetheclient andserver code.
Bothofthesearethencompiled, asarethetwostubprocedures. Theresulting cli-
entcodeandclient stubobject filesarethenlinked withtheruntime library topro-
ducetheexecutable binary fortheclient. Similarly, theserver codeandserver
stubarecompiled andlinked toproduce theserver's binary. Atruntime, theclient
andserver arestarted sothattheapplication isactually executed aswell.
Binding aClient toaServer
Toallow aclient tocallaserver, itisnecessary thattheserver beregistered
andprepared toaccept incoming calls.Registration ofaserver makes itpossible
foraclient tolocate theserver andbindtoit.Server location isdoneintwosteps:
1.Locate theserver's machine.
2.Locate theserver (i.e.,thecorrect process) onthatmachine.
Thesecond stepissomewhat subtle. Basically, whatitcomes down toisthatto
communicate withaserver, theclient needs toknow anendpoint, ontheserver's
machine towhich itcansendmessages. Anendpoint(alsocommonly known asa
port) isusedbytheserver's operating system todistinguish incoming messages
fordifferent processes. InDCE, atableof(server, endpoint)pairs ismaintained
oneachserver machine byaprocess called theDCEdaemon. Before itbecomes
available forincoming requests, theserver mustasktheoperating system foran
endpoint. Itthenregisters thisendpointwiththeDCEdaemon. TheDCEdaemon
records thisinformation (including which protocols theserver speaks) intheend
pointtableforfuture use.
Theserver alsoregisters withthedirectory service byproviding itthenetwork
address oftheserver's machine andanameunder which theserver canbelooked
up.Binding aclient toaserver thenproceeds asshown inFig.4-13.
Letusassume thattheclient wants tobindtoavideo server thatislocally
known under thename/local/multimedia/video/movies ..Itpasses thisnametothe
directory server, which returns thenetwork address ofthemachine running the
video server. Theclient thengoestotheDCEdaemon onthatmachine (which has
awell-known endpoint), andasksittolookuptheendpointofthevideo server in
itsendpointtable. Armed withthisinformation, theRPCcannowtakeplace. On
subsequent RPCs thislookup isnotneeded. DCEalsogivesclients theability to
domoresophisticated searches forasuitable server whenthatisneeded. Secure
RPCisalsoanoption where confidentiality ordataintegrity iscrucial.140 COMMUNICA nON CHAP. 4
Performing anRPC
Theactual RPCiscarried outtransparently andintheusual way.Theclient
stubmarshals theparameters totheruntime library fortransmission usingthepro-
tocolchosen atbinding time. When amessage arrives attheserver side,itis
routed tothecorrect server based ontheendpointcontained intheincoming mes-
sage.Theruntime library passes themessage totheserver stub,which unmarshals
theparameters andcallstheserver. Thereplygoesbackbythereverse route.
DCEprovides several semantic options. Thedefault isat-most-once opera-
tion,inwhich casenocallisevercarried outmorethanonce,eveninthefaceof
system crashes. Inpractice, whatthismeans isthatifaserver crashes during, an
RPCandthenrecovers quickly, theclient doesnotrepeat theoperation, forfear
thatitmight already havebeencarried outonce.
Alternatively, itispossible tomarkaremote procedure asidempotent (inthe
IDLfile),inwhich caseitcanberepeated multiple times without harm. Forex-
ample, reading aspecified block fromafilecanbetriedoverandoveruntilit
succeeds. When anidempotent RPCfailsduetoaserver crash. theclient canwait
untiltheserver reboots andthentryagain. Other semantics arealsoavailable (but
rarely used), including broadcasting theRPCtoallthemachines onthelocalnet-
work. Wereturn toRPCsemantics inChap. 8,when discussing RPCinthepres-
enceoffailures.
4.3MESSAGE-ORIENTED COMMUNICATION
Remote procedure callsandremote object invocations contribute tohiding
communication indistributed systems, thatis,theyenhance access transparency.
Unfortunately, neither mechanism isalways appropriate. Inparticular, when it
cannot beassumed thatthereceiving sideisexecuting atthetimearequest isFigure 4-13. Client-to-server binding inDCE.SEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 141
issued, alternative communication services areneeded. Likewise, theinherent
synchronous nature ofRPCs, bywhich aclient isblocked untilitsrequest has
beenprocessed, sometimes needs tobereplaced bysomething else.
Thatsomething elseismessaging. Inthissection weconcentrate onmessage-
oriented communication indistributed systems byfirsttaking acloser lookat
whatexactly synchronous behavior isandwhatitsimplications are.Then, wedis-
cussmessaging systems thatassume thatparties areexecuting atthetimeofcom-
munication. Finally, wewillexamine message-queuing systems thatallow proc-
essestoexchange information, eveniftheotherpartyisnotexecuting atthetime
communication isinitiated.
4.3.1 Message-Oriented Transient Communication
Many distributed systems andapplications arebuiltdirectly ontopofthesim-
plemessage-oriented model offered bythetransport layer. Tobetter understand
andappreciate themessage-oriented systems aspartofmiddle waresolutions, we
firstdiscuss messaging through transport-level sockets.
Berkeley Sockets
Special attention hasbeenpaidtostandardizing theinterface ofthetransport
layertoallow programmers tomake useofitsentire suiteof(messaging) proto-
colsthrough asimple setofprimitives. Also,standard interfaces makeiteasier to
portanapplication toadifferent machine.
Asanexample, webriefly discuss thesockets interface asintroduced inthe
1970s inBerkeley UNIX. Another important interface isXTI,which stands for
theX10pen Transport Interface, formerly called theTransport Layer Interface
(TLI), anddeveloped byAT&T. Sockets andXTIareverysimilar intheirmodel
ofnetwork programming, butdiffer intheirsetofprimitives.
Conceptually, asocket isacommunication endpointtowhich anapplication
canwritedatathataretobesentoutovertheunderlying network, andfromwhich
incoming datacanberead.Asocket forms anabstraction overtheactual commu-
nication endpoint thatisusedbythelocaloperating system foraspecific tran-
sportprotocol. Inthefollowing text,weconcentrate onthesocket primitives for
TCP,which areshown inFig.4-14.
Servers generally execute thefirstfourprimitives, normally intheorder
given. When calling thesocket primitive, thecaller creates anewcommunication
endpointforaspecific transport protocol. Internally, creating acommunication
endpointmeans thatthelocaloperating system reserves resources toaccommo-
datesending andreceiving messages forthespecified protocol.
Thebind primitive associates alocaladdress withthenewly-created socket.
Forexample, aserver should bindtheIPaddress ofitsmachine together witha
(possibly well-known) portnumber toasocket. Binding tellstheoperating system
thattheserver wants toreceive messages onlyonthespecified address andport.142 COMMUNICATION CHAP. 4
Figure 4-14. Thesocket primitives forTCPIIP.
Thelistenprimitive iscalled onlyinthecaseofconnection-oriented commu-
nication. Itisanonblocking callthatallows thelocaloperating system toreserve
enough buffers foraspecified maximum number ofconnections thatthecaller is
willing toaccept.
Acalltoaccept blocks thecaller untilaconnection request arrives. When a
request arrives, thelocaloperating system creates anewsocket withthesamepro-
perties astheoriginal one,andreturns ittothecaller. Thisapproach willallow the
server to,forexample, forkoffaprocess thatwillsubsequently handle theactual
communication through thenewconnection. Theserver, inthemeantime, cango
backandwaitforanother connection request ontheoriginal socket.
Letusnowtakealookattheclient side.Here, too,asocket mustfirstbe
created usingthesocket primitive, butexplicitly binding thesocket toalocalad-
dressisnotnecessary, sincetheoperating system candynamically allocate aport
whentheconnection issetup.Theconnect primitive requires thatthecaller speci-
fiesthetransport-level address towhich aconnection request istobesent.The
client isblocked untilaconnection hasbeensetupsuccessfully, afterwhich both
sidescanstartexchanging information through thesendandreceive primitives.
Finally, closing aconnection issymmetric whenusing sockets, andisestablished
byhaving boththeclient andserver callthecloseprimitive. Thegeneral pattern
followed byaclient andserver forconnection-oriented communication using
sockets isshown inFig.4-15. Details about network programming using sockets
andotherinterfaces inaUNIX environment canbefound inStevens (1998).
TheMessage-Passing Interface (MPI)
Withtheadvent ofhigh-performance multicomputers, developers havebeen
looking formessage-oriented primitives thatwould allow them toeasily write
highly efficient applications. Thismeans thattheprimitives should beatacon-
venient levelofabstraction (toeaseapplication development), andthattheirSEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 143
Figure 4-15. Connection-oriented communication pattern using sockets.
implementation incurs onlyminimal overhead. Sockets weredeemed insufficient
fortworeasons. First,theywereatthewrong levelofabstraction bysupporting
onlysimple sendandreceive primitives. Second, sockets hadbeendesigned to
communicate across networks using general-purpose protocol stacks suchas
TCPIIP. They werenotconsidered suitable fortheproprietary protocols devel-
opedforhigh-speed interconnection networks, suchasthoseusedinhigh-perfor-
mance server clusters. Those protocols required an'interface thatcould handle
moreadvanced features, suchasdifferent forms ofbuffering andsynchronization.
Theresult wasthatmost interconnection networks andhigh-performance
multicomputers wereshipped withproprietary communication libraries. These
libraries offered awealth ofhigh-level andgenerally efficient communication
primitives. Ofcourse, alllibraries weremutually incompatible, sothatapplication
developers nowhadaportability problem.
Theneedtobehardware andplatform independent eventually ledtothe
definition ofastandard formessage passing, simply called theMessage-Passing
Interface orMPI. MPIisdesigned forparallel applications andassuchis
tailored totransient communication. Itmakes direct useoftheunderlying net-
work..Also, itassumes thatserious failures suchasprocess crashes ornetwork
partitions arefatalanddonotrequire automatic recovery.
MPIassumes communication takesplacewithin aknowngroup ofprocesses.
Eachgroup isassigned anidentifier. Eachprocess within agroup isalsoassigned
a(local) identifier. A(group/D, process/D) pairtherefore uniquely identifies the
source ordestination ofamessage, andisusedinstead ofatransport-level ad-
dress. There maybeseveral, possibly overlapping groups ofprocesses involved in
acomputation andthatareallexecuting atthesametime.
AtthecoreofMPIaremessaging primitives tosupport transient communica-
tion,ofwhich themostintuitive onesaresummarized inFig.4-16.
Transient asynchronous communication issupported bymeans ofthe
MPI_bsend primitive. Thesender submits amessage fortransmission, which is
generally firstcopied toalocalbuffer intheMPIruntime system. When themes-
sagehasbeencopied. thesender continues. ThelocalMPIruntime system will
remove themessage fromitslocalbuffer andtakecareoftransmission assoonas
areceiver hascalled areceive primitive.144 COMMUNICA nON CHAP. 4
Figure 4-16. Some ofthemostintuitive message-passing primitives ofMPI.
There isalsoablocking sendoperation, called MPLsend, ofwhich thesem-
antics areimplementation dependent. Theprimitive MPLsend mayeither block
thecaller untilthespecified message hasbeencopied totheMPIruntime system
atthesender's side,oruntilthereceiver hasinitiated areceive operation. Syn-
chronous communication bywhich thesender blocks untilitsrequest isaccepted
forfurther processing isavailable through theMPI~ssend primitive. Finally, the
strongest formofsynchronous communication isalsosupported: when asender
callsMPLsendrecv, itsends arequest tothereceiver andblocks untilthelatter
returns areply. Basically, thisprimitive corresponds toanormal RPC.
BothMPLsend andMPLssend havevariants thatavoid copying messages
fromuserbuffers tobuffers internal tothelocalMPIruntime system. These vari-
antscorrespond toaformofasynchronous communication. With MPI_isend, a
sender passes apointer tothemessage afterwhich theMPIruntime system takes
careofcommunication. Thesender immediately continues. Toprevent overwrit-
ingthemessage before communication completes, MPIoffers primitives tocheck
forcompletion, oreventoblock ifrequired. AswithMPLsend, whether themes-
sagehasactually beentransferred tothereceiver orthatithasmerely beencopied
bythelocalMPIruntime system toaninternal buffer isleftunspecified.
Likewise, withMPLissend, asender alsopasses onlyapointer tothe:MPI
runtime system. When theruntime system indicates ithasprocessed themessage,
thesender isthenguaranteed thatthereceiver hasaccepted themessage andis
nowworking onit.
Theoperation MPLrecv iscalled toreceive amessage; itblocks thecaller
untilamessage arrives. There isalsoanasynchronous variant, called MPLirecv,
bywhich areceiver indicates thatisprepared toaccept amessage. Thereceiver
cancheck whether ornotamessage hasindeed arrived, orblock untilonedoes.
Thesemantics ofMPIcommunication primitives arenotalways straightfor-
ward, anddifferent primitives cansometimes beinterchanged without affectingSEC. 4.3 MESSAGE-ORIENTED COMMUNICA nON 145
thecorrectness ofaprogram. Theofficial reason whysomany different forms of
communication aresupported isthatitgives implementers ofMPI systems
enough possibilities foroptimizing performance. Cynics might saythecommittee
could notmake upitscollective mind, soitthrew ineverything. MPIhasbeen
designed forhigh-performance parallel applications, which makes iteasier to
understand itsdiversity indifferent communication primitives.
More onMPIcanbefound inGropp etaI.(l998b) Thecomplete reference in
which theover100functions inMPIareexplained indetail, canbefound inSnir
etal.(1998) andGropp etal.(l998a)
4.3.2 Message-Oriented Persistent Communication
Wenowcome toanimportant classofmessage-oriented middle wareservices,
generally known asmessage-queuing systems, orjustMessage-Oriented Mid-
dleware (MOM). Message-queuing systems provide extensive support forper-
sistent asynchronous communication. Theessence ofthese systems isthatthey
offerintermediate-term storage capacity formessages, without requiring either the
sender orreceiver tobeactive during message transmission. Animportant differ-
ence withBerkeley sockets andMPIisthatmessage-queuing systems aretypi-
cally targeted tosupport message transfers thatareallowed totakeminutes in-
stead ofseconds ormilliseconds. Wefirstexplain ageneral approach tomessage-
queuing systems, andconclude thissection bycomparing themtomore traditional
systems, notably theInternet e-mail systems.
Message-Queuing Model
Thebasic ideabehind amessage-queuing system isthatapplications com-
municate byinserting messages inspecific queues. These messages areforwarded
overaseries ofcommunication servers andareeventually delivered tothedesti-
nation, evenifitwasdown when themessage wassent.Inpractice, mostcommu-
nication servers aredirectly connected toeachother. Inother words, amessage is
generally transferred directly toadestination server. Inprinciple, eachapplication
hasitsownprivate queue towhich other applications cansendmessages. Aqueue
canbereadonlybyitsassociated application, butitisalsopossible formultiple
applications toshare asingle queue.
Animportant aspect ofmessage-queuing systems isthatasender isgenerally
given onlytheguarantees thatitsmessage willeventually beinserted inthere-
cipient's queue. Noguarantees aregiven about when, orevenifthemessage will
actually beread, which iscompletely determined bythebehavior oftherecipient.
These semantics permit communication loosely-coupled intime. There isthus
noneedforthereceiver tobeexecuting when amessage isbeing senttoitsqueue.
Likewise, there isnoneedforthesender tobeexecuting atthemoment itsmes-
sageispicked upbythereceiver. Thesender andreceiver canexecute completely146 COMMUNICATION CHAP. 4
independently ofeachother. Infact,onceamessage hasbeendeposited ina
queue, itwillremain thereuntilitisremoved, irrespective ofwhether itssender or
receiver isexecuting. Thisgivesusfourcombinations withrespect totheexecu-
tionmode ofthesender andreceiver, asshown inFig.4-17.
InFig.4-17(a), boththesender andreceiver execute during theentire
transmission ofamessage. In.Fig.4-17(b),onlythesender isexecuting, while the
receiver ispassive, thatis,inastateinwhich message delivery isnotpossible.
Nevertheless, thesender canstillsendmessages. Thecombination ofapassive
sender andanexecuting receiver isshown inFig.4-17(c).Inthiscase, there-
ceiver canreadmessages thatweresenttoit,butitisnotnecessary 'thattheirre-
spective senders areexecuting aswell.Finally, inFig.4-17(d), weseethesitua-
tionthatthesystem isstoring (andpossibly transmitting) messages evenwhile
sender andreceiver arepassive.
Messages can,inprinciple, contain anydata.Theonlyimportant aspect from
theperspective ofmiddleware isthatmessages areproperly addressed. Inprac-
tice,addressing isdonebyproviding asystemwide unique name ofthedestination
queue. Insomecases, message sizemaybelimited, although itisalsopossible
thattheunderlying system takescareoffragmenting andassembling large mes-
sagesinawaythatiscompletely transparent toapplications. Aneffect ofthisap-
proach isthatthebasicinterface offered toapplications canbeextremely simple,
asshown inFig.4-18.
Theputprimitive iscalled byasender topassamessage totheunderlying
system thatistobeappended tothespecified queue. Asweexplained. thisisaFigure 4-17. Four combinations forloosely-coupled communications using
queues.SEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 147
Figure 4-18. Basic interface toaqueue inamessage-queuing system.
nonblocking call.Thegetprimitive isablocking callbywhich anauthorized pro-
cesscanremove thelongest pending message inthespecified queue. Theprocess
isblocked onlyifthequeue isempty. Variations onthiscallallow searching fora
specific message inthequeue, forexample, using apriority, oramatching pat-
tern.Thenonblocking variant isgiven bythepollprimitive. Ifthequeue isempty,
orifaspecific message couldnotbefound, thecalling process simply continues.
Finally, mostqueuing systems alsoallow aprocess toinstall ahandler asa
callback function, which isautomatically invoked whenever amessage isputinto
thequeue. Callbacks canalsobeusedtoautomatically startaprocess thatwill
fetchmessages fromthequeue ifnoprocess iscurrently executing. Thisapproach
isoftenimplemented bymeans ofadaemon onthereceiver's sidethatcontinu-
ouslymonitors thequeue forincoming messages andhandles accordingly.
General Architecture ofaMessage-Queuing System
Letusnowtakeacloser lookatwhatageneral message-queuing system looks
like.Oneofthefirstrestrictions thatwemake isthatmessages canbeputonly'
intoqueues thatarelocaltothesender, thatis,queues onthesamemachine, orno
worse thanonamachine nearby suchasonthesameLANthatcanbeefficiently
reached through anRPC. Suchaqueue iscalled thesource queue. Likewise,
messages canbereadonlyfromlocalqueues. However, amessage putintoa
queue willcontain thespecification ofadestination queue towhich itshould be
transferred. Itistheresponsibility ofamessage-queuing system toprovide queues
tosenders andreceivers andtakecarethatmessages aretransferred fromtheir
source totheirdestination queue.
Itisimportant torealize thatthecollection ofqueues isdistributed across
multiple machines. Consequently, foramessage-queuing system totransfer mes-
sages, itshould maintain amapping ofqueues tonetwork locations. Inpractice,
thismeans thatitshould maintain a(possibly distributed) database ofqueue
names tonetwork locations, asshown inFig.4-19. Notethatsuchamapping is
completely analogous totheuseoftheDomain Name System (DNS) fore-mail in
theInternet. Forexample, when sending amessage tothelogical mailaddress
steen@cs.vu.nl, themailing system willquery DNStofindthenetwork (i.e.,IP)
address oftherecipient's mailserver tousefortheactual message transfer.148 COMMUNICATION CHAP. 4
Figure 4-19. Therelationship between queue-level addressing andnetwork-
leveladdressing.
Queues aremanaged byqueue managers. Normally, aqueue manager inter-
actsdirectly withtheapplication thatissending orreceiving amessage. However,
therearealsospecial queue managers thatoperate asrouters, orrelays: theyfor-
ward incoming messages toother queue managers. Inthisway, amessage-
queuing system maygradually growintoacomplete, application-level, overlay
network, ontopofanexisting computer network. Thisapproach issimilar tothe
construction oftheearlyMBone overtheInternet, inwhich ordinary userproc-
esseswereconfigured asmulticast routers. Asitturnsout,multicasting through
overlay networks isstillimportant aswewilldiscuss laterinthischapter.
Relays canbeconvenient foranumber ofreasons. Forexample, inmany mes-
sage-queuing systems, thereisnogeneral naming service available thatcandy-
namically maintain qneue-to-Iocation mappings. Instead, thetopology ofthe
queuing network isstatic, andeachqueue manager needs acopyofthequeue-to-
location mapping. Itisneedless tosaythatinlarge-scale queuing systems. thisap-
proach caneasily leadtonetwork-management problems.
Onesolution istouseafewrouters thatknow about thenetwork topology.
When asender Aputsamessage fordestination Binitslocalqueue, thatmessage
isfirsttransferred tothenearest router, sayRl,asshown inFig.4-20. Atthat
point, therouter knows whattodowiththemessage andforwards itinthedirec-
tionofB.Forexample, Rlmayderive fromB'sname thatthemessage should be
forwarded torouter R2.Inthisway,onlytherouters needtobeupdated when
queues areadded orremoved. while every otherqueue manager hastoknow only
where thenearest router is.
Relays canthusgenerally helpbuildscalable message-queuing systems. How-
ever,asqueuing networks grow, itisclearthatthemanual configuration ofnet-
works willrapidly become completely unmanageable. Theonlysolution isto
adopt dynamic routing schemes asisdoneforcomputer networks. Inthatrespect,
itissomewhat surprising thatsuchsolutions arenotyetintegrated intosome of
thepopular message-queuing systems.SEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 149
Figure 4·20. Thegeneral organization ofamessage-queuing system withrouters.
Another reason whyrelays areusedisthattheyallow forsecondary proc-
essing ofmessages. Forexample, messages mayneedtobelogged forreasons of
security orfaulttolerance. Aspecial formofrelay thatwediscuss inthenextsec-
tionisonethatactsasagateway, transforming messages intoaformat thatcanbe
understood bythereceiver.
Finally, relays canbeusedformulticasting purposes. Inthatcase, anincom-
ingmessage issimply putintoeachsendqueue.
Message Brokers
Animportant application areaofmessage-queuing systems isintegrating
existing andnewapplications intoasingle, coherent distributed information sys-
tem.Integration requires thatapplications canunderstand themessages theyre-
ceive. Inpractice, thisrequires thesender tohave itsoutgoing messages inthe
same format asthatofthereceiver.
Theproblem withthisapproach isthateachtimeanapplication isadded to
thesystem thatrequires aseparate message format, each potential receiver will
havetobeadjusted inorder toproduce thatformat.
Analternative istoagree onacommon message format, asisdonewithtradi-
tional network protocols. Unfortunately, thisapproach willgenerally notwork for
message-queuing systems. Theproblem isthelevel ofabstraction atwhich these150 COMMUNICATION CHAP.4
Figure 4-21. Thegeneral organization ofamessage broker inamessage-
queuing system.
Amessage broker canbeassimple asareformatter formessages. Forex-
ample, assume anincoming message contains atablefromadatabase, inwhich
records areseparated byaspecial end-oj-record delimiter andfields within arec-
ordhaveaknown, fixedlength. Ifthedestination application expects adifferent
delimiter between records, andalsoexpects thatfields havevariable lengths, a
message broker canbeusedtoconvert messages totheformat expected bythe
destination.
Inamoreadvanced setting, amessage broker mayactasanapplication-level
gateway, suchasonethathandles theconversion between twodifferent database
applications. Insuchcases, frequently itcannot beguaranteed thatallinformationsystems operate. Acommon message format makes senseonlyifthecollection of
processes thatmakeuseofthatformat indeed haveenough incommon. Ifthecol-
lection ofapplications thatmakeupadistributed information system ishighly di-
verse(which itoftenis),thenthebestcommon format maywellbenomorethan
asequence ofbytes.
Although afewcommon message formats forspecific application domains
havebeendefined, thegeneral approach istolearntolivewithdifferent formats,
andtrytoprovide themeans tomakeconversions assimple aspossible. Inmes-
sage-queuing systems, conversions arehandled byspecial nodes inaqueuing net-
work, known asmessage brokers. Amessage broker actsasanapplication-level
gateway inamessage-queuing system. Itsmainpurpose istoconvert incoming
messages sothattheycanbeunderstood bythedestination application. Notethat
toamessage-queuing system, amessage broker isjustanother application. as
shown inFig.4-21. Inotherwords, amessage broker isgenerally notconsidered
tobeanintegral partofthequeuing system.SEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 151
contained intheincoming message canactually betransformed intosomething
appropriate fortheoutgoing message.
However, morecommon istheuseofamessage broker foradvanced enter-
prise application integration (EAI) aswediscussed inChap. 1.Inthiscase,
rather than(only) converting messages, abroker isresponsible formatching appli-
cations based onthemessages thatarebeing exchanged. Insuchamodel, called
publish/subscribe, applications sendmessages intheformofpublishing. Inpar-
ticular, theymaypublish amessage ontopicX,which isthensenttothebroker.
Applications thathavestated theirinterest inmessages ontopicX,thatis,who
havesubscribed tothose messages, willthenreceive these messages fromthe
broker. More advanced forms ofmediation arealsopossible, butwewilldefer
further discussion untilChap. 13.
Attheheartofamessage broker liesarepository ofrulesandprograms that
cantransform amessage oftypeTItooneoftypeT2.Theproblem isdefining
therulesanddeveloping theprograms. Mostmessage broker products comewith
sophisticated development tools, butthebottom lineisstillthattherepository
needs tobefilled byexperts. Hereweseeaperfect example where commercial -
products areoftenmisleadingly saidtoprovide "intelligence," where, infact,the
onlyintelligence istobefound intheheads ofthoseexperts.
ANoteonMessage-Queuing Systems
Considering what wehavesaidabout message-queuing systems, itwould_
appear thattheyhavelongexisted intheformofimplementations fore-mail ser-
vices. E-mail systems aregenerally implemented through acollection ofmailser-
versthatstoreandforward messages onbehalf oftheusersonhostsdirectly con-
nected totheserver. Routing isgenerally leftout,ase-mail systems canmake
direct useoftheunderlying transport services. Forexample, inthemailprotocol
fortheInternet, SMTP (Postel, 1982), amessage istransferred bysetting upa
direct TCPconnection tothedestination mailserver.
What makes e-mail systems special compared tomessage-queuing systems is
thattheyareprimarily aimed atproviding direct support forendusers. This
explains, forexample, whyanumber ofgroupware applications arebased directly
onane-mail system (Khoshafian andBuckiewicz 1995). Inaddition, e-mail sys-
temsmayhaveveryspecific requirements suchasautomatic message filtering,
support foradvanced messaging databases (e.g., toeasily retrieve previously
stored messages), andsoon.
General message-queuing systems arenotaimed atsupporting onlyendusers.
Animportant issueisthattheyaresetuptoenable persistent communication be-
tween processes, regardless ofwhether aprocess isrunning auserapplication.
handling access toadatabase, performing computations, andsoon.Thisapproach
leadstoadifferent setofrequirements formessage-queuing systems thanpuree-
mailsystems. Forexample, e-mail systems generally neednotprovide guaranteed152 COMMUNICA nON CHAP.4
message delivery, message priorities, logging facilities, efficient multicasting,
loadbalancing, faulttolerance, andsoonforgeneral usage.
General-purpose message-queuing systems, therefore, haveawiderange of
applications, including e-mail, workflow, groupware, andbatchprocessing. How-
ever,aswehavestated before, themostimportant application areaistheintegra-
tionofa(possibly widely-dispersed) collection ofdatabases andapplications into
afederated information system (Hohpe andWoolf, 2004). Forexample, aquery
expanding several databases mayneedtobesplitintosubqueries thatarefor-
warded toindividual databases. Message-queuing systems assist byproviding the
basic means topackage eachsubquery intoamessage androuting ittotheap-
propriate database. Other communication facilities wehavediscussed inthis
chapter arefarlessappropriate.
4.3.3 Example: IBM's WebSphere Message-Queuing System
Tohelpunderstand howmessage-queuing systems work inpractice, letus
takealookatonespecific system, namely themessage-queuing system thatis
partofIBM's WebSphere product. Formerly known asMQSeries, itisnow
referred toasWebSphere MQ. There isawealth ofdocumentation onWeb-
Sphere MQ,andinthefollowing wecanonlyresort tothebasicprinciples. Many
architectural details concerning message-queuing networks canbefound inIBM
(2005b, 2005d). Programming message-queuing networks isnotsomething that
canbelearned onaSunday afternoon, andMQ's programming guide (IBM,
2005a) isagoodexample showing thatgoing fromprinciples topractice may
require substantial effort.
Overview
Thebasic architecture ofanMQqueuing network isquitestraightforward,
andisshown inFig.4-22. Allqueues aremanaged byqueue managers. A
queue manager isresponsible forremoving messages fromitssendqueues, and
forwarding thosetootherqueue managers. Likewise, aqueue manager isrespon-
sibleforhandling incoming messages bypicking themupfromtheunderlying
network andsubsequently storing eachmessage intheappropriate inputqueue. To
giveanimpression ofwhatmessaging canmean: amessage hasamaximum de-
faultsizeof4MB,butthiscanbeincreased upto100MB.Aqueue isnormally
restricted to2GBofdata,butdepending ontheunderlying operating system, this
maximum canbeeasily sethigher.
Queue managers arepairwise connected through message channels, which
areanabstraction oftransport-level connections. Amessage channel isaunidirec-
tional, reliable connection between asending andareceiving queue manager,
through which queued messages aretransported. Forexample, anInternet-based
message channel isimplemented asaTCPconnection. EachofthetwoendsofaSEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 153
message channel ismanaged byamessage channel agent (MCA). Asending
:MCA isbasically doing nothing elsethanchecking sendqueues foramessage,
wrapping itintoatransport-level packet, andsending italong theconnection toits
associated receiving MCA. Likewise, thebasic taskofareceiving MCA islisten-
ingforanincoming packet, unwrapping it,andsubsequently storing theunwrap-
pedmessage intotheappropriate queue.
Figure 4-22. General organization ofIBM's message-queuing system.
Queue managers canbelinked intothesame process astheapplication for
which itmanages thequeues. Inthatcase, thequeues arehidden fromtheapplica-
tionbehind astandard interface, buteffectively canbedirectly manipulated bythe
application. Analternative organization isoneinwhich queue managers andap-
plications runonseparate machines. Inthatcase, theapplication isoffered the
same interface aswhen thequeue manager iscolocated onthesame machine.
However, theinterface isimplemented asaproxy thatcommunicates withthe
queue manager using traditional RPC-based synchronous communication. Inthis
way, MQbasically retains themodel thatonlyqueues localtoanapplication can
beaccessed.
Channels
Animportant component ofMQisformed bythemessage channels. Each
message channel hasexactly oneassociated sendqueue fromwhich itfetches the
messages itshould transfer totheother end.Transfer along thechannel cantake
place onlyifbothitssending andreceiving MCA areupandrunning. Apart from
starting bothMCAs manually, there areseveral alternative ways tostartachan-
nel,some ofwhich wediscuss next.154 COMMUNICATION CHAP. 4
Onealternative istohaveanapplication directly startitsendofachannel by
activating thesending orreceiving MCA. However, fromatransparency pointof
view, thisisnotaveryattractive alternative. Abetter approach tostartasending
MeA istoconfigure thechannel's sendqueue tosetoffatrigger when amessage
isfirstputintothequeue. Thattrigger isassociated withahandler tostartthe
sending MCA sothatitcanremove messages fromthesendqueue.
Another alternative istostartanMCA overthenetwork. Inparticular, ifone
sideofachannel isalready active, itcansendacontrol message requesting that
theotherMCA tobestarted. Suchacontrol message issenttoadaemon listening
toawell-known address onthesamemachine aswhere theotherMCA istobe
started.
Channels arestopped automatically afteraspecified timehasexpired during
which nomoremessages weredropped intothesendqueue.
EachMCA hasasetofassociated attributes thatdetermine theoverall be-
havior ofachannel. Some oftheattributes arelistedinFig.4-23. Attribute values
ofthesending andreceiving MCA should becompatible andperhaps negotiated
firstbefore achannel canbesetup.Forexample, bothMCAs should obviously
support thesametransport protocol. Anexample ofanonnegotiable attribute is
whether ornotmessages aretobedelivered inthesameorderastheyareputinto
thesendqueue. IfoneMCA wants FIFO delivery, theothermustcomply. Anex-
ample ofanegotiable attribute value isthemaximum message length, which will
simply bechosen astheminimum value specified byeither MCA.
Figure 4-23. Some attributes associated withmessage channel agents.
Message Transfer
Totransfer amessage fromonequeue manager toanother (possibly remote)
queue manager, itisnecessary thateachmessage carries itsdestination address,
forwhich atransmission header isused.Anaddress inMQconsists oftwoparts.
Thefirstpartconsists ofthename ofthequeue manager towhich themessage is
tobedelivered. Thesecond partisthename ofthedestination queue resorting
under thatmanager towhich themessage istobeappended.
Besides thedestination address, itisalsonecessary tospecify theroutethata
message should follow. Route specification isdonebyproviding thename oftheSEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 155
localsendqueue towhich amessage istobeappended. Thus itisnotnecessary to
provide thefullroute inamessage. Recall thateachmessage channel hasexactly
onesendqueue. Bytelling towhich sendqueue amessage istobeappended, we
efectively specify towhich queue manager amessage istobeforwarded.
Inmost cases, routes areexplicitly stored inside aqueue manager inarouting
table. Anentry inarouting tableisapair(destQM, sendQ), where destQM isthe
name ofthedestination queue manager, andsendQ isthename ofthelocal send
queue towhich amessage forthatqueue manager should beappended. (Arouting
tableentry iscalled analiasinMQ.)
Itispossible thatamessage needs tobetransferred across multiple queue
managers before reaching itsdestination. Whenever suchanintermediate queue
manager receives themessage, itsimply extracts thename ofthedestination
queue manager fromthemessage header, anddoesarouting-table look-uptofind
thelocal sendqueue towhich themessage should beappended.
Itisimportant torealize thateachqueue manager hasasystemwide unique
name thatiseffectively usedasanidentifier forthatqueue manager. Theproblem
withusing these names isthatreplacing aqueue manager, orchanging itsname,
willaffect allapplications thatsendmessages toit.Problems canbealleviated by
using alocal alias forqueue manager names. Analiasdefined within aqueue
manager Mlisanother name foraqueue manager M2,butwhich isavailable only
toapplications interfacing toMl. Analiasallows theuseofthesame (logical)
name foraqueue, evenifthequeue manager ofthatqueue changes. Changing the
name ofaqueue manager requires thatwechange itsaliasinallqueue managers.
However, applications canbeleftunaffected.
Figure 4-24. Thegeneral organization ofanMQqueuing network using routing
tables andaliases.156 COMMUNICATION CHAP. 4
Theprinciple ofusing routing tables andaliases isshown inFig.4-24. For
example, anapplication linked toqueue manager QMA canrefer toaremote
queue manager using thelocal aliasLAJ. Thequeue manager willfirstlookup
theactual destination inthealiastable tofinditisqueue manager QMC. The
route toQMC isfound intherouting table, which states thatmessages forQMC
should beappended totheoutgoing queue SQl, which isusedtotransfer mes-
sages toqueue manager QMB. Thelatter willuseitsrouting table toforward the
message toQMC.
Following thisapproach ofrouting andaliasing leads toaprogramming inter-
facethat,fundamentally, isrelatively simple, called theMessage Queue Inter-
face(MQI). Themostimportant primitives ofMQIaresummarized inFig.4-25.
Figure 4-25. Primitives available inthemessage-queuing interface.
Toputmessages intoaqueue, anapplication calls theMQopen primitive,
specifying adestination queue inaspecific queue manager. Thequeue manager
canbenamed using thelocally-available alias. Whether thedestination queue is
actually remote ornotiscompletely transparent totheapplication. MQopen
should alsobecalled iftheapplication wants togetmessages fromitslocal queue.
Only localqueues canbeopened forreading incoming messages. When anappli-
cation isfinished withaccessing aqueue, itshould close itbycalling MQclose.
Messages canbewritten to,orreadfrom, aqueue using MQput andMQget,
respectively. Inprinciple, messages areremoved fromaqueue onapriority basis.
Messages withthesame priority areremoved onafirst-in, first-out basis, thatis,
thelongest pending message isremoved first.Itisalsopossible torequest forspe-
cificmessages. Finally, MQprovides facilities tosignal applications when mes-
sages have arrived, thusavoiding thatanapplication willcontinuously have to
pollamessage queue forincoming messages.
Managing Overlay Networks
From thedescription sofar,itshould beclearthatanimportant partofmanag-
ingMQsystems isconnecting thevarious queue managers intoaconsistent over-
laynetwork. Moreover, thisnetwork needs tobemaintained overtime. Forsmall
networks, thismaintenance willnotrequire much more thanaverage administra-
tivework, butmatters become complicated when message queuing isused to
integrate anddisintegrate large existing systems.SEC. 4.3 MESSAGE-ORIENTED COMMUNICATION 157
Amajor issuewithMQisthatoverlay networks needtobemanually adminis-
trated. Thisadministration notonlyinvolves creating channels between queue
managers, butalsofilling intherouting tables. Obviously, thiscangrowintoa
nightmare. Unfortunately, management support forMQsystems isadvanced only
inthesense thatanadministrator cansetvirtually every possible attribute, and
tweak anythinkable configuration. However, thebottom lineisthatchannels and
routing tables needtobemanually maintained.
Attheheart ofoverlay management isthechannelcontrolfunctioncom-
ponent, which logically sitsbetween message channel agents. Thiscomponent
allows anoperator tomonitor exactly whatisgoing onattwoendpoints ofa
channel. Inaddition, itisusedtocreate channels androuting tables, butalsoto
manage thequeue managers thathostthemessage channel agents. Inaway,this
approach tooverlay management strongly resembles themanagement ofcluster
servers where asingle administration server isused.Inthelattercase,theserver
essentially offers onlyaremote shelltoeachmachine inthecluster, along witha
fewcollective operations tohandle groups ofmachines. Thegoodnewsaboutdis-
tributed-systems management isthatitoffers lotsofopportunities ifyouarelook-
ingforanareatoexplore newsolutions toserious problems.
4.4STREAM-ORIENTED COMMUNICATION
Communication asdiscussed sofarhasconcentrated onexchanging more-or-
lessindependent andcomplete unitsofinformation. Examples include arequest
forinvoking aprocedure, thereplytosucharequest, andmessages exchanged be-
tween applications asinmessage-queuing systems. Thecharacteristic feature of
thistypeofcommunication isthatitdoesnotmatter atwhatparticular pointin
timecommunication takesplace. Although asystem mayperform tooslowortoo
fast,timing hasnoeffect oncorrectness.
There arealsoforms ofcommunication inwhich timing playsacrucial role.
Consider, forexample, anaudio stream builtupasasequence of16-bit samples,
eachrepresenting theamplitude ofthesound waveasisdonethrough PulseCode
Modulation (PCM). Alsoassume thattheaudio stream represents CDquality,
meaning thattheoriginal sound wavehasbeensampled atafrequency of44,100
Hz.Toreproduce theoriginal sound, itisessential thatthesamples intheaudio
stream areplayed outintheordertheyappear inthestream, butalsoatintervals
ofexactly 1/44,100sec.Playing outatadifferent ratewillproduce anincorrect
version oftheoriginal sound.
Thequestion thatweaddress inthissection iswhich facilities adistributed
system should offertoexchange time-dependent information suchasaudio and
video streams. Various network protocols thatdealwithstream-oriented commu-
nication arediscussed inHalsall (2001). Steinmetz andNahrstedt (2004) provide158 COMMUNICATION CHAP. 4
anoverall introduction tomultimedia issues, partofwhich forms stream-oriented
communication. Query processing ondatastreams isdiscussed inBabcock etal.
(2002).
4.4.1 Support forContinuous Media
Support fortheexchange oftime-dependent information isoften formulated
assupport forcontinuous media. Amedium refers tothemeans bywhich infor-
mation isconveyed. These means include storage andtransmission media, pres-
entation media suchasamonitor, andsoon.Animportant typeofmedium isthe
waythatinformation isrepresented. Inotherwords, howisinformation encoded
inacomputer system? Different representations areusedfordifferent types ofin-
formation. Forexample, textisgenerally encoded asASCII orUnicode. Images
canberepresented indifferent formats suchasGIForlPEG. Audio streams can
beencoded inacomputer system by,forexample, taking 16-bit samples using
PCM.
Incontinuous (representation) media, thetemporal relationships between
different dataitemsarefundamental tocorrectly interpreting whatthedataactual-
lymeans. Wealready gaveanexample ofreproducing asound wave byplaying
outanaudio stream. Asanother example, consider motion. Motion canberepres-
ented byaseries ofimages inwhich successive images mustbedisplayed ata
uniform spacing Tintime,typically 30-40 msecperimage. Correct reproduction
requires notonlyshowing thestillsinthecorrect order, butalsoataconstant fre-
quency ofliTimages persecond.
Incontrast tocontinuous media, discrete (representation) media, ischarac-
terized bythefactthattemporal relationships between dataitems arenotfunda-
mental tocorrectly interpreting thedata.Typical examples ofdiscrete media
include representations oftextandstillimages, butalsoobject codeorexecutable
files.
DataStream
Tocapture theexchange oftime-dependent information, distributed systems
generally provide support fordatastreams. Adatastream isnothing butase-
quence ofdataunits.Datastreams canbeapplied todiscrete aswellascontinuous
media. Forexample, UNIX pipes orTCPIIP connections aretypical examples of
(byte-oriented) discrete datastreams. Playing anaudio filetypically requires set-
tingupacontinuous datastream between thefileandtheaudio device.
Timing iscrucial tocontinuous datastreams. Tocapture timing aspects, adis-
tinction isoftenmade between different transmission modes. Inasynchronous
transmission mode thedataitems inastream aretransmitted oneaftertheother,
buttherearenofurther timing constraints onwhentransmission ofitems should
takeplace. Thisistypically thecasefordiscrete datastreams. Forexample, afileSEC. 4.4 STREAM-ORIENTED COMMUNICATION 159
canbetransferred asadatastream, butitismostly irrelevant exactly when the
transfer ofeachitemcompletes.
Insynchronous transmission mode,thereisamaximum end-to-end delay
defined foreachunitinadatastream. Whether adataunitistransferred much fas-
terthanthemaximum tolerated delayisnotimportant. Forexample, asensor may
sample temperature atacertain rateandpassitthrough anetwork toanoperator.
Inthatcase,itmaybeimportant thattheend-to-end propagation timethrough the
network isguaranteed tobelower thanthetimeinterval between taking samples,
butitcannot doanyharmifsamples arepropagated much faster thannecessary.
Finally, inisochronous transmission mode,itisnecessary thatdataunitsare
transferred ontime.Thismeans thatdatatransfer issubject toamaximum and
minimum end-to-enddelay, alsoreferred toasbounded (delay) jitter. Isochronous
transmission mode isparticularly interesting fordistributed multimedia systems,
asitplaysacrucial roleinrepresenting audio andvideo. Inthischapter, wecon-
sideronlycontinuous datastreams usingisochronous transmission, which wewill
refertosimply asstreams.
Streams canbesimple orcomplex. Asimplestreamconsists ofonlyasingle
sequence ofdata,whereas acomplex streamconsists ofseveral related simple
streams, called substreams. Therelation between thesubstreams inacomplex
stream isoftenalsotimedependent. Forexample, stereo audio canbetransmitted
bymeans ofacomplex stream consisting oftwosubstreams, eachusedforasin-
gleaudiochannel. Itisimportant, however, thatthosetwosubstreams arecontinu-
ously synchronized. Inotherwords, dataunitsfromeachstream aretobecom-
municated pairwise toensure theeffect ofstereo. Another example ofacomplex
stream isonefortransmitting amovie. Suchastream could consist ofasingle
video stream, along withtwostreams fortransmitting thesound ofthemovie in
stereo. Afourth stream might contain subtitles forthedeaf,oratranslation intoa
different language thantheaudio. Again, synchronization ofthesubstreams isim-
portant. Ifsynchronization fails,reproduction ofthemovie fails.Wereturn to
stream synchronization below.
From adistributed systems perspective, wecandistinguish several elements
thatareneeded forsupporting streams. Forsimplicity, weconcentrate onstream-
ingstored data,asopposed tostreaming livedata.Inthelattercase.dataiscap-
turedinrealtimeandsentoverthenetwork torecipients. Themaindifference be-
tween thetwoisthatstreaming livedataleaves lessopportunities fortuning a
stream. Following Wuetal.(2001), wecanthensketch ageneral client-server ar-
chitecture forsupporting continuous multimedia streams asshown inFig.4-26.
Thisgeneral architecture reveals anumber ofimportant issues thatneedtobe
dealtwith.Inthefirstplace, themultimedia data,notably video andtoalesser
extent audio, willneedtobecompressed substantially inordertoreduce there-
quired storage andespecially thenetwork capacity. More important fromtheper-
spective ofcommunication arecontrolling thequality ofthetransmission andsyn-
chronization issues. Wediscuss theseissues next.160 COMMUNICA nON CHAP. 4
Figure 4-26. Ageneral architecture forstreaming stored multimedia dataovera
network.
4.4.2 Streams andQuality ofService
Timing (andother nonfunctional) requirements aregenerally expressed as
Quality ofService (QoS) requirements. These requirements describe what is
needed fromtheunderlying distributed system andnetwork toensure that,forex-
ample, thetemporal relationships inastream canbepreserved. QoSforcontinu-
ousdatastreams mainly concerns timeliness, volume, andreliability. Inthissec-
tionwetakeacloser lookatQoSanditsrelation tosetting upastream.
Much hasbeensaidabout howtospecify required QoS(see,e.g.,Jinand
Nahrstedt, 2004). From anapplication's perspective, inmany casesitboilsdown
tospecifying afewimportant properties (Halsall, 2001):
1.Therequired bitrateatwhich datashould betransported.
2.Themaximum delayuntilasession hasbeensetup(i.e.,when anap-
plication canstartsending data).
3.Themaximum end-to-end delay (i.e.,howlongitwilltakeuntila
dataunitmakes ittoarecipient).
4.Themaximum delayvariance, orjitter.
5.Themaximum round-trip delay.
Itshould benoted thatmany refinements canbemade tothesespecifications, as
explained, forexample, bySteinmetz andNahrstadt (2004). However, when deal-
ingwithstream-oriented communication thatisbased ontheInternet protocol
stack, wesimply havetolivewiththefactthatthebasisofcommunication is
formed byanextremely simple, best-effort datagram service: IP.When thegoing
getstough, asmayeasily bethecaseintheInternet, thespecification ofIPallows
aprotocol implementation todroppackets whenever itseesfit.Many, ifnotallSEC. 4.4 STREAM-ORIENTED COMMUNICATION 161
distributed systems thatsupport stream-oriented communication, arecurrently
builtontopoftheInternet protocol stack. Somuch forQoSspecifications. (Actu-
ally,IPdoesprovide someQoSsupport, butitisrarely implemented.)
Enforcing QoS
Given thattheunderlying system offers onlyabest-effort delivery service, a
distributed system cantrytoconceal asmuch aspossible ofthelackofquality of
service. Fortunately, thereareseveral mechanisms thatitcandeploy.
First, thesituation isnotreally sobadassketched sofar.Forexample, the
Internet provides ameans fordifferentiating classes ofdatabymeans ofitsdif-
ferentiated services. Asending hostcanessentially mark outgoing packets as
belonging tooneofseveral classes, including anexpedited forwarding classthat
essentially specifies thatapacket should beforwarded bythecurrent router with
absolute priority (Davie etal.,2002). Inaddition, thereisalsoanassured for-
warding class, bywhich traffic isdivided intofoursubclasses, along withthree
waystodroppackets ifthenetwork getscongested. Assured forwarding therefore
effectively defines arange ofpriorities thatcanbeassigned topackets, andas
suchallows applications todifferentiate time-sensitive packets fromnoncritical
ones.
Besides thesenetwork-level solutions, adistributed system canalsohelpin
getting dataacross toreceivers. Although therearegenerally notmanytoolsavail-
able,onethatisparticularly useful istousebuffers toreduce jitter. Theprinciple
issimple, asshown inFig.4-27. Assuming thatpackets aredelayed withacer-
tainvariance when transmitted overthenetwork, thereceiver simply stores them
inabuffer foramaximum amount oftime.Thiswillallow thereceiver topass
packets totheapplication ataregular rate,knowing thattherewillalways be
enough packets entering thebuffer tobeplayed backatthatrate.
Figure 4-27. Using abuffer toreduce jitter.
Ofcourse, things maygowrong, asisillustrated bypacket #8inFig.4-27.
Thesizeofthereceiver's buffer corresponds to9seconds ofpackets topasstothe
application. Unfortunately, packet #8took11seconds toreach thereceiver, at162 COMMUNICATION CHAP. 4
Figure 4-28. Theeffect ofpacket lossin(a)noninterleaved transmission and
(b)interleaved transmission.which timethebuffer willhavebeencompletely emptied. Theresult isagapin
theplayback attheapplication. Theonlysolution istoincrease thebuffer size.
Theobvious drawback isthatthedelay atwhich thereceiving application can
startplaying backthedatacontained inthepackets increases aswell.
Other techniques canbeusedaswell.Realizing thatwearedealing withan
underlying best-effort service alsomeans thatpackets maybelost.Tocompensate
forthislossinquality ofservice. weneedtoapply errorcorrection techniqu.es
(Perkins etal.,1998;andWahetal.,2000). Requesting thesender toretransmit a
missing packet isgenerally outofthequestion, sothatforward error correction
(FEe) needs tobeapplied. Awell-known technique istoencode theoutgoing
packets insuchawaythatanykoutofnreceived packets isenough toreconstruct
kcorrect packets.
Oneproblem thatmayoccur isthatasingle packet contains multiple audio
andvideo frames. Asaconsequence, whenapacket islost,thereceiver mayactu-
allyperceive alargegapwhen playing outframes. Thiseffect canbesomewhat
circumvented byinterleaving frames, asshown inFig.4-28. Inthisway,when a
packet islost,theresulting gapinsuccessive frames isdistributed overtime.
Note, however, thatthisapproach doesrequire alarger receive buffer incom-
parison tononinterleaving, andthusimposes ahigher startdelay forthereceiving
application. Forexample, when considering Fig.4-28(b), toplaythefirstfour
frames, thereceiver willneedtohavefourpackets delivered, instead ofonlyone
packet incomparison tononinterleaved transmission.SEC. 4.4 STREAM-ORIENTED COMMUNICATION 163
4.4.3StreamSynchronization
Animportant issueinmultimedia systems isthatdifferent streams, possibly in
theform ofacomplex stream, aremutually synchronized. Synchronization of
streams deals withmaintaining temporal relations between streams. Twotypes of
synchronization occur.
Thesimplest form ofsynchronization isthatbetween adiscrete datastream
andacontinuous datastream. Consider, forexample, aslide show ontheWeb
thathasbeenenhanced withaudio. Each slideistransferred fromtheserver tothe
client intheform ofadiscrete datastream. Atthesame time, theclient should
playoutaspecific (partofan)audio stream thatmatches thecurrent slidethatis
alsofetched fromtheserver. Inthiscase, theaudio stream istobe'synchronized
withthepresentation ofslides.
Amore demanding typeofsynchronization isthatbetween continuous data
streams. Adaily example isplaying amovie inwhich thevideo stream needs to
besynchronized withtheaudio, commonly referred toaslipsynchronization.
Another example ofsynchronization isplaying astereo audio stream consisting of
twosubstreams, oneforeachchannel. Proper playoutrequires thatthetwosub-
streams aretightly synchronized: adifference ofmore than20useecandistort the
stereo effect.
Synchronization takes place atthelevelofthedataunitsofwhich astream is
made up.Inother words, wecansynchronize twostreams onlybetween data
units. Thechoice ofwhatexactly adataunitisdepends verymuch onthelevelof
abstraction atwhich adatastream isviewed. Tomake things concrete, consider
again aCD-quality (single-channel) audio stream. Atthefinest granularity, sucha
stream appears asasequence of16-bit samples. With asampling frequency of
44,100 Hz,synchronization withother audio streams could, intheory, takeplace
approximately every 23usee. Forhigh-quality stereo effects, itturns outthatsyn-
chronization atthislevelisindeed necessary.
However, when weconsider synchronization between anaudio stream anda
video stream forlipsynchronization, amuch coarser granularity canbetaken. As
weexplained, video frames needtobedisplayed atarateof25Hzormore. Tak-
ingthewidely-used NTSC standard of29.97 Hz,wecould group audio samples
intological unitsthatlastaslongasavideo frame isdisplayed (33msec). With an
audio sampling frequency of44,100 Hz,anaudio dataunitcanthusbeaslarge as
1470 samples, or1l,760 bytes (assuming each sample is16bits). Inpractice,
larger unitslasting 40oreven80msec canbetolerated (Steinmetz, 1996).
Synchronization Mechanisms
Letusnowseehowsynchronization isactually done. Twoissues needtobe
distinguished: (1)thebasic mechanisms forsynchronizing twostreams, and(2)
thedistribution ofthose mechanisms inanetworked environment.164 COMMUNICATION CHAP. 4
Synchronization mechanisms canbeviewed atseveral different levels of
abstraction. Atthelowest level, synchronization isdoneexplicitly byoperating on
thedataunitsofsimple streams. Thisprinciple isshown inFig.4-29. Inessence,
thereisaprocess thatsimply executes readandwriteoperations onseveral simple
streams, ensuring thatthoseoperations adhere tospecific timing andsynchroniza-
tionconstraints.
Figure 4-29. Theprinciple ofexplicit synchronization ontheleveldataunits.
Forexample, consider amovie thatispresented astwoinput streams. The
video stream contains uncompressed low-quality images of320x240 pixels, each
encoded byasingle byte, leading tovideo dataunits of76,800 bytes each.
Assume thatimages aretobedisplayed at30Hz,oroneimage every 33msec.
Theaudiostream isassumed tocontain audiosamples grouped intounitsof11760
bytes, eachcorresponding to33msofaudio, asexplained above. Iftheinputproc-
esscanhandle 2.5MB/sec, wecanachieve lipsynchronization bysimply alternat-
ingbetween reading animage andreading ablock ofaudio samples every 33ms.
Thedrawback ofthisapproach isthattheapplication ismade completely
responsible forimplementing synchronization whileithasonlylow-level facilities
available. Abetter approach istoofferanapplication aninterface thatallows itto
moreeasily control streams anddevices. Returning toourexample, assume that
thevideo display hasacontrol interface thatallows ittospecify therateatwhich
images should bedisplayed. Inaddition, theinterface offers thefacility toregister
auser-defined handler thatiscalled eachtimeknewimages havearrived. An
analogous interface isoffered bytheaudio device. Withthesecontrol interfaces,
anapplication developer canwrite asimple monitor program consisting oftwo
handlers, oneforeachstream, thatjointly check ifthevideo andaudio stream are
sufficiently synchronized, andifnecessary, adjust therateatwhich video oraudio
unitsarepresented.
Thislastexample isillustrated inFig.4-30, andistypical formany mul-
timedia middleware systems. Ineffect, multimedia middleware offers acollection
ofinterfaces forcontrolling audio andvideo streams, including interfaces forcon-
trolling devices suchasmonitors, cameras, microphones, etc.Each device andSEC. 4.4 STREAM-ORIENTED COMMUNICATION 165
stream hasitsownhigh-level interfaces, including interfaces fornotifying anap-
plication when some event occurred. Thelatter aresubsequently used towrite
handlers forsynchronizing streams. Examples ofsuchinterfaces aregiven inBlair
andStefani (1998).
Figure 4·30. Theprinciple ofsynchronization assupported byhigh-level interfaces.
Thedistribution ofsynchronization mechanisms isanother issue thatneeds to
belooked at.First, thereceiving sideofacomplex stream consisting ofsub-
streams thatrequire synchronization, needs toknow exactly what todo.Inother
words, itmust have acomplete synchronization specification locally available.
Common practice istoprovide thisinformation implicitly bymultiplexing thedif-
ferent streams intoasingle stream containing alldataunits, including those for
synchronization.
Thislatter approach tosynchronization isfollowed forMPEG streams. The
MPEG (Motion Picture Experts Group) standards form acollection ofalgo-
rithms forcompressing video andaudio. Several MPEG standards exist. MPEG-2,
forexample, wasoriginally designed forcompressing broadcast quality video into
4to6Mbps. InMPEG-2, anunlimited number ofcontinuous anddiscrete streams
canbemerged intoasingle stream. Each input stream isfirstturned intoastream
ofpackets thatcarry atimestamp based ona90-kHz system clock. These streams
aresubsequently multiplexed intoaprogram stream thenconsisting ofvariable-
length packets, butwhich haveincommon thattheyallhavethesame timebase.
Thereceiving sidedemultiplexes thestream, again using thetimestamps ofeach
packet asthebasic mechanism forinterstream synchronization.
Another important issue iswhether synchronization should takeplace atthe
sending orthereceiving side. Ifthesender handles synchronization, itmaybe
possible tomerge streams intoasingle stream withadifferent typeofdataunit.
Consider again astereo audio stream consisting oftwosubstreams, oneforeach
channel. Onepossibility istotransfer eachstream independently tothereceiver
andletthelatter synchronize thesamples pairwise. Obviously, aseachsubstream
maybesubject todifferent delays, synchronization canbeextremely difficult, A166 COMMUNICATION CHAP. 4
better approach istomerge thetwosubstreams atthesender. Theresulting stream
consists ofdataunitsconsisting ofpairsofsamples, oneforeachchannel. There-
ceiver nowmerely hastoreadinadataunit,andsplititintoaleftandrightsam-
ple.Delays forbothchannels arenowidentical.
4.5MULTICAST COMMUNICATION
Animportant topicincommunication indistributed systems isthesupport for
sending datatomultiple receivers, alsoknown asmulticast communication. For
many years, thistopichasbelonged tothedomain ofnetwork protocols, where
numerous proposals fornetwork-level andtransport-level solutions havebeenim-
plemented andevaluated (Janie, 2005; andObraczka, 1998). Amajor issueinall
solutions wassetting upthecommunication pathsforinformation dissemination.
Inpractice, thisinvolved ahuge management effort, inmany cases requiring
human intervention. Inaddition, aslongasthereisnoconvergence ofproposals,
ISPshaveshown tobereluctant tosupport multicasting (DiotetaI.,2000).
Withtheadvent ofpeer-to-peer technology, andnotably structured overlay
management, itbecame easier tosetupcommunication paths. Aspeer-to-peer
solutions aretypically deployed attheapplication layer, various application-level
multicasting techniques havebeenintroduced. Inthissection, wewilltakeabrief
lookatthesetechniques.
Multicast communication canalsobeaccomplished inotherwaysthansetting
upexplicit communication paths. Aswealsoexplore inthissection. gossip-based
information dissemination provides simple (yetoftenlessefficient) waysformul-
ticasting.
4.5.1Application-Level Multicasting
Thebasicideainapplication-level multicasting isthatnodes organize intoan
overlay network, which isthenusedtodisseminate information toitsmembers.
Animportant observation isthatnetwork routers arenotinvolved ingroup
membership. Asaconsequence, theconnections between nodes intheoverlay
network maycrossseveral physical links, andassuch,routing messages within
theoverlay maynotbeoptimal incomparison towhatcould havebeenachieved
bynetwork-level routing.
Acrucial design issueistheconstruction oftheoverlay network. Inessence,
therearetwoapproaches (El-Sayed, 2003). First,nodes mayorganize themselves
directly intoatree,meaning thatthereisaunique (overlay) pathbetween every
pairofnodes. Analternative approach isthatnodes organize intoamesh network
inwhich everynodewillhavemultiple neighbors and,ingeneral, thereexistmul-
tiplepaths between every pairofnodes. Themaindifference between thetwois
thatthelattergenerally provides higher robustness: ifaconnection breaks (e.g.,SEC. 4.5 MULTICAST COMMUNICATION 167
because anodefails), there willstillbeanopportunity todisseminate information
without having toimmediately reorganize theentire overlay network.
Tomake matters concrete, letusconsider arelatively simple scheme forcon-
structing amulticast treeinChord, which wedescribed inChap. 2.Thisscheme
wasoriginally proposed forScribe (Castro etal.,2002) which isanapplication-
level multicasting scheme builtontopofPastry (Rowstron andDruschel, 2001).
Thelatter isalsoaDHT-based peer-to-peer system.
Assume anode wants tostartamulticast session. Tothisend,itsimply gen-
erates amulticast identifier, saymidwhich isjustarandomly-chosen 160-bit key.
Itthenlooks upsucc(mid), which isthenoderesponsible forthatkey,andpro-
motes ittobecome therootofthemulticast treethatwillbeusedtosending data
tointerested nodes. Inorder tojointhetree,anodePsimply executes theopera-
tionLOOKUP(mid) having theeffect thatalookup message withtherequest to
jointhemulticast group midwillberouted from Ptosuccimid). Aswemen-
tioned before, therouting algorithm itself willbeexplained indetail inChap. 5.
Onitswaytoward theroot,thejoinrequest willpassseveral nodes. Assume it
firstreaches node Q.IfQhadnever seenajoinrequest formidbefore, itwill
become aforwarder forthatgroup. Atthatpoint, Pwillbecome achild ofQ
whereas thelatter willcontinue toforward thejoinrequest totheroot.Ifthenext
nodeontheroot,sayRisalsonotyetaforwarder, itwillbecome oneandrecord
Q.asitschildandcontinue tosendthejoinrequest.
Ontheother hand, ifQ(orR)isalready aforwarder formid,itwillalso
record theprevious sender asitschild (i.e.,PorQ,respectively), butthere will
notbeaneedtosendthejoinrequest totherootanymore, asQ(orR)willalready
beamember ofthemulticast tree.
Nodes suchasPthathaveexplicitly requested tojointhemulticast treeare,
bydefinition, alsoforwarders. Theresult ofthisscheme isthatweconstruct a
multicast treeacross theoverlay network withtwotypes ofnodes: pureforward-
ersthatactashelpers, andnodes thatarealsoforwarders, buthaveexplicitly re-
quested tojointhetree.Multicasting isnowsimple: anodemerely sends amulti-
castmessage toward therootofthetreebyagain executing theLOOKUP(mid) op-
eration, afterwhich thatmessage canbesentalong thetree.
Wenotethatthishigh-level description ofmulticasting inScribe doesnotdo
justice toitsoriginal design. Theinterested reader istherefore encouraged totake
alookatthedetails, which canbefound inCastro etal.(2002).
Overlay Construction
From thehigh-level description given above, itshould beclear thatalthough
building atreebyitself isnotthatdifficult oncewehaveorganized thenodes into
anoverlay, building anefficient treemaybeadifferent story. Note thatinour
description sofar,theselection ofnodes thatparticipate inthetreedoesnottake168 COMMUNICATION CHAP. 4
intoaccount anyperformance metrics: itispurely based onthe(logical) routing of
messages through theoverlay.
Figure 4-31. Therelation between linksinanoverlay andactual network-level routes.
Tounderstand theproblem athand, takealookatFig.4-31which shows a
small setoffournodes thatareorganized inasimple overlay network, withnode
Aforming therootofamulticast tree.Thecostsfortraversing aphysical linkare
alsoshown. Now, whenever Amulticasts amessage totheothernodes, itisseen
thatthismessage willtraverse eachofthelinks<.B,Rb», <Ra,Rb>, «Rc,Rd»,
and<D,Rd»twice. Theoverlay network would havebeenmore efficient ifwe
hadnotconstructed anoverlay linkfromBtoD,butinstead fromAtoC.Sucha
configuration would havesaved thedouble traversal across links«Ra,Rb>and
<Rc,Rd>.
Thequality ofanapplication-level multicast treeisgenerally measured by
threedifferent metrics: linkstress, stretch, andtreecost. Linkstress isdefined
perlinkandcounts howoftenapacket crosses thesamelink(ChuetaI.,2002). A
linkstress greater than1comes fromthefactthatalthough atalogical levela
packet maybeforwarded along twodifferent connections, partofthose connec-
tionsmayactually correspond tothesamephysical link,asweshowed inFig.4-
31.
ThestretchorRelative DelayPenalty(RDP) measures theratiointhedelay
between twonodes intheoverlay, andthedelay thatthose twonodes would
experience intheunderlying network. Forexample, intheoverlay network, mes-
sagesfromBtoCfollow therouteB~Rb~Ra~Rc~C,having atotalcost
of59units. However, messages would havebeenrouted intheunderlying net-
workalongthepathB~Rb~Rd~Rc~C,withatotalcostof-+7units, lead-
ingtoastretch of1.255. Obviously, when constructing anoverlay network, the
goalistominimize theaggregated stretch, orsimilarly, theaverage RDP meas-
uredoverallnodepairs.
Finally, thetreecostisaglobal metric, generally related tominimizing the
aggregated linkcosts. Forexample, ifthecostofalinkistaken tobethedelay be-
tween itstwoendnodes, thenoptimizing thetreecostboilsdown tofinding aSEC. 4.5 MULTICAST COMMUNICATION 169
minimal spanning treeinwhich thetotaltimefordisseminating information toall
nodes isminimal.
Tosimplify matters somewhat, assume thatamulticast group hasanassoci-
atedandwell-known nodethatkeeps trackofthenodes thathavejoined thetree.
When anewnodeissues ajoinrequest, itcontacts thisrendezvous nodetoobtain
a(potentially partial) listofmembers. Thegoalistoselect thebestmember that
canoperate asthenewnode's parent inthetree.Whoshould itselect? There are
manyalternatives anddifferent proposals oftenfollow verydifferent solutions.
Consider, forexample, amulticast group withonlyasingle source. Inthis
case,theselection ofthebestnodeisobvious: itshould bethesource (because in
thatcasewecanbeassured thatthestretch willbeequalto1).However, indoing
so,wewould introduce astartopology withthesource inthemiddle. Although
simple, itisnotdifficult toimagine thesource mayeasily become overloaded. In
otherwords, selection ofanodewillgenerally beconstrained insuchawaythat
onlythose nodes maybechosen whohavekorlessneighbors, withkbeing a
design parameter. Thisconstraint severely complicates thetree-establishment al-
gorithm, asagoodsolution mayrequire thatpartoftheexisting treeisreconfig-
ured.
Tanetal.(2003) provide anextensive overview andevaluation ofvarious
solutions tothisproblem. Asanillustration, letustakeacloser lookatonespecif-
icfamily, known asswitch-trees (Helder andJamin, 2002). Thebasic ideais
simple. Assume wealready haveamulticast treewithasingle source asroot.In
thistree,anodePcanswitch parents bydropping thelinktoitscurrent parent in
favorofalinktoanother node.Theonlyconstraints imposed onswitching linksis
thatthenewparent cannever beamember ofthesubtree rooted atP(asthis
would partition thetreeandcreate aloop), andthatthenewparent willnothave
toomany immediate children. Thelatterisneeded tolimittheloadofforwarding
messages byanysingle node.
There aredifferent criteria fordeciding toswitch parents. Asimple oneisto
optimize theroutetothesource, effectively minimizing thedelay whenamessage
istobemulticast. Tothisend,eachnoderegularly receives information onother
nodes (wewillexplain onespecific wayofdoing thisbelow). Atthatpoint, the
nodecanevaluate whether another nodewould beabetter parent interms ofdelay
along theroutetothesource, andifso,initiates aswitch.
Another criteria could bewhether thedelay tothepotential otherparent is
lower thantothecurrent parent. Ifevery nodetakesthisasacriterion, thenthe
aggregated delays oftheresulting treeshould ideally beminimal. Inotherwords,
thisisanexample ofoptimizing thecostofthetreeasweexplained above. How-
ever,moreinformation would beneeded toconstruct suchatree,butasitturns
out,thissimple scheme isareasonable heuristic leading toagoodapproximation
ofaminimal spanning tree.
Asanexample, consider thecasewhere anodePreceives information onthe
neighbors ofitsparent. Notethattheneighbors consist ofP'sgrandparent, along170 COMMUNICA nON CHAP. 4
withtheothersiblings ofP'sparent. NodePcanthenevaluate thedelays toeach
ofthesenodes andsubsequently choose theonewiththelowest delay, sayQ,as
itsnewparent. Tothatend,itsends aswitch request toQ.Toprevent loops from
being formed duetoconcurrent switching requests. anodethathasanoutstanding
switch request willsimply refuse toprocess anyincoming requests. Ineffect, this
leadstoasituation where onlycompletely independent switches canbecarried
outsimultaneously. Furthermore, Pwillprovide Qwithenough information to
allow thelattertoconclude thatbothnodes havethesameparent, orthatQisthe
grandparent.
Animportant problem thatwehavenotyetaddressed isnodefailure. Inthe
caseofswitch-trees, asimple solution isproposed: whenever anodenotices that
itsparent hasfailed, itsimply attaches itselftotheroot.Atthatpoint, theoptimi-
zation protocol canproceed asusualandwilleventually place thenodeatagood
pointinthemulticast tree.Experiments described inHelder andJamin (2002)
showthattheresulting treeisindeed closetoaminimal spanning one.
4.5.2 Gossip-Based DataDissemination
Anincreasingly important technique fordisseminating information istorely
onepidemic behavior. Observing howdiseases spread among people, researchers
havesincelonginvestigated whether simple techniques could bedeveloped for
spreading information inverylarge-scale distributed systems. Themaingoalof
theseepidemic protocols istorapidly propagate information among alargecol-
lection ofnodes using onlylocalinformation. Inotherwords, thereisnocentral
component bywhich information dissemination iscoordinated.
Toexplain thegeneral principles ofthesealgorithms, weassume thatall·up-
datesforaspecific dataitemareinitiated atasingle node.Inthisway,wesimply
avoid write-write conflicts. Thefollowing presentation isbased ontheclassical
paper byDemers etal.(1987) onepidemic algorithms. Arecent overview ofepi-
demic information dissemination canbefound inEugster atel.(2004).
Information Dissemination Models
Asthename suggests, epidemic algorithms arebased onthetheory ofepi-
demics, which studies thespreading ofinfectious diseases. Inthecaseoflarge-
scaledistributed systems, instead ofspreading diseases, theyspread information.
Research onepidemics fordistributed systems alsoaimsatacompletely different
goal:whereas health organizations willdotheirutmost besttoprevent infectious
diseases fromspreading across largegroups ofpeople, designers ofepidemic al-
gorithms fordistributed systems willtryto"infect" allnodes withnewinforma-
tionasfastaspossible.
Using theterminology fromepidemics, anodethatispartofadistributed sys-
temiscalled infected ifitholds datathatitiswilling tospread toothernodes. ASEC. 4.5 MULTICAST COMMUNICA nON 171
nodethathasnotyetseenthisdataiscalled susceptible. Finally, anupdated
nodethatisnotwilling orabletospread itsdataissaidtoberemoved. Notethat
weassume wecandistinguish oldfromnewdata,forexample, because ithas
beentimestamped orversioned. Inthislight,nodes arealsosaidtospread updates.
Apopular propagation model isthatofanti-entropy. Inthismodel, anodeP
picks another nodeQatrandom, andsubsequently exchanges updates withQ.
There arethreeapproaches toexchanging updates:
1.Ponlypushes itsownupdates toQ
2.Ponlypullsinnewupdates fromQ
3.PandQsendupdates toeachother(i.e.,apush-pull approach)
When itcomes torapidly spreading updates, onlypushing updates turnsoutto
beabadchoice. Intuitively, thiscanbeunderstood asfollows. First,notethatina
purepush-based approach, updates canbepropagated onlybyinfected nodes.
However, ifmany nodes areinfected, theprobability ofeachoneselecting asus-
ceptible nodeisrelatively small. Consequently, chances arethataparticular node
remains susceptible foralongperiod simply because itisnotselected byan
infected node.
Incontrast, thepull-based approach works much better whenmany nodes are
infected. Inthatcase,spreading updates isessentially triggered bysusceptible
nodes. Chances arelargethatsuchanodewillcontact aninfected onetosubse-
quently pullintheupdates andbecome infected aswell.
Itcanbeshown thatifonlyasingle nodeisinfected, updates willrapidly
spread across allnodes using either formofanti-entropy, although push-pull
remains thebeststrategy (Jelasity etal.,2005a). Define around asspanning a
period inwhich every nodewillatleastoncehavetakentheinitiative toexchange
updates witharandomly chosen othernode. Itcanthenbeshown thatthenumber
ofrounds topropagate asingle update toallnodes takesO(log (N)) rounds, where
Nisthenumber ofnodes inthesystem. Thisindicates indeed thatpropagating
updates isfast,butabove allscalable.
Onespecific variant ofthisapproach iscalled rumor spreading, orsimply
gossiping. Itworks asfollows. IfnodePhasjustbeenupdated fordataitemx,it
contacts anarbitrary othernodeQandtriestopushtheupdate toQ.However, itis
possible thatQwasalready updated byanother node. Inthatcase,Pmaylose
interest inspreading theupdate anyfurther, saywithprobability 11k.Inother
words, itthenbecomes removed.
Gossiping iscompletely analogous toreallife.When Bobhassomehotnews
tospread around, hemayphone hisfriend Alicetelling herallabout it.Alice, like
Bob,willbereally excited tospread thegossip toherfriends aswell.However,
shewillbecome disappointed whenphoning afriend, sayChuck, onlytohearthat172 COMMUNICATION CHAP. 4
thenewshasalready reached him.Chances arethatshewillstopphoning other
friends, forwhatgoodisitiftheyalready know?
Gossiping turnsouttobeanexcellent wayofrapidly spreading news. How-
ever,itcannot guarantee thatallnodes willactually beupdated (Demers etaI.,
1987). Itcanbeshown thatwhenthereisalargenumber ofnodes thatparticipate
intheepidemics, thefraction sofnodes thatwillremain ignorant ofanupdate,
thatis,remain susceptible, satisfies theequation: '
s=e-(k +\)(1-.1')
Fig.4-32shows in(s)asafunction ofk.Forexample, ifk=4,In(51)=-4.97,
sothatsislessthan0.007, meaning thatlessthan0.7%ofthenodes remain sus-
ceptible. Nevertheless, special measures areneeded toguarantee thatthosenodes
willalsobeupdated. Combining anti-entropy withgossiping willdothetrick.
Figure 4-32. Therelation between thefraction sofupdate-ignorant nodes and
theparameter kinpuregossiping. Thegraph displays lnis)asafunction ofk.
Oneofthemainadvantages ofepidemic algorithms istheirscalability, dueto
thefactthatthenumber ofsynchronizations between processes isrelatively small
compared tootherpropagation methods. Forwide-area systems, LinandMarzullo
(1999) showthatitmakes sensetotaketheactual network topology intoaccount
toachieve better results. Intheirapproach, nodes thatareconnected toonlyafew
other nodes arecontacted witharelatively highprobability. Theunderlying
assumption isthatsuchnodes formabridge tootherremote partsofthenetwork;
therefore, theyshould becontacted assoonaspossible. Thisapproach isreferred
toasdirectional gossiping andcomes indifferent variants.
Thisproblem touches uponanimportant assumption thatmostepidemic solu-
tionsmake, namely thatanodecanrandomly select anyothernodetogossip with.
Thisimplies that,inprinciple, thecomplete setofnodes should beknown toeach
member. Inalargesystem, thisassumption canneverhold.SEC. 4.5 MULTICAST COMMUNICATION 173
Fortunately, thereisnoneedtohavesuchalist.Asweexplained inChap. 2,
maintaining apartial viewthatismoreorlesscontinuously updated willorganize
thecollection ofnodes intoarandom graph. Byregularly updating thepartial
viewofeachnode,random selection isnolonger aproblem.
Removing Data
Epidemic algorithms areextremely good forspreading updates. However,
theyhavearather strange side-effect: spreading thedeletion ofadataitemis
hard.Theessence oftheproblem liesinthefactthatdeletion ofadataitemdes-
troysallinformation onthatitem.Consequently, when adataitemissimply re-
moved fromanode, thatnodewilleventually receive oldcopies ofthedataitem
andinterpret thoseasupdates onsomething itdidnothavebefore.
Thetrickistorecord thedeletion ofadataitemasjustanother update, and
keeparecord ofthatdeletion. Inthisway,oldcopies willnotbeinterpreted as
something new,butmerely treated asversions thathavebeenupdated byadelete
operation. Therecording ofadeletion isdonebyspreading death certificates.
Ofcourse, theproblem withdeath certificates isthattheyshould eventually
becleaned up,orotherwise eachnodewillgradually buildahugelocaldatabase
ofhistorical information ondeleted dataitems thatisotherwise notused.Demers
etal.(1987) propose tousewhattheycalldormant deathcertificates. Eachdeath
certificate istimestamped when itiscreated. Ifitcanbeassumed thatupdates
propagate toallnodes within aknown finite time,thendeath certificates canbe
removed afterthismaximum propagation timehaselapsed.
However, toprovide hardguarantees thatdeletions areindeed spread toall
nodes, onlyaveryfewnodes maintain dormant death certificates thatarenever
thrown away. Assume nodePhassuchacertificate fordataitemx.Ifbyany
chance anobsolete update forxreaches P,Pwillreactbysimply spreading the
deathcertificate forxagain.
Applications
Tofinalize thispresentation, letustakealookatsomeinteresting applications
ofepidemic protocols. Wealready mentioned spreading updates, which isperhaps
themostwidely-deployed application. Also,inChap. 2wediscussed howprovid-
ingpositioning information aboutnodes canassistinconstructing specific topolo-
gies.Inthesamelight,gossiping canbeusedtodiscover nodes thathaveafew
outgoing wide-area links, tosubsequently apply directional gossiping aswemen-
tioned above. .
Another interesting application areaissimply collecting, oractually aggregat-
inginformation (Jelasity etal.,2005b). Consider thefollowing information174 COMMUNICA nON CHAP. 4
IfthereNnodes, theneventually eachnodewillcompute theaverage, which is
liN. Asaconsequence, every nodeicanestimate thesizeofthesystem asbeing
Ilxi' Thisinformation alone canbeusedtodynamically adjust various system pa-
rameters. Forexample, thesizeofthepartial view(i.e.,thenumber ofneighbors
thateachnodes keeps trackof)should bedependent onthetotalnumber ofparti-
cipating nodes. Knowing thisnumber willallow anodetodynamically adjust the
sizeofitspartial view. Indeed, thiscanbeviewed asaproperty ofself-manage-
ment.
Computing theaverage mayprove tobedifficult when nodes regularly join
andleave thesystem. Onepractical solution tothisproblem istointroduce
epochs. Assuming thatnodeIisstable, itsimply startsanewepoch nowandthen.
When nodeiseesanewepoch forthefirsttime,itresets itsownvariable Xito
zeroandstartscomputing theaverage again.
Ofcourse, otherresults canalsobecomputed. Forexample, instead ofhaving
afixednode(x1)startthecomputation oftheaverage, wecaneasily pickaran-
domnodeasfollows. Every nodeiinitially setsXitoarandom number fromthe
sameinterval, say[0,I],andalsostores itpermanently asm..Upon anexchange
between nodes iandj,eachchange theirvalueto:exchange. Every nodeiinitially chooses anarbitrary number, sayXi-When nodei
contacts nodej,theyeachupdate theirvalueas:
Obviously. afterthisexchange, bothiandjwillhavethesamevalue. Infact.itis
notdifficult toseethateventually allnodes willhavethesamevalue, namely, the
average ofallinitial values. Propagation speed isagainexponential.
What usedoescomputing theaverage have? Consider thesituation thatall
nodes ihavesetXitozero,except forxI,which hassetittoI:
Eachnodeiforwhich m,<Xiwilllosethecompetition forbeing theinitiator in
starting thecomputation oftheaverage. Intheend,therewillbeasingle winner.
Ofcourse, although itiseasytoconclude thatanodehaslost,itismuch moredif-
ficult todecide thatithaswon,asitremains uncertain whether allresults have
comein.Thesolution tothisproblem istobeoptimistic: anodealways assumes it
isthewinner untilproven otherwise. Atthatpoint, itsimply resets thevariable it
isusing forcomputing theaverage tozero.Notethatbynow, several different
computations (inourexample computing amaximum andcomputing anaverage)
maybeexecuting concurrently.SEC. 4.6 SUMMARY 175
4.6SU~IMARY
Having powerful andflexible facilities forcommunication between processes
isessential foranydistributed system. Intraditional network applications, com-
munication isoftenbased onthelow-level message-passing primitives offered by
thetransport layer. Animportant issueinmiddleware systems istoofferahigher
levelofabstraction thatwillmake iteasier toexpress communication between
processes thanthesupport offered bytheinterface tothetransport layer.
Oneofthemostwidely usedabstractions istheRemote Procedure Call
(RPC). Theessence ofanRPCisthataservice isimplemented bymeans ofapro-
cedure, ofwhich thebodyisexecuted ataserver. Theclient isoffered onlythe
signature oftheprocedure, thatis,theprocedure's name along withitsparame-
ters.When theclient callstheprocedure, theclient-side implementation, called a
stub,takescareofwrapping theparameter values intoamessage andsending that
totheserver. Thelattercallstheactual procedure andreturns theresults, againin
amessage. Theclient's stubextracts theresult values fromthereturn message and
passes itbacktothecalling client application.
RPCs offer synchronous communication facilities, bywhich aclient is
blocked untiltheserver hassentareply. Although variations ofeither mechanism
existbywhich thisstrictsynchronous model isrelaxed, itturnsoutthatgeneral-
purpose, high-level message-oriented models areoftenmoreconvenient.
Inmessage-oriented models, theissues arewhether ornotcommunication is
persistent, andwhether ornotcommunication issynchronous. Theessence ofper-
sistent communication isthatamessage thatissubmitted fortransmission, is
stored bythecommunication system aslongasittakes todeliver it.Inother
words, neither thesender northereceiver needs tobeupandrunning formessage
transmission totakeplace. Intransient communication, nostorage facilities are
offered, sothatthereceiver mustbeprepared toaccept themessage when itis
sent.
Inasynchronous communication, thesender isallowed tocontinue im-
mediately afterthemessage hasbeensubmitted fortransmission, possibly before
ithasevenbeensent.Insynchronous communication, thesender isblocked at
leastuntilamessage hasbeenreceived. Alternatively, thesender maybeblocked
untilmessage delivery hastakenplaceorevenuntilthereceiver hasresponded as
withRPCs.
Message-oriented middle waremodels generally offerpersistent asynchronous
communication, andareusedwhere RPCs arenotappropriate. Theyareoften
usedtoassist theintegration of(widely-dispersed) collections ofdatabases into
large-scale information systems. Other applications include e-mail andworkflow.
Averydifferent formofcommunication isthatofstreaming, inwhich the
issueiswhether ornottwosuccessive messages haveatemporal relationship. In
continuous datastreams, amaximum end-to-end delay isspecified foreachmes-
sage.Inaddition, itisalsorequired thatmessages aresentsubject toaminimum176 COMMUNICATION CHAP.4
end-to-end delay. Typical examples ofsuchcontinuous datastreams arevideo and
audio streams. Exactly whatthetemporal relations are,orwhatisexpected from
theunderlying communication subsystem interms ofquality ofservice isoften
difficult tospecify andtoimplement. Acomplicating factor istheroleofjitter.
Eveniftheaverage performance isacceptable, substantial variations indelivery
timemayleadtounacceptable performance.
Finally, animportant classofcommunication protocols indistributed systems
ismulticasting. Thebasicideaistodisseminate information fromonesender to
multiple receivers. Wehavediscussed twodifferent approaches. First, multicast-
ingcanbeachieved bysetting upatreefromthesender tothereceivers. Consid-
eringthatitisnowwellunderstood hownodes canself-organize intopeer-to-peer
system, solutions havealsoappeared todynamically setuptreesinadecentral-
izedfashion.
Another important classofdissemination solutions deploys epidemic proto-
cols.These protocols haveproven tobeverysimple, yetextremely robust. Apart
from merely spreading messages, epidemic protocols canalsobeefficiently
deployed foraggregating information across alargedistributed system.
PROBLEMS
1.Inmany layered protocols, eachlayer hasitsownheader. Surely itwould bemore
efficient tohaveasingle header atthefront ofeachmessage withallthecontrol init
thanallthese separate headers. Whyisthisnotdone?
2.Whyaretransport-level communication services often inappropriate forbuilding dis-
tributed applications?
3.Areliable multicast service allows asender toreliably passmessages toacollection of
receivers. Does suchaservice belong toamiddleware layer, orshould itbepartofa
lower-level layer?
4.Consider aprocedure incr withtwointeger parameters. Theprocedure adds oneto
eachparameter. Now suppose thatitiscalled withthesame variable twice, forex-
ample. asincr(i, i).Ifiisinitially O.what.value willithaveafterward ifcall-by-refer-
enceisused? Howabout ifcopy/restore isused?
5.Chasaconstruction called aunion, inwhich afieldofarecord (called astruct inC)
canholdanyone ofseveral alternatives. Atruntime, there isnosure-fire waytotell
which oneisinthere. Does thisfeature ofChaveanyimplications forremote proce-
durecall?Explain youranswer.
6.Onewaytohandle parameter conversion inRPC systems istohave each machine
sendparameters initsnative representation, withtheother onedoing thetranslation, if
needbe.Thenative system could beindicated byacodeinthefirstbyte. However,
since locating thefirstbyteinthefirstword isprecisely theproblem, canthiswork?CHAP. 4 PROBLEMS 177
7.Assume aclient callsanasynchronous RPCtoaserver, andsubsequently waits until
theserver returns aresult using another asynchronous RPC. Isthisapproach thesame
asletting theclient execute anormal RPC? What ifwereplace theasynchronous
RPCs withasynchronous RPCs?
8.Instead ofletting aserver register itself withadaemon asinDCE, wecould also
choose toalways assign itthesameendpoint. Thatendpoint canthenbeusedinref-
erences toobjects intheserver's address space. What isthemain drawback ofthis
scheme?
9.Would itbeuseful alsotomake adistinction between static anddynamic RPCs?
10.Describe howconnectionless communication between aclient andaserver proceeds
when using sockets.
11.Explain thedifference between theprimitives MPLbsend andMPLisend inMPI.
12.Suppose thatyoucould make useofonlytransient asynchronous communication
primitives, including onlyanasynchronous receive primitive. Howwould youimple-
mentprimitives fortransient synchronous communication?
13.Suppose thatyoucould make useofonlytransient synchronous communication primi-
tives. How would youimplement primitives fortransient asynchronous communica-
tion?
14.Does itmake sense toimplement persistent asynchronous communication bymeans of
RPCs?
15.Inthetextwestated thatinorder toautomatically startaprocess tofetch messages
fromaninput queue, adaemon isoften usedthatmonitors theinput queue. Givean
alternative implementation thatdoesnotmake useofadaemon.
16.Routing tables inIBMWebSphere, andinmany other message-queuing systems, are
configured manually. Describe asimple waytodothisautomatically.
17.With persistent communication, areceiver generally hasitsownlocal buffer where
messages canbestored when thereceiver isnotexecuting. Tocreate suchabuffer, we
mayneedtospecify itssize.Giveanargument whythisispreferable, aswellasone
against specification ofthesize.
18.Explain whytransient synchronous communication hasinherent scalability problems,
andhowthese could besolved.
19.Giveanexample where multicasting isalsouseful fordiscrete datastreams.
20.Suppose thatinasensor network measured temperatures arenottimestarnped bythe
sensor, butareimmediately senttotheoperator. Would itbeenough toguarantee only
amaximum end-to-end delay?
21.Howcould youguarantee amaximum end-to-end delay when acollection ofcom-
puters isorganized ina(logical orphysical) ring?
22.How could youguarantee aminimum end-to-end delay when acollection ofcom-
puters isorganized ina(logical orphysical) ring?178 COMMUNICATION CHAP. 4
23.Despite thatmulticasting istechnically feasible, thereisverylittlesupport todeploy it
intheInternet. Theanswer tothisproblem istobesought indown-to-earth business
models: noonereally knows howtomake money outofmulticasting. What scheme
canyouinvent?
24.Normally, application-level multicast treesareoptimized withrespect stretch, which is
measured interms ofdelay orhopcounts. Giveanexample where thismetric could
leadtoverypoortrees.
25.When searching forfilesinanunstructured peer-to-peer system, itmayhelptorestrict
thesearch tonodes thathavefilessimilar toyours. Explain howgossiping canhelpto
findthose nodes.5
NAMING
Names playa veryimportant roleinallcomputer systems. Theyareusedto
shareresources, touniquely identify entities, torefertolocations, andmore. An
important issuewithnaming isthatanamecanberesolved totheentity itrefers
to.Name resolution thusallows aprocess toaccess thenamed entity. Toresolve
names, itisnecessary toimplement anaming system. Thedifference between na-
mingindistributed systems andnondistributed systems liesinthewaynaming
systems areimplemented.
Inadistributed system, theimplementation ofanaming system isitselfoften
distributed across multiple machines. Howthisdistribution isdoneplays akey
roleintheefficiency andscalability ofthenaming system. Inthischapter, we
concentrate onthreedifferent, important waysthatnames areusedindistributed
systems.
First,afterdiscussing somegeneral issues withrespect tonaming, wetakea
closer lookattheorganization andimplementation ofhuman-friendly names.
Typical examples ofsuchnames include those forfilesystems andtheWorld
Wide Web. Building worldwide, scalable naming systems isaprimary concern
forthesetypesofnames.
Second, names areusedtolocate entities inawaythatisindependent oftheir
current location. Asitturnsout,naming systems forhuman-friendly names are
notparticularly suited forsupporting thistypeoftracking down entities. Most
names donotevenhintattheentity's location. Alternative organizations are
179180 NAMING CHAP.5
needed, suchasthosebeing usedformobile telephony where names arelocation-
independent identifiers, andthosefordistributed hashtables.
Finally, humans oftenprefer todescribe entities bymeans ofvarious charac-
teristics, leading toasituation inwhich weneedtoresolve adescription bymeans
ofattributes toanentity adhering tothatdescription. Thistypeofname resolution
isnotoriously difficult andwewillpayseparate attention toit.
5.1NAMES, IDENTIFIERS, AND ADDRESSES
Letusstartbytaking acloser lookatwhataname actually is.Aname ina
distributed system isastring ofbitsorcharacters thatisusedtorefertoanentity.
Anentity inadistributed system canbepractically anything. Typical examples
include resources suchashosts, printers, disks, andfiles.Other well-known ex-
amples ofentities thatareoftenexplicitly named areprocesses, users, mailboxes,
newsgroups, Webpages, graphical windows, messages, network connections, and
soon.
Entities canbeoperated on.Forexample, aresource suchasaprinter offers
aninterface containing operations forprinting adocument, requesting thestatus of
aprintjob,andthelike.Furthermore, anentity suchasanetwork connection may
provide operations forsending andreceiving data,setting quality-of-service pa-
rameters, requesting thestatus, andsoforth.
Tooperate onanentity, itisnecessary toaccess it,forwhich weneedanac-
cesspoint. Anaccess pointisyetanother, butspecial, kindofentity inadistrib-
utedsystem. Thenameofanaccess pointiscalled anaddress. Theaddress ofan
access pointofanentity isalsosimply called anaddress ofthatentity.
Anentity canoffermorethanoneaccess point. Asacomparison, atelephone
canbeviewed asanaccess pointofaperson, whereas thetelephone number cor-
responds toanaddress. Indeed, many people nowadays haveseveral telephone
numbers, eachnumber corresponding toapointwhere theycanbereached. Ina
distributed system, atypical example ofanaccess pointisahostrunning aspecif-
icserver, withitsaddress formed bythecombination of,forexample, anIFad-
dressandportnumber (i.e.,theserver's transport-level address).
Anentity maychange itsaccess points inthecourse oftime. Forexample.
when amobile computer moves toanother location, itisoftenassigned adifferent
IPaddress thantheoneithadbefore. Likewise, whenaperson moves toanother
cityorcountry, itisoftennecessary tochange telephone numbers aswell.Ina
similar fashion, changing jobsorInternet Service Providers, means changing your
e-mail address.
Anaddress isthusjustaspecial kindofname: itrefers toanaccess point of
anentity. Because anaccess pointistightly associated withanentity, itwould
seemconvenient tousetheaddress ofanaccess pointasaregular name fortheas-
sociated entity. Nevertheless, thisishardly everdoneassuchnaming isgenerally
veryinflexible andoftenhuman unfriendly.SEC. 5.1 NAMES. IDENTIFIERS, AND ADDRESSES 181
Forexample, itisnotuncommon toregularly reorganize adistributed system,
sothataspecific server isnowrunning onadifferent hostthanpreviously. The
oldmachine onwhich theserver usedtoberunning maybereassigned toacom-
pletely different server. Inother words, anentity mayeasily change anaccess
point, oranaccess pointmaybereassigned toadifferent entity. Ifanaddress is
usedtorefertoanentity, wewillhaveaninvalid reference theinstant theaccess
pointchanges orisreassigned toanother entity. Therefore, itismuch better tolet
aservice beknown byaseparate name independent oftheaddress oftheassoci-
atedserver.
Likewise, ifanentity offers morethanoneaccess point, itisnotclearwhich
address touseasareference. Forinstance, many organizations distribute their
Webservice across several servers. Ifwewould usetheaddresses ofthoseservers
asareference fortheWebservice, itisnotobvious which address should be
chosen asthebestone.Again, amuch better solution istohaveasingle namefor
theWebservice independent fromtheaddresses ofthedifferent Webservers.
These examples illustrate thatanameforanentity thatisindependent fromits
addresses isoftenmuch easier andmoreflexible touse.Suchaname iscalled lo-
cation independent.
Inaddition toaddresses, thereareothertypesofnames thatdeserve special
treatment, suchasnames thatareusedtouniquely identify anentity. Atrueiden-
tifierisanamethathasthefollowing properties (Wieringa anddeJonge, 1995):
1.Anidentifier refers toatmostoneentity.
2.Eachentity isreferred tobyatmostoneidentifier.
3.Anidentifier always refers tothesameentity (i.e.,itisnever reused).
Byusing identifiers, itbecomes much easier tounambiguously refertoanentity.
Forexample, assume twoprocesses eachrefertoanentity bymeans ofanidenti-
fier.To check iftheprocesses arereferring tothesameentity, itissufficient to
testifthetwoidentifiers areequal. Suchatestwould notbesufficient ifthetwo
processes wereusingregular, nonunique, nonidentifying names. Forexample, the
name "John Smith" cannot betaken asaunique reference tojustasingle person.
Likewise, ifanaddress canbereassigned toadifferent entity, wecannot use
anaddress asanidentifier. Consider theuseoftelephone numbers, which arerea-
sonably stable inthesense thatatelephone number forsome timerefers tothe
sameperson ororganization. However, usingatelephone number asanidentifier
willnotwork, asitcanbereassigned inthecourse oftime.Consequently, Bob's
newbakery maybereceiving phone callsforAlice's oldantique storeforalong
time.Inthiscase,itwould havebeenbetter touseatrueidentifier forAlice in-
steadofherphone number.
Addresses andidentifiers aretwoimportant typesofnames thatareeachused
forverydifferent purposes. Inmany computer systems, addresses andidentifiers182 NAMING CHAP. 5
arerepresented inmachine-readable formonly,thatis,intheformofbitstrings.
Forexample, anEthernet address isessentially arandom string of48bits.Like-
wise,memory addresses aretypically represented as32-bit or64-bit strings.
Another important typeofname isthatwhich istailored tobeused by
humans, alsoreferred toashuman-friendly names. Incontrast toaddresses and
identifiers, ahuman-friendly name isgenerally represented asacharacter string.
These names appear inmany different forms. Forexample, filesinUNIX systems
havecharacter-string names thatcanbeaslongas255characters, andwhich are
defined entirely bytheuser.Similarly, DNSnames arerepresented asrelatively
simple case-insensitive character strings.
Having names, identifiers, andaddresses brings ustothecentral theme ofthis
chapter: howdoweresolve names andidentifiers toaddresses? Before wegointo
various solutions, itisimportant torealize thatthereisoftenacloserelationship
between nameresolution indistributed systems andmessage routing. Inprinciple,
anaming system maintains aname-to-address binding which initssimplest
formisjustatableof(name, address) pairs. However, indistributed systems that
spanlargenetworks andforwhich many resources needtobenamed, acentral-
izedtableisnotgoing towork.
Instead, whatoftenhappens isthataname isdecomposed intoseveral parts
suchasJtp.cs. vu.nl andthatnameresolution takesplacethrough arecursive look-
upofthoseparts. Forexample, aclient needing toknow theaddress oftheFTP
server named byjtp.cs.vu.nl would firstresolve nltofindtheserver N'Stnl) re-
sponsible fornames thatendwithnl,afterwhich therestofthename ispassed to
server NS(nl). Thisserver maythenresolve thename vutotheserver NStvu.ni)
responsible fornames thatendwithvu.nl whocanfurther handle theremaining
namejtp.cs. Eventually, thisleadstorouting thenameresolution request as:
NS(.) ~NS(nl) ~NS(vu.nl) ~address ofjtp.cs.vu.nl
where NS(.) denotes theserver thatcanreturn theaddress ofNS(nl), alsoknown
astherootserver. NS(vu.nl) willreturn theactual address oftheFTPserver. Itis
interesting tonotethattheboundaries between name resolution andmessage rout-
ingarestarting toblur.
Inthefollowing sections wewillconsider threedifferent classes ofnaming
systems. First,wewilltakealookathowidentifiers canberesolved toaddresses.
Inthiscase,wewillalsoseeanexample where name resolution isactually indis-
tinguishable frommessage routing. Afterthat,weconsider human-friendly names
anddescriptive names (i.e.,entities thataredescribed byacollection ofnames).
5.2FLAT NAMING
Above, weexplained thatidentifiers areconvenient touniquely represent enti-
ties.Inmany cases, identifiers aresimply random bitstrings. which wecon-
veniently refertoasunstructured, orflatnames. Animportant property ofsuchaSEC. 5.2 FLAT NAMING 183
name isthatitdoesnotcontain anyinformation whatsoever onhowtolocate the
access pointofitsassociated entity. Inthefollowing, wewilltakealookathow
flatnames canberesolved, or,equivalently, howwecanlocate anentity when
given onlyitsidentifier.
5.2.1 Simple Solutions
Wefirstconsider twosimple solutions forlocating anentity. Bothsolutions
areapplicable onlytolocal-area networks. Nevertheless, inthatenvironment, they
oftendothejobwell,making theirsimplicity particularly attractive.
Broadcasting andMulticasting
Consider adistributed system builtonacomputer network: thatoffers efficient
broadcasting facilities. Typically, suchfacilities areoffered bylocal-area net-
works inwhich allmachines areconnected toasingle cableorthelogical equiv-
alentthereof. Also,local-area wireless networks fallintothiscategory.
Locating anentity insuchanenvironment issimple: amessage containing the
identifier oftheentity isbroadcast toeachmachine andeachmachine isrequested
tocheck whether ithasthatentity. Onlythemachines thatcanofferanaccess
point fortheentity sendareply message containing theaddress ofthataccess
point.
Thisprinciple isusedintheInternet Address Resolution Protocol (ARP) to
findthedata-link address ofamachine when given onlyanIPaddress (Plummer,
1982). Inessence, amachine broadcasts apacket onthelocalnetwork asking
whoistheowner ofagiven IPaddress. When themessage arrives atamachine,
thereceiver checks whether itshould listen totherequested IPaddress. Ifso,it
sendsareplypacket containing, forexample, itsEthernet address.
Broadcasting becomes inefficient when thenetwork grows. Notonlyisnet-
workbandwidth wasted byrequest messages, but,moreseriously, toomany hosts
maybe interrupted byrequests theycannot answer. Onepossible solution isto
switch tomulticasting, bywhich onlyarestricted group ofhostsreceives there-
quest. Forexample, Ethernet networks support data-link level multicasting
directly inhardware.
Multicasting canalsobeusedtolocate entities inpoint-to-point networks. For
example, theInternet supports network-level multicasting byallowing hosts to
joinaspecific multicast group. Suchgroups areidentified byamulticast address.
When ahostsends amessage toamulticast address, thenetwork layerprovides a
best-effort service todeliver thatmessage toallgroup members. Efficient imple-
mentations formulticasting intheInternet arediscussed inDeering andCheriton
(1990) andDeering etal.(1996).
Amulticast address canbeusedasageneral location service formultiple
entities. Forexample, consider anorganization where eachemployee hashisor184 NAMING CHAP. 5
herownmobile computer. When suchacomputer connects tothelocally avail-
ablenetwork. itisdynamically assigned anIPaddress. Inaddition, itjoinsaspe-
cificmulticast group. When aprocess wants tolocate computer A,itsends a
"where isA?"request tothemulticast group. IfAisconnected, itresponds with
itscurrent IPaddress.
Another waytouseamulticast address istoassociate itwithareplicated enti-
ty,andtousemulticasting tolocate thenearest replica. When sending arequest to
themulticast address, eachreplica responds withitscurrent (normal) IPaddress.
Acrude waytoselect thenearest replica istochoose theonewhose replycomes
infirst.Wewilldiscuss otheronesinlaterchapters. Asitturnsout.selecting a
nearest replica isgenerally notthateasy.
Forwarding Pointers
Another popular approach tolocating mobile entities istomake useoffor-
warding pointers (Fowler, 1985). Theprinciple issimple: when anentity moves
fromAtoB,itleaves behind inAareference toitsnewlocation atB.Themain
advantage ofthisapproach isitssimplicity: assoonasanentity hasbeenlocated,
forexample byusing atraditional naming service, aclient canlookupthecurrent
address byfollowing thechainofforwarding pointers.
There arealsoanumber ofimportant drawbacks. First,ifnospecial measures
aretaken, achainforahighly mobile entity canbecome solongthatlocating that
entity isprohibitively expensive. Second, allintermediate locations inachain will
havetomaintain theirpartofthechain offorwarding pointers aslongasneeded.
Athird(andrelated) drawback isthevulnerability tobroken links. Assoonasany
forwarding pointer islost(forwhatever reason) theentity cannolonger bereach-
ed.Animportant issueis,therefore, tokeepchains relatively short, andtoensure
thatforwarding pointers arerobust.
Tobetter understand howforwarding pointers work, consider theirusewith
respect toremote objects: objects thatcanbeaccessed bymeans ofaremote pro-
cedure call.Following theapproach inSSPchains (Shapiro etaI.,1992), each
forwarding pointer isimplemented asa(client stub,server stub) pairasshown in
Fig.5-1.(WenotethatinShapiro's original terminology, aserver stubwascalled
ascion, leading to(stub.scion} pairs, which explains itsname.) Aserver stubcon-
tainseither alocalreference totheactual object oralocalreference toaremote
client stubforthatobject.
Whenever anobject moves fromaddress spaceAtoB,itleaves behind acli-
entstubinitsplaceinAandinstalls aserver stubthatrefers toitinB.Aninterest-
ingaspect ofthisapproach isthatmigration iscompletely transparent toaclient.
Theonlythingtheclient seesofanobject isaclient stub.How, andtowhich lo-
cation thatclient stubforwards itsinvocations, arehidden fromtheclient. Also
notethatthisuseofforwarding pointers isnotlikelooking upanaddress. Instead.
aclient's request isforwarded alongthechain totheactual object.SEC. 5.2 FLAT NAMING 185
Figure 5-1.Theprinciple offorwarding pointers using (client stub,server stub)
pairs.
Toshort-cut achain of(client stub,server stub) pairs, anobject invocation
carries theidentification oftheclient stubfromwhere thatinvocation wasini-
tiated. Aclient-stub identification consists oftheclient's transport-level address,
combined withalocally generated number toidentify thatstub.When theinvoca-
tionreaches theobject atitscurrent location, aresponse issentbacktotheclient
stubwhere theinvocation wasinitiated (often without going backupthechain).
Thecurrent location ispiggybacked withthisresponse, andtheclient stubadjusts
itscompanion server stubtotheoneintheobject's current location. Thisprinciple
isshown inFig.5-2.
Figure 5-2.Redirecting aforwarding pointer bystoring ashortcut inaclient stub.
There isatrade-off between sending theresponse directly totheinitiating cli-
entstub,oralong thereverse pathofforwarding pointers. Intheformer case,
communication isfaster because fewer processes mayneedtobepassed. Onthe186 NAMING CHAP. 5
otherhand, onlytheinitiating client stubcanbeadjusted, whereas sending theres-
ponse along thereverse pathallows adjustment ofallintermediate stubs.
When aserver stubisnolonger referred tobyanyclient, itcanberemoved.
Thisbyitselfisstrongly related todistributed garbage collection, agenerally far
fromtrivial problem thatwewillnotfurther discuss here.Theinterested reader is
referred toAbdullahi andRingwood (1998), Plainfosse andShapiro (1995), and
Veiga andFerreira (2005).
Nowsuppose thatprocess PJinFig.5-1passes itsreference toobject 0to
process P2•Reference passing isdonebyinstalling acopyp'ofclient stubpin
theaddress space ofprocess P2.Client stubp'refers tothesameserver stubasp,
sothattheforwarding invocation mechanism works thesameasbefore.
Problems arisewhen aprocess inachain of(client stub,server stub) pairs
crashes orbecomes otherwise unreachable. Several solutions arepossible. One
possibility, asfollowed inEmerald (JuletaI.,1988) andintheLIIsystem (Black
andArtsy, 1990), istoletthemachine where anobject wascreated (called theob-
ject's home location), always keepareference toitscurrent location. Thatrefer-
enceisstored andmaintained inafault-tolerant way.When achain isbroken, the
object's home location isasked where theobject isnow.Toallow anobject's
home location tochange, atraditional naming service canbeusedtorecord the
current horne location. Suchhome-based approaches arediscussed next.
5.2.2 Home-Based Approaches
Theuseofbroadcasting andforwarding pointers imposes scalability prob-
lems. Broadcasting ormulticasting isdifficult toimplement efficiently inlarge-
scalenetworks whereas longchains offorwarding pointers introduce performance
problems andaresusceptible tobroken links.
Apopular approach tosupporting mobile entities inlarge-scale networks isto
introduce ahome location, which keeps trackofthecurrent location ofanentity.
Special techniques maybeapplied tosafeguard against network orprocess fail-
ures.Inpractice, thehome location isoftenchosen tobetheplace where anentity
wascreated.
Thehome-based approach isusedasafall-back mechanism forlocation ser-
vicesbased onforwarding pointers, asdiscussed above. Another example where
thehome-based approach isfollowed isinMobile IP(Johnson etaI.,2004), which
webriefly explained inChap. 3.Each mobile hostusesafixed IPaddress. All
communication tothatIPaddress isinitially directed tothemobile host's home
agent. Thishome agentislocated onthelocal-area network corresponding tothe
network address contained inthemobile host's IPaddress. InthecaseofIPy6, it
isrealized asanetwork-layer component. Whenever themobile hostmoves toan-
othernetwork, itrequests atemporary address thatitcanuseforcommunication.
Thiscare-of address isregistered atthehome agent.SEC. 5.2 FLAT NAMING 187
When thehome agent receives apacket forthemobile host,itlooks upthe
host's current location. Ifthehostisonthecurrent localnetwork, thepacket is
simply forwarded. Otherwise, itistunneled tothehost's current location, thatis,
wrapped asdatainanIPpacket andsenttothecare-of address. Atthesametime,
thesender ofthepacket isinformed ofthehost's current location. Thisprinciple
isshown inFig.5-3.NotethattheIPaddress iseffectively usedasanidentifier
forthemobile host.
Figure 5-3.Theprinciple ofMobile IP.
Fig.5-3alsoillustrates another drawback ofhome-based approaches inlarge-
scalenetworks. Tocommunicate withamobile entity, aclient firsthastocontact
thehome, which maybeatacompletely different location thantheentity itself.
Theresult isanincrease incommunication latency.
Adrawback ofthehome-based approach istheuseofafixedhome location.
Foronething, itmustbeensured thatthehome location always exists. Otherwise,
contacting theentity willbecome impossible. Problems areaggravated when a
long-lived entity decides tomove permanently toacompletely different partof
thenetwork thanwhere itshome islocated. Inthatcase,itwould havebeenbetter
ifthehome could havemoved alongwiththehost.
Asolution tothisproblem istoregister thehome atatraditional naming ser-
viceandtoletaclient firstlookupthelocation ofthehome. Because thehome
location canbeassumed toberelatively stable, thatlocation canbeeffectively
cached afterithasbeenlooked up.188 NAMING CHAP. 5
5.2.3Distributed HashTables
Letusnowtakeacloser lookatrecent developments onhowtoresolve ani-
dentifier totheaddress oftheassociated entity. Wehavealready mentioned dis-
tributed hashtables anumber oftimes, buthavedeferred discussion onhowthey
actually work. Inthissection wecorrect thissituation byfirstconsidering the
Chord system asaneasy-to-explain DHT-based system. Initssimplest form,
DHT-based systems donotconsider network proximity atall,Thisnegligence
mayeasily leadtoperformance problems. Wealsodiscuss solutions fornetwork-
aware systems.
GeneralMechanism
Various DHT-based systems exist, ofwhich abriefoverview isgiven in
Balakrishnan etal.(2003). TheChord system (Stoica etaI.,2003) isrepres-
entative formany ofthem, although therearesubtle important differences that
influence theircomplexity inmaintenance andlookup protocols. Asweexplained
briefly inChap. 2,Chord usesanm-bitidentifier spacetoassign randomly-chosen
identifiers tonodes aswellaskeystospecific entities. Thelattercanbevirtually
anything: files,processes, etc.Thenumber mofbitsisusually 128or160,
depending onwhich hashfunction isused. Anentity withkeykfallsunder the
jurisdiction ofthenodewiththesmallest identifier id~k.Thisnodeisreferred to
asthesuccessor ofkanddenoted assucc(k).
ThemainissueinDHT-based systems istoefficiently resolve akeyktothe
address ofsucc(k). Anobvious nonscalable approach isleteachnodepkeep
trackofthesuccessor succ(p+ 1)aswellasitspredecessor pred(p). Inthatcase,
whenever anodepreceives arequest toresolve keyk,itwillsimply forward the
request tooneofitstwoneighbors-whichever oneisappropriate-unless
pred(p)<k-:;'pinwhich casenodepshould return itsownaddress totheprocess
thatinitiated theresolution ofkeyk.
Instead ofthislinear approach toward keylookup, eachChord nodemaintains
afingertableofatmostmentries. IfFTpdenotes thefinger tableofnodep,then
Putinotherwords, thei-thentrypoints tothefirstnodesucceeding pbyatleast
i-I.Notethatthesereferences areactually short-cuts toexisting nodes inthei-
dentifier space, where the,short-cutted distance fromnodepincreases exponen-
tially astheindex inthefinger tableincreases. Tolookupakeyk,nodepwill
thenimmediately forward therequest tonodeqwithindex jinp'sfinger table
where:
(Forclarity, weignore modulo arithmetic.)SEC. 5.2 FLAT NAMING 189
Toillustrate thislookup, consider resolving k=26fromnode 1asshown
Fig.5-4.First, node1willlookupk=26initsfmger tabletodiscover thatthis
value islarger thanFTI[5],meaning thattherequest willbeforwarded tonode
18=FTd5]. Node 18,intum,willselect node20,asFTl8 [2]<k~FTl8 [3].
Finally, therequest isforwarded fromnode20tonode21andfromtheretonode
28,which isresponsible fork=26.Atthatpoint, theaddress ofnode28isre-
turned tonode1andthekeyhasbeenresolved. Forsimilar reasons, whennode28
isrequested toresolve thekeyk=12,arequest willberouted asshown bythe
dashed lineinFig.5-4.Itcanbeshown thatalookup willgenerally require
O(log (N)) steps, withNbeing thenumber ofnodes inthesystem.
14Finger table24
39 ·..i"49 x~
518 \9
Actual node i":>~&
~2: 19 ....,....~3': 2 91 1 ..... 3 9
2 1 414
3 1 _ _--- 52044 ." --- -- I •••••
~7" ---------- :5:
514 ..i"':Resolve k=12 ,/ ....\...
:26: from node 28 I (6.:
...' ~ ..\.1 .'". :25': \ (7:'..' \"1,J. \:"8":(24: , ....: 111
..r '...' 211
)'" 314
(E.~: - 418
\ 528
:~) j~128 v.,' ..'
228 _- 114
328 ".- 214
4 1 £12: 318
5 9 ...../.... 420
:13: 5281 .....
2
3 118
4 218
5 120 318
2~ 4~
3~ 51
428
54
Figure 5-4.Resolving key26fromnode1andkey12fromnode28inaChord system.
Inlarge distributed systems thecollection ofparticipating nodes canbe
expected tochange allthetime.Notonlywillnodes joinandleavevoluntarily, we
alsoneedtoconsider thecaseofnodes failing (andthuseffectively leaving the
system), tolaterrecover again(atwhich pointtheyjoinagain).190 NAMING CHAP. 5
Joining aDHT-based system suchasChord isrelatively simple. Suppose node
pwants tojoin.Itsimply contacts anarbitrary nodeintheexisting system andre-
quests alookup forsuccip-r 1).Oncethisnodehasbeenidentified, pcaninsert it-
selfintothering.Likewise, leaving canbejustassimple. Notethatnodes also
keeptrackoftheirpredecessor.
Obviously, thecomplexity comes fromkeeping thefinger tables up-to-date.
Mostimportant isthatforevery nodeq,FTq[1]iscorrect asthisentryrefers to,the
nextnodeinthering,thatis,thesuccessor ofq+1.Inordertoachieve thisgoal,
eachnodeqregularly runsasimple procedure thatcontacts succ(q+1)andre-
quests toreturn pred(succ(q+1)). Ifq:;::pred(succ(q+I))thenqknows itsinfor-
mation isconsistent withthatofitssuccessor. Otherwise, ifq'ssuccessor has
updated itspredecessor, thenapparently anewnodephadentered thesystem,
withq<P::; succ(q+l), sothatqwilladjust FTq[1]top.Atthatpoint, itwill
alsocheck whether phasrecorded qasitspredecessor. Ifnot,another adjustment
ofFTq[1]isneeded.
Inasimilar way,toupdate afinger table, nodeqsimply needs tofindthesuc-
cessor fork:;::q+i-Iforeachentryi.Again, thiscanbedonebyissuing are-
questtoresolve succ(k). InChord, suchrequests areissued regularly bymeans of
abackground process.
Likewise, eachnodeqwillregularly check whether itspredecessor isalive. If
thepredecessor hasfailed, theonlythingthatqcandoisrecord thefactbysetting
pred(q)to"unknown". Ontheotherhand, whennodeqisupdating itslinktothe
nextknown nodeinthering,andfindsthatthepredecessor ofsucciq+1)hasbeen
setto"unknown," itwillsimply notify succ(q+1)thatitsuspects ittobethe
predecessor. Byandlarge, thesesimple procedures ensure thataChord system is
generally consistent, onlyperhaps withexception ofafewnodes. Thedetails can
befound inStoica etal.(2003).
Exploiting Network Proximity
Oneofthepotential problems withsystems suchasChord isthatrequests
mayberouted erratically across theInternet. Forexample, assume thatnode1in
Fig.5-4isplaced inAmsterdam, TheNetherlands; node18inSanDiego, Califor-
nia;node20inAmsterdam again; andnode21inSanDiego. Theresult ofresolv-
ingkey26willthenincurthreewide-area message transfers which arguably could
havebeenreduced toatmostone.Tominimize thesepathological cases, design-
ingaDHT-based system requires taking theunderlying network intoaccount.
Castro etal.(2002b) distinguish threedifferent waysformaking aDHT-based
system aware oftheunderlying network. Inthecaseoftopology-based assign-
ment ofnode identifiers theideaistoassign identifiers suchthattwonearby
nodes willhaveidentifiers thatarealsoclosetoeachother. Itisnotdifficult to
imagine thatthisapproach mayimpose severe problems inthecaseofrelatively
simple systems suchasChord. Inthecasewhere nodeidentifiers aresampledSEC. 5.2 FLAT NAMING 191
fromaone-dimensional space, mapping alogical ringtotheInternet isfarfrom
trivial. Moreover, suchamapping caneasily expose correlated failures: nodes on
thesameenterprise network willhaveidentifiers fromarelatively smallinterval.
When thatnetwork becomes unreachable, wesuddenly haveagapintheother-
wiseuniform distribution ofidentifiers.
Withproximity routing, nodes maintain alistofalternatives toforward are-
quest to.Forexample, instead ofhaving onlyasingle successor, eachnodein
Chord could equally wellkeeptrackofrsuccessors. Infact,thisredundancy can
beapplied forevery e~tryin3:finger table. Fornodep,FTp[i]points tothefirst
nodeintherange fp+21-1,p+21_1]. There isnoreason whypcannot keeptrackof
rnodes inthatrange: ifneeded, eachoneofthemcanbeusedtoroutealookup
request forakeyk>p+2i-1. Inthatcase,whenchoosing toforward alookup re-
quest, anodecanpickoneofthersuccessors thatisclosest toitself, butalso
satisfies theconstraint thattheidentifier ofthechosen nodeshould besmaller
thanthatoftherequested key.Anadditional advantage ofhaving multiple succes-
sorsforevery tableentry isthatnodefailures neednotimmediately leadto
failures oflookups, asmultiple routes canbeexplored.
Finally, inproximity neighbor selection theideaistooptimize routing tables
suchthatthenearest nodeisselected asneighbor. Thisselection works onlywhen
therearemore nodes tochoose from. InChord, thisisnormally notthecase.
However, inotherprotocols suchasPastry (Rowstron andDruschel, 2001), when
anodejoinsitreceives information about thecurrent overlay frommultiple other
nodes. Thisinformation isusedbythenewnodetoconstruct arouting table.
Obviously, when therearealternative nodes tochoose from, proximity neighbor
selection willallow thejoining nodetochoose thebestone.
Notethatitmaynotbethateasytodrawalinebetween proximity routing and
proximity neighbor selection. Infact,whenChord ismodified toinclude rsucces-
sorsforeachfinger tableentry, proximity neighbor selection resorts toidentifying
theclosest rneighbors, which comes veryclosetoproximity routing aswejust
explained (Dabek atal.,2004b).
Finally, wealsonotethatadistinction canbemade between iterative and
recursive lookups. Intheformer case,anodethatisrequested tolookupakey
willreturn thenetwork address ofthenextnodefound totherequesting process.
Theprocess willthenrequest thatnextnodetotakeanother stepinresolving the
key.Analternative, andessentially thewaythatwehaveexplained itsofar,isto
letanodeforward alookup request tothenextnode. Bothapproaches havetheir
advantages anddisadvantages, which weexplore laterinthischapter.
5.2.4 Hierarchical Approaches
Inthissection, wefirstdiscuss ageneral approach toahierarchical location
scheme, afterwhich anumber ofoptimizations arepresented. Theapproach we
present isbased ontheGlobe location service, described indetail inBallintijn192 NAMING CHAP.5
(2003). Anoverview canbefound invanSteen etal.(l998b). Thisisageneral-
purpose location service thatisrepresentative ofmany hierarchical location ser-
vicesproposed forwhatarecalled Personal Communication Systems, ofwhich a
general overview canbefound inPitoura andSamaras (2001).
Inahierarchical scheme, anetwork isdivided intoacollection ofdomains.
There isasingle top-level domain thatspans theentire network. Eachdomain can
besubdivided intomultiple, smaUer subdomains. Alowest-level domain, called a
leafdomain, typically corresponds toalocal-area network inacomputer network
oracellinamobile telephone network.
Eachdomain Dhasanassociated directory nodedirtD)thatkeeps trackofthe
entities inthatdomain. Thisleadstoatreeofdirectory nodes. Thedirectory node
ofthetop-level domain, caUed theroot(directory) node, knows about allenti-
ties.Thisgeneral organization ofanetwork intodomains anddirectory nodes is
illustrated inFig.5-5.
Figure 5-5.Hierarchical organization ofalocation service intodomains, each
having anassociated directory node.
Tokeeptrackofthewhereabouts ofanentity, eachentity currently located in
adomain Disrepresented byalocation record inthedirectory nodedir(D). A
location record forentity Einthedirectory nodeNforaleafdomain Dcontains
theentity's current address inthatdomain. Incontrast, thedirectory nodeN'for
thenexthigher-level domain D'thatcontains D,willhavealocation record forE
containing onlyapointer toN.Likewise. theparent nodeofN'willstorealoca-
tionrecord forEcontaining onlyapointer toN'.Consequently, therootnodewill
havealocation record foreachentity, where eachlocation record stores apointer
tothedirectory nodeofthenextlower-level subdomain where thatrecord's asso-
ciated entity iscurrently located.
Anentity mayhavemultiple addresses, forexample ifitisreplicated. Ifan
entity hasanaddress inleafdomain D1andD2respectively, thenthedirectory
nodeofthesmallest domain containing bothD1andD2,willhavetwopointers,The rootdirectory Top-level
node dir(T) domain T
-----------"'~",,- '", Directory node
,//' <. dir(5) ofdomain 5
.c> ,Asubdomain 5
/;/ \\....- oftop-Ieve~ do~ain T
// - -',';'\ (5iscontained InT) / /1" ,\ \
'" ,\,' " I\ ,
" ,': :" I, ,': :
":"/' ,"",') "' ~,' "--_/,',' I , ' , ',,~ '__ ~ '/-'__ , ~
"":=::--::::::::: -::::::::::::.: ~------·7-:::::---.::.-::.-:.,~
Aleafdomain, contained in5SEC. 5.2 FLAT NAMING 193
Figure 5-6.Anexample ofstoring information ofanentity having twoad-
dresses indifferent leafdomains.
Letusnowconsider howalookup operation proceeds insuchahierarchical
location service. Asisshown inFig.5-7,aclient wishing tolocate anentity E,
issues alookup request tothedirectory nodeoftheleafdomain Dinwhich the
client resides. Ifthedirectory nodedoesnotstorealocation record fortheentity,
thentheentity iscurrently notlocated inD.Consequently, thenodeforwards the
request toitsparent. Notethattheparent noderepresents alarger domain thanits
child. Iftheparent alsohasnolocation record forE,thelookup request isfor-
warded toanextlevelhigher, andsoon.
Figure 5-7.Looking upalocation inahierarchically organized location service.
Assoonastherequest reaches adirectory nodeMthatstores alocation record
forentity E,weknow thatEissomewhere inthedomain dom(M) represented byoneforeachsubdomain containing anaddress. Thisleadstothegeneral organiza-
tionofthetreeasshown inFig.5-6.194 NAMING CHAP. 5
nodeM.InFig.5-7,Misshown tostorealocation record containing apointer to
oneofitssubdomains. Thelookup request isthenforwarded tothedirectory node
ofthatsubdomain, which intumforwards itfurther down thetree,untilthere-
questfinally reaches aleafnode. Thelocation record stored intheleafnodewill
contain theaddress ofEinthatleafdomain. Thisaddress canthenbereturned to
theclient thatinitially requested thelookup totakeplace.
Animportant observation withrespect tohierarchical location services isthat
thelookup operation exploits locality. Inprinciple, theentity issearched inagra-
dually increasing ringcentered around therequesting client. Thesearch areais
expanded eachtimethelookup request isforwarded toanexthigher-level direc-
torynode. Intheworstcase,thesearch continues untiltherequest reaches theroot
node. Because therootnodehasalocation record foreachentity, therequest can
thensimply beforwarded along adownward pathofpointers tooneoftheleaf
nodes.
Update operations exploit locality inasimilar fashion, asshown inFig.5-8.
Consider anentity Ethathascreated areplica inleafdomain Dforwhich itneeds
toinsert itsaddress. Theinsertion isinitiated attheleafnodedir(D) ofDwhich
immediately forwards theinsert request toitsparent. Theparent willforward the
insert request aswell,untilitreaches adirectory nodeMthatalready stores alo-
cation record forE.
Node Mwillthenstoreapointer inthelocation record forE,referring tothe
childnodefromwhere theinsert request wasforwarded. Atthatpoint, thechild
nodecreates alocation record forE,containing apointer tothenextlower-level
nodefromwhere therequest came. Thisprocess continues untilwereach theleaf
nodefromwhich theinsert wasinitiated. Theleafnode, finally, creates arecord
withtheentity's address intheassociated leafdomain.
Figure 5-8.(a)Aninsert request isforwarded tothefirstnodethatknows about
entity E.(b)Achain offorwarding pointers totheleafnodeiscreated.SEC. 5.2 FLAT NAMING 195
Inserting anaddress asjustdescribed leadstoinstalling thechain ofpointers
inatop-down fashion starting atthelowest-level directory nodethathasaloca-
tionrecord forentity E.Analternative istocreate alocation record before passing
theinsert request totheparent node. Inotherwords, thechainofpointers iscon-
structed from thebottom up.Theadvantage ofthelatter isthatanaddress
becomes available forlookups assoonaspossible. Consequently, ifaparent node
istemporarily unreachable, theaddress canstillbelooked upwithin thedomain
represented bythecurrent node.
Adelete operation isanalogous toaninsert operation. When anaddress for
entity Einleafdomain Dneeds toberemoved, directory nodedir(D) isrequested
toremove thataddress fromitslocation record forE.Ifthatlocation record
becomes empty, thatis,itcontains nootheraddresses forEinD,therecord can
beremoved. Inthatcase,theparent nodeofdireD)wants toremove itspointer to
dir(D). Ifthelocation record forEattheparent nowalsobecomes empty, that
record should beremoved aswellandthenexthigher-level directory nodeshould
beinformed. Again, thisprocess continues untilapointer isremoved fromaloca-
tionrecord thatremains nonempty afterward oruntiltherootisreached.
5.3STRUCTURED NAMING
Flatnames aregoodformachines, butaregenerally notveryconvenient for
humans touse.Asanalternative, naming systems generally support structured
names thatarecomposed fromsimple, human-readable names. Notonlyfilena-
ming, butalsohostnaming ontheInternet follow thisapproach. Inthissection,
weconcentrate onstructured names andthewaythatthesenames areresolved to
addresses.
5.3.1NameSpaces
Names arecommonly organized intowhatiscalled anamespace. Name
spaces forstructured names canberepresented asalabeled, directed graph with
twotypes ofnodes. Aleafnoderepresents anamed entity andhastheproperty
thatithasnooutgoing edges. Aleafnodegenerally stores information ontheenti-
tyitisrepresenting-for example, itsaddress-so thataclient canaccess it.
Alternatively, itcanstorethestateofthatentity, suchasinthecaseoffilesys-
tems'inwhich aleafnodeactually contains thecomplete fileitisrepresenting.
Wereturn tothecontents ofnodes below.
Incontrast toaleafnode, adirectory nodehasanumber ofoutgoing edges,
eachlabeled withaname, asshown inFig.5-9.Eachnodeinanaming graph is
considered asyetanother entity inadistributed system, and,inparticular, hasan196 NAMING CHAP.5
associated identifier. Adirectory nodestores atableinwhich anoutgoing edgeis
represented asapair(edge label, nodeidentifier). Suchatableiscalled adirec-
torytable.
Figure 5-9.Ageneral naming graph withasingle rootnode.
Thenaming graph shown inFig.5-9hasonenode, namely no,which hasonly
outgoing andnoincoming edges. Suchanodeiscalled theroot(node) ofthena-
minggraph. Although itispossible foranaming graph tohaveseveral rootnodes,
forsimplicity, many naming systems haveonlyone.Eachpathinanaming graph
canbereferred tobythesequence oflabels corresponding totheedges inthat
path,suchas
Nt-clabel-I, label-2, ...,label-n>
where Nrefers tothefirstnodeinthepath. Suchasequence iscalled apath
name. Ifthefirstnodeinapathname istherootofthenaming graph, itiscalled
an"absolute pathname. Otherwise, itiscalled arelative pathname.
Itisimportant torealize thatnames arealways organized inaname space. As
aconsequence, aname isalways defined relative onlytoadirectory node. Inthis
sense, theterm"absolute name" issomewhat misleading. Likewise, thediffer-
encebetween global andlocalnames canoftenbeconfusing. Aglobal name isa
name thatdenotes thesameentity, nomatter where thatnameisusedinasystem.
Inotherwords, aglobal nameisalways interpreted withrespect tothesamedirec-
torynode. Incontrast, alocalname isaname whose interpretation depends on
where thatnameisbeing used.Putdifferently, alocalname isessentially arela-
tivename whose directory inwhich itiscontained is(implicitly) known. Were-
turntotheseissues laterwhenwediscuss nameresolution.
Thisdescription ofanaming graph comes close towhatisimplemented in
many filesystems. However, instead ofwriting thesequence ofedgelabels torep-
represent apathname, pathnames infilesystems aregenerally represented asa
single string inwhich thelabels areseparated byaspecial separator character,
suchasaslash("1"). Thischaracter isalsousedtoindicate whether apathname
isabsolute. Forexample, inFig.5-9,instead ofusing no:<home, steen, mbox>,SEC. 5.3 STRUCTURED NAMING 197
thatis,theactual pathname, itiscommon practice touseitsstring representation
Ihome/steen/mbox. Notealsothatwhen thereareseveral paths thatleadtothe
samenode, thatnodecanberepresented bydifferent pathnames. Forexample,
noden5inFig.5-9canbereferred tobyIhome/steenlkeys aswellas/keys. The
string representation ofpathnames canbeequally wellapplied tonaming graphs
other thanthose usedforonlyfilesystems. InPlan9(Pikeetal.,1995), allre-
sources, suchasprocesses, hosts, I/Odevices, andnetwork interfaces, arenamed
inthesamefashion astraditional files.Thisapproach isanalogous toimplement-
ingasingle naming graph forallresources inadistributed system.
There aremany different waystoorganize aname space. Aswementioned,
mostname spaces haveonlyasingle rootnode. Inmany cases, aname space is
alsostrictly hierarchical inthesensethatthenaming graph isorganized asatree.
Thismeans thateachnodeexcept theroothasexactly oneincoming edge;theroot
hasnoincoming edges. Asaconsequence, eachnodealsohasexactly oneassoci-
ated(absolute) pathname.
Thenaming graph shown inFig.5-9isanexample ofdirected acyclic graph.
Insuchanorganization, anodecanhavemorethanoneincoming edge,butthe
graph isnotpermitted tohaveacycle. There arealsoname spaces thatdonot
havethisrestriction.
Tomake matters moreconcrete, consider thewaythatfilesinatraditional
UNIX filesystem arenamed. Inanaming graph forUNIX, adirectory noderepres-
entsafiledirectory, whereas aleafnoderepresents afile.There isasingle root
directory, represented inthenaming graph bytherootnode. Theimplementation
ofthenaming graph isanintegral partofthecomplete implementation ofthefile
system. Thatimplementation consists ofacontiguous series ofblocks fromalogi-
caldisk,generally divided intoabootblock, asuperblock, aseries ofindex nodes
(called inodes), andfiledatablocks. SeealsoCrowley (1997), Silberschatz etal.
(2005), andTanenbaum andWoodhull (2006). Thisorganization isshown in
Fig.5-10.
Figure 5·10. Thegeneral organization oftheUNIX filesystem implementation
onalogical diskofcontiguous diskblocks.
Thebootblock isaspecial block ofdataandinstructions thatareautomati-
callyloaded intomainmemory whenthesystem isbooted. Thebootblockisused
toloadtheoperating system intomainmemory.198 NAMING CHAP. 5
Thesuperblock contains information ontheentire filesystem. suchasitssize,
which blocks ondiskarenotyetallocated, which inodes arenotyetused,andso
on.Inodes arereferred tobyanindex number, starting atnumber zero,which is
reserved fortheinode representing therootdirectory.
Eachinode contains information onwhere thedataofitsassociated filecan
befound ondisk.Inaddition, aninode contains information onitsowner, timeof
creation andlastmodification, protection, andthelike.Consequently, when given
theindex number ofaninode, itispossible toaccess itsassociated file.Eachdi-
rectory isimplemented asafileaswell.Thisisalsothecasefortherootdirec-
tory,which contains amapping between filenames andindex numbers ofinodes.
Itisthusseenthattheindex number ofaninode corresponds toanodeidentifier
inthenaming graph.
5.3.2 Name Resolution
Name spaces offeraconvenient mechanism forstoring andretrieving infor-
mation about entities bymeans ofnames. More generally, given apathname, it
should bepossible tolookupanyinformation stored inthenodereferred toby
thatname. Theprocess oflooking upaname iscalled name resolution.
Toexplain howname resolution works, letusconsider apathname suchas
Ni<label v.label g,....label;». Resolution ofthisname startsatnodeNofthena-
minggraph, where thename label} islooked upinthedirectory table, andwhich
returns theidentifier ofthenodetowhich label} refers. Resolution thencontinues
attheidentified nodebylooking upthename label-. initsdirectory table, andso
on.Assuming thatthenamed pathactually exists, resolution stopsatthelastnode
referred tobylabel.; byreturning thecontent ofthatnode.
Aname lookup returns theidentifier ofanodefromwhere thename resolu-
tionprocess continues. Inparticular, itisnecessary toaccess thedirectory tableof
theidentified node. Consider again anaming graph foraUNIX filesystem. As
mentioned, anodeidentifier isimplemented astheindex number ofaninode.
Accessing adirectory tablemeans thatfirsttheinode hastobereadtofindout
where theactual dataarestored ondisk,andthensubsequently toreadthedata
blocks containing thedirectory table.
Closure Mechanism
Name resolution cantakeplace onlyifweknow howandwhere tostart.In
ourexample, thestarting nodewasgiven, andweassumed wehadaccess toitsdi-
rectory table. Knowing howandwhere tostartname resolution isgenerally
referred toasaclosure mechanism. Essentially, aclosure mechanism dealswith
selecting theinitial nodeinaname space fromwhich name resolution istostart
(Radia, 1989). What makes closure mechanisms sometimes hardtounderstand isSEC. 5.3 STRUCTURED NAMING 199
thattheyarenecessarily partly implicit andmaybeverydifferent whencompar-
ingthemtoeachother.
Forexample. name resolution inthenaming graph foraUNIX filesystem
makes useofthefactthattheinode oftherootdirectory isthefirstinode inthe
logical diskrepresenting thefilesystem. Itsactual byteoffset iscalculated from
thevalues inotherfields ofthesuperblock, together withhard-coded information
intheoperating system itselfontheinternal organization ofthesuperblock.
Tomakethispointclear, consider thestring representation ofafilenamesuch
asIhomelsteenlmbox. Toresolve thisname, itisnecessary toalready haveaccess
tothedirectory tableoftherootnodeoftheappropriate naming graph. Being a
rootnode, thenodeitselfcannot havebeenlooked upunless itisimplemented as
adifferent nodeinaanother naming graph, sayG.Butinthatcase,itwould have
beennecessary toalready haveaccess totherootnodeofG.Consequently, re-
solving afilename requires thatsomemechanism hasalready beenimplemented
bywhich theresolution process canstart.
Acompletely different example istheuseofthestring "0031204430784".
Many people willnotknow whattodowiththesenumbers, unless theyaretold
thatthesequence isatelephone number. Thatinformation isenough tostartthe
resolution process, inparticular, bydialing thenumber. Thetelephone system
subsequently doestherest.
Asalastexample, consider theuseofglobal andlocalnames indistributed
systems. Atypical example ofalocalname isanenvironment variable. Forex-
ample, inUNIX systems, thevariable named HOME isusedtorefertothehome
directory ofauser.Eachuserhasitsowncopyofthisvariable, which isinitialized
totheglobal, systemwide name corresponding totheuser's home directory. The
closure mechanism associated withenvironment variables ensures thatthename
ofthevariable isproperly resolved bylooking itupinauser-specific table.
LinkingandMounting
Strongly related toname resolution istheuseofaliases. Analiasisanother
name forthesameentity. Anenvironment variable isanexample ofanalias.In
terms ofnaming graphs, therearebasically twodifferent waystoimplement an
alias.Thefirstapproach istosimply allow multiple absolute pathsnames torefer
tothesamenodeinanaming graph. Thisapproach isillustrated inFig.5-9,in
which nodenscanbereferred tobytwodifferent pathnames. InUNIX terminol-
ogy,bothpathnames /keys and/homelsteen/keys inFig.5-9arecalled hardlinks
tonodens.
Thesecond approach istorepresent anentity byaleafnode, sayN,butin-
steadofstoring theaddress orstateofthatentity, thenodestores anabsolute path
name. When firstresolving anabsolute pathnamethatleadstoN,nameresolution
willreturn thepathnamestored inN,atwhich pointitcancontinue withresolving
thatnewpathname. Thisprinciple corresponds totheuseofsymbolic linksin200 NAMING CHAP. 5
UNIX filesystems, andisillustrated inFig.5-11. Inthisexample, thepathname
/home/steen/keys, which refers toanodecontaining theabsolute pathname/keys,
isasymbolic linktonoden5.
Figure 5-11. Theconcept ofasymbolic linkexplained inanaming graph.
Name resolution asdescribed sofartakesplace completely within asingle
name space. However, name resolution canalsobeusedtomerge different name
spaces inatransparent way.Letusfirstconsider amounted filesystem. Interms
ofournaming model, amounted filesystem corresponds toletting adirectory
nodestoretheidentifier ofadirectory nodefromadifferent name space, which
werefertoasaforeign name space. Thedirectory nodestoring thenodeidentifier
iscalled amount point. Accordingly, thedirectory nodeintheforeign name
space iscalled amounting point. Normally, themounting pointistherootofa
name space. During name resolution, themounting pointis,looked upandresolu-
tionproceeds byaccessing itsdirectory table.
Theprinciple ofmounting canbegeneralized toothername spaces aswell.In
particular, whatisneeded isadirectory nodethatactsasamount pointandstores
allthenecessary information foridentifying andaccessing themounting pointin
theforeign name space. Thisapproach isfollowed inmany distributed filesys-
tems.
Consider acollection ofname spaces thatisdistributed across different ma-
chines. Inparticular, eachname space isimplemented byadifferent server, each
possibly running onaseparate machine. Consequently. ifwewanttomount a
foreign name space NS2intoanamespaceNS1,itmaybenecessary tocommuni-
cateoveranetwork withtheserver ofNS2,asthatserver mayberunning ona
different machine thantheserver forNSi-Tomount aforeign name space ina
distributed system requires atleastthefollowing information:
1.Thenameofanaccess protocol.
2.Thenameoftheserver.
3.Thename ofthemounting pointintheforeign name space.SEC. 5.3 STRUCTURED NAMING 201
Notethateachofthesenames needs toberesolved. Thename ofanaccess proto-
colneeds toberesolved totheimplementation ofaprotocol bywhich communi-
cation withtheserver oftheforeign name space cantakeplace. Thenameofthe
server needs toberesolved toanaddress where thatserver canbereached. Asthe
lastpartinnameresolution, thenameofthemounting pointneeds toberesolved
toanodeidentifier intheforeign namespace.
Innondistributed systems, noneofthethreepoints mayactually beneeded.
Forexample, inUNIX, thereisnoaccess protocol andnoserver. Also,thename
ofthemounting pointisnotnecessary, asitissimply therootdirectory ofthe
foreign namespace.
Thenameofthemounting pointistoberesolved bytheserver oftheforeign
namespace. However, wealsoneednamespaces andimplementations fortheac-
cessprotocol andtheserver name. Onepossibility istorepresent thethreenames
listedabove asaURL.
Tomake matters concrete, consider asituation inwhich auserwithalaptop
computer wants toaccess filesthatarestored onaremote fileserver. Theclient
machine andthefileserver arebothconfigured withSun's Network FileSystem
(NFS), which wewilldiscuss indetail inChap. 11.NFSisadistributed filesys-
temthatcomes withaprotocol thatdescribes precisely howaclient canaccess a
filestored ona(remote) NFSfileserver. Inparticular, toallow NFStoworka-
crosstheInternet, aclient canspecify exactly which fileitwants toaccess by
means ofanNFSURL, forexample, nfs:l/flits.cs. vu.nl//homelsteen. ThisURL
names afile(which happens tobeadirectory) called /home/steen onanNFSfile
server flits.cs. vu.nl, which canbeaccessed byaclient bymeans oftheNFSproto-
col(Shepler etaI.,2003).
Thename nfsisawell-known name inthesense thatworldwide agreement
exists onhowtointerpret thatname. Given thatwearedealing withaURL, the
name nfswillberesolved toanimplementation oftheNFSprotocol. Theserver
name isresolved toitsaddress usingDNS, which isdiscussed inalatersection.
Aswesaid,/home/steen isresolved bytheserver oftheforeign namespace.
Theorganization ofafilesystem ontheclient machine ispartly shown in
Fig.5-12. Therootdirectory hasanumber ofuser-defined entries, including a
subdirectory called Iremote. Thissubdirectory isintended toinclude mount points
forforeign name spaces suchastheuser's home directory attheVrijeUniversi-
teit.Tothisend,adirectory nodenamed Iremote/vu isusedtostoretheURL
nfs:l/flits.cs. vu.nll/homelsteen.
Nowconsider thename/remotelvulmbox. Thisname isresolved bystarting
intherootdirectory ontheclient's machine andcontinues untilthenodeIre-
mote/vu isreached. Theprocess ofname resolution thencontinues byreturning
theURLnfs:l/flits.cs. vu.nl//homelsteen, inturnleading theclient machine tocon-
tactthefileserver flits.cs. vu.nlbymeans oftheNFSprotocol, andtosubsequently
access directory /home/steen. Name resolution canthenbecontinued byreading
thefilenamed mbox inthatdirectory, afterwhich theresolution process stops.202 NAMING CHAP. 5
Figure 5-12. Mounting remote name spaces through aspecific access protocol.
Distributed systems thatallowmounting aremote filesystem asjustdescribed
allowaclientmachine to,forexample, execute thefollowing commands:
cd/remote/vu
Is-I
which subsequently liststhefilesinthedirectory /home/steen ontheremote file
server. Thebeauty ofallthisisthattheuserisspared thedetails oftheactual ac-
cesstotheremote server. Ideally, onlysomelossinperformance isnoticed com-
pared toaccessing locally-available files.Ineffect, totheclient itappears thatthe
namespace rooted onthelocalmachine, andtheonerooted at/home/steen onthe
remote machine, formasingle name space.
5.3.3 TheImplementation ofaName Space
Aname space forms theheart ofanaming service, thatis,aservice that
allows usersandprocesses toadd,remove, andlookupnames. Anaming service
isimplemented byname servers. Ifadistributed system isrestricted toalocal-
areanetwork, itisoftenfeasible toimplement anaming service bymeans ofonly
asingle name server. However, inlarge-scale distributed systems withmany enti-
ties,possibly spread across alargegeographical area,itisnecessary todistribute
theimplementation ofaname space overmultiple name servers.SEC. 5.3 STRUCTURED NAMING 203
Name Space Distribution
Name spaces foralarge-scale, possibly worldwide distributed system, are
usually organized hierarchically. Asbefore, assume suchaname spacehasonlya
single rootnode. Toeffectively implement suchaname space, itisconvenient to
partition itintological layers. Cheriton andMann (1989) distinguish thefollowing
threelayers.
Theglobal layer isformed byhighest-level nodes, thatis,therootnodeand
otherdirectory nodes logically closetotheroot,namely itschildren. Nodes inthe
global layerareoftencharacterized bytheirstability, inthesense thatdirectory
tables arerarely changed. Suchnodes mayrepresent organizations.. orgroups of
organizations, forwhich names arestored inthenamespace.
Theadministrational layer isformed bydirectory nodes thattogether are
managed within asingle organization. Acharacteristic feature ofthedirectory
nodes intheadministrational layeristhattheyrepresent groups ofentities that
belong tothesameorganization oradministrational unit.Forexample, theremay
beadirectory nodeforeach'department inanorganization, oradirectory node
fromwhich allhosts canbefound. Another directory nodemaybeusedasthe
starting pointfornaming allusers, andsoforth.Thenodes intheadministrational
layerarerelatively stable, although changes generally occur morefrequently than
tonodes intheglobal layer.
Finally, themanagerial layer consists ofnodes thatmaytypically change
regularly. Forexample, nodes representing hostsinthelocalnetwork belong to
thislayer. Forthesamereason, thelayerincludes nodes representing shared files
suchasthoseforlibraries orbinaries. Another important classofnodes includes
thosethatrepresent user-defined directories andfiles.Incontrast totheglobal and
administrational layer, thenodes inthemanagerial layeraremaintained notonly
bysystem administrators, butalsobyindividual endusersofadistributed system.
Tomake matters more concrete, Fig.5-13shows anexample oftheparti-
tioning ofpartoftheDNSname space, including thenames offileswithin an
organization thatcanbeaccessed through theInternet, forexample, Webpages
andtransferable files.Thename space isdivided intononoverlapping parts,called
zones inDNS(Mockapetris, 1987). Azoneisapartofthenamespacethatisim-
plemented byaseparate name server. Some ofthese zones areillustrated in
Fig.5-13.
Ifwetakealookatavailability andperformance, name servers ineachlayer
havetomeetdifferent requirements. Highavailability isespecially critical for
name servers intheglobal layer. Ifanameserver fails,alargepartofthename
space willbeunreachable because name resolution cannot proceed beyond the
failing server.
Performance issomewhat subtle. Duetothelowrateofchange ofnodes in
theglobal layer, theresults oflookup operations generally remain validforalong
time.Consequently, thoseresults canbeeffectively cached (i.e.,stored locally) by204 NAMING CHAP. 5
Figure 5-13. Anexample partitioning oftheDNS name space, including
Internet-accessible files,intothreelayers.
theclients. Thenexttimethesamelookup operation isperformed, theresults can
beretrieved fromtheclient's cache instead ofletting thename server return the
results. Asaresult, name servers intheglobal layer donothavetorespond
quickly toasingle lookup request. Ontheotherhand, throughput maybeimpor-
tant,especially inlarge-scale systems withmillions ofusers.
Theavailability andperformance requirements forname servers intheglobal
layercanbemetbyreplicating servers, incombination withclient-side caching.
Aswediscuss inChap. 7,updates inthislayergenerally donothavetocome into
effect immediately, making itmucheasier tokeepreplicas consistent.
Availability foranameserver intheadministrational layerisprimarily impor-
tantforclients inthesameorganization asthename server. Ifthename server
fails,many resources within theorganization become unreachable because they
cannot belooked up.Ontheotherhand, itmaybelessimportant thatresources in
anorganization aretemporarily unreachable forusersoutside thatorganization.
Withrespect toperformance, name servers intheadministrational layerhave
similar characteristics asthose intheglobal layer. Because changes tonodes do
notoccur allthatoften, caching lookup results canbehighly effective, making
performance lesscritical. However, incontrast totheglobal layer, theadministra-
tionallayer should takecarethatlookup results arereturned within afewmillisec-SEC. 5.3 STRUCTURED NAMING 205
onds, either directly fromtheserver orfromtheclient's localcache. Likewise,
updates should generally beprocessed quicker thanthoseoftheglobal layer. For
example, itisunacceptable thatanaccount foranewusertakeshours tobecome
effective.
These requirements canoftenbemetbyusinghigh-performance machines to
runname servers. Inaddition, client-side caching should beapplied, combined
withreplication forincreased overall availability.
Availability requirements forname servers atthemanagerial levelaregener-
allylessdemanding. Inparticular, itoftensuffices touseasingle (dedicated) ma-
chine torunname servers attheriskoftemporary unavailability. However, per-
formance iscrucial. Users expect operations totakeplace immediately. Because
updates occur regularly, client-side caching isoftenlesseffective, unless special
measures aretaken, which wediscuss inChap. 7.
Figure 5-14. Acomparison between name servers forimplementing nodes from
alarge-scale name space partitioned intoaglobal layer, anadministrational
layer, andamanagerial layer.
Acomparison between name servers atdifferent layers isshown inFig.5-14.
Indistributed systems, name servers intheglobal andadministrational layerare
themostdifficult toimplement. Difficulties arecaused byreplication andcach-
ing,which areneeded foravailability andperformance, butwhich alsointroduce
consistency problems. Some oftheproblems areaggravated bythefactthat
caches andreplicas arespread across awide-area network, which introduces long
communication delays thereby making synchronization evenharder. Replication
andcaching arediscussed extensively inChap. 7.
Implementation ofNameResolution
Thedistribution ofaname space across multiple name servers affects the
implementation ofnameresolution. Toexplain theimplementation ofnamereso-
lution inlarge-scale name services, weassume forthemoment thatname servers
arenotreplicated andthatnoclient-side caches areused.Eachclient hasaccess to206 NAMING CHAP. 5
alocalname resolver, which isresponsible forensuring thatthename resolution
process iscarried out.Referring toFig.5-13,assume the(absolute) pathname
root:«nl,VU, CS,ftp,pub,globe, index.html>
istoberesolved. Using aURLnotation, thispathname would correspond to
ftp://ftp.cs. vu.nl/pub/globe/index.html. There arenowtwoways toimplement
nameresolution.
Initerative name resolution, aname resolver hands overthecomplete name
totherootname server. Itisassumed thattheaddress where therootserver canbe
contacted iswellknown. Therootserver willresolve thepathname asfarasit
can,andreturn theresult totheclient. Inourexample, therootserver canresolve
onlythelabelnl,forwhich itwillreturn theaddress oftheassociated name ser-
ver.
Atthatpoint. theclient passes theremaining pathname (i.e.,nl:<VU, cs,jtp,
pub, globe, index.html> tothatname server. Thisserver canresolve onlythe
labelVU, andreturns theaddress oftheassociated name server, along withthe
remaining pathnamevu:<cs, ftp,pub,globe, index.html>.
Theclient's name resolver willthencontact thisnextname server, which
responds byresolving thelabelcs,andsubsequently alsoftp,returning theaddress
oftheFTPserver along withthepathnameftp:<pub, globe, index.html>. The
client thencontacts theFTPserver, requesting ittoresolve thelastpartoftheori-
ginalpathname. TheFTPserver willsubsequently resolve thelabels pub.globe,
andindex.html, andtransfer therequested file(inthiscaseusingFTP). Thisproc-
essofiterative name resolution isshown inFig.5-15. (Thenotation #<cs> is
usedtoindicate theaddress oftheserver responsible forhandling thenode
referred toby<cs>.)
Figure 5-15. Theprinciple ofiterative name resolution.SEC. 5.3 STRUCTURED NAMING 207
Inpractice, thelaststep,namely contacting theFTPserver andrequesting it
totransfer thefilewithpathname ftpi-cpub, globe, index.himl», iscarried out
separately bytheclient process. Inother words, theclient would normally hand
onlythepathname root:«nl,VU, CS, ftp> tothename resolver, from which it
would expect theaddress where itcancontact theFTPserver, asisalsoshown in
Fig.5-15.
Analternative toiterative name resolution istouserecursion during name
resolution. Instead ofreturning eachintermediate result backtotheclient's name
resolver, withrecursive name resolution, aname server passes theresult tothe
nextname server itfinds. So,forexample, when therootname server finds the
address ofthename server implementing thenodenamed nl,itrequests thatname
server toresolve thepathname nl:<vu, CS,ftp,pub,globe, index.html>. Using
recursive name resolution aswell, thisnextserver willresolve thecomplete path
andeventually return thefileindex.html totherootserver, which, intum,will
passthatfiletotheclient's name resolver.
Recursive name resolution isshown inFig.5-16. Asiniterative name resolu-
tion,thelastresolution step(contacting theFTPserver andasking ittotransfer
theindicated file)isgenerally carried outasaseparate process bytheclient.
Figure 5-16. Theprinciple ofrecursive name resolution.
Themain drawback ofrecursive name resolution isthatitputsahigher per-
formance demand oneachname server. Basically, aname server isrequired to
handle thecomplete resolution ofapathname, although itmaydosoincoopera-
tionwithother name servers. Thisadditional burden isgenerally sohighthat
name servers intheglobal layerofaname space support onlyiterative name reso-
lution.
There aretwoimportant advantages torecursive name resolution. Thefirst
advantage isthatcaching results ismore effective compared toiterative name
resolution. Thesecond advantage isthatcommunication costs maybereduced. To208 NAMING CHAP. 5
explain these advantages, assume thataclient's name resolver willaccept path
names referring onlytonodes intheglobal oradministrational layerofthename
space. Toresolve thatpartofapathnamethatcorresponds tonodes inthemanag-
eriallayer, aclient willseparately contact thename server returned byitsname
resolver, aswediscussed above.
Recursive name resolution allows eachname server togradually learnthead-
dressofeachname server responsible forimplementing lower-level nodes. Asa
result, caching canbeeffectively usedtoenhance performance. Forexample,
when therootserver isrequested toresolve thepathname root:<nl, vu,cs,ftp>,
itwilleventually gettheaddress ofthename server implementing thenode
referred tobythatpathname. Tocome tothatpoint, thename server forthenl
nodehastolookuptheaddress ofthename server forthevunode, whereas the
latterhastolookuptheaddress ofthenameserver handling thecsnode.
Because changes tonodes intheglobal andadministrational layer donot
occur often, therootname server caneffectively cache thereturned address.
Moreover, because theaddress isalsoreturned, byrecursion, tothename server
responsible forimplementing thevunodeandtotheoneimplementing thenl
node,itmight aswellbecached atthoseservers too.
Likewise, theresults ofintermediate name lookups canalsobereturned and
cached. Forexample, theserver forthenlnodewillhavetolookuptheaddress of
thevunodeserver. Thataddress canbereturned totherootserver when thenl
server returns theresult oftheoriginal name lookup. Acomplete overview ofthe
resolution process, andtheresults thatcanbecached byeachname server is
shown inFig.5-17.
Figure 5-17. Recursive name resolution of«nl,l'U, CS. jtp>. Name servers
cache intermediate results forsubsequent lookups.
Themainbenefit ofthisapproach isthat,eventually. lookup operations canbe
handled quiteefficiently. Forexample, suppose thatanother client laterrequestsSEC. 5.3 STRUCTURED NAMING 209
resolution ofthepathname root:<nl, Vii,cs,flits>. Thisname ispassed tothe
root,which canimmediately forward ittothenameserver forthecsnode,andre-
questittoresolve theremaining pathnamecs:<jlits>.
Withiterative nameresolution, caching isnecessarily restricted totheclient's
name resolver. Consequently, ifaclient Arequests theresolution ofaname, and
another client Blaterrequests thatsamenametoberesolved, nameresolution will
havetopassthrough thesamename servers aswasdoneforclient A.Asacom-
promise, many organizations usealocal, intermediate name server thatisshared
byallclients. Thislocalname server handles allnaming requests andcaches re-
sults.Suchanintermediate server isalsoconvenient fromamanagement pointof
view. Forexample, onlythatserver needs toknow where therootname server is
located; othermachines donotrequire thisinformation.
Thesecond advantage ofrecursive name resolution isthatitisoftencheaper
withrespect tocommunication. Again, consider theresolution ofthepathname
root:<nl, vu,cs,ftp>andassume theclient islocated inSanFrancisco. Assuming
thattheclient knows theaddress oftheserver forthenlnode,withrecursive name
resolution, communication follows theroutefromtheclient's hostinSanFran-
ciscotothenlserver inTheNetherlands, shown asR1inFig.5-18. From there
on,communication issubsequently needed between thenlserver andthename
server oftheVrije Universiteit ontheuniversity campus inAmsterdam, The
Netherlands. Thiscommunication isshown asR2.Finally, communication is
needed between thevuserver andthename server intheComputer Science
Department, shown asR3.Therouteforthereplyisthesame, butintheopposite
direction. Clearly, communication costsaredictated bythemessage exchange be-
tween theclient's hostandthenlserver.
Incontrast, withiterative name resolution, theclient's hosthastocommuni-
cateseparately withthenlserver, thevuserver, andthecsserver, ofwhich the
totalcosts mayberoughly threetimes thatofrecursive name resolution. The
arrows inFig.5-18labeled /1,/2,and/3showthecommunication pathforitera-
tivename resolution.
5.3.4 Example: TheDomain Name System
Oneofthelargest distributed naming services inusetoday istheInternet
Domain Name System (DNS). DNSisprimarily usedforlooking upIPaddresses
ofhostsandmailservers. Inthefollowing pages, weconcentrate ontheorganiza-
tionoftheDNSname space, andtheinformation stored initsnodes. Also, we
takeacloser lookattheactual implementation ofDNS. More information canbe
found inMockapetris (1987) andAlbitz andLiu(2001). Arecent assessment of
DNS, notably concerning whether itstillfitstheneeds ofthecurrent Internet, can
befound inLevien (2005). Fromthisreport, onecandrawthesomewhat surpris-
ingconclusion thatevenaftermorethan30years, DNSgivesnoindication thatit210 NAMING CHAP. 5
Figure 5-18. Thecomparison between recursive anditerative name resolution
withrespect tocommunication costs.
needs tobereplaced. Wewould argue thatthemaincause liesinthedesigner's
deepunderstanding ofhowtokeepmatters simple. Practice inotherfields ofdis-
tributed systems indicates thatnotmany aregifted withsuchanunderstanding.
TheDNSName Space
TheDNSname space ishierarchically organized asarooted tree.Alabelisa
case-insensitive string made upofalphanumeric characters. Alabelhasamax-
imum length of63characters; thelength ofacomplete pathname isrestricted to
255characters. Thestring representation ofapathname consists oflisting itsla-
bels,starting withtherightmost one,andseparating thelabels byadot(H.").The
rootisrepresented byadot.So,forexample, thepathname root:<nl,VU, cs,
flits>, isrepresented bythestringflits.cs. vu.nl., which includes therightmost dot
toindicate therootnode. Wegenerally omitthisdotforreadability.
Because eachnodeintheDNSname space hasexactly oneincoming edge
(withtheexception oftherootnode, which hasnoincoming edges), thelabelat-
tached toanode's incoming edgeisalsousedasthename forthatnode. Asubtree
iscalled adomain; apathname toitsrootnodeiscalled adomain name. Note
that,justlikeapathname, adomain namecanbeeither absolute orrelative.
Thecontents ofanodeisformed byacollection ofresource records. There
aredifferent typesofresource records. Themajor onesareshown inFig.5-19.
AnodeintheDNSname space often willrepresent several entities atthe
sametime.Forexample, adomain name suchasvu.nl isusedtorepresent ado-
mainandazone. Inthiscase,thedomain isimplemented bymeans ofseveral
(nonoverlapping) zones.
AnSOA (startofauthority) resource record contains information suchasan
e-mail address ofthesystem administrator responsible fortherepresented zone.
thename ofthehostwhere dataonthezonecanbefetched, andsoon.SEC. 5.3 STRUCTURED NAMING 211
Figure 5-19. Themostimportant types ofresource records forming thecontents
ofnodes intheDNSname space.
AnA(address) record, represents aparticular hostintheInternet. TheA
record contains anIPaddress forthathosttoallow communication. Ifahosthas
several IPaddresses, asisthecasewithmulti-homed machines, thenodewillcon-
tainanArecord foreachaddress.
Another typeofrecord istheMX(mailexchange) record, which islikeasym-
boliclinktoanoderepresenting amailserver. Forexample, thenoderepresenting
thedomain cs.vu.nl hasanMXrecord containing thename zephyr.cs.vu.nl, which
refers toamailserver. Thatserver willhandle allincoming mailaddressed to
usersinthecs.vu.nldomain. There maybeseveral MXrecords stored inanode.
Related toMXrecords areSRVrecords, which contain thename ofaserver
foraspecific service. SRVrecords aredefined inGulbrandsen (2000). Theser-
viceitselfisidentified bymeans ofaname along withthenameofaprotocol. For
example, theWebserver inthecs.vu.nl domain could benamed bymeans ofan
SRVrecord suchas.Jutp.ctcp.cs.vu.nl, Thisrecord would thenrefertotheactual
name oftheserver (which issoling.cs. vu.nl). Animportant advantage ofSRV
records isthatclients neednolonger know theDNSname ofthehostproviding a
specific service. Instead, onlyservice names needtobestandardized, afterwhich
theproviding hostcanbelooked up.
Nodes thatrepresent azone, contain oneormoreNS(name server) records.
LikeMXrecords, anNSrecord contains thename ofaname server thatimple-
ments thezonerepresented bythenode.Inprinciple, eachnodeinthenamespace
canstoreanNSrecord referring tothename server thatimplements it.However,
aswediscuss below, theimplementation oftheDNSnamespace issuchthatonly
nodes representing zones needtostoreNSrecords.
DNSdistinguishes aliases fromwhatarecalled canonical names. Eachhost
isassumed tohaveacanonical, orprimary name. Analiasisimplemented by212 NAMING CHAP. 5
means ofnodestoring aCNAME record containing thecanonical name ofahost.
Thenameofthenodestoring sucharecord isthusthesameasasymbolic link,as
wasshown inFig.5-JJ.
DNSmaintains aninverse mapping ofIPaddresses tohostnames bymeans of
PTR(pointer) records. Toaccommodate thelookups ofhostnames when given
onlyanIPaddress, DNSmaintains adomain named in-addr.arpa, which contains
nodes thatrepresent Internet hostsandwhich arenamed bytheIPaddress ofthe
represented host.Forexample, hosttVww.cs.\'u.nl hasIPaddress 130.37.20.20.
DNScreates anodenamed 20.20.37.130.in-addr.mpa, which isusedtostorethe
canonical nameofthathost(which happens tobesoling.cs. vu.nliinaPTRrecord.
Thelasttworecord types areHINFO records andTXTrecords. AnHINFO
(hostinfo)record isusedtostoreadditional information onahostsuchasitsma-
chine typeandoperating system. Inasimilar fashion, TXTrecords areusedfor
anyotherkindofdatathatauserfindsuseful tostoreabout theentity represented
bythenode.
DNSImplementation
Inessence, theDNSname space canbedivided intoaglobal layer andan
administrational layerasshown inFig.5-13.Themanagerial layer, which isgen-
erally formed bylocalfilesystems, isformally notpartofDNSandistherefore
alsonotmanaged byit.
Eachzoneisimplemented byaname server, which isvirtually always repli-
cated foravailability. Updates forazonearenormally handled bytheprimary
name server. Updates takeplace bymodifying theDNSdatabase localtothepri-
maryserver. Secondary name servers donotaccess thedatabase directly, but,in-
stead, request theprimary server totransfer itscontent. Thelatteriscalled azone
transfer inDNSterminology.
ADNSdatabase isimplemented asa(small) collection offiles,ofwhich the
mostimportant onecontains alltheresource records forallthenodes inaparticu-
larzone.Thisapproach allows nodes tobesimply identified bymeans oftheirdo-
mainname, bywhich thenotion ofanodeidentifier reduces toan(implicit) index
intoafile.
Tobetter understand these implementation issues, Fig.5-20shows asmall
partofthefilethatcontains mostoftheinformation forthecs.vu.nl domain (the
filehasbeenedited forsimplicity). Thefileshows thecontents ofseveral nodes
thatarepartofthecs.vu.nldomain, where eachnodeisidentified bymeans ofits
domain name.
Thenodecs.vu.nlrepresents thedomain aswellasthezone.ItsSOAresource
record contains specific information onthevalidity ofthisfile.which willnot
concern usfurther. There arefourname servers forthiszone, referred tobytheir
canonical hostnames intheNSrecords. TheTXTrecord isusedtogivesomeSEC. 5.3 STRUCTURED NAMING 213
additional information onthiszone, butcannot beautomatically processed byany
name server. Furthermore, there isasingle mailserver thatcanhandle incoming
mailaddressed tousers inthisdomain. Thenumber preceding thename ofamail
server specifies aselection priority. Asending mailserver should always firstat-
tempt tocontact themailserver withthelowest number.
Figure 5-20. Anexcerpt fromtheDNSdatabase forthezonecs.vU.1l1.
Thehoststar.cs. vu.nloperates asaname server forthiszone. Name servers
arecritical toanynaming service. What canbeseenabout thisname server isthat
additional robustness hasbeencreated bygiving twoseparate network interfaces,214 NAMING CHAP. 5
eachrepresented byaseparate Aresource record. Inthisway,theeffects ofabro-
kennetwork linkcanbesomewhat alleviated astheserver willremain accessible.
Thenextfourlines(forzephyr.cs. vu.nl) givethenecessary information about
oneofthedepartment's mailservers. Note thatthismailserver isalsobacked up
byanother mailserver, whose pathistornado.cs. vu.nl,
Thenextsixlines show atypical configuration inwhich thedepartment's
Web server, aswellasthedepartment's FTPserver areimplemented byasingle
machine, called soling. cs.vu.nl.Byexecuting bothservers onthesame machine
(andessentially using thatmachine onlyforInternet services andnotanything
else), system management becomes easier. Forexample, bothservers willhave
thesame viewofthefilesystem, andforefficiency, partofthefilesystem maybe
implemented onsoling.cs.vu.nl, This approach isoften applied inthecaseof
WWW andFTPservices.
Thefollowing twolines show information ononeofthedepartment's older
server clusters. Inthiscase, ittellsusthattheaddress 130.37.198.0 isassociated
withthehostname vucs-dasl.cs.vu.nl,
Thenextfourlinesshow information ontwomajor printers connected tothe
local network. Note thataddresses intherange 192.168.0.0 to192.168.255.255
areprivate: theycanbeaccessed onlyfrom inside thelocal network andarenot
accessible fromanarbitrary Internet host.
Figure 5-21. Partofthedescription forthevu.nl domain which contains the
cs.vu.nldomain.
Because thecs.vu.nl domain isimplemented asasingle zone. Fig.5-20does
notinclude references toother zones. Thewaytorefertonodes inasubdomain
thatareimplemented inadifferent zoneisshown inFig.5-21. What needs tobe
done istospecify aname server forthesubdomain bysimply giving itsdomain
name andIPaddress. When resolving aname foranode thatliesinthecs.vu.nl
domain, name resolution willcontinue atacertain point byreading theDNS data-
basestored bythename server forthecs.vu.nldomain.SEC. 5.3 STRUCTURED NAMING 215
Decentralized DNSImplementations
Theimplementation ofDNSwedescribed sofaristhestandard one.Itfol-
lowsahierarchy ofservers with13well-known rootservers andending inmil-
lionsofservers attheleaves. Animportant observation isthathigher-level nodes
receive many morerequests thanlower-level nodes. Onlybycaching thename-
to-address bindings ofthesehigher levels isitpossible toavoid sending requests
tothemandthusswamping them.
These scalability problems canbeavoided alt-ogether withfullydecentralized
solutions. Inparticular, wecancompute thehashofaDNS name, andsubse-
quently takethathashasakeyvaluetobelooked upinadistributed- hashtableor
ahierarchical location service withafullypartitioned rootnode. Theobvious
drawback ofthisapproach isthatwelosethestructure oftheoriginal name. This
lossmayprevent efficient implementations of,forexample, finding allchildren in
aspecific domain.
Ontheother hand, therearemany advantages tomapping DNStoaDHT-
based implementation, notably itsscalability. Asargued byWalfish etal.(2004),
whenthereisaneedformany names, usingidentifiers asasemantic-free wayof
accessing datawillallow different systems tomake useofasingle naming sys-
tem.Thereason issimple: bynowitiswellunderstood howahugecollection of
(flat)names canbeefficiently supported. Whatneeds tobedoneistomaintain the
mapping ofidentifier-to-name information, where inthiscaseaname maycome
fromtheDNSspace, beaURL, andsoon.Using identifiers canbemadeeasier
byletting usersororganizations useastrictlocalname space. Thelatteriscom-
pletely analogous tomaintaining aprivate setting ofenvironment variables ona
computer.
Mapping DNSontoDHT-based peer-to-peer systems hasbeenexplored in
CoDoNS (Ramasubramanian andSirer, 2004a). TheyusedaDHT-based system
inwhich theprefixes ofkeysareusedtoroutetoanode.Toexplain, consider the
casethateachdigitfromanidentifier istakenfromtheset{0,...,b-l},where b
isthebasenumber. Forexample, inChord, b=2.Ifweassume thatb=4,then
consider anodewhose identifier is3210. Intheirsystem, thisnodeisassumed to
keeparouting tableofnodes having thefollowing identifiers:
no: anodewhose identifier hasprefix 0
n1: anodewhose identifier hasprefix 1
n2: anodewhose identifier hasprefix 2
n30: anodewhose identifier hasprefix 30
n31: anodewhose identifier hasprefix 31
n33: anodewhose identifier hasprefix 33
n320: anodewhose identifier hasprefix320
n322: anodewhose identifier hasprefix 322
n323: anodewhose identifier hasprefix 323216 NAMING CHAP. 5
where Nisthenumber ofnodes inthenetwork andaistheparameter intheZipf
distribution.
Thisformula allows totakeinformed decisions onwhich DNSrecords should
bereplicated. Tomake matters concrete, consider thecasethatb=32and
a=0.9.Then, inanetwork with10,000 nodes and1,000,000 DNSrecords, and
trying toachieve anaverage ofC=1 hoponlywhendoing alookup, wewillhave
thatXo=0.0000701674, meaning thatonlythe70mostpopular DNS recordsNode 3210isresponsible forhandling keysthathaveprefix 321.Ifitreceives a
lookup request forkey3123,itwillforward ittonode113bwhich, inturn,willsee
whether itneeds toforward ittoanodewhose identifier hasprefix 312.(We
should notethateachnodemaintains twootherliststhatitcanuseforrouting ifit
misses anentryinitsrouting table.) Details ofthisapproach canbefound forPas-
try(Rowstron andDruschel, 2001) andTapestry (Zhao etal.,2004).
Returning toCoDoNS, anoderesponsible forkeykstores theDNSresource
records associated withdomain name thathashes tok.Theinteresting part,how-
ever,isthatCoDoNS attempts tominimize thenumber ofhopsinrouting are-
questbyreplicating resource records. Theprinciple strategy issimple: node3210
willreplicate itscontent tonodes having prefix 321.Suchareplication willre-
duceeachrouting pathending innode3210byonehop.Ofcourse, thisreplica-
tioncanbeapplied againtoallnodes having prefix 32,andsoon.
When aDNSrecord getsreplicated toallnodes withimatching prefixes, itis
saidtobereplicated atleveli.Notethatarecord replicated atleveli(generally)
requires ilookup stepstobefound. However, thereisatrade-off between the
levelofreplication andtheuseofnetwork andnoderesources. What CoDoNS
doesisreplicate totheextent thattheresulting aggregate lookup latency isless
thanagiven constant C.
More specifically, thinkforamoment about thefrequency distribution ofthe
queries. Imagine ranking thelookup queries byhowoften aspecific keyisre-
quested putting themostrequested keyinfirstposition. Thedistribution ofthe
lookups issaidtobeZipf-like ifthefrequency ofthen-thranked itemispropor-
tional tol/na,withaclose to1.George ZipfwasaHarvard linguist who
discovered thisdistribution while studying word-use frequencies inanatural lan-
guage. However, asitturnsout,italsoapplies among many otherthings, tothe
population ofcities, sizeofearthquakes, top-income distributions, revenues of
corporations, and,perhaps nolonger surprisingly, DNSqueries (Jung etal.,2002).
Now, ifXiisthefraction ofmostpopular records thataretobereplicated at
leveli,thenRamasubramanian andSirer(2004b) showthatXicanbeexpressed
bythefollowing formula (forourpurposes, onlythefactthatthisformula exists is
actually important; wewillseehowtouseitshortly):SEC. 5.3 STRUCTURED NAMING 217
should bereplicated everywhere. Likewise, withxI=0.00330605, the3306next
mostpopular records should bereplicated atlevel1.Ofcourse, itisrequired that
Xi<1.Inthisexample, Xl=0.155769 andX3>1,sothatonlythenextmost
popular 155,769 records getreplicated andalltheothers ornot.Nevertheless, on
average, asingle hopisenough tofindarequested DNSrecord.
S.4ATTRIBUTE-BASED NAMING
Flatandstructured names generally provide aunique andlocation-indepen-
dentwayofreferring toentities. Moreover, structured names havebeenpartly
designed toprovide ahuman-friendly waytoname entities sothattheycanbe
conveniently accessed. Inmostcases, itisassumed thatthename refers toonlya
single entity. However, location independence andhuman friendliness arenotthe
onlycriterion fornaming entities. Inparticular, asmoreinformation isbeingmade
available itbecomes important toeffectively search forentities. Thisapproach re-
quires thatausercanprovide merely adescription ofwhatheislooking for.
There aremany waysinwhich descriptions canbeprovided, butapopular
oneindistributed systems istodescribe anentity interms of(attribute, value)
pairs, generally referred toasattribute-based naming. Inthisapproach, anenti-
tyisassumed tohaveanassociated collection ofattributes. Eachattribute says
something about thatentity. Byspecifying which values aspecific attribute should
have,auseressentially constrains thesetofentities thatheisinterested in.Itisup
tothenaming system toreturn oneormoreentities thatmeettheuser's descrip-
tion.Inthissection wetakeacloser lookatattribute-based naming systems.
5.4.1 Directory Services
Attribute-based naming systems arealsoknown asdirectory services, where-
assystems thatsupport structured naming aregenerally called naming systems.
Withdirectory services, entities haveasetofassociated attributes thatcanbe
usedforsearching. Insomecases, thechoice ofattributes canberelatively sim-
ple.Forexample, inane-mail system, messages canbetagged withattributes for
thesender, recipient, subject, andsoon.However, eveninthecaseofe-mail,
matters become difficult when othertypes ofdescriptors areneeded, asisillus-
trated bythedifficulty ofdeveloping filters thatwillallow onlycertain messages
(based ontheirdescriptors) tobepassed through.
What itallboilsdown toisthatdesigning anappropriate setofattributes is
nottrivial. Inmostcases, attribute design hastobedonemanually. Evenifthere
isconsensus onthesetofattributes touse,practice shows thatsetting thevalues
consistently byadiverse group ofpeople isaproblem byitself, asmany willhave
experienced whenaccessing music andvideodatabases ontheInternet.218 NAMING CHAP. 5
Toalleviate someoftheseproblems, research hasbeenconducted onunifying
theways thatresources canbedescribed. Inthecontext ofdistributed systems,
oneparticularly relevant development istheresource description framework
(RDF). Fundamental totheRDFmodel isthatresources aredescribed astriplets
consisting ofasubject, apredicate, andanobject. Forexample, (Person, name,
Alice) describes aresource Person whose name isAlice. InRDF, eachsubject,
predicate, orobject canbearesource itself. Thismeans thatAlice maybeimple-
mented asreference toafilethatcanbesubsequently retrieved. Inthecaseofa
predicate, sucharesource could contain atextual description ofthatpredicate. Of
course, resources associated withsubjects andobjects could beanything. Refer-
ences inRDFareessentially URLs.
Ifresource descriptions arestored, itbecomes possible toquery thatstorage in
awaythatiscommon formany attributed-based naming systems. Forexample, an
application could askfortheinformation associated withaperson named Alice.
Such aquery would return areference totheperson resource associated with
Alice. Thisresource canthensubsequently befetched bytheapplication. More in-
formation onRDFcanbefound inManola andMiller (2004).
Inthisexample, theresource descriptions arestored atacentral location.
There isnoreason whytheresources should reside atthesamelocation aswell.
However, nothaving thedescriptions inthesameplace mayincuraserious per-
formance problem. Unlike structured naming systems, looking upvalues inanat-
tribute-based naming system essentially requires anexhaustive search through all
descriptors. When considering performance, suchasearch islessofproblem with-
inasingle datastore,butseparate techniques needtobeapplied when thedatais
distributed across multiple, potentially dispersed computers. Inthefollowing, we
willtakealookatdifferent approaches tosolving thisproblem indistributed sys-
tems.
5.4.2 Hierarchical Implementations: LDAP
Acommon approach totackling distributed directory services istocombine
structured naming withattribute-based naming. Thisapproach hasbeenwidely
adopted, forexample, inMicrosoft's Active Directory service andothersystems.
Many ofthesesystems use,orrelyonthelightweight directory access protocol
commonly referred simply asLDAP. TheLDAP directory service hasbeen
derived fromOS1's X.500 directory service. Aswithmany OSIservices, thequal-
ityoftheirassociated implementations hindered widespread use,andsimplifica-
tionswereneeded tomakeituseful. Detailed information onLDAP canbefound
inArkills (2003).
Conceptually, anLDAP directory service consists ofanumber ofrecords,
usually referred toasdirectory entries. Adirectory entryiscomparable toare-
source record inDNS. Eachrecord ismade upofacollection of(attribute. value)
pairs, where eachattribute hasanassociated type.Adistinction ismade betweenSEC. 5.4 ATIRIBUTE-BASED NAMING 219
single-valued attributes andmultiple-valued attributes. Thelattertypically repres-
entarrays andlists.Asanexample, asimple directory entryidentifying thenet-
workaddresses ofsomegeneral servers fromFig.5-20isshown inFig.5-22.
Figure 5-22. Asimple example ofanLDAP directory entry using LDAP na-
mingconventions.
Inourexample, wehaveusedanaming convention described intheLDAP
standards, which applies tothefirstfiveattributes. Theattributes Organization
andOrganization Unitdescribe, respectively, theorganization andthedepartment
associated withthedatathatarestored intherecord. Likewise, theattributes
Locality andCountry provide additional information onwhere theentryisstored.
TheCommonName attribute isoftenusedasan(ambiguous) name toidentify an
entrywithin alimited partofthedirectory. Forexample, thename "Main server"
maybeenough tofindourexample entrygiven thespecific values fortheother
fourattributes Country, Locality, Organization, andOrganizational Unit. Inour
example, onlyattribute Mail..Servers hasmultiple values associated withit.All
otherattributes haveonlyasingle value.
Thecollection ofalldirectory entries inanLDAP directory service iscalled a
directory information base(DIB). Animportant aspect ofaDIBisthateach
record isuniquely named sothatitcanbelooked up.Suchaglobally unique name
appears asasequence ofnaming attributes ineachrecord. Eachnaming attribute
iscalled arelative distinguished name, orRDN forshort. Inourexample in
Fig:5-22,thefirstfiveattributes areallnaming attributes. Using theconventional
abbreviations forrepresenting naming attributes inLDAP, asshown inFig.5-22,
theattributes Country, Organization, andOrganizational Unitcould beusedto
formtheglobally unique name
analogous totheDNSnamenl.vu.cs,
AsinDNS, theuseofglobally unique names bylisting RDNs insequence,
leadstoahierarchy ofthecollection ofdirectory entries, which isreferred toasa220 NAMING CHAP. 5
directory information tree(DIT). ADITessentially forms thenaming graph of
anLDAP directory service inwhich eachnoderepresents adirectory entry. Inad-
dition. anodemayalsoactasadirectory inthetraditional sense, inthattheremay
beseveral children forwhich thenodeactsasparent. Toexplain, consider thena-
minggraph aspartly shown inFig.5-23(a).(Recall thatlabels areassociated with
edges.)
Figure 5-23. (a)Partofadirectory information tree. (b)Twodirectory entries
having Host.Name asRDN.
Node Ncorresponds tothedirectory entryshown, inFig.5-22. Atthesame
time,thisnodeactsasaparent toanumber ofotherdirectory entries thathavean
additional naming attribute Host....Name thatisusedasanRDN. Forexample, such
entries maybeusedtorepresent hostsasshown inFig.5-23(b).
AnodeinanLDAP naming graph canthussimultaneously represent adirec-
toryinthetraditional senseaswediscussed previously, aswellasanLDAP rec-
ord.Thisdistinction issupported bytwodifferent lookup operations. Thereadop-
eration isusedtoreadasingle record given itspathnameintheDIT.Incontrast,
thelistoperation isusedtolistthenames ofalloutgoing edges ofagiven nodein
theDIT.Eachname corresponds toachildnodeofthegiven node. NotethattheSEC. 5.4 ATTRIBUTE-BASED NAMING 221
listoperation doesnotreturn anyrecords; itmerely returns names. Inotherwords,
calling read withasinputthename
/C=NUO= Vrije UniversiteitlOU=Comp. Sc.lCN=Main server
willreturn therecord shown inFig.5-22, whereas calling listwillreturn the
names starandzephyr fromtheentries shown inFig.5-23(b) aswellasthenames
ofotherhoststhathavebeenregistered inasimilar way.
Implementing anLDAP directory service proceeds inmuch thesamewayas
implementing anaming service suchasDNS, except thatLDAP supports more
lookup operations aswewilldiscuss shortly. When dealing withalarge-scale di-
rectory, theDITisusually partitioned anddistributed across several servers,
known asdirectory service agents (DSA). Eachpartofapartitioned DITthus
corresponds toazoneinDNS. Likewise, eachDSAbehaves verymuch thesame
asanormal name server, except thatitimplements anumber oftypical directory
services, suchasadvanced search operations.
Clients arerepresented bywhatarecalled directory useragents, orsimply
DUAs. ADUA issimilar toaname resolver instructured-naming services. A
DUA exchanges information withaDSAaccording toastandardized access pro-
tocol.
What makes anLDAP implementation different fromaDNSimplementation
arethefacilities forsearching through aDIB.Inparticular, facilities areprovided
tosearch foradirectory entrygiven asetofcriteria thatattributes ofthesearched
entries should meet. Forexample, suppose thatwewantalistofallmainservers
attheVrijeUniversiteit. Using thenotation defined inHowes (1997), suchalist
canbereturned usingasearch operation suchas
answer =search("&(C=NL)(O=Vrije Universiteit)(OU=*)(CN=Main server)")
Inthisexample, wehavespecified thattheplace tolookformainservers isthe
organization named Vrije Universiteit incountry NL,butthatwearenot
interested inaparticular organizational unit.However, eachreturned result should
havetheCNattribute equaltoMain server.
Aswealready mentioned, searching inadirectory service isgenerally an
expensive operation. Forexample, tofindallmainservers attheVrijeUniversiteit
requires searching allentries ateachdepartment andcombining theresults ina
single answer. Inotherwords, wewillgenerally needtoaccess several leafnodes
ofaDITinordertogetananswer. Inpractice, thisalsomeans thatseveral DSAs
needtobeaccessed. Incontrast, naming services canoftenbeimplemented in
suchawaythatalookup operation requires accessing onlyasingle leafnode.
Thiswhole setupofLDAP canbetaken onestepfurther byallowing several
treestoco-exist, while alsobeing linked toeachother. Thisapproach isfollowed
inMicrosoft's Active Directory leading toaforest ofLDAP domains (Allen and
Lowe-Norris, 2003). Obviously, searching insuchanorganization canbe
overwhelmingly complex. Tocircumvent someofthescalability problems, Active222 NAMING CHAP. 5
Directory usually assumes thereisaglobal index server (called aglobal catalog)
thatcanbesearched first.Theindex willindicate which LDAP domains needto
besearched further.
Although LDAP byitselfalready exploits hierarchy forscalability, itiscom-
montocombine LDAP withDNS. Forexample, every treeinLDAP needs tobe
accessible attheroot(known inActive Directory asadomain controller). The
rootisoftenknown under aDNSname, which, intum,canbefound through an
appropriate SRVrecord asweexplained above.
LDAP typically represents astandard wayofsupporting attribute-based na-
ming. Other recent directory services following thismore traditional approach
havebeendeveloped aswell,notably inthecontext ofgridcomputing andWeb
services. Onespecific example istheuniversal directory anddiscovery integra-
tionorsimply UDDI.
These services assume animplementation inwhich one,orotherwise onlya
fewnodes cooperate tomaintain asimple distributed database. From atechnologi-
calpoint ofview, thereisnorealnovelty here.Likewise, thereisalsonothing
really newtoreport when itcomes tointroducing terminology, ascanbereadily
observed when going through thehundreds ofpages oftheUDDI specifications
(Clement etal.,2004). Thefundamental scheme isalways thesame: scalability is
achieved bymaking several ofthese databases accessible toapplications, which
arethenresponsible forquerying eachdatabase separately andaggregating there-
sults.Somuchformiddleware support.
5.4.3 Decentralized Implementations
Withtheadvent ofpeer-to-peer systems, researchers havealsobeenlooking
forsolutions fordecentralized attribute-based naming systems. Thekeyissuehere
isthat(attribute, value) pairsneedtobeefficiently mapped sothatsearching can
bedoneefficiently, thatis,byavoiding anexhaustive search through theentire
attribute space. Inthefollowing wewilltakealookatseveral wayshowtoestab-
lishsuchamapping.
Mapping toDistributed Hash Tables
Letusfirstconsider thecasewhere (attribute, value) pairsneedtobesup-
ported byaDHT-based system. First,assume thatqueries consist ofaconjunction
ofpairsaswithLDAP, thatis.auserspecifies alistofattributes, along withthe
unique valuehewants toseeforevery respective attribute. Themainadvantage of
thistypeofquery isthatnoranges needtobesupported. Range queries maysigni-
ficantly increase thecomplexity ofmapping pairstoaDHT.
Single-valued queries aresupported intheINSrrwine system (Balazinska et
aI.,2002). Eachentity (referred toasaresource) isassumed tobedescribed by
means ofpossibly hierarchically organized attributes suchasshown inFig.5-24.SEC. 5.4 ATTRIBUTE-BASED NAMING 223
Each suchdescription istranslated intoanattribute-value tree(AVTree) which
isthenusedasthebasis foranencoding thatmaps wellontoaDHT-based system.
Figure 5-24. (a)Ageneral description ofaresource. (b)Itsrepresentation asan
AVTree.
Themain issue istotransform theAVTrees intoacollection ofkeysthatcan
belooked upinaDHT system. Inthiscase, every pathoriginating intherootis
assigned aunique hashvalue, where apathdescription starts withalink(repres-
enting anattribute), andendseither inanode (value), oranother link.Taking
Fig.5-24(b) asourexample, thefollowing hashes ofallsuchpaths areconsidered:
hI: hash(type-book)
h2: hash(type-book-author)
h3: hashttype-book-author- Tolkien)
h4: hash(type-book-title)
h5: hash(type-book-title-LOTR)
h6: hash(genre-fantasy)
Anoderesponsible forhashvalue hiwillkeep(areference to)theactual resource.
Inourexample, thismayleadtosixnodes storing information onTolkien's Lord
oftheRings. However, thebenefit ofthisredundancy isthatitwillallow sup-
porting partial queries. Forexample, consider aquery suchas"Return books writ-
tenbyTolkien." Thisquery istranslated intotheAVTree shown inFig.5-25
leading tocomputing thefollowing threehashes:
hi: hash(type-book)
h2:hash(type-book -author)
h3: hashttype-book-author- Tolkien)
These values willbesenttonodes thatstore information onTolkien' sbooks, and
willatleastreturn LordoftheRings. Notethatahashsuchash1israther general
andwillbegenerated often. These typeofhashes canbefiltered outofthesys-
tem.Moreover, itisnotdifficult toseethatonlythemostspecific hashes needto
beevaluated. Further details canbefound inBalzinska etal.(2002).
Now let'stakealookatanother typeofquery, namely those thatcancontain
range specifications forattribute values. Forexample, someone looking fora224 NAMING CHAP. 5
Figure 5-25. (a)Theresource description ofaquery. (b)Itsrepresentation asan
AVTree.
house willgenerally wanttospecify thatthepricemustfallwithin aspecific
range. Again. several solutions havebeenproposed andwewillcome across some
ofthemwhendiscussing publish/subscribe systems inChap. 13.Here, wediscuss
asolution adopted intheSWORD resource discovery system (Oppenheimer etal.,
2005).
InSWORD, (attribute, value) pairsasprovided byaresource description are
firsttransformed intoakeyforaDHT. Notethatthesepairsalways contain asin-
glevalue; onlyqueries maycontain value ranges forattributes. When computing
thehash,thename oftheattribute anditsvalue arekeptseparate. Inotherwords,
specific bitsintheresulting keywillidentify theattribute name, while others
identify itsvalue. Inaddition, thekeywillcontain anumber ofrandom bitsto
guarantee uniqueness among allkeysthatneedtobegenerated.
Inthisway,thespace ofattributes isconveniently partitioned: if11bitsarere-
served tocodeattribute names, 2ndifferent server groups canbeused, onegroup
foreachattribute name. Likewise, byusingmbitstoencode values, afurther par-
titioning perserver group canbeapplied tostorespecific (attribute, value) pairs.
DHTs areusedonlyfordistributing attribute names.
Foreachattribute name, thepossible range ofitsvalue ispanitioned into
subranges andasingle server isassigned toeachsubrange. Toexplain, consider a
resource description withtwoattributes: a1taking values intherange [1..10] and
a2taking values intherange [101...200].Assume therearetwoservers fora1:
Sll takescareofrecording values ofa1in[1..5], andS12 forvalues in[6..10].
Likewise, server S21records values fora2inrange [101..150] andserver S22for
values in[151..200]. Then, when theresource getsvalues (a1=7,a2 =175),
server S12andserver S22willhavetobeinformed.
Theadvantage ofthisscheme isthatrange queries canbeeasily supported.
When aquery isissued toreturn resources thathavea2lying between 165and
189,thequery canbeforwarded toserver S22whocanthenreturn theresources
thatmatch thequery range. Thedrawback, however, isthatupdates needtobe
senttomultiple servers. Moreover, itisnotimmediately clearhowwelltheloadisSEC. 5.4 ATTRIBUTE-BASED NAMING 225
balanced between thevarious servers. Inparticular, ifcertain range queries tum
outtobeverypopular, specific servers willreceive ahighfraction ofallqueries.
Howthisload-balancing problem canbetackled forDHT-based systems isdis-
cussed inBharambe atal.(2004).
Semantic Overlay Networks
Thedecentralized implementations ofattribute-based naming already showan
increasing degree ofautonomy ofthevarious nodes. Thesystem islesssensitive
tonodes joining andleaving incomparison to,forexample, distributed LDAP-
based systems. Thisdegree ofautonomy isfurther increased when nodes have
descriptions ofresources thataretheretobediscovered byothers. Inotherwords,
thereisnoapriori deterministic scheme bywhich (attribute, value) pairsare
spread across acollection ofnodes.
Nothaving suchascheme forces nodes todiscover where requested resources
are.Such adiscovery istypical forunstructured overlay networks, which we
already discussed inChap. 2.Inordertomake searching efficient, itisimportant
thatanodehasreferences toothers thatcanmostlikely answer itsqueries. Ifwe
make theassumption thatqueries originating fromnodeParestrongly related to
theresources thatPhas,thenweareseeking toprovide Pwithacollection of
linkstosemantically proximal neighbors. Recall thatsuchalistisalsoknown asa
partial view. Semantical proximity canbedefined indifferent ways, butitboils
down tokeeping trackofnodes withsimilar resources. Thenodes andtheselinks
willthenformwhatisknown asasemantic overlay network.
Acommon approach tosemantic overlay networks istoassume thatthereis
commonality inthemetainformation maintained ateachnode. Inotherwords, the
resources stored ateachnodearedescribed usingthesamecollection ofattributes,
or,more precisely, thesame dataschema (Crespo andGarcia-Molina, 2003).
Having suchaschema willallow defining specific similarity functions between
nodes. EachnodewillthenkeeponlylinkstotheKmostsimilar neighbors and
query those nodes firstwhen looking forspecific data.Notethatthisapproach
makes sense onlyifwecangenerally assume thataquery initiated atanode
relates tothecontent stored atthatnode.
Unfortunately, assuming commonality indataschemas isgenerally wrong. In
practice, themetainformation onresources ishighly inconsistent across different
nodes andreaching consensus andwhatandhowtodescribe resources iscloseto
impossible. Forthisreason, semantic overlay networks willgenerally needtofind
different waystodefine similarity.
Oneapproach istoforget about attributes altogether andconsider onlyvery
simple descriptors suchasfilenames. Passively constructing anoverlay canbe
donebykeeping trackofwhich nodes respond positively tofilesearches. Forex-
ample, Sripanidkulchai etal.(2003) firstsendaquery toanode's semantic neigh-
bors,butiftherequested fileisnottherea(limited) broadcast isthendone. Of226 NAMING CHAP. 5
course, suchabroadcast mayleadtoanupdate ofthesemantic-neighbors list.As
anote,itisinteresting toseethatifanoderequests itssemantic neighbors tofor-
ward aquery totheirsemantic neighbors, thattheeffect isminimal (Handrukande
etaI.,2004). Thisphenomenon canbeexplained bywhatisknown asthesmall-
worldeffectwhich essentially states thatthefriends ofAlice arealsoeachother's
friends (Watts. 1999).
Amore proactive approach toward constructing asemantic-neighbor list'is
proposed byVoulgaris andvanSteen (2005) whouseasimple semantic proxim-
ityfunction defined onthefilelistsFLp andFLQ oftwonodes PandQ,respec-
tively. Thisfunction simply counts thenumber ofcommon filesinFLp andFLQ.
Thegoalisthentooptimize theproximity function byletting anodekeepalistof
onlythose neighbors thathavethemostfilesincommon withit.
Figure 5-26. Maintaining asemantic overlay through gossiping.
Tothisend,atwo-layered gossiping scheme isdeployed asshown inFig.5-
26.Thebottom layer consists ofanepidemic protocol thataimsatmaintaining a
partial view ofuniform randomly-selected nodes. There aredifferent ways to
achieve thisasweexplained inChap. 2[seealsoJelasity etal.(2005a)]. Thetop
layer maintains alistofsemantically proximal neighbors through gossiping. To
initiate anexchange, annodePcanrandomly select aneighbor Qfrom itscurrent
list,butthetrickistoletPsendonlythose entries thataresemantically closest to
Q.Intum,when Preceives entries from Q,itwilleventually keep apartial view
consisting onlyofthesemantically closest nodes. Asitturns out,thepartial views
asmaintained bythetoplayer willrapidly converge toanoptimum.
Aswillhave become clear bynow, semantic overlay networks areclosely
related todecentralized searching. Anextensive overview ofsearching inallkinds
ofpeer-to-peer systems isdiscussed inRisson andMoors (2006).
5.5SUMMARY
Names areusedtorefertoentities. Essentially, there arethree types ofnames.
Anaddress isthename ofanaccess point associated withanentity, alsosimply
called theaddress ofanentity. Anidentifier isanother typeofname. IthasthreeSEC. 5.5 SUMMARY 227
properties: eachentity isreferred tobyexactly oneidentifier, anidentifier refers
toonlyoneentity, andisnever assigned toanother entity. Finally, human-friendly
names aretargeted tobeusedbyhumans andassucharerepresented ascharacter
strings. Given thesetypes, wemake adistinction between flatnaming, structured
naming, andattribute-based naming.
Systems forflatnaming essentially needtoresolve anidentifier totheaddress
ofitsassociated entity. Thislocating ofanentity canbedoneindifferent ways.
Thefirstapproach istousebroadcasting ormulticasting. Theidentifier oftheen-
tityisbroadcast toevery process inthedistributed system. Theprocess offering
anaccess point fortheentity responds byproviding anaddress forthataccess
point. Obviously, thisapproach haslimited scalability.
Asecond approach istouseforwarding pointers. Eachtimeanentity moves
toanextlocation, itleaves behind apointer telling where itwillbenext.Locating
theentity requires traversing thepathofforwarding pointers. Toavoid large
chains ofpointers, itisimportant toreduce chains periodically
Athirdapproach istoallocate ahome toanentity. Eachtimeanentity moves
toanother location, itinforms itshome where itis.Locating anentity proceeds by
firstasking itshome forthecurrent location.
Afourth approach istoorganize allnodes intoastructured peer-to-peer sys-
tem,andsystematically assign nodes toentities taking theirrespective identifiers
intoaccount. Bysubsequently devising arouting algorithm bywhich lookup re-
quests aremoved toward thenoderesponsible foragiven entity, efficient and
robust nameresolution ispossible.
Afifthapproach istobuildahierarchical search tree.Thenetwork isdivided
intononoverlapping domains. Domains canbegrouped intohigher-level (nono-
verlapping) domains, andsoon.There isasingle top-level domain thatcovers the
entire network. Eachdomain atevery levelhasanassociated directory node.Ifan
entity islocated inadomain D,thedirectory nodeofthenexthigher-level domain
willhaveapointer toD.Alowest-level directory nodestores theaddress ofthe
entity. Thetop-level directory nodeknows aboutallentities.
Structured names areeasily organized inaname space. Aname space canbe
represented byanaming graph inwhich anoderepresents anamed entity andthe
labelonanedgerepresents thename under which thatentity isknown. Anode
having multiple outgoing edges represents acollection ofentities andisalso
known asacontext nodeordirectory. Large-scale naming graphs areoftenorgan-
izedasrooted acyclic directed graphs.
Naming graphs areconvenient toorganize human-friendly names inastruc-
tured way.Anentity canbereferred tobyapathname. Name resolution isthe
process oftraversing thenaming graph bylooking upthecomponents ofapath
name, oneatatime.Alarge-scale naming graph isimplemented bydistributing
itsnodes across multiple nameservers. When resolving apathnamebytraversing
thenaming graph, name resolution continues atthenextname server assoonasa
nodeisreached implemented bythatserver.228 NAMING CHAP. 5
More problematic areattribute-based naming schemes inwhich entities are
described byacollection of(attribute, value) pairs.Queries arealsoformulated as
suchpairs, essentially requiring anexhaustive search through alldescriptors. Such
asearch isonlyfeasible when thedescriptors arestored inasingle database.
However, alternative solutions havebeendevised bywhich thepairsaremapped
ontoDHT-based systems, essentially leading toadistribution ofthecollection of
entity descriptors.
Related toattribute-based naming istogradually replace name resolution by
distributed search techniques. Thisapproach isfollowed insemantic overlay net-
works, inwhich nodes maintain alocalEstofothernodes thathavesemantically
similar content. These semantic listsallow forefficient search totakeplace by
which firsttheimmediate neighbors arequeried, andonlyafterthathashadno
success willa(limited) broadcast bedeployed.
PROBLEMS
1.Giveanexample ofwhere anaddress ofanentity Eneeds tobefurther resolved into
another address toactually access E.
2.Would youconsider aURL suchashttp://www.acme.org/index.html tobelocation
independent? What about http://www.acme.nllindex.html?
3.Givesome examples oftrueidentifiers.
4.Isanidentifier allowed tocontain information ontheentity itrefers to?
5.Outline anefficient implementation ofglobally unique identifiers.
6.Consider theChord system asshown inFig.5-4andassume thatnode 7hasjust
joined thenetwork. What would itsfinger tablebeandwould there beanychanges to
other finger tables?
7.Consider aChord DHT-based system forwhich kbitsofanm-bit identifier space have
beenreserved forassigning tosuperpeers. Ifidentifiers arerandomly assigned, how
many superpeers canoneexpect tohaveinanN-node system?
8.Ifweinsert anodeintoaChord system, doweneedtoinstantly update allthefinger
tables?
9.What isamajor drawback ofrecursive lookups when resolving akeyinaDHT-based
system?
10.Aspecial formoflocating anentity iscalled anycasting, bywhich aservice isidenti-
fiedbymeans ofanIFaddress (see.forexample, RFC1546). Sending arequest toan
anycast address, returns aresponse fromaserver implementing theservice identifiedCHAP. 5 PROBLEMS 229
bythatanycast address. Outline theimplementation ofananycast service based onthe
hierarchical location service described inSec.5.2.4.
11.Considering thatatwo-tiered home-based approach isaspecialization ofahierarchi-
callocation service, where istheroot?
12.Suppose thatitisknown thataspecific mobile entity willalmost never move outside
domain D,andifitdoes. itcanbeexpected toreturn soon. Howcanthisinformation
beusedtospeed upthelookup operation inahierarchical location service?
13.Inahierarchical location service withadepth ofk,howmany location records needto
beupdated atmostwhen amobile entity changes itslocation?
14.Consider anentity moving fromlocation AtoB.while passing several intermediate lo-
cations where itwillreside foronlyarelatively shorttime.When arriving atB,itset-
tlesdown forawhile. Changing anaddress inahierarchical location service maystill
takearelatively longtimetocomplete, andshould therefore beavoided when visiting
anintermediate location. Howcantheentity belocated atanintermediate location?
15.Therootnode inhierarchical location services maybecome apotential bottleneck.
Howcanthisproblem beeffectively circumvented?
16.Giveanexample ofhowtheclosure mechanism foraURLcould work.
17.Explain thedifference between ahardlinkandasoftlinkinUNIX systems. Arethere
things thatcanbedone withahardlinkthatcannot bedonewithasoftlinkorvice
versa?
18.High-level name servers inDNS, thatis,name servers implementing nodes inthe
DNS name space thatareclose totheroot,generally donotsupport recursive name
resolution. Canweexpect much performance improvement iftheydid?
19.Explain howDNS canbeusedtoimplement ahome-based approach tolocating
mobile hosts.
20.Howisamounting point looked upinmostUNIX systems?
21.Consider adistributed filesystem thatusesper-user name spaces. Inother words, each
userhashisown,private name space. Cannames fromsuchname spaces beusedto
share resources between twodifferent users?
22.Consider DNS. TorefertoanodeNinasubdomain implemented asadifferent zone
thanthecurrent domain, aname server forthatzoneneeds tobespecified. Isitalways
necessary toinclude aresource record forthatserver's address, orisitsometimes suf-
ficient toprovide onlyitsdomain name?
23.Counting common filesisarather naive wayofdefining semantic proximity. Assume
youwere tobuild semantic overlay networks based ontextdocuments, what other
semantic proximity function canyouthink of?
24.(Lab assignment) SetupyourownDNSserver. Install BIND oneither aWindows or
UNIX machine andconfigure itforafewsimple names. Testyourconfiguration using
tools suchastheDomain Information Groper (DIG). Make sureyourDNS database
includes records forname servers, mailservers, andstandard servers. Notethatifyou230 NAMING CHAP. 5
arerunning BIND onamachine withhostname HOSTNAME, youshould beableto
resolve names oftheformRESOURCE-NAME.HOSTNAME.6
SYNCHRONIZATION
Intheprevious chapters, wehavelooked atprocesses andcommunication be-
tween processes. While communication isimportant, itisnottheentire story.
Closely related ishowprocesses cooperate andsynchronize withoneanother.
Cooperation ispartly supported bymeans ofnaming, which allows processes toat
leastshare resources, orentities ingeneral.
Inthischapter, wemainly concentrate onhowprocesses cansynchronize. For
example, itisimportant thatmultiple processes donotsimultaneously access a
shared resource, suchasprinter, butinstead cooperate ingranting eachother tem-
porary exclusive access. Another example isthatmultiple processes maysome-
times needtoagree ontheordering ofevents, suchaswhether message mlfrom
process Pwassentbefore oraftermessage m2fromprocess Q.
Asitturns out,synchronization indistributed systems isoften much more dif-
ficult compared tosynchronization inuniprocessor ormultiprocessor systems.
Theproblems andsolutions thatarediscussed inthischapter are,bytheirnature,
rather general, andoccur inmany different situations indistributed systems.
Westartwithadiscussion oftheissue ofsynchronization based onactual
time, followed bysynchronization inwhich onlyrelative ordering matters rather
thanordering inabsolute time.
Inmany cases, itisimportant thatagroup ofprocesses canappoint oneproc-
essasacoordinator, which canbedonebymeans ofelection algorithms. Wedis-
cussvarious election algorithms inaseparate section.
231232 SYNCHRONIZATION CHAP. 6
Distributed algorithms come inallsortsandflavors andhavebeendeveloped
forverydifferent typesofdistributed systems. Many examples (andfurther refer-
ences) canbefound inAndrews (2000) andGuerraoui andRodrigues (2006).
More formal approaches toawealth ofalgorithms canbefound intextbooks
fromAttiya andWelch (2004), Lynch (1996), and(Tel,2000).
6.1CLOCKSYNCHRONIZATION
Inacentralized system, timeisunambiguous. When aprocess wants toknow
thetime,itmakes asystem callandthekernel tellsit.Ifprocess Aasksforthe
time.andthenalittlelaterprocess Basksforthetime,thevalue thatBgetswill
behigher than(orpossibly equalto)thevalueAgot.Itwillcertainly notbelower.
Inadistributed system, achieving agreement ontimeisnottrivial.
Justthink, foramoment, about theimplications ofthelackofglobal timeon
theUNIX make program, asasingle example. Normally, inUNIX, largeprograms
aresplitupintomultiple source files,sothatachange toonesource fileonlyre-
quires onefiletoberecompiled, notallthefiles.Ifaprogram consists of100
files, nothaving torecompile everything because onefilehasbeen changed
greatly increases thespeed atwhich programmers canwork.
Thewaymake normally works issimple. When theprogrammer hasfinished
changing allthesource files,herunsmake, which examines thetimes atwhich all
thesource andobject fileswerelastmodified. Ifthesource fileinput. chastime
2151andthecorresponding object fileinput.o hastime2150, make knows that
input.c hasbeenchanged sinceinput.o wascreated, andthusinput.c mustbere-
compiled. Ontheotherhand,ifoutput.c hastime2144andoutput.o hastime2145,
nocompilation isneeded. Thusmake goesthrough allthesource filestofindout
which onesneedtoberecompiled andcallsthecompiler torecompile them.
Nowimagine whatcould happen inadistributed system inwhich therewere
noglobal agreement ontime.Suppose thatoutput.o hastime2144asabove, and
shortly thereafter output.c ismodified butisassigned time2143because theclock
onitsmachine isslightly behind, asshown inFig.6-1.Make willnotcallthe
compiler. Theresulting executable binary program willthencontain amixture of
object filesfromtheoldsources andthenewsources. Itwillprobably crash and
theprogrammer willgocrazy trying tounderstand whatiswrong withthecode.
There aremany moreexamples where anaccurate account oftimeisneeded.
Theexample above caneasily bereformulated tofiletimestamps ingeneral. In
addition, thinkofapplication domains suchasfinancial brokerage, security audit-
ing,andcollaborative sensing, anditwillbecome clearthataccurate timing isim-
portant. Sincetimeissobasictothewaypeople thinkandtheeffect ofnothaving
alltheclocks synchronized canbesodramatic, itisfitting thatwebegin ourstudy
ofsynchronization withthesimple question: Isitpossible tosynchronize allthe
clocks inadistributed system? Theanswer issurprisingly complicated.Figure 6-1.When eachmachine hasitsownclock, anevent thatoccurred after
another event maynevertheless beassigned anearlier time.
6.1.1 Physical Clocks
Nearly allcomputers haveacircuit forkeeping trackoftime. Despite the
widespread useoftheword"clock" torefertothesedevices, theyarenotactually
clocks intheusual sense. Timer isperhaps abetter word. Acomputer timer is
usually aprecisely machined quartz crystal. When keptunder tension, quartz crys-
talsoscillate atawell-defined frequency thatdepends onthekindofcrystal, how
itiscut,andtheamount oftension. Associated witheachcrystal aretworegisters,
acounter andaholding register. Eachoscillation ofthecrystal decrements the
counter byone.When thecounter getstozero,aninterrupt isgenerated andthe
counter isreloaded fromtheholding register. Inthisway,itispossible toprogram
atimer togenerate aninterrupt 60times asecond, oratanyotherdesired fre-
quency. Eachinterrupt iscalled oneclock tick.
When thesystem isbooted, itusually askstheusertoenterthedateandtime,
which isthenconverted tothenumber ofticksaftersomeknown starting dateand
stored inmemory. Mostcomputers haveaspecial battery-backed upCMOS RAM
sothatthedateandtimeneednotbeentered onsubsequent boots. Atevery clock
tick,theinterrupt service procedure addsonetothetimestored inmemory. Inthis
way,the(software) clockiskeptuptodate.
With asingle computer andasingle clock, itdoesnotmatter much ifthis
clock isoffbyasmall amount. Since allprocesses onthemachine usethesame.
clock, theywillstillbeinternally consistent. Forexample, ifthefileinput.c has
time2151andfileinput.o hastime2150, make willrecompile thesource file,
eveniftheclock isoffby2andthetruetimes are2153and2152, respectively.
Allthatreally matters aretherelative times.
Assoonasmultiple CPUsareintroduced, eachwithitsownclock, thesitua-
tionchanges radically. Although thefrequency atwhich acrystal oscillator runsis
usually fairly stable, itisimpossible toguarantee thatthecrystals indifferent
computers allrunatexactly thesamefrequency. Inpractice, whenasystem hasn
computers, allncrystals willrunatslightly different rates,causing the(software)
clocks gradually togetoutofsynch andgivedifferent values whenreadout.This
difference intimevalues iscalled clock skew. Asaconsequence ofthisclock233 CLOCK SYNCHRONIZATION SEC. 6.1234 SYNCHRONIZATION CHAP. 6
skew, programs thatexpect thetimeassociated withafile,object, process, or
message tobecorrect andindependent ofthemachine onwhich itwasgenerated
(i.e.,which clockitused)canfail,aswesawinthemake example above.
Insomesystems (e.g.,real-time systems), theactual clock timeisimportant.
Under thesecircumstances, external physical clocks areneeded. Forreasons ofef-
ficiency andredundancy, multiple physical clocks aregenerally considered desir-
able,which yields twoproblems: (1)Howdowesynchronize them withreal-
world clocks. and(2)Howdowesynchronize theclocks witheachother?
Before answering thesequestions, letusdigress slightly toseehowtimeisac-
tually measured. Itisnotnearly aseasyasonemight think, especially when high
accuracy isrequired. Since theinvention ofmechanical clocks inthe17thcentury,
timehasbeenmeasured astronomically. Every day,thesunappears toriseonthe
eastern horizon, thenclimbs toamaximum height inthesky,andfinally sinksin
thewest.Theevent ofthesun'sreaching itshighest apparent point intheskyis
called thetransit ofthesun.Thisevent occurs atabout nooneachday.Thein-
terval between twoconsecutive transits ofthesuniscalled thesolar day.Since
thereare24hours inaday,eachcontaining 3600seconds, thesolar second isde-
finedasexactly 1I86400th ofasolarday.Thegeometry ofthemean solardaycal-
culation isshown inFig.6-2.
Figure 6-2.Computation ofthemean solarday.
Inthe1940s, itwasestablished thattheperiod oftheearth's rotation isnot
constant. Theearthisslowing down duetotidalfriction andatmospheric drag.
Based onstudies ofgrowth patterns inancient coral, geologists nowbelieve that
300million yearsagotherewereabout 400daysperyear.Thelength oftheyear
(thetimeforonetriparound thesun)isnotthought tohavechanged; thedayhas
simply become longer. Inaddition tothislong-term trend, short-term variations inSEC.6.1 CLOCKSYNCHROMZATION 235
thelength ofthedayalsooccur, probably caused byturbulence deepintheearth's
coreofmolten iron.These revelations ledastronomers tocompute thelength of
thedaybymeasuring alargenumber ofdaysandtaking theaverage before divid-
ingby86,400. Theresulting quantity wascalled themean solarsecond.
Withtheinvention oftheatomic clockin1948,itbecame possible tomeasure
timemuch moreaccurately, andindependent ofthewiggling andwobbling ofthe
earth, bycounting transitions ofthecesium 133atom. Thephysicists tookoverthe
joboftimekeeping fromtheastronomers anddefined thesecond tobethetimeit
takesthecesium 133atomtomakeexactly 9,192,631,770 transitions. Thechoice
of9,192,631,770 wasmade tomake theatomic second equal tothemean solar
second intheyearofitsintroduction. Currently, several laboratories around the
world havecesium 133clocks. Periodically, eachlaboratory tellstheBureau
International del'Heure (BIR) inParishowmany times itsclock hasticked. The
BIRaverages thesetoproduce International Atomic Time, which isabbreviated
TAl. ThusTAIisjustthemean number ofticksofthecesium 133clocks since
midnight onJan.1,1958 (thebeginning oftime)divided by9,192,631,770.
Although TAlishighly stable andavailable toanyone whowants togotothe
trouble ofbuying acesium clock, thereisaserious problem withit;86,400 TAl
seconds isnowabout 3mseclessthanamean solarday(because themean solar
dayisgetting longer allthetime). Using TAlforkeeping timewould mean that
overthecourse oftheyears, noonwould getearlier andearlier, untilitwould
eventually occur intheweehours ofthemorning. People might notice thisandwe
could havethesamekindofsituation asoccurred in1582when PopeGregory
XIIIdecreed that10daysbeomitted fromthecalendar. Thiseventcaused riotsin
thestreets because landlords demanded afullmonth's rentandbankers afull
month's interest, while employers refused topayworkers forthe10daystheydid
notwork, tomention onlyafewoftheconflicts. TheProtestant countries, asa
matter ofprinciple, refused tohaveanything todowithpapal decrees anddidnot
accept theGregorian calendar for170years.
Figure 6-3.TAlseconds areofconstant length, unlike solar seconds. Leap
seconds areintroduced when necessary tokeepinphase withthesun.
BIRsolves theproblem byintroducing leapseconds whenever thedis-
crepancy between TAIandsolartimegrows to800msec. Theuseofleapseconds236 SYNCHRONIZATION CHAP. 6
isiJlustrated inFig.6-3.Thiscorrection givesrisetoatimesystem based oncon-
stantTAlseconds butwhich staysinphase withtheapparent motion ofthesun.It
iscaned Universal Coordinated Time, butisabbreviated asUTC. UTCisthe
basisofallmodern civiltimekeeping. Ithasessentially replaced theoldstandard,
Greenwich Mean Time. which isastronomical time.
Mostelectric power companies synchronize thetiming oftheir60-Hz or50-
Hzclocks toUTC, sowhenBIHannounces aleapsecond, thepower companies
raisetheirfrequency to61Hzor51Hzfor60or50sec.toadvance alltheclocks
intheirdistribution area.Since Isecisanoticeable interval foracomputer, an
operating system thatneeds tokeepaccurate timeoveraperiod ofyears must
havespecial software toaccount forleapseconds astheyareannounced (unless
theyusethepower linefortime,which isusually toocrude). Thetotalnumber of
leapseconds introduced intoUTCsofarisabout 30.
Toprovide UTCtopeople whoneedprecise time,theNational Institute of
Standard Time (NIST) operates ashortwave radiostation withcallletters WWV
fromFortCollins, Colorado. WWV broadcasts ashortpulse atthestartofeach
UTCsecond. Theaccuracy ofWWV itselfisabout ±lmsec, butduetorandom
atmospheric fluctuations thatcanaffect thelength ofthesignal path,inpractice
theaccuracy isnobetter than±10msec. InEngland, thestation MSF, operating
fromRugby, Warwickshire, provides asimilar service, asdostations inseveral
othercountries.
Several earthsatellites alsoofferaUTCservice. TheGeostationary Environ-
mentOperational Satellite canprovide UTC accurately to0.5msec, andsome
othersatellites doevenbetter.
Using either shortwave radioorsatellite services requires anaccurate know-
ledge oftherelative position ofthesender andreceiver, inorder tocompensate
forthesignal propagation delay. Radio receivers forWWV, GEOS, andtheother
UTCsources arecommercially available.
6.1.2 Global Positioning System
Asasteptoward actual clock synchronization problems, wefirstconsider a
related problem, namely determining one's geographical position anywhere on
Earth. Thispositioning problem isbyitselfsolved through ahighly specific. dedi-
cated distributed system, namely GPS, which isanacronym forglobal posi-
tioning system. GPSisasatellite-based distributed system thatwaslaunched in
1978.Although ithasbeenusedmainly formilitary applications, inrecent yearsit
hasfound itswaytomany civilian applications, notably fortraffic navigation.
However, many moreapplication domains exist. Forexample, GPSphones now
allow toletcallers trackeachother's position, afeature which mayshow tobe
extremely handy when youarelostorintrouble. Thisprinciple caneasily be
applied totracking otherthings aswell,including pets,children, cars,boats, and
soon.Anexcellent overview ofGPSisprovided byZogg(2002).SEC. 6.1 CLOCK SYNCHRONIZATION 237
GPSuses29satellites eachcirculating inanorbitataheight ofapproximately
20,000 km.Each satellite hasuptofouratomic clocks, which areregularly cali-
brated fromspecial stations onEarth. Asatellite continuously broadcasts itsposi-
tion,andtimestamps eachmessage withitslocal time. Thisbroadcasting allows
every receiver onEarth toaccurately compute itsownposition using, inprinciple,
onlythree satellites. Toexplain, letusfirstassume thatallclocks, including the
receiver's, aresynchronized.
- Inorder tocompute aposition, consider firstthetwo-dimensional case, as
shown inFig.6-4,inwhich twosatellites aredrawn, along withthecircles repres-
enting points atthesame distance from each respective satellite. They-axis
represents theheight, while thex-axis represents astraight linealong theEarth's
surface atsealevel. Ignoring thehighest point, weseethattheintersection ofthe
twocircles isaunique point (inthiscase,perhaps somewhere upamountain).
Figure 6-4.Computing aposition inatwo-dimensional space.
Thisprinciple ofintersecting circles canbeexpanded tothree dimensions,
meaning thatweneedthree satellites todetermine thelongitude, latitude, andalti-
tudeofareceiver onEarth. Thispositioning isallfairly straightforward, butmat-
tersbecome complicated when wecannolonger assume thatallclocks areper-
fectly synchronized.
There aretwoimportant real-world factsthatweneedtotakeintoaccount:
1.Ittakes awhile before dataonasatellite's position reaches there-
cerver,
2.Thereceiver's clock isgenerally notinsynch withthatofasatellite.
Assume thatthetimestamp from asatellite iscompletely accurate. LetArdenote
thedeviation ofthereceiver's clock from theactual time. When amessage is238 SYNCHRONlZA nON CHAP. 6
where Xi,)'i.andZidenote thecoordinates ofsatellite i.What weseenowisthatif
wehavefoursatellites, wegetfourequations infourunknowns, allowing usto
solvethecoordinates Xp)'pandz,forthereceiver, butalsob.r.Inotherwords, a
GPSmeasurement willalsogiveanaccount oftheactual time. Later inthis
chapter wewillreturn todetermining positions following asimilar approach.
Sofar,wehaveassumed thatmeasurements areperfectly accurate. Ofcourse,
theyarenot.Foronething, GPSdoesnottakeleapseconds intoaccount. Inother
words, thereisasystematic deviation fromUTe, which byJanuary 1,2006is14
seconds. Suchanerrorcanbeeasily compensated forinsoftware. However, there
aremany othersources oferrors, starting withthefactthattheatomic clocks in
thesatellites arenotalways inperfect synch, theposition ofasatellite isnot
known precisely, thereceiver's clockhasafiniteaccuracy, thesignal propagation
speed isnotconstant (assignals slowdown when entering, e.g.,theionosphere),
andsoon.Moreover, weallknow thattheearthisnotaperfect sphere, leading to
further corrections.
Byandlarge, computing anaccurate position isfarfromatrivial undertaking
andrequires going down intomany gorydetails. Nevertheless, evenwithrela-
tively cheap GPSreceivers, positioning canbeprecise within arange of1-5
meters. Moreover, professional receivers (which caneasily behooked upina
computer network) haveaclaimed erroroflessthan20-35 nanoseconds. Again,
werefertotheexcellent overview byZogg(2002) asafirststeptoward getting
acquainted withthedetails.
6.1.3ClockSynchronization Algorithms
Ifonemachine hasaWWV receiver, thegoalbecomes keeping alltheother
machines synchronized toit.Ifnomachines haveWWV receivers, eachmachine
keeps trackofitsowntime,andthegoalistokeepallthemachines together as
wellaspossible. Many algorithms havebeenproposed fordoing thissynchroniza-
tion.Asurvey isgiveninRamanathan eta1.(1990).received fromsatellite iwithtimestamp Ti,thenthemeasured delay b.ibythere-
ceiver consists oftwocomponents: theactual delay, along withitsowndeviation:
Assignals travel withthespeed oflight,c,themeasured distance ofthesatellite is
clearly cb.i'With
being therealdistance between thereceiver andthesatellite, themeasured dis-
tancecanberewritten tod,+Cb.r.Therealdistance issimply computed as:SEC.6.1 CLOCKSYNCHRON~ATION 239
thetimer canbesaidtobeworking within itsspecification. Theconstant pis
specified bythemanufacturer andisknown asthemaximum driftrate. Note
thatthemaximum driftratespecifies towhatextent aclock's skewisallowed to
fluctuate. Slow, perfect, andfastclocks areshown inFig.6-5.Allthealgorithms havethesameunderlying model ofthesystem. Eachma-
chineisassumed tohaveatimer thatcauses aninterrupt Htimes asecond. When
thistimer goesoff,theinterrupt handler adds1toasoftware clock thatkeeps
trackofthenumber ofticks(interrupts) sincesomeagreed-upon timeinthepast.
Letuscallthevalue ofthisclock C.More specifically, when theUTCtimeist,
thevalue oftheclock onmachine pisCpU). Inaperfect world, wewould have
CpU) =tforallpandallt.Inotherwords, C;U)=dCldt ideally should be1.C;(t)
iscalled thefrequency ofp'»clock attimet.Theskewoftheclock isdefined as
C;(t) -1anddenotes theextent towhich thefrequency differs fromthatofaper-
fectclock. Theoffset relative toaspecific timetisCpU) -t.
Realtimers donotinterrupt exactly Htimes asecond. Theoretically, atimer
withH=60should generate 216,000 ticksperhour.Inpractice, therelative error
obtainable withmodem timer chips isabout 10-5, meaning thataparticular ma-
chine cangetavalue intherange 215,998 to216,002 ticksperhour.More pre-
cisely, ifthereexists someconstant psuchthat
Figure 6-5.Therelation between clock timeandUTewhen clocks tickatdif-
ferent rates.
Iftwoclocks aredrifting fromUTCintheopposite direction, atatimedt
aftertheyweresynchronized, theymaybeasmuchas2p&apart. Iftheoperating
system designers wanttoguarantee thatnotwoclocks everdiffer bymorethan0,
clocks mustberesynchronized (insoftware) atleastevery 0/2p seconds. Thevar-
iousalgorithms differ inprecisely howthisresynchronization isdone.240 SYNCHRONIZA nON CHAP. 6
Network TimeProtocol
Acommon approach inmany protocols andoriginally proposed byCristian
(1989) istoletclients contact atimeserver. Thelattercanaccurately provide the
current time,forexample, because itisequipped withaWWV receiver oran
accurate clock. Theproblem, ofcourse, isthatwhen contacting theserver, mes-
sagedelays willhaveoutdated thereported time.Thetrickistofindagoodesti-
mation forthesedelays. Consider thesituation sketched inFig.6-6.
Figure 6-6.Getting thecurrent timefromatimeserver.
Ofcourse, timeisnotallowed torunbackward. IfA'sclock isfast,e<0,mean-
ingthatAshould. inprinciple, setitsclock backward. Thisisnotallowed asit
could cause serious problems suchasanobject filecompiled justaftertheclock
change having atimeearlier thanthesource which wasmodified justbefore the
clock change.
Suchachange mustbeintroduced gradually. Onewayisasfollows. Suppose
thatthetimerissettogenerate 100interrupts persecond. Normally, eachinterrupt
would add10msec tothetime.When slowing down, theinterrupt routine adds
only9mseceachtimeuntilthecorrection hasbeenmade. Similarly, theclock can
beadvanced gradually byadding 11msecateachinterrupt instead ofjumping it
forward allatonce.
Inthecaseofthenetwork timeprotocol (NTP), thisprotocol issetuppair- .
wisebetween servers. Inotherwords, Bwillalsoprobe Aforitscurrent time.The
offset eiscomputed asgiven above, along withtheestimation 8forthedelay:Inthiscase,Awillsendarequest toB,timestamped withvalue Ti-B,inturn,
willrecord thetimeofreceipt T2(taken fromitsownlocalclock), andreturns a
response timestamped withvalue T3,andpiggybacking thepreviously recorded
value T2.Finally, Arecords thetimeoftheresponse's arrival, T4.Letusassume
thatthepropagation delays fromAtoBisroughly thesameasBtoA,meaning
thatT2-T1 ::::T4-T3- Inthatcase,Acanestimate itsoffset relative toBasSEC. 6.1 CLOCK SYNCHRONIZATION 241
Eightpairsof(8,8) values arebuffered, finally taking theminimal valuefound for
8asthebestestimation forthedelay between thetwoservers, andsubsequently
theassociated valueeasthemostreliable estimation oftheoffset.
Applying NTPsymmetrically should, inprinciple, alsoletBadjust itsclockto
thatofA.However, ifB'sclock isknown tobemore accurate, thensuchan
adjustment would befoolish. Tosolve thisproblem, NTPdivides servers into
strata. Aserver withareference clock suchasaWWV receiver oranatomic
clock, isknown tobeastratum-I server (theclock itselfissaidtooperate at
stratum 0).When Acontacts B,itwillonlyadjust itstimeifitsownstratum level
ishigher thanthatofB..Moreover, afterthesynchronization, A'sstratum level
willbecome onehigher thanthatofB.Inotherwords, ifBisastratum-k server,
thenAwillbecome astratum-(k+l) server ifitsoriginal stratum levelwasalready
larger thank.Duetothesymmetry ofNTP, ifA'sstratum levelwaslower than
thatofB,Bwilladjust itselftoA.
There aremany important features aboutNTP,ofwhich many relate toidenti-
fying andmasking errors, butalsosecurity attacks. NTPisdescribed inMills
(1992) andisknown toachieve (worldwide) accuracy intherange of1-50msec.
Thenewest version (NTPv4) wasinitially documented onlybymeans ofits
implementation, butadetailed description cannowbefound inMills(2006).
TheBerkeley Algorithm
Inmany algorithms suchasNTP,thetimeserver ispassive. Other machines
periodically askitforthetime.Allitdoesisrespond totheirqueries. InBerkeley
UNIX, exactly theopposite approach istaken(Gusella andZatti, 1989). Herethe
timeserver (actually, atimedaemon) isactive, polling every machine fromtime
totimetoaskwhattimeitisthere. Based ontheanswers, itcomputes anaverage
timeandtellsalltheothermachines toadvance theirclocks tothenewtimeor
slowtheirclocks down untilsome specified reduction hasbeenachieved. This
method issuitable forasystem inwhich nomachine hasaWWV receiver. The
timedaemon's timemustbesetmanually bytheoperator periodically. Themeth-
odisillustrated inFig.6-7.
InFig.6-7(a), at3:00,thetimedaemon tellstheothermachines itstimeand
asksfortheirs. InFig.6-7(b), theyrespond withhowfarahead orbehind thetime
daemon theyare.Armed withthesenumbers, thetimedaemon computes theaver-
ageandtellseachmachine howtoadjust itsclock[seeFig.6-7(c)].
Notethatformany purposes, itissufficient thatallmachines agree onthe
same time. Itisnotessential thatthistimealsoagrees withtherealtimeas
announced ontheradio every hour. Ifinourexample ofFig.6-7thetime
daemon's clock would never bemanually calibrated, noharm isdoneprovided242 SYNCHRONIZA TION
Animportant advantage ofmoretraditional distributed systems isthatwecan
easily andefficiently deploy timeservers. Moreover, mostmachines cancontact
eachother, allowing forarelatively simple dissemination ofinformation. These
assumptions arenolonger validinmany wireless networks, notably sensor net-
works. Nodes areresource constrained, andmultihop routing isexpensive. Inad-
dition, itisoftenimportant tooptimize algorithms forenergy consumption. These
andotherobservations haveledtothedesign ofverydifferent clock synchroniza-
tionalgorithms forwireless networks. Inthefollowing, weconsider onespecific
solution. Sivrikaya andYener (2004) provide abriefoverview ofothersolutions.
Anextensive survey canbefound inSundararaman etal.(2005).
Reference broadcast synchronization (RBS) isaclock synchronization pro-
tocolthatisquitedifferent fromotherproposals (Elson etal.,2002). First, the
protocol doesnotassume thatthereisasingle nodewithanaccurate account of
theactual timeavailable. Instead ofaiming toprovide allnodes UTe time,itaims
atmerely internally synchronizing theclocks, justastheBerkeley algorithm does.
Second, thesolutions wehavediscussed sofararedesigned tobring thesender
andreceiver intosynch, essentially following atwo-way protocol. RBSdeviates
fromthispattern byletting onlythereceivers synchronize, keeping thesender out
oftheloop.
InRBS, asender broadcasts areference message thatwillallow itsreceivers
toadjust theirclocks. Akeyobservation isthatinasensor network thetimetoCHAP. 6
Figure 6-7.(a)Thetimedaemon asksalltheother machines fortheirclock
values. (b)Themachines answer. (c)Thetimedaemon tellseveryone howto
adjust theirclock.
noneoftheothernodes communicates withexternal computers. Everyone will
justhappily agree onacurrent time,without thatvalue having anyrelation with
reality.
Clock Synchronization inWireless Networks243
propagate asignal toothernodes isroughly constant, provided nomulti-hop rout-
ingisassumed. Propagation timeinthiscaseismeasured fromthemoment thata
message leaves thenetwork interface ofthesender. Asaconsequence, twoimpor-
tantsources forvariation inmessage transfer nolonger playaroleinestimating
delays: thetimespenttoconstruct amessage, andthetimespenttoaccess thenet-
work. Thisprinciple isshown inFig.6-8.
Figure 6-8.(a)Theusual critical pathindetermining network delays. (b)The
critical pathinthecaseofRBS.
Notethatinprotocols suchasNTP, atimestamp isadded tothemessage before it
ispassed onthenetwork interface. Furthermore, aswireless networks arebased
onacontention protocol, thereisgenerally nosaying howlongitwilltakebefore
amessage canactually betransmitted. These factors ofnondeterminism areelim-
inated inRBS. What remains isthedelivery timeatthereceiver, butthistime
varies considerably lessthanthenetwork-access time.
Theideaunderlying RBSissimple: when anodebroadcasts areference mes-
sagem,eachnodepsimply records thetimeTp,mthatitreceived m.NotethatTp.m
isreadfromp'slocalclock. Ignoring clock skew, twonodes pandqcanexchange
eachother's delivery timesinordertoestimate theirmutual, relative offset:
where Misthetotalnumber ofreference messages sent.Thisinformation isim-
portant: nodepwillknow thevalue ofq'sclock relative toitsownvalue. More-
over, ifitsimply stores these offsets, thereisnoneedtoadjust itsownclock,
which savesenergy.
Unfortunately, clocks candriftapart. Theeffect isthatsimply computing the
average offset asdoneabove willnotwork: thelastvalues sentaresimply lessCLOCKSYNCHRON~ATION SEC. 6.1244 SYNCHRONIZA TJON CHAP. 6
accurate thanthefirstones. Moreover, astimegoesby,theoffset willpresumably
increase. Elson etal.useaverysimple algorithm tocompensate forthis:instead
ofcomputing anaverage theyapply standard linear regression tocompute the
offset asafunction:
6.2LOGICAL CLOCKS
Sofar,wehaveassumed thatclock synchronization isnaturally related toreal
time. However, wehavealsoseenthatitmaybesufficient thatevery nodeagrees
onacurrent time, without thattimenecessarily being thesame astherealtime.
Wecangoonestepfurther. Forrunning make, forexample, itisadequate thattwo
nodes agree thatinput.o isoutdated byanewversion ofinput.c. Inthiscase,
keeping track ofeach other's events (such asaproducing anewversion of
input.c) iswhat matters. Forthese algorithms, itisconventional tospeak ofthe
clocks aslogical clocks.
Inaclassic paper, Lamport (1978) showed thatalthough clock synchroniza-
tionispossible, itneednotbeabsolute. Iftwoprocesses donotinteract, itisnot
necessary thattheirclocks besynchronized because thelackofsynchronization
would notbeobservable andthuscould notcause problems. Furthermore, he
pointed outthatwhat usually matters isnotthatallprocesses agree onexactly
what timeitis,butrather thattheyagree ontheorder inwhich events occur. In
themake example, whatcounts iswhether input.c isolder ornewer thaninput.o,
nottheirabsolute creation times.
Inthissection wewilldiscuss Lamport's algorithm, which synchronizes logi-
calclocks. Also, wediscuss anextension toLamport's approach, called vector
timestamps.
6.2.1 Lamport's Logical Clocks
Tosynchronize logical clocks, Lamport defined arelation called happens-be-
fore. Theexpression a~bisread "ahappens before b"andmeans thatall
processes agree thatfirstevent aoccurs, thenafterward, event boccurs. The
happens-before relation canbeobserved directly intwosituations:
1.Ifaandbareevents inthesame process, andaoccurs before b,then
a~bistrue.
2.Ifaistheevent ofamessage being sentbyoneprocess, andbisthe
event ofthemessage being received byanother process, thena~bTheconstants aandParecomputed fromthepairs(Tp,k,Tq,k). Thisnewform'will
allow amuch more accurate computation ofq'scurrent clock value bynodep,
andviceversa.SEC. 6.2 LOGICAL CLOCKS 245
isalsotrue.Amessage cannot bereceived before itissent,orevenat
thesame timeitissent,sinceittakes afinite, nonzero amount of
timetoarrive.
Happens-before isatransitive relation, soifa~band b~c,thena~c.If
twoevents, xandy,happen indifferent processes thatdonotexchange messages
(notevenindirectly viathirdparties), thenx~yisnottrue,butneither isy~x.
These events aresaidtobeconcurrent, which simply means thatnothing canbe
said(orneedbesaid)about whentheevents happened orwhich event happened
first.
What weneedisawayofmeasuring anotion oftimesuchthatforevery
event, a,wecanassign itatimevalue C(a)onwhich allprocesses agree. These
timevalues musthavetheproperty thatifa~b,thenC(a) <C(b). Torephrase
theconditions westated earlier, ifaandbaretwoevents within thesameprocess
andaoccurs before b,thenC(a) <C(b). Similarly, ifaisthesending ofames-
sagebyoneprocess andbisthereception ofthatmessage byanother process,
thenC(a)andC(b)mustbeassigned insuchawaythateveryone agrees onthe
values ofC(a)andC(b)withC(a)<C(b). Inaddition, theclock time,C,must
always goforward (increasing), never backward (decreasing). Corrections totime
canbemade byadding apositive value, never bysubtracting one.
Nowletuslookatthealgorithm Lamport proposed forassigning times to
events. Consider thethreeprocesses depicted inFig.6-9(a). Theprocesses runon
different machines, eachwithitsownclock, running atitsownspeed. Ascanbe
seenfromthefigure, whentheclockhasticked 6timesinprocess PI,ithasticked
8times inprocess Pzand10times inprocess P3'Eachclock runsataconstant
rate,buttheratesaredifferent duetodifferences inthecrystals.
Figure 6-9.(a)Three processes, eachwithitsownclock. Theclocks runatdif-
ferent rates. (b)Lamport's algorithm corrects theclocks.246 SYNCHRONIZA TlON CHAP. 6
Attime6,process P,sends message 111Itoprocess P2•Howlongthismes-
sagetakestoarrive depends onwhose clock youbelieve. Inanyevent, theclock
inprocess P2reads 16when itarrives. Ifthemessage carries thestarting time,6,
init,process P2willconclude thatittook10tickstomake thejourney. Thisvalue
iscertainly possible. According tothisreasoning, message m2fromP2toRtakes
16ticks,againaplausible value.
Nowconsider message m3-Itleaves process P3at60andarrives atP2at'56.
Similarly, message m4 fromP2toPIleaves at64andarrives at54.These values
areclearly impossible. Itisthissituation thatmustbeprevented.
Lamport's solution follows directly fromthehappens-before relation. Since
m3leftat60,itmustarrive at61orlater.Therefore, eachmessage carries the
sending timeaccording tothesender's clock. When amessage arrives andthere-
ceiver's clock shows avalue priortothetimethemessage wassent,thereceiver
fastforwards itsclock tobeonemorethanthesending time.InFig.6-9(b) wesee
that1113 nowarrives at61.Similarly, m4 arrives at70.
Toprepare forourdiscussion onvector clocks, letusformulate thisprocedure
moreprecisely. Atthispoint, itisimportant todistinguish threedifferent layers of
software aswealready encountered inChap. 1:thenetwork, amiddleware layer,
andanapplication layer, asshown inFig.6-10. What follows istypically partof
themiddleware layer.
Figure 6-10. Thepositioning ofLamport's logical clocks indistributed systems.
Toimplement Lamport's logical clocks, eachprocess Pimaintains alocalcounter
G.These counters areupdated asfollows steps(Raynal andSinghal, 1996):
1.Before executing anevent (i.e.,sending amessage overthenetwork,
delivering amessage toanapplication, orsomeotherinternal event),
Piexecutes Gf-G+1.
2.When process Pisends amessage mtoPj'itsets11l'S timestamp
ts(m)equal toGafterhaving executed theprevious step.SEC. 6.2 LOGICAL CLOCKS 247
3.Upon thereceipt ofamessage m,process ljadjusts itsownlocal
counter as0f-max{0,ts(m)},afterwhich itthenexecutes the
firststepanddelivers themessage totheapplication.
Insomesituations, anadditional requirement isdesirable: notwoevents ever
occur atexactly thesametime.Toachieve thisgoal,wecanattach thenumber of
theprocess inwhich theevent occurs tothelow-order endofthetime,separated
byadecimal point. Forexample, anevent attime40atprocess Piwillbetime-
stamped with40.i.
Notethatbyassigning theevent timeC(a) f-q(a) ifahappened atprocess
Piattimeq(a), wehaveadistributed implementation oftheglobal timevaluewe
wereinitially seeking for.
Example: Totally Ordered Multicasting
Asanapplication ofLamport's logical clocks, consider thesituation inwhich
adatabase hasbeenreplicated across several sites.For'example, toimprove query
performance, abankmayplace copies ofanaccount database intwodifferent
cities, sayNewYork andSanFrancisco. Aquery isalways forwarded tothe
nearest copy. Theprice forafastresponse toaquery ispartly paidinhigher
update costs, because eachupdate operation mustbecarried outateachreplica.
Infact,thereisamorestringent requirement withrespect toupdates. Assume
acustomer inSanFrancisco wants toadd$100tohisaccount, which currently
contains $1,000. Atthesame time,abankemployee inNewYorkinitiates an
update bywhich thecustomer's account istobeincreased with1percent interest.
Bothupdates should becarried outatbothcopies ofthedatabase. However, due
tocommunication delays intheunderlying network, theupdates mayarrive inthe
orderasshown inFig.6-11.
Figure 6-11. Updating areplicated database andleaving itinaninconsistent
state.
Thecustomer's update operation isperformed inSanFrancisco before the
interest update. Incontrast, thecopyoftheaccount intheNewYorkreplica is248 SYNCHRONIZA nON CHAP. 6
firstupdated withthe1percent interest, andafterthatwiththe$100deposit. Con-
sequently, theSanFrancisco database willrecord atotalamount of$1,] 11,
whereas theNewYorkdatabase records $1,110.
Theproblem thatwearefaced withisthatthetwoupdate operations should
havebeenperformed inthesameorder ateachcopy. Although itmakes adiffer-
encewhether thedeposit isprocessed before theinterest update ortheother, way
around, which orderisfollowed isnotimportant fromaconsistency pointofview.
Theimportant issueisthatbothcopies should beexactly thesame. Ingeneral,
situations suchastheserequire atotally-ordered multicast, thatis,amulticast
operation bywhich allmessages aredelivered inthesameordertoeachreceiver.
Lamport's logical clocks canbeusedtoimplement totally-ordered multicastsina
completely distributed fashion.
Consider agroup ofprocesses multicasting messages toeachother. Eachmes-
sageisalways timestamped withthecurrent (logical) timeofitssender. When a
message ismulticast, itisconceptually alsosenttothesender. Inaddition, we
assume thatmessages fromthesame sender arereceived intheorder theywere
sent,andthatnomessages arelost.
When aprocess receives amessage, itisputintoalocalqueue, ordered ac-
cording toitstimestamp. Thereceiver multicasts anacknowledgment totheother
processes. Notethatifwefollow Lamport's algorithm foradjusting localclocks,
thetimestamp ofthereceived message islower thanthetimestamp oftheack-
nowledgment. Theinteresting aspect ofthisapproach isthatallprocesses will
eventually havethesamecopyofthelocalqueue (provided nomessages arere-
moved).
Aprocess candeliver aqueued message totheapplication itisrunning only
whenthatmessage isattheheadofthequeue andhasbeenacknowledged byeach
otherprocess. Atthatpoint, themessage isremoved fromthequeue andhanded
overtotheapplication; theassociated acknowledgments cansimply beremoved.
Because eachprocess hasthesamecopyofthequeue, allmessages aredelivered
inthesameordereverywhere. Inotherwords, wehaveestablished totally-ordered
multicasting.
Asweshallseeinlaterchapters. totally-ordered multicasting isanimportant
vehicle forreplicated services where thereplicas arekeptconsistent byletting
themexecute thesameoperations inthesameorder everywhere. Asthereplicas
essentially follow thesametransitions inthesamefinite statemachine, itisalso
known asstatemachine replication (Schneider, 1990).
6.2.2 Vector Clocks
Lamport's logical clocks leadtoasituation where allevents inadistributed
system aretotally ordered withtheproperty thatifeventahappened before event
b,thenawillalsobepositioned inthatordering before b,thatis,C(a)<C(b).SEC. 6.2 LOGICAL CLOCKS 249
However, withLamport clocks, nothing canbesaidabout therelationship be-
tween twoevents aandbbymerely comparing theirtimevalues C(a) andC(b),
respectively. Inother words, ifC(a) <C(b), thenthisdoesnotnecessarily imply
thataindeed happened before b.Something moreisneeded forthat.
Toexplain, consider themessages assentbythethree processes shown in
Fig.6-12. Denote byI'snd(mi)thelogical timeatwhich message m,wassent,and
likewise, byT,.cv(mi) thetimeofitsreceipt. Byconstruction, weknow thatfor
eachmessage I'snd(mi) <T,.cy(mi). Butwhat canweconclude ingeneral from
T,.cv(mi)<I'snd(mj)?
Figure 6-12. Concurrent message transmission using logical clocks.
Inthecase forwhich mi=m 1andmj=m 3,weknow thatthese values
correspond toevents thattookplace atprocess Pz,meaning thatm-;wasindeed
sentafterthereceipt ofmessage mi. Thismayindicate thatthesending ofmes-
sagem-;depended onwhatwasreceived through message mi.However, wealso
know thatT,.CY(m1)<I'snd (mz).However, thesending ofmzhasnothing todo
withthereceipt ofmi.
Theproblem isthatLamport clocks donotcapture causality. Causality can
becaptured bymeans ofvectorclocks. Avector clock VC(a)assigned toan
event ahastheproperty thatifVC(a)<VC(b)forsome event b,thenevent ais
known tocausally precede event b.Vector clocks areconstructed byletting each
process P,maintain avector VCiwiththefollowing twoproperties:
1.VCj[i]isthenumber ofevents thathave occurred sofaratPi.In
other words, VCj[i]isthelocallogical clock atprocess Pi.
2.IfVCjU]=kthenPiknows thatkevents haveoccurred atPj.Itis
thusPi'Sknowledge ofthelocaltimeatPj.
Thefirstproperty ismaintained byincrementing VCj[i]attheoccurrence ofeach
newevent thathappens atprocess Pi.Thesecond property ismaintained by250 SYNCHRONIZATION CHAP.6
piggybacking vectors along withmessages thataresent.Inparticular, thefollow-
ingstepsareperformed:
1.Before executing anevent (i.e.,sending amessage overthenetwork,
delivering amessage toanapplication, orsomeotherinternal event),
Piexecutes VCj[I]~VCj[i]+1.
2.When process Pisends amessage mtolj,itsetsm's(vector) time-
stamp ts(m)equaltoVCjafterhaving executed theprevious step.
3.Upon thereceipt ofamessage m,process ljadjusts itsownvector by
setting VCj[k]~max{VCj [k],ts(m)[k]} foreachk,afterwhich it
executes thefirststepanddelivers themessage totheapplication.
Notethatifanevent ahastimestamp ts(a), thents(a)[I ]-1denotes thenumber
ofevents processed atP;thatcausally precede a.Asaconsequence, when lj
receives amessage fromPiwithtimestamp ts(m), itknows about thenumber of
events thathaveoccurred atPithatcausally preceded thesending ofm.More im-
portant, however, isthatljisalsotoldhowmany events atother processes have
taken place before Pisentmessage m.Inotherwords, timestamp ts(m) tellsthe
receiver howmany events inotherprocesses havepreceded thesending ofm,and
onwhich mmaycausally depend.
Enforcing Causal Communication
Using vector clocks, itisnowpossible toensure thatamessage isdelivered
onlyifallmessages thatcausally precede ithavealsobeenreceived aswell.To
enable suchascheme, wewillassume thatmessages aremulticast within agroup
ofprocesses. Notethatthiscausally-ordered multicasting isweaker thanthe
totally-ordered multicasting wediscussed earlier. Specifically, iftwomessages
arenotinanywayrelated toeachother, wedonotcareinwhich order theyare
delivered toapplications. Theymayevenbedelivered indifferent orderatdiffer-
entlocations.
Furthermore, weassume thatclocks areonlyadjusted when sending and
receiving messages. Inparticular, uponsending amessage, process P;willonly
increment VCj[i]by1.When itreceives amessage mwithtimestamp ts(m), it
onlyadjusts VCj[k]tomax{VCj [k],ts(111)[k]} foreachk.
Nowsuppose thatljreceives amessage mfromPiwith(vector) timestamp
ts(m). Thedelivery ofthemessage totheapplication layerwillthenbedelayed
untilthefollowing twoconditions aremet:SEC. 6.2 LOGICAL CLOCKS 251
Thefirstcondition states thatmisthenextmessage thatljwasexpecting from
process Pi'Thesecond condition states thatljhasseenallthemessages thathave
beenseenbyPiwhen itsentmessage m.Notethatthere isnoneedforprocess Pj
todelay thedelivery ofitsownmessages.
Asanexample, consider three processes Po,PbandP2asshown inFig.6-
13.Atlocal time(1,0,0), PIsends message mtotheother twoprocesses. After
itsreceipt byPI,thelatter decides tosendm», which arrives atP2sooner thanm.
Atthatpoint, thedelivery ofm»isdelayed byP2untilmhasbeenreceived and
delivered toP2'sapplication layer.
Figure 6-13. Enforcing causal communication.
ANote onOrdered Message Delivery
Some middleware systems, notably ISISanditssuccessor Horus (Birman and
vanRenesse, 1994), provide support fortotally-ordered andcausally-ordered (reli-
able) multicasting. There hasbeensome controversy whether suchsupport should
beprovided aspartofthemessage-communication layer, orwhether applications
should handle ordering (see,e.g.,Cheriton andSkeen, 1993; andBirman, 1994).
Matters havenotbeensettled, butmore important isthatthearguments stillhold
today.
There aretwomain problems withletting themiddle ware dealwithmessage
ordering. First, because themiddle ware cannot tellwhatamessage actually con-
tains, onlypotential causality iscaptured. Forexample, twomessages from the
same sender thatarecompletely independent willalways bemarked ascausally
related bythemiddleware layer. Thisapproach isoverly restrictive andmaylead
toefficiency problems.
Asecond problem isthatnotallcausality maybecaptured. Consider anelec-
tronic bulletin board. Suppose Alice posts anarticle. Ifshethenphones Bobtel-
lingabout whatshejustwrote, Bobmaypostanother article asareaction without
having seenAlice's posting ontheboard. Inother words, there isacausality be-
tween Bob's posting andthatofAlice duetoexternal communication. This
causality isnotcaptured bythebulletin board system.252 SYNCHRONIZA nON CHAP. 6
Inessence, ordering issues, likemany otherapplication-specific communica-
tionissues, canbeadequately solved bylooking attheapplication forwhich com-
munication istaking place. Thisisalsoknown astheend-to-end argument in
systems design (Saltzer etaI.,1984). Adrawback ofhaving onlyapplication-
levelsolutions isthatadeveloper isforced toconcentrate onissues thatdonotim-
mediately relate tothecorefunctionality oftheapplication. Forexample, ordering
maynotbethemostimportant problem when developing amessaging system
suchasanelectronic bulletin board. Inthatcase,having anunderlying communi-
cation layerhandle ordering maytumouttobeconvenient. Wewillcome across
theend-to-end argument anumber oftimes, notably when dealing withsecurity in
distributed systems.
6.3MUTUAL EXCLUSION
Fundamental todistributed systems istheconcurrency andcollaboration
among multiple processes. Inmany cases, thisalsomeans thatprocesses willneed
tosimultaneously access thesameresources. Toprevent thatsuchconcurrent ac-
cesses corrupt theresource, ormake itinconsistent, solutions areneeded togrant
mutual exclusive access byprocesses. Inthissection, wetakealookatsome of
themoreimportant distributed algorithms thathavebeenproposed. Arecent sur-
veyofdistributed algorithms formutual exclusion isprovided bySaxena andRai
(2003). Older, butstillrelevant isVelazquez (1993).
6.3.1 Overview
Distributed mutual exclusion algorithms canbeclassified intotwodifferent
categories. Intoken-based solutions mutual exclusion isachieved bypassing a
special message between theprocesses, known asatoken. There isonlyone
token available andwhoeverhasthattoken isallowed toaccess theshared re-
source. When finished, thetoken ispassed ontoanextprocess. Ifaprocess hav-
ingthetoken isnotinterested inaccessing theresource, itsimply passes iton.
Token-based solutions haveafewimportant properties. First, depending on
thehowtheprocesses areorganized, theycanfairlyeasily ensure thatevery proc-
esswillgetachance ataccessing theresource. Inotherwords, theyavoid starva-
tion. Second, deadlocks bywhich several processes arewaiting foreachotherto
proceed, caneasily beavoided, contributing totheirsimplicity. Unfortunately, the
maindrawback oftoken-based solutions isarather serious one:when thetoken is
lost(e.g.,because theprocess holding itcrashed), anintricate distributed proce-
dureneeds tobestarted toensure thatanewtoken iscreated, butabove all,thatit
isalsotheonlytoken.
Asanalternative, many distributed mutual exclusion algorithms follow a
permission-based approach. Inthiscase.aprocess wanting toaccess there-SEC. 6.3 MUTUAL EXCLUSION 253
source firstrequires thepermission ofotherprocesses. There aremany different
waystoward granting suchapermission andinthesections thatfollow wewill
consider afewofthem.
6.3.2ACentralized Algorithm
Themoststraightforward waytoachieve mutual. exclusion inadistributed
system istosimulate howitisdoneinaone-processor system. Oneprocess is
elected asthecoordinator. Whenever aprocess wants toaccess ashared resource,
itsendsarequest message tothecoordinator stating which resource itwants toac-
cessandasking forpermission. Ifnootherprocess iscurrently accessing thatre-
source, thecoordinator sends back areply granting permission, asshown in
Fig.6-14(a). When thereplyarrives, therequesting process cangoahead.
Figure 6-14. (a)Process 1asksthecoordinator forpermission toaccess a
shared resource. Permission isgranted. (b)Process 2thenaskspermission toac-
cessthesame resource. Thecoordinator doesnotreply. (c)When process 1
releases theresource, ittellsthecoordinator, which thenreplies to2.
Nowsuppose thatanother process, 2inFig.6-14(b), asksforpermission to
access theresource. Thecoordinator knows thatadifferent process isalready at
theresource, soitcannot grantpermission. Theexact method usedtodenyper-
mission issystem dependent. InFig.6-14(b), thecoordinator justrefrains from
replying, thusblocking process 2,which iswaiting forareply. Alternatively, it
could sendareplysaying "permission denied." Either way,itqueues therequest
from2forthetimebeingandwaitsformoremessages.
When process 1isfinished withtheresource, itsends amessage tothecoordi-
nator releasing itsexclusive access, asshown inFig.6-14(c). Thecoordinator
takes thefirstitemoffthequeue ofdeferred requests andsends thatprocess a
grantmessage. Iftheprocess wasstillblocked (i.e.,thisisthefirstmessage toit),
itunblocks andaccesses theresource. Ifanexplicit message hasalready beensent
denying permission, theprocess willhavetopollforincoming traffic orblock
later.Either way,whenitseesthegrant, itcangoahead aswell.
Itiseasytoseethatthealgorithm guarantees mutual exclusion: thecoordina-
toronlyletsoneprocess atatimetotheresource. Itisalsofair,sincerequests are254 CHAP. 6 SYNCHRONIZATION
granted intheorderinwhich theyarereceived. Noprocess everwaitsforever (no
starvation). Thescheme iseasytoimplement, too,andrequires onlythreemes-
sagesperuseofresource (request, grant, release). It'ssimplicity makes anattrac-
tivesolution formanypractical situations.
Thecentralized approach alsohasshortcomings. Thecoordinator isasingle
pointoffailure, soifitcrashes, theentire system maygodown. Ifprocesses nor-
mally block aftermaking arequest, theycannot distinguish adeadcoordinator
from"permission denied" sinceinbothcases nomessage comes back. Inaddi-
tion,inalargesystem, asingle coordinator canbecome aperformance bottleneck.
Nevertheless, thebenefits coming fromitssimplicity outweigh inmany cases the
potential drawbacks. Moreover, distributed solutions arenotnecessarily better, as
ournextexample illustrates.
6.3.3ADecentralized Algorithm
Having asingle coordinator isoftenapoorapproach. Letustakealookat
fullydecentralized solution. Linetal.(2004) propose touseavoting algorithm
thatcanbeexecuted usingaDHT-based system. Inessence, theirsolution extends
thecentral coordinator inthefollowing way.Eachresource isassumed toberepli-
catedntimes. Every replica hasitsowncoordinator forcontrolling theaccess by
concurrent processes.
However, whenever aprocess wants toaccess theresource, itwillsimply
needtogetamajority votefrom111>nl2coordinators. Unlike inthecentralized
scheme discussed before, weassume thatwhen acoordinator doesnotgiveper-
mission toaccess aresource (which itwilldowhen ithadgranted permission to
another process), itwilltelltherequester.
Thisscheme essentially makes theoriginal centralized solution lessvulner-
abletofailures ofasingle coordinator. Theassumption isthatwhen acoordinator
crashes, itrecovers quickly butwillhaveforgotten anyvoteitgavebefore it
crashed. Another wayofviewing thisisthatacoordinator resets itselfatarbitrary
moments. Theriskthatwearetaking isthataresetwillmake thecoordinator for-
getthatithadpreviously granted permission tosome process toaccess there-
source. Asaconsequence, itmayincorrectly grantthispermission again toanoth-
erprocess afteritsrecovery.
Letpbetheprobability thatacoordinator resets during atimeinterval !:J.t.The
probability P[k]thatkoutofmcoordinators resetduring thesameinterval isthen
Given thatatleast2m-ncoordinators needtoresetinorder toviolate the
correctness ofthevoting mechanism, theprobability thatsuchaviolation occurs
isthen"'II P[k].Togiveanimpression ofwhatthiscould mean, assumek.Jk=2m-1ISEC. 6.3 MUTUAL EXCLUSION 255
thatwearedealing withaDHT-based system inwhich eachnodeparticipates for
about 3hours inarow.LetMbe10seconds, which isconsidered tobeaconser-
vative value forasingle process towanttoaccess ashared resource. (Different
mechanisms areneeded forverylongallocations.) Withn=32andm=0.75n, the
probability ofviolating correctness islessthan10-40. Thisprobability issurely
smaller thantheavailability ofanyresource.
Toimplement thisscheme, Linetal.(2004) useaDHT-based system in
which aresource isreplicated ntimes. Assume thattheresource isknown under
itsunique name mame. Wecanthenassume thatthei-threplica isnamed
rname-i which isthenusedtocompute aunique keyusingaknown hashfunction.
Asaconsequence, everyprocess cangenerate thenkeysgiven aresource's name,
andsubsequently lookup eachnoderesponsible forareplica (andcontrolling ac-
cesstothatreplica).
Ifpermission toaccess theresource isdenied (i.e.,aprocess getslessthanm
votes), itisassumed thatitwillbackoffforarandomly-chosen time,andmake a
nextattempt later.Theproblem withthisscheme isthatifmany nodes wanttoac-
cessthesame resource, itturns outthattheutilization rapidly drops. Inother
words, therearesomany nodes competing togetaccess thateventually nooneis
abletogetenough votes leaving theresource unused. Asolution tosolve this
problem canbefound inLinetal.(2004).
6.3.4ADistributed Algorithm
Tomany, having aprobabilistic allycorrect algorithm isjustnotgoodenough.
Soresearchers havelooked fordeterministic distributed mutual exclusion algo-
rithms. Lamport's 1978paper onclock synchronization presented thefirstone.
Ricart andAgrawala (1981) made itmore efficient. Inthissection wewill
describe theirmethod.
Ricart andAgrawala's algorithm requires thattherebeatotalordering ofall
events inthesystem. Thatis,foranypairofevents, suchasmessages, itmustbe
unambiguous which oneactually happened first.Lamport's algorithm presented in
Sec.6.2.1isonewaytoachieve thisordering andcanbeusedtoprovide time-
stamps fordistributed mutual exclusion.
Thealgorithm works asfollows. When aprocess wants toaccess ashared re-
source, itbuilds amessage containing thename oftheresource, itsprocess num-
ber,andthecurrent (logical) time.Itthensends themessage toallother proc-
esses, conceptually including itself. Thesending ofmessages isassumed tobe
reliable; thatis,nomessage islost.
When aprocess receives arequest message fromanother process, theaction it
takesdepends onitsownstatewithrespect totheresource named inthemessage.
Three different caseshavetobeclearly distinguished:256 SYNCHRONIZATION CHAP. 6
1.Ifthereceiver isnotaccessing theresource anddoesnotwanttoac-
cessit,itsendsbackanOKmessage tothesender.
2.Ifthereceiver already hasaccess totheresource, itsimply doesnot
reply. Instead, itqueues therequest.
3.Ifthereceiver wants toaccess theresource aswellbuthasnotyet
doneso,itcompares thetimestamp oftheincoming message withme.
onecontained inthemessage thatithassenteveryone. Thelowest
onewins. Iftheincoming message hasalower timestamp, there-
ceiver sends backanOKmessage. Ifitsownmessage hasalower
timestamp, thereceiver queues theincoming request andsends noth-
ing.
After sending outrequests asking permission, aprocess sitsbackandwaits
untileveryone elsehasgiven permission. Assoonasallthepermissions arein,it
maygoahead. When itisfinished, itsends OKmessages toallprocesses onits
queue anddeletes themallfromthequeue.
Letustrytounderstand whythealgorithm works. Ifthereisnoconflict, it
clearly works. However, suppose thattwoprocesses trytosimultaneously access
theresource, asshown inFig.6-15(a).
Figure 6-15. (a)Twoprocesses want toaccess ashared resource atthesame
moment. (b)Process 0hasthelowest timestamp. soitwins. (c)When process 0
isdone, itsends anOKalso,so2cannowgoahead.
Process 0sends everyone arequest withtimestamp 8,while atthesame time,
process 2sends everyone arequest withtimestamp 12.Process 1isnotinterested
intheresource, soitsends OKtobothsenders. Processes 0and2bothseethe
conflict andcompare timestamps. Process 2seesthatithaslost,soitgrants per-
mission to0bysending OK. Process 0nowqueues therequest from2forlater
processing andaccess theresource, asshown inFig.6-15(b). When itisfinished,
itremoves therequest from2fromitsqueue andsends anOKmessage toprocess
2,allowing thelattertogoahead, asshown inFig.6-15(c). Thealgorithm worksSEC. 6.3 MUTUAL EXCLUSION 257
because inthecaseofaconflict, thelowest timestamp winsandeveryone agrees
ontheordering ofthetimestamps.
Notethatthesituation inFig.6-15would havebeenessentially different if
process 2hadsentitsmessage earlier intimesothatprocess 0hadgotten itand
granted permission before making itsownrequest. Inthiscase,2would have
noticed thatititselfhadalready access totheresource atthetimeoftherequest,
andqueued itinstead ofsending areply.
Aswiththecentralized algorithm discussed above, mutual exclusion is
guaranteed without deadlock orstarvation. Thenumber ofmessages required per
entryisnow2(n-1),where thetotalnumber ofprocesses inthesystem isn.Best
ofall,nosingle pointoffailure exists.
Unfortunately, thesingle point offailure hasbeenreplaced bynpoints of
failure. Ifanyprocess crashes, itwillfailtorespond torequests. Thissilence will
beinterpreted (incorrectly) asdenial ofpermission, thusblocking allsubsequent
attempts byallprocesses toenterallcritical regions. Since theprobability ofone
ofthenprocesses failing isatleastntimesaslargeasasingle coordinator failing,
wehavemanaged toreplace apooralgorithm withonethatismorethanntimes
worse andrequires muchmorenetwork traffic aswell.
Thealgorithm canbepatched upbythesametrickthatweproposed earlier.
When arequest comes in,thereceiver always sends areply, either granting or
denying permission. Whenever either arequest orareplyislost,thesender times
outandkeeps trying untileither areplycomes backorthesender concludes that
thedestination isdead.Afterarequest isdenied, thesender should block waiting
forasubsequent OKmessage.
Another problem withthisalgorithm isthateither amulticast communication
primitive mustbeused.oreachprocess mustmaintain thegroup membership list
itself, including processes entering thegroup, leaving thegroup, andcrashing.
Themethod works bestwithsmall groups ofprocesses thatnever change their
group memberships.
Finally, recall thatoneoftheproblems withthecentralized algorithm isthat
making ithandle allrequests canleadtoabottleneck. Inthedistributed algorithm,
allprocesses areinvolved inalldecisions concerning accessing theshared re-
source. Ifoneprocess isunable tohandle theload,itisunlikely thatforcing
everyone todoexactly thesamethinginparallel isgoing tohelpmuch.
Various minor improvements arepossible tothisalgorithm. Forexample, get-
tingpermission fromeveryone isreally overkill. Allthatisneeded isamethod to
prevent twoprocesses fromaccessing theresource atthesametime.Thealgo-
rithm canbemodified tograntpermission whenithascollected permission froma
simple majority oftheotherprocesses, rather thanfromallofthem. Ofcourse, in
thisvariation, afteraprocess hasgranted permission tooneprocess, itcannot
grantthesamepermission toanother process untilthefirstonehasfinished.
Nevertheless, thisalgorithm isslower, more complicated, moreexpensive,
andlessrobust thattheoriginal centralized one.Whybother studying itunder258 SYNCHRONIZATION CHAP. 6
theseconditions? Foronething, itshows thatadistributed algorithm isatleast
possible, something thatwasnotobvious when westarted. Also, bypointing out
theshortcomings, wemaystimulate future theoreticians totrytoproduce algo-
rithms thatareactually useful. Finally, likeeating spinach andlearning Latin in
highschool, somethings aresaidtobegoodforyouinsomeabstract way.Itmay
takesometimetodiscover exactly what.
6.3.5 AToken RingAlgorithm
Acompletely different approach todeterministically achieving mutual exclu-
sioninadistributed system isillustrated inFig.6-16. Herewehaveabusnet-
work, asshown inFig.6-16(a), (e.g.,Ethernet), withnoinherent ordering ofthe
processes. Insoftware, alogical ringisconstructed inwhich eachprocess is
assigned aposition inthering,asshown inFig.6-16(b). Theringpositions may
beallocated innumerical orderofnetwork addresses orsomeothermeans. Itdoes
notmatter whattheordering is.Allthatmatters isthateachprocess knows whois
nextinlineafteritself.
Figure 6-16. (a)Anunordered group ofprocesses onanetwork. (b)Alogical
ringconstructed insoftware.
When theringisinitialized, process 0isgiven atoken. Thetoken circulates
around thering.Itispassed fromprocess ktoprocess k+1(modulo theringsize)
inpoint-to-point messages. When aprocess acquires thetoken fromitsneighbor,
itchecks toseeifitneeds toaccess theshared resource. Ifso,theprocess goes
ahead, doesalltheworkitneeds to,andreleases theresources. After ithasfin-
ished, itpasses thetoken along thering.Itisnotpermitted toimmediately enter
theresource againusingthesametoken.
Ifaprocess ishanded thetoken byitsneighbor andisnotinterested inthere-
source, itjustpasses thetoken along. Asaconsequence, when noprocesses need
theresource, thetokenjustcirculates athighspeed around thering.
Thecorrectness ofthisalgorithm iseasytosee.Onlyoneprocess hasthe
token atanyinstant, soonlyoneprocess canactually gettotheresource. SinceSEC. 6.3 MUTUAL EXCLUSION 259
thetoken circulates among theprocesses inawell-defined order, starvation can-
notoccur. Onceaprocess decides itwants tohaveaccess totheresource, atworst
itwillhavetowaitforevery otherprocess tousetheresource.
Asusual, thisalgorithm hasproblems too.Ifthetoken iseverlost,itmustbe
regenerated. Infact,detecting thatitislostisdifficult, sincetheamount oftime
between successive appearances ofthetoken onthenetwork isunbounded. The
factthatthetoken hasnotbeenspotted foranhourdoesnotmeanthatithasbeen
lost;somebody maystillbeusingit.
Thealgorithm alsorunsintotrouble ifaprocess crashes, butrecovery is
easier thanintheothercases. Ifwerequire aprocess receiving thetoken toac-
knowledge receipt, adeadprocess willbedetected whenitsneighbor triestogive
itthetoken andfails.Atthatpointthedeadprocess canberemoved fromthe
group, andthetoken holder canthrow thetoken overtheheadofthedeadprocess
tothenextmember down theline,ortheoneafterthat,ifnecessary. Ofcourse,
doing sorequires thateveryone maintain thecurrent ringconfiguration.
6.3.6 AComparison oftheFourAlgorithms
Abriefcomparison ofthefourmutual exclusion algorithms wehavelooked at
isinstructive. InFig.6-17wehavelistedthealgorithms andthreekeyproperties:
thenumber ofmessages required foraprocess toaccess andrelease ashared re-
source, thedelay before access canoccur (assuming messages arepassed sequen-
tiallyoveranetwork), andsomeproblems associated witheachalgorithm.
Figure 6-17. Acomparison ofthreemutual exclusion algorithms.
Thecentralized algorithm issimplest andalsomostefficient. Itrequires only
threemessages toenterandleaveacritical region: arequest, agranttoenter, and
arelease toexit.Inthedecentralized case,weseethatthesemessages needtobe
carried outforeachofthemcoordinators, butnowitispossible thatseveral
attempts needtobemade(forwhich weintroduce thevariable k).Thedistributed
algorithm requires n-1request messages, onetoeachoftheotherprocesses, and
anadditional n-1grantmessages, foratotalof2(n- 1).(Weassume thatonly
point-to-point communication channels areused.) Withthetoken ringalgorithm,
thenumber isvariable. Ifevery process constantly wants toenteracritical region.260 SYNCHRONIZATION CHAP. 6
theneachtoken passwillresult inoneentryandexit,foranaverage ofonemes-
sagepercritical region entered. Attheotherextreme, thetoken maysometimes
circulate forhours without anyone being interested init.Inthiscase,thenumber
ofmessages perentryintoacritical region isunbounded.
Thedelay fromthemoment aprocess needs toenteracritical region untilits
actual entryalsovaries forthethreealgorithms. When thetimeusingaresource is
short, thedominant factor inthedelayistheactual mechanism foraccessing are-
source. When resources areusedforalongtimeperiod, thedominant factor is
waiting foreveryone elsetotaketheirtum.InFig.6-17weshowtheformer case.
Ittakesonlytwomessage times toenteracritical region inthecentralized case,
but3mktimes forthedecentralized case,where kisthenumber ofattempts that
needtobemade. Assuming thatmessages aresentoneaftertheother, 2(n-1)
message times areneeded inthedistributed case.Forthetoken ring,thetime
varies from0(token justarrived) ton-1(token justdeparted).
Finally, allalgorithms except thedecentralized onesuffer badly intheevent
ofcrashes. Special measures andadditional complexity mustbeintroduced to
avoid having acrashbringdown theentire system. Itisironic thatthedistributed
algorithms areevenmoresensitive tocrashes thanthecentralized one.Inasystem
thatisdesigned tobefaulttolerant, noneofthesewould besuitable, butifcrashes
areveryinfrequent, theymight do.Thedecentralized algorithm islesssensitive to
crashes, butprocesses maysuffer fromstarvation andspecial measures areneeded
toguarantee efficiency.
6.4GLOBAL POSITIONING OFNODES
When thenumber ofnodes inadistributed system grows, itbecomes increas-
inglydifficult foranynodetokeeptrackoftheothers. Suchknowledge maybe
important forexecuting distributed algorithms suchasrouting, multicasting, data
placement, searching, andsoon.Wehavealready seendifferent examples in
which largecollections ofnodes areorganized intospecific topologies thatfacili-
tatetheefficient execution ofsuchalgorithms. Inthissection, wetakealookat
another organization thatisrelated totiming issues.
Ingeometric overlay networks eachnode isgiven aposition inan111-
dimensional geometric space, suchthatthedistance between twonodes inthat
space reflects areal-world performance metric. Thesimplest, andmostapplied
example, iswhere distance corresponds tointernode latency. Inother words.
given twonodes PandQ,thenthedistance d(P,Q) reflects howlongitwould
takeforamessage totravel fromPtoQandviceversa.
There aremany applications ofgeometric overlay networks. Consider the
situation where aWebsiteatserver 0hasbeenreplicated tomultiple servers
S}.""Sk ontheInternet. When aclient Crequests apagefrom0,thelatter may
decide toredirect thatrequest totheserver closest toC,thatis,theonethatwillSEC. 6.4 GLOBAL POSITIONING OFNODES 261
givethebestresponse time.Ifthegeometric location ofCisknown, aswellas
those ofeachreplica server, 0canthensimply pickthatserver S,forwhich
d(C,SJ isminimal. Notethatsuchaselection requires onlylocalprocessing atO.
Inotherwords, thereis,forexample, noneedtosample allthelatencies between
Candeachofthereplica servers.
Another example, which wewillworkoutindetail inthefollowing chapter, is
optimal replica placement. Consider againaWebsitethathasgathered theposi-
tionsofitsclients. Ifthesiteweretoreplicate itscontent toKservers, itcancom-
putetheKbestpositions where toplacereplicas suchthattheaverage client-to-
replica response timeisminimal. Performing suchcomputations isalmost trivially
feasible ifclients andservers havegeometric positions thatreflect internode laten-
cies.
Asalastexample, consider position-based routing (Araujo andRodrigues,
2005; andStojmenovic, 2002). Insuchschemes, amessage isforwarded toits
destination using onlypositioning information. Forexample, anaive routing al-
gorithm toleteachnodeforward amessage totheneighbor closest tothedestina-
tion.Although itcanbeeasily shown thatthisspecific algorithm neednotcon-
verge, itillustrates thatonlylocalinformation isusedtotakeadecision. There is
noneedtopropagate linkinformation orsuchtoallnodes inthenetwork, asisthe
casewithconventional routing algorithms.
Figure 6-18. Computing anode's position inatwo-dimensional space.
Theoretically, positioning anodeinanm-dimensional geometric space re-
quires m+1distance measures tonodes withknown positions. Thiscanbeeasily
seenbyconsidering thecasem=2,asshown inFig.6-18. Assuming thatnodeP
wants tocompute itsownposition, itcontacts threeothernodes withknown posi-
tionsandmeasures itsdistance toeachofthem. Contacting onlyonenodewould262 SYNCHRONIZA nON CHAP. 6
Assaid,d,generally corresponds tomeasuring thelatency between Pandthe
nodeat(Xj,yJ. Thislatency canbeestimated asbeing halftheround-trip delay,
butitshould beclearthatitsvaluewillbedifferent overtime.Theeffect isadif-
ferent positioning whenever Pwould wanttorecompute itsposition. Moreover, if
othernodes would useP'scurrent position tocompute theirowncoordinates, then
itshould beclearthattheerrorinpositioning Pwillaffect theaccuracy ofthe
positioning ofothernodes.
Moreover, itshould alsobeclearthatmeasured distances bydifferent nodes
willgenerally notevenbeconsistent. Forexample, assume wearecomputing dis-
tances inaone-dimensional space asshown inFig.6-19. Inthisexample, wesee
thatalthough Rmeasures itsdistance toQas2.0,andd(P,Q)hasbeenmeasured
tobe1.0,whenRmeasures d(P,R) itfinds3.2,which isclearly inconsistent with
theothertwomeasurements.
Figure 6-19. Inconsistent distance measurements inaone-dimensional space.tellPabout thecircle itislocated on;contacting onlytwonodes would tellit
about theposition oftheintersection oftwocircles (which generally consists of
twopoints); athirdnodewould subsequently allow Ptocompute isactual loca-
tion.
JustasinGPS,nodePcancompute isowncoordinates (xp,yp) bysolving the
threeequations withthetwounknowns Xpandyp:
Fig.6-19alsosuggests howthissituation canbeimproved. Inoursimple ex-
ample, wecould solve theinconsistencies bymerely computing positions ina
two-dimensional space. Thisbyitself, however, isnotageneral solution when
dealing withmany measurements. Infact,considering thatInternet latency meas-
urements mayviolate thetriangle inequality, itisgenerally impossible toresolve
inconsistencies completely. Thetriangle inequality states thatinageometric
snace. foranyarbitrary three nodes P,Q,andRitmustalways betruethat
d(P,K) Sa~r,~) +a~~,J().
There arevarious waystoapproach theseissues. Oneapproach, proposed by
NgandZhang (2002) istouseLspecial nodes bI'... ,bL, known aslandmarks.
Landmarks measure theirpairwise latencies d(bj,bj) andsubsequently letaSEC. 6.4 GLOBAL POSITIONING OFNODES 263
Asitturns out,withwell-chosen landmarks, mcanbeassmall as6or7,with"d(P,Q) being nomore thanafactor 2different fromtheactual latency d(P,Q) for
arbitrary nodes PandQ(Szyamniak etaI.,2004).
Another waytotackle thisproblem istoview thecollection ofnodes asa
huge system inwhich nodes areattached toeachother through springs. Inthis
case, Id(P,Q) -d(P,Q) Iindicates towhatextent nodes PandQaredisplaced
relative tothesituation inwhich thesystem ofsprings would beatrest.Byletting
eachnode(slightly) change itsposition, itcanbeshown thatthesystem willeven-
tually converge toanoptimal organization inwhich theaggregated errorismini-
mal.Thisapproach isfollowed inVivaldi, ofwhich thedetails canbefound in
Dabek etal.(2004a).
6.5ELECTION ALGORITHMS
Many distributed algorithms require oneprocess toactascoordinator, initia-
tor,orotherwise perform some special role.Ingeneral, itdoesnotmatter which
process takes onthisspecial responsibility, butoneofthem hastodoit.Inthis
section wewilllookatalgorithms forelecting acoordinator (using thisasagen-
ericname forthespecial process).
Ifallprocesses areexactly thesame, withnodistinguishing characteristics,
there isnowaytoselect oneofthem tobespecial -.Consequently, wewillassume
thateachprocess hasaunique number, forexample, itsnetwork address (forsim-
plicity, wewillassume oneprocess permachine). Ingeneral, election algorithms
attempt tolocate theprocess withthehighest process number anddesignate itas
coordinator. Thealgorithms differ inthewaytheydothelocation.central nodecompute thecoordinates foreachlandmark. Tothisend,thecentral
nodeseeks tominimize thefollowing aggregated errorfunction:
"
where d(bi,bj) corresponds tothegeometric distance, thatis,thedistance after
nodes b,andb,havebeenpositioned.
Thehidden parameter inminimizing theaggregated error function isthe
dimension m.Obviously, wehavethatL>m,butnothing prevents usfromchoos-
ingavalue formthatismuch smaller thanL.Inthatcase. anodePmeasures its
distance toeachoftheLlandmarks andcomputes itscoordinates byminimizing264 SYNCHRONlZA TION CHAP. 6
Furthermore, wealsoassume thatevery process knows theprocess number of
every otherprocess. What theprocesses donotknow iswhich onesare.currently
upandwhich onesarecurrently down. Thegoalofanelection algorithm istoen-
surethatwhen anelection starts, itconcludes withallprocesses agreeing onwho
thenewcoordinator istobe.There aremany algorithms andvariations, ofwhich
several important onesarediscussed inthetextbooks byLynch (l996) andTel
(2000), respectively.
6.5.1 Traditional Election Algorithms
Westartwithtaking alookattwotraditional election algorithms togivean
impression whatwhole groups ofresearchers havebeendoing inthepastdecades.
Insubsequent sections, wepayattention tonewapplications oftheelection prob-
lem.
TheBully Algorithm
Asafirstexample, consider thebully algorithm devised byGarcia-Molina
(1982). When anyprocess notices thatthecoordinator isnolonger responding to
requests, itinitiates anelection. Aprocess, P,holds anelection asfollows:
1.PsendsanELECTION message toallprocesses withhigher numbers.
2.Ifnooneresponds, Pwinstheelection andbecomes coordinator.
3.Ifoneofthehigher-ups answers, ittakesover.P'sjobisdone.
Atanymoment, aprocess cangetanELECTION message from oneofits
lower-numbered colleagues. When suchamessage arrives, thereceiver sends an
OKmessage backtothesender toindicate thatheisaliveandwilltakeover.The
receiver thenholds anelection, unless itisalready holding one.Eventually, all
processes giveupbutone,andthatoneisthenewcoordinator. Itannounces its
victory bysending allprocesses amessage telling themthatstarting immediately
itisthenewcoordinator.
Ifaprocess thatwaspreviously down comes backup,itholds anelection. Ifit
happens tobethehighest-numbered process currently running, itwillwinthe
election andtakeoverthecoordinator's job.Thusthebiggest guyintownalways
wins,hence thename "bully algorithm."
InFig.6-20weseeanexample ofhowthebullyalgorithm works. Thegroup
consists ofeightprocesses, numbered from0to7.Previously process 7wasthe
coordinator, butithasjustcrashed. Process 4isthefirstonetonotice this,soit
sends ELECTION messages toalltheprocesses higher thanit,namely 5,6,and7.
asshown inFig.6-20(a). Processes 5and6bothrespond withOK, asshown inSEC. 6.5 ELECTION ALGORITHMS 265
Fig.6-20(b). Upon getting thefirstofthese responses, 4knows thatitsjobis
over. Itknows thatoneofthese bigwigs willtakeoverandbecome coordinator. It
justsitsbackandwaits toseewhothewinner willbe(although atthispoint itcan
make apretty goodguess).
Figure 6·20. Thebully election algorithm. (a)Process 4holds anelection. (b)
Processes 5and6respond. telling 4tostop. (c)Now5and6eachholdanelec-
tion.(d)Process 6tells5tostop. (e)Process 6winsandtellseveryone.
InFig.6-20(c), both5and6holdelections, eachoneonlysending messages
tothose processes higher thanitself. InFig.6-20(d) process 6tells5thatitwill
takeover. Atthispoint 6knows that7isdeadandthatit(6)isthewinner. Ifthere
isstateinformation tobecollected fromdiskorelsewhere topickupwhere the
oldcoordinator leftoff,6must nowdowhatisneeded. When itisready totake
over, 6announces thisbysending aCOORDINATOR message toallrunning proc-
esses. When 4getsthismessage, itcannowcontinue withtheoperation itwas
trying todowhen itdiscovered that7wasdead, butusing 6asthecoordinator this
time. Inthiswaythefailure of7ishandled andthework cancontinue.
Ifprocess 7iseverrestarted, itwilljustsendantheothers aCOORDINATOR
message andbully them intosubmission.266 SYNCHRONIZA nON CHAP. 6
ARingAlgorithm
Another election algorithm isbased ontheuseofaring.Unlike someringal-
gorithms, thisonedoesnotuseatoken. Weassume thattheprocesses arephysi-
callyorlogically ordered, sothateachprocess knows whoitssuccessor is.When
anyprocess notices thatthecoordinator isnotfunctioning, itbuilds anELEC-
TION message containing itsownprocess number andsends themessage to'its
successor. Ifthesuccessor isdown, thesender skipsoverthesuccessor andgoes
tothenextmember along thering.ortheoneafterthat,untilarunning process is
located. Ateachstepalong theway,thesender addsitsownprocess number to
thelistinthemessage effectively making itselfacandidate tobeelected ascoor-
dinator.
Eventually, themessage getsbacktotheprocess thatstarted itall.Thatproc-
essrecognizes thisevent when itreceives anincoming message containing its
ownprocess number. Atthatpoint, themessage typeischanged toCOORDINA-
TORandcirculated onceagain, thistimetoinform everyone elsewhothecoordi-
natoris(thelistmember withthehighest number) andwhothemembers ofthe
newringare.When thismessage hascirculated once, itisremoved andeveryone
goesbacktowork.
Figure 6-21. Election algorithm using aring.
InFig.6-21weseewhathappens iftwoprocesses, 2and5,discover simul-
taneously thattheprevious coordinator, process 7,hascrashed. Each ofthese
builds anELECTION message andandeachofthem starts circulating itsmes-
sage,independent oftheotherone.Eventually, bothmessages willgoalltheway
around, andboth2and5willconvert themintoCOORDINATOR messages, with
exactly thesamemembers andinthesameorder. When bothhavegonearound
again, bothwillberemoved. Itdoesnoharmtohaveextramessages circulating;
atworst itconsumes alittlebandwidth, butthisnotconsidered wasteful.SEC. 6.5 ELECTION ALGORITHMS 267
6.5.2Elections inWirelessEnvironments
Traditional election algorithms aregenerally based onassumptions thatare
notrealistic inwireless environments. Forexample, theyassume thatmessage
passing isreliable andthatthetopology ofthenetwork doesnotchange. These
assumptions arefalseinmost wireless environments, especially those formobile
adhocnetworks.
Onlyfewprotocols forelections havebeendeveloped thatwork inadhocnet-
works. Vasudevan etal.(2004) propose asolution thatcanhandle failing nodes
andpartitioning networks. Animportant property oftheirsolution isthatthebest
leader canbeelected rather thanjustarandom aswasmore orlessthecaseinthe
previously discussed solutions. Their protocol works asfollows. To·simplify our
discussion, weconcentrate onlyonadhocnetworks andignore thatnodes can
move.
Consider awireless adhocnetwork. Toelect aleader, anynode inthenet-
work, called thesource, caninitiate anelection bysending anELECTION mes-
sage toitsimmediate neighbors (i.e., thenodes initsrange). When anode
receives anELECTION forthefirsttime, itdesignates thesender asitsparent,
andsubsequently sends outanELECTION message toallitsimmediate neigh-
bors, except fortheparent. When anodereceives anELECTION message froma
nodeother thanitsparent, itmerely acknowledges thereceipt.
When nodeRhasdesignated nodeQasitsparent, itforwards theELECTION
message toitsimmediate neighbors (excluding Q)andwaits foracknowledgments
tocome inbefore acknowledging theELECTION message from Q.Thiswaiting
hasanimportant consequence. First, note thatneighbors thathave already
selected aparent willimmediately respond toR.More specifically, ifallneigh-
borsalready haveaparent, Risaleafnode andwillbeabletoreport backtoQ
quickly. Indoing so,itwillalsoreport information suchasitsbattery lifetime and
other resource capacities.
Thisinformation willlaterallow Qtocompare R'scapacities tothatofother
downstream nodes, andselect thebesteligible nodeforleadership. Ofcourse, Q
hadsentanELECTION message onlybecause itsownparent Phaddone soas
well. Intum, when Qeventually acknowledges theELECTION message previ-
ously sentbyP,itwillpassthemosteligible nodetoPaswell. Inthisway,the
source willeventually gettoknow which node isbesttobeselected asleader,
afterwhich itwillbroadcast thisinformation toallother nodes.
Thisprocess isillustrated inFig.6-22. Nodes havebeenlabeled atoj,along
withtheircapacity. Node ainitiates anelection bybroadcasting anELECTION
message tonodes band j,asshown inFig.6-22(b). After thatstep,ELECTION
messages arepropagated toallnodes, ending withthesituation shown inFig.6-
22(e), where wehaveomitted thelastbroadcast bynodes fandi:From there on,
each node reports toitsparent thenode withthebestcapacity, asshown in
Fig.6-22(f). Forexample, when nodegreceives theacknowledgments from its268 SYNCHRONIZATION CHAP. 6
Figure 6-22. Election algorithm inawireless network, withnodeaasthesource.
(a)Initial network. (b)-(e) Thebuild-tree phase (lastbroadcast stepbynodes f
andinotshown). (f)Reporting ofbestnodetosource.
children eandh,itwillnotice thathisthebestnode, propagating [h,8]toitsown
parent, nodeb.Intheend,thesource willnotethathisthebestleader andwill
broadcast thisinformation toallothernodes.SEC. 6.5 ELECTION ALGORITHMS 269
When multiple elections areinitiated, eachnodewilldecide tojoinonlyone
election. Tothisend,eachsource tagsitsELECTION message withaunique i-
dentifier. Nodes willparticipate onlyintheelection withthehighest identifier,
stopping anyrunning participation inotherelections.
With some minor adjustments, theprotocol canbeshown tooperate also
when thenetwork partitions, andwhen nodes joinandleave. Thedetails canbe
found inVasudevan etal.(2004).
6.5.3 Elections inLarge-Scale Systems
Thealgorithms wehavebeendiscussing sofargenerally apply· torelatively
small distributed systems. Moreover, thealgorithms concentrate ontheselection
ofonlyasingle node.There aresituations whenseveral nodes should actually be
selected, suchasinthecaseofsuperpeers inpeer-to-peer networks, which we
discussed inChap. 2.Inthissection, weconcentrate specifically ontheproblem
ofselecting superpeers.
Loetal.(2005) identified thefollowing requirements thatneedtobemetfor
superpeer selection:
1.Normal nodes should havelow-latency access tosuperpeers.
2.Superpeers should beevenly distributed across theoverlay network.
3.There should beapredefined portion ofsuperpeers relative tothe
totalnumber ofnodes intheoverlay network.
4.Eachsuperpeer should notneedtoservemorethanafixednumber of
normal nodes.
Fortunately, theserequirements arerelatively easytomeetinmostpeer-to-peer
systems, given thefactthattheoverlay network iseither structured (asinDHT-
based systems), orrandomly unstructured (as,forexample, canberealized with
gossip-based solutions). Letustakealookatsolutions proposed byLoetal.
(2005).
InthecaseofDHT-based systems, thebasicideaistoreserve afraction ofthe
identifier space forsuperpeers. Recall thatinDHT-based systems eachnode
receives arandom anduniformly assigned m-bit identifier. Now suppose we
reserve thefirst(i.e.,leftmost) kbitstoidentify superpeers. Forexample, ifwe
needNsuperpeers, thenthefirstrlog2 (N)l bitsofanykeycanbeusedtoidentify
thesenodes.
Toexplain, assume wehavea(small) Chord system withm=8andk=3.
When looking upthenoderesponsible foraspecific keyp,wecanfirstdecide to
routethelookup request tothenoderesponsible forthepattern
pAND 11100000270 SYNCHRONIZATION CHAP. 6
toseeifthisrequest isrouted toitself. Provided nodeidentifiers areuniformly
assigned tonodes. itcanbeseenthatwithatotalofNnodes thenumber of
superpeers is,onaverage. equal2k-m N. .
Acompletely different approach isbased onpositioning nodes inanm-
dimensional geometric space aswediscussed above. Inthiscase,assume weneed
toplaceNsuperpeers evenly throughout theoverlay. Thebasicideaissimple: a
totalofNtokens arespread across Nrandomly-chosen nodes. Nonodecanhold
morethanonetoken. Eachtoken represents arepelling forcebywhich another
token isinclined tomove away. Theneteffect isthatifalltokens exertthesame
repulsion force, theywillmove away fromeachother andspread themselves
evenly inthegeometric space.
Thisapproach requires thatnodes holding atoken learnabout other tokens.
Tothisend,Laetal.propose touseagossiping protocol bywhich atoken's force
isdisseminated throughout thenetwork. Ifanodediscovers thatthetotalforces
thatareacting onitexceed athreshold, itwillmove thetoken inthedirection of
thecombined forces, asshown inFig.6-23.
Figure 6-23. Moving tokens inatwo-dimensional space using repulsion forces.
When atoken isheldbyanodeforagiven amount oftime,thatnodewillpro-
moteitselftosuperpeer.
6.6SUMMARY
Strongly related tocommunication between processes istheissue ofhow
processes indistributed systems synchronize. Synchronization isallabout doing
therightthingattherighttime.Aproblem indistributed systems, andcomputer
networks ingeneral, isthatthereisnonotion ofaglobally shared clock. Inother
words, processes ondifferent machines havetheirownideaofwhattimeitis.which isthentreated asthesuperpeer. Notethateachnodeidcancheck whether
itisasuoemeer bvlooking upSEC. 6.6 SUMMARY 271
There arevarious waytosynchronize clocks inadistributed system, butall
methods areessentially based onexchanging clock values, while taking into
account thetimeittakestosendandreceive messages. Variations incommunica-
tiondelays andthewaythose variations aredealtwith, largely determine the
accuracy ofclock synchronization algorithms.
Related tothesesynchronization problems ispositioning nodes inageometric
overlay. Thebasicideaistoassign eachnodecoordinates fromanrn-dimensional
space suchthatthegeometric distance canbeusedasanaccurate measure forthe
latency between twonodes. Themethod ofassigning coordinates strongly resem-
blestheoneapplied indetermining thelocation andtimeinGPS.
Inmany cases, knowing theabsolute timeisnotnecessary. What counts is
thatrelated events atdifferent processes happen inthecorrect order. Lamport
showed thatbyintroducing anotion oflogical clocks, itispossible foracollec-
tionofprocesses toreach global agreement onthecorrect ordering ofevents. In
essence, eachevent e,suchassending orreceiving amessage, isassigned aglo-
ballyunique logical timestamp C(e)suchthatwhen event ahappened before b,
C(a)<C(b). Lamport timestamps canbeextended tovector timestamps: if
C(a)<C(b),weevenknowthateventacausally preceded b.
Animportant classofsynchronization algorithms isthatofdistributed mutual
exclusion. These algorithms ensure thatinadistributed collection ofprocesses, at
mostoneprocess atatimehasaccess toashared resource. Distributed mutual
exclusion caneasily beachieved ifwemake useofacoordinator thatkeeps track
ofwhose turnitis.Fullydistributed algorithms alsoexist,buthavethedrawback
thattheyaregenerally moresusceptible tocommunication andprocess failures.
Synchronization between processes oftenrequires thatoneprocess actsasa
coordinator. Inthosecaseswhere thecoordinator isnotfixed, itisnecessary that
processes inadistributed computation decide onwhoisgoing tobethatcoordina-
tor.Suchadecision istakenbymeans ofelection algorithms. Election algorithms
areprimarily usedincases where thecoordinator cancrash. However, theycan
alsobeapplied fortheselection ofsuperpeers inpeer-to-peer systems.
PROBLEMS
1.Name atleastthreesources ofdelay thatcanbeintroduced between WWV broadcast-
ingthetimeandtheprocessors inadistributed system setting theirinternal clocks.
2.Consider thebehavior oftwomachines inadistributed system. Bothhaveclocks that
aresupposed totick1000times permillisecond. Oneofthem actually does, butthe
other ticksonly990times permillisecond. IfUTC updates come inonceaminute,
whatisthemaximum clock skew thatwilloccur?
3.Oneofthemodem devices thathave(silently) crept intodistributed systems areGPS
receivers. Giveexamples ofdistributed applications thatcanuseGPSinformation.272 SYNCHRONIZATION CHAP. 6
4.When anodesynchronizes itsclock tothatofanother node, itisgenerally agood idea
totakeprevious measurements intoaccount aswell.Why? Also, giveanexample of
howsuchpastreadings could betaken intoaccount.
5.Addanewmessage toFig.6-9thatisconcurrent withmessage A,thatis,itneither
happens before Anorhappens afterA.
6.Toachieve totally-ordered multicasting withLamport timestamps, isitstrictly neces-
sarythateachmessage isacknowledged? .
7.Consider acommunication layer inwhich messages aredelivered onlyintheorder
thattheywere sent.Giveanexample inwhich eventhisordering isunnecessarily re-
strictive.
8.Many distributed algorithms require theuseofacoordinating process. Towhatextent
cansuchalgorithms actually beconsidered distributed? Discuss.
9.Inthecentralized approach tomutual exclusion (Fig.6-14), upon receiving amessage
fromaprocess releasing itsexclusive access totheresources itwasusing, thecoordi-
nator normally grants permission tothefirstprocess onthequeue. Give another pos-
siblealgorithm forthecoordinator.
10.Consider Fig.6-14again. Suppose thatthecoordinator crashes. Does thisalways bring
thesystem down? Ifnot,under whatcircumstances doesthishappen? Isthere anyway
toavoid theproblem andmake thesystem abletotolerate coordinator crashes?
11.Ricart andAgrawala's algorithm hastheproblem thatifaprocess hascrashed and
doesnotreply toarequest from another process toaccess aresources, thelackof
response willbeinterpreted asdenial ofpermission. Wesuggested thatallrequests be
answered immediately tomake iteasytodetect crashed processes. Arethere anycir-
cumstances where eventhismethod isinsufficient? Discuss.
12.Howdotheentries inFig.6-17change ifweassume thatthealgorithms canbeimple-
mented onaLAN thatsupports hardware broadcasts?
13.Adistributed system mayhavemultiple, independent resources. Imagine thatprocess
owants toaccess resource Aandprocess 1wants toaccess resource B.CanRicart and
Agrawala's algorithm leadtodeadlocks? Explain youranswer.
14.Suppose thattwoprocesses detect thedemise ofthecoordinator simultaneously and
bothdecide toholdanelection using thebully algorithm. What happens?
15.InFig.6-21wehavetwoELECTION messages circulating simultaneously. While it
doesnoharm tohavetwoofthem, itwould bemore elezant ifonecould bekilled off."-
Devise analgorithm fordoing thiswithout affecting theoperation ofthebasic election
algorithm.
16.(Lab assignment) UNIX systems provide many facilities tokeepcomputers insynch,
notably thecombination ofthecrontab tool(which allows toautomatically schedule
operations) andvarious synchronization commands arepowerful. Configure aUNIX
system thatkeeps thelocal timeaccurate withintherange ofasingle second. Like-
wise, configure anautomatic backup facility bywhich anumber ofcrucial filesare.
automatically transferred toaremote machine once every 5minutes. Your solution
should beefficient when itcomes tobandwidth usage.7
CONSISTENCY AND REPLICATION
:i.:Animportant issueindistributed systems isthereplication ofdata.Dataare
generally replicated toenhance reliability orimprove performance. Oneofthe
major problems iskeeping replicas consistent. Informally, thismeans thatwhen
onecopyisupdated weneedtoensure thattheothercopies areupdated aswell;
otherwise thereplicas willnolonger bethesame. Inthischapter, wetakeade-
tailed lookatwhatconsistency ofreplicated data.actually means andthevarious
waysthatconsistency canbeachieved.
Westartwithageneral introduction discussing whyreplication isuseful and
howitrelates toscalability. Wethencontinue byfocusing onwhatconsistency
actually means. Animportant classofwhatareknown asconsistency models as-
sumes thatmultiple processes simultaneously access shared data.Consistency for
thesesituations canbeformulated withrespect towhatprocesses canexpect when
reading andupdating theshared data,knowing thatothers areaccessing thatdata
aswell.
Consistency models forshared dataareoftenhardtoimplement efficiently in
large-scale distributed systems. Moreover, inmany cases simpler models canbe
used,which arealsoofteneasier toimplement. Onespecific classisformed by
client-centric consistency models, which concentrate, onconsistency fromtheper-
spective ofasingle (possibly mobile) client. Client-centric consistency models are
discussed inaseparate section.
Consistency isonlyhalfofthestory. Wealsoneedtoconsider howconsisten-
cyisactually implemented. There areessentially two,moreorlessindependent,
273274 CONSISTENCY AND REPLICATION CHAP. 7
issues weneedtoconsider. Firstofall,westartwithconcentrating onmanaging
replicas, which takesintoaccount notonlytheplacement ofreplica servers, but
alsohowcontent isdistributed totheseservers.
Thesecond issueishowreplicas arekeptconsistent. Inmostcases, applica-
tionsrequire astrong formofconsistency. Informally, thismeans thatupdates are
tobepropagated moreorlessimmediately between replicas. There arevarious al-
ter/natives forimplementing strong consistency, which arediscussed inaseparate
section. Also,attention ispaidtocaching protocols, which formaspecial caseof
consistency protocols.
7.1INTRODUCTION
Inthissection, westartwithdiscussing theimportant reasons forwanting to
replicate datainthefirstplace. Weconcentrate onreplication asatechnique for
achieving scalability, andmotivate whyreasoning about consistency issoimpor-
tant.
7.1.1ReasonsforReplication
There aretwoprimary reasons forreplicating data:reliability andperfor-
mance. First,dataarereplicated toincrease thereliability ofasystem. Ifafile
system hasbeenreplicated itmaybepossible tocontinue working afteronerep-
licacrashes bysimply switching tooneoftheotherreplicas. Also,bymaintaining
multiple copies, itbecomes possible toprovide better protection against corrupted
data.Forexample, imagine therearethreecopies ofafileandevery readand
writeoperation isperformed oneachcopy. Wecansafeguard ourselves against a
single, failing writeoperation, byconsidering thevalue thatisreturned byatleast
twocopies asbeing thecorrect one.
Theotherreason forreplicating dataisperformance. Replication forperfor-
mance isimportant when thedistributed system needs toscaleinnumbers and
geographical area.Scaling innumbers. occurs, forexample, when anincreasing
number ofprocesses needs toaccess datathataremanaged byasingle server. In
thatcase,performance canbeimproved byreplicating theserver andsubse-
quently dividing thework.
Scaling withrespect tothesizeofageographical areamayalsorequire repli-
cation. Thebasicideaisthatbyplacing acopyofdataintheproximity ofthe
process usingthem, thetimetoaccess thedatadecreases. Asaconsequence, the
performance asperceived bythatprocess increases. Thisexample alsoillustrates
thatthebenefits ofreplication forperformance maybehardtoevaluate. Although
aclient process mayperceive better performance, itmayalsobethecasethat
morenetwork bandwidth isnowconsumed keeping allreplicas uptodate.SEC. 7.1 INTRODUCTION 275
Ifreplication helps toimprove reliability andperformance, whocould be
against it?Unfortunately, thereisapricetobepaidwhen dataarereplicated. The•..problem withreplication isthathaving multiple copies mayleadtoconsistency
problems. Whenever acopyismodified, thatcopybecomes different fromthe
rest.Consequently, modifications havetobecarried outonallcopies toensure
consistency. Exactly when andhowthose modifications needtobecarried out
determines thepriceofreplication.
Tounderstand theproblem, consider improving access timestoWebpages. If
nospecial measures aretaken, fetching apagefromaremote Webserver may
sometimes eventakeseconds tocomplete. Toimprove performance, Webbrow-
sersoftenlocally storeacopyofapreviously fetched Webpage(i.e.,theycache a
Webpage). Ifauserrequires thatpageagain, thebrowser automatically returns
thelocalcopy. Theaccess timeasperceived bytheuserisexcellent. However, if
theuseralways wants tohavethelatestversion ofapage, hemaybeinforbad
luck.Theproblem isthatifthepagehasbeenmodified inthemeantime, modifi-
cations willnothavebeenpropagated tocached copies, making thosecopies out-
of-date.
Onesolution totheproblem ofreturning astalecopytotheuseristoforbid
thebrowser tokeeplocalcopies inthefirstplace, effectively letting theserver be
fullyincharge ofreplication. However, thissolution maystillleadtopooraccess
times ifnoreplica isplaced neartheuser.Another- solution istolettheWeb
server invalidate orupdate eachcached copy, butthisrequires thattheserver
keeps trackofallcaches andsending themmessages. This,inturn,maydegrade
theoverall performance oftheserver. Wereturn toperformance versus scalability
issues below.
7.1.2 Replication asScaling Technique
Replication andcaching forperformance arewidely applied asscaling tech-
niques. Scalability issues generally appear intheformofperformance problems.
Placing copies ofdataclosetotheprocesses usingthemcanimprove performance
through reduction ofaccess timeandthussolvescalability problems.
Apossible trade-off thatneeds tobemade isthatkeeping copies uptodate
mayrequire morenetwork bandwidth. Consider aprocess Pthataccesses alocal
replica Ntimes persecond, whereas thereplica itselfisupdated Mtimespersec-
ond.Assume thatanupdate completely refreshes theprevious version ofthelocal
replica. IfN«M, thatis,theaccess-to-update ratioisverylow,wehavethe
situation where many updated versions ofthelocalreplica willneverbeaccessed
byP,rendering thenetwork communication forthose versions useless. Inthis
case,itmayhavebeenbetter nottoinstall alocalreplica closetoP,ortoapply a
different strategy forupdating thereplica. Wereturn totheseissues below.
Amoreserious problem, however, isthatkeeping multiple copies consistent
mayitselfbesubject toserious scalability problems. Intuitively, acollection of276 CONSISTENCY AND REPLlCA TION CHAP. 7
copies isconsistent when thecopies arealways thesame. Thismeans thataread
operation performed atanycopywillalways return thesame result. Consequently,
when anupdate operation isperformed ononecopy, theupdate should bepro-
pagated toallcopies before asubsequent operation takes place, nomatter at
which copythatoperation isinitiated orperformed.
Thistypeofconsistency issometimes informally (andimprecisely) referred, to
astight consistency asprovided bywhat isalsocalled synchronous replication.
(Inthenextsection, wewillprovide precise definitions ofconsistency andintro-
ducearange ofconsistency models.) Thekeyideaisthatanupdate isperformed
atallcopies asasingle atomic operation, ortransaction. Unfortunately, imple-
menting atomicity involving alarge number ofreplicas thatmaybewidely dis-
persed across alarge-scale network isinherently difficult when operations are
alsorequired tocomplete quickly.
Difficulties come from thefactthatweneed tosynchronize allreplicas. In
essence, thismeans thatallreplicas firstneedtoreach agreement onwhen exactly
anupdate istobeperformed locally. Forexample, replicas mayneedtodecide on
aglobal ordering ofoperations using Lamport timestamps, orletacoordinator
assign suchanorder. Global synchronization simply takes alotofcommunication
time, especially when replicas arespread across awide-area network.
Wearenowfaced withadilemma. Ontheonehand, scalability problems can
bealleviated byapplying replication and.caching, leading toimproved perfor-
mance. Ontheother hand, tokeepallcopies consistent generally requires global
synchronization, which isinherently costly interms ofperformance. Thecure
maybeworse thanthedisease.
Inmany cases, theonlyrealsolution istoloosen theconsistency constraints.
Inother words, ifwecanrelax therequirement thatupdates needtobeexecuted
asatomic operations, wemaybeabletoavoid (instantaneous) global synchroniza-
tions, andmaythusgainperformance. Theprice paidisthatcopies maynotal-
ways bethesame everywhere. Asitturns out,towhat extent consistency canbe
loosened depends highly ontheaccess andupdate patterns ofthereplicated data,
aswellasonthepurpose forwhich those dataareused.
Inthefollowing sections, wefirstconsider arange ofconsistency models by
providing precise definitions ofwhat consistency actually means. Wethencon-
tinue withourdiscussion ofthedifferent ways toimplement consistency models
through what arecalled distribution andconsistency protocols. Different ap-
proaches toclassifying consistency andreplication canbefound inGray eta1.
(1996) andWiesmann eta1.(2000).
7.2DATA-CENTRIC CONSISTENCY MODELS
Traditionally, consistency hasbeendiscussed inthecontext ofreadandwrite
operations onshared data, available bymeans of(distributed) shared memory. a
(distributed) shared database, ora(distributed) filesystem. Inthissection, weuseSEC. 7.2 DATA-CENTRIC CONSISTENCY MODELS 277
thebroader termdatastore. Adatastoremaybephysically distributed across
multiple machines. Inparticular, eachprocess thatcanaccess datafromthestore
isassumed tohavealocal(ornearby) copyavailable oftheentire store.Write op-
erations arepropagated totheothercopies, asshown inFig.7-1.Adataoperation
isclassified asawriteoperation whenitchanges thedata,andisotherwise classi-
tiedasareadoperation.
Figure 7·1.Thegeneral organization ofalogical datastore, physically distrib-
utedandreplicated across multiple processes.
Aconsistency model isessentially acontract between processes andthedata
store. Itsaysthatifprocesses agree toobeycertain.rules, thestorepromises to
workcorrectly. Normally, aprocess thatperforms areadoperation onadataitem,
expects theoperation toreturn avaluethatshows theresults ofthelastwriteoper-
ationonthatdata.
Intheabsence ofaglobal clock, itisdifficult todefine precisely which write
operation isthelastone.Asanalternative, weneedtoprovide otherdefinitions,
leading toarange ofconsistency models. Eachmodel effectively restricts the
values thatareadoperation onadataitemcanreturn. Asistobeexpected, the
oneswithmajor restrictions areeasytouse,forexample when developing appli-
cations, whereas those withminor restrictions aresometimes difficult. Thetrade-
offis,ofcourse, thattheeasy-to-use models donotperform nearly aswellasthe
difficult ones.Suchislife.
7.2.1 Continuous Consistency
From whatwehavediscussed sofar,itshould beclearthatthereisnosuch
thingasabestsolution toreplicating data.Replicating dataposes consistency
problems thatcannot besolved efficiently inageneral way.Onlyifweloosen
consistency canthere behopeforattaining efficient solutions. Unfortunately,
therearealsonogeneral rulesforloosening consistency: exactly whatcanbe
tolerated ishighly dependent onapplications.
There aredifferent waysforapplications tospecify whatinconsistencies they
cantolerate. YuandVahdat (2002) takeageneral approach bydistinguishing278 CONSISTENCY AND REPLICA nON CHAP. 7
threeindependent axesfordefining inconsistencies: deviation innumerical values
between replicas, deviation instaleness between replicas, anddeviation with
respect totheordering ofupdate operations. They refertothese deviations as
forming continuous consistency ranges.
Measuring inconsistency interms ofnumerical deviations canbeusedbyap-
plications forwhich thedatahavenumerical semantics. Oneobvious example is
thereplication ofrecords containing stockmarket prices. Inthiscase,anapplica-
tionmayspecify thattwocopies should notdeviate morethan$0.02, which would
beanabsolute numerical deviation. Alternatively, arelative numerical deviation
could bespecified, stating thattwocopies should differ bynomorethan,forex-
ample, 0.5%. Inbothcases, wewould seethatifastockgoesup(andoneofthe
replicas isimmediately updated) without violating thespecified numerical devia-
tions,replicas would stillbeconsidered tobemutually consistent.
Numerical deviation canalsobeunderstood interms ofthenumber ofupdates
thathavebeenapplied toagiven replica, buthavenotyetbeenseenbyothers.
Forexample, aWebcache maynothaveseenabatchofoperations carried outby
aWebserver. Inthiscase,theassociated deviation inthevalue isalsoreferred to
asitsweight.
Staleness deviations relate tothelasttimeareplica wasupdated. Forsome
applications, itcanbetolerated thatareplica provides olddataaslongasitisnot
tooold.Forexample, weather reports typically stayreasonably accurate over
some time, sayafewhours. Insuchcases, amainserver mayreceive timely
updates, butmaydecide topropagate updates tothereplicas onlyonceinawhile.
Finally, thereareclasses ofapplications inwhich theordering ofupdates are
allowed tobedifferent atthevarious replicas, aslongasthedifferences remain
bounded. Onewayoflooking attheseupdates isthattheyareapplied tentatively
toalocalcopy, awaiting global agreement fromallreplicas. Asaconsequence,
someupdates mayneedtoberolled backandapplied inadifferent order before
becoming permanent. Intuitively, ordering deviations aremuch harder tograsp
thantheothertwoconsistency metrics. Wewillprovide examples below toclarify
matters.
TheNotion ofaConit
Todefine inconsistencies, YuandVahdat introduce aconsistency unit,abbre-
viated toconit. Aconitspecifies theunitoverwhich consistency istobemeas-
ured.Forexample, inourstock-exchange example, aconitcould bedefined asa
record representing asingle stock. Another example isanindividual weather re-
port.
Togiveanexample ofaconit, andatthesametimeillustrate numerical and
ordering deviations, consider thetworeplicas asshown inFig.7-2.Eachreplica i
maintains atwo-dimensional vector clock vq,justliketheoneswedescribed inSEC. 7.2 279
Figure 7-2.Anexample ofkeeping track ofconsistency deviations [adapted
from(YuandVahdat, 2002)].
Inthisexample weseetworeplicas thatoperate onaconitcontaining thedata
itemsxandy.Bothvariables areassumed tohavebeeninitialized toO.Replica A
receivedtheoperation
5,B:x~x+2
fromreplica Bandhasmade itpermanent (i.e.,theoperation hasbeencommitted
atAandcannot berolled back). Replica Ahasthreetentative update operations:
8,A, 12,A, and14,A, which brings itsordering deviation to3.Alsonotethat
duetothelastoperation 14,A, A'svector clockbecomes (15,5).
Theonlyoperation fromBthatAhasnotyetseenisIO,B, bringing its
numerical deviation withrespect tooperations to1.Inthisexample, theweight of
thisdeviation canbeexpressed asthemaximum difference between the(commit-
ted)values ofxandyatA,andtheresult fromoperations atBnotseenbyA.The
committed value atAis(x,y) =(2,0), whereas the-for Aunseen-operation atB
yields adifference ofy=5.
Asimilar reasoning shows thatBhastwotentative update operations: 5,B
and10,B,which means ithasanordering deviation of2.Because Bhasnotyet
seenasingle operation fromA,itsvector clock becomes (0,11).Thenumerical
deviation is3withatotalweight of6.Thislastvalue comes fromthefactB's
committed value is(x,y) =(0,0), whereas thetentative operations atAwill
already bringxto6.
Notethatthereisatrade-off between maintaining fine-grained andcoarse-
grained conits. Ifaconitrepresents alotofdata,suchasacomplete database,
thenupdates areaggregated forallthedataintheconit. Asaconsequence, thisDATA-CENTRIC CONSISTENCY MODELS280
maybring replicas sooner inaninconsistent state. Forexample, assume thatin
Fig.7-3tworeplicas maydiffer innomorethanoneoutstanding update. Inthat
case,when thedataitems inFig.7-3(a) haveeachbeenupdated onceatthefirst
replica, thesecond onewillneedtobeupdated aswell.Thisisnotthecasewhen
choosing asmaller conit, asshown inFig.7-3(b). There, thereplicas arestillcon-
sidered tobeuptodate.Thisproblem isparticularly important when thedata
itemscontained inaconitareusedcompletely independently, inwhich casethey
aresaidtofalsely share theconit.
Figure 7-3.Choosing theappropriate granularity foraconit. (a)Twoupdates
leadtoupdate propagation. (b)Noupdate propagation isneeded (yet).
Unfortunately, making conits verysmallisnotagoodidea,forthesimple rea-
sonthatthetotalnumber ofconits thatneedtobemanaged grows aswell.Inother
words, thereisanoverhead related tomanaging theconits thatneeds tobetaken
intoaccount. Thisoverhead, intum,mayadversely affect overall performance,
which hastobetakenintoaccount.
Although fromaconceptual pointofviewconits formanattractive means for
capturing consistency requirements, therearetwoimportant issues thatneedtobe
dealtwithbefore theycanbeputtopractical use.First,inordertoenforce consis-
tency weneedtohaveprotocols. Protocols forcontinuous consistency aredis-
cussed laterinthischapter.
Asecond issueisthatprogram developers mustspecify theconsistency re-
quirements fortheirapplications. Practice indicates thatobtaining suchrequire-
-ments maybeextremely difficult. Programmers aregenerally notusedtohandling
replication, letaloneunderstanding whatitmeans toprovide detailed information
onconsistency. Therefore, itismandatory thattherearesimple andeasy-to-under-
standprogramming interfaces.
Continuous consistency canbeimplemented asatoolkit which appears topro-
grammers asjustanother library thattheylinkwiththeirapplications. Aconitis
simply declared alongside anupdate ofadataitem.Forexample, thefragment of
pseudocode
AffectsConit(ConitQ, 1,1);
append message mtoqueue Q;CHAP. 7 CONSISTENCY AND REPLICA nONSEC. 7.2 DATA-CENTRIC CONSISTENCY MODELS 281
states thatappending amessage toqueue Qbelongs toaconit named ""ConitQ."
Likewise, operations maynowalsobedeclared asbeing dependent onconits:
DependsOnConit(ConitQ, 4,0,60);
readmessage mfromheadofqueue Q;
Inthiscase, thecalltoDependsOnConitO specifies thatthenumerical deviation,
ordering deviation, andstaleness should belimited tothevalues 4,0,and60(sec-
onds), respectively. Thiscanbeinterpreted asthatthere should beatmost 4
unseen update operations atother replicas, there should benotentative local
updates, andthelocalcopyofQshould havebeenchecked forstaleness nomore
than60seconds ago.Ifthese requirements arenotfulfilled, theunderlying
middle ware willattempt tobring thelocal copyofQtoastatesuchthattheread
operation canbecarried out.
7.2.2 Consistent Ordering ofOperations
Besides continuous consistency, there isahugebody ofwork ondata-centric
consistency models from thepastdecades. Animportant class ofmodels comes
fromthefieldofconcurrent programming. Confronted withthefactthatinparal-
lelanddistributed computing multiple processes willneedtoshare resources and
access these resources simultaneously, researchers have sought toexpress the
semantics ofconcurrent accesses when shared resources arereplicated. Thishas
ledtoatleastoneimportant consistency model thatiswidely used. Inthefollow-
ing,weconcentrate onwhatisknown assequential consistency, andwewillalso
discuss aweaker variant, namely causal consistency.
Themodels thatwediscuss inthissection alldealwithconsistently ordering
operations onshared, replicated data. Inprinciple, themodels augment those of
continuous consistency inthesense thatwhen tentative updates atreplicas needto
becommitted, replicas willneedtoreach agreement onaglobal ordering ofthose
updates. Inother words, theyneed toagree onaconsistent ordering ofthose
updates. Theconsistency models wediscuss nextareallabout reaching suchcon-
sistent orderings.
Sequential Consistency
Inthefollowing, wewilluseaspecial notation inwhich wedraw theopera-
tions ofaprocess along atimeaxis.Thetimeaxisisalways drawn horizontally,
withtimeincreasing fromlefttoright. Thesymbols
mean thatawrite byprocess P;todataitemxwiththevalue aandareadfrom
thatitembyPireturning bhave been done, respectively. Weassume thateach
dataitemisinitially NIL. When there isnoconfusion concerning which process is
accessing data,weomittheindex fromthesymbols Wand R.282 CONSISTENCY AND REPLICATION CHAP. 7
Asanexample, inFig.7-4PIdoesawritetoadataitemx,modifying itsval-
uetoa.Notethat,inprinciple, thisoperation WI(x)aisfirstperformed onacopy
ofthedatastorethatislocaltoPI,andisthensubsequently propagated tothe
otherlocalcopies. Inourexample, P2laterreads thevalue NIL, andsome time
afterthata(from itslocalcopyofthestore). What weareseeing hereisthatit
tooksometimetopropagate theupdate ofxtoP2,which isperfectly acceptable.
Sequential consistency isanimportant data-centric consistency model,
which wasfirstdefined byLamport (1979) inthecontext ofshared memory for
multiprocessor systems. Ingeneral, adatastoreissaidtobesequentially con-
sistent whenitsatisfies thefollowing condition:
Theresult ofanyexecution isthesame asifthe(read andwrite) opera-
tionsbyallprocesses onthedatastore were executed insome sequential
order andtheoperations of-each individual process appear inthisse-
quence intheorder specified byitsprogram.
What thisdefinition means isthatwhenprocesses runconcurrently on(possi-
bly)different machines, anyvalidinterleaving ofreadandwrite operations is
acceptable behavior, butallprocesses seethesame interleaving ofoperations.
Notethatnothing issaidabout time;thatis,thereisnoreference tothe"most
recent" writeoperation onadataitem.Notethatinthiscontext, aprocess "sees"
writes fromallprocesses butonlyitsownreads.
Thattimedoesnotplaya rolecanbeseenfromFig.7-5.Consider fourproc-
essesoperating onthesamedataitemx.InFig.7-5(a) process PIfirstperforms
W(x)a tox.Later(inabsolute time), process P2alsoperforms awriteoperation,
bysetting thevalue ofxtob.However, bothprocesses P3andP4firstreadvalue
b,andlatervalue a.Inotherwords, thewriteoperation ofprocess P2appears to
havetakenplacebefore thatofPI·
Incontrast, Fig.7-5(b) violates sequential consistency because notallproc-
essesseethesameinterleaving ofwriteoperations. Inparticular, toprocess P3,it
appears asifthedataitemhasfirstbeenchanged tob,andlatertoa.Ontheother
hand,P4willconclude thatthefinalvalueisb.
Tomake thenotion ofsequential consistency moreconcrete, consider three
concurrently-executing processes PI,P2,andP3,shown inFig.7-6(Dubois etaI.,
1988). Thedataitems inthisexample areformed bythethreeinteger variables x,
y,andz,which arestored ina(possibly distributed) shared sequentially consistentFigure 7-4.Behavior oftwoprocesses operating onthesame dataitem. The
horizontal axisistime.SEC. 7.2 DATA-CENTRIC CONSISTENCY MODELS 283
Figure 7-5.(a)Asequentially consistent datastore. (b)Adatastorethatisnot
sequentially consistent.
Figure 7-6.Three concurrently-executing processes.
datastore. Weassume thateachvariable isinitialized toO.Inthisexample, an
assignment corresponds toawriteoperation, whereas aprintstatement corres-
ponds toasimultaneous readoperation ofitstwoarguments. Allstatements are
assumed tobeindivisible.
Various interleaved execution sequences arepossible. Withsixindependent
statements, therearepotentially 720(6!)possible execution sequences, although
someofthese violate program order. Consider the120(5!)sequences thatbegin
withx~1.Halfofthesehaveprint(r.z) before y~1andthusviolate program
order. Halfalsohaveprint(x,y) before z~1andalsoviolate program order.
Only1/4ofthe120sequences, or30,arevalid. Another 30validsequences are
possible starting withy~1andanother 30canbegin withz~1,foratotalof90
validexecution sequences. Fouroftheseareshown inFig.7-7.
InFig.7-7(a), thethreeprocesses areruninorder, firstPhthenP2,thenP3.
Theotherthreeexamples demonstrate different, butequally valid, interleavings of
thestatements intime.Eachofthethreeprocesses prints twovariables. Since the
onlyvalues eachvariable cantakeonaretheinitial value (0),ortheassigned
value (1),eachprocess produces a2-bitstring. Thenumbers afterPrints arethe
actual outputs thatappear ontheoutput device.
Ifweconcatenate theoutput ofPI,P2, andP3inthatorder, wegeta6-bit
string thatcharacterizes aparticular interleaving ofstatements. Thisisthestring
listed astheSignature inFig.7-7.Below wewillcharacterize eachordering by
itssignature rather thanbyitsprintout.
Notall64signature patterns areallowed. Asatrivial example, 000000 isnot
permitted, because thatwould imply thattheprintstatements ranbefore the
assignment statements, violating therequirement thatstatements areexecuted in284 CONSISTENCY AND REPLICATION CHAP. 7
Figure 7-7.Fourvalid execution sequences fortheprocesses ofFig.7-6.The
vertical axisistime.
program order. Amoresubtle example is001001. Thefirsttwobits,00,mean that
yandzwereboth0when PIdiditsprinting. Thissituation occurs onlywhen PI
executes bothstatements before P2orP3starts. Thenexttwobits,10,mean that
P2mustrunafterP,hasstarted butbefore P3hasstarted. Thelasttwobits,01,
mean thatP3mustcomplete before P,starts, butwehavealready seenthatPI
mustgofirst.Therefore, 001001 isnotallowed.
Inshort, the90different validstatement orderings produce avariety ofdif-
ferent program results (lessthan64,though) thatareallowed under theassump-
tionofsequential consistency. Thecontract between theprocesses andthedistrib-
utedshared datastoreisthattheprocesses mustaccept allofthese asvalidre-
sults.Inotherwords, theprocesses mustaccept thefourresults shown inFig.7-7
andalltheothervalidresults asproper answers, andmustworkcorrectly ifanyof
themoccurs. Aprogram thatworks forsome oftheseresults andnotforothers
violates thecontract withthedatastoreandisincorrect.
Causal Consistency
Thecausal consistency model (Hutto andAhamad, 1990) represents aweak-
ening ofsequential consistency inthatitmakes adistinction between events that
arepotentially causally related andthose thatarenot.Wealready came across
causality when discussing vector timestamps intheprevious chapter. Ifevent bis
caused orinfluenced byanearlier event a,causality requires thateveryone else
firstseea,thenseeb.
Consider asimple interaction bymeans ofadistributed shared database. Sup-
posethatprocess P,writes adataitemx.ThenP2readsxandwrites y.Herethe
reading ofxandthewriting ofyarepotentially causally related because theSEC.7.2 DATA-CENTRIC CONSISTENCY MODELS 285
computation ofymayhavedepended onthevalue ofxasreadbyPz(i.e.,the
valuewritten byPI)'
Ontheotherhand, iftwoprocesses spontaneously andsimultaneously write
twodifferent dataitems, thesearenotcausally related. Operations thatarenot
causally related aresaidtobeconcurrent.
Foradatastoretobeconsidered causally consistent, itisnecessary thatthe
storeobeys thefollowing condition:
Writes thatarepotentially causally related mustbeseenbyallprocesses
inthesame order. Concurrent writes maybeseeninadifferent order on
different machines.
Asanexample ofcausal consistency, consider Fig.7-8.Herewehaveanevent
sequence thatisallowed withacausally-consistent store, butwhich isforbidden
withasequentially-consistent storeorastrictly consistent store.Thethingtonote
isthatthewrites Wz(x)b andWI(x)careconcurrent, soitisnotrequired thatall
processes seetheminthesameorder.
Figure 7-8.Thissequence isallowed withacausally-consistent store, butnot
withasequentially consistent store.
Nowconsider asecond example. InFig.7-9(a) wehaveWz(x)b potentially
depending onWI(x)a because thebmaybearesult ofacomputation involving
thevalue readbyRz(x)a. Thetwowrites arecausally related, soallprocesses
mustseetheminthesameorder. Therefore, Fig.7-9(a) isincorrect. Ontheother
hand, inFig.7-9(b) thereadhasbeenremoved, soWI(x)aandWz(x)b arenow
concurrent writes. Acausally-consistent storedoesnotrequire concurrent writes
tobeglobally ordered, soFig.7-9(b) iscorrect. NotethatFig.7-9(b) reflects a
situation thatwould notbeacceptable forasequentially consistent store.
Figure 7-9.(a)Aviolation ofacausally-consistent store. (b)Acorrect se-
quence ofevents inacausally-consistent store.
Implementing causal consistency requires keeping trackofwhich processes
haveseenwhich writes. Iteffectively means thatadependency graph ofwhich286 CONSISTENCY ANDREPLICA DON CHAP. 7
operation isdependent onwhich otheroperations mustbeconstructed andmain-
tained. Onewayofdoing thisisbymeans ofvector timestamps, aswediscussed
intheprevious chapter. Wereturn totheuseofvector timestamps tocapture
causality laterinthischapter.
Grouping Operations
Sequential andcausal consistency aredefined atthelevelreadandwriteoper-
ations. Thislevelofgranularity isforhistorical reasons: thesemodels haveini-
tiallybeendeveloped forshared-memory multiprocessor systems andwereactual-
lyimplemented atthehardware level.
Thefinegranularity oftheseconsistency models inmany casesdidnotmatch
thegranularity asprovided byapplications. What weseethereisthatconcurrency
between programs sharing dataisgenerally keptunder control through synchroni-
zation mechanisms formutual exclusion andtransactions. Effectively, whathap-
pensisthatattheprogram levelreadandwriteoperations arebracketed bythe
pairofoperations ENTER_CS andLEAVE_CS where "CS" stands forcritical
section. Asweexplained inChap. 6,thesynchronization between processes takes
placebymeans ofthesetwooperations. Interms ofourdistributed datastore, this
means thataprocess thathassuccessfully executed ENTER_CS willbeensured
thatthedatainitslocalstoreisuptodate.Atthatpoint, itcansafely execute a
series ofreadandwriteoperations onthatstore, andsubsequently wrapthings up
bycalling LEAVE_CS.
Inessence, whathappens isthatwithin aprogram thedatathatareoperated
onbyaseries ofreadandwriteoperations areprotected against concurrent ac-
cesses thatwould leadtoseeing something elsethantheresult ofexecuting the
series asawhole. Putdifferently, thebracketing turnstheseries ofreadandwrite
operations intoanatomically executed unit,thusraising thelevelofgranularity.
Inordertoreach thispoint, wedoneedtohaveprecise semantics concerning
theoperations ENTER_CS andLEAVE_CS. These semantics canbeformulated
interms ofshared synchronization variables. There aredifferent ways touse
thesevariables. Wetakethegeneral approach inwhich eachvariable hassome
associated data,which could amount tothecomplete setofshared data. Weadopt
theconvention thatwhen aprocess enters itscritical section itshould acquire the
relevant synchronization variables, andlikewise when itleaves thecritical sec-
tion,itreleases thesevariables. Notethatthedatainaprocess' critical section
maybeassociated todifferent synchronization variables.
Eachsynchronization variable hasacurrent owner, namely, theprocess that
lastacquired it.Theowner mayenterandexitcritical sections repeatedly without
having tosendanymessages onthenetwork. Aprocess notcurrently owning a
synchronization variable butwanting toacquire ithastosendamessage tothe
current owner asking forownership andthecurrent values ofthedataassociated
withthatsynchronization variable. Itisalsopossible forseveral processes toSEC. 7.2 DATA-CENTRIC CONSISTENCY MODELS 287
Figure 7·10. Avalidevent sequence forentry consistency.
Oneoftheprogramming problems withentry consistency isproperly associat-
ingdatawithsynchronization variables. Onestraightforward approach istoexpli-
citlytellthemiddleware which dataaregoing tobeaccessed, asisgenerally donesimultaneously ownasynchronization variable innonexclusive mode, meaning
thattheycanread,butnotwrite, theassociated data.
Wenowdemand thatthefollowing criteria aremet(Bershad etal.,1993):
1.Anacquire access ofasynchronization variable isnotallowed to
perform withrespect toaprocess untilallupdates totheguarded
shared datahavebeenperformed withrespect tothatprocess.
2.Before anexclusive mode access toasynchronization variable bya
process isallowed toperform withrespect tothatprocess, noother
process mayholdthesynchronization variable, noteveninnonex-
clusive mode.
3.After anexclusive mode access toasynchronization variable has
beenperformed, anyotherprocess' nextnonexclusive mode access
tothatsynchronization variable maynotbeperformed untilithas
performed withrespect tothatvariable's owner.
Thefirstcondition saysthatwhen aprocess doesanacquire, theacquire maynot
complete (i.e.,return control tothenextstatement) untilalltheguarded shared
datahave been brought uptodate. Inother words, atanacquire, allremote
changes totheguarded datamustbemade visible.
Thesecond condition saysthatbefore updating ashared dataitem, aprocess
mustenter acritical section inexclusive mode tomake surethatnoother process
istrying toupdate theshared dataatthesame time.
Thethirdcondition saysthatifaprocess wants toenter acritical region in
nonexclusive mode, itmustfirstcheck withtheowner ofthesynchronization vari-
ableguarding thecritical region tofetch themost recent copies oftheguarded
shared data.
Fig.7-10shows anexample ofwhatisknown asentry consistency. Instead
ofoperating ontheentire shared data, inthisexample weassociate locks with
eachdataitem. Inthiscase, PIdoesanacquire forx,changes xonce, afterwhich
italsodoesanacquire fory.Process P2doesanacquire forxbutnotforY'.sothat
itwillreadvalue aforx,butmayreadNILfory.Because process P3firstdoesan
acquire fory,itwillreadthevalue bwhen yisreleased byPl'288 CONSISTENCY AND REPLICATION CHAP. 7
bydeclaring which database tables willbeaffected byatransaction. Inanobject-
based approach, wecould implicitly associate aunique synchronization variable
witheachdeclared object, effectively serializing allinvocations tosuchobjects.
Consistency versus Coherence
Atthispoint, itisuseful toclarify thedifference between twoclosely related
concepts. Themodels wehavediscussed sofaralldealwiththefactthatanumber
ofprocesses execute readandwriteoperations onasetofdataitems. Aconsis-
tency model describes whatcanbeexpected withrespect tothatsetwhen multi-
pleprocesses concurrently operate onthatdata.Thesetisthensaidtobecon-
sistent ifitadheres totherulesdescribed bythemodel.
Where dataconsistency isconcerned withasetofdataitems, coherence
models describe whatcanbeexpected toonlyasingle dataitem(Cantin etaI.,
2005). Inthiscase,weassume thatadataitemisreplicated atseveral places; itis
saidtobecoherent whenthevarious copies abidetotherulesasdefined byitsas-
sociated coherence model. Apopular model isthatofsequential consistency, but
nowapplied toonlyasingle dataitem. Ineffect, itmeans thatinthecaseof
concurrent writes, allprocesses willeventually seethesameorderofupdates tak-
ingplace.
7.3CLIENT-CENTRIC CONSISTENCY MODELS
Theconsistency models described intheprevious section aimatproviding a
systemwide consistent viewonadatastore. Animportant assumption isthat
concurrent processes maybesimultaneously updating thedatastore, andthatitis
necessary toprovide consistency inthefaceofsuchconcurrency. Forexample, in
thecaseofobject-based entryconsistency, thedatastoreguarantees thatwhen an
object iscalled, thecalling process isprovided withacopyoftheobject thatre-
flects allchanges totheobject thathavebeenmade sofar,possibly byotherproc-
esses. During thecall,itisalsoguaranteed thatnootherprocess caninterfere-
thatis,mutual exclusive access isprovided tothecalling process.
Being abletohandle- concurrent operations onshared datawhile maintaining
sequential consistency isfundamental todistributed systems. Forperformance
reasons, sequential consistency maypossibly beguaranteed onlywhen processes
usesynchronization mechanisms suchastransactions orlocks.
Inthissection, wetakealookataspecial classofdistributed datastores. The
datastores weconsider arecharacterized bythelackofsimultaneous updates, or
when suchupdates happen, theycaneasily beresolved. Mostoperations involve
reading data.These datastores offeraveryweakconsistency model, called even-
tualconsistency. Byintroducing special client-centric consistency models, itturns
outthatmany inconsistencies canbehidden inarelatively cheap way.SEC. 7.3 CLIENT-CENTRIC CONSISTENCY MODELS 289
7.3.1Eventual Consistency
Towhatextent processes actually operate inaconcurrent fashion, andtowhat
extent consistency needs tobeguaranteed, mayvary.There aremany examples in
which concurrency appears onlyinarestricted form. Forexample, inmany data-
basesystems, mostprocesses hardly everperform update operations; theymostly
readdatafromthedatabase. Only one,orveryfewprocesses perform update op-
erations. Thequestion thenishowfastupdates should bemade available toonly-
reading processes.
Asanother example, consider aworldwide naming system suchasDNS. The
DNS name space ispartitioned intodomains, where eachdomain isassigned toa
naming authority, which actsasowner ofthatdomain. Only thatauthority isal-
lowed toupdate itspartofthename space. Consequently, conflicts resulting from
twooperations thatbothwant toperform anupdate onthesame data(i.e.,write-
writeconflicts), never occur. Theonlysituation thatneeds tobehandled are
read-write conflicts, inwhich oneprocess wants toupdate adataitemwhile an-
other isconcurrently attempting toreadthatitem. Asitturns out,itisoften
acceptable topropagate anupdate inalazyfashion, meaning thatareading proc-
esswillseeanupdate onlyaftersome timehaspassed since theupdate tookplace.
Yetanother example istheWorld Wide Web. Invirtually allcases, Web
pages areupdated byasingle authority, suchasawebmaster ortheactual owner
ofthepage. There arenormally nowrite-write conflicts toresolve. Ontheother
hand, toimprove efficiency, browsers andWebproxies areoften configured to
keepafetched pageinalocalcache andtoreturn thatpageuponthenextrequest.
Animportant aspect ofbothtypes ofWebcaches isthattheymayreturn out-
of-date Web pages. Inother words, thecached page thatisreturned tothere-
questing client isanolder version compared totheoneavailable attheactual Web
server. Asitturns out,many users findthisinconsistency acceptable (toacertain
degree).
These examples canbeviewed ascases of(large-scale) distributed andrepli-
cated databases thattolerate arelatively highdegree ofinconsistency. They have
incommon thatifnoupdates takeplace foralongtime, allreplicas willgradually
become consistent. Thisformofconsistency iscalled eventual consistency.
Data stores thatareeventually consistent thushavetheproperty thatinthe
absence ofupdates, allreplicas converge toward identical copies ofeachother.
Eventual consistency essentially requires onlythatupdates areguaranteed topro-
pagate toallreplicas. Write-write conflicts areoften relatively easytosolve when
assuming thatonlyasmall group ofprocesses canperform updates. Eventual con-
sistency istherefore often cheap toimplement.
Eventual consistent datastores work tineaslongasclients always access the
same replica. However, problems arisewhen different replicas areaccessed overa
short period oftime. This isbestillustrated byconsidering amobile userac-
cessing adistributed database, asshown inFig.7-11.290 CONSISTENCY AND REPLICATION CHAP. 7
Figure '-11. Theprinciple ofamobile useraccessing different replicas ofa
distributed database.
Themobile useraccesses thedatabase byconnecting tooneofthereplicas in
atransparent way.Inotherwords, theapplication running ontheuser's portable
computer isunaware onwhich replica itisactually operating. Assume theuser
performs several update operations andthendisconnects again. Later, heaccesses
thedatabase again, possibly aftermoving toadifferent location orbyusing adif-
ferent access device. Atthatpoint, theusermaybeconnected toadifferent rep-
licathanbefore, asshown inFig.7-11. However, iftheupdates performed prev-
iously havenotyetbeenpropagated, theuserwillnotice inconsistent behavior. In
particular, hewould expect toseeallpreviously made changes, butinstead, it
appears asifnothing atallhashappened.
Thisexample istypical foreventually-consistent datastores andiscaused by
thefactthatusersmaysometimes operate ondifferent replicas. Theproblem can
bealleviated byintroducing client-centric consistency. Inessence, client-centric
consistency provides guarantees forasingle client concerning theconsistency of
accesses toadatastorebythatclient. Noguarantees aregiven concerning concur-
rentaccesses bydifferent clients.
Client-centric consistency models originate fromtheworkonBayou [see,for
example Terry etal.(1994) andTerry etaI.,1998)]. Bayou isadatabase system
developed formobile computing, where itisassumed thatnetwork connectivity is
unreliable andsubject tovarious performance problems. Wireless networks and
networks thatspanlargeareas, suchastheInternet, fallintothiscategory.SEC. 7.3 CLIENT-CENTRIC CONSISTENCY MODELS 291
Bayou essentially distinguishes fourdifferent consistency models. Toexplain
thesemodels, weagain consider adatastorethatisphysically distributed across
multiple machines. When aprocess accesses thedatastore, itgenerally connects
tothelocally (ornearest) available copy, although, inprinciple, anycopywilldo
justfine.Allreadandwriteoperations areperformed onthatlocalcopy. Updates
areeventually propagated totheothercopies. Tosimplify matters, weassume that
dataitemshaveanassociated owner, which istheonlyprocess thatispermitted to
modify thatitem.Inthisway,weavoid write-write conflicts.
Client-centric consistency models aredescribed usingthefollowing notations.
LetXi[t]denote theversion ofdataitemxatlocalcopyL,attimet.Version Xi(t]
istheresult ofaseries ofwriteoperations atLithattookplacesinceinitialization.
\Vedenote thissetasWS(xi[tD. Ifoperations inWS(xJtIJ) havealsobeenper-
formed atlocalcopyLjatalatertimet2,wewriteWS(xi(td~[t2]). Iftheorder-
ingofoperations orthetiming isclearfromthecontext, thetimeindex willbe
omitted.
7.3.2 Monotonic Reads
Thefirstclient-centric consistency model isthatofmonotonic reads. Adata
storeissaidtoprovide monotonic-read consistency ifthefollowing condition
holds:
..Ifaprocess reads thevalue ofadataitemx,anysuccessive readopera-
tiononxbythatprocess willalways return thatsame value oramore
recent value.
Inotherwords, monotonic-read consistency guarantees thatifaprocess hasseena
valueofxattimet,itwillnever seeanolderversion ofxatalatertime.
Asanexample where monotonic reads areuseful, consider adistributed e-
maildatabase. Insuchadatabase, eachuser's mailbox maybedistributed and
replicated across multiple machines. Mailcanbeinserted inamailbox atanylo-
cation. However, updates arepropagated inalazy(i.e.,ondemand) fashion. Only
when acopyneeds certain dataforconsistency arethosedatapropagated tothat
copy. Suppose auserreads hismailinSanFrancisco. Assume thatonlyreading
maildoesnotaffect themailbox, thatis,messages arenotremoved, stored in
subdirectories, oreventagged ashaving already beenread,andsoon.When the
userlaterfliestoNewYorkandopens hismailbox again, monotonic-read consis-
tency guarantees thatthemessages thatwereinthemailbox inSanFrancisco will
alsobeinthemailbox whenitisopened inNewYork.
Using anotation similar tothatfordata-centric consistency models, mono-
tonic-read consistency canbegraphically represented asshown inFig.7-12.
Along thevertical axis,twodifferent localcopies ofthedatastoreareshown, LI
andL2.Time isshown along thehorizontal axisasbefore. Inallcases, weare292 CONSISTENCY ANDREPLICATION CHAP. 7
interested intheoperations carried outbyasingle process P.These specific oper-
ations areshown inboldface areconnected byadashed linerepresenting theorder
inwhich theyarecarried outbyP.
Figure 7-12. Thereadoperations performed byasingle process Pattwodif-
ferent localcopies ofthesamedatastore. (a)Amonotonic-read consistent datu
store. (b)Adatastorethatdoesnotprovide monotonic reads.
InFig.7-l2(a), process Pfirstperforms areadoperation onxatLI,returning
thevalue ofXl(atthattime). Thisvalue results fromthewrite operations in
WS(xI)performed atLI.Later, Pperforms areadoperation onxatL2,shown as
R(X2)' Toguarantee monotonic-read consistency, alloperations inWS(x1)should
havebeenpropagated toL2before thesecond readoperation takesplace. Inother
words, weneedtoknow forsurethatWS(xI)ispartofWS(x2)'which is
expressed asWS(xI;X2)'
Incontrast, Fig.7-l2(b) shows asituation inwhich monotonic-read consisten-
cyisnotguaranteed. Afterprocess PhasreadxIatLI,itlaterperforms theoper-
ationR(X2) atL2.However, onlythewriteoperations inWS(X2) havebeenper-
formed atL2•Noguarantees aregiven thatthissetalsocontains alloperations
contained inWS(xI)'.
7.3.3 Monotonic Writes
Inmany situations, itisimportant thatwriteoperations arepropagated inthe
correct ordertoallcopies ofthedatastore. Thisproperty isexpressed inmon-
otonic-write consistency. Inamonotonic-write consistent store, thefollowing
condition holds:
Awrite operation byaprocess onadataitemxiscompleted before any
successive write operation onXbythesameprocess.
Thuscompleting awriteoperation means thatthecopyonwhich asuccessive op-
eration isperformed reflects theeffect ofaprevious writeoperation bythesame
process, nomatter where thatoperation wasinitiated. Inotherwords, awriteop-
eration onacopyofitemxisperformed onlyifthatcopyhasbeenbrought upto
datebymeans ofanypreceding writeoperation, which mayhavetaken place on
othercopies ofx.Ifneedbe,thenewwritemustwaitforoldonestofinish.SEC. 7.3 CLIENT-CENTRIC CONSISTENCY MODELS 293
Notethatmonotonic-write consistency resembles data-centric FIFO consis-
tency. Theessence ofFIFO consistency isthatwriteoperations bythesameproc-
essareperformed inthecorrect order everywhere. Thisordering constraint also
applies tomonotonic writes, except thatwearenowconsidering consistency only
forasingle process instead offoracollection ofconcurrent processes.
Bringing acopyofxuptodateneednotbenecessary wheneachwriteopera-
tioncompletely overwrites thepresent value ofx.However, writeoperations are
oftenperformed ononlypartofthestateofadataitem.Consider, forexample, a
software library. Inmany cases, updating suchalibrary isdonebyreplacing one
ormorefunctions, leading toanextversion. Withmonotonic-write consistency,
guarantees aregiven thatifanupdate isperformed onacopyofthelibrary, all
preceding updates willbeperformed first.Theresulting library willthenindeed
become themostrecent version andwillinclude allupdates thathaveledtoprevi-
ousversions ofthelibrary.
Monotonic-write consistency isshown inFig.7-13. InFig.7-13(a), process P
performs awrite operation onxatlocalcopyL1, presented astheoperation
W(XI). Later, Pperforms another writeoperation onx,butthistimeatL2,shown
asW(X2). Toensure monotonic-write consistency, itisnecessary thattheprevious
writeoperation atL1hasalready beenpropagated toL2• Thisexplains operation
W(Xl) atL2,andwhyittakesplacebefore W(X2)·
Figure 7-13. Thewrite operations performed byasingle process Pattwodif-
ferent localcopies ofthesame datastore. (a)Amonotonic-write consistent data
store. (b)Adatastorethatdoesnotprovide monotonic-write consistency.
Incontrast, Fig.7-13(b) shows asituation inwhich monotonic-write consis-
tency isnotguaranteed. Compared toFig.7-13(a),whatismissing isthepropaga-
tionofW(x1)tocopyL2.Inotherwords, noguarantees canbegiven thatthe
copyofxonwhich thesecond writeisbeing performed hasthesameormore
recent valueatthetimeW(xI)completed atLI.
Notethat,bythedefinition ofmonotonic-write consistency, writeoperations
bythesame process areperformed inthesame order astheyareinitiated. A
somewhat weaker formofmonotonic writes isoneinwhich theeffects ofawrite
operation areseenonlyifallpreceding writes havebeencarried outaswell,but
perhaps notintheorderinwhich theyhavebeenoriginally initiated. Thisconsis-
tency isapplicable inthosecases inwhich writeoperations arecommutative, so
thatordering isreally notnecessary. Details arefound inTerry etal.(1994).294 CONSISTENCY AND REPLICATION CHAP. 7
7.3.4 Read Your Writes
Aclient-centric consistency model thatisclosely related tomonotonic reads
isasfollows. Adatastoreissaidtoprovide read-your-writes consistency, ifthe
following condition holds:
Theeffect ofawriteoperation byaprocess ondataitemxwillalways be
seenbyasuccessive readoperation onxbythesameprocess.
Inotherwords, awriteoperation isalways completed before asuccessive readop-
eration bythesameprocess, nomatter where thatreadoperation takesplace.
Theabsence ofread-your-writes consistency issometimes experienced when
updating Webdocuments andsubsequently viewing theeffects. Update operations
frequently takeplace bymeans ofastandard editor orword processor, which
saves thenewversion onafilesystem thatisshared bytheWebserver. The
user's Webbrowser accesses thatsamefile,possibly afterrequesting itfromthe
localWebserver. However, oncethefilehasbeenfetched, either theserver orthe
browser oftencaches alocalcopyforsubsequent accesses. Consequently, when
theWebpageisupdated, theuserwillnotseetheeffects ifthebrowser orthe
server returns thecached copyinstead oftheoriginal file.Read-your-writes con-
sistency canguarantee thatiftheeditor andbrowser areintegrated intoasingle
program, thecache isinvalidated when thepageisupdated, sothattheupdated
fileisfetched anddisplayed.
Similar effects occur whenupdating passwords. Forexample, toenteradigi-
tallibrary ontheWeb, itisoftennecessary tohaveanaccount withanaccom-
panying password. However, changing apassword make takesometimetocome
intoeffect, withtheresult thatthelibrary maybeinaccessible totheuserforafew
minutes. Thedelaycanbecaused because aseparate server isusedtomanage pass-
words anditmaytakesometimetosubsequently propagate (encrypted) passwords
tothevarious servers thatconstitute thelibrary.
Fig.7-14(a) shows adatastorethatprovides read-your-writes consistency.
NotethatFig.7-14(a) isverysimilar toFig.7-12(a), except thatconsistency is
nowdetermined bythelastwriteoperation byprocess P,instead ofitslastread.
Figure 7-14. (a)Adatastorethatprovides read-your-writes consistency. (b)A
datastorethatdoesnot.
InFig.7-14(a), process Pperformed awriteoperation W(XI) andlateraread
operation atadifferent localcopy. Read-your-writes consistency guarantees thatSEC. 7.3 CLIENT-CENTRIC CONSISTENCY MODELS 295
theeffects ofthewriteoperation canbeseenbythesucceeding readoperation.
Thisisexpressed byWS(XI ;X2), which states thatW(Xl) ispartofWS(X2)' In
contrast, inFig.7-14(b), W(Xl) hasbeenleftoutofWS(X2), meaning thattheef-
fectsoftheprevious writeoperation byprocess Phavenotbeenpropagated toL2·
7.3.5 Writes Follow Reads
Thelastclient-centric consistency model isoneinwhich updates arepro-
pagated astheresult ofprevious readoperations. Adatastoreissaidtoprovide
writes-follow-reads consistency, ifthefollowing holds.
Awrite operation byaprocess onadataitemxfollowing aprevious read
operation onxbythesame process isguaranteed totakeplace onthe
same oramore recent value ofxthatwasread.
Inotherwords, anysuccessive writeoperation byaprocess onadataitemxwill
beperformed onacopyofxthatisuptodatewiththevaluemostrecently readby
thatprocess.
Writes-follow-reads consistency canbeusedtoguarantee thatusersofanet-
worknewsgroup seeaposting ofareaction toanarticle onlyaftertheyhaveseen
theoriginal article (Terry etaI.,1994). Tounderstand theproblem, assume thata
userfirstreads anarticle A.Then, hereacts byposting aresponse B.Byrequiring
writes-follow-reads consistency, Bwillbewritten toanycopyofthenewsgroup
onlyafterAhasbeenwritten aswell.Notethatuserswhoonlyreadarticles need
notrequire anyspecific client-centric consistency model. Thewrites-follows-
readsconsistency assures thatreactions toarticles arestored atalocalcopyonly
iftheoriginal isstored thereaswell.
Figure 7-15. (a)Awrites-follow-reads consistent datastore. (b)Adatastore
thatdoesnotprovide writes-follow-reads consistency.
Thisconsistency model isshown inFig.7-15. InFig.7-15(a), aprocess reads
xatlocalcopyL1.Thewriteoperations thatledtothevaluejustread,alsoappear
inthewrite setatL2.where thesameprocess laterperforms awriteoperation.
(Note thatotherprocesses atL2seethosewriteoperations aswell.) Incontrast, no
guarantees aregiven thattheoperation performed atL2,asshown inFig.7-15(b),
areperformed onacopythatisconsistent withtheonejustreadatL1•
Wewillreturn toclient-centric consistency models when wediscuss imple-
mentations lateroninthischapter.296 CONSISTENCY AND REPLICA nON CHAP. 7
7.4REPLICA MANAGEMENT
Akeyissueforanydistributed system thatsupports replication istodecide
where, when, andbywhom replicas should beplaced, andsubsequently which
mechanisms touseforkeeping thereplicas consistent. Theplacement problem it-
selfshould besplitintotwosubproblems: thatofplacing replica servers, andthat
ofplacing content. Thedifference isasubtle butimportant oneandthetwoissues
areoftennotclearly separated. Replica-server placement isconcerned withfind-
ingthebestlocations toplaceaserver thatcanhost(partof)adatastore. Content
placement deals withfinding thebestservers forplacing content. Notethatthis
oftenmeans thatwearelooking fortheoptimal placement ofonlyasingle data
item. Obviously, before content placement cantakeplace, replica servers will
havetobeplaced first.Inthefollowing, takealookatthesetwodifferent place-
mentproblems, followed byadiscussion onthebasicmechanisms formanaging
thereplicated content.
7.4.1Replica-Server Placement
Theplacement ofreplica servers isnotanintensively studied problem forthe
simple reason thatitisoftenmoreofamanagement andcommercial issuethanan
optimization problem. Nonetheless, analysis ofclient andnetwork properties are
useful tocometoinformed decisions.
There arevarious waystocompute the.bestplacement ofreplica servers, but
allboildown toanoptimization problem inwhich thebestKoutofNlocations
needtobeselected (K<N).These problems areknown tobecomputationally
complex andcanbesolved onlythrough heuristics. Qiuetal.(2001) takethedis-
tancebetween clients andlocations astheirstarting point. Distance canbemeas-
uredinterms oflatency orbandwidth. Their solution selects oneserver atatime
suchthattheaverage distance between thatserver anditsclients isminimal given
thatalready kservers havebeenplaced (meaning thatthereareN-klocations
left).
Asanalternative, Radoslavov etaI.(2001) propose toignore theposition of
clients andonlytakethetopology oftheInternet asformed bytheautonomous
systems. Anautonomous system (AS)canbestbe.viewed asanetwork inwhich
thenodes allrunthesamerouting protocol andwhich ismanaged byasingle
organization. AsofJanuary 2006, therewerejustover20,000 ASes. Radoslavov
etaI.firstconsider thelargest ASandplaceaserver ontherouter withthelargest
number ofnetwork interfaces (i.e.,links). Thisalgorithm isthenrepeated withthe
second largest AS,andsoon.
Asitturns out,client-unaware server placement achieves similar results as
client-aware placement, under theassumption thatclients areuniformly distrib-
utedacross theInternet (relative totheexisting topology). Towhatextent thisas-
sumption istrueisunclear. Ithasnotbeenwellstudied.SEC. 7.4 REPLICA MANAGEMENT 297
Oneproblem withthese algorithms isthattheyarecomputationally expen-
sive.Forexample, boththeprevious algorithms haveacomplexity thatishigher
thanO(N'2), where Nisthenumber oflocations toinspect. Inpractice, thismeans
thatforevenafewthousand locations, acomputation mayneedtorunfortensof
minutes. Thismaybeunacceptable, notably when thereareflashcrowds (asud-
denburstofrequests foronespecific site,which occur regularly ontheInternet).
Inthatcase,quickly determining where replica servers areneeded isessential,
afterwhich aspecific onecanbeselected forcontent placement.
Szymaniak etal.(2006) havedeveloped amethod bywhich aregion forplac-
ingreplicas canbequickly identified. Aregion isidentified tobeacollection of
nodes accessing thesamecontent, butforwhich theinternode latency islow.The
goalofthealgorithm isfirsttoselect themostdemanding regions-that is,the
onewiththemostnodes-and thentoletoneofthenodes insucharegion actas
replica server.
Tothisend,nodes areassumed tobepositioned inanm-dimensional geo-
metric space, aswediscussed intheprevious chapter. Thebasicideaistoidentify
theKlargest clusters andassign anodefromeachcluster tohostreplicated con-
tent.Toidentify these clusters, theentire space ispartitioned intocells.TheK
mostdense cellsarethenchosen forplacing areplica server. Acellisnothing but
anm-dimensional hypercube. Foratwo-dimensional space, thiscorresponds toa
rectangle.
Obviously, thecellsizeisimportant, asshown inFig.7-16. Ifcellsare
chosen toolarge, thenmultiple clusters ofnodes maybecontained inthesame
cell.Inthatcase,toofewreplica servers forthoseclusters would bechosen. On
theotherhand, choosing smallcellsmayleadtothesituation thatasingle cluster
isspread across anumber ofcells,leading tochoosing toomanyreplica servers.
Figure 7-16. Choosing aproper cellsizeforserver placement.
Asitturnsout,anappropriate cellsizecanbecomputed asasimple function
oftheaverage distance between twonodes andthenumber ofrequired replicas.
Withthiscellsize,itcanbeshown thatthealgorithm performs aswellasthe
close-to-optimal onedescribed inQiuetal.(2001), buthaving amuchlower com-
plexity: O(Nxmax {log (N), K}). Togiveanimpression whatthisresult means:298 CONSISTENCY ANDREPLICATION CHAP. 7
experiments show thatcomputing the20bestreplica locations foracollection of
64,000 nodes isapproximately 50.000 times faster. Asaconsequence, replica-
server placement cannowbedoneinrealtime.
7.4.2 Content Replication andPlacement
Letusnowmove away from server placement andconcentrate oncontent
placement. When itcomes tocontent replication andplacement, three different
types ofreplicas canbedistinguished logically organized asshown inFig.7-17.
Figure 7-17. Thelogical organization ofdifferent kinds ofcopies ofadatastore
intothreeconcentric rings.
Permanent Replicas
Permanent replicas canbeconsidered astheinitial setofreplicas thatconsti-
tuteadistributed datastore. Inmany cases, thenumber ofpermanent replicas is
small. Consider, forexample, aWeb site.Distribution ofaWeb sitegenerally
comes inoneoftwoforms. Thefirstkindofdistribution isoneinwhich thefiles
thatconstitute asitearereplicated across alimited number ofservers atasingle
location. Whenever arequest comes in,itisforwarded tooneoftheservers, for
instance, using around-robin strategy. .
Thesecond formofdistributed Websitesiswhatiscalled mirroring. Inthis
case, aWeb siteiscopied toalimited number ofservers, called mirror sites.
which aregeographically spread across theInternet. Inmost cases, clients simply
choose oneofthevarious mirror sitesfrom alistoffered tothem. Mirrored v..'eb
siteshaveincommon withcluster-based Websitesthatthere areonlyafewnum-
berofreplicas, which aremore orlessstatically configured.
Similar static organizations alsoappear withdistributed databases (OSZu and
Valduriez, 1999). Again, thedatabase canbedistributed andreplicated acrOSS ~\
number ofservers thattogether form acluster ofservers, often referred toas~\
shared-nothing architecture, emphasizing thatneither disks normain memorySEC. 7.4 REPLICA MANAGEMENT 299
areshared byprocessors. Alternatively, adatabase isdistributed andpossibly rep-
licated across anumber ofgeographically dispersed sites.Thisarchitecture isgen-
erally deployed infederated databases (Sheth andLarson, 1990).
Server-Initiated Replicas
Incontrast topermanent replicas, server-initiated replicas arecopies ofadata
storethatexisttoenhance performance andwhich arecreated attheinitiative of
the(owner ofthe)datastore. Consider, forexample, aWebserver placedin New
York. Normally, thisserver canhandle incoming requests quiteeasily, butitmay
happen thatoveracouple ofdaysasudden burstofrequests come infroman
unexpected location farfromtheserver. Inthatcase,itmaybeworthwhile to
install anumber oftemporary replicas inregions where requests arecoming from.
Theproblem ofdynamically placing replicas isalsobeing addressed inWeb
hosting services. These services offera(relatively static) collection ofservers
spread across theInternet thatcanmaintain andprovide access toWebfiles
belonging tothirdparties. Toprovide optimal facilities suchhosting services can
dynamically replicate filestoservers where thosefilesareneeded toenhance per-
formance, thatis,close todemanding (groups of)clients. Sivasubramanian et
al.(2004b) provide anin-depth overview ofreplication inWebhosting services to
which wewillreturn inChap. 12.
Given thatthereplica servers arealready inplace, deciding where toplace
content iseasier thaninthecaseofserver placement. Anapproach todynamic
replication offilesinthecaseofaWebhosting service isdescribed inRabinovich
etal.(1999). Thealgorithm isdesigned tosupport Webpages forwhich reason it
assumes thatupdates arerelatively rarecompared toreadrequests. Using tilesas
theunitofdata,thealgorithm works asfollows.
Thealgorithm fordynamic replication takes twoissues intoaccount. First,
replication cantakeplacetoreduce theloadonaserver. Second, specific fileson
aserver canbemigrated orreplicated toservers placed intheproximity ofclients
thatissuemany requests forthosefiles.Inthefollowing pages, weconcentrate
onlyonthissecond issue. Wealsoleaveoutanumber ofdetails, which canbe
found inRabinovich etal.(1999).
Eachserver keeps trackofaccess counts perfile,andwhere access requests
come from. Inparticular, itisassumed that,given aclient C,eachserver can
determine which oftheservers intheWebhosting service isclosest toC.(Such
information canbeobtained, forexample, fromrouting databases.) Ifclient C1
andclient C2share thesame"closest" server P,allaccess requests forfileFat
server Qfromeland C2arejointly registered atQasasingle access count
cntQ(P,F). Thissituation isshown inFig.7-18.
When thenumber ofrequests foraspecific fileFatserver Sdrops below a
deletion threshold del(S,F),thatfilecanberemoved fromS.Asaconsequence,
thenumber ofreplicas ofthatfileisreduced, possibly leading tohigher work300 CONSISTENCY AND REPLICATION CHAP. 7
Figure 7-18. Counting access requests fromdifferent clients.
loads atother servers. Special measures aretaken toensure thatatleastonecopy
ofeachfilecontinues toexist.
Areplication threshold rep(5,F),which isalways chosen higher thanthe
deletion threshold, indicates thatthenumber ofrequests foraspecific fileisso
highthatitmaybeworthwhile replicating itonanother server. Ifthenumber of
requests liesomewhere between thedeletion andreplication threshold, thefileis
allowed onlytobemigrated. Inother words, inthatcaseitisimportant toatleast
keepthenumber ofreplicas forthatfilethesame.
When aserver Qdecides toreevaluate theplacement ofthefilesitstores, it
checks theaccess count foreachfile.Ifthetotalnumber ofaccess requests forF
atQdrops below thedeletion threshold del(Q,F), itwilldelete Funless itisthe
lastcopy. Furthermore, ifforsome server P,cntQ(p,F) exceeds more thanhalfof
thetotalrequests forFatQ,server Pisrequested totakeoverthecopy ofF.In
other words, server Qwillattempt tomigrate FtoP.
Migration offileFtoserver Pmaynotalways succeed, forexample, because
Pisalready heavily loaded orisoutofdiskspace. Inthatcase, Qwillattempt to
replicate Fonother servers. Ofcourse, replication cantakeplace onlyifthetotal
number ofaccess requests forFatQexceeds thereplication threshold rep(Q,F).
Server Qchecks allother servers intheWebhosting service, starting withtheone
farthest away. If,forsome server R,cntQ(R,F) ex-ceeds acertain fraction ofallre-
quests forFatQ,anattempt ismade toreplicate FtoR.
Server-initiated replication continues toincrease inpopularity intime, espe-
cially inthecontext ofWeb hosting services suchastheonejustdescribed. Note
thataslongasguarantees canbegiven thateachdataitemishosted byatleast
oneserver, itmaysuffice touseonlyserver-initiated replication andnothaveany
permanent replicas. Nevertheless, permanent replicas arestilloften useful asa
back-up facility, ortobeusedastheonlyreplicas thatareallowed tobechanged
toguarantee consistency. Server-initiated replicas arethenusedforplacing read-
onlycopies close toclients.SEC.7.4 REPLICA MANAGEMENT 301
Client- Initiated Replicas
Animportant kindofreplica istheoneinitiated byaclient. Client-initiated
replicas aremorecommonly known as(client) caches. Inessence, acache isa
localstorage facility thatisusedbyaclient totemporarily storeacopyofthedata
ithasjustrequested. Inprinciple, managing thecache isleftentirely totheclient.
Thedatastorefromwhere thedatahadbeenfetched hasnothing todowithkeep-
ingcached dataconsistent. However, asweshallsee,therearemany occasions in
which theclient canrelyonparticipation fromthe.data storetoinform itwhen
cached datahasbecome stale.
Client caches areusedonlytoimprove access times todata.Normally, when
aclientwants access tosomedata,itconnects tothenearest copyofthedatastore
fromwhere itfetches thedataitwants toread,ortowhere itstores thedataithad
justmodified. When mostoperations involve onlyreading data,performance can
beimproved byletting theclient storerequested datainanearby cache. Sucha
cache could belocated ontheclient's machine, oronaseparate machine inthe
samelocal-area network astheclient. Thenexttimethatsamedataneeds tobe
read,theclient cansimply fetchitfromthislocalcache. Thisscheme works fine
aslongasthefetched datahavenotbeenmodified inthemeantime.
Dataaregenerally keptinacache foralimited amount oftime,forexample,
toprevent extremely staledatafrombeing used,orsimply tomakeroomforother
data.Whenever requested datacanbefetched fromthelocalcache, acache bitis
saidtohaveoccurred. Toimprove thenumber ofcache hits,caches canbeshared
between clients. Theunderlying assumption isthatadatarequest fromclient C1
mayalsobeuseful forarequest fromanother nearby client C2·
Whether thisassumption iscorrect depends verymuch onthetypeofdata
store. Forexample, intraditional filesystems, datafilesarerarely shared atall
(see,e.g.,Muntz andHoneyman, 1992;andBlaze, 1993) rendering ashared cache
useless. Likewise, itturnsoutthatusing Webcaches toshare dataisalsolosing
someground, partly alsobecause oftheimprovement innetwork andserver per-
formance. Instead, server-initiated replication schemes arebecoming moreeffec-
tive.
Placement ofclient caches isrelatively simple: acache isnormally placed on
thesamemachine asitsclient, orotherwise onamachine shared byclients onthe
samelocal-area network. However, insome cases, extra levels ofcaching are..introduced bysystem administrators byplacing ashared cache between anumber
ofdepartments ororganizations, orevenplacing ashared cache foranentire
region suchasaprovince orcountry.
Yetanother approach istoplace (cache) servers atspecific points inawide-
areanetwork andletaclient locate thenearest server. When theserver islocated,
itcanberequested toholdcopies ofthedatatheclient waspreviously fetching
fromsomewhere else,asdescribed inNoble etal.(1999). Wewillreturn tocach-
inglaterinthischapter whendiscussing consistency protocols.302 CONSISTENCY AND REPLICA nON CHAP. 7
7.4.3 Content Distribution
Replica management alsodealswithpropagation of(updated) content tothe
relevant replica servers. There arevarious trade-offs tomake, which wediscuss
next.
Stateversus Operations
Animportant design issueconcerns whatisactually tobepropagated. Basi-
cally,therearethreepossibilities:
1.Propagate onlyanotification ofanupdate.
2.Transfer datafromonecopytoanother.
3.Propagate theupdate operation toothercopies.
Propagating anotification iswhatinvalidation protocols do.Inaninvalida-
tionprotocol, othercopies areinformed thatanupdate hastaken placeandthatthe
datatheycontain arenolonger valid. Theinvalidation mayspecify which partof
thedatastorehasbeenupdated, sothatonlypartofacopyisactually invalidated.
Theimportant issueisthatnomorethananotification ispropagated. Whenever
anoperation onaninvalidated copyisrequested, thatcopygenerally needs tobe
updated first,depending onthespecific consistency model thatistobesupported.
Themainadvantage ofinvalidation protocols isthattheyuselittlenetwork
bandwidth. Theonlyinformation thatneeds tobetransferred isaspecification of
which dataarenolonger valid. Suchprotocols generally workbestwhenthereare
many update operations compared toreadoperations, thatis,theread-to-write
ratioisrelatively small.
Consider, forexample, adatastoreinwhich updates arepropagated bysend-
ingthemodified datatoallreplicas. Ifthesizeofthemodified dataislarge, and
updates occur frequently compared toreadoperations, wemayhavethesituation
thattwoupdates occur afteroneanother without anyreadoperation being per-
formed between them. Consequently, propagation ofthefirstupdate toallreplicas
iseffectively useless, asitwillbeoverwritten bythesecond update. Instead, send-
inganotification thatthedatahavebeenmodified would havebeenmoreeffi-
cient.
Transferring themodified dataamong replicas isthesecond alternative, andis
useful whentheread-to-write ratioisrelatively high.Inthatcase,theprobability
thatanupdate willbeeffective inthesensethatthemodified datawillbereadbe-
forethenextupdate takesplaceishigh.Instead ofpropagating modified data,itis
alsopossible tologthechanges andtransfer onlythoselogstosavebandwidth. In
addition, transfers areoften aggregated inthesense thatmultiple modifications
arepacked intoasingle message, thussaving communication overhead.SEC. 7.4 REPLICA MANAGEMENT 303
Thethirdapproach isnottotransfer anydatamodifications atall,buttotell
eachreplica which update operation itshould perform (andsending onlythepa-
rameter values thatthose operations need). Thisapproach, alsoreferred toas
active replication, assumes thateachreplica isrepresented byaprocess capable
of"actively" keeping itsassociated datauptodatebyperforming operations
(Schneider, 1990). Themainbenefit ofactive replication isthatupdates canoften
bepropagated atminimal bandwidth costs, provided thesizeoftheparameters as-
sociated withanoperation arerelatively small. Moreover, theoperations canbeof
arbitrary complexity, which mayallow further improvements inkeeping replicas
consistent. Ontheotherhand, moreprocessing power mayberequired byeach
replica, especially inthosecaseswhenoperations arerelatively complex.
Pullversus PushProtocols
Another design issueiswhether updates arepulled orpushed. Inapush-
based approach, alsoreferred toasserver-based protocols, updates arepro-
pagated toother replicas without those replicas evenasking fortheupdates.
Push-based approaches areoften usedbetween permanent andserver-initiated
replicas, butcanalsobeusedtopushupdates toclientcaches. Server-based proto-
colsareapplied whenreplicas generally needtomaintain arelatively highdegree
ofconsistency. Inotherwords, replicas needtobekeptidentical.
Thisneedforahighdegree ofconsistency isrelated tothefactthatpermanent
andserver-initiated replicas, aswellaslargeshared caches, areoftenshared by
many clients, which, intum,mainly perform readoperations. Consequently, the
read-to-update ratioateachreplica isrelatively high.Inthesecases, push-based
protocols areefficient inthesensethatevery pushed update canbeexpected tobe
ofuseforoneormorereaders. Inaddition, push-based protocols make consistent
dataimmediately available whenasked for.
Incontrast, inapull-based approach, aserver orclient requests another
server tosenditanyupdates ithasatthatmoment. Pull-based protocols, alsocall-
edclient-based protocols, areoftenusedbyclient caches. Forexample, acom-
monstrategy applied toWebcaches isfirsttocheck whether cached dataitems
arestilluptodate.When acache receives arequest foritemsthatarestilllocally
available, thecache checks withtheoriginal Webserver whether thosedataitems
havebeenmodified sincetheywerecached. Inthecaseofamodification, the
modified dataarefirsttransferred tothecache, andthenreturned totherequesting
client. Ifnomodifications tookplace, thecached dataarereturned. Inother
words, theclient pollstheserver toseewhether anupdate isneeded.
Apull-based approach isefficient when theread-to-update ratioisrelatively
low.Thisisoftenthecasewith(nonshared) client caches, which haveonlyone
client. However, evenwhen acache isshared bymany clients, apull-based ap-
proach mayalsoprove tobeefficient when thecached dataitems arerarely304 CONSISTENCY AND REPLICATIONCHAP. 7
shared. Themaindrawback ofapull-based strategy incomparison toapush-
based approach isthattheresponse timeincreases inthecaseofacache miss.
When comparing push-based andpull-based solutions, thereareanumber of
trade-offs tobemade, asshown inFig.7-19. Forsimplicity, consider aclient-
server system consisting ofasingle, nondistributed server, andanumber ofclient
processes, eachhaving theirowncache.
Figure 7-19. Acomparison between push-based andpull-based protocols inthe
caseofmultiple-client. single-server systems.
Animportant issueisthatinpush-based protocols, theserver needs tokeep
trackofallclient caches. Apart fromthefactthatstateful servers areoftenless
faulttolerant, aswediscussed inChap. 3,keeping trackofallclient caches may
introduce aconsiderable overhead attheserver. Forexample, inapush-based ap-
proach, aWebserver mayeasily needtokeeptrackoftensofthousands ofclient
caches. EachtimeaWebpageisupdated, theserver willneedtogothrough its
listofclient caches holding acopyofthatpage, andsubsequently propagate the
update. Worse yet,ifaclient purges apageduetolackofspace, ithastoinform
theserver, leading toevenmorecommunication.
Themessages thatneedtobesentbetween aclient andtheserver alsodiffer.
Inapush-based approach, theonlycommunication isthattheserver sends updates
toeachclient. When updates areactually onlyinvalidations, additional communi-
cation isneeded byaclient tofetchthemodified data.Inapull-based approach, a
client willhavetopolltheserver, and,ifnecessary. fetchthemodified data.
Finally, theresponse timeattheclient isalsodifferent. When aserver pushes
modified datatotheclient caches, itisclearthattheresponse timeattheclient
sideiszero.When invalidations arepushed, theresponse timeisthesameasin
thepull-based approach, andisdetermined bythetimeittakestofetchthemodi-
fieddatafromtheserver.
These trade-offs haveleadtoahybrid formofupdate propagation based on
leases. Aleaseisapromise bytheserver thatitwillpushupdates totheclient for
aspecified time.When aleaseexpires, theclient isforced topolltheserver for
updates andpullinthemodified dataifnecessary. Analternative isthataclient
requests anewleaseforpushing updates whentheprevious leaseexpires.
Leases wereoriginally introduced byGrayandCheriton (1989). They pro-
videaconvenient mechanism fordynamically switching between apush-based
andpull-based strategy. Duvvuri etal.(2003) describe aflexible leasesystem thatSEC. 7.4 REPLICA MANAGEMENT 305
;1110\\"s theexpiration timetobedynamically adapted depending ondifferent lease
criteria. They distinguish thefollowing three types ofleases. (Note thatinall
cases. updates arepushed bytheserver aslongastheleasehasnotexpired.)
First,age-based leases aregiven outondataitemsdepending onthelasttime
theitemwasmodified. Theunderlying assumption isthatdatathathavenotbeen
modified foralongtimecanbeexpected toremain unmodified forsometimeyet
tocome. Thisassumption hasshown tobereasonable inthecaseofWeb-based
data.Bygranting long-lasting leases todataitems thatareexpected toremain
unmodified, thenumber ofupdate messages canbestrongly reduced compared to
thecasewhere allleases havethesameexpiration time.
Another leasecriterion ishowoftenaspecific client requests its·cached copy
tobeupdated. Withrenewal-frequency-based leases, aserver willhandouta
long-lasting leasetoaclient whose cache often needs toberefreshed. Onthe
otherhand, aclient thatasksonlyoccasionally foraspecific dataitemwillbe
handed ashort-term leaseforthatitem.Theeffect ofthisstrategy isthattheser-
veressentially keeps trackonlyofthoseclients where itsdataarepopular; more-
over,thoseclients areoffered ahighdegree ofconsistency.
Thelastcriterion isthatofstate-space overhead attheserver. When theserver
realizes thatitisgradually becoming overloaded, itlowers theexpiration timeof
newleases ithands outtoclients. Theeffect ofthisstrategy isthattheserver
needs tokeeptrackoffewer clients asleases expire morequickly. Inotherwords,
theserver dynamically switches toamore stateless mode ofoperation, thereby
offloading itselfsothatitcanhandle requests moreefficiently.
Lnicasting versus Multicasting
Related topushing orpulling updates isdeciding whether unicasting ormulti-
casting should beused.Inunicast communication, whenaserver thatispartofthe
datastoresends itsupdate toNotherservers, itdoessobysending Nseparate
messages, onetoeachserver. Withmulticasting, theunderlying network takes
careofsending amessage efficiently tomultiple receivers.
Inmany cases. itischeaper touseavailable multicasting facilities. An
extreme situation iswhen allreplicas arelocated inthesamelocal-area network
andthathardware broadcasting isavailable. Inthatcase,broadcasting ormulti-
casting amessage isnomoreexpensive thanasingle point-to-point message. Uni-
casting updates would thenbelessefficient.
Multicasting canoftenbeefficiently combined withapush-based approach to
propagating updates. When thetwoarecarefully integrated, aserver thatdecides
topushitsupdates toanumber ofotherservers simply usesasingle multicast
group tosenditsupdates. Incontrast, withapull-based approach, itisgenerally
onlyasingle client orserver thatrequests itscopytobeupdated. Inthatcase,uni-
casting maybethemostefficient solution.306 CONSISTENCY AND REPLICATIONCHAP. 7
7.5CONSISTENCY PROTOCOLS
Sofar,wehavemainly concentrated onvarious consistency models andgen-
eraldesign issues forconsistency protocols. Inthissection, weconcentrate onthe
actual implementation ofconsistency models bytaking alookatseveral consis-
tencyprotocols. Aconsistency protocol describes animplementation ofaspecif-
icconsistency model. Wefollow theorganization ofourdiscussion onconsisten-
cymodels byfirsttaking alookatdata-centric models, followed byprotocols for
client-centric models.
7.5.1 Continuous Consistency
Aspartoftheirwork oncontinuous consistency, YuandVahdat have
developed anumber ofprotocols totackle thethreeforms ofconsistency. Inthe
following, webriefly consider anumber ofsolutions, omitting details forclarity.
Bounding Numerical Deviation
Wefirstconcentrate ononesolution forkeeping thenumerical deviation with-
inbounds. Again, ourpurpose isnottogointoallthedetails foreachprotocol, but
rather togivethegeneral idea.Details forbounding numerical deviation canbe
found inYuandVahdat (2000b).
Weconcentrate onwrites toasingle dataitemx.Eachwrite W(x) hasanas-
sociated weight thatrepresents thenumerical value bywhich xisupdated,
denoted asweight (lV(x)). orsimply weight (W). Forsimplicity, weassume that
weight (W) >O.Eachwrite Wisinitially submitted tooneoutoftheNavailable
replica servers, inwhich casethatserver becomes thewrite's origin, denoted as
origin (W). Ifweconsider thesystem ataspecific moment intimewewillsee
several submitted writes thatstillneedtobepropagated toallservers. Tothisend,
eachserver S,willkeeptrackofalogL,ofwrites thatithasperformed onitsown
localcopyofx.
LetTW[i,j] bethewrites executed byserver S,thatoriginated fromserver Sj:
NotethatTW[i,i] represents theaggregated writes submitted toSi'Ourgoalis
foranytimet,toletthecurrent value Viatserver S,deviate within bounds from
theactual value v(t)ofx.Thisactual value iscompletely determined byallsub-
mitted writes. Thatis.ifr(0)istheinitial valueofx,then
andSEC. 7.5 CONSISTENCY PROTOCOLS 307
Bounding Staleness Deviations
There aremany ways tokeep thestaleness ofreplicas within specified
bounds. Onesimple approach istoletserver Skkeep areal-time vector clock
RVCk where RVCk[i] =T(i) means thatSkhasseenallwrites thathavebeensub-
mitted toS,uptotimeT(i). Inthiscase, weassume thateachsubmitted write is
timestamped byitsorigin server, andthatT(i) denotes thetimelocaltoSi.
Iftheclocks between thereplica servers areloosely synchronized, thenan
acceptable protocol forbounding staleness would bethefollowing. Whenever
server Sknotes thatT(k) -RVCk[i] isabout toexceed aspecified limit, itsimply
starts pulling inwrites thatoriginated from S,with atimestamp later than
RVCk[i]·
Notethatinthiscaseareplica server isresponsible forkeeping itscopy ofx
uptodateregarding writes thathave been issued elsewhere. Incontrast, when
maintaining numerical bounds, wefollowed apushapproach byletting anorigin
server keep replicas uptodatebyforwarding writes. Theproblem withpushing
writes inthecaseofstaleness isthatnoguarantees canbegiven forconsistency
when itisunknown inadvance whatthemaximal propagation timewillbe.This
situation issomewhat improved bypulling inupdates, asmultiple servers canhelp
tokeepaserver's copyofxfresh(uptodate).NotethatVi~V(t).Letusconcentrate onlyonabsolute deviations. Inparticular,
forevery server Si,weassociate anupperbound bisuchthatweneedtoenforce:
Writes submitted toaserver S,willneedtobepropagated toallother servers.
There aredifferent ways inwhich thiscanbedone, buttypically anepidemic pro-
tocolwillallow rapid dissemination ofupdates. Inanycase, when aserver S,pro-
pagates awrite originating from~toSbthelatter willbeabletolearn about the
value TW[i,j] atthetimethewrite wassent.Inother words, Skcanmaintain a
viewTWk[i,j] ofwhatitbelieves S,willhaveasvalue forTW[i,j]. Obviously,
Thewhole ideaisthatwhen server Sknotices thatS,hasnotbeenkeeping in
therightpacewiththeupdates thathavebeen submitted toSbitforwards writes
fromitslogtoSi.Thisforwarding effectively advances theviewl1tl-Hi,k] thatSk
hasofTW[i,k], making thedeviation TIV[i,k] -~[i,k] smaller. Inparticular,
Skadvances itsview onTW[i,k] when anapplication submits anewwrite that
would increase TW[k,k] -~[i,k] beyond bi/(N-1). Weleave itasanexer-
cisetoshow thatadvancement always ensures thatv(t)-Vi~bi•308 CONSISTENCY AND REPLICATION CHAP. 7
Bounding Ordering Deviations
Recall thatordering deviations incontinuous consistency arecaused bythe
factthatareplica server tentatively applies updates thathavebeensubmitted toit.
Asaresult, eachserver willhavealocalqueue oftentative writes forwhich the
actual orderinwhich theyaretobeapplied tothelocalcopyofxstillneeds to,be
determined. Theordering deviation isbounded byspecifying themaximal length
ofthequeue oftentative writes.
Asaconsequence, detecting whenordering consistency needs tobeenforced
issimple: when thelength ofthislocalqueue exceeds aspecified maximal length.
Atthatpoint, aserver willnolonger accept anynewly submitted writes, butwill
instead attempt tocommit tentative writes bynegotiating withother servers in
which order itswrites should beexecuted. Inother words, weneedtoenforce a
globally consistent ordering oftentative writes. There aremany ways indoing
this,butitturnsoutthatso-called primary-based orquorum-based protocols are
usedinpractice. Wediscuss theseprotocols next.
7.5.2 Primary-Based Protocols
Inpractice, weseethatdistributed applications generally follow consistency
models thatarerelatively easytounderstand. These models include those for
bounding staleness deviations, andtoalesser extent alsothoseforbounding num-
erical deviations. When itcomes tomodels thathandle consistent ordering ofop-
erations, sequential consistency, notably thoseinwhich operations canbegrouped
through locking ortransactions arepopular.
Assoonasconsistency models.become slightly difficult tounderstand forap-
plication developers, weseethattheyareignored evenifperformance could be
improved. Thebottom lineisthatifthesemantics ofaconsistency model arenot
intuitively clear, application developers willhaveahardtimebuilding correct ap-
plications. Simplicity isappreciated (andperhaps justifiably so).
Inthecaseofsequential consistency, itturnsoutthatprimary-based protocols
prevail. Intheseprotocols, eachdataitemxinthedatastorehasanassociated pri-
mary, which isresponsible forcoordinating write operations onx.Adistinction
canbemadeastowhether theprimary isfixedataremote server orifwriteoper-
ations canbecarried outlocally aftermoving theprimary totheprocess where the
writeoperation isinitiated. Letustakealookatthisclassofprotocols.
Remote- Write Protocols
Thesimplest primary-based protocol thatsupports replication istheonein
which allwriteoperations needtobeforwarded toafixedsingle server. Readop-
erations canbecarried outlocally. Suchschemes arealsoknown asprimary-
backup protocols (Budhiraja etal.,1993). Aprimary-backup protocol works as
shown inFig.7-20. Aprocess wanting toperform awriteoperation ondataitemSEC.7.5 CONSISTENCY PROTOCOLS 309
x,forwards thatoperation totheprimary server forx.Theprimary performs the
update onitslocalcopyofx,andsubsequently forwards theupdate tothebackup
servers. Each backup server performs theupdate aswell, andsends anack-
nowledgment backtotheprimary. When allbackups haveupdated theirlocal
copy,theprimary sends anacknowledgment backtotheinitial process.
Figure 7-20. Theprinciple ofaprimary-backup protocol.
Apotential performance problem withthisscheme isthatitmaytakearela-
tively longtimebefore theprocess thatinitiated theupdate isallowed tocontinue.
Ineffect, anupdate isimplemented asablocking operation. Analternative isto
useanonblocking approach. Assoonastheprimary hasupdated itslocalcopyof
x,itreturns anacknowledgment. Afterthat,ittellsthebackup servers toperform
theupdate aswell. Nonblocking primary-backup protocols arediscussed in
Budhiraja andMarzullo (1992).
Themainproblem withnonblocking primary-backup protocols hastodowith
faulttolerance. Inablocking scheme, theclient process knows forsurethatthe
update operation isbacked upbyseveral otherservers. Thisisnotthecasewitha
nonblocking solution. Theadvantage, ofcourse, isthatwrite operations may
speed upconsiderably. Wewillreturn tofaulttolerance issues extensively inthe
nextchapter.
Primary-backup protocols provide astraightforward implementation ofse-
quential consistency, astheprimary canorder allincoming writes inaglobally
unique timeorder. Evidently, allprocesses seeallwriteoperations inthesame
order, nomatter which backup server theyusetoperform readoperations. Also,
withblocking protocols, processes willalways seetheeffects oftheirmostrecent
writeoperation (notethatthiscannot beguaranteed withanonblocking protocol
without taking special measures).310 CONSISTENCY AND REPLICA nON CHAP. 7
Local-WriteProtocols
Avariant ofprimary-backup protocols isoneinwhich theprimary copy
migrates between processes thatwishtoperform awrite operation. Asbefore,
whenever aprocess wants toupdate dataitemx,itlocates theprimary copyofx,
andsubsequently moves ittoitsownlocation, asshown inFig.7-21. Themainad-
vantage ofthisapproach isthatmultiple, successive writeoperations canbecar-
riedoutlocally, while reading processes canstillaccess theirlocalcopy. How-
ever,suchanimprovement canbeachieved onlyifanonblocking protocol isfol-
lowed bywhich updates arepropagated tothereplicas aftertheprimary hasfin-
ishedwithlocally performing theupdates.
Figure 7-21. Primary-backup protocol inwhich theprimary migrates tothe
process wanting toperform anupdate.
Thisprimary-backup local-write protocol canalsobeapplied tomobile com-
puters thatareabletooperate indisconnected mode. Before disconnecting, the
mobile computer becomes theprimary server foreachdataitemitexpects toup-
date.While being disconnected, allupdate operations arecarried outlocally.
while otherprocesses canstillperform readoperations (butnoupdates). Later.
when connecting again, updates arepropagated fromtheprimary tothebackups.
bringing thedatastoreinaconsistent stateagain. Wewillreturn tooperating in
disconnected mode inChap. 11whenwediscuss distributed filesystems.
Asalastvariant ofthisscheme, nonblocking local-write primary-based proto-
colsarealsousedfordistributed filesystems ingeneral. Inthiscase,theremaybe
afixedcentral server through which normally allwriteoperations takeplace, asin
thecaseofremote-write primary backup. However, theserver temporarily allows
oneofthereplicas toperform aseries oflocalupdates, asthismayconsiderablySEC. 7.5 CONSISTENCY PROTOCOLS 311
speed upperformance. When thereplica server isdone, theupdates arepropaga-
tedtothecentral server, fromwhere theyarethendistributed totheotherreplica
servers.
7.5.3Replicated-Write Protocols
Inreplicated-write protocols, writeoperations canbecarried outatmultiple
replicas instead ofonlyone,asinthecaseofprimary-based replicas. Adistinction
canbemadebetween active replication, inwhich anoperation isforwarded toall
replicas, andconsistency protocols based onmajority voting.
Active Replication
Inactive replication, eachreplica hasanassociated process thatcarries out
update operations. Incontrast tootherprotocols, updates aregenerally propagated
bymeans ofthewriteoperation thatcauses theupdate. Inotherwords, theopera-
tionissenttoeachreplica. However, itisalsopossible tosendtheupdate, asdis-
cussed before.
Oneproblem withactive replication isthatoperations needtobecarried out
inthesameordereverywhere. Consequently, whatisneeded isatotally-ordered
multicast mechanism. Suchamulticast canbeimplemented usingLamport's logi-
calclocks, asdiscussed intheprevious chapter. Unfortunately, thisimplementa-
tionofmulticasting doesnotscalewellinlargedistributed systems. Asanalterna-
tive,totalordering canbeachieved using acentral coordinator, alsocalled ase-
quencer. Oneapproach istofirstforward eachoperation tothesequencer, which
assigns itaunique sequence number andsubsequently forwards theoperation to
allreplicas. Operations arecarried outintheorder oftheirsequence number.
Clearly, thisimplementation oftotally-ordered multicasting strongly resembles
primary-based consistency protocols.
Notethatusing asequencer doesnotsolvethescalability problem. Infact,if
totally-ordered multicasting isneeded, acombination ofsymmetric multicasting
usingLamport timestamps andsequencers maybenecessary. Suchasolution is
described inRodrigues etal.(1996).
Quorum-Based Protocols
Adifferent approach tosupporting replicated writes istousevoting asorigi-
nallyproposed byThomas (1979) andgeneralized byGifford (1979). Thebasic
ideaistorequire clients torequest andacquire thepermission ofmultiple servers
before either reading orwriting areplicated dataitem.
Asasimple example ofhowthealgorithm works, consider adistributed file
system andsuppose thatafileisreplicated onNservers. Wecould make arule
stating thattoupdate afile,aclient mustfirstcontact atleasthalftheservers plus312 CONSISTENCY AND REPLICATION CHAP. 7
one(amajority) andgetthemtoagree todotheupdate. Oncetheyhaveagreed,
thefileischanged andanewversion number isassociated withthenewfile.The
version number isusedtoidentify theversion ofthefileandisthesameforallthe
newly updated files.
Toreadareplicated file,aclient mustalsocontact atleasthalftheservers
plusoneandaskthemtosendtheversion numbers associated withthefile.Ifall
theversion numbers arethesame, thismustbethemostrecent version because 'an
attempt toupdate onlytheremaining servers would failbecause there arenot
enough ofthem.
Forexample. iftherearefiveservers andaclient determines thatthree of
themhaveversion 8,itisimpossible thattheothertwohaveversion 9.After all,
anysuccessful update fromversion 8toversion 9requires getting threeservers to
agreetoit,notjusttwo.
Gifford's scheme isactually somewhat moregeneral thanthis.Init,toreada
fileofwhich Nreplicas exist,aclient needs toassemble areadquorum, anarbi-
trarycollection ofanyNRservers, ormore. Similarly, tomodify afile,awrite
quorum ofatleastNwservers isrequired. Thevalues ofNRandNwaresubject to
thefollowing twoconstraints:
Thefirstconstraint isusedtoprevent read-write conflicts, whereas thesecond
prevents write-write conflicts. Onlyaftertheappropriate number ofservers has
agreed toparticipate canafilebereadorwritten.
Toseehowthisalgorithm works, consider Fig.7-22(a), which hasNR=3and
Nw=10.Imagine thatthemostrecent writequorum consisted ofthe10servers C
through 1.Allofthesegetthenewversion andthenewversion number. Anysub-
sequent readquorum ofthreeservers willhavetocontain atleastonemember of
thisset.When theclient looks attheversion numbers, itwillknow which ismost
recent andtakethatone.
InFig.7-.22(b) and(c),weseetwomore examples. InFig.7-22(b) awrite-
write conflict mayoccur because Nw$N/2.Inparticular, ifoneclient chooses
{A,B, C,E,F,G} asitswritesetandanother client chooses {D,H,I.J,K,L} asits
write set,thenclearly wewillrunintotrouble asthetwoupdates willbothbe
accepted without detecting thattheyactually conflict.
Thesituation shown inFig.7-22(c) isespecially interesting because itsetsNR
toone,making itpossible toreadareplicated filebyfinding anycopyandusing
it.Thepricepaidforthisgoodreadperformance, however, isthatwriteupdates
needtoacquire allcopies. Thisscheme isgenerally referred toasRead-One,
Write-All (ROW A).There areseveral variations ofquorum-based replication
protocols. Agoodoverview ispresented inJalote (1994).SEC.7.5 CONSISTENCY PROTOCOLS 313
Figure 7-22. Three examples ofthevoting algorithm. (a)Acorrect choice of
readandwrite set.(b)Achoice thatmayleadtowrite-write conflicts. (c)A
correct choice, known asROW A(readone,write all).
7.5.4 Cache-Coherence Protocols
Caches formaspecial caseofreplication, inthesense thattheyaregenerally
controlled byclients instead ofservers. However, cache-coherence protocols,
which ensure thatacache isconsistent withtheserver-initiated replicas are,in
principle, notverydifferent fromtheconsistency protocols discussed sofar.
There hasbeenmuch research inthedesign andimplementation ofcaches,
especially inthecontext ofshared-memory multiprocessor systems. Many solu-
tionsarebased onsupport from theunderlying hardware, forexample, byassum-
ingthatsnooping orefficient broadcasting canbedone. Inthecontext of
middleware-based distributed systems thatarebuilt ontopofgeneral ...purpose
operating systems, software-based solutions tocaches aremore interesting. Inthis
case,twoseparate criteria areoften maintained toclassify caching protocols (Min
andBaer, 1992; Lilja, 1993; andTartalja andMilutinovic, 1997).
First, caching solutions maydiffer intheircoherence detection strategy, that
is,when inconsistencies areactually detected. Instatic solutions, acompiler is
assumed toperform thenecessary analysis prior toexecution, andtodetermine
which datamayactually leadtoinconsistencies because theymaybecached. The
compiler simply inserts instructions thatavoid inconsistencies. Dynamic solutions
aretypically applied inthedistributed systems studied inthisbook. Inthese solu-
tions, inconsistencies aredetected atruntime. Forexample, acheck ismade with
theserver toseewhether thecached datahave been modified since theywere
cached.
Inthecaseofdistributed databases, dynamic detection-based protocols canbe
further classified byconsidering exactly when during atransaction thedetection is
done. Franklin etal.(1997) distinguish thefollowing threecases. First, when dur-
ingatransaction acached dataitemisaccessed, theclient needs toverify whether
thatdataitemisstillconsistent withtheversion stored atthe(possibly replicated)314 CONSISTENCY ANDREPLICATION CHAP. 7
server. Thetransaction cannot proceed tousethecached version untilitsconsis-
tencyhasbeendefinitively validated.
Asecond, optimistic, approach istoletthetransaction proceed while verifica-
tionistaking place. Inthiscase,itisassumed thatthecached datawereuptodate
whenthetransaction started. Ifthatassumption laterproves tobefalse, thetran-
saction willhavetoabort.
Thethirdapproach istoverify whether thecached dataareuptodateonly
whenthetransaction commits. Thisapproach iscomparable totheoptimistic con-
currency control scheme discussed intheprevious chapter. Ineffect. thetrans-
action juststartsoperating onthecached dataandhopes forthebest.Afterallthe
workhasbeendone, accessed dataareverified forconsistency. When staledata
wereused,thetransaction isaborted.
Another design issueforcache-coherence protocols isthecoherence enforce-
ment strategy, which determines howcaches arekeptconsistent withthecopies
stored atservers. Thesimplest solution istodisallow shared datatobecached at
all.Instead, shared dataarekeptonlyattheservers, which maintain consistency
using oneoftheprimary-based orreplication-write protocols discussed above.
Clients areallowed tocache onlyprivate data.Obviously, thissolution canoffer
onlylimited performance improvements.
When shared datacanbecached, therearetwoapproaches toenforce cache
coherence. Thefirstistoletaserver sendaninvalidation toallcaches whenever a
dataitemismodified. Thesecond istosimply propagate theupdate. Mostcaching
systems useoneofthese twoschemes. Dynamically choosing between sending
invalidations orupdates issometimes supported inclient-server databases (Frank-
linetal.,1997).
Finally, wealsoneedtoconsider whathappens when a.process modifies
cached data.When read-only caches areused,update operations canbeperformed
onlybyservers, which subsequently follow some distribution protocol toensure
thatupdates arepropagated tocaches. Inmany cases, apull-based approach isfol-
lowed. Inthiscase,aclient detects thatitscache isstale,andrequests aserver for
anupdate.
Analternative approach istoallow clients todirectly modify thecached data,
andforward theupdate totheservers. Thisapproach isfollowed inwrite-through
caches, which areoftenusedindistributed filesystems. Ineffect, write-through
caching issimilar toaprimary-based local-write protocol inwhich theclient's
cache hasbecome atemporary primary. Toguarantee (sequential) consistency, it
isnecessary thattheclient hasbeengranted exclusive writepermissions, orother-
wisewrite-write conflicts mayoccur.
Write-through caches potentially offer improved performance overother
schemes asalloperations canbecarried outlocally. Further improvements canbe
made ifwedelay thepropagation ofupdates byallowing multiple writes totake
placebefore informing theservers. Thisleadstowhatisknown asawrite-back
cache, which is,again, mainly applied indistributed filesystems.SEC. 7.5 CONSISTENCY PROTOCOLS 315
7.5.5 Implementing Client-Centric Consistency
Forourlasttopic onconsistency protocols, letusdraw ourattention toimple-
menting client-centric consistency. Implementing client-centric consistency is
relatively straightforward ifperformance issues areignored. Inthefollowing
pages, wefirstdescribe suchanimplementation, followed byadescription ofa
more realistic implementation.
ANaive Implementation
Inanaive implementation ofclient-centric consistency, eachwrite operation
Wisassigned aglobally unique identifier. Such anidentifier isassigned bythe
server towhich thewrite hadbeensubmitted. Asinthecaseofcontinuous consis-
tency, werefer tothisserver astheorigin ofW.Then, foreachclient, wekeep
trackoftwosetsofwrites. Thereadsetforaclient consists ofthewrites relevant
forthereadoperations performed byaclient. Likewise, thewrite setconsists of
the(identifiers ofthe)writes performed bytheclient.
Monotonic-read consistency isimplemented asfollows. When aclient per-
forms areadoperation ataserver, thatserver ishanded theclient's readsetto
check whether alltheidentified writes havetaken place locally. (Thesizeofsuch
asetmayintroduce aperformance problem, forwhich asolution isdiscussed
below.) Ifnot,itcontacts theother servers toensure thatitisbrought uptodate
before carrying outthereadoperation. Alternatively, thereadoperation isfor-
warded toaserver where thewrite operations havealready taken place. After the
readoperation isperformed, thewrite operations thathave taken place atthe
selected server andwhich arerelevant forthereadoperation areadded tothe cli-
ent'sreadset.
Note thatitshould bepossible todetermine exactly where thewrite opera-
tionsidentified inthereadsethavetaken place. Forexample, thewrite identifier
could include theidentifier oftheserver towhich theoperation wassubmitted.
Thatserver isrequired to,forexample, logthewrite operation sothatitcanbe
replayed atanother server. Inaddition, write operations should beperformed in
theorder theyweresubmitted. Ordering canbeachieved byletting theclient gen-
erateaglobally unique sequence number thatisincluded inthewrite identifier. If
eachdataitemcanbemodified onlybyitsowner, thelatter cansupply these-
quence number.
Monotonic-write consistency isimplemented analogous tomonotonic reads.
Whenever aclient initiates anewwrite operation ataserver, theserver ishanded
overtheclient's write set.(Again, thesizeofthesetmaybeprohibitively largein
thefaceofperformance requirements. Analternative solution isdiscussed below.)
Itthenensures thattheidentified write operations areperformed firstandinthe
correct order. After performing thenewoperation, thatoperation's write identifier
isadded tothewrite set.Notethatbringing thecurrent server uptodatewiththe316 CONSISTENCY ANDREPLICATION CHAP. 7
client's write setmayintroduce aconsiderable increase intheclient's response
timesince theclient thenwaitfortheoperation tofullycomplete.
Likewise, read-your-writes consistency requires thattheserver where theread
operation isperformed hasseenallthewrite operations intheclient's write set.
Thewrites cansimply befetched from other servers before thereadoperation is
performed, although thismayleadtoapoorresponse time. Alternatively, thecli-
ent-side software cansearch foraserver where theidentified write operations in
theclient's write sethavealready beenperformed.
Finally, writes-follow-reads consistency canbeimplemented byfirstbringing
theselected server uptodatewiththewrite operations intheclient's readset,and
thenlateradding theidentifier ofthewrite operation tothewrite set,along with
theidentifiers inthereadset(which havenowbecome relevant forthewrite oper-
ationjustperformed).
Improving Efficiency
Itiseasytoseethatthereadsetandwrite setassociated witheachclient can
become verylarge. Tokeepthese setsmanageable, aclient's readandwrite oper-
ations aregrouped intosessions. Asession istypically associated withanapplica-
tion:itisopened when theapplication starts andisclosed when itexits. However,
sessions mayalsobeassociated withapplications thataretemporarily exited, such
asuseragents fore-mail. Whenever aclient closes asession, thesetsaresimply
cleared. Ofcourse, ifaclient opens asession thatitnever closes, theassociated
readandwrite setscanstillbecome verylarge.
Themainproblem withthenaive implementation liesintherepresentation of
thereadandwrite sets.Each setconsists ofanumber ofidentifiers forwrite oper-
ations. Whenever aclient forwards areadorwrite request toaserver, a\setof
identifiers ishanded totheserver aswelltoseewhether allwrite operations rel-
evant totherequest havebeencarried outbythatserver.
Thisinformation canbemore efficiently represented bymeans ofvector time-
stamps asfollows. First, whenever aserver accepts anewwrite operation W,it
assigns thatoperation aglobally unique identifier along withatimestamp ts(W).
Asubsequent write operation submitted tothatserver isassigned ahigher-valued
timestamp. Each server S,maintains avector timestamp WVCj, where WVCj U]is
equal tothetimestamp ofthemostrecent write operation originating from Sjthat
hasbeenprocessed bySj.Forclarity, assume thatforeachserver, writes from~
areprocessed intheorder thattheyweresubmitted.
Whenever aclient issues arequest toperform areadorwrite operation 0ata
specific server, thatserver returns itscurrent timestamp along withtheresults of
O.Read andwrite setsaresubsequently represented byvector timestamps. More
specifically, foreach session A,weconstruct avector timestamp SVCA with
SVCA [i]setequal tothemaximum timestamp ofallwrite operations inAthatori-
ginate fromserver Sj:SEC.7.5 CONSISTENCY PROTOCOLS 317
Again, weseehowvector timestamps canprovide anelegant andcompact
wayofrepresenting history inadistributed system.
7.6SUMMARY
There areprimarily tworeasons forreplicating data:improving thereliability
ofadistributed system andimproving performance. Replication introduces acon-
sistency problem: whenever areplica isupdated, thatreplica becomes different
fromtheothers. Tokeepreplicas consistent, weneedtopropagate updates insuch
awaythattemporary inconsistencies arenotnoticed. Unfortunately, doing somay
severely degrade performance, especially inlarge-scale distributed systems.
Theonlysolution tothisproblem istorelaxconsistency somewhat. Different
consistency models exist.Forcontinuous consistency, thegoalissettobounds to
numerical deviation between replicas, staleness deviation, anddeviations inthe
ordering ofoperations.
Numerical deviation refers tothevalue bywhich replicas maybedifferent.
Thistypeofdeviation ishighly application dependent, butcan,forexample, be
usedinreplication ofstocks. Staleness deviation refers tothetimebywhich a
replica isstillconsidered tobeconsistent, despite thatupdates mayhavetaken
place some timeago.Staleness deviation isoftenusedforWebcaches. Finally,
ordering deviation refers tothemaximum number oftentative writes thatmaybe
outstanding atanyserver without having synchronized withtheotherreplica ser-
vers.
Consistent ordering ofoperations hassincelongformed thebasisformany
consistency models. Many variations exist,butonlyafewseemtoprevail among
application developers. Sequential consistency essentially provides thesemantics
thatprogrammers expect inconcurrent programming: allwriteoperations areseen
byeveryone inthesameorder. Lessused,butstillrelevant, iscausal consistency,Inotherwords, thetimestamp ofasession always represents thelatestwriteoper-
ations thathavebeenseenbytheapplications thatarebeing executed aspartof
thatsession. Thecompactness isobtained byrepresenting allobserved writeoper-
ations originating fromthesameserver through asingle timestamp.
Asanexample, suppose aclient, aspartofsession A,logsinatserver Si'To
thatend,itpasses SVCAtoSi'Assume thatSVCAUJ >WVCiUJ. What thismeans
isthatS,hasnotyetseenallthewrites originating from~thattheclient hasseen.
Depending ontherequired consistency, server S,maynowhavetofetchthese
writes before being abletoconsistently report backtotheclient. Oncetheopera-
tionhasbeenperformed, server S,willreturn itscurrent timestamp WvCi. Atthat
point, SVCA isadjusted to:318 CONSISTENCY AND REPLICATION CHAP. 7
which reflects thatoperations thatarepotentially dependent oneachotherarecar-
riedoutintheorderofthatdependency.
Weaker consistency models consider series ofreadandwrite operations. In
particular, theyassume thateachseries isappropriately "bracketed" byaccom-
panying operations onsynchronization variables, suchaslocks. Although thisre-
quires explicit effort fromprogrammers, these models aregenerally easier to
implement inanefficient waythan,forexample, puresequential consistency.
Asopposed tothesedata-centric models, researchers inthefieldofdistributed
databases formobile usershavedefined anumber ofclient-centric consistency
models. Suchmodels donotconsider thefactthatdatamaybeshared byseveral
users, butinstead, concentrate ontheconsistency thatanindividual client should
beoffered. Theunderlying assumption isthataclient connects todifferent repli-
casinthecourse oftime,butthatsuchdifferences should bemade transparent. In
essence, client-centric consistency models ensure thatwhenever aclient connects
toanewreplica, thatreplica isbrought uptodatewiththedatathathadbeen
manipulated bythatclient before, andwhich maypossibly reside atotherreplica
sites.
Topropagate updates, different techniques canbeapplied. Adistinction needs
tobemade concerning what isexactly propagated, towhere updates arepro-
pagated, andbywhom propagation isinitiated. Wecandecide topropagate notifi-
cations, operations, orstate.Likewise, notevery replica always needs tobeup-
dated immediately. Which replica isupdated atwhich timedepends onthedis-
tribution protocol. Finally, achoice canbemade whether updates arepushed to
otherreplicas, orthatareplica pullsinupdates fromanother replica.
Consistency protocols describe specific implementations ofconsistency
models. Withrespect tosequential consistency anditsvariants, adistinction can
bemade between primary-based protocols andreplicated-write protocols. In
primary-based protocols, allupdate operations areforwarded toaprimary copy
thatsubsequently ensures theupdate isproperly ordered andforwarded. In
replicated-write protocols, anupdate isforwarded toseveral replicas atthesame
time.Inthatcase,correctly ordering operations oftenbecomes moredifficult.
PROBLEMS
1.Access toshared Javaobjects canbeserialized bydeclaring itsmethods asbeing syn-
chronized. Isthisenough toguarantee serialization when suchanobject isreplicated?
2.Explain inyourownwords whatthemainreason isforactually considering weak con-
sistency models.
3.Explain howreplication inDNStakesplace, andwhyitactually works sowell.CHAP.7 PROBLEMS 319
~.During thediscussion ofconsistency models, weoften referred tothecontract be-
tween thesoftware anddatastore. Whyissuchacontract needed?
5.Given thereplicas inFig.7-2,whatwould needtobedonetofinalize thevalues inthe
conit suchthatbothAandBseethesame result?
6.InFig.7-7,is001110 alegal output forasequentially consistent memory? Explain
youranswer.
7.Itisoften argued thatweak consistency models impose anextra burden forpro-
grammers. Towhatextent isthisstatement actually true?
8.Does totally-ordered multicasting bymeans ofasequencer andforthesakeofconsis-
tency inactive replication, violate theend-to-end argument insystem design?
9.What kindofconsistency would youusetoimplement anelectronic stock market?
Explain youranswer.
10.Consider apersonal mailbox foramobile user, implemented aspartofawide-area
distributed database. What kindofclient-centric consistency would bemostappropri-
ate?
11.Describe asimple implementation ofread-your-writes consistency fordisplaying Web
pages thathavejustbeenupdated.
12.Tomake matters simple, weassumed thatthere were nowrite-write conflicts in
Bayou. Ofcourse, thisisanunrealistic assumption. Explain howconflicts mayhap-
pen.
13.When using alease, isitnecessary thattheclocks ofaclient andtheserver, respec-
tively, aretightly synchronized?
14.Wehave stated thattotally-ordered multicasting using Lamport's logical clocks does
notscale. Explain why.
15.Show that,inthecaseofcontinuous consistency, having aserver Skadvance itsview
TWk(i,k) whenever itreceives afresh update thatwould increase TW(k,k) -TWk(i,k)
beyond OJ/N-1),ensures thatv(t)- Vj:5OJ.
16.Forcontinuous consistency, wehaveassumed thateachwriteonlyincreases thevalue
ofdataitemx.Sketch asolution inwhich itisalsopossible todecrease x'svalue.
17.Consider anonblocking primary-backup protocol usedtoguarantee sequential consis-
tency inadistributed datastore. Does suchadatastore always provide read-your-
writes consistency?
18.Foractive replication towork ingeneral, itisnecessary thatalloperations becarried
outinthesame order ateachreplica. Isthisordering always necessary?
19.Toimplement totally-ordered multicasting bymeans ofasequencer, oneapproach is
tofirstforward anoperation tothesequencer, which thenassigns itaunique number
andsubsequently multicasts theoperation. Mention twoalternative approaches, and
compare thethreesolutions.
20.Afileisreplicated on10servers. Listallthecombinations ofreadquorum andwrite
quorum thatarepermitted bythevoting algorithm.320 CONSISTENCY AND REPLICA nON CHAP. 7
21.State-based leases areusedtooffload aserver byletting itallow tokeeptrack ofas
fewclients asneeded. Willthisapproach necessarily leadtobetter performance?
22.(Lab assignment) Forthisexercise, youaretoimplement asimple system thatsup-
ports multicast RPC. Weassume thatthere aremultiple, replicated servers andthat
eachclient communicates withaserver through anRPC. However, when dealing with
replication, aclient willneedtosendanRPCrequest toeachreplica. Program thecli-
entsuchthattotheapplication itappears asifasingle RPCissent.Assume youare
replicating forperformance, butthatservers aresusceptible tofailures.8
FAULT TOLERANCE
Acharacteristic feature ofdistributed systems thatdistinguishes themfrom
single-machine systems isthenotion ofpartial failure. Apartial failure mayhap-
penwhenonecomponent inadistributed system fails.Thisfailure mayaffect the
proper operation ofothercomponents, while atthesametimeleaving yetother
components totally unaffected. Incontrast, afailure innondistributed systems is
oftentotalinthesense thatitaffects allcomponents, andmayeasily bringdown
theentire system.
Animportant goalindistributed systems design istoconstruct thesystem in
suchawaythatitcanautomatically recover frompartial failures without seriously
affecting theoverall performance. Inparticular, whenever afailure occurs, the
distributed system should continue tooperate inanacceptable waywhile repairs
arebeing made, thatis,itshould tolerate faults andcontinue tooperate tosome
extent evenintheirpresence.
Inthischapter, wetakeacloser lookattechniques formaking distributed sys-
temsfaulttolerant. Afterproviding somegeneral background onfaulttolerance,
wewilllookatprocess resilience andreliable multicasting. Process resilience
incorporates techniques bywhich oneormoreprocesses canfailwithout seriously
disturbing therestofthesystem. Related tothisissueisreliable multicasting, by
which message transmission toacollection ofprocesses isguaranteed tosucceed.
Reliable multicasting isoftennecessary tokeepprocesses synchronized.
Atomicity isaproperty thatisimportant inmany applications. Forexample,
indistributed transactions, itisnecessary toguarantee thatevery operation ina
321322 FAULT TOLERANCE CHAP. 8
transaction iscarried outornoneofthem are.Fundamental toatomicity indistrib-
utedsystems isthenotion ofdistributed commit protocols, which arediscussed in
aseparate section inthischapter.
Finally, wewillexamine howtorecover fromafailure. Inparticular, wecon-
siderwhen andhowthestateofadistributed system should besaved toallow re-
covery tothatstatelateron.
8.1INTRODUCTION TOFAULT TOLERANCE
Fault tolerance hasbeensubject tomuch research incomputer science. Inthis
section, westartwithpresenting thebasic concepts related toprocessing failures,
followed byadiscussion offailure models. Thekeytechnique forhandling
failures isredundancy, which isalsodiscussed. Formore general information on
faulttolerance indistributed systems, see,forexample Jalote (1994) or(Shooman,
2002).
8.1.1 Basic Concepts
Tounderstand theroleoffaulttolerance indistributed systems wefirstneed
totakeacloser lookatwhatitactually means foradistributed system totolerate
faults. Being faulttolerant isstrongly related towhat arecalled dependable sys-
tems. Dependability isatermthatcovers anumber ofuseful requirements for
distributed systems including thefollowing (Kopetz andVerissimo, 1993):
1.Availability
2.Reliability
3.Safety
4.Maintainability
Availability isdefined astheproperty thatasystem isready tobeusedim-
mediately. Ingeneral, itrefers totheprobability thatthesystem isoperating
correctly. atanygiven moment andisavailable toperform itsfunctions onbehalf
ofitsusers. Inother words, ahighly available system isonethatwillmost likely
beworking atagiven instant intime.
Reliability refers totheproperty thatasystem canruncontinuously without
failure. Incontrast toavailability, reliability isdefined interms ofatimeinterval
instead ofaninstant intime. Ahighly-reliable system isonethatwillmost likely
continue towork without interruption during arelatively longperiod oftime. This
isasubtle butimportant difference when compared toavailability. Ifasystem
goesdown foronemillisecond every hour, ithasanavailability ofover99.9999
percent, butisstillhighly unreliable. Similarly, asystem thatnever crashes butisSEC. 8.1 INTRODUCTION TOFAULT TOLERANCE 323
shutdown fortwoweeks every August hashighreliability butonly96percent
availability. Thetwoarenotthesame.
Safety refers tothesituation thatwhen asystem temporarily failstooperate
correctly, nothing catastrophic happens. Forexample, many process control sys-
tems,suchasthose usedforcontrolling nuclear power plants orsending people
intospace, arerequired toprovide ahighdegree ofsafety. Ifsuchcontrol systems
temporarily failforonlyaverybriefmoment, theeffects could bedisastrous.
Many examples fromthepast(andprobably many moreyettocome) showhow
harditistobuildsafesystems.
Finally, maintainability refers tohoweasyafailed system canberepaired. A-
highly maintainable system mayalsoshow ahighdegree ofavailability, espe-
ciallyiffailures canbedetected andrepaired automatically. However, asweshall
seelaterinthischapter, automatically recovering fromfailures iseasier saidthan
done.
Often, dependable systems arealsorequired toprovide ahighdegree ofsecu-
rity,especially when itcomes toissues suchasintegrity. Wewilldiscuss security
inthenextchapter.
Asystem issaidtofailwhen itcannot meetitspromises. Inparticular, ifa
distributed system isdesigned toprovide itsuserswithanumber ofservices, the
system hasfailed when oneormoreofthoseservices cannot be(completely) pro-
vided. Anerror isapartofasystem's statethatmayleadtoafailure. Forex-
ample, whentransmitting packets across anetwork, itistobeexpected thatsome
packets havebeendamaged when theyarrive atthereceiver. Damaged inthis
context means thatthereceiver mayincorrectly senseabitvalue (e.g.,reading a1
instead ofa0),ormayevenbeunable todetect thatsomething hasarrived.
Thecause ofanerroriscalled afault. Clearly, finding outwhatcaused an
errorisimportant. Forexample, awrong orbadtransmission medium mayeasily
cause packets tobedamaged. Inthiscase,itisrelatively easytoremove thefault.
However, transmission errors mayalsobecaused bybadweather conditions such
asinwireless networks. Changing theweather toreduce orprevent errors isabit
trickier.
Building dependable systems closely relates tocontrolling faults. Adistinc-
tioncanbemadebetween preventing, removing, andforecasting faults (Avizienis
etaI.,2004). Forourpurposes, themostimportant issueisfaulttolerance, mean-
ingthatasystem canprovide itsservices eveninthepresence offaults. Inother
words, thesystem cantolerate faults andcontinue tooperate normally.
Faults aregenerally classified astransient, intermittent, orpermanent. Tran-
sientfaults occur onceandthendisappear. Iftheoperation isrepeated, thefault
goesaway. Abirdflying through thebeamofamicrowave transmitter maycause
lostbitsonsomenetwork (nottomention aroasted bird). Ifthetransmission times
outandisretried, itwillprobably workthesecond time.
Anintermittent faultoccurs, thenvanishes ofitsownaccord, thenreappears,
andsoon.Aloosecontact onaconnector willoftencause anintermittent fault.324 FAULT TOLERANCE CHAP. 8
Intermittent faults cause agreatdealofaggravation because theyaredifficult to
diagnose. Typically, whenthefaultdoctor shows up,thesystem works fine.
Apermanent faultisonethatcontinues toexistuntilthefaulty component is
replaced. Burnt-out chips, software bugs, anddiskheadcrashes areexamples of
permanent faults.
8.1.2FailureModels
Asystem thatfailsisnotadequately providing theservices itwasdesigned
for.Ifweconsider adistributed system asacollection ofservers thatcommuni-
catewithoneanother andwiththeirclients, notadequately providing services
means thatservers, communication channels, orpossibly both,arenotdoing what
theyaresupposed todo.However, amalfunctioning server itselfmaynotalways
bethefaultwearelooking for.Ifsuchaserver depends onotherservers toade-
quately provide itsservices, thecause ofanerrormayneedtobesearched for
somewhere else.
Suchdependency relations appear inabundance indistributed systems. Afail-
ingdiskmaymake lifedifficult forafileserver thatisdesigned toprovide a
highly available filesystem. Ifsuchafileserver ispartofadistributed database,
theproper working oftheentire database maybeatstake, asonlypartofitsdata
maybeaccessible.
Togetabetter grasp onhowserious afailure actually is,several classification
schemes havebeendeveloped. Onesuchscheme isshown inFig.8-1,andis
based onschemes described inCristian (1991) andHadzilacos andToueg (1993).
Figure 8-1.Different types offailures.
Acrashfailureoccurs when aserver prematurely halts, butwasworking
correctly untilitstopped. Animportant aspect ofcrashfailures isthatoncethe
server hashalted, nothing isheard fromitanymore. Atypical example ofacrash
failure isanoperating system thatcomes toagrinding halt,andforwhich thereis
onlyonesolution: reboot it.Many personal computer systems suffer fromcrashSEC. 8.1 INTRODUCTION TOFAULT TOLERANCE 325
failures sooften thatpeople havecome toexpect themtobenormal. Conse-
quently, moving theresetbutton fromthebackofacabinet tothefrontwasdone
forgoodreason. Perhaps onedayitcanbemoved tothebackagain, orevenre-
moved altogether.
Anomission failure occurs when aserver failstorespond toarequest.
Several things might gowrong. Inthecaseofareceive omission failure, possibly
theserver never gottherequest inthefirstplace. Notethatitmaywellbethecase
thattheconnection between aclient andaserver hasbeencorrectly established,
butthattherewasnothread listening toincoming requests. Also, areceive omis-
sionfailure willgenerally notaffect thecurrent stateoftheserver, astheserver is
unaware ofanymessage senttoit.
Likewise, asendomission failure happens whentheserver hasdoneitswork,
butsomehow failsinsending aresponse. Suchafailure mayhappen, forexample,
whenasendbuffer overflows while theserver wasnotprepared forsuchasitua-
tion.Notethat,incontrast toareceive omission failure, theserver maynowbein
astatereflecting thatithasjustcompleted aservice fortheclient. Asaconse-
quence, ifthesending ofitsresponse fails,theserver hastobeprepared forthe
client toreissue itsprevious request.
Other typesofomission failures notrelated tocommunication maybecaused
bysoftware errors suchasinfinite loops orimproper memory management by
which theserver issaidto"hang."
Another classoffailures isrelated totiming. Timing failures occur whenthe
response liesoutside aspecified real-time interval. Aswesawwithisochronous
datastreams inChap. 4,providing datatoosoonmayeasily cause trouble fora
recipient ifthereisnotenough buffer space toholdalltheincoming data.More
common, however, isthataserver responds toolate,inwhich caseaperformance
failure issaidtooccur.
Aserious typeoffailure isaresponse failure, bywhich theserver's response
issimply incorrect. Twokinds ofresponse failures mayhappen. Inthecaseofa
value failure, aserver simply provides thewrong replytoarequest. Forexample,
asearch engine thatsystematically returns Webpages notrelated toanyofthe
search terms used.hasfailed.
Theother typeofresponse failure isknown asastatetransition failure.
Thiskindoffailure happens when theserver reacts unexpectedly toanincoming
request. Forexample, ifaserver receives amessage itcannot recognize, astate
transition failure happens ifnomeasures havebeentaken tohandle suchmes-
sages. Inparticular, afaulty server mayincorrectly takedefault actions itshould
never haveinitiated.
Themostserious arearbitrary failures, alsoknown asByzantine failures.
Ineffect, when arbitrary failures occur, clients should beprepared fortheworst.
Inparticular, itmayhappen thataserver isproducing output itshould never have
produced, butwhich cannot bedetected asbeing incorrect Worse yetafaulty
server mayevenbemaliciously working together withotherservers toproduce326 FAULT TOLERANCE CHAP. 8
intentionally wrong answers. Thissituation illustrates whysecurity isalsoconsid-
eredanimportant requirement when talking about dependable systems. Theterm
"Byzantine" refers totheByzantine Empire, atime(330-1453) andplace (the
Balkans andmodem Turkey) inwhich endless conspiracies, intrigue, anduntruth-
fulness werealleged tobecommon inruling circles. Byzantine faults werefirst
analyzed byPease etal.(1980) andLamport etal.(1982). Wereturn tosuchfail-
uresbelow.
Arbitrary failures areclosely related tocrashfailures. Thedefinition ofcrash
failures aspresented above isthemostbenign wayforaserver tohalt.Theyare
alsoreferred toasfail-stop failures. Ineffect, afail-stop server willsimply stop
producing output insuchawaythatitshalting canbedetected byotherprocesses.
Inthebestcase,theserver mayhavebeensofriendly toannounce itisabout to
crash; otherwise itsimply stops.
Ofcourse, inreallife,servers haltbyexhibiting omission orcrash failures,
andarenotsofriendly astoannounce inadvance thattheyaregoing tostop.Itis
uptotheotherprocesses todecide thataserver hasprematurely halted. However,
insuchfail-silent systems, theother process mayincorrectly conclude thata
server hashalted. Instead, theserver mayjustbeunexpectedly slow, thatis,itis
exhibiting performance failures.
Finally, therearealsooccasions inwhich theserver isproducing random out-
put,butthisoutput canberecognized byotherprocesses asplainjunk.Theserver
isthenexhibiting arbitrary failures, butinabenign way.These faults arealso
referred toasbeing fail-safe.
8.1.3 Failure Masking b)'Redundancy
Ifasystem istobefaulttolerant, thebestitcandoistotrytohidethe
occurrence offailures fromotherprocesses. Thekeytechnique formasking faults
istouseredundancy. Three kinds arepossible: information redundancy, time
redundancy, andphysical redundancy [seealsoJohnson (1995)]. Withinforma-
tionredundancy, extrabitsareadded toallow recovery fromgarbled bits.Forex-
ample, aHamming codecanbeadded totransmitted datatorecover fromnoiseon
thetransmission line.
Withtimeredundancy, anaction isperformed, andthen.ifneedbe,itisper-
formed again. Transactions (seeChap. 1)usethisapproach. Ifatransaction
aborts, itcanberedone withnoharm. Time redundancy isespecially helpful
whenthefaultsaretransient orintermittent.
Withphysical redundancy, extraequipment orprocesses areadded tomake it
possible forthesystem asawhole totolerate thelossormalfunctioning ofsome
components. Physical redundancy canthusbedoneeither inhardware orinsoft-
ware. Forexample, extraprocesses canbeadded tothesystem sothatifasmall
number ofthemcrash, thesystem canstillfunction correctly. Inother words, bySEC. 8.1 INTRODUCTION TOFAULT TOLERANCE 327
Figure 8-2.Triple modular redundancy.
InFig.8-2(b), eachdevice isreplicated threetimes. Following eachstagein
thecircuit isatriplicated voter. Eachvoterisacircuit thathasthreeinputs and
oneoutput. Iftwoorthreeoftheinputs arethesame, theoutput isequal tothat
input. Ifallthreeinputs aredifferent, theoutput isundefined. Thiskindofdesign
isknown asTMR(Triple Modular Redundancy).
Suppose thatelement Azfails.Eachofthevoters, VbVz,andV3getstwo
good(identical) inputs andonerogue input, andeachofthemoutputs thecorrect
value tothesecond stage. Inessence, theeffect ofAzfailing iscompletely mask-
ed,sothattheinputs toBI,Bz,andB3areexactly thesameastheywould have
beenhadnofaultoccurred.
Nowconsider whathappens ifB3andC1arealsofaulty, inaddition toAz·
These effects arealsomasked, sothethreefinaloutputs arestillcorrect.
Atfirstitmaynotbeobvious whythreevoters areneeded ateachstage. After
all,onevotercould alsodetect andpassthough themajority view. However, a
voterisalsoacomponent andcanalsobefaulty. Suppose, forexample, thatvoter
VImalfunctions. TheinputtoBIwillthenbewrong, butaslongaseverything
elseworks, BzandB3willproduce thesameoutput andV4,Vs,andV6willall
produce thecorrect result intostagethree. AfaultinVIiseffectively nodifferentreplicating processes, ahighdegree offaulttolerance maybeachieved. Wereturn
tothistypeofsoftware redundancy below.
Physical redundancy isawell-known technique forproviding faulttolerance.
Itisusedinbiology (mammals havetwoeyes,twoears,twolungs, etc.),aircraft
(747shavefourengines butcanflyonthree), andsports (multiple referees incase
onemisses anevent). Ithasalsobeenusedforfaulttolerance inelectronic circuits
foryears; itisillustrative toseehowithasbeenapplied there. Consider, forex-
ample, thecircuit ofFig.8-2(a). Heresignals passthrough devices A,B,andC,in
sequence. Ifoneofthemisfaulty, thefinalresult willprobably beincorrect.328 FAULT TOLERANCE CHAP. 8
thanafaultinBI.InbothcasesBIproduces incorrect output, butinbothcasesit
isvoteddownlaterandthefinalresult isstillcorrect.
Although notallfault-tolerant distributed systems useTMR, thetechnique is
verygeneral, andshould giveaclearfeeling forwhatafault-tolerant system is,as
opposed toasystem whose individual components arehighly reliable butwhose
organization cannot tolerate faults (i.e.,operate correctly eveninthepresence of
faulty components). Ofcourse, TMR canbeapplied recursively, forexample, 'to
make achiphighly reliable byusing TMR inside it,unknown tothedesigners
whousethechip,possibly intheirowncircuit containing multiple copies ofthe
chipsalongwithvoters.
8.2PROCESS RESILIENCE
Nowthatthebasic issues offaulttolerance havebeendiscussed, letuscon-
centrate onhowfaulttolerance canactually beachieved indistributed systems.
Thefirsttopicwediscuss isprotection against process failures, which isachieved
byreplicating processes intogroups. Inthefollowing pages, weconsider thegen-
eraldesign issues ofprocess groups, anddiscuss whatafault-tolerant group actu-
allyis.Also,welookathowtoreach agreement within aprocess group when one
ormoreofitsmembers cannot betrusted togivecorrect answers.
8.2.1 Design Issues
Thekeyapproach totolerating afaulty process istoorganize several identical
processes intoagroup. Thekeyproperty thatallgroupshave isthatwhen ames-
sageissenttothegroup itself, allmembers ofthegroup receive it.Inthisway,if
oneprocess inagroup fails,hopefully some otherprocess cantakeoverforit
(Guerraoui andSchiper, 1997).
Process groups maybedynamic. Newgroups canbecreated andoldgroups
canbedestroyed. Aprocess canjoinagroup orleave oneduring system opera-
tion.Aprocess canbeamember ofseveral groups atthesametime.Consequent-
ly,mechanisms areneeded formanaging groups andgroup membership.
Groups areroughly analogous tosocial organizations. Alice might bea
member ofabookclub,atennis club,andanenvironmental organization. Ona
particular day,shemight receive mailings (messages) announcing anewbirthday
cakecookbook fromthebookclub,theannual Mother's Daytennis tournament
fromthetennis club,andthestartofacampaign tosavetheSouthern groundhog
fromtheenvironmental organization. Atanymoment, sheisfreetoleave anyor
allofthesegroups, andpossibly joinothergroups.
Thepurpose ofintroducing groups istoallow processes todealwithcollec-
tionsofprocesses asasingle abstraction. Thusaprocess cansendamessage toa
group ofservers without having toknow whotheyareorhowmany thereareor
where theyare,which maychange fromonecalltothenext.SEC. 8.2 PROCESS RESILIENCE 329
FlatGroups versus Hierarchical Groups
Animportant distinction between different groups hastodowiththeirinternal
structure. Insome groups, alltheprocesses areequal. Nooneisbossandalldeci-
sions aremade collectively. Inother groups, some kindofhierarchy exists. For
example, oneprocess isthecoordinator andalltheothers areworkers. Inthis
model, when arequest forwork isgenerated, either byanexternal client orbyone
oftheworkers, itissenttothecoordinator. Thecoordinator thendecides which
worker isbestsuited tocarry itout,andforwards itthere. More complex hierar-
chies arealsopossible, ofcourse. These communication patterns areillustrated in
Fig.8-3.
Figure 8-3.(a)Communication inaflatgroup. (b)Communication inasimple
hierarchical group.
Each ofthese organizations hasitsownadvantages anddisadvantages. The
flatgroup issymmetrical andhasnosingle point offailure. Ifoneoftheprocesses
crashes, thegroup simply becomes smaller, butcanotherwise continue. Adisad-
vantage isthatdecision making ismore complicated. Forexample, todecide any-
thing, avoteoften hastobetaken, incurring some delay andoverhead.
Thehierarchical group hastheopposite properties. Loss ofthecoordinator
brings theentire group toagrinding halt,butas"longasitisrunning, itcanmake
decisions without bothering everyone else.
Group Membership
When group communication ispresent, some method isneeded forcreating
anddeleting groups, aswellasforallowing processes tojoinandleave groups.
Onepossible approach istohaveagroup server towhich allthese requests can
besent.Thegroup server canthenmaintain acomplete databaseofallthegroups330 FAULT TOLERANCE CHAP. 8
andtheirexact membership. Thismethod isstraightforward, efficient, andfairly
easytoimplement. Unfortunately, itshares amajor disadvantage withallcentral-
izedtechniques: asingle point offailure. Ifthegroup server crashes, group
management ceases toexist. Probably mostorallgroups willhavetoberecon-
structed fromscratch, possibly terminating whatever workwasgoing on.
Theopposite approach istomanage group membership inadistributed way.
Forexample, if(reliable) multicasting isavailable, anoutsider cansendames-
sagetoallgroup members announcing itswishtojointhegroup.
Ideally, toleave agroup, amember justsends agoodbye message toevery-
one.Inthecontext offaulttolerance, assuming fail-stop semantics isgenerally not
appropriate. Thetrouble is,thereisnopolite announcement thataprocess crashes
asthereiswhen aprocess leaves voluntarily. Theothermembers havetodiscover
thisexperimentally bynoticing thatthecrashed member nolonger responds to
anything. Onceitiscertain thatthecrashed member isreally down (andnotjust
slow), itcanberemoved fromthegroup.
Another knotty issueisthatleaving andjoining havetobesynchronous with
datamessages being sent.Inotherwords, starting attheinstant thataprocess has
joined agroup, itmustreceive allmessages senttothatgroup. Similarly, assoon
asaprocess hasleftagroup, itmustnotreceive anymoremessages fromthe
group, andtheothermembers mustnotreceive anymoremessages fromit.One
wayofmaking surethatajoinorleave isintegrated intothemessage stream at
therightplaceistoconvert thisoperation intoasequence ofmessages senttothe
whole group.
Onefinalissuerelating togroup membership iswhattodoifsomany ma-
chines godown thatthegroup cannolonger function-at all.Some protocol is
needed torebuild thegroup. Invariably, someprocess willhavetotaketheinitia-
tivetostarttheballrolling, butwhathappens iftwoorthreetryatthesametime?
Theprotocol musttobeabletowithstand this.
8.2.2FailureMasking andReplication
Process groups arepartofthesolution forbuilding fault-tolerant systems. In
particular, having agroup ofidentical processes allows ustomask oneormore
faulty processes inthatgroup. Inother words, wecanreplicate processes and
organize themintoagroup toreplace asingle (vulnerable) process witha(fault
tolerant) group. Asdiscussed intheprevious chapter, therearetwoways toap-
proach such replication: bymeans ofprimary-based protocols, orthrough
replicated-write protocols.
Primary-based replication inthecaseoffaulttolerance generally appears in
theformofaprimary-backup protocol. Inthiscase,agroup ofprocesses isorgan-
izedinahierarchical fashion inwhich aprimary coordinates allwriteoperations.
Inpractice, theprimary isfixed, although itsrolecanbetaken overbyoneoftheSEC. 8.2 PROCESS RESILIENCE 331
backups. ifneedbe.Ineffect, when theprimary crashes, thebackups execute
someelection algorithm tochoose anewprimary.
Asweexplained intheprevious chapter, replicated-write protocols areused
intheformofactive replication, aswellasbymeans ofquorum-based protocols.
These solutions correspond toorganizing acollection ofidentical processes intoa
flatgroup. Themainadvantage isthatsuchgroups havenosingle pointoffailure,
atthecostofdistributed coordination.
Animportant issuewithusing process groups totolerate faults ishowmuch
replication isneeded. Tosimplify ourdiscussion, letusconsider onlyreplicated-
writesystems. Asystem issaidtobekfaulttolerant ifitcansurvive faults ink
components andstillmeetitsspecifications. Ifthecomponents, sayprocesses, fail
silently, thenhaving k+1ofthemisenough toprovide kfaulttolerance. Ifkof
themsimply stop,thentheanswer fromtheotheronecanbeused.
Ontheotherhand, ifprocesses exhibit Byzantine failures, continuing torun
when sickandsending outerroneous orrandom replies, aminimum of2k+1
processors areneeded toachieve kfaulttolerance. Intheworst case,thekfailing
processes could accidentally (orevenintentionally) generate thesame reply.
However, theremaining k+1willalsoproduce thesameanswer, sotheclient or
votercanjustbelieve themajority.
Ofcourse, intheory itisfinetosaythatasystem iskfaulttolerant andjustlet
thek+Iidentical replies outvote thekidentical replies, butinpractice itishard
toimagine circumstances inwhich onecansaywithcertainty thatkprocesses can
failbutk+1processes cannot fail.Thuseveninafault-tolerant system somekind
ofstatistical analysis maybeneeded.
Animplicit precondition forthismodel toberelevant isthatallrequests
arrive atallservers inthesameorder, alsocalled theatomic multicast problem.
Actually, thiscondition canberelaxed slightly, sincereads donotmatter and
somewrites maycommute, butthegeneral problem remains. Atomic multicasting
isdiscussed indetail inalatersection.
8.2.3 Agreement inFaulty Systems
Organizing replicated processes intoagroup helpstoincrease faulttolerance.
Aswementioned, ifaclient canbaseitsdecisions through avoting mechanism,
wecaneventolerate thatkoutof2k+1processes arelyingabout theirresult.
Theassumption wearemaking, however, isthatprocesses donotteamuptopro-
duceawrong result.
Ingeneral, matters become moreintricate ifwedemand thataprocess group
reaches anagreement, which isneeded inmany cases. Some examples are:elect-
ingacoordinator, deciding whether ornottocommit atransaction, dividing up
tasksamong workers. andsynchronization, among numerous otherpossibilities.
When thecommunication andprocesses areallperfect, reaching suchagreement
isoftenstraightforward, butwhentheyarenot,problems arise.332 FAULT TOLERANCE CHAP. 8
Thegeneral goalofdistributed agreement algorithms istohave allthenon-
faulty processes reach consensus onsome issue, andtoestablish thatconsensus
within afinite number ofsteps. Theproblem iscomplicated bythefactthatdif-
ferent assumptions about theunderlying system require different solutions, assum-
ingsolutions evenexist. Turek andShasha (1992) distinguish thefollowing cases,
1.Synchronous versus asynchronous systems. Asystem issynchro-
nousifandonlyiftheprocesses areknown tooperate inalock-step
mode. Formally, thismeans thatthere should besome constant c;?:1,
suchthatifanyprocessor hastaken c+1steps, every other process
hastaken atleast 1step.Asystem thatisnotsynchronous issaidto
beasynchronous.
2.Communication delay isbounded ornot.Delay isbounded ifandon-
lyifweknow thatevery message isdelivered withaglobally and
predetermined maximum time.
3.Message delivery isordered ornot.Inother words, wedistinguish
thesituation where messages from thesame sender aredelivered in
theorder thattheywere sent,fromthesituation inwhich wedonot
havesuchguarantees.
4.Message transmission isdonethrough unicasting ormulticasting.
Asitturns out,reaching agreement isonlypossible forthesituations shown in
Fig.8-4.Inallother cases, itcanbeshown thatnosolution exists. Note thatmost
distributed systems inpractice assume thatprocesses behave asynchronously,
message transmission isunicast, andcommunication delays areunbounded. Asa
consequence, weneedtomake useofordered (reliable) message delivery, suchas
provided asbyTCP. Fig.8-4illustrates thenontrivial nature ofdistributed agree-
ment when processes mayfail.
Theproblem wasoriginally studied byLamport etal.(1982) andisalso
known astheByzantine agreement problem, referring tothenumerous warsin
which several armies needed toreach agreement on,forexample, troop strengths
while being faced withtraitorous generals, conniving lieutenants, andsoon.Con-
siderthefollowing solution, described inLamport etal.(1982). Inthiscase, we
assume thatprocesses aresynchronous, messages areunicast while preserving
ordering, andcommunication delay isbounded. Weassume thatthere areNproc-
esses, where eachprocess iwillprovide avalue Vitotheothers. Thegoalislet
eachprocess construct avector Voflength N,suchthatifprocess iisnonfaulty,
V[iJ =Vi'Otherwise, V[i] isundefined. Weassume thatthere areatmost kfaulty
processes.
InFig.8-5weillustrate theworking ofthealgorithm forthecaseofN=4and
k=1.Forthese parameters, thealgorithm operates infoursteps. Instep1,everySEC. 8.2 PROCESS RESILIENCE 333
Figure 8-4.Circumstances under which distributed agreement canbereached.
nonfaulty process isends Vitoevery other process using reliable unicasting.
Faulty processes maysendanything. Moreover, because weareusingmulticast-
ing,theymaysenddifferent values todifferent processes. LetVi=i.InFig.8-5(a)
weseethatprocess 1reports 1,process 2reports 2,process 3liestoeveryone,
giving x,y,andz,respectively, andprocess 4reports avalue of4.Instep2,the
results oftheannouncements ofstep1arecollected together intheformofthe
vectors ofFig.8-5(b).
Figure 8-5.TheByzantine agreement problem forthreenonfaulty andonefaul-
typrocess. (a)Eachprocess sends theirvalue totheothers. (b)Thevectors that
eachprocess assembles based on(a).(c)Thevectors thateachprocess receives
instep3.
Step3consists ofevery process passing itsvector fromFig.8-5(b) toevery
otherprocess. Inthisway,every process getsthreevectors, onefromevery other
process. Here, too,process 3lies,inventing 12newvalues, athrough 1.There-
sultsofstep3areshown inFig.8-5(c). Finally, instep4,eachprocess examines
theithelement ofeachofthenewly received vectors. Ifanyvaluehasamajority,334 FAULT TOLERANCE CHAP. 8
thatvalue isputintotheresult vector. Ifnovalue hasamajority, thecorrespond-
ingelement oftheresult vector ismarked UNKNOWN. From Fig.8-5(c) wesee
that1,2,and4allcome toagreement onthevalues forVI,v2,andv4,which is
thecorrect result. Whattheseprocesses conclude regarding v3cannot bedecided,
butisalsoirrelevant. ThegoalofByzantine agreement isthatconsensus is
reached onthevalueforthenonfaulty processes only.
Nowletusrevisit thisproblem forN=3andk=1,thatis,onlytwononfaulty
process andonefaulty one,asillustrated inFig.8-6.HereweseethatinFig.8-
6(c)neither ofthecorrectly behaving processes seesamajority forelement 1,ele-
ment2,orelement 3,soallofthemaremarked UNKNOWN. Thealgorithm has
failed toproduce agreement.
Figure 8-6.Thesame asFig.8-5,except nowwithtwocorrect process andone
faulty process.
Intheirpaper, Lamport eta1.(1982) proved thatinasystem withkfaulty
processes, agreement canbeachieved onlyif2k+1correctly functioning proc-
essesarepresent, foratotalof3k+1.Putinslightly different terms, agreement is
possible onlyifmore thantwo-thirds oftheprocesses areworking properly.
Another wayoflooking atthisproblem, isasfollows. Basically, whatwe
needtoachieve isamajority voteamong agroup ofnonfaulty processes regard-
lessofwhether therearealsofaulty onesamong theirmidsts. Iftherearekfaulty
processes, weneedtoensure thattheirvote,along withthatofanycorrect process
whohavebeenmislead bythefaulty ones,stillcorresponds tothemajority voteof
thenonfaulty processes. With2k+1nonfaulty processes, thiscanbeachieved by
.requiring thatagreement isreached onlyifmorethantwo-thirds ofthevotes are
thesame. Inotherwords, ifmorethantwo-thirds oftheprocesses agree onthe
samedecision, thisdecision corresponds tothesamemajority votebythegroup of
nonfaulty processes.
However, reaching agreement canbeevenworse. Fischer eta1.(1985) proved
thatinadistributed system inwhich messages cannot beguaranteed tobe
delivered within aknown, finitetime,noagreement ispossible ifevenoneproc-
essisfaulty (albeit ifthatoneprocess failssilently). Theproblem withsuchsys-
temsisthatarbitrarily slowprocesses areindistinguishable fromcrashed ones
(i.e.,youcannot tellthedeadfromtheliving). Many othertheoretical results areSEC. 8.2 PROCESS RESILIENCE 335
known about when agreement ispossible andwhen itisnot.Surveys ofthesere-
sultsaregiven inBarborak etal.(1993) andTurek andShasha (1992).
Itshould alsobenoted thattheschemes described sofarassume thatnodes
areeither Byzantine, orcollaborative. Thelatter cannot always besimply
assumed when processes arefromdifferent administrative domains. Inthatcase,
theywillmorelikely exhibit rational behavior, forexample, byreporting timeouts
whendoing soischeaper thanexecuting anupdate operation. Howtodealwith
thesecasesisnottrivial. Afirststeptoward asolution iscaptured intheformof
BARfaulttolerance, which stands forByzantine, Altruism, andRationality. '
BARfaulttolerance isdescribed inAiyer etal.(2005).
8.2.4FailureDetection
Itmayhavebecome clearfromourdiscussions sofarthatinordertoproperly
maskfailures, wegenerally needtodetect themaswell.Failure detection isone
ofthecornerstones offaulttolerance indistributed systems. Whatitallboilsdown
toisthatforagroup ofprocesses, nonfaulty members should beabletodecide
whoisstillamember, andwhoisnot.Inotherwords, weneedtobeabletodetect
whenamember hasfailed.
When itcomes todetecting process failures, thereareessentially onlytwo
mechanisms. Either processes actively send"areyoualive?" messages toeach
other(forwhich theyobviously expect ananswer), orpassively waituntilmes-
sages come infromdifferent processes. Thelatter approach makes sense only
whenitcanbeguaranteed thatthereisenough communication between processes.
Inpractice, actively pingingprocesses isusually followed.
There hasbeenahugebodyoftheoretical workonfailure detectors. Whatit
allboilsdown toisthatatimeout mechanism isusedtocheck whether aprocess
hasfailed. Inrealsettings, therearetwomajor problems withthisapproach. First,
duetounreliable networks, simply stating thataprocess hasfailed because itdoes
notreturn ananswer toapingmessage maybewrong. Inotherwords, itisquite
easytogenerate falsepositives. Ifafalsepositive hastheeffect thataperfectly
healthy process isremoved fromamembership list,thenclearly wearedoing
something wrong.
Another serious problem isthattimeouts arejustplaincrude. Asnoticed by
Birman (2005), there ishardly anywork onbuilding proper failure detection
subsystems thattakemoreintoaccount thanonlythelackofareplytoasingle
message. Thisstatement isevenmoreevident when looking atindustry-deployed
distributed systems.
There arevarious issues thatneedtobetaken intoaccount when designing a
failure detection subsystem [seealsoZhuang etal.(2005)]. Forexample, failure
detection cantakeplace through gossiping inwhich each node regularly
announces toitsneighbors thatitisstillupandrunning. Aswementioned, an
alternative istoletnodes actively probe eachother.336 FAULT TOLERANCE CHAP. 8
Failure detection canalsobedoneasaside-effect ofregularly exchanging in-
formation withneighbors, asisthecasewithgossip-based information dissemina-
tion(which wediscussed inChap. 4).Thisapproach isessentially alsoadopted in
Obduro (Vogels, 2003): processes periodically gossip theirservice availability.
Thisinformation isgradually disseminated through thenetwork bygossiping.
Eventually, every process willknow about every otherprocess, butmoreimpor-
tantly, willhaveenough information locally available todecide whether aprocess
hasfailed ornot.Amember forwhich theavailability information isold,will
presumably havefailed.
Another important issueisthatafailure detection subsystem should ideally be
abletodistinguish network failures fromnodefailures. Onewayofdealing with
thisproblem isnottoletasingle nodedecide whether oneofitsneighbors has
crashed. Instead, whennoticing atimeout onapingmessage, anoderequests oth-
erneighbors toseewhether theycanreach thepresumed failing node. Ofcourse,
positive information canalsobeshared: ifanodeisstillalive, thatinformation
canbeforwarded tootherinterested parties (whomaybedetecting alinkfailure
tothesuspected node).
Thisbrings ustoanother keyissue: when amember failure isdetected, how
should othernonfaulty processes beinformed? Onesimple, andsomewhat radical
approach istheonefollowed inFUSE (Dunagan etal.,2004). InFUSE, proc-
essescanbejoined inagroup thatspans awide-area network. Thegroup mem-
berscreate aspanning treethatisusedformonitoring member failures. Members
sendpingmessages totheirneighbors. When aneighbor doesnotrespond, the
pinging nodeimmediately switches toastateinwhich itwillalsonolonger re-
spond topings fromothernodes. Byrecursion, itisseenthatasingle nodefailure
israpidly promoted toagroup failure notification. FUSE doesnotsuffer alot
fromlinkfailures forthesimple reason thatitrelies onpoint-to-point TCPcon-
nections between group members.
8.3RELIABLE CLIENT-SERVER COMMUNICATION
Inmany cases, faulttolerance indistributed systems concentrates onfaulty
processes. However, wealsoneedtoconsider communication failures. Most of
thefailure models discussed previously apply equally welltocommunication
channels. Inparticular, acommunication channel mayexhibit crash, omission,
timing, andarbitrary failures. Inpractice, when building reliable communication
channels, thefocus isonmasking crash andomission failures. Arbitrary failures
mayoccur intheformofduplicate messages, resulting fromthefactthatina
computer network messages maybebuffered forarelatively longtime, andare
reinjected intothenetwork aftertheoriginal sender hasalready issued a
retransmission [see,forexample, Tanenbaum, 2003)].SEC. 8.3 RELIABLE CLIENT-SERVER COMMUNICATION 337
8.3.1 Point-to-Point Communication
Inmany distributed systems, reliable point-to-point communication isesta-
blished bymaking useofareliable transport protocol, suchasTCP.TCPmasks
omission failures, which occur intheformoflostmessages, byusing ack-
nowledgments andretransmissions. Suchfailures arecompletely hidden froma
TCPclient.
However, crash failures ofconnections arenotmasked. Acrash failure may
occur when(forwhatever reason) aTCPconnection isabruptly broken sothatno
moremessages canbetransmitted through thechannel. Inmostcases, theclient is
informed thatthechannel hascrashed byraising anexception. Theonlywayto
masksuchfailures istoletthedistributed system attempt toautomatically setupa
newconnection, bysimply resending aconnection request. Theunderlying
assumptioriis thattheothersideisstill,oragain, responsive tosuchrequests.
8.3.2RPCSemantics inthePresence ofFailures
Letusnowtakeacloser lookatclient-server communication when using
high-level communication facilities suchasRemote Procedure Calls(RPCs). The
goalofRPCistohidecommunication bymaking remote procedure callslookjust
likelocalones.Withafewexceptions, sofarwehavecome fairlyclose. Indeed,
aslongasbothclient andserver arefunctioning perfectly, RPCdoesitsjobwell.
Theproblem comes about when errors occur. Itisthenthatthedifferences be-
tween localandremote callsarenotalways easytomask.
Tostructure ourdiscussion, letusdistinguish between fivedifferent classes of
failures thatcanoccur inRPCsystems, asfollows:
1.Theclient isunable tolocate theserver.
2.Therequest message fromtheclient totheserver islost.
3.Theserver crashes afterreceiving arequest.
4.Thereplymessage fromtheserver totheclient islost.
5.Theclient crashes aftersending arequest.
Eachofthesecategories poses different problems andrequires different solutions.
Client Cannot Locate theServer
Tostartwith,itcanhappen thattheclient cannot locate asuitable server. All
servers might bedown, forexample. Alternatively, suppose thattheclient iscom-
piledusingaparticular version oftheclient stub,andthebinary isnotusedfora
considerable period oftime.Inthemeantime, theserver evolves andanewver-
sionoftheinterface isinstalled; newstubsaregenerated andputintouse.When338 FAULT TOLERANCE CHAP. 8
theclient iseventuaIJy run,thebinder willbeunable tomatch itupwithaserver
andwillreport failure. While thismechanism isusedtoprotect theclient fromac-
cidentally trying totalktoaserver thatmaynotagreewithitinterms ofwhatpa-
rameters arerequired orwhatitissupposed todo,theproblem remains ofhow
should thisfailure bedealtwith.
Onepossible solution istohavetheerrorraiseanexception. Insomelan-
guages, (e.g.,Java), programmers canwritespecial procedures thatareinvoked
uponspecific errors, suchasdivision byzero.InC,signal handlers canbeused
forthispurpose. Inother words, wecould define anewsignal typeSIGNO-
SERVER, andallow ittobehandled inthesamewayasothersignals.
Thisapproach, too,hasdrawbacks. Tostartwith, notevery language has
exceptions orsignals. Another pointisthathaving towriteanexception orsignal
handler destroys thetransparency wehavebeentrying toachieve. Suppose that
youareaprogrammer andyourbosstellsyoutowritethesumprocedure. You
smileandtellheritwillbewritten, tested, anddocumented infiveminutes. Then
shementions thatyoualsohavetowriteanexception handler aswell,justincase
theprocedure isnottheretoday. Atthispointitispretty hardtomaintain theillu-
sionthatremote procedures arenodifferent fromlocalones, since writing an
exception handler for"Cannot locate server" would bearather unusual request in
asingle-processor system. Somuchfortransparency.
LostRequest Messages
Thesecond itemonthelistisdealing withlostrequest messages. Thisisthe
easiest onetodealwith:justhavetheoperating system orclient stubstartatimer
when sending therequest. Ifthetimerexpires before areplyoracknowledgment
comes back, themessage issentagain. Ifthemessage wastrulylost,theserver
willnotbeabletotellthedifference between theretransmission andtheoriginal,
andeverything willworkfine.Unless, ofcourse, somany request messages are
lostthattheclient givesupandfalsely concludes thattheserver isdown, inwhich
casewearebackto"Cannot locate server." Iftherequest wasnotlost,theonly
thing weneedtodoislettheserver beabletodetect itisdealing witha
retransmission. Unfortunately, doing soisnotsosimple, asweexplain when dis-
cussing lostreplies.
Server Crashes
Thenextfailure onthelistisaserver crash. Thenormal sequence ofevents at
aserver isshown inFig.8-7(a). Arequest arrives, iscarried out,andareplyis
sent.Nowconsider Fig.8-7(b). Arequest arrives andiscarried out,justasbe-
fore,buttheserver crashes before itcansendthereply. Finally, lookatFig.8-
7(c).Again arequest arrives, butthistimetheserver crashes before itcaneven
becarried out.And,ofcourse, noreplyissentback.SEC. 8.3 RELIABLE CLIENT-SERVER COMMUNICATION 339
Figure 8-7.Aserver inclient-server communication. (a)Thenormal case.
(b)Crash afterexecution. (c)Crash before execution.
Theannoying partofFig.8-7isthatthecorrect treatment differs for(b)and
(c).In(b)thesystem hastoreport failure backtotheclient (e.g.,raise,anexcep-
tion),whereas in(c)itcanjustretransmit therequest. Theproblem isthatthecli-
ent'soperating system cannot tellwhich iswhich. Allitknows isthatitstimerhas
expired.
Three schools ofthought existonwhattodohere(Spector, 1982). Onephilo-
sophy istowaituntiltheserver reboots (orrebind toanewserver) andtrytheop-
eration again. Theideaistokeeptrying untilareplyhasbeenreceived, thengive
ittotheclient. Thistechnique iscalled atleastoncesemantics andguarantees
thattheRPChasbeencarried outatleastonetime,butpossibly more.
Thesecond philosophy gives upimmediately andreports backfailure. This
wayiscalled at-most-once semantics andguarantees thattheRPChasbeencar-
riedoutatmostonetime,butpossibly noneatall.
Thethirdphilosophy istoguarantee nothing. When aserver crashes, thecli-
entgetsnohelpandnopromises about whathappened. TheRPCmayhavebeen
carried outanywhere fromzerotoalargenumber oftimes. Themainvirtue of
thisscheme isthatitiseasytoimplement.
None ofthese areterribly attractive. What onewould likeisexactly once
semantics, butingeneral, thereisnowaytoarrange this.Imagine thattheremote
operation consists ofprinting some text,andthattheserver sends acompletion
message totheclient when thetextisprinted. Alsoassume thatwhen aclient
issues arequest, itreceives anacknowledgment thattherequest hasbeen
delivered totheserver. There aretwostrategies theserver canfollow. Itcaneither
sendacompletion message justbefore itactually tellstheprinter todoitswork,
orafterthetexthasbeenprinted.
Assume thattheserver crashes andsubsequently recovers. Itannounces toall
clients thatithasjustcrashed butisnowupandrunning again. Theproblem is
thattheclient doesnotknow whether itsrequest toprintsometextwillactually be
carried out.
There arefourstrategies theclient canfollow. First,theclient candecide to
never reissue arequest, attheriskthatthetextwillnotbeprinted. Second, itcan
decide toalways reissue arequest, butthismayleadtoitstextbeing printed
twice. Third, itcandecide toreissue arequest onlyifitdidnotyetreceive anTheparentheses indicate anevent thatcannolonger happen because theserver
already crashed. Fig.8-8shows allpossible combinations. Ascanbereadily veri-
fied,there isnocombination ofclient strategy andserver strategy thatwillwork
correctly under allpossible event sequences. Thebottom lineisthattheclient can
never know whether theserver crashed justbefore orafterhaving thetextprinted.
Figure 8-8.Different combinations ofclient andserver strategies inthepres-
enceofserver crashes.acknowledgment thatitsprint request hadbeen delivered totheserver. Inthat
case, theclient iscounting onthefactthattheserver crashed before theprintre-
quest could bedelivered. Thefourth andlaststrategy istoreissue arequest onlyif
ithasreceived anacknowledgment fortheprintrequest.
With twostrategies fortheserver, andfourfortheclient, there areatotalof
eight combinations toconsider. Unfortunately, nocombination issatisfactory. To
explain, notethatthere arethree events thatcanhappen attheserver: sendthe
completion message (M),printthetext(P),andcrash (C).These events canoccur
insixdifferent orderings:
1.M~P~C:Acrash occurs aftersending thecompletion message
andprinting thetext.
2.M~C(~P): Acrash happens aftersending thecompletion mes-
sage,butbefore thetextcould beprinted.
3.p~M~C:Acrash occurs aftersending thecompletion message
andprinting thetext.
4.P~C( ~M): Thetextprinted, afterwhich acrash occurs before the
completion message could besent.
5.C(~P ~M): Acrash happens before theserver could doanything.
6.C(~M ~P): Acrash happens before theserver could doanything.340 FAULT TOLERANCE CHAP. 8SEC. 8.3 RELIABLE CLIENT-SERVER COMMUNICATION 341
Inshort, thepossibility ofserver crashes radically changes thenature ofRPC
andclearly distinguishes single-processor systems fromdistributed systems. Inthe
former case,aserver crashalsoimplies aclient crash, sorecovery isneither pos-
siblenornecessary. Inthelatteritisbothpossible andnecessary totakeaction.
LostReply Messages
Lostreplies canalsobedifficult todealwith.Theobvious solution isjustto
relyonatimeragainthathasbeensetbytheclient's operating system. Ifnoreply
isforthcoming within areasonable period, justsendtherequest oncemore. The
trouble withthissolution isthattheclient isnotreally surewhytherewasnoans-
wer.Didtherequest orreplygetlost,oristheserver merely slow? Itmaymake a
difference.
Inparticular, some operations cansafely berepeated asoften asnecessary
withnodamage being done. Arequest suchasasking forthefirst1024bytesofa
filehasnosideeffects andcanbeexecuted asoftenasnecessary without any
harmbeing done.Arequest thathasthisproperty issaidtobeidempotent.
Nowconsider arequest toabanking server asking totransfer amillion dollars
fromoneaccount toanother. Iftherequest arrives andiscarried out,butthereply
islost,theclient willnotknow thisandwillretransmit themessage. Thebank
server willinterpret thisrequest asanewone,andwillcarryitouttoo.Twomil-
liondollars willbetransferred. Heaven forbid thatthereply islost10times.
Transferring money isnotidempotent.
Onewayofsolving thisproblem istotrytostructure alltherequests inan
idempotent way.Inpractice, however, many requests (e.g.,transferring money)
areinherently nonidempotent, sosomething elseisneeded. Another method isto
havetheclient assign eachrequest asequence number. Byhaving theserver keep
trackofthemostrecently received sequence number fromeachclient thatisusing
it,theserver cantellthedifference between anoriginal request andaretransmis-
sionandcanrefuse tocarryoutanyrequest asecond time.However, theserver
willstillhavetosendaresponse totheclient. Notethatthisapproach doesrequire
thattheserver maintains administration oneachclient. Furthermore, itisnotclear
howlongtomaintain thisadministration. Anadditional safeguard istohaveabit
inthemessage header thatisusedtodistinguish initial requests fromretransmis-
sions(theideabeing thatitisalways safetoperform anoriginal request; retrans-
missions mayrequire morecare).
Client Crashes
Thefinalitemonthelistoffailures istheclient crash. Whathappens ifacli-
entsends arequest toaserver todosome workandcrashes before theserver
replies? Atthispointacomputation isactive andnoparent iswaiting forthere-
sult.Suchanunwanted computation iscalled anorphan.342 FAULT TOLERANCE CHAP. 8
Orphans cancause avariety ofproblems thatcaninterfere withnormal opera-
tionofthesystem. Asabareminimum, theywaste CPUcycles. They canalso
lockfilesorotherwise tieupvaluable resources. Finally, iftheclient reboots and
doestheRPCagain, butthereplyfromtheorphan comes backimmediately after-
ward, confusion canresult.
What canbedoneabout orphans? Nelson (1981) proposed foursolutions. In
solution 1,before aclient stubsends anRPCmessage, itmakes alogentrytelling
whatitisabout todo.Thelogiskeptondiskorsomeothermedium thatsurvives
crashes. Afterareboot, thelogischecked andtheorphan isexplicitly killed off.
Thissolution iscalled orphan extermination.
Thedisadvantage ofthisscheme isthehorrendous expense ofwriting adisk
record forevery RPC. Furthermore, itmaynotevenwork, since orphans them-
selves maydoRPCs, thuscreating grandorphans orfurther descendants thatare
difficult orimpossible tolocate. Finally, thenetwork maybepartitioned, duetoa
failed gateway, making itimpossible tokillthem, eveniftheycanbelocated. All
inall,thisisnotapromising approach.
Insolution 2.called reincarnation, alltheseproblems canbesolved without
theneedtowritediskrecords. Thewayitworks istodivide timeupintosequen-
tiallynumbered epochs. When aclient reboots, itbroadcasts amessage toallma-
chines declaring thestartofanewepoch. When suchabroadcast comes in,allre-
motecomputations onbehalf ofthatclient arekilled. Ofcourse, ifthenetwork is
partitioned, someorphans maysurvive. Fortunately, however, when theyreport
back, theirreplies willcontain anobsolete epoch number, making themeasyto
detect.
Solution 3isavariant onthisidea,butsomewhat lessdraconian. Itiscalled
gentle reincarnation. When anepoch broadcast comes in,eachmachine checks
toseeifithasanyremote computations running locally, andifso,triesitsbestto
locate theirowners. Onlyiftheowners cannot belocated anywhere isthecompu-
tation killed.
Finally, wehavesolution 4,expiration, inwhich eachRPCisgiven astan-
dardamount oftime,T,todothejob.Ifitcannot finish, itmustexplicitly askfor
another quantum, which isanuisance. Ontheotherhand, ifafteracrashtheclient
waits atimeTbefore rebooting, allorphans aresuretobegone. Theproblem to
besolved hereischoosing areasonable valueofTinthefaceofRPCs withwildly
differing requirements.
Inpractice, allofthesemethods arecrude andundesirable. Worse yet,killing
anorphan mayhaveunforeseen consequences. Forexample, suppose thatan
orphan hasobtained locksononeormorefilesordatabaserecords. Iftheorphan
issuddenly killed, these locks mayremain forever. Also, anorphan mayhave
already madeentries invarious remote queues tostartupotherprocesses atsome
future time,soevenkilling theorphan maynotremove alltraces ofit.Conceiv-
ably,itmayevenstarted again, withunforeseen consequences. Orphan elimina-
tionisdiscussed inmoredetail byPanzieri andShrivastava (1988).SEC. 8.4 RELIABLE GROUP COMMUNICATION 343
8.4RELIABLE GROUP COMMUNICATION
Considering howimportant process resilience byreplication is,itisnot
surprising thatreliable multicast services areimportant aswell.Suchservices
guarantee thatmessages aredelivered toallmembers inaprocess group. Unfor-
tunately, reliable multicasting turnsouttobesurprisingly tricky. Inthissection,
wetakeacloser lookattheissues involved inreliably delivering messages toa
process group.
8.4.1 Basic Reliable-Multicasting Schemes
Although most transport layers offerreliable point-to-point channels, they
rarely offerreliable communication toacollection ofprocesses. Thebesttheycan
offeristoleteachprocess setupapoint-to-point connection toeachotherprocess
itwants tocommunicate with.Obviously, suchanorganization isnotveryeffi-
cientasitmaywaste network bandwidth. Nevertheless, ifthenumber ofproc-
essesissmall, achieving reliability through multiple reliable point-to-point chan-
nelsisasimple andoftenstraightforward solution.
Togobeyond thissimple case,weneedtodefine precisely whatreliable mul-
ticasting is.Intuitively, itmeans thatamessage thatissenttoaprocess group
should bedelivered toeachmember ofthatgroup. However, whathappens ifdur-
ingcommunication aprocess joinsthegroup? Should thatprocess alsoreceive the
message? Likewise, weshould alsodetermine whathappens ifa(sending) process
crashes during communication.
Tocover suchsituations, adistinction should bemade between reliable com-
munication inthepresence offaulty processes, andreliable communication when
processes areassumed tooperate correctly. Inthefirstcase,multicasting iscon-
sidered tobereliable whenitcanbeguaranteed thatallnonfaulty group members
receivethemessage. Thetricky partisthatagreement should bereached onwhat
thegroup actually lookslikebefore amessage canbedelivered, inaddition tovar-
iousordering constraints. Wereturn tothesematters when wediscussw atomic
multicasts below.
Thesituation becomes simpler ifweassume agreement exists onwhoisa
member ofthegroup andwhoisnot.Inparticular, ifweassume thatprocesses do
notfail,andprocesses donotjoinorleave thegroup while communication is
going on,reliable multicasting simply means thatevery message should bede-
livered toeachcurrent group member. Inthesimplest case,thereisnorequire-
mentthatallgroup members receive messages inthesameorder, butsometimes
thisfeature isneeded.
Thisweaker formofreliable multicasting isrelatively easytoimplement,
again subject tothecondition thatthenumber ofreceivers islimited. Consider
thecasethatasingle sender wants tomulticast amessage tomultiple receivers.344 FAULT TOLERANCE CHAP. 8
Assume thattheunderlying communication system offers onlyunreliable multi-
casting, meaning thatamulticast message maybelostpartwayanddelivered to
some, butnotall,oftheintended receivers.
Figure 8-9.Asimple solution toreliable multicasting when allreceivers are
known andareassumed nottofail.(a)Message transmission. (b)Reporting
feedback.
Asimple solution isshown inFig.8-9.Thesending process assigns ase-
quence number toeachmessage itmulticasts. Weassume thatmessages arere-
ceived intheordertheyaresent.Inthisway,itiseasyforareceiver todetect itis
missing amessage. Eachmulticast message isstored locally inahistory buffer at
thesender. Assuming thereceivers areknown tothesender, thesender simply
keeps themessage initshistory buffer untileachreceiver hasreturned anacknow-
ledgment. Ifareceiver detects itismissing amessage, itmayreturn anegative
acknowledgment, requesting thesender foraretransmission. Alternatively, the
sender mayautomatically retransmit themessage whenithasnotreceived allack-
nowledgments within acertain time.
There arevarious design trade-offs tobemade. Forexample, toreduce the
number ofmessages returned tothesender, acknowledgments could possibly be
piggybacked withother messages. Also, retransmitting amessage canbedone
using point-to-point communication toeachrequesting process, orusing asingle
multicast message senttoallprocesses. Aextensive anddetailed survey oftotal-
orderbroadcasts canbefound inDefago etal.(2004).SEC. 8.4 RELIABLE GROUP COMMUNICATION 345
8.4.2Scalability inReliableMulticasting
Themainproblem withthereliable multicast scheme justdescribed isthatit
cannot support largenumbers ofreceivers. IfthereareNreceivers, thesender
mustbeprepared toaccept atleastNacknowledgments. Withmany receivers, the
sender maybeswamped withsuchfeedback messages, which isalsoreferred to
asafeedback implosion. Inaddition, wemayalsoneedtotakeintoaccount that
thereceivers arespread across awide-area network.
Onesolution tothisproblem isnottohavereceivers acknowledge thereceipt
ofamessage. Instead, areceiver returns afeedback message onlytoinform the
sender itismissing amessage. Returning onlysuchnegative acknowledgments
canbeshown togenerally scalebetter [see,forexample, Towsley etal.(1997)]~
butnohardguarantees canbegiventhatfeedback implosions willneverhappen.
Another problem withreturning onlynegative acknowledgments isthatthe
sender will,intheory, beforced tokeepamessage initshistory buffer forever.
Because thesender cannever know ifamessage hasbeencorrectly delivered to
allreceivers, itshould always beprepared forareceiver requesting theretrans-
mission ofanoldmessage. Inpractice, thesender willremove amessage fromits
history buffer aftersometimehaselapsed toprevent thebuffer fromoverflowing.
However, removing amessage isdoneattheriskofarequest foraretransmission
notbeing honored.
Several proposals forscalable reliable multicasting exist. Acomparison be-
tween different schemes canbefound inLevine andGarcia-Luna-Aceves (1998).
Wenowbriefly discuss twoverydifferent approaches thatarerepresentative of
manyexisting solutions.
Nonhierarchical Feedback Control
Thekeyissuetoscalable solutions forreliable multicasting istoreduce the
number offeedback messages thatarereturned tothesender. Apopular model
thathasbeenapplied toseveral wide-area applications isfeedback suppression.
Thisscheme underlies theScalable Reliable Multicasting (SRM) protocol
developed byFloyd etal.(1997) andworks asfollows.
First,inSRM, receivers never acknowledge thesuccessful delivery ofamul-
ticast message, butinstead, report onlywhen theyaremissing amessage. How
message lossisdetected islefttotheapplication. Onlynegative acknowledgments
arereturned asfeedback. Whenever areceiver notices thatitmissed amessage, it
multicasts itsfeedback totherestofthegroup.
Multicasting feedback allows another group member tosuppress itsownfeed-
back.Suppose several receivers missed message m.Eachofthemwillneedtore-
turnanegative acknowledgment tothesender, S,sothatmcanberetransmitted.
However, ifweassume thatretransmissions arealways multicast totheentire
group, itissufficient thatonlyasingle request forretransmission reaches S.346 FAULT TOLERANCE CHAP. 8
Forthisreason, areceiver Rthatdidnotreceive message 111schedules afeed-
backmessage withsome random delay. Thatis,therequest forretransmission is
notsentuntilsome random timehaselapsed. If,inthemeantime, another request
forretransmission formreaches R,Rwillsuppress itsownfeedback, knowing
thatmwillberetransmitted shortly. Inthisway, ideally, onlyasingle feedback
message willreach S,which inturnsubsequently retransmits m.Thisscheme is
shown inFig.8-10.
Figure 8·10. Several receivers havescheduled arequest forretransmission, but
thefirstretransmission request leadstothesuppression ofothers.
Feedback suppression hasshown toscale reasonably well, andhasbeenused
astheunderlying mechanism foranumber ofcollaborative Internet applications,
suchasashared whiteboard. However, theapproach alsointroduces anumber of
serious problems. First, ensuring thatonlyonerequest forretransmission isre-
turned tothesender requires areasonably accurate scheduling offeedback mes-
sages ateachreceiver. Otherwise, many receivers willstillreturn theirfeedback
atthesame time. Setting timers accordingly inagroup ofprocesses thatis
dispersed across awide-area network isnotthateasy.
Another problem isthatmulticasting feedback alsointerrupts those processes
towhich themessage hasbeen successfully delivered. Inother words, other re-
ceivers areforced toreceive andprocess messages thatareuseless tothem. The
onlysolution tothisproblem istoletreceivers thathavenotreceived message 111
joinaseparate multicast group form,asexplained inKasera etal.(1997). Unfor-
tunately, thissolution requires thatgroups canbemanaged inahighly efficient
manner, which ishardtoaccomplish inawide-area system. Abetter approach is
therefore toletreceivers thattendtomissthesame messages team upandshare
thesame multicast channel forfeedback messages andretransmissions. Details on
thisapproach arefound inLiuetal.(1998).
Toenhance thescalability ofSRM, itisuseful toletreceivers assist inlocal
recovery. Inparticular, ifareceiver towhich message mhasbeen successfully
delivered, receives arequest forretransmission, itcandecide tomulticast meven
before theretransmission request reaches theoriginal sender. Further details can
befound inFloyd etal.(1997) andLiuetaI.(1998).SEC. 8.4 RELIABLE GROUP COMMUNICATION 347
Hierarchical Feedback Control
Feedback suppression asjustdescribed isbasically anonhierarchical solution.
However, achieving scalability forverylarge groups ofreceivers requires that
hierarchical approaches areadopted. Inessence, ahierarchical solution toreliable
multicasting works asshown inFig.8-11.
Figure 8-11. Theessence ofhierarchical reliable multicasting. Eachlocalcoor-
dinator forwards themessage toitschildren andlaterhandles retransmission re-
quests.
Tosimplify matters, assume there isonlyasingle sender thatneeds tomulti-
castmessages toaverylarge group ofreceivers. Thegroup ofreceivers isparti-
tioned intoanumber ofsubgroups, which aresubsequently organized intoatree.
Thesubgroup containing thesender forms therootofthetree.Within eachsub-
group, anyreliable multicasting scheme thatworks forsmall groups canbeused.
Each subgroup appoints alocalcoordinator, which isresponsible forhandling
retransmission requests ofreceivers contained initssubgroup. Thelocalcoordina-
torwillthushave itsownhistory buffer. Ifthecoordinator itself hasmissed a
message m,itasksthecoordinator oftheparent subgroup toretransmit m.Ina
scheme based onacknowledgments, alocalcoordinator sends anacknowledgment
toitsparent ifithasreceived themessage. Ifacoordinator hasreceived ack-
nowledgments formessage mfrom allmembers initssubgroup, aswellasfrom
itschildren, itcanremove mfromitshistory buffer.
Themain problem withhierarchical solutions istheconstruction ofthetree.
Inmany cases, atreeneeds tobeconstructed dynamically. Oneapproach isto
make useofthemulticast treeintheunderlying network, ifthere isone.Inprinci-
ple,theapproach isthentoenhance eachmulticast router inthenetwork layer in
suchawaythatitcanactasalocalcoordinator inthewayjustdescribed. Unfor-
tunately, asapractical matter, suchadaptations toexisting computer networks are348 FAULT TOLERANCE CHAP. 8
noteasytodo.Forthesereasons, application-level multicasting solutions aswe
discussed inChap. 4havegained popularity.
Inconclusion, building reliable multicast schemes thatcanscaletoalarge
number ofreceivers spread across awide-area network, isadifficult problem. No
single bestsolution exists, andeachsolution introduces newproblems.
8.4.3 Atomic Multicast
Letusnowreturn tothesituation inwhich weneedtoachieve reliable multi-
casting inthepresence ofprocess failures. Inparticular, whatisoftenneeded ina
distributed system istheguarantee thatamessage isdelivered toeither allproc-
essesortononeatall.Inaddition, itisgenerally alsorequired thatallmessages
aredelivered inthesameordertoallprocesses. Thisisalsoknown astheatomic
multicast problem.
Toseewhyatomicity issoimportant, consider areplicated database con-
structed asanapplication ontopofadistributed system. Thedistributed system
offers reliable multicasting facilities. Inparticular, itallows theconstruction of
process groups towhich messages canbereliably sent.Thereplicated database is
therefore constructed asagroup ofprocesses, oneprocess foreachreplica. Up-
dateoperations arealways multicast toallreplicas andsubsequently performed
locally. Inotherwords, weassume thatanactive-replication protocol isused.
Suppose thatnowthataseries ofupdates istobeperformed, butthatduring
theexecution ofoneoftheupdates, areplica crashes. Consequently, thatupdate is
lostforthatreplica butontheotherhand, itiscorrectly performed attheother
replicas.
When thereplica thatjustcrashed recovers, atbestitcanrecover tothesame
stateithadbefore thecrash; however, itmayhavemissed several updates. Atthat
point, itisessential thatitisbrought uptodatewiththeotherreplicas. Bringing
thereplica intothesamestateastheothers requires thatweknow exactly which
operations itmissed, andinwhich ordertheseoperations aretobeperformed.
Nowsuppose thattheunderlying distributed system supported atomic multi-
casting. Inthatcase,theupdate operation thatwassenttoallreplicas justbefore
oneofthemcrashed iseither performed atallnonfaulty replicas, orbynoneatall.
Inparticular, withatomic multicasting, theoperation canbeperformed byall
correctly operating replicas onlyiftheyhavereached agreement onthegroup
membership. Inother words, theupdate isperformed iftheremaining replicas
haveagreed thatthecrashed replica nolonger belongs tothegroup.
When thecrashed replica recovers, itisnowforced tojointhegroup once
more. Noupdate operations willbeforwarded untilitisregistered asbeing a
member again. Joining thegroup requires thatitsstateisbrought uptodatewith
therestofthegroup members. Consequently, atomic multicasting ensures that
nonfaulty processes maintain aconsistent viewofthedatabase, andforces recon-
ciliation whenareplica recovers andrejoins thegroup.SEC. 8.4 RELIABLE GROUP COMMUNICA nON 349
Virtual Synchrony
Reliable multicast inthepresence ofprocess failures canbeaccurately de-
finedinterms ofprocess groups andchanges togroup membership. Aswedid
earlier, wemake adistinction between receiving anddelivering amessage. Inpar-
ticular, weagain adopt amodel inwhich thedistributed system consists ofacom-
munication layer, asshown inFig.8-12. Within thiscommunication layer, mes-
sagesaresentandreceived. Areceived message islocally buffered inthecommu-
nication layeruntilitcanbedelivered totheapplication thatislogically placed at
ahigher layer.
Figure 8-12. Thelogical organization ofadistributed system todistinguish between
message receipt andmessage delivery.
Thewhole ideaofatomic multicasting isthatamulticast message misuniq-
uelyassociated withalistofprocesses towhich itshould bedelivered. This
delivery listcorresponds toagroup view, namely, theviewonthesetofproc-
essescontained inthegroup, which thesender hadatthetimemessage mwas
multicast. Animportant observation isthateachprocess onthatlisthasthesame
view. Inotherwords, theyshould allagreethatmshould bedelivered toeachone
ofthemandtonootherprocess.
Nowsuppose thatthemessage mismulticast atthetimeitssender hasgroup
viewG.Furthermore, assume thatwhile themulticast istaking place, another
process joinsorleaves thegroup. Thischange ingroup membership isnaturally
announced toallprocesses inG.Stated somewhat differently, aviewchange
takesplace bymulticasting amessage vcannouncing thejoining orleaving ofa
process. Wenowhavetwomulticast messages simultaneously intransit: mand
vc.What weneedtoguarantee isthatmiseither delivered toallprocesses inG
before eachoneofthemisdelivered message vc,ormisnotdelivered atall.Note
thatthisrequirement issomewhat comparable tototally-ordered multicasting,
which wediscussed inChap. 6.350 FAULT TOLERANCE CHAP. 8
Aquestion thatquickly comes tomindisthatifmisnotdelivered toany
process, howcanwespeak ofareliable multicast protocol? Inprinciple. thereis
onlyonecaseinwhich delivery ofmisallowed tofail:when thegroup member-
shipchange istheresult ofthesender ofmcrashing. Inthatcase,either allmem-
bersofGshould heartheabortofthenewmember, ornone. Alternatively, mmay
beignored byeachmember, which corresponds tothesituation thatthesender
crashed before mwassent.
Thisstronger formofreliable multicast guarantees thatamessage multicast to
group viewGisdelivered toeachnonfaulty process inG.Ifthesender ofthe
message crashes during themulticast, themessage mayeither bedelivered toall
remaining processes, orignored byeachofthem. Areliable multicast withthis
property issaidtobevirtually synchronous (Birman andJoseph, 1987).
Consider thefourprocesses shown inFig.8-13. Atacertain point intime,
process PIjoinsthegroup, which thenconsists ofPhP2,P3,andP4•Aftersome
messages havebeenmulticast, P3crashes. However, before crashing. itsuc-
ceeded inmulticasting amessage toprocess P2andP4, butnottoPI.However,
virtual synchrony guarantees thatthemessage isnotdelivered atall,effectively
establishing thesituation thatthemessage wasnever sentbefore P3crashed.
Figure 8-13. Theprinciple ofvirtual synchronous multicast.
AfterP3hasbeenremoved fromthegroup, communication proceeds between
theremaining group members. Later, when P3recovers. itcanjointhegroup
again, afteritsstatehasbeenbrought uptodate.
Theprinciple ofvirtual synchrony comes fromthefactthatallmulticasts take
place between viewchanges. Putsomewhat differently, aviewchange actsasa
barrier across which nomulticast canpass.Inasense. itiscomparable totheuse
ofasynchronization variable indistributed datastores asdiscussed intheprevious
chapter. Allmulticasts thatareintransit while aviewchange takesplacearecom-
pleted before theviewchange comes intoeffect. Theimplementation ofvirtual
synchrony isnottrivial aswewilldiscuss indetail below.SEC. 8.4 RELIABLE GROUP COMMUNICATION 351
~Iessage Ordering
Virtual synchrony allows anapplication developer tothinkabout multicasts as
taking place inepochs thatareseparated bygroup membership changes. How-
ever,nothing hasyetbeensaidconcerning theordering ofmulticasts. Ingeneral,
fourdifferent orderings aredistinguished:
1.Unordered multicasts
2.FIFO-ordered multicasts
3.Causally-ordered multicasts
4.Totally-ordered multicasts
Areliable, unordered multicast isavirtually synchronous multicast in
which noguarantees aregiven concerning theorderinwhich received messages
aredelivered bydifferent processes. Toexplain, assume thatreliable multicasting
issupported byalibrary providing asendandareceive primitive. Thereceive op-
eration blocks thecalling process untilamessage isdelivered toit.
Figure 8-14. Three communicating processes inthesame group. Theordering
ofevents perprocess isshown along thevertical axis.
Nowsuppose asender PImulticasts twomessages toagroup while twoother
processes inthatgroup arewaiting formessages toarrive, asshown inFig.8-14.
Assuming thatprocesses donotcrashorleavethegroup during thesemulticasts, it
ispossible thatthecommunication layeratP2firstreceives message m1andthen
m2.Because therearenomessage-ordering constraints, themessages maybe
delivered toP1intheorderthattheyarereceived. Incontrast, thecommunication
layeratP3mayfirstreceive message m2followed bymI,anddelivers thesetwo
inthissameordertoP3•
Inthecaseofreliable FIFO-ordered multicasts. thecommunication layeris
forced todeliver incoming messages fromthesameprocess inthesameorderas
theyhavebeensent.Consider the·communication within agroup offourproc-
esses, asshown inFig.8-15. WithFIFOordering, theonlythingthatmatters is
thatmessage m1isalways delivered before m-;and.likewise, thatmessage m3is
always delivered before ms,Thisrulehastobeobeyed byallprocesses inthe
group. Inotherwords, when thecommunication layeratP3receives m2 first,it
willwaitwithdelivery toP3untilithasreceived anddelivered mI'352 FAULT TOLERANCE CHAP. 8
Figure 8-15. Fourprocesses inthesamegroup withtwodifferent senders, anda
possible delivery order ofmessages under FIFO-ordered multicasting.
However, thereisnoconstraint regarding thedelivery ofmessages sentby
different processes. Inotherwords, ifprocess P2receives m1before 1113,itmay
deliver thetwomessages inthatorder. Meanwhile, process P3mayhavereceived
m3before receiving mI' FIFO ordering states thatP3maydeliver m3before mh
although thisdelivery orderisdifferent fromthatofP2.
Finally, reliablecausally-ordered multicast delivers messages sothatpoten-
tialcausality between different messages ispreserved. Inotherwords. ifames-
sagem1causally precedes another message m2, regardless ofwhether theywere
multicast bythesamesender, thenthecommunication layerateachreceiver will
always deliver m2afterithasreceived anddelivered ml'Notethatcausally-
ordered multicasts canbeimplemented using vector timestamps asdiscussed in
Chap. 6.
Besides thesethreeorderings, theremaybetheadditional constraint thatmes-
sagedelivery istobetotally ordered aswell. Total-ordered deliverymeans that
regardless ofwhether message delivery isunordered, FIFO ordered, orcausally
ordered, itisrequired additionally thatwhenmessages aredelivered, theyarede-
livered inthesameordertoallgroup members.
Forexample, withthecombination ofFIFO andtotally-ordered multicast,
processes P2andP3inFig.8-15maybothfirstdeliver message m-;andthenmes-
sagemI.' However, ifP2delivers ml before m3, while P3delivers m-; before
delivering m1,theywould violate thetotal-ordering constraint. NotethatFIFO
ordering should stillberespected. Inotherwords, m2should bedelivered after
m1and,accordingly, m4should bedelivered afterm3. .
Virtually synchronous reliable multicasting offering totally-ordered delivery
ofmessages iscalled atomicmulticasting. Withthethreedifferent message ord-
eringconstraints discussed above, thisleadstosixforms ofreliable multicasting
asshown inFig.8-16(Hadzilacos andToueg, 1993).
Implementing VirtualSynchrony
Letusnowconsider apossible implementation ofavirtually synchronous
reliable multicast. Anexample ofsuchanimplementation appears inIsis,afault-
tolerant distributed system thathasbeeninpractical useinindustry forseveralSEC. 8.4 RELIABLE GROUP COMMUNICA nON 353
Figure 8-16. Sixdifferent versions ofvirtually synchronous reliable multicasting.
years. Wewillfocus onsome oftheimplementation issues ofthistechnique as
described inBirman etal.(1991).
Reliable multicasting inIsismakes useofavailable reliable point-to-point
communication facilities oftheunderlying network, inparticular, TCP. Multicast-
ingamessage mtoagroup ofprocesses isimplemented byreliably sending mto
eachgroup member. Asaconsequence, although eachtransmission isguaranteed
tosucceed, there arenoguarantees thatallgroup members receive m.Inparticu-
lar,thesender mayfailbefore having transmitted mtoeachmember.
Besides reliable point-to-point communication, Isisalsoassumes thatmes-
sages from thesame source arereceived byacommunication layer intheorder
theyweresentbythatsource. Inpractice, thisrequirement issolved byusing TCP
connections forpoint-to-point communication.
Themain problem thatneeds tobesolved istoguarantee thatallmessages
senttoview Garedelivered toallnonfaulty processes inGbefore thenextgroup
membership change takes place. Thefirstissue thatneeds tobetaken careofis
making surethateachprocess inGhasreceived allmessages thatweresenttoG.
Note thatbecause thesender ofamessage mtoGmayhavefailed before com-
pleting itsmulticast, theremayindeed beprocesses inGthatwillnever receive m.
Because thesender hascrashed, these processes should getmfrom somewhere
else.Howaprocess detects itismissing amessage isexplained next.
Thesolution tothisproblem istoletevery process inGkeepmuntilitknows
forsurethatallmembers inGhave received it.Ifmhasbeen received byall
members inG,missaidtobestable. Only stable messages areallowed tobe
delivered. Toensure stability, itissufficient toselect anarbitrary (operational)
process inGandrequest ittosendmtoallother processes.
Tobemore specific, assume thecurrent viewisGj, butthatitisnecessary to
install thenextviewG;+l. Without lossofgenerality, wemayassume thatG;and
Gj+1 differ byatmostoneprocess. Aprocess Pnotices theviewchange when it
receives aview-change message. Such amessage maycome from theprocess
wanting tojoinorleave thegroup, orfromaprocess thathaddetected thefailure
ofaprocess inG;thatisnowtoberemoved, asshown inFig.8-17(a).354FAULT TOLERANCECHAP. 8
When aprocess Preceives theview-change message forGi+1, itfirstfor-
wards acopyofanyunstable message fromG,itstillhastoevery process inGi+1,
andsubsequently marks itasbeing stable. Recall thatIsisassumes point-to-point
communication isreliable, sothatforwarded messages arenever lost.Such for-
warding guarantees thatallmessages inG,thathavebeenreceived byatleastone
process arereceived byallnonfaulty processes inGi. Note thatitwould alsohave
beensufficient toelectasingle coordinator toforward unstable messages.
Figure 8-17. (a)Process 4notices thatprocess 7hascrashed andsends aview
change. (b)Process 6sends outallitsunstable messages, followed byaflush
message. (c)Process 6installs thenewviewwhen ithasreceived aflushmes-
sagefromeveryone else.
Toindicate thatPnolonger hasanyunstable messages andthatitisprepared
toinstall Gi+1 assoonastheother processes candothataswell, itmulticasts a
flushmessage forGi+b asshown inFig.8-17(b). After Phasreceived aflush
message forGi+1 from each other process, itcansafely install thenewview
'[shown inFig.8-17(c)].
When. aprocess Qreceives amessage mthatwassentinGi, andQstillbe-
'lieves thecurrent viewisG;,itdelivers. mtaking anyadditional message-ordering
'constraints intoaccount. Ifithadalready received 171,'itconsiders themessage to
'beaduplicate andfurther discards it. .
Because process Qwilleventually receive theview-change message forGi+1,
litwillalsofirstforward anyofitsunstable messages andsubsequently wrap
Lpnngs upbysending aflushmessage.for Gi+l,., Notethatdue.tothemessage ord-
f¢ring underlying thecommunication layer, aflushmessage from aprocess isal-
\vays; received afterthereceipt ofauunstable message fromthatsame process. .
.'themajor flawintheprotocol described soIfaristhatitcannot dealwith
'process failures while anewview change isbeing announced. Inparticular, it
'assumes thatuntilthenewviewGi+1 hasbeeninstalled byeachmember inGi+1,
'no-process inGi+1 willfail(which would leadtoanextview Gi+2)' ThisproblemSEC. 8.4 RELIABLE GROUP COMMUNICATION 355
issolved byannouncing viewchanges foranyviewGi+k evenwhile previous
changes havenotyetbeeninstalled byallprocesses. Thedetails areleftasan
exercise forthereader.
8.5DISTRIBUTED COMMIT
Theatomic multicasting problem discussed intheprevious section isanex-
ample ofamoregeneral problem, known asdistributed commit.Thedistributed
commit problem involves having anoperation being performed byeachmember
ofaprocess group, ornoneatall.Inthecaseofreliable multicasting, theopera-
tionisthedelivery ofamessage. Withdistributed transactions, theoperation may
bethecommit ofatransaction atasingle sitethattakespartinthetransaction.
Other examples ofdistributed commit, andhowitcanbesolved arediscussed in
Tanisch (2000).
Distributed commit isoftenestablished bymeans ofacoordinator. Inasimple
scheme, thiscoordinator tellsallotherprocesses thatarealsoinvolved, called par-
ticipants, whether ornotto(locally) perform theoperation inquestion. This
scheme isreferred toasaone-phase commitprotocol. Ithastheobvious draw-
backthatifoneoftheparticipants cannot actually perform theoperation, thereis
nowaytotellthecoordinator. Forexample, inthecaseofdistributed transactions,
alocalcommit maynotbepossible because thiswould violate concurrency con-
trolconstraints.
Inpractice, more sophisticated schemes areneeded, themostcommon one
being thetwo-phase commit protocol, which isdiscussed indetail below. The
maindrawback ofthisprotocol isthatitcannot efficiently handle thefailure of
thecoordinator. Tothatend,athree-phase protocol hasbeendeveloped, which we
alsodiscuss.
8.5.1Two-Phase Commit
Theoriginal two-phase commitprotocol (2PC) isduetoGray (1978)
Without lossofgenerality, consider adistributed transaction involving thepartici-
pation ofanumber ofprocesses eachrunning onadifferent machine. Assuming
thatnofailures occur, theprotocol consists ofthefollowing twophases, eachcon-
sisting oftwosteps[seealsoBernstein etal.(1987)]:
1.Thecoordinator sends aVOTE-.REQUEST message toallpartici-
pants.
2.When aparticipant receives aVOTE-.REQUEST message, itreturns
either aVOTE_COMMIT message tothecoordinator telling thecoor-
dinator thatitisprepared tolocally commit itspartofthetransaction,
orotherwise aVOTE-ABORT message.356 FAULT TOLERANCE CHAP. 8·
Figure 8~18. (a)Thefinite statemachine forthecoordinator in;2PC. (b)The
finite statemachine foraparticipant.
Several problems arisewhen thisbasic 2PCprotocol isusedinasystem
where failures occur. First, notethatthecoordinator aswellastheparticipants
havestatesinwhich theyblock waiting forincoming messages. Consequently, the
protocol caneasily failwhen aprocess crashes forotherprocesses maybeinde-
finitely waiting foramessage fromthatprocess. Forthisreason, timeout mechan-
ismareused. These mechanisms areexplained inthefollowing pages.
When taking alookatthefinitestatemachines inFig.8-18,itcanbeseenthat
there areatotalofthree states inwhich either acoordinator orparticipant is
blocked waiting foranincoming message. First,aparticipant maybewaiting in
itsINITstateforaVOTE-REQUEST message fromthecoordinator. Ifthatmes-
sageisnotreceived aftersometime,theparticipant willsimply decide tolocally
abortthetransaction, andthussendaVOTE..ABORT message tothecoordinator.
Likewise, thecoordinator canbeblocked instate"~4IT, waiting forthevotes •..
ofeachparticipant. Ifnotallvoteshavebeencollected afteracertain period of3.Thecoordinator collects allvotesfromtheparticipants. Ifallpartici-
pantshavevoted tocommit thetransaction, thensowillthecoordi-
nator. Inthatcase,itsends aGLOBAL_COMMIT message toallpar-
ticipants. However, ifoneparticipant hadvoted toabort thetran-
saction, thecoordinator willalsodecide toabortthetransaction and
multicasts aGLOBAL..ABORT message.
4.Eachparticipant thatvoted foracommit waitsforthefinalreaction
bythecoordinator. Ifaparticipant receives aGLOBAL_COMMIT
message, itlocally commits thetransaction. Otherwise, when receiv-
ingaGLOBAL..ABORT message, thetransaction islocally aborted
aswell.
Thefirstphase isthevoting phase, andconsists ofsteps 1and2.Thesecond
phase isthedecision phase, andconsists ofsteps3and4.These fourstepsare
shown asfinitestatediagrams inFig.8-18.SEC.8.5 DISTRIBUTED COMMIT 357
time, thecoordinator should voteforanabort aswell, andsubsequently send
GLOBAL....ABORT toallparticipants.
Finally, aparticipant canbeblocked instateREADY, waiting fortheglobal
voteassentbythecoordinator. Ifthatmessage isnotreceived within agiven
time,theparticipant cannot simply decide toabort thetransaction. Instead, itmust
findoutwhich message thecoordinator actually sent.Thesimplest solution tothis
problem istoleteachparticipant block untilthecoordinator recovers again.
Abetter solution istoletaparticipant Pcontact another participant Qtoseeif
itcandecide from Q'scurrent statewhatitshould do.Forexample, suppose that
Qhadreached stateCOMMIT. Thisispossible onlyifthecoordinator hadsenta
GLOBAL_COMMIT message toQjustbefore crashing. Apparently; thismessage
hadnotyetbeensenttoP.Consequently, Pmaynowalsodecide tolocally com-
mit.Likewise, ifQisinstateABORT, Pcansafely abort aswell.
Nowsuppose thatQisstillinstateINIT. Thissituation canoccur when the
coordinator hassentaVOTE....REQUEST toallparticipants, butthismessage has
reached P(which subsequently responded withaVOTE_COMMIT message), but
hasnotreached Q.Inother words, thecoordinator hadcrashed while multicasting
VOTE....REQUEST. Inthiscase, itissafetoabort thetransaction: bothPandQ
canmake atransition tostateABORT.
Themostdifficult situation occurs when QisalsoinstateREADY, waiting for
aresponse from thecoordinator. Inparticular, ifitturns outthatallparticipants
areinstateREADY, nodecision canbetaken. Theproblem isthatalthough all
participants arewilling tocommit, theystillneedthecoordinator's votetoreach
thefinaldecision. Consequently, theprotocol blocks untilthecoordinator recov-
ers.
Thevarious options aresummarized inFig.8-19.
Figure 8-19. Actions taken byaparticipant Pwhen residing instateREADY
andhaving contacted another participant Q.
Toensure thataprocess canactually recover, itisnecessary thatitsaves its
statetopersistent storage. (How saving datacanbedone inafault-tolerant wayis
discussed laterinthischapter.) Forexample, ifaparticipant wasinstateINIT, it
cansafely decide tolocally abort thetransaction when itrecovers, andthen
inform thecoordinator. Likewise, when ithadalready taken adecision suchas358 FAULT TOLERANCE CHAP: 8
Figure 8-20. Outline ofthestepstaken bythecoordinator inatwo-phase com-
mitprotocol.
Ifnotallvoteshavebeencollected butnomorevotes arereceived within a
given timeinterval prescribed inadvance, thecoordinator assumes thatoneor
moreparticipants havefailed. Consequently, itshould abortthetransaction and
multicasts aGLOBAL-ABORT tothe(remaining) participants.whenitcrashed while being ineither stateCOMMIT orABORT, itisinorderto
recover tothatstateagain, andretransmit itsdecision tothecoordinator.
Problems arisewhenaparticipant crashed while residing instateREADY. In
thatcase.when recovering, itcannot decide onitsownwhatitshould donext,
thatis,commit orabortthetransaction. Consequently, itisforced tocontact other
participants tofindwhatitshould do,analogous tothesituation when ittimesout
while residing instateREADY asdescribed above. '
Thecoordinator hasonlytwocritical statesitneeds tokeeptrackof.When it
startsthe2PCprotocol, itshould record thatitisentering stateWAIT sothatitcan
possibly retransmit theVOTEJ?EQUEST message toallparticipants afterrecov-
ering. Likewise, ifithadcome toadecision inthesecond phase, itissufficient if
thatdecision hasbeenrecorded sothatitcanberetransmitted when recovering.
Anoutline oftheactions thatareexecuted bythecoordinator isgiven in
Fig.8-20. Thecoordinator startsbymulticasting aVOTEJ?EQUEST toallparti-
cipants inordertocollect theirvotes. Itsubsequently records thatitisentering the
WAIT state,afterwhich itwaitsforincoming votesfromparticipants.SEC.8.5 DISTRIBUTED COMMIT 359
Ifnofailures occur, thecoordinator willeventually havecollected allvotes. If
allparticipants aswellasthecoordinator votetocommit, GLOBAL_COMMIT is
firstlogged andsubsequently senttoallprocesses. Otherwise, thecoordinator
multicasts aGLOBAL-ABORT (after recording itinthelocallog).
Fig.8-21(a) showsthe steps taken byaparticipant. First, theprocess waits for
avoterequest fromthecoordinator. Note thatthiswaiting canbedonebyasepa-
ratethread running intheprocess's address space. Ifnomessage comes in,the
transaction issimply aborted. Apparently, thecoordinator hadfailed.
After receiving avoterequest, theparticipant maydecide tovoteforcommit-
tingthetransaction forwhich itfirstrecords itsdecision inalocal log,andthen
informs thecoordinator bysending aVOTE_COMMIT message. Theparticipant
must thenwaitfortheglobal decision. Assuming thisdecision (which again
should come from thecoordinator) comes inontime, itissimply written tothe
locallog,afterwhich itcanbecarried out.
However, iftheparticipant times outwhile waiting forthecoordinator's deci-
siontocome in,itexecutes atermination protocol byfirstmulticasting a
DECISION-REQUEST message totheother processes, after which itsubse-
quently blocks while waiting foraresponse. When aresponse comes in(possibly
from thecoordinator, which isassumed toeventually recover), theparticipant
writes thedecision toitslocallogandhandles itaccordingly.
Each participant should beprepared toaccept requests foraglobal decision
from other participants. Tothatend,assume each participant starts aseparate
thread, executing concurrently withthemain thread oftheparticipant asshown in
Fig.8-21(b). Thisthread blocks untilitreceives adecision request. Itcanonlybe
ofhelptoanther process ifitsassociated participant hasalready reached afinal
decision. Inother words, ifGLOBAL_COMMIT orGLOBAL-ABORT hadbeen
written tothelocal log,itiscertain thatthecoordinator hadatleastsentitsdeci-
sion tothisprocess. Inaddition, thethread may also decide tosend a
GLOBAL-ABORT when itsassociated participant isstillinstate INIT, asdis-
cussed previously. Inallother cases, thereceiving thread cannot help, andthere-
questing participant willnotberesponded to.
What isseenisthatitmaybepossible thataparticipant willneedtoblock
untilthecoordinator recovers. Thissituation occurs when allparticipants havere-
ceived andprocessed theVOTE-REQUEST from thecoordinator, while inthe
meantime, thecoordinator crashed. Inthatcase,participants cannot cooperatively
decide onthefinalaction totake. Forthisreason, 2PCisalsoreferred toasa
blocking commitprotocol.
There areseveral solutions toavoid blocking. Onesolution, described by
Babaoglu andToueg (1993), istouseamulticast primitive bywhich areceiver
immediately multicasts areceived message toallother processes. Itcanbeshown
thatthisapproach allows aparticipant toreach afinaldecision, evenifthecoordi-
nator hasnotyetrecovered. Another solution isthethree-phase commit protocol,
which isthelasttopic ofthissection andisdiscussed next.360 FAULT TOLERANCE CHAP. 8
Figure 8-21. (a)Thestepstaken byaparticipant process in2PC. (b)Thesteps
forhandling incoming decision requests.SEC. 8.5 DISTRIBUTED COMMIT 361
8.5.2 Three-Phase Commit
Aproblem withthetwo-phase commit protocol isthatwhen thecoordinator
hascrashed, participants maynotbeabletoreachafinaldecision. Consequently,
participants mayneedtoremain blocked untilthecoordinator recovers. Skeen
(1981) developed avariant of2PC,called thethree-phase commit protocol
(3PC), thatavoids blocking processes inthepresence offail-stop crashes. Al-
though 3PCiswidely referred tointheliterature, itisnotapplied ofteninpractice
astheconditions under which 2PCblocks rarely occur. Wediscuss theprotocol,
asitprovides further insight intosolving fault-tolerance problems indistributed
systems.
Like2PC,3PCisalsoformulated interms ofacoordinator andanumber of
participants. Their respective finite statemachines areshown inFig.8-22. The
essence oftheprotocol isthatthestates ofthecoordinator andeachparticipant
satisfy thefollowing twoconditions:
1.There isnosingle statefromwhich itispossible tomake atransition
directly toeither aCOMMIT oranABORT state.
2.There isnostateinwhich itisnotpossible tomake afinaldecision,
andfromwhich atransition toaCOMMIT statecanbemade.
Itcanbeshown thatthesetwoconditions arenecessary andsufficient foracom-
mitprotocol tobenonblocking (Skeen andStonebraker, 1983).
Figure 8-22. (a)Thefinite statemachine forthecoordinator in3PC. (b)The
finite statemachine foraparticipant.
Thecoordinator in3PCstartswithsending aVOTE....REQUEST message toall
participants, afterwhich itwaits forincoming responses. Ifanyparticipant votes
toabortthetransaction, thefinaldecision willbetoabortaswell,sothecoordina-
torsends GLOBAL-ABORT. However, whenthetransaction canbecommitted, a362 FAULT TOLERANCE CHAP. 8
PREPARE_COMMIT message issent.Onlyaftereachparticipant hasacknowl-
edged itisnowprepared tocommit, willthecoordinator send thefinal
GLOBAL_COMMIT message bywhich thetransaction isactually committed.
Again, thereareonlyafewsituations inwhich aprocess isblocked while
waiting forincoming messages. First,ifaparticipant iswaiting foravoterequest
fromthecoordinator while residing instateINIT, itwilleventually make atransi-
tiontostateABORT, thereby assuming thatthecoordinator hascrashed. This
situation isidentical tothatin2PC.Analogously, thecoordinator maybeinstate
WAIT, waiting forthevotesfromparticipants. Onatimeout, thecoordinator will
conclude thataparticipant crashed, andwillthusabortthetransaction bymulti-
casting aGLOBAL-ABORT message.
Nowsuppose thecoordinator isblocked instatePRECOMMIT. Onatimeout,
itwillconclude thatoneoftheparticipants hadcrashed, butthatparticipant is
known tohavevoted forcommitting thetransaction. Consequently, thecoordina-
torcansafely instruct theoperational participants tocommit bymulticasting a
GLOBAL_COMMIT message. Inaddition, itrelies onarecovery protocol forthe
crashed participant toeventually commit itspartofthetransaction when itcomes
upagain.
Aparticipant Pmayblock intheREADY stateorinthePRECOMMIT state.
Onatimeout, Pcanconclude onlythatthecoordinator hasfailed, sothatitnow
needs tofindoutwhattodonext.Asin2PC,ifPcontacts anyotherparticipant
thatisinstateCOMMIT (orABORD, Pshould move tothatstateaswell.Inaddi-
tion,ifallparticipants areinstatePRECOMMIT, thetransaction canbesafely
committed.
Again analogous to2PC,ifanother participant QisstillintheINITstate,the
transaction cansafely beaborted. Itisimportant tonotethatQcanbeinstate
INITonlyifnootherparticipant isinstatePRECOMMIT. Aparticipant canreach
PRECOMMIT onlyifthecoordinator hadreached statePRECOMMIT before
crashing, andhasthusreceived avotetocommit fromeachparticipant. Inother
words, noparticipant canreside instateINITwhile another participant isinstate
PRECOMMIT.
Ifeach:oftheparticipants thatPcancontact isinstateREAD Y(andthey
together formamajority), thetransaction should beaborted. Thepointtonoteis
thatanother participant mayhavecrashed andwilllaterrecover. However, neither
P,noranyother oftheoperational participants knows what thestateofthe
crashed participant willbewhenitrecovers. Iftheprocess recovers tostateINIT,
thendeciding toabortthetransaction istheonlycorrect decision. Atworst, the
process mayrecover tostatePRECOMMIT, butinthatcase, itcannot doany
harmtostillabortthetransaction.
Thissituation isthemajor difference with2PC,where acrashed participant
could recover toaCOMMIT statewhile alltheothers werestillinstateREAD Y.
Inthatcase,theremaining operational processes could notreach afinaldecision
andwould havetowaituntilthecrashed process recovered. With 3PC,ifanySEC. 8.5 DISTRIBUTED COMMIT 363
operational process isinitsREAD Ystate, nocrashed process willrecover toa
stateotherthanINIT, ABORT, orPRECOMMIT. Forthisreason, surviving proc-
essescanalways cometoafinaldecision.
Finally, iftheprocesses thatPcanreach areinstatePRECOMMIT (andthey
forma majority), thenitissafetocommit thetransaction. Again, itcanbeshown
thatinthiscase,allotherprocesses willeither beinstateREADY oratleast,will
recover tostateREADY, PRECOMMIT, orCOMMIT whentheyhadcrashed.
Further details on3PCcanbefound inBernstein etal.(1987) andChow and
Johnson (1997).
8.6RECOVERY
Sofar,wehavemainly concentrated onalgorithms thatallow ustotolerate
faults. However, onceafailure hasoccurred, itisessential thattheprocess where
thefailure happened canrecover toacorrect state.Inwhatfollows, wefirstcon-
centrate onwhatitactually means torecover toacorrect state,andsubsequently
whenandhowthestateofadistributed system canberecorded andrecovered to,
bymeans ofcheckpointing andmessage logging.
8.6.1 Introduction
Fundamental tofaulttolerance istherecovery fromanerror. Recall thatan
erroristhatpartofasystem thatmayleadtoafailure. Thewhole ideaoferror
recovery istoreplace anerroneous statewithanerror-free state.There areessen-
tiallytwoforms oferrorrecovery.
Inbackward recovery, themainissueistobringthesystem fromitspresent
erroneous statebackintoapreviously correct state.Todoso,itwillbenecessary
torecord thesystem's statefromtimetotime,andtorestore sucharecorded state
when things gowrong. Eachtime(partof)thesystem's present stateisrecorded,
acheckpoint issaidtobemade.
Another formoferrorrecovery isforward recovery. Inthiscase,when the
system hasentered anerroneous state, instead ofmoving backtoaprevious,
checkpointed state,anattempt ismade tobringthesystem inacorrect newstate
fromwhich itcancontinue toexecute. Themainproblem withforward errorre-
covery mechanisms isthatithastobeknown inadvance which errors mayoccur.
Onlyinthatcaseisitpossible tocorrect thoseerrors andmovetoanewstate.
Thedistinction between backward andforward error recovery iseasily
explained when considering theimplementation ofreliable communication. The
common approach torecover fromalostpacket istoletthesender retransmit that
packet. Ineffect, packet retransmission establishes thatweattempt togobacktoa
previous, correct state,namely theoneinwhich thepacket thatwaslostisbeing364 FAULT TOLERANCE CHAP. 8
sent. Reliable communication through packet retransmission istherefore anex-
ample ofapplying backward errorrecovery techniques.
Analternative approach istouseamethod known aserasure correction. In
thisapproach. amissing packet isconstructed from other, successfully delivered
packets. Forexample, inan(n,k) block erasure code, asetofksource packets is
encoded intoasetofnencoded packets, suchthatanysetofkencoded packets is
enough toreconstruct theoriginal ksource packets. Typical values arek=16'or
k=32, andk<11~2k [see,forexample, Rizzo (1997)]. Ifnotenough packets have
yetbeendelivered, thesender willhavetocontinue transmitting packets untila
previously lostpacket canbeconstructed. Erasure correction isatypical example
ofaforward errorrecovery approach.
Byandlarge, backward error recovery techniques arewidely applied asa
general mechanism forrecovering fromfailures indistributed systems. Themajor
benefit ofbackward error recovery isthatitisagenerally applicable method
independent ofanyspecific system orprocess. Inother words, itcanbeintegrated
into(themiddleware layer) ofadistributed system asageneral-purpose service.
However, backward error recovery alsointroduces some problems (Singhal
andShivaratri, 1994). First, restoring asystem orprocess toaprevious stateis
generally arelatively costly operation interms ofperformance. Aswillbedis-
cussed insucceeding sections, much work generally needs tobedone torecover
from, forexample, aprocess crash orsitefailure. Apotential wayoutofthisprob-
lem,istodevise verycheap mechanisms bywhich components aresimply re-
booted. Wewillreturn tothisapproach below.
Second, because backward errorrecovery mechanisms areindependent ofthe
distributed application forwhich theyareactually used, noguarantees canbe
given thatoncerecovery hastaken place, thesame orsimilar failure willnothap-
penagain. Ifsuchguarantees areneeded, handling errors often requires thatthe
application getsintotheloopofrecovery. Inother words, full-fledged failure tran-
sparency cangenerally notbeprovided bybackward errorrecovery mechanisms.
Finally, although backward errorrecovery requires checkpointing, some states
cansimply never berolled backto.Forexample, oncea(possibly malicious) per-
sonhastaken the$1.000 thatsuddenly came rolling outoftheincorrectly func-
tioning automated teller machine, there isonlyasmall chance thatmoney willbe
stuffed back inthemachine. Likewise, recovering toaprevious state inmost
UNIX systems afterhaving enthusiastically typed
rrn-fr*
butfromthewrong working directory, mayturnafewpeople pale. Some things
aresimply irreversible.
Checkpointing allows therecovery toaprevious correct state. However, tak-
ingacheckpoint isoften acostly operation andmayhave asevere performance
penalty. Asaconsequence, many fault-tolerant distributed systems combine
checkpointing withmessage logging. Inthiscase, after acheckpoint hasbeenSEC. 8.6 RECOVERY 365
taken, aprocess logsitsmessages before sending themoff(called sender-based
logging). Analternative solution istoletthereceiving process firstloganincom-
ingmessage before delivering ittotheapplication itisexecuting. Thisscheme is
alsoreferred toasreceiver-based logging. When areceiving process crashes, it
isnecessary torestore themostrecently checkpointed state, andfromthereon
replay themessages thathavebeensent.Consequently, combining checkpoints
withmessage logging makes itpossible torestore astatethatliesbeyond themost
recent checkpoint without thecostofcheckpointing.
Another important distinction between checkpointing andschemes thataddi-
tionally uselogsfollows. Inasystem where onlycheckpointing isused,processes
willberestored toacheckpointed state.From thereon,theirbehavior maybedif-
ferent thanitwasbefore thefailure occurred. Forexample, because communica-
tiontimes arenotdeterministic, messages maynowbedelivered inadifferent or-
der,intumleading todifferent reactions bythereceivers. However, ifmessage
logging takes place, anactual replay oftheevents thathappened sincethelast
checkpoint takesplace. Suchareplay makes iteasier tointeract withtheoutside
world,
Forexample, consider thecasethatafailure occurred because auserprovided
erroneous input. Ifonlycheckpointing isused,thesystem would havetotakea
checkpoint before accepting theuser's input inorder torecover toexactly the
samestate.Withmessage logging, anoldercheckpoint canbeused,afterwhich a
replay ofevents cantakeplaceuptothepointthattheusershould provide input.
Inpractice, thecombination ofhaving fewer checkpoints andmessage logging is
moreefficient thanhaving totakemany checkpoints.
Stable Storage
Tobeabletorecover toaprevious state,itisnecessary thatinformation need-
edtoenable recovery issafely stored. Safely inthiscontext means thatrecovery
information survives process crashes andsitefailures, butpossibly alsovarious
storage media failures. Stable storage plays animportant rolewhen itcomes to
recovery indistributed systems. Wediscuss itbriefly here.
Storage comes inthree categories. Firstthere isordinary RAM memory,
which iswiped outwhenthepower failsoramachine crashes. Nextthereisdisk
storage, which survives CPUfailures butwhich canbelostindiskheadcrashes.
Finally, thereisalsostable storage, which isdesigned tosurvive anything ex-
ceptmajor calamities suchasfloods andearthquakes. Stable storage canbeim-
plemented withapairofordinary disks, asshown inFig.8-23(a). Eachblock on
drive2isanexact copyofthecorresponding block ondrive 1.When ablock is
updated, firsttheblock ondrive1isupdated andverified. thenthesameblock on
drive2isdone.
Suppose thatthesystem crashes afterdrive 1isupdated butbefore theupdate
ondrive 2,asshown inFig.8-23(b). Upon recovery, thediskcanbecompared366 FAULT TOLERANCE CHAP. 8
Figure 8-23. (a)Stable storage. (b)Crash afterdrive Iisupdated. (c)Bad
spot.
block forblock. Whenever twocorresponding blocks differ, itcanbeassumed
thatdrive1isthecorrect one(because drive1isalways updated before drive2),
sothenewblock iscopied fromdrive1todrive2.When therecovery process is
complete, bothdrives willagainbeidentical.
Another potential problem isthespontaneous decay ofablock. Dustparticles
orgeneral wearandtearcangiveapreviously validblock asudden checksum
error, without cause orwarning, asshown inFig.8-23(c). When suchanerroris
detected, thebadblock canberegenerated fromthecorresponding block onthe
otherdrive.
Asaconsequence ofitsimplementation, stable storage iswellsuited toappli-
cations thatrequire ahighdegree offaulttolerance, suchasatomic transactions.
When dataarewritten tostable storage andthenreadbacktocheck thattheyhave
beenwritten correctly, thechance ofthemsubsequently being lostisextremely
small.
Inthenexttwosections wegointofurther details concerning checkpoints and
message logging. Elnozahy etal.(2002) provide asurvey ofcheckpointing and
logging indistributed systems. Various algorithmic details canbefound inChow
andJohnson (1997).
8.6.2 Checkpointing
Inafault-tolerant distributed system, backward errorrecovery requires that
thesystem regularly saves itsstateontostable storage. Inparticular, weneedto
record aconsistent global state,alsocalled adistributed snapshot. Inadistrib-
utedsnapshot, ifaprocess Phasrecorded thereceipt ofamessage, thenthereSEC. 8.6 RECOVERY 367
should alsobeaprocess Qthathasrecorded thesending ofthatmessage. After
all,itmusthavecome fromsomewhere.
Figure 8-24. Arecovery line.
Inbackward errorrecovery schemes, eachprocess savesitsstatefromtimeto
timetoalocally-available stable storage. Torecover afteraprocess orsystem
failure requires thatweconstruct aconsistent global statefromtheselocalstates.
Inparticular, itisbesttorecover tothemostrecent distributed snapshot, also
referred toasarecovery line.Inotherwords, arecovery linecorresponds tothe
mostrecent consistent collection ofcheckpoints, asshown inFig.8-24.
Independent Checkpointing
Unfortunately, thedistributed nature ofcheckpointing (inwhich eachprocess
simply records itslocalstatefromtimetotimeinanuncoordinated fashion) may
make itdifficult tofindarecovery line.Todiscover arecovery linerequires that
eachprocess isrolled backtoitsmostrecently saved state.Iftheselocalstates
jointly donotform adistributed snapshot, further rolling backisnecessary.
Below, wewilldescribe awaytofindarecovery line.Thisprocess ofacascaded
rollback mayleadtowhatiscalled thedomino effect andisshown inFig.8-25.
Figure 8-25. Thedomino effect.
When process P2crashes, weneedtorestore itsstatetothemostrecently
saved checkpoint. Asaconsequence, process PIwillalsoneedtoberolled back.368FAULT TOLERANCECHAP. 8
Unfortunately, thetwomostrecently saved localstates donotformaconsistent
global state: thestatesaved byP2indicates thereceipt ofamessage m,butno
otherprocess canbeidentified asitssender. Consequently, P2needs toberolled
backtoanearlier state.
However, thenextstatetowhich P2isrolled backalsocannot beusedaspart
ofadistributed snapshot. Inthiscase,PIwillhaverecorded thereceipt ofmes-
sagemI, butthereisnorecorded event ofthismessage being sent.Itistherefore
necessary toalsorollPIbacktoaprevious state.Inthisexample, itturnsoutthat
therecovery lineisactually theinitial stateofthesystem. . .
Asprocesses takelocalcheckpoints independent ofeachother, thismethod is
alsoreferred toasindependent checkpointing. Analternative solution istoglo-
ballycoordinate checkpointing, aswediscuss below, butcoordination requires
global synchronization, which mayintroduce performance problems. Another dis-
advantage ofindependent checkpointing isthateachlocalstorage needs tobe
cleaned upperiodically, forexample, byrunning aspecial distributed garbage col-
lector. However, themaindisadvantage liesincomputing therecovery line.
Implementing independent checkpointing requires thatdependencies are
recorded insuchawaythatprocesses canjointly rollbacktoaconsistent global
state. Tothatend,letCPi(m) denote them-thcheckpoint taken byprocess Pi'
Also,letINTi(m) denote theinterval between checkpoints CPi(m-l) andCPi(m).
When process Pisends amessage ininterval INTi(m), itpiggybacks thepair
(i,m) tothereceiving process. When process Pj receives amessage ininterval
IN1j(n), along withthepairofindices (i,m), itthenrecords thedependency
INTi(m )-7IN1j(n). Whenever Ijtakescheckpoint CPln), itadditionally writes
thisdependency toitslocalstable storage, along withtherestoftherecovery in-
formation thatispartofCPln).
Nowsuppose thatatacertain moment, process' PIisrequired torollbackto
checkpoint CPi(m-l). Toensure global consistency, weneedtoensure thatall
processes thathavereceived messages fromPiandweresentininterval INTi(m),
arerolled backtoacheckpointed statepreceding thereceipt ofsuchmessages. In
particular, .process Pjinourexample, willneedtoberolled backatleasttocheck-
point CPj(n-l). IfCPj(n-l) doesnotleadtoaglobally consistent state,further
rolling backmaybenecessary.
Calculating therecovery linerequires ananalysis oftheinterval dependencies
recorded byeachprocess when acheckpoint wastaken. Without going intoany
further details, itturnsoutthatsuchcalculations arefairly complex anddonot
justify theneedforindependent checkpointing incomparison tocoordinated
checkpointing. Inaddition, asitturnsout,itisoftennotthecoordination between
processes thatisthedominating performance factor, buttheoverhead astheresult
ofhaving tosavethestatetolocalstable storage. Therefore, coordinated check-
pointing, which ismuch simpler thanindependent checkpointing, isoftenmore
popular, andwillpresumably staysoevenwhen systems grow tomuch larger
sizes(Elnozahy andPlanck, 2004).SEC. 8.6 RECOVERY 369
Coordinated Checkpointing
Asitsname suggests, incoordinated checkpointing allprocesses synchron-
izetojointly write theirstatetolocalstable storage. Themain advantage ofcoor-
dinated checkpointing isthatthesaved stateisautomatically globally consistent,
sothatcascaded rollbacks leading tothedomino effect areavoided. Thedistrib-
utedsnapshot algorithm discussed inChap. 6canbeusedtocoordinate check-
pointing. Thisalgorithm isanexample ofnonblocking checkpoint coordination.
Asimpler solution istouseatwo-phase blocking protocol. Acoordinator first
multicasts aCHECKPOINT .-REQUEST message toallprocesses. When aprocess
receives suchamessage, ittakes alocalcheckpoint, queues anysubsequent mes-
sagehanded toitbytheapplication itisexecuting, andacknowledges tothecoor-
dinator thatitishastaken acheckpoint. When thecoordinator hasreceived an
acknowledgment from allprocesses, itmulticasts aCHECKPOINT ...DONE mes-
sagetoallow the(blocked) processes tocontinue.
Itiseasytoseethatthisapproach willalsoleadtoaglobally consistent state,
because noincoming message willeverberegistered aspartofacheckpoint. The
reason forthisisthatanymessage thatfollows arequest fortaking acheckpoint is
notconsidered tobepartofthelocalcheckpoint. Atthesame time, outgoing mes-
sages (ashanded tothecheckpointing process bytheapplication itisrunning), are
queued locally untiltheCHECKPOINT ...DONE message isreceived.
Animprovement tothisalgorithm istomulticast acheckpoint request onlyto
those processes thatdepend ontherecovery ofthecoordinator, andignore the
other processes. Aprocess isdependent onthecoordinator ifithasreceived a
message thatisdirectly orindirectly causally related toamessage thatthecoordi-
nator hadsentsince thelastcheckpoint. Thisleads tothenotion ofanincremen-
talsnapshot.
Totakeanincremental snapshot, thecoordinator multicasts acheckpoint re-
quest onlytothose processes ithadsentamessage tosince itlasttookacheck-
point. When aprocess Preceives sucharequest, itforwards therequest toall
those processes towhich Pitself hadsentamessage since thelastcheckpoint, and
soon.Aprocess forwards therequest onlyonce. When allprocesses havebeen
identified, asecond multicast isusedtoactually trigger checkpointing andtolet
theprocesses continue where theyhadleftoff.
8.6.3 Message Logging
Considering thatcheckpointing isanexpensive operation, especially concern-
ingtheoperations involved inwriting statetostable storage, techniques havebeen
sought toreduce thenumber ofcheckpoints, butstillenable recovery. Animpor-
tanttechnique indistributed systems islogging messages.
Thebasic ideaunderlying message logging isthatifthetransmission ofmes-
sages canbereplayed, wecanstillreach aglobally consistent statebutwithout370 FAULT TOLERANCECHAP. 8
having torestore thatstatefromstable storage. Instead, acheckpointed stateis
taken asastarting point, andallmessages thathavebeensentsincearesimply
retransmitted andhandled accordingly.
Thisapproach works fineunder theassumption ofwhatiscalled apiecewise
deterministic model. Insuchamodel, theexecution ofeachprocess isassumed
totakeplaceasaseries ofintervals inwhich events takeplace. These events are
thesameasthosediscussed inthecontext ofLamport's happened-before relation-
shipinChap. 6.Forexample, aneventmaybetheexecution ofaninstruction, the
sending ofamessage, andsoon.Eachinterval inthepiecewise deterministic
model isassumed tostartwithanondeterministic event, suchasthereceipt ofa
message. However, fromthatmoment on,theexecution oftheprocess iscom-
pletely deterministic. Aninterval endswiththelastevent before anondeterminis-
ticeventoccurs.
Ineffect, aninterval canbereplayed withaknown result, thatis,inacom-
pletely deterministic way,provided itisreplayed starting withthesamenondeter-
ministic eventasbefore. Consequently, ifwerecord allnondeterministic events in
suchamodel, itbecomes possible tocompletely replay theentire execution ofa
process inadeterministic way.
Considering thatmessage logsarenecessary torecover fromaprocess crash
sothataglobally consistent stateisrestored, itbecomes important toknow pre-
cisely when messages aretobelogged. Following theapproach described by
Alvisi andMarzullo (1998), itturns outthatmany existing message-logging
schemes canbeeasily characterized, ifweconcentrate onhowtheydealwith
orphan processes.
Anorphan process isaprocess thatsurvives thecrashofanother process, but
whose stateisinconsistent withthecrashed process afteritsrecovery. Asanex-
ample, consider thesituation shown inFig.8-26. Process Qreceives messages
m1andm2fromprocess PandR,respectively, andsubsequently sends amessage
m3toR.However, incontrast toallothermessages, message m2isnotlogged. If
process Qcrashes andlaterrecovers again, onlythelogged messages required for
therecovery ofQarereplayed, inourexample, mI' Because m2wasnotlogged,
itstransmission willnotbereplayed, meaning thatthetransmission ofm3also
maynottakeplace. Fig.8-26.
However, thesituation aftertherecovery ofQisinconsistent withthatbefore
itsrecovery. Inparticular, Rholdsamessage (m3)thatwassentbefore thecrash,
butwhose receipt anddelivery donottakeplace when replaying whathadhap-
pened before thecrash. Suchinconsistencies should obviously beavoided.
Characterizing Message-Logging Schemes
Tocharacterize different message-logging schemes, wefollow theapproach
described inAlvisi andMarzullo (1998). Eachmessage misconsidered tohavea
header thatcontains allinformation necessary toretransmit m,andtoproperlySEC. 8.6 RECOVERY 371
Figure 8-26. Incorrect replay ofmessages afterrecovery, leading toanorphan
process.
handle it.Forexample, eachheader willidentify thesender andthereceiver, but
alsoasequence number torecognize itasaduplicate. Inaddition, adelivery num-
bermaybeadded todecide when exactly itshould behanded overtothereceiv-
.ingapplication.
Amessage issaidtobestable ifitcannolonger belost,forexample, because
ithasbeen written tostable storage. Stable messages canthusbeused for
recovery byreplaying theirtransmission.
Each message mleads toasetDEP(m) ofprocesses thatdepend onthe
delivery ofm.Inparticular, DEP (m) consists ofthose processes towhich mhas
beendelivered. Inaddition, ifanother message m'iscausally dependent onthe
delivery ofm,andm'hasbeendelivered toaprocess Q,thenQwillalsobecon-
tained inDEP (m). Note thatm'iscausally dependent onthedelivery ofm,ifit
weresentbythesame process thatpreviously delivered m,orwhich haddelivered
another message thatwascausally dependent onthedelivery ofm.
ThesetCOPY(m) consists ofthose processes thathaveacopy ofm,butnot
(yet)intheirlocal stable storage. When aprocess Qdelivers message m,italso
becomes amember ofCOPY(m). NotethatCOPY(m) consists ofthose processes
thatcould handoveracopyofmthatcanbeusedtoreplay thetransmission ofm.
Ifallthese processes crash, replaying thetransmission ofmisclearly notfeasible.
Using these notations, itisnoweasytodefine precisely whatanorphan proc-
essis.Suppose thatinadistributed system some processes havejustcrashed. Let
Qbeoneofthesurviving processes. Process Qisanorphan process ifthere isa
message m,suchthatQiscontained inDEP (m), while atthesame timeevery
process inCOPY(m) hascrashed.' Inother words, anorphan process appears
when itisdependent onm,butthereisnowaytoreplay m'stransmission.
Toavoid orphan processes, wethusneed toensure thatifeach process in
COPY(m) crashed, thennosurviving process isleftinDEP(m). Inother words,
allprocesses inDEP (m) should have crashed aswell. This condition canbe
enforced ifwecanguarantee thatwhenever aprocess becomes amember of
DEP(m), italsobecomes amember ofCOPY(m). Inother words, whenever a
process becomes dependent onthedelivery ofm,itwillalways keepacopyofm.372 FAULT TOLERANCE CHAP. 8
There areessentially twoapproaches thatcannowbefollowed. Thefirstap-
proach isrepresented bywhatarecalled pessimistic logging protocols. These
protocols takecarethatforeachnonstable message m,thereisatmostoneproc-
essdependent onm.Inotherwords, pessimistic logging protocols ensure thateach
nonstable message misdelivered toatmostoneprocess. Notethatassoonasmis
delivered to,sayprocess P,Pbecomes amember ofCOpy (m).
Theworst thatcanhappen isthatprocess Pcrashes without meverhaving
beenlogged. Withpessimistic logging, Pisnotallowed tosendanymessages af-
terthedelivery ofmwithout firsthaving ensured thatmhasbeenwritten tostable
storage. Consequently, nootherprocesses willeverbecome dependent onthede-
livery ofmtoP,without having thepossibility ofreplaying thetransmission ofm.
Inthisway,orphan processes arealways avoided.
Incontrast, inanoptimistic logging protocol. theactual workisdoneaftera
crash occurs. Inparticular, assume thatforsome message m,eachprocess in
COpy (m)hascrashed. Inanoptimistic approach, anyorphan process inDEP (m)
isrolled backtoastateinwhich itnolonger belongs toDEP(m). Clearly,
optimistic logging protocols needtokeeptrackofdependencies, which compli-
catestheirimplementation.
Aspointed outinElnozahy etal.(2002), pessimistic logging issomuch sim-
plerthanoptimistic approaches, thatitisthepreferred wayofmessage logging in
practical distributed systems design.
8.6.4 Recovery-Oriented Computing
Arelated wayofhandling recovery isessentially tostartoveragain. The
underlying principle toward thiswayofmasking failures isthatitmaybemuch
cheaper tooptimize forrecovery, thenitisaiming forsystems thatarefreefrom
failures foralongtime. Thisapproach isalsoreferred toasrecovery-oriented
computing (Candea etaI.,2004a).
There aredifferent flavors ofrecovery-oriented computing. Oneflavor isto
simply reboot (partofasystem) andhasbeenexplored torestart Internet servers
(Candea etal.,2004b, 2006). Inordertobeablereboot onlyapartofthesystem,
itiscrucial thefaultisproperly localized. Atthatpoint, rebooting simply means
deleting allinstances oftheidentified components. along withthethreads operat-
ingonthem, and(often) tojustrestart theassociated requests. Notethatfault
localization itselfmaybeanontrivial exercise (Steinder andSethi. 2004).
Toenable rebooting asapractical recovery technique requires thatcom-
ponents arelargely decoupled inthesense thattherearefewornodependencies
between different components. Iftherearestrong dependencies, thenfaultlocali-
zation andanalysis maystillrequire thatacomplete server needs toberestarted at
which pointapplying traditional recovery techniques astheoneswejustdiscussed
maybemoreefficient.SEC. 8.6 RECOVERY 373
Another flavor ofrecovery-oriented computing istoapply checkpointing and
recovery techniques, buttocontinue execution inachanged environment. The
basicideahereisthatmany failures canbesimply avoided ifprograms aregiven
somemorebuffer space, memory iszeroed before allocated, changing theorder-
ingofmessage delivery (aslongasthisdoesnotaffect semantics), andsoon(Qin
etaI.,2005). Thekeyideaistotackle software failures (whereas many ofthe
techniques discussed sofarareaimed at,orarebased onhardware failures).
Because software execution ishighly deterministic, changing anexecution
environment maysavetheday,but,ofcourse, without repairing anything.
8.7SUMMARY
Fault tolerance isanimportant subject indistributed systems design. Fault
tolerance isdefined asthecharacteristic bywhich asystem canmask the
occurrence andrecovery fromfailures. Inotherwords, asystem isfaulttolerant if
itcancontinue tooperate inthepresence offailures.
Several types offailures exist. Acrashfailure occurs when aprocess simply
halts.Anomission failure occurs whenaprocess doesnotrespond toincoming re-
quests. When aprocess responds toosoonortoolatetoarequest, itissaidto
exhibit atiming failure. Responding toanincoming request, butinthewrong
way,isanexample ofaresponse failure. Themostdifficult failures tohandle are
thosebywhich aprocess exhibits anykindoffailure, called arbitrary orByzan-
tinefailures.
Redundancy isthekeytechnique needed toachieve faulttolerance. When
applied toprocesses, thenotion ofprocess groups becomes important. Aprocess
group consists ofanumber ofprocesses thatclosely cooperate toprovide aser-
vice.Infault-tolerant process groups, oneormore processes canfailwithout
affecting theavailability oftheservice thegroup implements. Often, itisneces-
sarythatcommunication within thegroup behighly reliable, andadheres to
stringent ordering andatomicity properties inordertoachieve faulttolerance.
Reliable group communication, alsocalled reliable multicasting, comes indif-
ferent forms. Aslongasgroups arerelatively small, itturnsoutthatimplementing
reliability isfeasible. However, assoonasverylargegroups needtobesupported,
scalability ofreliable multicasting becomes problematic. Thekeyissueinachiev-
ingscalability istoreduce thenumber offeedback messages bywhich receivers
report the(un)successful receipt ofamulticasted message.
Matters become worse when atomicity istobeprovided. Inatomic multicast
protocols, itisessential thateachgroup member havethesameviewconcerning
towhich members amulticasted message hasbeendelivered. Atomic multicasting
canbeprecisely formulated interms ofavirtual synchronous execution model. In
essence, thismodel introduces boundaries between which group membership does374 FAULT TOLERANCE CHAP. 8
notchange andwhich messages arereliably transmitted. Amessage cannever
crossaboundary.
Group membership changes areanexample where eachprocess needs to
agree onthesamelistofmembers. Suchagreement canbereached bymeans ofa
commit protocol, ofwhich thetwo-phase commit protocol isthemostwidely
applied. Inatwo-phase commit protocol, acoordinator firstchecks whether all
processes agree toperform thesame operation (i.e.,whether theyallagree to
commit), andinasecond round, multicasts theoutcome ofthatpoll.Athree-
phase commit protocol isusedtohandle thecrash ofthecoordinator without hav-
ingtoblock allprocesses toreachagreement untilthecoordinator recovers.
Recovery infault-tolerant systems isinvariably achieved bycheckpointing the
stateofthesystem onaregular basis. Checkpointing iscompletely distributed.
Unfortunately, taking acheckpoint isanexpensive operation. Toimprove perfor-
mance, many distributed systems combine checkpointing withmessage logging.
Bylogging thecommunication between processes, itbecomes possible toreplay
theexecution ofthesystem afteracrashhasoccurred.
PROBLEMS
1.Dependable systems areoftenrequired toprovide ahighdegree ofsecurity. Why?
2.What makes thefail-stop model inthecaseofcrash failures sodifficult toimplement?
3.Consider aWebbrowser thatreturns anoutdated cached pageinstead ofamore recent
onethathadbeen updated attheserver. Isthisafailure, andifso,what kindof
failure?
4.Canthemodel oftriple modular redundancy described inthetexthandle Byzantine
failures?
5.How many failed elements (devices plusvoters) canFig.8-2handle? Give anex-
ample oftheworst casethatcanbemasked.
6.Does TMR generalize tofiveelements pergroup instead ofthree? Ifso,whatproper-
tiesdoesithave?
7.Foreachofthefollowing applications. doyouthink at-least-once semantics orat-
most-once semantics isbest? Discuss.
(a)Reading andwriting filesfromafileserver.
(b)Compiling aprogram.
(c)Remote banking.
8.With asynchronous RPCs, aclient isblocked untilitsrequest hasbeenaccepted bythe
server. Towhatextent dofailures affect thesemantics ofasynchronous RPCs?
9.Giyeanexample inwhich group communication requires nomessage ordering atall.CHAP. 8 PROBLEMS 375
10.Inreliable multicasting, isitalways necessary thatthecommunication layer keeps a
copyofamessage forretransmission purposes?
11.Towhatextent isscalability ofatomic multicasting important?
12.Inthetext,wesuggest thatatomic multicasting cansavethedaywhen itcomes toper-
forming updates onanagreed setofprocesses. Towhatextent canweguarantee that
eachupdate isactually performed?
13.Virtual synchrony isanalogous toweak consistency indistributed datastores, with
group viewchanges acting assynchronization points. Inthiscontext, what would be
theanalog ofstrong consistency?
14.What arethepermissible delivery orderings forthecombination ofFIFO andtotal-
ordered multicasting inFig.8-15?
15.Adapt theprotocol forinstalling anextview Gi+1 inthecaseofvirtual synchrony so
thatitcantolerate process failures.
16.Inthetwo-phase commit protocol, whycanblocking never becompletely eliminated,
evenwhen theparticipants electanewcoordinator?
17.Inourexplanation ofthree-phase commit, itappears thatcommitting atransaction is
based onmajority voting. Isthistrue?
18.Inapiecewise deterministic execution model, isitsufficient tologonlymessages, or
doweneedtologother events aswell?
19.Explain howthewrite-ahead logindistributed transactions canbeusedtorecover
fromfailures.
20.Does astateless server needtotakecheckpoints?
21.Receiver-based message logging isgenerally considered better thansender-based log-
ging.Why?9
SECURITY
Thelastprinciple ofdistributed systems thatwediscuss issecurity. Security is
bynomeans theleastimportant principle. However, onecould argue thatitisone
ofthemostdifficult principles, assecurity needs tobepervasive throughout asys-
tem.Asingle design flawwithrespect tosecurity mayrender allsecurity meas-
uresuseless. Inthischapter, weconcentrate onthevarious mechanisms thatare
generally incorporated indistributed systems tosupport security.
Westartwithintroducing thebasic issues ofsecurity. Building allkinds ofse-
curity mechanisms intoasystem doesnotreally make sense unless itisknown
howthose mechanisms aretobeused, andagainst what. Thisrequires thatwe
know about thesecurity policy thatistobeenforced. Thenotion ofasecurity pol-
icy,along withsome general design issues formechanisms thathelpenforce such
policies, arediscussed first.Wealsobriefly touch upon thenecessary cryptogra-
phy.
Security indistributed systems canroughly bedivided intotwoparts. One
partconcerns thecommunication between users orprocesses, possibly residing on
different machines. Theprincipal mechanism forensuring secure communication
isthatofasecure channel. Secure channels, andmore specifically, authentication,
message integrity, andconfidentiality, arediscussed inaseparate section.
Theother partconcerns authorization, which deals withensuring thataproc-
essgetsonlythose access rights totheresources inadistributed system itisenti-
tledto.Authorization iscovered inaseparate section dealing withaccess control.
Inaddition totraditional access control mechanisms, wealsofocus onaccess con-
trolwhen wehavetodealwithmobile codesuchasagents.
377378 SECURITY CHAP. 9
Secure channels andaccess control require mechanisms todistribute crypto-
graphic keys, butalsomechanisms toaddandremove users fromasystem. These
topics arecovered bywhatisknown assecurity management. Inaseparate sec-
tion,wediscuss issues dealing withmanaging cryptographic keys, secure group
management, andhanding outcertificates thatprove theowner isentitled toac-
cessspecified resources.
9.1INTRODUCTION TOSECURITY
Westartourdescription ofsecurity indistributed systems bytaking alookat
some general security issues. First, itisnecessary todefine whatasecure system
is.Wedistinguish security policies from security mechanisms. andtakealookat
theGlobus wide-area system forwhich asecurity policy hasbeenexplicitly for-
mulated. Oursecond concern istoconsider some general design issues forsecure
systems. Finally, webriefly discuss some cryptographic algorithms, which playa
keyroleinthedesign ofsecurity protocols.
9.1.1 Security Threats, Policies, andMechanisms
Security inacomputer system isstrongly related tothenotion ofdependabil-
ity.Informally, adependable computer system isonethatwejustifiably trustto
deliver itsservices (Laprie, 1995). Asmentioned inChap. 7,dependability in-
cludes availability, reliability, safety, andmaintainability. However, ifweareto
putourtrustinacomputer system, thenconfidentiality andintegrity should also
betaken intoaccount. Confidentiality refers totheproperty ofacomputer sys-
temwhereby itsinformation isdisclosed onlytoauthorized parties. Integrity is
thecharacteristic thatalterations toasystem's assets canbemade onlyinanauth-
orized way. Inother words, improper alterations inasecure computer system
should bedetectable andrecoverable. Major assets ofanycomputer system areits
hardware, software, anddata.
Another wayoflooking atsecurity incomputer systems isthatweattempt to
protect theservices anddataitoffers against security threats. There arefour
types ofsecurity threats toconsider (Pfleeger, 2003):
1.Interception
2.Interruption
3.Modification
4.Fabrication
Theconcept ofinterception refers tothesituation thatanunauthorized party
hasgained access toaservice ordata.Atypical example ofinterception iswhereSEC. 9.1 INTRODUCTION TOSECURITY 379
communication between twoparties hasbeen overheard bysomeone else.Inter-
ception alsohappens when dataareillegally copied, forexample, afterbreaking
intoaperson's private directory inafilesystem.
Anexample ofinterruption iswhen afileiscorrupted orlost.More generally
interruption refers tothesituation inwhich services ordatabecome unavailable,
unusable, destroyed, andsoon.Inthissense, denial ofservice attacks bywhich
someone maliciously attempts tomake aservice inaccessible toother parties isa
security threat thatclassifies asinterruption.
Modifications involve unauthorized changing ofdataortampering withaser-
vicesothatitnolonger adheres toitsoriginal specifications. Examples ofmodifi-
cations include intercepting andsubsequently changing transmitted data,tamper-
ingwithdatabase entries, andchanging aprogram sothatitsecretly logsthe
activities ofitsuser.
Fabrication refers tothesituation inwhich additional dataoractivity aregen-
erated thatwould normally notexist. Forexample, anintruder mayattempt toadd
anentry intoapassword fileordatabase. Likewise, itissometimes possible to
break intoasystem byreplaying previously sentmessages. Weshallcome across
suchexamples laterinthischapter.
Note thatinterruption, modification, andfabrication caneachbeseenasa
formofdatafalsification.
Simply stating thatasystem should beabletoprotect itself against allpos-
siblesecurity threats isnotthewaytoactually build asecure system. What isfirst
needed isadescription ofsecurity requirements, thatis,asecurity policy. Asecu-
ritypolicy describes precisely which actions theentities inasystem areallowed
totakeandwhich onesareprohibited. Entities include users, services, data, ma-
chines, andsoon.Once asecurity policy hasbeenlaiddown, itbecomes possible
toconcentrate onthesecurity mechanisms bywhich apolicy canbeenforced.
Important security mechanisms are:
1.Encryption
2.Authentication
3.Authorization
4.Auditing
Encryption isfundamental tocomputer security. Encryption transforms data
intosomething anattacker cannot understand. Inother words, encryption provides
ameans toimplement dataconfidentiality. Inaddition, encryption allows usto
check whether datahavebeenmodified. Itthusalsoprovides support forintegrity
checks.
Authentication isusedtoverify theclaimed identity ofauser,client, server,
host, orother entity. Inthecaseofclients, thebasic premise isthatbefore aser-
vicestarts toperform anywork onbehalf ofaclient, theservice must learn the380 SECURITY CHAP. 9
client's identity (unless theservice isavailable toall).Typically, usersareauth-
enticated bymeans ofpasswords, buttherearemany otherwaystoauthenticate
clients.
Afteraclient hasbeenauthenticated, itisnecessary tocheck whether thatcli-
entisauthorized toperform theaction requested. Access torecords inamedical
database isatypical example. Depending onwhoaccesses thedatabase. permis-
sionmaybegranted toreadrecords, tomodify certain fields inarecord, ortoadd
orremove arecord.
Auditing toolsareusedtotracewhich clients accessed what, andwhich way.
Although auditing doesnotreally provide anyprotection against security threats,
auditlogscanbeextremely useful fortheanalysis ofasecurity breach, andsubse-
quently taking measures against intruders. Forthisreason, attackers aregenerally
keennottoleave anytraces thatcould eventually leadtoexposing theiridentity.
Inthissense, logging accesses makes attacking sometimes ariskier business.
Example: TheGlobus Security Architecture
Thenotion ofsecurity policy andtherolethatsecurity mechanisms playin
distributed systems forenforcing suchpolicies isoftenbestexplained bytaking a
lookataconcrete example. Consider thesecurity policy defined fortheGlobus
wide-area system (Chervenak etal.,2000). Globus isasystem supporting large-
scaledistributed computations inwhich many hosts, files,andotherresources are
simultaneously usedfordoing acomputation. Suchenvironments arealsoreferred
toascomputational grids(Foster andKesselman, 2003). Resources inthesegrids
areoftenlocated indifferent administrative domains thatmaybelocated indif-
ferent partsoftheworld.
Because usersandresources arevastinnumber andwidely spread across dif-
ferent administrative domains, security isessential. Todevise andproperly usese-
curity mechanisms, itisnecessary tounderstand whatexactly needs tobepro-
tected, andwhattheassumptions arewithrespect tosecurity. Simplifying matters
somewhat, thesecurity policy forGlobus entails thefollowing eightstatements,
which weexplain below (Foster etal.,1998):
1.Theenvironment consists ofmultiple administrative domains. -
2.Local operations (i.e.,operations thatarecarried outonlywithin a
single domain) aresubject toalocaldomain security policy only.
3.Global operations (i.e.,operations involving several domains) require
theinitiator tobeknown ineachdomain where theoperation iscar-
riedout.
4.Operations between entities indifferent domains require mutual
authentication.
5.Global authentication replaces localauthentication.SEC.9.1 INTRODUCTION TOSECURITY 381
6.Controlling access toresources issubject tolocalsecurity only.
7.Users candelegate rights toprocesses.
8.Agroup ofprocesses inthesamedomain cansharecredentials.
Globus assumes thattheenvironment consists ofmultiple administrative do-
mains, where eachdomain hasitsownlocalsecurity policy. Itisassumed thatlo-
calpolicies cannot bechanged justbecause thedomain participates inGlobus, nor
cantheoverall policy ofGlobus override localsecurity decisions. Consequently,
security inGlobus willrestrict itselftooperations thataffect multiple domains.
Related tothisissueisthatGlobus assumes thatoperations thatareentirely
localtoadomain aresubject onlytothatdomain's security policy. Inotherwords,
ifanoperation isinitiated andcarried outwithin asingle domain, allsecurity
issues willbecarried outusing localsecurity measures only.Globus willnotim-
poseadditional measures. .
TheGlobus security policy states thatrequests foroperations canbeinitiated
either globally orlocally. Theinitiator, beitauserorprocess acting onbehalf ofa
user,mustbelocally known within eachdomain where thatoperation iscarried
out.Forexample, ausermayhaveaglobal name thatismapped todomain-spe-
cificlocalnames. Howexactly thatmapping takesplaceislefttoeachdomain.
Animportant policy statement isthatoperations between entities indifferent
domains require mutual authentication. Thismeans, forexample, thatifauserin
onedomain makes useofaservice fromanother domain, thentheidentity ofthe
userwillhavetobeverified. Equally important isthattheuserwillhavetobe
assured thatheisusing aservice hethinks heisusing. Wereturn toauthentica-
tion,extensively, laterinthischapter.
Theabove twopolicy issues arecombined intothefollowing security require-
ment. Iftheidentity ofauserhasbeenverified, andthatuserisalsoknown
locally inadomain, thenhecanactasbeing authenticated forthatlocaldomain.
Thismeans thatGlobus requires thatitssystemwide authentication measures are
sufficient toconsider thatauserhasalready beenauthenticated foraremote do-
main(where thatuserisknown) whenaccessing resources inthatdomain. Addi-
tional authentication bythatdomain should notbenecessary.
Onceauser(orprocess acting onbehalf ofauser)hasbeenauthenticated, itis
stillnecessary toverify theexact access rights withrespect toresources. Forex-
ample,a userwanting tomodify afilewillfirsthavetobeauthenticated, after
which itcanbechecked whether ornotthatuserisactually permitted tomodify
thefile.TheGlobus security policy states thatsuchaccess control decisions are
madeentirely localwithin thedomain where theaccessed resource islocated.
Toexplain theseventh statement, consider amobile agentinGlobus thatcar-
riesoutataskbyinitiating several operations indifferent domains, oneafteran-
other. Suchanagent maytakealongtimetocomplete itstask.Toavoid having382 SECURITY CHAP. 9
tocommunicate withtheuseronwhose behalf theagent isacting, Globus requires
thatprocesses canbedelegated asubset oftheuser's rights. Asaconsequence, by
authenticating anagent andsubsequently checking itsrights, Globus should beab-
letoallow anagent toinitiate anoperation without having tocontact theagent's
owner.
Asafinalpolicy statement, Globus requires thatgroups ofprocesses running
withasingle domain andacting onbehalf ofthesame usermayshare asingle set
ofcredentials. Aswillbeexplained below, credentials areneeded forauthentica-
tion.Thisstatement essentially opens theroadtoscalable solutions forauthentica-
tionbynotdemanding thateachprocess carries itsownunique setofcredentials.
TheGlobus security policy allows itsdesigners toconcentrate ondeveloping
anoverall solution forsecurity. Byassuming eachdomain enforces itsown-secu-
ritypolicy, Globus concentrates onlyonsecurity threats involving multiple do-
mains. Inparticular, thesecurity policy indicates thattheimportant design issues
aretherepresentation ofauserinaremote domain, andtheallocation ofre-
sources fromaremote domain toauserorhisrepresentative. What Globus there-
foreprimarily needs, aremechanisms forcross-domain authentication, andmak-
ingauserknown inremote domains.
Forthispurpose, twotypes ofrepresentatives areintroduced. Auserproxy is
aprocess thatisgiven permission toactonbehalf ofauserforalimited period of
time. Resources arerepresented byresource proxies. Aresource proxy isaproc-
essrunning within aspecific domain thatisusedtotranslate global operations on
aresource intolocaloperations thatcomply withthatparticular domain's security
policy. Forexample, auserproxy typically communicates witharesource proxy
when access tothatresource isrequired.
TheGlobus security architecture essentially consists ofentities suchasusers,
userproxies, resource proxies, andgeneral processes. These entities arelocated in
domains andinteract witheachother. Inparticular, thesecurity architecture de-
fines fourdifferent protocols, asillustrated inFig.9-1[seealsoFoster eta1.
(1998)].
Thefirstprotocol describes precisely howausercancreate auserproxy and
delegate rights tothatproxy. Inparticular, inorder tolettheuserproxy acton
behalf ofitsuser,theusergives theproxy anappropriate setofcredentials.
Thesecond protocol specifies howauserproxy canrequest theallocation ofa
resource inaremote domain. Inessence, theprotocol tellsaresource proxy to
create aprocess intheremote domain aftermutual authentication hastaken place.
Thatprocess represents theuser(justastheuserproxy did),butoperates inthe
same domain astherequested resource. Theprocess isgiven access tothere-
source subject totheaccess control decisions localtothatdomain.
Aprocess created inaremote domain mayinitiate additional computations in
other domains. Consequently, aprotocol isneeded toallocate resources inare-
mote domain asrequested byaprocess other thanauserproxy. IntheGlobus sys-
tem,thistypeofallocation isdoneviatheuserproxy, byletting aprocess haveitsSEC.9.1 ThITRODUCTIONTOSECURITY 383
Figure 9-1.TheGlobus security architecture.
associated userproxy request theallocation ofresources, essentially following the
second protocol.
Thefourth andlastprotocol intheGlobus security architecture isthewaya
usercanmake himself known inadomain. Assuming thatauserhasanaccount in
adomain, whatneeds tobeestablished isthatthesystemwide credentials asheld
byauserproxy areautomatically converted tocredentials thatarerecognized by
thespecific domain. Theprotocol prescribes howthemapping between theglobal
credentials andthelocal onescanberegistered bytheuserinamapping table
localtothatdomain.
Specific details ofeachprotocol aredescribed inFoster etal.(1998). Theim-
portant issue hereisthattheGlobus security architecture reflects itssecurity pol-
icyasstated above. Themechanisms usedtoimplement thatarchitecture, inpar-
ticular theabove mentioned protocols, arecommon tomany distributed systems,
andarediscussed extensively inthischapter. Themain difficulty indesigning
secure distributed systems isnotsomuch caused bysecurity mechanisms, butby384 SECURITY CHAP. 9
deciding onhowthosemechanisms aretobeusedtoenforce asecurity policy. In
thenextsection, weconsider someofthesedesign decisions.
9.1.2DesignIssues
Adistributed system, oranycomputer system forthatmatter, mustprovide
security services bywhich awiderange ofsecurity policies canbeimplemented.
There areanumber ofimportant design issues thatneedtobetaken intoaccount
when implementing general-purpose security services. Inthefollowing pages, we
discuss threeoftheseissues: focus ofcontrol, layering ofsecurity mechanisms,
andsimplicity [seealsoGollmann (2006)].
FocusofControl
When considering theprotection ofa(possibly distributed) application, there
areessentially three different approaches thatcanbefollowed, asshown in
Fig.9-2.Thefirstapproach istoconcentrate directly ontheprotection ofthedata
thatisassociated withtheapplication. Bydirect, wemean thatirrespective ofthe
various operations thatcanpossibly beperformed onadataitem,theprimary con-
cernistoensure dataintegrity. Typically, thistypeofprotection occurs indata-
basesystems inwhich various integrity constraints canbeformulated thatareau-
tomatically checked eachtimeadataitemismodified [see,forexample, Doom
andRivero (2002)].
Thesecond approach istoconcentrate onprotection byspecifying exactly
which operations maybeinvoked, andbywhom, when certain dataorresources
aretobeaccessed. Inthiscase.thefocus ofcontrol isstrongly related toaccess
control mechanisms, which wediscuss extensively laterinthischapter. Forex-
ample, inanobject-based system, itmaybedecided tospecify foreachmethod
thatismadeavailable toclients which clients arepermitted toinvoke thatmethod.
Alternatively, access control methods canbeapplied toanentire interface offered
byanobject, ortotheentire object itself. Thisapproach thusallows forvarious
granularities ofaccess control.
Athirdapproach istofocus directly onusersbytaking measures bywhich
-onlyspecific people haveaccess totheapplication, irrespective oftheoperations
theywanttocarryout.Forexample, adatabase inabankmaybeprotected by
denying access toanyone except thebank's upper management andpeople specif-
ically authorized toaccess it.Asanother example, inmany universities, certain
dataandapplications arerestricted tobeusedbyfaculty andstaffmembers only,
whereas access bystudents isnotallowed. Ineffect, control isfocused ondefining
rolesthatusershave,andonceauser's rolehasbeenverified, access toaresource
iseither granted ordenied. Aspartofdesigning asecure system, itisthusneces-
sarytodefine rolesthatpeople mayhave, andprovide mechanisms tosupport
role-based access control. Wereturn toroleslaterinthischapter.SEC. 9.1 INTRODUCTION TOSECURITY 385
Figure 9-2.Three approaches forprotection against security threats. (a)Pro-
tection against invalid operations (b)Protection against unauthorized invoca-
tions. (c)Protection against unauthorized users.
Layering ofSecurity Mechanisms
Animportant issue indesigning secure systems istodecide atwhich levelse-
curity mechanisms should beplaced. Alevelinthiscontext isrelated tothelogi-
calorganization ofasystem intoanumber oflayers. Forexample, computer net-
works areoften organized intolayers following some reference model, aswedis...
cussed inChap. 4.InChap. 1,weintroduced theorganization ofdistributed sys-
temsconsisting ofseparate layers forapplications, middleware, operating system
services, andtheoperating system kernel. Combining thelayered organization of
computer networks anddistributed systems, leads roughly towhat isshown in
Fig.9-3.
Inessence, Fig.9-3separates general-purpose services from communication
services. Thisseparation isimportant forunderstanding thelayering ofsecurity in
distributed systems and,inparticular, thenotion oftrust. Thedifference between
trustandsecurity isimportant. Asystem iseither secure oritisnot(taking various
probabilistic measures intoaccount), butwhether aclient considers asystem tobe
secure isamatter oftrust(Bishop, 2003). Security istechnical; trustisemotional.
Inwhich layer security mechanisms areplaced depends onthetrustaclient hasin
howsecure theservices areinaparticular layer.386 SECURITY CHAP. 9
Figure 9-3.Thelogical organization ofadistributed system intoseveral layers.
Asanexample, consider anorganization located atdifferent sitesthatarecon-
nected through acommunication service suchasSwitched Multi-megabit Data
Service (SMDS). AnSMDS network canbethought ofasalink-level backbone
connecting various local-area networks atpossibly geographically dispersed sites,
asshown inFig.9-4.
Figure 9-4.Several sitesconnected through awide-area backbone service.
Security canbeprovided byplacing encryption devices ateachSMDS router,
asalsoshown inFig.9-4.These devices automatically encrypt anddecrypt pack-
etsthataresentbetween sites,butdonototherwise provide secure communica-
tionbetween hostsatthesamesite.IfAlice atsiteAsends amessage toBobat
siteB,andsheisworried about hermessage being intercepted, shemustatleast
trusttheencryption ofintersite traffic toworkproperly. Thismeans, forexample,
thatshemusttrustthesystem administrators atbothsitestohavetaken theproper
measures against tampering withthedevices.
Nowsuppose thatAlicedoesnottrustthesecurity ofintersite traffic. Shemay
thendecide totakeherownmeasures byusing atransport-level security service
suchasSSL.SSLstands forSecure Sockets Layer andcanbeusedtosecurely
sendmessages across aTCPconnection. Wewilldiscuss thedetails ofSSLlater
Chap. 12when discussing Web-based systems. Theimportant thing toobserve
hereisthatSSLallows Alice tosetupasecure connection toBob.Alltransport-SEC. 9.1 INTRODUCTION TOSECURITY 387
levelmessages willbeencrypted-and attheSMDS ·levelaswell,butthatisof
noconcern toAlice. Inthiscase,Alice willhavetoputhertrustintoSSL.Inother
words, shebelieves thatSSLissecure.
Indistributed systems, security mechanisms areoftenplaced inthemiddle-
warelayer. IfAlice doesnottrustSSL,shemaywanttousealocalsecure RPC
service. Again, shewillhavetotrustthisRPCservice todowhatitpromises, such
asnotleaking information orproperly authenticating clients andservers.
Security services thatareplaced inthemiddleware layerofadistributed sys-
temcanbetrusted onlyiftheservices theyrelyontobesecure areindeed secure.
Forexample, ifasecure RPCservice ispartly implemented bymeans ofSSL,
thentrustintheRPCservice depends onhowmuch trustonehasinSSL.IfSSLis
nottrusted, thentherecanbenotrustinthesecurity oftheRPCservice.
Distribution ofSecurity Mechanisms
Dependencies between services regarding trustleadtothenotion ofa
Trusted Computing Base(TCB). ATCBisthesetofallsecurity mechanisms
ina(distributed) computer system thatareneeded toenforce asecurity policy,
andthatthusneedtobetrusted. Thesmaller theTCB, thebetter. Ifadistributed
system isbuiltasmiddleware onanexisting network operating system, itssecuri-
tymaydepend onthesecurity oftheunderlying localoperating systems. Inother
words, theTCBinadistributed system mayinclude thelocaloperating systems at
various hosts.
Consider afileserver inadistributed filesystem. Suchaserver mayneedto
relyonthevarious protection mechanisms offered byitslocaloperating system.
Suchmechanisms include notonlythose forprotecting filesagainst accesses by
processes otherthanthefileserver, butalsomechanisms toprotect thefileserver
frombeing maliciously brought down.
Middleware-based distributed systems thusrequire trustintheexisting local
operating systems theydepend on.Ifsuchtrustdoesnotexist, thenpartofthe
functionality ofthelocaloperating systems mayneedtobeincorporated intothe
distributed system itself. Consider amicrokernel operating system, inwhich most
operating-system services runasnormal userprocesses. Inthiscase,thefilesys-
tem,forinstance, canbeentirely replaced byonetailored tothespecific needs of
adistributed system, including itsvarious security measures.
Consistent withthisapproach istoseparate security services fromothertypes
ofservices bydistributing services across different machines depending on
amount ofsecurity required. Forexample, forasecure distributed filesystem, it
maybepossible toisolate thefileserver fromclients byplacing theserver ona
machine withatrusted operating system, possibly running adedicated secure file
system. Clients andtheirapplications areplaced onuntrusted machines.
Thisseparation effectively reduces theTCBtoarelatively small number of
machines andsoftware components. Bysubsequently protecting those machines388 SECURITY CHAP. 9
against security attacks fromtheoutside, overall trustinthesecurity ofthedistrib-
utedsystem canbeincreased. Preventing clients andtheirapplications direct ac-
cesstocritical services isfollowed intheReduced Interfaces forSecure System
Components (RISSC) approach, asdescribed inNeumann (1995). IntheRISSC
approach. anysecurity-critical server isplaced onaseparate machine isolated
from end-user systems using low-level secure network interfaces, asshown in
Fig.9-5.Clients andtheirapplications runondifferent machines andcanaccess
thesecured server onlythrough these network interfaces.
Simplicity
Another important design issue related todeciding inwhich layer toplace se-
curity mechanisms isthatofsimplicity. Designing asecure computer system is
generally considered adifficult task.Consequently, ifasystem designer canusea
few,simple mechanisms thatareeasily understood andtrusted towork, thebetter
itis.
Unfortunately, simple mechanisms arenotalways sufficient forimplementing
security policies. Consider onceagain thesituation inwhich Alice wants tosenda
message toBobasdiscussed above. Link-level encryption isasimple andeasy-
to-understand mechanism toprotect against interception ofintersite message
traffic. However, much more isneeded ifAlice wants tobesurethatonlyBob
willreceive hermessages. Inthatcase, user-level authentication, services are
needed, andAlice mayneedtobeaware ofhowsuchservices work inorder toput
hertrustinit.User-level authentication maytherefore require atleastanotion of
cryptographic keysandawareness ofmechanisms suchascertificates, despite the
factthatmany security services arehighly automated andhidden fromusers.
Inother cases, theapplication itself isinherently complex andintroducing se-
curity onlymakes matters worse. Anexample application domain involving com-
plexsecurity protocols (aswediscuss laterinthischapter) isthatofdigital pay-
ment systems. Thecomplexity ofdigital payment protocols isoften caused bythe
factthatmultiple parties needtocommunicate tomake apayment. Inthese cases.SEC. 9.1 INTRODUCTION TOSECURITY 389
itisimportant thattheunderlying mechanisms thatareusedtoimplement thepro-
tocols arerelatively simple andeasytounderstand. Simplicity willcontribute to
thetrustthatendusers willputintotheapplication and,more importantly, will
contribute toconvincing thedesigners thatthesystem hasnosecurity holes.
9.1.3 Cryptography
Fundamental tosecurity indistributed systems istheuseofcryptographic
techniques. Thebasic ideaofapplying these techniques issimple. Consider a
sender Swanting totransmit message mtoareceiver R.Toprotect themessage
against security threats, thesender firstencrypts itintoanunintelligible message
m',andsubsequently sends m'toR.R,intum,mustdecrypt thereceived mes-
sageintoitsoriginal formm.
Encryption anddecryption areaccomplished byusing cryptographic methods
parameterized bykeys, asshown inFig.9-6.Theoriginal form ofthemessage
thatissentiscalled theplaintext, shown asPinFig.9-6;theencrypted form is
referred toastheciphertext, illustrated asC.
Figure 9-6.Intruders andeavesdroppers incommunication.
Todescribe thevarious security protocols thatareusedinbuilding security
services fordistributed systems, itisuseful tohaveanotation torelate plaintext,
ciphertext, andkeys. Following thecommon notational conventions, wewilluse
C=EK(P) todenote thattheciphertext Cisobtained byencrypting theplaintext
Pusing keyK.Likewise, P=DK(C)isused toexpress thedecryption ofthe
ciphertext Cusing keyK,resulting intheplaintext P.
Returning toourexample shown inFig.9-6,while transferring amessage as
ciphertext C,there arethree different attacks thatweneedtoprotect against, and
forwhich encryption helps. First, anintruder mayintercept themessage without
either thesender orreceiver being aware thateavesdropping ishappening. Of390 SECURITY CHAP. 9
course, ifthetransmitted message hasbeenencrypted insuchawaythatitcannot
beeasily decrypted without having theproper key,interception isuseless: thein-
truder willseeonlyunintelligible data.(Bytheway,thefactalone thatamessage
isbeing transmitted maysometimes beenough foranintruder todrawconclu-
sions. Forexample, ifduring aworld crisistheamount oftraffic intotheWhite
House suddenly drops dramatically while theamount oftraffic going intoacer-
tainmountain inColorado increases bythesameamount, theremaybeuseful in-
formation inknowing that.)
Thesecond typeofattack thatneeds tobedealtwithisthatofmodifying the
message. Modifying plaintext iseasy;modifying ciphertext thathasbeenproperly
encrypted ismuchmoredifficult because theintruder willfirsthavetodecrypt the
message before hecanmeaningfully modify it.Inaddition, hewillalsohaveto
properly encrypt itagain orotherwise thereceiver maynotice thatthemessage
hasbeentampered with.
Thethirdtypeofattack iswhen anintruder inserts encrypted messages into
thecommunication system, attempting tomake Rbelieve these messages came
fromS.Again. asweshallseelaterinthischapter, encryption canhelpprotect
against suchattacks. Notethatifanintruder canmodify messages, hecanalso
insert messages.
There isafundamental distinction between different cryptographic systems,
based onwhether ornottheencryption anddecryption keyarethesame. Ina
symmetric cryptosystem, thesamekeyisusedtoencrypt anddecrypt amessage.
Inotherwords,
Symmetric cryptosystems arealsoreferred toassecret-key orshared-key systems,
because thesender andreceiver arerequired toshare thesamekey,andtoensure
thatprotection works, thisshared keymustbekeptsecret; nooneelseisallowed
toseethekey.Wewillusethenotation KA,B todenote akeyshared byAandB.
Inanasymmetric cryptosystem, thekeysforencryption anddecryption are
different, buttogether formaunique pair.Inotherwords, thereisaseparate key
KEforenciyption andonefordecryption, KD, suchthat
P=DK (Ev (P))D AE
Oneofthekeysinanasymmetric cryptosystem iskeptprivate; theotherismade
public. Forthisreason, asymmetric cryptosystems arealsoreferred toaspublic-
keysystems. Inwhatfollows, weusethenotation K1todenote apublic key
belonging toA,andKAasitscorresponding private key.
Anticipating thedetailed discussions onsecurity protocols later inthis
chapter, which oneoftheencryption ordecryption keysthatisactually made pub-
licdepends onhowthekeysareused.Forexample, ifAlicewants tosendaconfi-
dential message toBob,sheshould useBob's public keytoencrypt themessage.
Because Bobistheonlyoneholding theprivate decryption key,heisalsothe
onlyperson thatcandecrypt themessage.SEC. 9.1 INTRODUCTION TOSECURITY 391
Ontheotherhand, suppose thatBobwants toknow forsurethatthemessage
hejustreceived actually came fromAlice. Inthatcase,Alice cankeepheren-
cryption keyprivate toencrypt themessages shesends. IfBobcansuccessfully
decrypt amessage usingAlice's public key(andtheplaintext inthemessage has
enough information tomake itmeaningful toBob), heknows thatmessage must
havecome fromAlice, because thedecryption keyisuniquely tiedtotheencryp-
tionkey.Wereturn tosuchalgorithms indetail below.
Onefinalapplication ofcryptography indistributed systems istheuseofhash
functions. Ahashfunction Htakesamessage mofarbitrary length asinputand
produces abitstring hhaving afixedlength asoutput:
Ahashhissomewhat comparable totheextrabitsthatareappended toamessage
incommunication systems toallow forerrordetection, suchacyclic-redundancy
check (CRC).
Hash functions thatareusedincryptographic systems haveanumber of
essential properties. First,theyareone-way functions, meaning thatitiscompu-
tationally infeasible tofindtheinputmthatcorresponds toaknown output h.On
theotherhand, computing hfrommiseasy.Second, theyhavetheweak collision
resistance property, meaning thatgiven aninput manditsassociated output
h=H(m), itiscomputationally infeasible tofindanother, different inputm'::/;m,
suchthatH(m)=H(m').Finally, cryptographic hashfunctions alsohavethe
strong collision resistance property, which means that,when given onlyH,itis
computationally infeasible tofindanytwodifferent inputvalues mandm';such
thatH(m) =H(m').
Similar properties mustapply toanyencryption function Eandthekeysthat
areused.Furthermore, foranyencryption function E,itshould becomputationally
infeasible tofindthekeyKwhen given theplaintext Pandassociated ciphertext
C=EK(P). Likewise, analogous tocollision resistance, when given aplaintext P
andakeyK,itshould beeffectively impossible tofindanother keyK'suchthat
EK(P) =EK,(P).
Theartandscience ofdevising algorithms forcryptographic systems hasa
longandfascinating history (Kahn, 1967), andbuilding secure systems isoften
surprisingly difficult, orevenimpossible (Schneier, 2000). Itisbeyond thescope
ofthisbooktodiscuss anyofthesealgorithms indetail. However, togivesome
impression ofcryptography incomputer systems, wewillnowbriefly present
threerepresentative algorithms. Detailed information ontheseandothercrypto-
graphic algorithms canbefound inFerguson andSchneier (2003), Menezes etaI.,
(1996), andSchneier (1996).
Before wegointothedetails ofthevarious protocols, Fig.9-7summarizes the
notation andabbreviations weuseinthemathematical expressions tofollow.392 SECURITY CHAP. 9
Figure 9-7.Notation usedinthischapter.
Symmetric Cryptosystems: DES
Ourfirstexample ofacryptographic algorithm istheDataEncryption Stan-
dard (DES), which isusedforsymmetric cryptosystems. DESisdesigned to
operate on64-bit blocks ofdata.Ablock istransformed intoanencrypted (64bit)
block ofoutput in16rounds, where eachround usesadifferent 48-bit keyfor
encryption. Eachofthese16keysisderived froma56-bit master key,asshown in
Fig.9-8(a). Before aninputblock startsits16rounds ofencryption, itisfirstsub-
jecttoaninitial permutation, ofwhich theinverse islaterapplied totheencrypted
output leading tothefinaloutput block.
Figure 9-8.(a)Theprinciple ofDES. (b)Outline ofoneencryption round.SEC. 9.1 INTRODUCTION TOSECURITY 393
Eachencryption round itakesthe64-bit block produced bytheprevious round
i-I asitsinput, asshown inFig.9-8(b). The64bitsaresplitintoaleftpartLj-1
andarightpartR,-1, eachcontaining 32bits.Therightpartisusedfortheleft
partinthenextround, thatis,L,=R,-1.
Thehardworkisdoneinthemangler function f.Thisfunction takesa32-bit
blockRj-1 asinput, together witha48-bit keyKi,andproduces a32-bit blockthat
isXORed withLj-1 toproduce Ri.(XOR isanabbreviation fortheexclusive or
operation.) Themangler function firstexpands Rj-1 toa48-bit block andXORs it
withKj• Theresult ispartitioned intoeightchunks ofsixbitseach.Eachchunk is
thenfedintoadifferent S-box, which isanoperation thatsubstitutes eachofthe
64possible 6-bitinputs intooneof16possible 4-bitoutputs. The.eightoutput
chunks offourbitseacharethencombined intoa32-bit value andpermuted
again.
The48-bit keyK,forround iisderived fromthe56-bit master keyasfollows.
First,themaster keyispermuted anddivided intotwo28-bit halves. Foreach
round, eachhalfisfirstrotated oneortwobitstotheleft,afterwhich 24bitsare
extracted. Together with24bitsfromtheotherrotated half,a48-bit keyiscon-
structed. Thedetails ofoneencryption round areshown inFig.9-9.
Figure 9-9.Details ofper-round keygeneration inDES.
Theprinciple ofDESisquitesimple, butthealgorithm isdifficult tobreak
usinganalytical methods. Using abrute-force attack bysimply searching forakey
thatwilldothejobhasbecome easyashasbeendemonstrated anumber oftimes.
However, using DESthreetimes inaspecial encrypt-decrypt-encrypt mode with394SECURITYCHAP. 9
different keys, alsoknown asTriple DESismuch more safeandisstilloften
used[seealsoBarker (2004)].
Whatmakes DESdifficult toattack byanalysis isthattherationale behind the
design hasnever beenexplained inpublic. Forexample, itisknown thattaking
other S-boxes thanarecurrently usedinthestandard, makes thealgorithm sub-
stantially easier tobreak (seePfleeger, 2003forabriefanalysis ofDES). A
rationale forthedesign anduseoftheS-boxes waspublished onlyafter"new"
attack models hadbeendevised inthe1990s. DESproved tobequiteresistant to
these attacks, anditsdesigners revealed thatthenewly devised models were
already known tothemwhentheydeveloped DESin1974(Coppersmith, 1994).
DEShasbeenusedasastandard encryption technique foryears, butiscur-
rently intheprocess ofbeing replaced bytheRijndael algorithm blocks of128
bits.There arealsovariants withlarger keysandlarger datablocks. Thealgorithm
hasbeendesigned tobefastenough sothatitcanevenbeimplemented onsmart
cards, which formanincreasingly important application areaforcryptography.
Public-Key Cryptosystems: RSA
Oursecond example ofacryptographic algorithm isverywidely usedfor
public-key systems: RSA, named afteritsinventors: Rivest, Shamir, andAdleman
(1978). Thesecurity ofRSAcomes fromthefactthatnomethods areknown to
efficiently findtheprime factors oflargenumbers. Itcanbeshown thateach
integer canbewritten astheproduct ofprime numbers. Forexample, 2100canbe
written as
2100=2x2x3x5x5x7
making 2,3,5,and7theprime factors in2100. InRSA, theprivate andpublic
keysareconstructed fromverylargeprime numbers (consisting ofhundreds of
decimal digits). Asitturnsout,breaking RSAisequivalent tofinding those two
prime numbers. Sofar,thishasshown tobecomputationally infeasible despite
mathematicians working ontheproblem forcenturies.
Generating theprivate andpublic keysrequires foursteps:
1.Choose twoverylargeprime numbers, pandq.
2.Compute n=pxqandz=(p-1)x(q-1).
3.Choose anumber dthatisrelatively prime toz.
4.Compute thenumber esuchthatexd=1modz.
Oneofthenumbers, sayd,cansubsequently beusedfordecryption, whereas eis
usedforencryption. Onlyoneofthesetwoismadepublic, depending onwhatthe
algorithm isbeing usedfor.SEC. 9.1 INTRODUCTION TOSECURITY 395
Letusconsider thecasethatAlice wants tokeepthemessages shesends to
Bobconfidential. Inother words, shewants toensure thatnoonebutBobcan
intercept andreadhermessages tohim.RSAconsiders eachmessage mtobejust
astring ofbits.Eachmessage isfirstdivided intofixed-length blocks, where each
block-ei., interpreted asabinary number, should lieintheinterval 0:s;m,<n.
Toencrypt message m,thesender calculates foreachblock m,thevalue
c,=mf(mod n),which isthensenttothereceiver. Decryption atthereceiver's
sidetakesplacebycomputing m,=cf(mod n).Notethatfortheencryption, both
eandnareneeded, whereas decryption. requires knowing thevalues dandn.
When comparing RSAtosymmetric cryptosystems suchasDES,RSAhasthe
drawback ofbeing computationally morecomplex. Asitturnsout,encrypting
messages usingRSAisapproximately 100-1000 times slower thanDES,depend-
ingontheimplementation technique used.Asaconsequence, manycryptographic
systems useRSAtoexchange onlyshared keysinasecure way,butmuchlessfor
actually encrypting "normal" data.Wewillseeexamples ofthecombination of
thesetwotechniques laterinsucceeding sections.
HashFunctions: MD5
Asalastexample ofawidely-used cryptographic algorithm, wetakealookat
MD5 (Rivest, 1992). l\'ID5 isahashfunction forcomputing a128-bit, fixed
length message digest fromanarbitrary length binary input string. Theinput
string isfirstpadded toatotallength of448bits(modulo 512),afterwhich the
length oftheoriginal bitstring isadded asa64-bit integer. Ineffect, theinputis
converted toaseries of512-bit blocks.
Thestructure ofthealgorithm isshown inFig.9-10. Starting withsomecon-
stant128-bit value, thealgorithm proceeds inkphases, where kisthenumber of
512-bit blocks comprising thepadded message. During eachphase, a128-bit dig-
estiscomputed outofa512-bit block ofdatacoming fromthepadded message,
andthe128-bit digest computed inthepreceding phase.
Figure 9-10. Thestructure ofM05.396 SECURITY CHAP. 9
Aphase inMD5consists offourrounds ofcomputations. where eachround uses
oneofthefollowing fourfunctions:
F(x.y.z) =(xAND y)OR«NOT x)AND z)
G(r.y.z) =(xAND z)OR(yAND (NOT z)
Htx.y.z) =xXOR yXOR z
I(z.y.z) =yXOR (xOR(NOT z)
Eachofthesefunctions operates on32-bit variables x,y.andz.Toillustrate how
thesefunctions areused,consider a512-bit block bfromthepadded message that
isbeing processed during phase k.Block bisdivided into1632-bit subblocks
bo,b I••••,b15.During thefirstround, function Fisusedtochange fourvariables
(denoted asp,q,r,ands,respectively) in16iterations asshown inFig.9-11
These variables arecarried toeachnextround, andafteraphase hasfinished,
passed ontothenextphase. There areatotalof64predefined constants Ci,The
notation x<<<nisusedtodenote aleftrotate: thebitsinxareshifted npositions
totheleft,where thebitshifted offtheleftisplaced intherightmost position.
Figure 9-11. The16iterations during thefirstround inaphase inMD5.
Thesecond round usesthefunction Ginasimilar fashion, whereas HandI
areusedinthethirdandfourth round, respectively. Eachstepthusconsists of64
iterations. afterwhich thenextphase isstarted, butnowwiththevalues thatP.q,
r,andshaveatthatpoint.
9.2SECURE CHANNELS
Inthepreceding chapters. wehavefrequently usedtheclient-server model as
aconvenient waytoorganize adistributed system. Inthismodel, servers maypos-
siblybedistributed andreplicated, butalsoactasclients withrespect tootherser-
vers.When considering security indistributed systems, itisonceagain useful to
think interms ofclients andservers. Inparticular, making adistributed system
secure essentially boilsdown totwopredominant issues. ThefirstissueishowtoSEC. 9.2 SECURE CHANNELS 397
makethecommunication between clients andservers secure. Secure communica-
tionrequires authentication ofthecommunicating parties. Inmany cases italso
requires ensuring message integrity andpossibly confidentiality aswell.Aspart
ofthisproblem, wealsoneedtoconsider protecting thecommunication within a
group ofservers.
Thesecond issueisthatofauthorization: onceaserver hasaccepted arequest
fromaclient, howcanitfindoutwhether thatclient isauthorized tohavethatre-
questcarried out?Authorization isrelated totheproblem ofcontrolling access to
resources, which wediscuss extensively inthenextsection. Inthissection, we
concentrate onprotecting thecommunication within adistributed system.
Theissueofprotecting communication between clients andservers, canbe
thought ofinterms ofsetting upasecure channelbetween communicating par-
ties(Voydock andKent, 1983). Asecure channel protects senders andreceivers
against interception, modification, andfabrication ofmessages. Itdoesnotalso
necessarily protect against interruption. Protecting messages against interception
isdonebyensuring confidentiality: thesecure channel ensures thatitsmessages
cannot beeavesdropped byintruders. Protecting against modification andfabrica-
tionbyintruders isdonethrough protocols formutual authentication andmessage
integrity. Inthefollowing pages, wefirstdiscuss various protocols thatcanbe
usedforauthentication, using symmetric aswellaspublic-key cryptosystems. A
detailed description ofthelogics underlying authentication canbefound inLamp-
sonetal.(1992). Wediscuss confidentiality andmessage integrity separately.
9.2.1Authentication
Before going intothedetails ofvarious authentication protocols, itisworth-
while noting thatauthentication andmessage integrity cannot dowithout each
other. Consider, forexample, adistributed system thatsupports authentication of
twocommunicating parties, butdoesnotprovide mechanisms toensure message
integrity. Insuchasystem, Bobmayknow forsurethatAlice isthesender ofa
message m.However, ifBobcannot begivenguarantees thatmhasnotbeenmod-
ifiedduring transmission, whatuseisittohimtoknow thatAlice sent(theorigi-
nalversion of)m?
Likewise, suppose thatonlymessage integrity issupported, butnomechan-
ismsexistforauthentication. When Bobreceives amessage stating thathehas
justwon$1,000,000 inthelottery, howhappy canhebeifhecannot verify that
themessage wassentbytheorganizers ofthatlottery?
Consequently, authentication andmessage integrity should gotogether. In
many protocols, thecombination works roughly asfollows. Again, assume that
Alice andBobwanttocommunicate, andthatAlice takestheinitiative insetting
upachannel. Alice startsbysending amessage toBob,orotherwise toatrusted
thirdpartywhowillhelpsetupthechannel. Oncethechannel hasbeensetup,398SECURITYCHAP. 9
Aliceknows forsurethatsheistalking toBob,andBobknows forsureheistalk-
ingtoAlice. theycanexchange messages.
Tosubsequently ensure integrity ofthedatamessages thatareexchanged
afterauthentication hastaken place, itiscommon practice tousesecret-key cryp-
tography bymeans ofsession keys.Asession keyisashared (secret) keythatis
usedtoencrypt messages forintegrity andpossibly alsoconfidentiality. Sucha
keyisgenerally usedonlyforaslongasthechannel exists. When thechannel, is
closed, itsassociated session keyisdiscarded (oractually, securely destroyed).
Wereturn tosession keysbelow.
Authentication Based onaShared Secret Key
Letusstartbytaking alookatanauthentication protocol based onasecret
keythatisalready shared between AliceandBob.Howthetwoactually managed
toobtain ashared keyinasecure wayisdiscussed laterinthischapter. Inthe
description oftheprotocol, Alice andBobareabbreviated byAandB,respec-
tively, andtheirshared keyisdenoted asKA,B' Theprotocol takesacommon ap-
proach whereby onepartychallenges theothertoaresponse thatcanbecorrect
onlyiftheotherknows theshared secret key.Suchsolutions arealsoknown as
challenge-response protocols. '
Inthecaseofauthentication based onashared secret key,theprotocol
proceeds asshown inFig.9-12. First,Alice sends heridentity toBob(message
1),indicating thatshewants tosetupacommunication channel between thetwo.
Bobsubsequently sends achallenge RB toAlice, shown asmessage 2.Sucha
challenge could taketheformofarandom number. Alice isrequired toencrypt
thechallenge withthesecret keyKA,Bthatsheshares withBob,andreturn the
encrypted challenge toBob.Thisresponse isshown asmessage 3inFig.9-12
containing KA,B(RB)·
Figure 9-12. Authentication based onashared secret key.
When Bobreceives theresponse KA,B(RB) tohischallenge RB,hecandecrypt
themessage using theshared keyagain toseeifitcontains RB· Ifso,hethen
knows thatAlice isontheotherside,forwhoelsecould haveencrypted RBwithSEC. 9.2 SECURE CHANNELS 399
K-t.B inthefirstplace? Inotherwords, Bobhasnowverified thatheisindeed talk-
ingtoAlice. However, notethatAlice hasnotyetverified thatitisindeed Bobon
theothersideofthechannel. Therefore, shesends achallenge R.tt(message 4),
which Bobresponds tobyreturning ~.B(R.tt), shown asmessage 5.When Alice
decrypts itwithKA,B andseesher"R.tt,sheknows sheistalking toBob.
Oneoftheharder issues insecurity isdesigning protocols thatactually work.
Toillustrate howeasily things cangowrong, consider an"optimization" ofthe
authentication protocol inwhich thenumber ofmessages hasbeenreduced from
fivetothree, asshown inFig.9-13. Thebasic ideaisthatifAlice eventually
wants tochallenge Bobanyway, shemight aswellsendachallenge along with
heridentity when setting upthechannel. Likewise, Bobreturns his.response to
thatchallenge, alongwithhisownchallenge inasingle message.
Figure 9-13. Authentication based onashared secret key,butusing three in-
steadoffivemessages.
Unfortunately, thisprotocol nolonger works. Itcaneasily bedefeated by
whatisknown asareflection attack. Toexplain howsuchanattack works, con-
sideranintruder called Chuck, whom wedenote asCinourprotocols. Chuck's
goalistosetupachannel withBobsothatBobbelieves heistalking toAlice.
Chuck canestablish thisifheresponds correctly toachallenge sentbyBob,for
instance, byreturning theencrypted version ofanumber thatBobsent.Without
knowledge ofKA•B, onlyBobcandosuchanencryption, andthisisprecisely what
Chuck tricks Bobintodoing.
Theattack isillustrated inFig.9-14. Chuck startsoutbysending amessage
containing Alice's identity A,along withachallenge Re.Bobreturns hischal-
lenge RBandtheresponse KA.B(Re) inasingle message. Atthatpoint, Chuck
would needtoprove heknows thesecret keybyreturning KA,B(RB) toBob.Unfor-
tunately, hedoesnothaveKA,B' Instead, whathedoesisattempt tosetupasec-
ondchannel toletBobdotheencryption forhim.
Therefore, Chuck sendsAandRBinasingle message asbefore, butnowpre-
tends thathewants asecond channel. Thisisshown asmessage 3inFig.9-14.
Bob,notrecognizing thathe,himself, hadusedRBbefore asachallenge, responds
withKA,B(RB) andanother challenge Rs2, shown asmessage 4.Atthatpoint,400SECURITYCHAP. 9
Figure 9-14. Thereflection attack.
Chuck hasKA,B(RB)andfinishes setting upthefirstsession byreturning message
5containing theresponse KA,B(RB), which wasoriginally requested fromthechal-
lenge sentinmessage 2.
Asexplained inKaufman etal.(2003), oneofthemistakes made during the
adaptation oftheoriginal protocol wasthatthetwoparties inthenewversion of
theprotocol wereusing thesamechallenge intwodifferent runsoftheprotocol.
Abetter design istoalways usedifferent challenges fortheinitiator andforthe
responder. Forexample, ifAlice always usesanoddnumber andBobaneven
number, Bobwould haverecognized thatsomething fishywasgoing onwhen
receiving RBinmessage 3inFig.9-14. (Unfortunately, thissolution issubject to
.otherattacks, notably theoneknown asthe"man-in-the-middle-attack," which is
explained inFerguson andSchneier, 2003). Ingeneral, letting thetwoparties set-
tingupasecure channel doanumber ofthings identically isnotagoodidea.
Another principle thatisviolated intheadapted protocol isthatBobgave
awayvaluable information intheformoftheresponse KA,B(Rd without knowing
forsuretowhom hewasgiving it.Thisprinciple wasnotviolated intheoriginal
protocol, inwhich Alicefirstneeded toprove heridentity, afterwhich Bobwas
willing topassherencrypted information.
There. areother principles thatdevelopers ofcryptographic protocols have
gradually come tolearnovertheyears, andwewillpresent some ofthemwhen
discussing otherprotocols below. Oneimportant lesson isthatdesigning security
protocols thatdowhattheyaresupposed todoisoftenmuch harder thanitlooks.
Also,tweaking anexisting protocol toimprove itsperformance, caneasily affect
itscorrectness aswedemonstrated above. More ondesign principles forprotocols
canbefound inAbadi andNeedham (1996).
Authentication Using aKeyDistribution Center
Oneoftheproblems withusingashared secret keyforauthentication isscala-
bility. Ifadistributed system contains Nhosts, andeachhostisrequired tosharea
secret keywitheachoftheotherN-1hosts, thesystem asawhole needs toSEC. 9.2 SECURE CHANNELS 401
manage N(N-1)/2 keys,andeachhosthastomanage N-Ikeys.ForlargeN,
thiswillleadtoproblems. Analternative istouseacentralized approach by
means ofaKeyDistribution Center (KDC). ThisKDCshares asecret keywith
eachofthehosts, butnopairofhostsisrequired tohaveashared secret keyas
well.Inother words, using aKDC requires thatwemanage Nkeysinstead of
N(N-1)/2,which isclearly animprovement.
IfAlice wants tosetupasecure channel withBob,shecandosowiththe
helpofa(trusted) KDC. Thewhole ideaisthattheKDChands outakeytoboth
AliceandBobthattheycanuseforcommunication, shown inFig.9-15.
Figure 9-15. Theprinciple ofusing aKDC.
Alice firstsends amessage totheKDC, telling itthatshewants totalkto
Bob.TheKDCreturns amessage containing ashared secret keyKA,B thatshecan
use.Themessage isencrypted withthesecret keyKA,KDC thatAlice shares with
theKDC. Inaddition, theKDCsends KA,B alsotoBob,butnowencrypted with
thesecret keyKBKDC itshares withBob. ,
Themaindrawback ofthisapproach isthatAlice maywanttostartsetting up
asecure channel withBobevenbefore Bobhadreceived theshared keyfromthe
KDC. Inaddition, theKDCisrequired togetBobintotheloopbypassing himthe
key.These problems canbecircumvented iftheKDCjustpasses KB,KDC(KA,B)
backtoAlice, andletshertakecareofconnecting toBob.Thisleadstotheproto-
colshown inFig.9-16. Themessage ~,KDC(KA,B) isalsoknown asaticket. Itis
Alice's jobtopassthisticket toBob.NotethatBobisstilltheonlyonethatcan
make sensible useoftheticket, asheistheonlyonebesides theKDCwhoknows
howtodecrypt theinformation itcontains.
Theprotocol shown inFig.9-16isactually avariant ofawell-known example
ofanauthentication protocol using aKDC, known astheNeedham-Schroeder
authentication protocol, named afteritsinventors (Needham andSchroeder,
1978). Adifferent variant oftheprotocol isbeing usedintheKerberos system,
which wedescribe later.TheNeedham-Schroeder protocol, shown inFig.9-17,is
amultiway challenge-response protocol andworks asfollows.
When Alice wants tosetupasecure channel withBob,shesends arequest to
theKDCcontaining achallenge RA,along withheridentity Aand,ofcourse, that402SECURITYCHAP. 9
Figure 9-16. Using aticket andletting Alice setupaconnection toBob.
Figure 9-17. TheNeedham-Schroeder authentication protocol.
ofBob.TheKDCresponds bygiving hertheticket KBKDC(KA B),along withthe , ,
secret keyKA,Bthatshecansubsequently sharewithBob.
Thechallenge RA1thatAlice sends totheKDC along withherrequest toset
upachannel toBobisalsoknown asanonce. Anonceisarandom number thatis
usedonlyonce, suchasonechosen fromaverylargeset.Themainpurpose ofa
nonce istouniquely relate twomessages toeachother, inthiscasemessage 1and
message 2.Inparticular, byincluding RA1againinmessage 2,Alicewillknow for
surethatmessage 2issentasaresponse tomessage 1,andthatitisnot,forex-
ample, areplay ofanoldermessage.
Tounderstand theproblem athand, assume thatwedidnotusenonces, and
thatChuck hasstolen oneofBob's oldkeys, sayKB~~DC' Inaddition, Chuck has
intercepted anoldresponse KA.KDcCB,KA,B,KB~fDC(A,KA.B)) thattheKDChadre-
turned toaprevious request fromAlice totalktoBob.Meanwhile, Bobwillhave
negotiated anewshared secret keywiththeKDC. However, Chuck patiently
waitsuntilAlice againrequests tosetupasecure channel withBob.Atthatpoint,
hereplays theoldresponse, andfoolsAlice intomaking herbelieve sheistalkingSEC. 9.2 SECURE CHANNELS 403
toBob,because hecandecrypt theticket andprove heknows theshared secret
keyK.4..B' Clearly thisisunacceptable andmustbedefended against.
Byincluding anonce, suchanattack isimpossible, because replaying anolder
message willimmediately bediscovered. Inparticular, thenonce intheresponse
message willnotmatch thenonce intheoriginal request.
Message 2alsocontains B,theidentity ofBob.Byincluding B,theKDCpro-
tectsAliceagainst thefollowing attack. Suppose thatBwasleftoutofmessage 2.
Inthatcase,Chuck could modify message 1byreplacing theidentity ofBobwith
hisownidentity, sayC.TheKDCwould thenthinkAlice wantsto setupasecure
channel toChuck, andresponds accordingly. AssoonasAlice wants tocontact
Bob,Chuck intercepts themessage andfoolsAlice intobelieving sheistalking to
Bob.Bycopying theidentity oftheotherparty frommessage 1tomessage 2,
Alicewillimmediately detect thatherrequest hadbeenmodified.
After theKDC haspassed theticket toAlice, thesecure channel between
AliceandBobcanbesetup.Alice startswithsending message 3,which contains
thetickettoBob,andachallenge RA2encrypted withtheshared keyKA,B. thatthe
KDChadjustgenerated. Bobthendecrypts theticket tofindtheshared key,and
returns aresponse RA2-1along withachallenge RB forAlice.
Thefollowing remark regarding message 4isinorder. Ingeneral, byre-
turning RA2-1andnotjustRA2,Bobnotonlyproves heknows theshared secret
key,butalsothathehasactually decrypted thechallenge. Again, thistiesmessage
4tomessage 3inthesamewaythatthenonce ~tiedmessage 2tomessage 1.
Theprotocol isthusmoreprotected against replays.
However, inthisspecial case,itwould havebeensufficient tojustreturn
KA,B(RA2,RB), forthesimple reason thatthismessage hasnotyetbeenusedany-
where intheprotocol before. KA,B(RA2,RB) already proves thatBobhasbeen
capable ofdecrypting thechallenge sentinmessage 3.Message 4asshown in
Fig.9-17isduetohistorical reasons.
TheNeedham-Schroeder protocol aspresented herestillhastheweak point
thatifChuck evergotaholdofanoldkey~,B' hecould replay message 3and
getBobtosetupachannel. Bobwillthenbelieve heistalking toAlice, while, in
fact,Chuck isattheotherend.Inthiscase,weneedtorelate message 3tomes-
sage1,thatis,make thekeydependent ontheinitial request fromAlice tosetup
achannel withBob.Thesolution isshown inFig.9-18.
Thetrickistoincorporate anonce intherequest sentbyAlice totheKDC.
However, thenonce hastocome fromBob:thisassures Bobthatwhoever wants
tosetupasecure channel withhim,willhavegotten theappropriate information
fromtheKDC. Therefore, Alice firstrequests Bobtosendheranonce RB1,
encrypted withthekeyshared between BobandtheKDC. Aliceincorporates this
nonce inherrequest totheKDC, which willthensubsequently decrypt itandput
theresult inthegenerated ticket. Inthisway,Bobwillknow forsurethattheses-
sionkeyistiedtotheoriginal request fromAlicetotalktoBob.404SECURITYCHAP. 9
Figure 9-18. Protection against malicious reuse ofapreviously generated ses-
sionkeyintheNeedham-Schroeder protocol.
Figure 9-19. Mutual authentication inapublic-key cryptosystem.
Authentication Using Public-Key Cryptography
Letusnowlookatauthentication withapublic-key cryptosystem thatdoes
notrequire aKDC. Again, consider thesituation thatAlice wants tosetupa
secure channel toBob,andthatbothareinthepossession ofeachother's public
key.Atypical authentication protocol based onpublic-key cryptography isshown
inFig.9-19,which weexplain next.
Alicestartswithsending ~challenge RAtoBobencrypted withhispublic key
!G.ItisBob's jobtodecrypt themessage andreturn thechallenge toAlice. Be-
cause Bobistheonlyperson thatcandecrypt themessage (using theprivate key
thatisassociated withthepublic keyAliceused). Alice willknow thatsheistalk-
ingtoBob.Notethatitisimportant thatAlice isguaranteed tobeusing Bob's
public key,andnotthepublic keyofsomeone impersonating Bob.Howsuch
guarantees canbegiven isdiscussed laterinthischapter.
When Bobreceives Alice's request tosetupachannel, hereturns the
decrypted challenge, along withhisownchallenge RBtoauthenticate Alice. Inad-
dition, hegenerates asession keyKA,B thatcanbeusedforfurther communica-
tion.Bob's response toAlice's challenge, hisownchallenge, andthesession keySEC. 9.2 SECURE CHANNELS 405
areputintoamessage encrypted withthepublic keyK;tbelonging toAlice,
shown asmessage 2inFig.9-19. OnlyAlice willbecapable ofdecrypting this
message usingtheprivate keyKi.associated withK;t.
Alice, finally, returns herresponse toBob's challenge using thesession key
KA.B .generated byBob.Inthatway,shewillhaveproven thatshecould decrypt
message 2,andthusthatsheisactually Alicetowhom Bobistalking.
9.2.2Message Integrity andConfidentiality
Besides authentication, asecure channel should alsoprovide guarantees for
message integrity andconfidentiality. Message integrity means thatmessages are
protected against surrepitious medification; confidentiality ensures thatmessages
cannot beintercepted andreadbyeavesdroppers. Confidentiality iseasily esta-
blished bysimply encrypting amessage before sending it.Encryption cantake
placeeither through asecret keyshared withthereceiver oralternatively byusing
thereceiver's public key.However, protecting amessage against modifications is
somewhat morecomplicated, aswediscuss next.
Digital Signatures
Message integrity often goesbeyond theactual transfer through asecure
channel. Consider thesituation inwhich BobhasjustsoldAliceacollector's item
ofsomephonograph record for$500. Thewhole dealwasdonethrough e-mail. In
theend,Alice sends Bobamessage confirming thatshewillbuytherecord for
$500. Inaddition toauthentication, thereareatleasttwoissues thatneedtobe
takencareofregarding theintegrity ofthemessage.
1.Alice needs tobeassured thatBobwillnotmaliciously change the
$500mentioned inhermessage intosomething higher, andclaim she
promised morethan$500.
2.Bobneeds tobeassured thatAlice cannot denyeverhaving sentthe
message, forexample, because shehadsecond thoughts.
These twoissues canbedealtwithifAlicedigitally signsthemessage insuch
awaythathersignature isuniquely tiedtoitscontent. Theunique association be-
tween amessage anditssignature prevents thatmodifications tothemessage will
gounnoticed. Inaddition, ifAlice's signature canbeverified tobegenuine, she
cannot laterrepudiate thefactthatshesigned themessage.
There areseveral waystoplacedigital signatures. Onepopular formistouse
apublic-key cryptosystem suchasRSA, asshown inFig.9-20. When Alice
sends amessage mtoBob,sheencrypts itwithherprivate keyK;.,andsends it406 SECURITY CHAP. 9
offtoBob. Ifshealsowants tokeep themessage content asecret, shecanuse
Bob's public keyandsend K/i(m,KA(m», which combines mandtheversion
signed byAlice.
Figure 9·20. Digital signing amessage using public-key cryptography.
When themessage arrives atBob,hecandecrypt itusing Alice's public key.
Ifhecanbeassured thatthepublic keyisindeed owned byAlice, thendecrypting
thesigned version ofmandsuccessfully comparing itto111canmean onlythatit
came fromAlice. Alice isprotected against anymalicious modifications tomby
Bob,because Bobwillalways havetoprove thatthemodified version ofmwas
alsosigned byAlice. Inother words, thedecrypted message alone essentially
never counts asproof. ItisalsoinBob's owninterest tokeepthesigned version of
mtoprotect himself against repudiation byAlice.
There areanumber ofproblems withthisscheme, although theprotocol init-
selfiscorrect. First, thevalidity ofAlice's signature holds onlyaslongasAlice's
private keyremains asecret. IfAlice wants tobailoutofthedealevenaftersend-
ingBobherconfirmation, shecould claim. thatherprivate keywasstolen before
themessage wassent.
Another problem occurs when Alice decides tochange herprivate key.Doing
somayinitselfbenotsuchabadidea,aschanging keysfromtimetotimegener-
allyhelps against intrusion. However, onceAlice haschanged herkey,herstate-
ment senttoBobbecomes worthless. What maybeneeded insuchcases isacen-
tralauthority thatkeeps track ofwhen keysarechanged, inaddition tousing time-
stamps when signing messages.
Another problem withthisscheme isthatAlice encrypts theentire message
withherprivate key.Such anencryption maybecostly interms ofprocessing re-
quirements (oreven mathematically infeasible asweassume thatthemessage
interpreted asabinary number isbounded byapredefined maximum), andisactu-
allyunnecessary. Recall thatweneedtouniquely associate asignature withaonly
specific message. Acheaper andarguably more elegant scheme istouseames-
sagedigest.
Asweexplained, amessage digest isafixed-length bitstring hthathasbeen
computed from anarbitrary-length message 111bymeans ofacryptographic hash
function H.Ifmischanged tom',itshashH(111')willbedifferent from h=H(m)
sothatitcaneasily bedetected thatamodification hastaken place.SEC. 9.2 SECURE CHANNELS 407
Todigitally signamessage, Alice canfirstcompute amessage digest and
subsequently encrypt thedigest withherprivate key,asshown inFig.9-21. The
encrypted digest issentalong withthemessage toBob. Notethatthemessage it-
selfissentasplaintext: everyone isallowed toreadit.Ifconfidentiality isre-
quired, thenthemessage should alsobeencrypted withBob's public key.
Figure 9-21. Digitally signing amessage using amessage digest.
When Bobreceives themessage anditsencrypted digest, heneed merely
decrypt thedigest withAlice's public key,andseparately calculate themessage
digest. Ifthedigest calculated fromthereceived message andthedecrypted digest
match, Bobknows themessage hasbeensigned byAlice.
Session Keys
During theestablishment ofasecure channel, aftertheauthentication phase
hascompleted, thecommunicating parties generally useaunique shared session
keyforconfidentiality. Thesession keyissafely discarded when thechannel isno
longer used. Analternative would havebeentousethesame keysforconfiden-
tiality asthose thatareusedforsetting upthesecure channel. However, there are
anumber ofimportant benefits tousing session keys(Kaufman etaI.,2003).
First, when akeyisusedoften, itbecomes easier toreveal it.Inasense, cryp-
tographic keysaresubject to"wear andtear" justlikeordinary keys. Thebasic
ideaisthatifanintruder canintercept alotofdatathathavebeenencrypted using
thesame key,itbecomes possible tomount attacks tofindcertain characteristics
ofthekeysused, andpossibly reveal theplaintext orthekeyitself. Forthisrea-
son,itismuch safertousetheauthentication keysaslittleaspossible. Inaddition,
suchkeysareoften exchanged using some relatively time-expensive out-of-band
mechanism suchasregular mailortelephone. Exchanging keysthatwayshould
bekepttoaminimum.
Another important reason forgenerating aunique keyforeachsecure channel
istoensure protection against replay attacks aswehavecome across previously a408 SECURITY CHAP. 9
number oftimes. Byusingaunique session keyeachtimeasecure channel isset
up,thecommunicating parties areatleastprotected against replaying anentire
session. Toprotect replaying individual messages fromaprevious session, addi-
tional measures aregenerally needed suchasincluding timestamps orsequence
numbers aspartofthemessage content.
Suppose thatmessage integrity andconfidentiality wereachieved byusing the
samekeyusedforsession establishment. Inthatcase,whenever thekeyiscom-
promised, anintruder maybeabletodecrypt messages transferred during anold
conversation, clearly notadesirable feature. Instead, itismuch safertouseper-
session keys,because ifsuchakeyiscompromised, atworst, onlyasingle session
isaffected. Messages sentduring othersessions stayconfidential.
Related tothislastpointisthatAlice maywanttoexchange some confiden-
tialdatawithBob,butshedoesnottrusthimsomuch thatshewould givehimin-
formation intheformofdatathathavebeenencrypted withlong-lasting keys.She
maywanttoreserve suchkeysforhighly-confidential messages thatsheex-
changes withparties shereally trusts. Insuchcases, using arelatively cheap ses-
sionkeytotalktoBobissufficient.
Byandlarge, authentication keysareoftenestablished insuchawaythatre-
placing themisrelatively expensive. Therefore, thecombination ofsuchlong-
lasting keyswiththemuch cheaper andmoretemporary session keysisoftena
goodchoice forimplementing secure channels forexchanging data.
9.2.3 Secure Group Communication
Sofar,wehaveconcentrated onsetting upasecure communication channel
between twoparties. Indistributed systems, however, itisoften necessary to
enable secure communication between morethanjusttwoparties. Atypical ex-
ample isthatofareplicated server forwhich allcommunication between therep-
licasshould beprotected against modification, fabrication, andinterception, just
asinthecaseoftwo-party secure channels. Inthissection, wetakeacloser look
atsecure group communication.
Confidential Group Communication
First,consider theproblem ofprotecting communication between agroup of
Nusersagainst eavesdropping. Toensure confidentiality, asimple scheme istolet
allgroup members sharethesame secret key,which isusedtoencrypt andde-
cryptallmessages transmitted between group members. Because thesecret keyin
thisscheme isshared byallmembers, itisnecessary thatallmembers aretrusted
toindeed keepthekeyasecret. Thisprerequisite alonemakes theuseofasingle
shared secret keyforconfidential group communication more vulnerable to
attacks compared totwo-party secure channels.SEC. 9.2 SECURE CHANNELS 409
Analternative solution istouseaseparate shared secret keybetween each
pairofgroup members. Assoonasonemember turnsouttobeleaking informa-
tion,theothers cansimply stopsending messages tothatmember, butstillusethe
keystheywereusingtocommunicate witheachother. However, instead ofhaving
tomaintain onekey,itisnownecessary tomaintain N(N -1)/2keys,which may
beadifficult problem byitself.
Using apublic-key cryptosystem canimprove matters. Inthatcase, each
member hasitsown(public key,private key)pair,inwhich thepublic keycanbe
usedbyallmembers forsending confidential messages. Inthiscase,atotalofN
keypairsareneeded. Ifonemember ceases tobetrustworthy, itissimply re-
moved fromthegroup without having beenabletocompromise theotherkeys.
Secure Replicated Servers
Nowconsider acompletely different problem: aclient issues arequest toa
group ofreplicated servers. Theservers mayhavebeenreplicated forreasons of
faulttolerance orperformance, butinanycase,theclient expects theresponse to
betrustworthy. Inotherwords, regardless ofwhether thegroup ofservers issub-
jecttoByzantine failures aswediscussed intheprevious chapter, aclient expects
thatthereturned response hasnotbeensubject toasecurity attack. Suchanattack
could happen ifoneormore servers hadbeensuccessfully corrupted byanin-
truder.
Asolution toprotect theclient against suchattacks istocollect theresponses
fromallservers andauthenticate eachoneofthem.If amajority exists among the
responses fromthenoncorrupted (i.e.,authenticated) servers, theclient cantrust
theresponse tobecorrect aswell.Unfortunately, thisapproach reveals therepli-
cation oftheservers, thusviolating replication transparency.
Reiter etal.(1994) proposes asolution toasecure, replicated server inwhich
replication transparency ismaintained. Theadvantage oftheirscheme isthatbe-
cause clients areunaware oftheactual replicas, itbecomes much easier toaddor
remove replicas inasecure way.Wereturn tomanaging secure groups below
whendiscussing keymanagement.
Theessence ofsecure andtransparent replicated servers liesinwhatisknown
assecret sharing. When multiple users (orprocesses) share asecret, noneof
themknows theentire secret. Instead, thesecret canberevealed onlyiftheyall
gettogether. Such schemes canbeextremely useful. Consider, forexample,
launching anuclear missile. Suchanactgenerally requires theauthorization ofat
leasttwopeople. Eachofthemholds aprivate keythatshould beusedincombi-
nation withtheothertoactually launch amissile. Using onlyasingle keywillnot
do.
Inthecaseofsecure, replicated servers, whatweareseeking isasolution by
which atmostkoutoftheNservers canproduce anincorrect answer, andofthose
kservers, atmostc~khaveactually beencorrupted byanintruder. Notethatthis410 SECURITY CHAP.9
requirement makes theservice itself kfaulttolerant asdiscussed intheprevious
chapter. Thedifference liesinthefactthatwenowclassify amaliciously cor-
rupted server asbeing faulty.
Nowconsider thesituation inwhich theservers areactively replicated. Inoth-
erwords, arequest issenttoallservers simultaneously, andsubsequently handled
byeachofthem. Each server produces aresponse thatitreturns totheclient. For
asecurely replicated group ofservers, werequire thateachserver accompanies, its
response withadigital signature. Ifr,istheresponse from server S;,letmd(ri)
denote themessage digest computed byserver Si.Thisdigest issigned withserver
S,'sprivate keyK].
Suppose thatwewanttoprotect theclient against atmostccorrupted servers.
Inother words, theserver group should beabletotolerate corruption byatmost c
servers, andstillbecapable ofproducing aresponse thattheclient canputitstrust
in.Ifthesignatures oftheindividual servers could becombined insuchawaythat
atleastc+1signatures areneeded toconstruct avalid signature fortheresponse,
thenthiswould solve ourproblem. Inother words, wewanttoletthereplicated
servers generate asecret valid signature withtheproperty thatccorrupted ser-
versalone arenotenough toproduce thatsignature.
Asanexample, consider agroup offivereplicated servers thatshould beable
totolerate twocorrupted servers, andstillproduce aresponse thataclient can
trust. Each server S,sends itsresponse r,totheclient, along withitssignature
sig(S;,r;) =Kj(md (r;)). Consequently, theclient willeventually have received
fivetriplets «r.,md(r;),sig(S;,rJ>from which itshould derive thecorrect
response. Thissituation isshown inFig.9-22.
Each digest md(ri)isalsocalculated bytheclient. Ifr,isincorrect, thennor-
mally thiscanbedetected bycomputing Kt(Kj(md(ri)))' However, thismethod
cannolonger beapplied, because noindividual server canbetrusted. Instead, the
client usesaspecial, publicly-known decryption function D,which takes aset
V={sig(S,r),sig (S',r'),sig (S",r")} ofthree signatures asinput, andproduces a
single digest asoutput:
dout =D(V)=D(sig(S,r),sig (S',r'),sig (S", r"))
Fordetails onD,seeReiter (1994). There are5!/(3!2!)=10 possible combinations
ofthree signatures thattheclient canuseasinput forD.Ifoneofthese combina-
tions produces acorrect digest md(r;)forsome response r.,thentheclient can
consider r,asbeing correct. Inparticular, itcantrustthattheresponse hasbeen
produced byatleastthreehonest servers.
Toimprove replication transparency, Reiter andBirman leteach server S;
broadcast amessage containing itsresponse r,totheother servers, along withthe
associated signature sig(Si,r;). When aserver hasreceived atleastc+1ofsuch
messages, including itsownmessage. itattempts tocompute avalid signature for"
oneoftheresponses. Ifthissucceeds for,say,response randthesetVofc+1
signatures. theserver sends randVasasingle message totheclient. TheclientSEC. 9.2 SECURE CHANNELS 411
Figure 9-22. Sharing asecret signature inagroup ofreplicated servers.
cansubsequently verify thecorrectness ofrbychecking itssignature, thatis,
whether md(r) =D(V).
What wehavejustdescribed isalsoknown as.an (m,n)-threshold scheme
with, inourexample, m=c+1andn=N,thenumber ofservers. Inan(m,n)-
threshold scheme, amessage hasbeendivided intonpieces, known asshadows,
since anymshadows canbeusedtoreconstruct theoriginal message, butusing
m-1orfewer messages cannot. There areseveral ways toconstruct (m,n)-
threshold schemes. Details canbefound inSchneier (1996).
9.2.4 Example: Kerberos
Itshould beclearbynowthatincorporating security intodistributed systems
ISnottrivial. Problems arecaused bythefactthattheentire system must be
secure; ifsome partisinsecure, thewhole system maybecompromised. Toassist
theconstruction ofdistributed systems thatcanenforce amyriad ofsecurity poli-
cies,anumber ofsupporting systems havebeendeveloped thatcanbeusedasa
basis forfurther development. Animportant system thatiswidely usedisKer-
heros (Steiner etal.,1988; andKohlandNeuman, 1994).
Kerberos wasdeveloped atM.LT. andisbased ontheNeedham-Schroeder
authentication protocol wedescribed earlier. There arecurrently twodifferent
versions ofKerberos inuse,version 4(V4)andversion 5(V5). Bothversions are
conceptually similar, withV5being much more flexible andscalable. Adetailed412 SECURITY CHAP. 9
description ofV5canbefound inNeuman etal.(2005), whereas practical infor-
mation onrunning Kerberos isdescribed byGarman (2003).
Kerberos canbeviewed asasecurity system thatassists clients insetting upa
secure channel withanyserver thatispartofadistributed system. Security is
based onshared secret keys. There aretwodifferent components. TheAuthenti-
cation Server (AS) isresponsible forhandling alogin request from auser. The
ASauthenticates auserandprovides akeythatcanbeusedtosetupsecure chan-
nelswithservers. Setting upsecure channels ishandled byaTicket Granting
Service (TGS). TheTGShands outspecial messages, known astickets, thatare
usedtoconvince aserver thattheclient isreally whoheorsheclaims tobe.We
giveconcrete examples oftickets below.
LetustakealookathowAlice logsontoadistributed system thatusesKer-
beros andhowshecansetupasecure channel withserver Bob. ForAlice tolog
ontothesystem, shecanuseanyworkstation available. Theworkstation sends her
name inplaintext totheAS,which returns asession keyKA.TGSandaticket that
shewillneedtohandovertotheTGS.
Theticket thatisreturned bytheAScontains theidentity ofAlice, along with
agenerated secret keythatAlice andtheTGScanusetocommunicate witheach
other. Theticket itself willbehanded overtotheTGSbyAlice. Therefore, itis
important thatnoonebuttheTGS canreadit.Forthisreason, theticket is
encrypted withthesecret keyKAS,TGS shared between theASandtheTGS.
Thispartofthelogin procedure isshown asmessages 1,2,and3inFig.9-23.
Message 1isnotreally amessage, butcorresponds toAlice typing inherlogin
name ataworkstation. Message 2contains thatname andissenttotheAS.Mes-
sage3contains thesession key.KA,TGS andtheticket KAS,TGS(A,KA,TGS)' Toensure
privacy, message 3isencrypted withthesecret keyKA,AS shared between Alice
-andtheAS.
Figure 9-23. Authentication inKerberos.
When theworkstation receives theresponse fromtheAS,itprompts Alice for
herpassword (shown asmessage 4).which itusestosubsequently generate the
shared keyKA,AS' (Itisrelatively simple totakeacharacter string password, applySEC. 9.2 SECURE CHANNELS 413
3cryptographic hash,andthentakethefirst56bitsasthesecret key.)Notethat
thisapproach notonlyhastheadvantage thatAlice's password isnever sentas
plaintext across thenetwork, butalsothattheworkstation doesnotevenhaveto
temporarily storeit.Moreover, assoonasithasgenerated theshared key~,AS'
theworkstation willfmdthesession key~,TGS' andcanforget about Alice's
password anduseonlytheshared secret KA,AS'
Afterthispartoftheauthentication hastakenplace, Alicecanconsider herself
logged intothesystem through thecurrent workstation. Theticket received from
theASisstored temporarily (typically for8-24hours), andwillbeusedforac-
cessing remote services. Ofcourse, ifAlice leaves herworkstation, sheshould
destroy anycached tickets. Ifshewants totalktoBob,sherequests theTGSto
generate asession keyforBob,shown asmessage 6inFig.9-23. Thefactthat
Alicehastheticket KAS,TGS(A,~,TGS) proves thatsheisAlice. TheTGSresponds
withasession keyKA,B, againencapsulated inaticket thatAlicewilllaterhaveto
passtoBob.
Message 6alsocontains atimestamp, t,encrypted withthesecret keyshared
between Alice andtheTGS.Thistimestamp isusedtoprevent Chuck frommali-
ciously replaying message 6again, andtrying tosetupachannel toBob.The
TGSwillverify thetimestamp before returning aticket toAlice. Ifitdiffers more
thanafewminutes fromthecurrent time,therequest foraticket isrejected.
Thisscheme establishes whatisknown assingle sign-on. AslongasAlice
doesnotchange workstations, thereisnoneedforhertoauthenticate herself to
any"other server thatispartofthedistributed system. Thisfeature isimportant
when having todealwithmany different services thatarespread across multiple
machines. Inprinciple, servers inawayhavedelegated client authentication tothe
ASandTGS, andwillaccept requests fromanyclient thathasavalidticket. Of
course, services suchasremote loginwillrequire thattheassociated userhasan
account, butthisisindependent fromauthentication through Kerberos.
Setting upasecure channel withBobisnowstraightforward, andisshown in
Fig.9-24. First,Alice sends toBobamessage containing theticket shegotfrom
theTGS, along withanencrypted timestamp. When Bobdecrypts theticket, he
notices thatAlice istalking tohim,because onlytheTGScould haveconstructed
theticket. Healsofindsthesecret keyKA,B, allowing himtoverify thetimestamp.
Atthatpoint, Bobknows heistalking toAlice andnotsomeone maliciously
replaying message 1.Byresponding withKA,8(t +1),Bobproves toAlice thathe
isindeed Bob.
9.3ACCESS CONTROL
Intheclient-server model, which wehaveusedsofar,onceaclient anda
server havesetupasecure channel, theclient canissuerequests thataretobecar-
riedoutbytheserver. Requests involve carrying outoperations onresources that414 SECURITY CHAP. 9
Figure 9-24. Setting upasecure channel inKerberos.
arecontrolled bytheserver. Ageneral situation isthatofanobject server thathas
anumber ofobjects under itscontrol. Arequest fromaclient generally involves
invoking amethod ofaspecific object. Sucharequest canbecarried outonlyif
theclient hassufficient access rights forthatinvocation.
Formally, verifying access rights isreferred toasaccess control, whereas
authorization isabout granting access rights. Thetwoterms arestrongly related
toeachotherandareoftenusedinaninterchangeable way.There aremany ways
toachieve access control. Westartwithdiscussing some ofthegeneral issues,
concentrating ondifferent models forhandling access control. Oneimportant way
ofactually controlling access toresources istobuildafirewall thatprotects appli-
cations orevenanentire network. Firewalls arediscussed separately. Withthead-
ventofcodemobility, access control could nolonger bedoneusing onlythetradi-
tional methods. Instead, newtechniques hadtobedevised, which arealsodis-
cussed inthissection.
9.3.1 General Issues inAccess Control
Inordertounderstand thevarious issues involved inaccess control, thesim-
plemodel shown inFig.9-25isgenerally adopted. Itconsists ofsubjects that
issuearequest toaccess anobject. Anobject isverymuch liketheobjects we
havebeendiscussing sofar.Itcanbethought ofasencapsulating itsownstateand
implementing theoperations onthatstate. Theoperations ofanobject thatsub-
jectscanrequest tobecarried outaremade available through interfaces. Subjects
canbestbethought ofasbeing processes acting onbehalf ofusers, butcanalsobe
objects thatneedtheservices ofotherobjects inordertocarryouttheirwork.
Figure 9-25. General model ofcontrolling access toobjects.
Controlling theaccess toanobject isallabout protecting theobject against
invocations bysubjects thatarenotallowed tohavespecific (orevenany)oftheSEC. 9.3 ACCESS CONTROL 415
methods carried out.Also, protection mayinclude object management issues,
suchascreating, renaming, ordeleting objects. Protection isoftenenforced bya
program called areference monitor. Areference monitor records which subject
maydowhat, anddecides whether asubject isallowed tohaveaspecific opera-
tioncarried out.Thismonitor iscalled (e.g.,bytheunderlying trusted operating
system) eachtimeanobject isinvoked. Consequently, itisextremely important
thatthereference monitor isitselftamperproof: anattacker mustnotbeableto
foolaround withit.
Access Control Matrix
Acommon approach tomodeling theaccess rights ofsubjects withrespect to
objects istoconstruct anaccess control matrix. Eachsubject isrepresented bya
rowinthismatrix; eachobject isrepresented byacolumn. Ifthematrix isdenoted
M,thenanentryM[s,o] listsprecisely which operations subject scanrequest to
becarried outonobject o.Inotherwords, whenever asubject srequests theinvo-
cation ofmethod mofobject 0,thereference monitor should check whether mis
listedinM[s,o]. Ifmisnotlistedin1\1[s,o], theinvocation fails.
Considering thatasystem mayeasily needtosupport thousands ofusersand
millions ofobjects thatrequire protection, implementing anaccess control matrix
asatruematrix isnotthewaytogo.Many entries inthematrix willbeempty: a
single subject willgenerally haveaccess torelatively fewobjects. Therefore,
other, moreefficient waysarefollowed toimplement anaccess control matrix.
Onewidely-applied approach istohaveeachobject maintain alistoftheac-
cessrights ofsubjects thatwanttoaccess theobject. Inessence, thismeans that
thematrix isdistributed column-wise across allobjects, andthatempty entries are
leftout.Thistypeofimplementation leadstowhatiscalled anAccess Control
List(ACL). Eachobject isassumed tohaveitsownassociated ACL.
Another approach istodistribute thematrix row-wise bygiving eachsubject a
listofcapabilities ithasforeachobject. Inotherwords, acapability corresponds
toanentryintheaccess control matrix. Nothaving acapability foraspecific ob-
jectmeans thatthesubject hasnoaccess rights forthatobject.
Acapability canbecompared toaticket: itsholder isgivencertain rights that
areassociated withthatticket. Itisalsoclearthataticket should beprotected
against modifications byitsholder. Oneapproach thatisparticularly suited indis-
tributed systems andwhich hasbeenapplied extensively inAmoeba (Tanenbaum
etaI.,1990), istoprotect (alistof)capabilities withasignature. Wereturn to
theseandothermatters laterwhendiscussing security management.
Thedifference between howACLs andcapabilities areusedtoprotect theac-
cesstoanobject isshown inFig.9-26. Using ACLs, when aclient sends are-
quest toaserver, theserver's reference monitor willcheck whether itknows the
client andifthatclient isknown andallowed tohavetherequested operation car-
riedout,asshown inFig.9-26(a).416 SECURITY CHAP. 9
Figure 9-26. Comparison between ACLs andcapabilities forprotecting objects.
(a)Using anACL. (b)Using capabilities.
However, when using capabilities, aclient simply sends itsrequest tothe
server. Theserver isnotinterested inwhether itknows theclient; thecapability
saysenough. Therefore, theserver peedonlycheck whether thecapability isvalid
andwhether therequested operation islisted inthecapability. Thisapproach to
protecting objects bymeans ofcapabilities isshown inFig.9-26(b).
Protection Domains
ACLs andcapabilities helpinefficiently implementing anaccess control ma-
trixbyignoring allempty entries. Nevertheless, anACLoracapability listcan
stillbecome quitelargeifnofurther measures aretaken.
Onegeneral wayofreducing ACLs istomakeuseofprotection domains. For-
mally, aprotection domainisasetof(object, access rights) pairs. Each pair
specifies foragiven object exactly which operations areallowed tobecarried out
(Saltzer andSchroeder, 1975). Requests forcarrying outanoperation arealways
issued within adomain. Therefore, whenever asubject requests anoperation tobe
carried outatanobject, thereference monitor firstlooksuptheprotection domain
associated withthatrequest. Then, given thedomain, thereference monitor can
subsequently check whether therequest isallowed tobecarried out.Different
usesofprotection domains exist.SEC.9.3 ACCESS CONTROL 417
Oneapproach istoconstruct groupsofusers. Consider, forexample, aWeb
pageonacompany's internal intranet. Such apage should beavailable toevery
employee, butotherwise tonooneelse.Instead ofadding anentry foreachpos-
sibleemployee totheACL forthatWebpage, itmaybedecided tohaveasepa-
rategroup Employee containing allcurrent employees. Whenever auseraccesses
theWeb page, thereference monitor need onlycheck whether thatuserisan
employee. Which users belong tothegroup Employee iskeptinaseparate list
(which, ofcourse, isprotected against unauthorized access).
.Matters canbemade more flexible byintroducing hierarchical groups. Forex-
ample, ifanorganization hasthree different branches at,say,Amsterdam, New
York, andSanFrancisco, itmaywant tosubdivide itsEmployee group intosub-
groups, oneforeachcity,leading toanorganization asshown inFig.'9-27.
Figure 9-27. Thehierarchical organization ofprotection domains asgroups of
users.
Accessing Webpages oftheorganization's intranet should bepermitted byall
employees. However, changing forexample Web pages associated with the
Amsterdam branch should bepermitted onlybyasubset ofemployees inAmster-
dam. IfuserDick fromAmsterdam wants toreadaWebpagefromtheintranet,
thereference monitor needs tofirst look upthesubsets Employee.AlviS,
Employee.N'YC, andEmployee-SF thatjointly comprise thesetEmployee. Itthen
hastocheck ifoneofthese setscontains Dick. Theadvantage ofhaving hierarchi-
calgroups isthatmanaging group membership isrelatively easy, andthatvery
largegroups canbeconstructed efficiently. Anobvious disadvantage isthatlook-
ingupamember canbequitecostly ifthemembership database isdistributed.
Instead ofletting thereference monitor doallthework, analternative istolet
eachsubject carry acertificate listing thegroups itbelongs to.So,whenever Dick
wants toreadaWebpagefromthecompany's intranet, hehands overhiscertifi-
catetothereference monitor stating thatheisamember ofEmployee-AMS. To
guarantee thatthecertificate isgenuine andhasnotbeentampered with, itshould
beprotected bymeans of,forexample, adigital signature. Certificates areseento
becomparable tocapabilities. Wereturn tothese issues later.418 SECURITY CHAP. 9
Related tohaving groups asprotection domains, itisalsopossible toimple-
mentprotection domains asroles. Inrole-based access control, auseralways logs
intothesystem withaspecific role,which isoften associated withafunction the
userhasinanorganization (Sandhu etal.,1996). Ausermayhave several func-
tions. Forexample, Dick could simultaneously behead ofadepartment, manager
ofaproject, andmember ofapersonnel search committee. Depending ontherole
hetakes when logging in,hemaybeassigned different privileges. Inother words,
hisroledetermines theprotection domain (i.e.,group) inwhich hewilloperate.
When assigning roles tousers andrequiring thatusers takeonaspecific role
when logging in.itshould alsobepossible forusers tochange theirrolesifneces-
sary.Forexample, itmayberequired toallow Dick asheadofthedepartment to
occasionally change tohisroleofproject manager. Note thatsuchchanges aredif-
ficult toexpress when implementing protection domains onlyasgroups.
Besides using protection domains, efficiency canbefurther improved by
(hierarchically) grouping objects based ontheoperations theyprovide ..Forex-
ample, instead ofconsidering individual objects, objects aregrouped according to
theinterfaces theyprovide, possibly using subtyping [alsoreferred toasinterface
inheritance, seeGamma etaI.(1994)] toachieve ahierarchy. Inthiscase, when a
subject requests anoperation tobecarried outatanobject, thereference monitor
looks uptowhich interface theoperation forthatobject belongs. Itthenchecks
whether thesubject isallowed tocallanoperation belonging tothatinterface,
rather thanifitcancalltheoperation forthespecific object.
Combining protection domains andgrouping ofobjects isalsopossible. Using
bothtechniques, along withspecific datastructures andrestricted operations on
objects, Gladney (1997) describes howtoimplement ACLs forverylarge collec-
tionsofobjects thatareusedindigital libraries.
9.3.2 Firewalls
Sofar,wehaveshown howprotection canbeestablished using cryptographic
techniques, combined with some implementation ofanaccess control matrix.
These approaches work fineaslongasallcommunicating parties playaccording
tothesame setofrules. Such rules maybeenforced when developing astand-
alone distributed system thatisisolated fromtherestoftheworld. However, mat-
tersbecome more complicated when outsiders areallowed toaccess theresources
controlled byadistributed system. Examples ofsuchaccesses including sending
mail, downloading files,uploading taxforms, andsoon.
Toprotect resources under these circumstances, adifferent approach isneed-
ed.Inpractice, what happens isthatexternal access toanypartofadistributed
system iscontrolled byaspecial kindofreference monitor known asafirewall
(Cheswick andBellovin, 2000; andZwicky etaI.,2000). Essentially, afirewall -
disconnects anypartofadistributed system from theoutside world, asshown in
Fig.9-28. Alloutgoing, butespecially allincoming packets arerouted through aSEC.9.3 ACCESS CONTROL 419
special computer andinspected before theyarepassed. Unauthorized traffic isdis-
carded andnotallowed tocontinue. Animportant issueisthatthefirewall itself
should beheavily protected against anykindofsecurity threat: itshould never
fail.
Figure 9-28. Acommon implementation ofafirewall.
Firewalls essentially come intwodifferent flavors thatareoftencombined.
Animportant typeoffirewall isapacket-filtering gateway. Thistypeoffirewall
operates asarouter andmakes decisions astowhether ornottopassanetwork
packet based onthesource anddestination address ascontained inthepacket's
header. Typically, thepacket-filtering gateway shown ontheoutside LAN in
Fig.9-28would protect against incoming packets, whereas theoneontheinside
LANwould filteroutgoing packets.
Forexample, toprotect aninternal Webserver against requests fromhosts
thatarenotontheinternal network, apacket-filtering gateway could decide to
dropallincoming packets addressed totheWebserver.
More subtle isthesituation inwhich acompany's network consists ofmulti-
plelocal-area networks connected, forexample, through anSMDS network aswe
discussed before. EachLANcanbeprotected bymeans ofapacket-filtering gate-
way,which isconfigured topassincoming traffic onlyifitoriginated fromahost
ononeoftheotherLANs. Inthisway,aprivate virtual network canbesetup.
Theothertypeoffirewall isanapplication-level gateway. Incontrast toa
packet-filtering gateway, which inspects onlytheheader ofnetwork packets, this
typeoffirewall actually inspects thecontent ofanincoming oroutgoing message.
Atypical example isamailgateway thatdiscards incoming oroutgoing mail
exceeding acertain size.More sophisticated mailgateways existthatare,forex-
ample, capable offiltering spame-mail.
Another example ofanapplication-level gateway isonethatallows external
access toadigital library server, butwillsupply onlyabstracts ofdocuments. Ifan
external userwants more, anelectronic payment protocol isstarted. Users inside
thefirewall havedirect access tothelibrary service.420 SECURITY CHAP. 9
Aspecial kindofapplication-level gateway iswhatisknown asaproxy gate-
way. Thistypeoffirewall works asafrontendtoaspecific kindofapplication,
andensures thatonlythose messages arepassed thatmeetcertain criteria. Con-
sider, forexample, surfing theWeb.Aswediscuss inthenextsection, many Web
pages contain scripts orapplets thataretobeexecuted inauser's browser. To
prevent suchcodetobedownloaded totheinside LAN, allWebtraffic could be
directed through aWebproxy gateway. Thisgateway accepts regular HTTP re-
quests, either frominside oroutside thefirewall. Inotherwords, itappears toits
users asanormal Webserver. However, itfilters allincoming andoutgoing
traffic, either bydiscarding certain requests andpages, ormodifying pages when
theycontain executable code.
9.3.3 Secure Mobile Code
Aswediscussed inChap. 3,animportant development inmodem distributed
systems istheability tomigrate codebetween hostsinstead ofjustmigrating pas-
sivedata.However, mobile codeintroduces anumber ofserious security threats.
Foronething, when sending anagent across theInternet, itsowner willwantto
protect itagainst malicious hoststhattrytostealormodify information carried by
theagent.
Another issueisthathostsneedtobeprotected against malicious agents. Most
usersofdistributed systems willnotbeexperts insystems technology andhaveno
wayoftelling whether theprogram theyarefetching fromanother hostcanbe
trusted nottocorrupt theircomputer. Inmany casesitmaybedifficult evenforan
expert todetect thataprogram isactually being downloaded atall.
Unless security measures aretaken, onceamalicious program hassettled it-
selfinacomputer, itcaneasily corrupt itshost.Wearefacedwithanaccess con-
trolproblem: theprogram should notbeallowed unauthorized access tothehost's
resources. Asweshallsee.protecting ahostagainst downloaded malicious pro-
grams isnotalways easy.Theproblem isnotsomuch astoavoid downloading of
programs. Instead, whatwearelooking forissupporting mobile codethatwecan
allow access tolocalresources inaflexible, yetfullycontrolled manner.
Protecting anAgent
Before wetakealookatprotecting acomputer system against downloaded
malicious code,letusfirsttakealookattheopposite situation. Consider amobile
agent thatisroaming adistributed system onbehalf ofauser.Suchanagent may
besearching forthecheapest airplane ticket fromNairobi toMalindi, andhas
beenauthorized byitsowner tomake areservation assoonasitfound aflight.
Forthispurpose, theagentmaycarryanelectronic credit card.
Obviously, weneedprotection here.Whenever theagentmoves toahost,that
hostshould notbeallowed tostealtheagent's credit cardinformation. Also, theSEC.9.3 ACCESS CONTROL 421
:.lgent should beprotected against modifications thatmake theowner paymuch
morethanactually isneeded. Forexample, ifChuck's Cheaper Charters cansee
thattheagent hasnotyetvisited itscheaper competitor Alice Airlines, Chuck
should beprevented fromchanging theagent sothatitwillnotvisitAlice Air-
lines' host.Other examples thatrequire protection ofanagent against attacks
fromahostile hostinclude maliciously destroying anagent, ortampering withan
agentsuchthatitwillattack orstealfromitsowner whenitreturns.
Unfortunately, fullyprotecting anagent against allkinds ofattacks isimpos-
sible(Farmer etaI.,1996). Thisimpossibility isprimarily caused bythefactthat
nohardguarantees canbegiven thatahostwilldowhatitpromises. Analterna-
tiveapproach istherefore toorganize agents insuchawaythatmodifications can
atleastbedetected. Thisapproach hasbeenfollowed intheAjanta system (Kat-
nikandTripathi, 2001). Ajanta provides threemechanisms thatallow anagent's
owner todetect thattheagent hasbeentampered with:read-only state,append-
onlylogs,andselective revealing ofstatetocertain servers.
Theread-only stateofanAjanta agentconsists ofacollection ofdataitems
thatissigned bytheagent's owner. Signing takesplace when theagent iscon-
structed andinitialized before itissentofftootherhosts. Theowner firstcon-
structs amessage digest, which itsubsequently encrypts withitsprivate key.
When theagentarrives atahost,thathostcaneasily detect whether theread-only
statehasbeentampered withbyverifying thestateagainst thesigned message di-
gestoftheoriginal state.
Toallow anagenttocollect information while moving between hosts, Ajanta
provides secure append-only logs. These logsarecharacterized bythefactthat
datacanonlybeappended tothelog;thereisnowaythatdatacanberemoved or
modified without theowner being abletodetect this.Using anappend-only log
works asfollows. Initially, thelogisempty andhasonlyanassociated checksum
Cinitcalculated asCinit=~wner(N), where KblVner isthepublic keyoftheagent's
owner, andNisasecret nonce known onlytotheowner.
When theagentmoves toaserver Sthatwants tohanditsomedataX,Sappends
XtothelogthensignsXwithitssignature sig(S,X), andcalculates achecksum:
Cnew=Kbwner(Cold, sig(S,X), S)
where Cold isthechecksum thatwasusedpreviously.
When theagentcomes backtoitsowner, theowner caneasily verify whether
theloghasbeentampered with.Theowner startsreading thelogattheendby
successively computing K~wner(C) onthechecksum C.Each iteration returns a
checksum C"extforthenextiteration, along withsig(S,X) andSforsomeserver
S.Theowner canthenverify whether ornotthethen-last element inthelog
matches sig(S,X). Ifso,theelement isremoved andprocessed, afterwhich the
nextiteration stepistaken. Theiteration stops when theinitial checksum is
reached. orwhen theowner notices thatthelogasbeentampered withbecause a
signature doesnotmatch.422 SECURITY CHAP. 9
Finally, Ajanta supports selective revealing ofstatebyproviding anarray of
dataitems, where eachentry isintended foradesignated server. Each entry isen-
crypted withthedesignated server's public keytoensure confidentiality. Theen-
tirearray issigned bytheagent's owner toensure integrity ofthearray asa
whole. Inother words, ifanyentry ismodified byamalicious host, anyofthe
designated servers willnotice andcantakeappropriate action.
Besides protecting anagent against malicious hosts, Ajanta alsoprovides vari-
ousmechanisms toprotect hosts against malicious agents. Aswediscuss next,
many ofthese mechanisms arealsosupplied byother systems thatsupport mobile
code. Further information onAjanta canbefound inTripathi etaI.(1999).
Protecting theTarget
Although protecting mobile codeagainst amalicious hostisimportant, more
attention hasbeenpaidtoprotecting hosts against malicious mobile code. Ifsend-
inganagent intotheoutside world isconsidered toodangerous, auserwillgener-
allyhavealternatives togetthejobdoneforwhich theagent wasintended. How-
ever,there areoften noalternatives toletting anagent intoyoursystem, other than
locking itoutcompletely. Therefore, ifitisoncedecided thattheagent cancome
in,theuserneeds fullcontrol overwhattheagent cando.
Aswejustdiscussed, although protecting anagent frommodification maybe
impossible, atleastitispossible fortheagent's owner todetect thatmodifications
havebeen made. Atworst, theowner willhavetodiscard theagent when itre-
turns, butotherwise noharm willhavebeen done. However, when dealing with
malicious incoming agents, simply detecting thatyourresources have been har-
assed istoolate.Instead, itisessential toprotect allresources against unauthor-
izedaccess bydownloaded code.
Oneapproach toprotection istoconstruct asandbox. Asandbox isatech-
nique bywhich adownloaded program isexecuted insuchawaythateachofits
instructions canbefullycontrolled. Ifanattempt ismade toexecute aninstruction
thathasbeen forbidden bythehost, execution oftheprogram willbestopped.
Likewise, execution ishalted when aninstruction accesses certain registers or
areas inmemory thatthehosthasnotallowed.
Implementing asandbox isnoteasy. Oneapproach istocheck theexecutable
codewhen itisdownloaded, andtoinsert additional instructions forsituations that
canbechecked only atruntime (Wahbe etal.,1993). Fortunately. matters
become much simpler when dealing withinterpreted code. Letusbriefly consider
theapproach taken inJava [seealsoMacGregor etal.(1998)]. Each Javapro-
gram consists ofanumber ofclasses fromwhich objects arecreated. There areno
global variables andfunctions; everything hastobedeclared aspartofaclass.
Program execution starts atamethod called main. AJavaprogram iscompiled to
asetofinstructions thatareinterpreted bywhat iscalled theJavaVirtual
Machine (JVM). Foraclient todownload andexecute acompiled Javaprogram,SEC. 9.3 ACCESS CONTROL 423
itistherefore necessary thattheclient process isrunning theJVM. TheJVMwill
subsequently handle theactual execution ofthedownloaded program byinterpret-
ingeachofitsinstructions, starting attheinstructions thatcomprise main.
InaJavasandbox, protection startsbyensuring thatthecomponent thathand-
lesthetransfer ofaprogram totheclient machine canbetrusted. Downloading in
Javaistakencareofbyasetofclassloaders. Eachclassloader isresponsible for
fetching aspecified classfromaserver andinstalling itintheclient's address
space sothattheJVMcancreate objects fromit.Because aclassloader isjustan-
otherJavaclass, itispossible thatadownloaded program contains itsownclass
loaders. Thefirstthingthatishandled byasandbox isthatexclusively trusted
classloaders areused.Inparticular, aJavaprogram isnotallowedto create its
ownclassloaders bywhich itcould circumvent thewayclassloading isnormally
handled.
Thesecond component ofaJavasandbox consists ofabytecodeverifier,
which checks whether adownloaded classobeys thesecurity rulesofthesandbox.
Inparticular, theverifier checks thattheclasscontains noillegal instructions or
instructions thatcould somehow corrupt thestackormemory. Notallclasses are
checked, asshown inFig.9-29;onlytheonesthataredownloaded fromanexter-
nalserver totheclient. Classes thatarelocated ontheclient's machine aregener-
allytrusted, although theirintegrity could alsobeeasily verified.
Figure 9-29. Theorganization ofaJavasandbox.
Finally, when aclasshasbeensecurely downloaded andverified, theJVM
caninstantiate objects fromitandexecute those object's methods. Tofurther
prevent objects fromunauthorized access totheclient's resources, asecurity
manager isusedtoperform various checks atruntime. Javaprograms intended to
bedownloaded areforced tomake useofthesecurity manager; thereisnoway424 SECURITY CHAP. 9
theycancircumvent it.Thismeans, forexample, thatanyI/Ooperation isvetted
forvalidity andwillnotbecarried outifthesecurity manager says"no." These-
curity manager thusplaystheroleofareference monitor wediscussed earlier.
Atypical security manager willdisallow many operations tobecarried out.
Forexample, virtually ansecurity managers denyaccess tolocalfilesandallow a
program onlytosetupaconnection totheserver fromwhere itcame. Manipulat-
ingtheJVMisobviously notallowed aswell.However, aprogram ispermitted to
access thegraphics library fordisplay purposes andtocatchevents suchasmov-
ingthemouse orclicking itsbuttons.
Theoriginal Javasecurity manager implemented arather strictsecurity policy
inwhich itmade nodistinction between different downloaded programs, oreven
programs fromdifferent servers. Inmany cases, theinitial Javasandbox model
wasoverly restricted andmoreflexibility wasrequired. Below, wediscuss anal-
ternati veapproach thatiscurrently followed.
Anapproach inlinewithsandboxing, butwhich offers somewhat moreflexi-
bility, istocreate aplayground fordownloaded mobile code(Malkhi andReiter,
2000). Aplayground isaseparate, designated machine exclusively reserved for
running mobile code.Resources localtotheplayground, suchasfilesornetwork
connections toexternal servers areavailable toprograms executing intheplay-
ground, subject tonormal protection mechanisms. However, resources localto
othermachines arephysically disconnected fromtheplayground andcannot be
accessed bydownloaded code.Users ontheseothermachines canaccess theplay-
ground inatraditional way,forexample, bymeans ofRPCs. However, nomobile
codeiseverdownloaded tomachines notintheplayground. Thisdistinction be-
tween asandbox andaplayground isshown inFig.9-30.
Figure 9·30. (a)Asandbox. (b)Aplayground.
Anextsteptoward increased flexibility istorequire thateachdownloaded
program canbeauthenticated, andtosubsequently enforce aspecific security pol-
icybased onwhere theprogram came from. Demanding thatprograms canbeSEC. 9.3 ACCESS CONTROL 425
authenticated isrelatively easy: mobile codecanbesigned, justlikeanyother
document. Thiscode-signing approach isoftenapplied asanalternative tosand-
boxing aswell.Ineffect, onlycodefromtrusted servers isaccepted.
However, thedifficult partisenforcing asecurity policy. Wallach etal.
(1997) propose threemechanisms inthecaseofJavaprograms. Thefirstapproach
isbased ontheuseofobject references ascapabilities. Toaccess alocalresource
suchasafile,aprogram musthavebeengiven areference toaspecific object that
handles fileoperations when itwasdownloaded. Ifnosuchreference isgiven,
thereisnowaythatfilescanbeaccessed. Thisprinciple isshown inFig.9-31.
Figure 9-31. Theprinciple ofusing Javaobject references ascapabilities.
Allinterfaces toobjects thatimplement thefilesystem areinitially hidden
fromtheprogram bysimply nothanding outanyreferences totheseinterfaces.
Java's strong typechecking ensures thatitisimpossible toconstruct areference to
oneoftheseinterfaces atruntime. Inaddition, wecanusetheproperty ofJavato
keepcertain variables andmethods completely internal toaclass. Inparticular, a
program canbeprevented frominstantiating itsownfile-handling objects, by
essentially hiding theoperation thatcreates newobjects fromagiven class. (In
Javaterminology, aconstructor ismadeprivate toitsassociated class.)
Thesecond mechanism forenforcing asecurity policy is(extended) stack
introspection. Inessence, anycalltoamethod mofalocalresource ispreceded
byacalltoaspecial procedure enable_privilege thatchecks whether thecaller is
authorized toinvoke monthatresource. Iftheinvocation isauthorized, thecaller
isgiven temporary privileges fortheduration ofthecall.Before returning control
totheinvoker when misfinished, thespecial procedure disable_privilege is
invoked todisable theseprivileges.
Toenforce callstoenable_privilege anddisable_privilege, adeveloper ofin-
terfaces tolocalresources could berequired toinsertthesecallsintheappropriate
places. However, itismuch better tolettheJavainterpreter handle thecalls
automatically. Thisisthestandard approach followed in,forexample, Webbrow-
sersfordealing withJavaapplets. Anelegant solution isasfollows. Whenever an426 SECURITY CHAP. 9
invocation toalocalresource ismade, theJavainterpreter automatically calls
enable_privilege, which subsequently checks whether thecallispermitted. Ifso,a
calltodisable_privilege ispushed onthestacktoensure thatprivileges aredis-
abled when themethod callreturns. Thisapproach prevents malicious pro-
grammers fromcircumventing therules.
Figure 9-32. Theprinciple ofstackintrospection.
Another important advantage ofusingthestackisthatitenables amuch better
wayofchecking privileges. Suppose thataprogram invokes alocalobject 01,
which, inturn,invokes object 02.Although 01mayhavepermission toinvoke
02, iftheinvoker of01isnottrusted toinvoke aspecific method belonging to
02, thenthischain ofinvocations should notbeallowed. Stack introspection
makes iteasytocheck suchchains, astheinterpreter needmerely inspect each
stackframe starting atthetoptoseeifthereisaframe having therightprivileges
enabled (inwhich casethecallispermitted), orifthereisaframe thatexplicitly
forbids access tothecurrent resource (inwhich casethecallisimmediately termi-
nated). Thisapproach isshown inFig.9-32.
Inessence, stackintrospection allows fortheattachment ofprivileges toclas-
sesormethods, andthechecking ofthoseprivileges foreachcaller separately. In
thisway, Itispossible toimplement class-based protection domains, asis
explained indetail inGong andSchemers (1998).
Thethirdapproach toenforcing asecurity policy isbymeans ofname space
management. Theideaisputforthbelow. Togiveprograms access tolocalre-
sources, theyfirstneedtoattain access byincluding theappropriate filesthatcon-
taintheclasses implementing thoseresources. Inclusion requires thataname is
given totheinterpreter, which thenresolves ittoaclass, which issubsequently
loaded atruntime. Toenforce asecurity policy foraspecific downloaded pro-
gram, thesamename canberesolved todifferent classes, depending onwhere the
downloaded program came from. Typically, name resolution ishandled byclass
loaders, which needtobeadapted toimplement thisapproach. Details ofhowthis
canbedonecanbefound inWallach etal.(1997).SEC. 9.3 ACCESS CONTROL 427
Theapproach described sofarassociates privileges withclasses ormethods
bas~d onwhere adownloaded program came from. Byvirtue oftheJavainter-
preter, itispossible toenforce security policies through themechanisms described
above. Inthissense, thesecurity architecture becomes highly language dependent,
andwillneedtobedeveloped anew forotherlanguages. Language-independent
solutions, suchas,forexample, described inJaeger eta1.(1999), require amore
general approach toenforcing security, andarealsoharder toimplement. Inthese
cases, support isneeded fromasecure operating system thatisaware ofdown-
loaded mobile codeandwhich enforces allcallstolocalresources torunthrough
thekernel where subsequent checking isdone.
9.3.4Denial ofService
Access control isgenerally about carefully ensuring thatresources areac-
cessed onlybyauthorized processes. Aparticularly annoying typeofattack thatis
related toaccess control ismaliciously preventing authorized processes fromac-
cessing resources. Defenses against suchdenial-of-service (DoS) attacks are
becoming increasingly important asdistributed systems areopened upthrough the
Internet. Where DoSattacks thatcome fromoneorafewsources canoftenbe
handled quiteeffectively, matters become much moredifficult when having to
dealwithdistributed denial ofservice (DDoS).
InDDoS attacks, ahugecollection ofprocesses jointly attempt tobringdown
anetworked service. Inthese cases, weoften seethattheattackers havesuc-
ceeded inhijacking alargegroup ofmachines which unknowingly participate in
theattack. Specht andLee(2004) distinguish twotypesofattacks: thoseaimed at
bandwidth depletion andthoseaimed atresource depletion.
Bandwidth depletion canbeaccomplished bysimply sending many messages
toasingle machine. Theeffect isthatnormal messages willhardly beableto
reach thereceiver. Resource depletion attacks concentrate onletting thereceiver
useupresources onotherwise useless messages. Awell-known resource-depletion
attack isTCPSYN-flooding. Inthiscase,theattacker attempts toinitiate ahuge
amount ofconnections (i.e.,sendSYNpackets aspartofthethree-way hand-
shake), butwillotherwise neverrespond toacknowledgments fromthereceiver.
There isnosingle method toprotect against DDoS attacks. Oneproblem is
thatattackers make useofinnocent victims bysecretly installing software ontheir
machines. Inthesecases, theonlysolution istohavemachines continuously mon-
itortheirstatebychecking filesforpollution. Considering theeasebywhich a
viruscanspread overtheInternet, relying onlyonthiscountermeasure isnot
feasible.
Much better istocontinuously monitor network traffic, forexample, starting
attheegress routers where packets leave anorganization's network. Experience
shows thatbydropping packets whose source address doesnotbelong tothe428 SECURITY CHAP. 9
organization's network wecanprevent alotofhavoc. Ingeneral, themorepack-
etscanbefiltered closetothesources, thebetter.
Alternatively, itisalsopossible toconcentrate oningress routers, thatis,
where traffic flows intoanorganization's network. Theproblem isthatdetecting
anattack ataningress router istoolateasthenetwork willprobably already be
unreachable forregular traffic. Better istohaverouters further intheInternet,
suchasinthenetworks ofISPs,startdropping packets whentheysuspect that'an
attack isgoing on.Thisapproach isfollowed byGilandPoletto (2001), where a
router willdroppackets whenitnotices thattheratebetween thenumber ofpack-
etstoaspecific nodeisdisproportionate tothenumber ofpackets from thatnode.
Ingeneral, amyriad oftechniques needtobedeployed, whereas newattacks
continue toemerge. Apractical overview ofthestate-of-the-art indenial-of-ser-
viceattacks andsolutions canbefound inMirkovic eta1.(2005); adetailed taxon-
omyispresented inMirkovic andReiher (2004).
9.4SECURITY MANAGEMENT
Sofar,wehaveconsidered secure channels andaccess control, buthave
hardly touched upontheissuehow,forexample, keysareobtained. Inthissec-
tion,wetakeacloser lookatsecurity management. Inparticular, wedistinguish
three different subjects. First, weneedtoconsider thegeneral management of
cryptographic keys, andespecially themeans bywhich public keysaredistrib-
uted.Asitturnsout,certificates playanimportant rolehere.
Second, wediscuss theproblem ofsecurely managing agroup ofservers by
.concentrating ontheproblem ofadding anewgroup member thatistrusted bythe
current members. Clearly, inthefaceofdistributed andreplicated services, itis
important thatsecurity isnotcompromised byadmitting amalicious process toa
group.
Third, wepayattention toauthorization management bylooking atcapabili-
tiesandwhatareknown asattribute certificates. Animportant issueindistributed
systems withrespect toauthorization management isthatoneprocess candel-
egate some orallofitsaccess rights toanother process. Delegating rights ina
secure wayhasitsownsubtleties aswealsodiscuss inthissection.
9.4.1KeyManagement
Sofar,wehavedescribed various cryptographic protocols inwhich we(impli-
citly) assumed thatvarious keyswerereadily available. Forexample, inthecase
ofpublic-key cryptosystems, weassumed thatasender ofamessage hadthepub-
lickeyofthereceiver atitsdisposal sothatitcould encrypt themessage toensure
confidentiality. Likewise, inthecaseofauthentication using akeydistribution
center (KDC), weassumed eachpartyalready shared asecret keywiththeKDC.SEC. 9.4 SECURITY MANAGEMENT 429
However, establishing anddistributing keysisnotatrivial matter. Forex-
ample, distributing secret keysbymeans ofanunsecured channel isoutofthe
.------questIOn andinmany-cases weneed toresort toout-of-band methods. Also,
mechanisms areneeded torevoke keys, thatis,prevent akeyfrom being used
afterithasbeen compromised orinvalidated. Forexample, revocation isneces-
sarywhen akeyhasbeencompromised.
KeyEstablishment
Letusstartwithconsidering howsession keyscanbeestablished. When Alice
wants tosetupasecure channel withBob,shemayfirstuseBob's public keyto
initiate communication asshown inFig.9-19. IfBobaccepts, hecansubsequently
generate thesession keyandreturn ittoAlice encrypted withAlice's public key.
Byencrypting theshared session keybefore itstransmission, itcanbesafely
passed across thenetwork.
Asimilar scheme canbeusedtogenerate anddistribute asession keywhen
Alice andBobalready share asecret key.However, bothmethods require thatthe
communicating parties already have themeans available toestablish asecure
channel. Inother words, some form ofkeyestablishment anddistribution must
already havetaken place. Thesame argument applies when ashared secret keyis
established bymeans ofatrusted thirdparty, suchasaKDC.
,Anelegant andwidely-applied scheme forestablishing ashared keyacross an
insecure channel istheDiffie- Hellman keyexchange (Diffie andHellman,
1976). Theprotocol works asfollows. Suppose thatAlice andBobwanttoestab-
lishashared secret key.Thefirstrequirement isthattheyagree ontwolarge num-
bers, nand gthataresubject toanumber ofmathematical properties (which we
donotdiscuss here). Both nandgcanbemade public; there isnoneedtohide
them from outsiders. Alice picks alarge random number, sayx,which shekeeps
secret Likewise, Bobpicks hisownsecret largenumber, sayy.Atthispoint there
isenough information toconstruct asecret key,asshown inFig.9-33.
Figure 9-33. Theprinciple ofDiffie-Hellman keyexchange.
Alice starts bysending s'modntoBob,along withnandg.Itisimportant to
notethatthisinformation canbesentasplaintext, asitisvirtually impossible to430SECURITYCHAP. 9
compute xgiven gXmodn.When Bobreceives themessage, hesubsequently cal-
culates (gXmodn}'"which ismathematically equal togX.\'modn.Inaddition, he
sends gYmodntoAlice, whocanthencompute (gYmodnt=gXYmodn.Conse-
quently, bothAlice andBob,andonlythose two,willnowhav~etne shared secret -
keygXYmodn.Notethatneither ofthem needed tomake theirprivate number (x
andy,respectively), known totheother.
Diffie- Hellman canbeviewed asapublic-key cryptosystem. Inthecase,of
Alice, xisherprivate key,whereas gXmodnisherpublic key.Aswediscuss
next, securely distributing thepublic keyisessential tomaking Diffie-Hellman
work inpractice.
KeyDistribution
Oneofthemore difficult partsinkeymanagement istheactual distribution of
initial keys. Inasymmetric cryptosystem, theinitial shared secret keymust be
communicated along asecure channel thatprovides authentication aswellascon-
fidentiality, asshown inFig.9-34(a). Ifthere arenokeysavailable toAlice and
Bobtosetupsuchasecure channel, itisnecessary todistribute thekeyout-of-
band. Inother words, Alice andBobwillhave togetintouch witheach other
using some other communication means thanthenetwork. Forexample, oneof
themmayphone theother, orsendthekeyonafloppy diskusing snailmail.
Inthecaseofapublic-key cryptosystem, weneedtodistribute thepublic key
insuchawaythatthereceivers canbesurethatthekeyisindeed paired toa
claimed private key.Inother words, asshown inFig.9-34(b), although thepublic
keyitself maybesentasplaintext, itisnecessary thatthechannel through which
itissentcanprovide authentication. Theprivate key,ofcourse, needs tobesent
across asecure channel providing authentication aswellasconfidentiality.
When itcomes tokeydistribution, theauthenticated distribution ofpublic
keys isperhaps themost interesting. Inpractice, public-key distribution takes
place bymeans ofpublic-key certificates. Such acertificate consists ofapublic
keytogether withastring identifying theentity towhich thatkeyisassociated.
Theentity 'could beauser,butalsoahostorsome special device. Thepublic key
andidentifier havetogether beensigned byacertification authority, andthissig-
nature hasbeenplaced onthecertificate aswell. (Theidentity ofthecertification
authority isnaturally partofthecertificate.) Signing takes place bymeans ofa
private keyKCAthatbelongs tothecertification authority. Thecorresponding
public keyK~Aisassumed tobewellknown. Forexample, thepublic keysofvar-
iouscertification authorities arebuiltintomost Webbrowsers andshipped with
thebinaries.
Using apublic-key certificate works asfollows. Assume thataclient wishes
toascertain thatthepublic keyfound inthecertificate indeed belongs totheiden-
tified entity. Itthenusesthepublic keyoftheassociated certification authority to
verify thecertificate's signature. Ifthesignature onthecertificate matches theSECURITY MANAGEMENT 431
Figure 9-34. (a)Secret-key distribution. (b)Public-key distribution [seealso
Menezes etal.(1996)].
(public key,identifier )-pair, theclient accepts thatthepublic keyindeed belongs
totheidentified entity.
Itisimportant tonotethatbyaccepting thecertificate asbeing inorder, the
client actually trusts thatthecertificate hasnotbeenforged. Inparticular, thecli-
entmustassume thatthepublic keyKtA indeed belongs totheassociated certifi-
cation authority. Ifindoubt, itshould bepossible toverify thevalidity ofKtA
through another certificate coming fromadifferent, possibly moretrusted certifi-
cation authority.
Suchhierarchical trustmodelsinwhich thehighest-level certification author-
itymust betrusted byeveryone, arenotuncommon. Forexample, Privacy
Enhanced Mail(PEM) usesathree-level trustmodel inwhich lowest-level cer-
tification authorities canbeauthenticated byPolicyCertification Authorities
(PCA), which inturncanbeauthenticated bytheInternet PolicyRegistration
Authority (IPRA). IfauserdoesnottrusttheIPRA, ordoesnotthinkhecanSEC. 9.4432 SECURITY CHAP. 9
safely talktotheIPRA, there isnohopehewillevertruste-mail messages tobe
sentinasecure waywhen using PEM. More information onthismodel canbe
found inKent(993). Other trustmodels arediscussed inMenezes etal.(1996).
Lifetime ofCertificates
Animportant issue concerning certificates istheirlongevity. Firstletuscon-
siderthesituation inwhich acertification authority hands outlifelong certificates.
Essentially, what thecertificate thenstates isthatthepublic keywillalways be
valid fortheentity identified bythecertificate. Clearly, suchastatement isnot
whatwewant. Iftheprivate keyoftheidentified entity isevercompromised, no
unsuspecting client should everbeabletousethepublic key(letalone malicious
clients). Inthatcase, weneedamechanism torevoke thecertificate bymaking it
publicly-known thatthecertificate isnolonger valid,
There areseveral ways torevoke acertificate. Onecommon approach iswith
aCertificate Revocation List(CRL) published regularly bythecertification
authority. Whenever aclient checks acertificate, itwillhavetocheck theCRLto
seewhether thecertificate hasbeenrevoked ornot.Thismeans thattheclient will
atleasthave tocontact thecertification authority each timeanewCRL ispub-
lished. NotethatifaCRLispublished daily, italsotakes adaytorevoke acertifi-
cate.Meanwhile, acompromised certificate canbefalsely useduntilitispub-
lished onthenextCRL. Consequently, thetimebetween publishing CRLs cannot
betoolong. Inaddition, getting aCRLincurs some overhead.
Analternative approach istorestrict thelifetime ofeachcertificate. Ines-
sence, thisapproach isanalogous tohanding outleases aswediscussed in
Chap. 6.Thevalidity ofacertificate automatically expires aftersome time. Iffor
whatever reason thecertificate should berevoked before itexpires, thecertifica-
tionauthority canstillpublish itonaCRL. However, thisapproach willstillforce
clients tocheck thelatest CRL whenever verifvins acertificate. Inother words, .•...
theywillneedtocontact thecertification authority oratrusted database contain-
ingthelatest CRL.
Afinalextreme caseistoreduce thelifetime ofacertificate tonearly zero. In
-effect, thismeans thatcertificates arenolonger used; instead, aclient willalways
havetocontact thecertification authority tocheck thevalidity ofapublic key.As
aconsequence, thecertification authority mustbecontinuously online.
Inpractice, certificates arehanded outwithrestricted lifetimes. Inthecaseof
Internet applications, theexpiration timeisoften asmuch asayear(Stein, 1998).
Such anapproach requires thatCRLs arepublished regularly, butthattheyare
alsoinspected when certificates arechecked. Practice indicates thatclient applica-
tionshardly everconsult CRLs andsimply assume acertificate tobevalid untilit
expires. Inthisrespect, when itcomes toInternet security inpractice, there isstill
much room forimprovement, unfortunately.SEC. 9.4 SECURITY MANAGEMENT 433
9.4.2 Secure Group Management
Many security systems make useofspecial services suchasKeyDistribution
Centers (KDCs) orCertification Authorities (CAs). These services demonstrate a
difficult problem indistributed systems. Inthefirstplace, theymustbetrusted. To
enhance thetrustinsecurity services, itisnecessary toprovide ahighdegree of
protection against allkinds ofsecurity threats. Forexample, assoonasaCAhas
beencompromised, itbecomes impossible toverify thevalidity ofapublic key,
making theentire security system completely worthless.
Ontheother hand, itisalsonecessary thatmany security services offer high
availability. Forexample, inthecaseofaKDC, eachtimetwoprocesses wantto
setupasecure channel, atleastoneofthem willneedtocontact theKDC fora
shared secret key.IftheKDC isnotavailable, secure communication cannot be
established unless analternative technique forkeyestablishment isavailable, such
astheDiffie-Hellman keyexchange.
Thesolution tohighavailability isreplication. Ontheother hand, replication
makes aserver more vulnerable tosecurity attacks. Wealready discussed how
secure group communication cantakeplace bysharing asecret among thegroup
members. Ineffect, nosingle group member iscapable ofcompromising certifi-
cates, making thegroup itself highly secure. What remains toconsider ishowto
actually manage agroup ofreplicated servers. Reiter etal.(1994) propose thefol-
lowing solution.
Theproblem thatneeds tobesolved istoensure thatwhen aprocess asksto
joinagroup G,theintegrity ofthegroup isnotcompromised. Agroup Gis
assumed touseasecret keyeKe shared byallgroup members forencrypting
group messages. Inaddition, italsousesapublic/private keypair(Kt;, K(;) for
communication withnongroup members.
Whenever aprocess Pwants tojoinagroup G,itsends ajoinrequest JRiden-
tifying GandP,P'slocaltimeT,agenerated replypadRPandagenerated secret
keyKp,e.RPandKp.earejointly encrypted using thegroup's public keyK(;,as
shown asmessage IinFig.9-35. TheuseofRPandKp,Gisexplained inmore
detail below. Thejoinrequest JRissigned byP,andissentalong withacertifi-
catecontaining P'spublic key.Wehaveusedthewidely-applied notation [M1A to
denote. thatmessage Mhasbeensigned bysubject A.
When agroup member Qreceives suchajoinrequest, itfirstauthenticates P,
after which communication withtheother group members takes place tosee
whether Pcanbeadmitted asagroup member. Authentication ofPtakes place in
theusual waybymeans ofthecertificate. Thetimestamp Tisusedtomake sure
thatthecertificate wasstillvalid atthetimeitwassent.(Note thatweneedtobe
surethatthetimehasnotbeentampered withaswell.) Group member Qverifies
thesignature ofthecertification authority andsubsequently extracts P'spublic
keyfrom thecertificate tocheck thevalidity ofJR.Atthatpoint, agroup-specific
protocol isfollowed toseewhether allgroup members agree onadmitting P.434 SECURITY CHAP. 9
Figure 9-35. Securely admitting anewgroup member.
IfPisallowed tojointhegroup, Qreturns agroup admittance message GA,
shown asmessage 2inFig.9-35,identifying Pandcontaining anonce N.The
replypadRPisusedtoencrypt thegroup's communication keyCKG· Inaddition,
Pwillalsoneedthegroup's private keyKG,which isencrypted withCKG· Mes-
sageGAissubsequently signed byQusingkeyKp.G·
Process Pcannowauthenticate Q,because onlyatruegroup member can
havediscovered thesecret keyKp,G' Thenonce Ninthisprotocol isnotusedfor
security; instead, when Psends backNencrypted withKp,G (message 3),Qthen
knows thatPhasreceived allthenecessary keys, andhastherefore nowindeed
joined thegroup.
Notethatinstead ofusingthereplypadRP,PandQcould alsohaveencrypt-
tedCKG using P'spublic key.However, because RPisusedonlyonce, namely
fortheencryption ofthegroup's communication keyinmessage GA, usingRPis
safer. IfP'sprivate keywereevertorevealed, itwould become possible toalso
reveal CKG, which would compromise thesecrecy ofallgroup communication.
9.4.3Authorization Management
Managing security indistributed systems isalsoconcerned withmanaging ac-
cessrights. Sofar,wehavehardly touched upontheissueofhowaccess rights are
initially granted tousersorgroups ofusers, andhowtheyaresubsequently main-
tained inanunforgeable way.Itistimetocorrect thisomission.
Innondistributed systems, managing access rights isrelatively easy.When a
newuserisadded tothesystem, thatuserisgiven initial rights, forexample, to
create filesandsubdirectories inaspecific directory. create processes, useCPU
time,andsoon.Inotherwords, acomplete account forauserissetupforone
specific machine inwhich allrights havebeenspecified inadvance bythesystem
administrators.
Inadistributed system, matters arecomplicated bythefactthatresources~e
spread across several machines. Iftheapproach fornondistributed systems were
tobefollowed, itwould benecessary tocreate anaccount foreachuseroneach
machine. Inessence, thisistheapproach followed innetwork operating systems.SEC. 9.4 SECURITY MANAGEMENT 435
Matters canbesimplified abitbycreating asingle account onacentral server.
Thatserver isconsulted eachtimeauseraccesses certain resources ormachines.
Capabilities andAttribute Certificates
Amuch better approach thathasbeenwidely applied indistributed systems is
theuseofcapabilities. Asweexplained briefly above, acapability isanunforge-
abledatastructure foraspecific resource, specifying exactly theaccess rights that
theholder ofthecapability haswithrespect tothatresource. Different implemen-
tations ofcapabilities exist. Here, webriefly discuss theimplementation asused
intheAmoeba operating system (Tanenbaum etal.,1986).
Amoeba wasoneofthefirstobject-based distributed systems. Itsmodel of
distributed objects isthatofremote objects. Inotherwords, anobject resides ata
server while clients areoffered transparent access tothatobject bymeans ofa
proxy. Toinvoke anoperation onanobject, aclient passes acapability toitslocal
operating system, which thenlocates theserver where theobject resides andsub-
sequently doesanRPCtothatserver.
Acapability isa128-bit identifier, internally organized asshown inFig.9-36.
Thefirst48bitsareinitialized bytheobject's server when theobject iscreated
andeffectively form amachine-independent identifier oftheobject's server,
referred toastheserver port. Amoeba usesbroadcasting tolocate themachine
where theserver iscurrently located.
Figure 9-36. Acapability inAmoeba.
Thenext24bitsareusedtoidentify theobject atthegiven server. Notethat
theserver porttogether withtheobject identifier forma72-bit systemwide unique
identifier forevery object inAmoeba. Thenext8bitsareusedtospecify theac-
cessrights oftheholder ofthecapability. Finally, the48-bits check fieldisusedto
makeacapability unforgeable, asweexplain inthefollowing pages.
When anobject iscreated, itsserver picksarandom check fieldandstores it
bothinthecapability aswellasinternally initsowntables. Alltherightbitsina
newcapability areinitially on,anditisthisowner capability thatisreturned to
theclient. When thecapability issentbacktotheserver inarequest toperform an
operation, thecheck fieldisverified.
Tocreate arestricted capability, aclient canpassacapability backtothe
server, along withabitmask forthenewrights. Theserver takestheoriginal
check fieldfromitstables, XORs itwiththenewrights (which mustbeasubset of
therights inthecapability), andthenrunstheresult through aone-way function.436SECURITYCHAP. 9
Theserver thencreates anewcapability, withthesamevalue intheobject
field.butwiththenewrights bitsintherights fieldandtheoutput oftheone-way
function inthecheck field.Thenewcapability isthenreturned tothecaller. The
client maysendthisnewcapability toanother process, ifitwishes.
Themethod ofgenerating restricted capabilities isillustrated inFig.9-37. In
thisexample, theowner hasturned offalltherights except one.Forexample, the
restricted capability might allow theobject toberead,butnothing else.The
meaning oftherights fieldisdifferent foreachobject typesincethelegalopera-
tionsthemselves alsovaryfromobject typetoobject type.
Figure 9-37. Generation ofarestricted capability fromanowner capability.
When therestricted capability comes backtotheserver, theserver seesfrom
therights fieldthatitisnotanowner capability because atleastonebitisturned
off.Theserver thenfetches theoriginal random number fromitstables, XORs it
withtherights fieldfromthecapability, andrunstheresult through theone-way
function. Iftheresult agrees withthecheck field, thecapability isaccepted as
valid.Itshould beobvious fromthisalgorithm thatauserwhotriestoaddrights that
hedoesnothavewillsimply invalidate thecapability. Inverting thecheck fieldin
arestricted capability togettheargument (CXOR 00000001 inFig.9-37) is
impossible because thefunction fisaone-way function. Itisthrough thiscrypto-
graphic technique thatcapabilities areprotected fromtampering. Notethatfes-
sentially doesthesame ascomputing amessage digest asdiscussed earlier.
Changing anything intheoriginal message (likeinverting abit),willimmediately
bedetected.Ageneralization ofcapabilities thatissometimes usedinmodern distributed
systems istheattribute certificate. Unlike thecertificates discussed above that
areusedtoverify thevalidity ofapublic key,attribute certificates areusedtolist.-
certain (attribute, value)-pairs thatapplytoanidentified entity. Inparticular, attri-
butecertificates canbeusedtolisttheaccess rights thattheholder ofacertificate
haswithrespect totheidentified resource.SEC. 9.4 SECURITY MANAGEMENT 437
Likeothercertificates, attribute certificates arehanded outbyspecial certifi-
cation authorities, usually called attribute certification authorities. Compared
toAmoeba's capabilities, suchanauthority corresponds toanobject's server. In
general, however, theattribute certification authority andtheserver managing the
entity forwhich acertificate hasbeencreated neednotbethesame. Theaccess
rights listedinacertificate aresigned bytheattribute certification authority.
Delegation
Nowconsider thefollowing problem. Auserwants tohavealargefileprinted
forwhich hehasread-only access rights. Inordernottobother others toomuch,
theusersends arequest totheprintserver, asking ittostartprinting thefileno
earlier than20'clock inthemorning. Instead ofsending theentire filetothe
printer, theuserpasses thefilename totheprinter sothatitcancopyittoits
spooling directory, ifnecessary, whenactually needed.
Although thisscheme seems tobeperfectly inorder, thereisonemajor prob-
lem:theprinter willgenerally nothavetheappropriate access permissions tothe
named file.Inotherwords, ifnospecial measures aretaken, assoonastheprint
server wants toreadthefileinordertoprintit,thesystem willdenytheserver ac-
cesstothefile.Thisproblem could havebeensolved iftheuserhadtemporarily
delegated hisaccess rights forthefiletotheprintserver.
Delegation ofaccess rights isanimportant technique forimplementing pro-
tection incomputer systems anddistributed systems, inparticular. Thebasicidea
issimple: bypassing certain access rights fromoneprocess toanother, itbecomes
easier todistribute workbetween several processes without adversely affecting
theprotection ofresources. Inthecaseofdistributed systems, processes mayrun
ondifferent machines andevenwithin different administrative domains aswedis-
cussed forGlobus. Delegation canavoid much overhead asprotection canoften
behandled locally.
There areseveral ways toimplement delegation. Ageneral approach as
described inNeuman (1993), istomakeuseofaproxy. Aproxy inthecontext of
security incomputer systems isatoken thatallows itsowner tooperate withthe
sameorrestricted rights andprivileges asthesubject thatgranted thetoken. (Note
thatthisnotion ofaproxy isdifferent fromaproxy asasynonym foraclient-side
stub.Although wetrytoavoid overloading terms, wemake anexception hereas
theterm"proxy" inthedefinition above istoowidely usedtoignore.) Aprocess
cancreate aproxy withatbestthesamerights andprivileges ithasitself. Ifa
process creates anewproxy based ononeitcurrently has,thederived proxy will
haveatleastthesamerestrictions astheoriginal one,andpossibly more.
Before considering ageneral scheme fordelegation, consider thefollowing
twoapproaches. First,delegation isrelatively simple ifAlice knows everyone. If
shewants todelegate rights toBob,shemerely needs toconstruct acertificate438 SECURITY CHAP. 9
saying "Alice saysBobhasrights R."suchas[A,B,R lA.IfBobwants topass
someoftheserights toCharlie, hewillaskCharlie tocontact Alice andaskher
foranappropriate certificate.
Inasecond simple caseAlice cansimply construct acertificate saying "The
bearer ofthiscertificate hasrights R."However, inthiscaseweneedtoprotect
thecertificate against illegal copying, asisdonewithsecurely passing capabilities
between processes. Neuman's scheme handles thiscase,aswellasavoiding the
issuethatAliceneeds toknow everyone towhom rights needtobedelegated.
Aproxy inNeuman's scheme hastwoparts, asillustrated inFig.9-38. LetA
betheprocess thatcreated theproxy. Thefirstpartoftheproxy isaset
C={R,S;'.o.\}'}, consisting ofasetRofaccess rights thathavebeendelegated by
A,along withapublicly-known partofasecret thatisusedtoauthenticate the
holder ofthecertificate. Wewillexplain theuseofS;roxy below. Thecertificate
carries thesignature sig(A,C)ofA,toprotect itagainst modifications. Thesecond
partcontains theotherpartofthesecret, denoted asSprox)" Itisessential thatSpro:>,:y
isprotected against disclosure whendelegating rights toanother process.
Figure 9-38. Thegeneral structure ofaproxy asusedfordelegation.
Another wayoflooking attheproxy isasfollows. IfAlice wants todelegate
someofherrights toBob,shemakes alistofrights (R)thatBobcanexercise. By
signing thelist,sheprevents Bobfromtampering withit.However, having onlya
signed listofrights isoften notenough. IfBobwants toexercise hisrights, he
mayhavetoprove thatheactually gotthelistfromAlice anddidnot,forex-
ample, stealitfromsomeone else.Therefore, Alice comes upwithaverynasty
question (S;ro.x:J thatonlysheknows theanswer to(Sproxy)' Anyone caneasily
verify thecorrectness oftheanswer when given thequestion. Thequestion is
appended tothelistbefore Alice addshersignature.
When delegating some ofherrights, Alice gives thesigned listofrights,
alongwiththenastyquestion, toBob.ShealsogivesBobtheanswer ensuring that
noonecanintercept it.Bobnowhasalistofrights, signed byAlice, which hecan
handoverto,say,Charlie, when necessary. Charlie willaskhimthenastyques-
tionatthebottom ofthelist.IfBobknows theanswer toit,Charlie willknow for
surethatAlicehadindeed delegated thelistedrights toBob.
Animportant property ofthisscheme isthatAlice neednotbeconsulted. In
fact,Bobmaydecide topasson(some of)therights onthelisttoDave. Indoing
so,hewillalsotellDave theanswer tothequestion. sothatDave canprove theSEC. 9.4 SECURITY MANAGEMENT 439
listwashanded overtohimbysomeone entitled toit.Alice never needs toknow
aboutDaveatall.
Aprotocol fordelegating andexercising rights isshown inFig.9-39. Assume
thatAlice andBobshare asecret key~,B thatcanbeusedforencrypting mes-
sages theysendtoeach other. Then, Alice firstsends Bobthecertificate
C={R,S;roxy}, signed withsig(A,C) (anddenoted againas[R,S;roxy]A)' There is
noneedtoencrypt thismessage: itcanbesentasplaintext. Onlytheprivate part
ofthesecret needs tobeencrypted, shown asKA,B(S;roxy) inmessage 1.
Figure 9-39. Using aproxy todelegate andprove ownership ofaccess rights.
Nowsuppose thatBobwants anoperation tobecarried outatanobject that
resides ataspecific server. Also, assume thatAliceisauthorized tohavethatop-
eration carried out,andthatshehasdelegated thoserights toBob.Therefore, Bob
hands overhiscredentials totheserver intheformofthesigned certificate
'+[R,Sproxy]A'
Atthatpoint, theserver willbeabletoverify thatChasnotbeentampered
with:anymodification tothelistofrights, orthenastyquestion willbenoticed,
because bothhavebeenjointly signed byAlice. However, theserver doesnot
know yetwhether Bobistherightful owner ofthecertificate. Toverify this,the
server mustusethesecret thatcamewithC.
There areseveral waystoimplement S;roxy andS;roxy. Forexample, assume
S;roxy isapublic keyandS;roxy thecorresponding private key.Zcanthenchal-
lenge Bobbysending himanonce N,encrypted withS;roxy. Bydecrypting
S;roxy(N)andreturning N,Bobproves heknows thesecret andisthustherightful
holder ofthecertificate. There areotherwaystoimplement secure delegation as
well,butthebasicideaisalways thesame: showyouknow asecret.
9.SSUMMARY
Security plays anextremely important roleindistributed systems. Adistrib-
utedsystem should provide themechanisms thatallowavariety ofdifferent secu-
ritypolicies tobeenforced. Developing andproperly applying thosemechanisms
generally makes security adifficult engineering exercise.440 SECURITY CHAP. 9
Three important issues canbedistinguished. Thefirstissueisthatadistrib-
utedsystem should offerfacilities toestablish secure channels between processes.
Asecure channel. inprinciple, provides themeans tomutually authenticate the
communicating parties, andprotect messages against tampering during their
transmission. Asecure channel generally alsoprovides confidentiality sothatno
onebutthecommunicating parties canreadthemessages thatgothrough the
channel.
Animportant design issueiswhether touseonlyasymmetric cryptosystem
(which isbased onshared secret keys), ortocombine itwithapublic-key system.
Current practice shows theuseofpublic-key cryptography fordistributing short-
termshared secret keys.Thelatterareknown assession keys.
Thesecond issueinsecure distributed systems isaccess control, orauthoriza-
tion.Authorization dealswithprotecting resources insuchawaythatonlyproc-
essesthathavetheproper access rights canactual access andusethoseresources.
Access control always takeplace afteraprocess hasbeenauthenticated. Related
toaccess control ispreventing denial-of-service, which turnsouttoadifficult
problem forsystems thatareaccessible through theInternet.
There aretwowaysofimplementing access control. First,eachresource can
maintain anaccess control list,listing exactly theaccess rights ofeachuseror
process. Alternatively, aprocess cancarryacertificate stating precisely whatits
rights areforaparticular setofresources. Themainbenefit ofusingcertificates is
thataprocess caneasily passitsticket toanother process, thatis,delegate itsac-
cessrights. Certificates, however, havethedrawback thattheyareoftendifficult
torevoke.
Special attention isneeded when dealing withaccess control inthecaseof
mobile code.Besides being abletoprotect mobile codeagainst amalicious host,it
isgenerally more important toprotect ahostagainst malicious mobile code.
Several proposals havebeenmade, ofwhich thesandbox iscurrently themost
widely-applied one.However, sandboxes arerather restrictive, andmoreflexible
approaches based ontrueprotection domains havebeendevised aswell.
Thethirdissueinsecure distributed systems concerns management. There are
essentially twoimportant subtopics: keymanagement andauthorization manage-
ment. Keymanagement includes thedistribution ofcryptographic keys,forwhich
certificates asissued bytrusted thirdparties playanimportant role.Important
withrespect toauthorization management areattribute certificates anddelegation.
PROBLEMS
1.Which mechanisms could adistributed system provide assecurity services toapplica-
tiondevelopers thatbelieve onlyintheend-to-end argument insystem's design. as
discussed inChap. 61CtLA..P-.- 9 PROBLEMS 441
2.IntheRISSC approach, canallsecurity beconcentrated onsecure servers ornot?
3.Suppose thatyouwere asked todevelop adistributed application thatwould allow
teachers tosetupexams. Give atleastthreestatements thatwould bepartofthesecu-
ritypolicy forsuchanapplication.
4.Would itbesafetojoinmessage 3andmessage 4intheauthentication protocol shown
inFig.9-12, intoKA.B(Rs,RA)?
5.Why isitnotnecessary inFig.9-15fortheKDC toknow forsureitwastalking to
Alice when itreceives arequest forasecret keythatAlice canshare withBob?
6.What iswrong inimplementing anonce asatimestamp?
7.Inmessage 2oftheNeedham-Schroeder authentication protocol, 'theticket is
encrypted withthesecret keyshared between Alice andtheKDC. Isthisencryption
necessary?
8.Canwesafely adapt theauthentication protocol shown inFig.9-19suchthatmessage
3consists onlyofRB?
9.Devise asimple authentication protocol using signatures inapublic-key cryptosystem.
10.Assume Alice wants tosendamessage mtoBob.Instead ofencrypting mwithBob's
public keyKt,shegenerates asession keyKA.B andthensends [KA.B(m),Kt(KA.B)]·
Whyisthisscheme generally better? (Hint: consider performance issues.)
11•.What istheroleofthetimestamp inmessage 6inFig.9-23, andwhydoesitneedto
beencrypted?
12.Complete Fig.9-23byadding thecommunication forauthentication between Alice
andBob.
13.Howcanrolechanges beexpressed inanaccess control matrix?
14.HowareACLs implemented inaUNIX filesystem?
15.How cananorganization enforce theuseofaWeb proxy gateway andprevent its
users todirectly access external Webservers?
16.Referring toFig.9-31, towhat extent doestheuseofJavaobject references ascapa-
bilities actually depend ontheJavalanguage?
17.Name three problems thatwillbeencountered when developers ofinterfaces tolocal
resources arerequired toinsert callstoenable anddisable privileges toprotect against
unauthorized access bymobile programs asexplained inthetext.
18.Name afewadvantages anddisadvantages ofusing centralized servers forkey
management.
19.TheDiffie-Hellman key-exchange protocol canalsobeusedtoestablish ashared
secret keybetween threeparties. Explain how.
20.There isnoauthentication intheDiffie-Hellman key-exchange protocol. Byexploiting
thisproperty, amalicious thirdparty, Chuck, caneasily break intothekeyexchange
taking place between Alice andBob,andsubsequently ruinthesecurity. Explain how
thiswould work.442 SECURITY CHAP. 9
21.Giveastraightforward wayhowcapabilities inAmoeba canberevoked.
22.Does itmake sense torestrict thelifetime ofasession key?Ifso,giveanexample how
thatcould beestablished.
23.(Lab assignment) Install andconfigure aKerberos v5environment foradistributed
system consisting ofthree different machines. Oneofthese machines should berun-
ningtheKDC. Make sureyoucansetup a(Kerberos) telnet connection between any
twomachines, butmaking useofonlyasingle registered password attheKOC. Many
ofthedetails onrunning Kerberos areexplained inGarman (2003).10
DISTRIBUTED
OBJECT-BASED SYSTEMS
With thischapter, weswitch fromourdiscussion ofprinciples toanexamina-
tionofvarious paradigms thatareusedtoorganize distributed systems. Thefirst
paradigm consists ofdistributed objects. Indistributed object-based systems, the
notion ofanobject plays akeyroleinestablishing distribution transparency. In
principle, everything istreated asanobject andclients areoffered services andre-
sources intheformofobjects thattheycaninvoke.
Distributed objects formanimportant paradigm because itisrelatively easyto
hidedistribution aspects behind anobject's interface. Furthermore, because anob-
jectcanbevirtually anything, itisalsoapowerful paradigm forbuilding systems.
Inthischapter, wewilltakealookathowtheprinciples ofdistributed systems are
applied toanumber ofwell-known object-based systems. Inparticular, wecover
aspects ofCORBA, Java-based systems, andGlobe.
10.1ARCHITECTURE
Object orientation forms animportant paradigm insoftware development.
Eversince itsintroduction, ithasenjoyed ahugepopularity. Thispopularity stems
from thenatural ability tobuild software intowell-defined andmore orless
independent components. Developers could concentrate onimplementing specific
functionality independent fromother developers.
443444 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Object orientation began tobeusedfordeveloping distributed systems inthe
1980s. Again, thenotion ofanindependent object hosted byaremote server while
attaining ahighdegree ofdistribution transparency formed asolidbasisforde-
veloping anewgeneration ofdistributed systems. Inthissection, wewillfirsttake
adeeper lookintothegeneral architecture ofobject-based distributed systems,
afterwhich wecanseehowspecific principles havebeendeployed inthesesys-
tems.
10.1.1 Distributed Objects
Thekeyfeature ofanobject isthatitencapsulates data.called thestate, and
theoperations onthose data,called themethods. Methods aremade available
through aninterface. Itisimportant tounderstand thatthereisno"legal" waya
process canaccess ormanipulate thestateofanobject other thanbyinvoking
methods made available toitviaanobject's interface. Anobject mayimplement
multiple interfaces. Likewise, given aninterface definition, theremaybeseveral
objects thatofferanimplementation forit.
Thisseparation between interfaces andtheobjects implementing theseinter-
facesiscrucial fordistributed systems. Astrictseparation allows ustoplace an
interface atonemachine, while theobject itselfresides onanother machine. This
organization, which isshown inFig.10-1,iscommonly referred toasadistrib-
utedobject.
Figure 10-1. Common organization ofaremote object withclient-side proxy.
When aclient binds toadistributed object. animplementation oftheobject" s
interface, called aproxy, isthenloaded intotheclient's address space. Aproxy isSEC. 10.1 ARCHITECTURE 445
analogous toaclient stubinRPCsystems. Theonlything itdoesismarshal meth-
odinvocations intomessages andunmarshal reply messages toreturn theresult of
themethod invocation totheclient. Theactual object resides ataserver machine,
where itoffers thesame interface asitdoesontheclient machine. Incoming invo-
cation requests arefirstpassed toaserver stub,which unmarshals them tomake
method invocations attheobject's interface attheserver. Theserver stubisalso
responsible formarshaling replies andforwarding reply messages totheclient-
sideproxy.
Theserver-side stubisoften referred toasaskeleton asitprovides thebare
means forletting theserver middleware access theuser-defined objects. Inprac-
tice,itoften contains incomplete codeintheformofalanguage-specific classthat
needs tobefurther specialized bythedeveloper.
Acharacteristic, butsomewhat counterintuitive feature ofmostdistributed ob-
jectsisthattheirstateisnotdistributed: itresides atasingle machine. Only the
interfaces implemented bytheobject aremade available onother machines. Such
objects arealsoreferred toasremote objects. Inageneral distributed object, the
stateitself maybephysically distributed across multiple machines, butthisdistri-
bution isalsohidden fromclients behind theobject's interfaces.
Compile- Time versus Runtime Objects
Objects indistributed systems appear inmany forms. Themostobvious form
istheonethatisdirectly related tolanguage-level objects suchasthose supported
byJava, C++, orother object-oriented languages, which arereferred toas
compile-time objects. Inthiscase, anobject isdefined astheinstance ofaclass.
Aclass isadescription ofanabstract typeinterms ofamodule withdataele-
ments andoperations onthatdata(Meyer, 1997).
Usingcompile-time objects indistributed systems often makes itmuch easier
tobuild distributed applications. Forexample, inJava, anobject canbefullyde-
fined bymeans ofitsclassandtheinterfaces thattheclassimplements. Compiling
theclassdefinition results incodethatallows ittoinstantiate Javaobjects. Thein-
terfaces canbecompiled intoclient-side andserver-side stubs, allowing theJava
objects tobeinvoked from aremote machine. AJavadeveloper canbelargely
unaware ofthedistribution ofobjects: heseesonlyJavaprogramming code.
Theobvious drawback ofcompile-time objects isthedependency onapartic-
ularprogramming language. Therefore, analternative wayofconstructing distrib-
utedobjects istodothisexplicitly during runtime. Thisapproach isfollowed in
many object-based distributed systems, asitisindependent oftheprogramming
language inwhich distributed applications arewritten. Inparticular, anapplica-
tionmaybeconstructed fromobjects written inmultiple languages.
When dealing withruntime objects, howobjects areactually implemented is
basically leftopen. Forexample, adeveloper maychoose towrite aClibrary con-
taining anumber offunctions thatcanallwork onacommon datafile.The446 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
essence ishowtoletsuchanimplementation appear tobeanobject whose meth-
odscanbeinvoked fromaremote machine. Acommon approach istouseanob-
jectadapter, which actsasawrapper around theimplementation withthesole
purpose togiveittheappearance ofanobject. Thetermadapter isderived froma
design pattern described inGamma etal.(1994), which allows aninterface tobe
converted intosomething thataclient expects. Anexample object adapter isone
thatdynami<.:aUy binds totheClibrary mentioned above andopens anassociated
datafilerepresenting anobject's current state.
Object adapters playanimportant roleinobject-based distributed systems. To
make \\Tapping aseasyaspossible, objects aresolely defined interms ofthein-
terfaces theyimplement. Animplementation ofaninterface canthenberegistered
atanadapter, which cansubsequently make thatinterface available for(remote)
invocations. Theadapter willtakecarethatinvocation requests arecarried out,
andthusprovide animage ofremote objects toitsclients. Wereturn totheorgani-
zation ofohject servers andadapters laterinthischapter.
Persistent andTransient Objects
Besides thedistinction between language-level objects andruntime objects,
there isalsoadistinction between persistent andtransient objects. Apersistent
object is011<.: thatcontinues toexistevenifitiscurrently notcontained inthead-
dress space ofanyserver process. Inother words, apersistent object isnotdepen-
dentonitscurrent server. Inpractice, thismeans thattheserver thatiscurrently
managing thepersistent object, canstore theobject's stateonsecondary storage
andthenexit.Later, anewly started server canreadtheobject's statefrom storage
intoitsownaddress space, andhandle invocation requests. Incontrast, atran-
sient object isanobject thatexists onlyaslongastheserver thatishosting the
object. AsS'lonasthatserver exits, theobject ceases toexistaswell. There used
tobemuch controversy about having persistent objects; some people believe that
transient O~.K'cts areenough. Totakethediscussion away frommiddleware issues,
mostobject-hased distributed systems simply support bothtypes.
10.1.2 Exulnple: Enterprise JavaBeans
TheJav., programming language andassociated model hasformed thefoun-
dation fornumerous distributed systems andapplications. Itspopularity canbe
attributed tothestraightforward support forobject orientation, combined withthe
inherent SUpport forremote method invocation. Aswewilldiscuss laterinthis
chapter, Jav.,provides ahighdegree ofaccess transparency, making iteasier to
usethan,foiexample, thecombination ofCwithremote procedure calling.
Eversin\.'t' itsintroduction, there hasbeenastrong incentive toprovide facili-
tiesthatwonIIIeasethedevelopment ofdistributed applications. These facilities
gowellbey,\Ildlanguage support, requiring aruntime environment thatsupportsSEC. 10.1 ARCHITECTURE 447
traditional multitiered client-server architectures. Tothisend,much work has
beenputintothedevelopment of(Enterprise) JavaBeans(EJB).
AnEJBisessentially aJavaobject thatishosted byaspecial server offering
different waysforremote clients toinvoke thatobject. Crucial isthatthisserver
provides thesupport toseparate application functionality fromsystems-oriented
functionality. Thelatterincludes functions forlooking upobjects, storing objects,
letting objects bepartofatransaction, andsoon.Howthisseparation canbereal-
izedisdiscussed below when weconcentrate onobject servers. Howtodevelop
EJBsisdescribed indetail byMonson-Hafael etal.(2004). Thespecifications
canbefound inSunMicrosystems (2005a).
Figure 10-2. General architecture ofanEJBserver.
Withthisseparation inmind, EJBscanbepictured asshown inFig.10-2.
Theimportant issueisthatanEJBisembedded inside acontainer which effec-
tively provides interfaces tounderlying services thatareimplemented bytheap-
plication server. Thecontainer canmoreorlessautomatically bindtheEJBto
theseservices, meaning thatthecorrect references arereadily available toapro-
grammer. Typical services include those forremote method invocation (RMI),
database access (JDBC), naming (JNDI), andmessaging (JMS). Making useof
these services ismoreorlessautomated, butdoesrequire thattheprogrammer
makes adistinction between fourkindsofEJBs:
1.Stateless session beans
2.Stateful session beans
3.Entity beans
4.Message-driven beans448 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Asitsname suggests, astateless session bean isatransient object thatis
invoked once, doesitswork, afterwhich itdiscards anyinformation itnl'l'lkd to
perform theservice itoffered toaclient. Forexample, astateless session bean
could beusedtoimplement aservice thatliststhetop-ranked books. Inthiscase,
thebeanwould typically consist ofanSQLquery thatissubmitted toandawhase.
Theresults would beputintoaspecial format thattheclient canhandle. utter
which itswork would havebeencompleted andthelisted books discarded.
Incontrast, astateful session bean maintains client-related state. Ther:lIHmi-
calexample isabeanimplementing anelectronic shopping cartlikethose "ilkly
deployed forelectronic commerce. Inthiscase,aclient would typically beabkto
putthings inacart,remove items, andusethecarttogotoanelectronic c1ll,,'kllut.
Thebean, intum,would typically access databases forgetting current prirr~and
information onnumber ofitems stillinstock. However, itslifetime would stillhe
limited, which iswhyitisreferred toasasession bean: when theclient isfinished
(possibly having invoked theobject several times), thebeanwillautomatically he
destroyed.
Anentity bean canbeconsidered tobealong-lived persistent objr,'1. As
such, anentity beanwillgenerally bestored inadatabase, andlikewise, will,-ttcn
alsobepartofdistributed transactions. Typically, entity beans store infonl\;IIion
thatmaybeneeded anexttimeaspecific client access theserver. Insetlill~s for
electronic commerce, anentity beancanbeusedtorecord customer inforlll:l1ion,
forexample, shipping address, billing address, credit cardinformation, ands,'on.
Inthese cases, when aclient logsin,hisassociated entity bean willben'sh'red
andusedforfurther processing.
Finally, message-driven beans areusedtoprogram objects thatshould react
toincoming messages (andlikewise, beabletosendmessages). Message-driyen
beans cannot beinvoked directly byaclient, butrather fitintoapublish-suh" .:ribe
wayofcommunication, which webriefly discussed inChap. 4.What itboils
down toisthatamessage-driven beanisautomatically called bytheserver when
aspecific message misreceived, towhich theserver (orrather anapplication itis
hosting) hadpreviously subscribed. Thebeancontains application code huhan-
dling themessage, after which theserver simply discards it.Message·driven
beans arethusseentobestateless. Wewillreturn extensively tothistypeIll' :I.)m-
munication inChap. 13.
10.1.3 Example: Globe Distributed Shared Objects
Letusnowtakealookatacompletely different typeofobject-based dl:-rrib-
utedsystem. Globe isasystem inwhich scalability plays acentral rolt'.All
aspects thatdealwithconstructing alarge-scale wide-area system thatcansurport
hugenumbers ofusers andobjects drive thedesign ofGlobe. Fundamental h)this
approach isthewayobjects areviewed. Likeother object-based systems. ,lr5ects
inGlobe areexpected toencapsulate stateandoperations onthatstate.SEC. 10.1 ARCHITECTURE 449
~ important difference withotherobject-based systems isthatobjects are
alsoexpected toencapsulate theimplementation ofpolicies thatprescribe thedis-
tribution ofanobject's stateacross multiple machines. Inotherwords, eachobject
determines howitsstatewillbedistributed overitsreplicas. Eachobject alsocon-
trolsitsownpolicies inotherareasaswell.
Byandlarge, objects inGlobe areputincharge asmuch aspossible. Forex-
ample, anobject decides how,when, andwhere itsstateshould bemigrated. Also,
anobject decides ifitsstateistobereplicated, andifso,howreplication should
takeplace. Inaddition, anobject mayalsodetermine itssecurity policy and
implementation. Below, wedescribe howsuchencapsulation isachieved.
Object Model
Unlike mostotherobject-based distributed systems, Globe doesnotadopt the
remote-object modeL Instead, objects inGlobe canbephysically distributed,
meaning thatthestateofanobject canbedistributed andreplicated across multi-
pleprocesses. Thisorganization isshown inFig.10-3,which shows anobject that
isdistributed across fourprocesses, eachrunning onadifferent machine. Objects
inGlobe arereferred toasdistributed shared objects, toreflect thatobjects are
normally shared between several processes. Theobject model originates fromthe
distributed objects usedinOrcaasdescribed inBal(1989). Similar approaches
havebeenfollowed forfragmented objects (Makpangou etaL,1994).
Figure 10-3.Theorganization ofaGlobe distributed shared object.
Aprocess thatisbound toadistributed shared object isoffered alocalimple-
mentation oftheinterfaces provided bythatobject. Suchalocalimplementation is
called alocalrepresentative, orsimply localobject. Inprinciple, whether ornot
alocalobject hasstateiscompletely transparent tothebound process. Allimple-
mentation details ofanobject arehidden behind theinterfaces offered toaproc-
ess.Theonlythingvisible outside thelocalobject areitsmethods.450 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Globe localobjects come intwoflavors. Aprimitive localobject isalocal
object thatdoesnotcontain anyotherlocalobjects. Incontrast. acomposite local
object isanobject thatiscomposed ofmultiple (possibly composite) localob-
jects.Composition isusedtoconstruct alocalobject thatisneeded forimplemen-
tingdistributed shared objects. Thislocalobject isshown inFig.10-4andconsists
ofatleastfoursubobjects.
Figure 10-4. Thegeneral organization ofalocal object fordistributed shared
objects inGlobe.
Thesemantics subobject implements thefunctionality provided byadistrib-
utedshared object. Inessence, itcorresponds toordinary remote objects, similar
inflavor toEIBs.
Thecommunication snbobject isusedtoprovide astandard interface tothe
underlying network. Thissubobject offers anumber ofmessage-passing primi-
tivesforconnection-oriented aswellasconnectionless communication. There are
alsomore advanced communication subobjects available thatimplement multi-
casting interfaces. Communication subobjects canbeusedthatimplement reliable
communication, while others offeronlyunreliable communication.
Crucial tovirtually alldistributed shared objects isthereplication subobject.
Thissubobject implements theactual distribution strategy foranobject. Asinthe
caseofthecommunication subobject, itsinterface isstandardized. Thereplication
subobject isresponsible fordeciding exactly when amethod asprovided bythe
semantics subobject istobecarried out.Forexample, areplication subobject that
implements active replication willensure thatallmethod invocations arecarried
outinthesameorderateachreplica. Inthiscase,thesubobject willhavetocom-
municate withthereplication subobjects inotherlocalobjects thatcomprise the
distributed shared object.SEC. 10.1 ARCHITECTURE 451
Thecontrol. subobject isusedasanintermediate between theuser-defined
interfaces ofthesemantics subobject andthestandardized interfaces oftherepli-
cation subobject. Inaddition, itisresponsible forexporting theinterfaces ofthe
semantics subobject totheprocess bound tothedistributed shared object. All
method invocations requested bythatprocess aremarshaled bythecontrol subob-
jectandpassed tothereplication subobject.
Thereplication subobject willeventually allow thecontrol subobject tocarry
onwithaninvocation request andtoreturn theresults totheprocess. Likewise,
invocation requests fromremote processes areeventually passed tothecontrol
subobject aswell.Sucharequest isthenunmarshaled, afterwhich theinvocation
iscarried outbythecontrol subobject, passing results backtothereplication
subobject.
10.2PROCESSES
Akeyroleinobject-based distributed systems isplayed byobject servers, that
is,theserver designed tohostdistributed objects. Inthefollowing, wefirstcon-
centrate ongeneral aspects ofobject servers, afterwhich wewilldiscuss the
open-source JBoss server.
10.2.1ObjectServers
Anobject server isaserver tailored tosupport distributed objects. Theimpor-
tantdifference between ageneral object server andother(more traditional) ser-
versisthatanobject server byitselfdoesnotprovide aspecific service. Specific
services areimplemented bytheobjects thatreside intheserver. Essentially, the
server provides onlythemeans toinvoke localobjects, based onrequests fromre-
moteclients. Asaconsequence, itisrelatively easytochange services bysimply
adding andremoving objects.
Anobject server thusactsasaplacewhere objects live.Anobject consists of
twoparts: datarepresenting itsstateandthecodeforexecuting itsmethods.
Whether ornotthesepartsareseparated, orwhether method implementations are
shared bymultiple objects, depends ontheobject server. Also, therearediffer-
ences inthewayan object server invokes itsobjects. Forexample, inamul-
tithreadedserver, eachobject maybeassigned aseparate thread, oraseparate
thread maybeusedforeachinvocation request. These andotherissues aredis-
cussed next.
Alternatives forInvoking Objects
Foranobject tobeinvoked, theobject server needs toknow which codeto
execute, onwhich dataitshould operate, whether itshould startaseparate thread
totakecareoftheinvocation, andsoon.Asimple approach istoassume thatall452 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
objects lookalikeandthatthereisonlyonewaytoinvoke anobject. Unfor-
tunately. suchanapproach isgenerally inflexible andoften unnecessarily con-
strains developers ofdistributed objects.
Amuchbetter approach isforaserver tosupport different policies. Consider,
forexample, transient objects. RecaJI thatatransient object isanobject thatexists
onlyaslongasitsserver exists, butpossibly forashorter period oftime.Anin-
memory, read-only copyofafilecould typically beimplemented asatransient
object. Likewise, acalculator could alsobeimplemented asatransient object. A
reasonable policy istocreate atransient object atthefirstinvocation request and
todestroy itassoonasnoclients arebound toitanymore.
Theadvantage ofthisapproach isthatatransient object willneedaserver's
resources onlyaslongastheobject isreally needed. Thedrawback isthatanin-
vocation maytakesometimetocomplete, because theobject needs tobecreated
first.Therefore, analternative policy issometimes tocreate alltransient objects at
thetimetheserver isinitialized, atthecostofconsuming resources evenwhenno
client ismaking useoftheobject.
Inasimilar fashion, aserver could follow thepolicy thateachofitsobjects is
placed inamemory segment ofitsown.Inotherwords, objects shareneither code
nordata.Suchapolicy maybenecessary whenanobject implementation doesnot
separate codeanddata,orwhenobjects needtobeseparated forsecurity reasons.
Inthelattercase,theserver willneedtoprovide special measures, orrequire sup-
portfromtheunderlying operating system, toensure thatsegment boundaries are
notviolated. .
Thealternative approach istoletobjects atleastshare theircode. Forex-
ample, adatabase containing objects thatbelong tothesameclasscanbeeffi-
ciently implemented byloading theclassimplementation onlyonceintotheser-
ver.When arequest foranobject invocation comes in,theserver needonlyfetch
thatobject's statefromthedatabase andexecute therequested method.
Likewise, there aremany different policies withrespect tothreading. The
simplest approach istoimplement theserver withonlyasingle thread ofcontrol.
Alternatively, theserver mayhaveseveral threads, oneforeachofitsobjects.
Whenever aninvocation request comes inforanobject, theserver passes there-
quest tothethread responsible forthatobject. Ifthethread iscurrently busy, the
request istemporarily queued.
Theadvantage ofthisapproach isthatobjects areautomatically protected
against concurrent access: allinvocations areserialized through thesingle thread
associated withtheobject. Neatandsimple. Ofcourse, itisalsopossible tousea
separate thread foreachinvocation request, requiring thatobjects should have
already beenprotected against concurrent access. Independent ofusing athread
perobject orthread permethod isthechoice ofwhether threads arecreated on
demand ortheserver maintains apoolofthreads. Generally thereisnosingle best
policy. Which onetousedepends onwhether threads areavailable, howmuch
performance matters, andsimilar factors.SEC. 10.2 PROCESSES 453
ObjectAdapter
Decisions onhowtoinvoke anobject arecommonly referred toasactivation
policies, toemphasize thatinmany cases theobject itselfmustfirstbebrought
intotheserver's address space (i.e.,activated) before itcanactually beinvoked.
What isneeded thenisamechanism togroup objects perpolicy. Suchamechan-
ismissometimes called anobjectadapter, oralternatively anobjectwrapper.
Anobject adapter canbestbethought ofassoftware implementing aspecific ac-
tivation policy. Themainissue, however, isthatobject adapters come asgeneric
components toassistdevelopers ofdistributed objects, andwhich needonlytobe
configured foraspecific policy.
Anobject adapter hasoneormoreobjects under itscontrol. Because aserver
should becapable ofsimultaneously supporting objects thatrequire different
activation policies, several object adapters mayreside inthesameserver atthe
sametime.When aninvocation request isdelivered totheserver, thatrequest is
firstdispatched totheappropriate object adapter, asshown inFig.10-5.
Figure 10-5.Organization ofanobject server supporting different activation policies.
Animportant observation isthatobject adapters areunaware ofthespecific
interfaces oftheobjects theycontrol. Otherwise, theycould neverbegeneric. The
onlyissuethatisimportant toanobject adapter isthatitcanextract anobject ref-
erence fromaninvocation request, andsubsequently dispatch therequest tothe
referenced object, butnowfollowing aspecific activation policy. Asisalso0;-
lustrated inFig.10-5,rather thanpassing therequest directly totheobject, an454 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
adapter hands aninvocation request totheserver-side stubofthatobject. The
stub,alsocalled askeleton, isnormally generated fromtheinterface definitions of
theobject, unmarshals therequest andinvokes theappropriate method.
Anobject adapter cansupport different activation policies bysimply configur-
ingitatruntime. Forexample, inCORBA-compliant systems (OMG, 2004a), itis
possible tospecify whether anobject should continue toexistafteritsassociated
adapter hasstopped. Likewise, anadapter canbeconfigured togenerate object i-
dentifiers, ortolettheapplication provide one.Asafinalexample, anadapter can
beconfigured tooperate insingle-threaded ormultithreaded mode asweex-
plained above.
Asasideremark, notethatalthough inFig.10-5wehavespoken aboutob-
jects, wehavesaidnothing about whattheseobjects actually are.Inparticular, it
should bestressed thataspartoftheimplementation ofsuchanobject theserver
may(indirectly) access databases orcallspecial library routines. Theimplementa-
tiondetails arehidden fortheobject adapter whocommunicates onlywithaskele-
ton.Assuch.theactual implementation mayhavenothing todowithwhatwe
oftenseewithlanguage-level (i.e.,compile-time) objects. Forthisreason, adif-
ferent terminology isgenerally adopted. Aservant isthegeneral termforapiece
ofcodethatforms theimplementation ofanobject. Inthislight,aJavabeancan
beseenasnothing butjustanother kindofservant.
10.2.2 Example: TheIceRuntime System
Letustakealookathowdistributed objects arehandled inpractice. We
briefly consider theIcedistributed-object system, which hasbeenpartly de-
veloped inresponse totheintricacies ofcommercial object-based distributed sys-
tems(Henning, 2004). Inthissection, weconcentrate onthecoreofanIceobject
server anddeferotherpartsofthesystem tolatersections.
Anobject server inIceisnothing butanordinary process thatsimply starts
withinitializing theIceruntime system (RTS). Thebasisoftheruntime environ-
mentisformed bywhatiscalled acommunicator. Acommunicator isacompon-
entthatmanages anumber ofbasicresources, ofwhich themostimportant oneis
formed byapoolofthreads. Likewise, itwillhaveassociated dynamically allo-
cated memory, andsoon.Inaddition, acommunicator provides themeans for
configuring theenvironment. Forexample, itispossible tospecify maximum
message lengths, maximum invocation retries, andsoon.
Normally, anobject server would haveonlyasingle communicator. However,
when different applications needtobefullyseparated andprotected fromeach
other, aseparate communicator (with possibly adifferent configuration) canbe
created within thesameprocess. Attheveryleast,suchanapproach would sepa-
ratethedifferent thread pools sothatifoneapplication hasconsumed allits
threads, thenthiswould notaffect theotherapplication.SEC. 10.2 PROCESSES 455
Acommunicator canalsobeusedtocreate anobject adapter, suchasshown
inFig.10-6. Wenotethatthecodeissimplified andincomplete. More examples
anddetailed information onIcecanbefound inHenning andSpruiell (2005).
Figure 10-6. Example ofcreating anobject server inIce.
Inthisexample, westartwithcreating andinitializing theruntime environ-
ment. When thatisdone,anobject adapter iscreated. Inthiscase,itisinstructed
tolisten forincoming TCPconnections onport10000. Notethattheadapter is
created inthecontext ofthejustcreated communicator. Wearenowintheposi-
tiontocreate anobject andtosubsequently addthatobject totheadapter. Finally,
theadapter isactivated, meaning that,under thehood. athread isactivated that
willstartlistening forincoming requests.
Thiscodedoesnotyetshowmuch differentiation inactivation policies. Poli-
ciescanbechanged bymodifying theproperties ofanadapter. Onefamily ofpro-
perties isrelated tomaintaining anadapter-specific setofthreads thatareusedfor
handling incoming requests. Forexample, onecanspecify thatthereshould al-
waysbeonlyonethread, effectively serializing allaccesses toobjects thathave
beenadded totheadapter.
Again, notethatwehavenotspecified MyObject. Likebefore, thiscould bea
simple C++object. butalsoonethataccesses databases andotherexternal ser-
vicesthatjointly implement anobject. Byregistering MyObject withanadapter,
suchimplementation details arecompletely hidden fromclients, whonowbelieve
thattheyareinvoking aremote object.
Intheexample above, anobject iscreated aspartoftheapplication, after
which itisadded toanadapter. Effectively, thismeans thatanadapter mayneed
tosupport many objects atthesame time,leading topotential scalability prob-
lems. Analternative solution istodynamically loadobjects intomemory when
theyareneeded. Todothis,Iceprovides support forspecial objects known as
locators. Alocator iscalled whentheadapter receives anincoming request foran456 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
object thathasnotbeenexplicitly added. Inthatcase,therequest isforwarded to
thelocator, whose jobistofurther handle therequest.
Tomake matters moreconcrete, suppose alocator ishanded arequest foran
object ofwhich thelocator knows thatitsstateisstored inarelational database
system. Ofcourse, thereisnomagic here:thelocator hasbeenprogrammed expli-
citlytohandle suchrequests. Inthiscase,theobject's identifier maycorrespond
tothekeyofarecord inwhich thatstateisstored. Thelocator willthensimply do
alookup onthatkey,fetchthestate,andwillthenbeabletofurther process the
request.
There canbemore thanonelocator added toanadapter. Inthatcase,the
adapter would keeptrackofwhich object identifiers would belong tothesame
locator. Using multiple locators allows supporting many objects byasingle
adapter. Ofcourse, objects (orrather theirstate) would needtobeloaded atrun-
time,butthisdynamic behavior would possibly make theserver itselfrelatively
simple.
10.3COMMUNICATION
Wenowdrawourattention tothewaycommunication ishandled inobject-
based distributed systems. Notsurprisingly, these systems generally offerthe
means foraremote client toinvoke anobject. Thismechanism islargely based on
remote procedure calls(RPCs), which wediscussed extensively inChap. 4.How-
ever,before thiscanhappen, therearenumerous issues thatneedtobedealtwith.
10.3.1BindingaClienttoanObject
Aninteresting difference between traditional RPCsystems andsystems sup-
porting distributed objects isthatthelattergenerally provides systemwide object
references. Suchobject references canbefreely passed between processes ondif-
ferent machines, forexample asparameters tomethod invocations. Byhiding the
actual implementation ofanobject reference, thatis.making itopaque, and
perhaps evenusing itastheonlywaytoreference _objects, distribution trans-
parency isenhanced compared totraditional RPCs.
When aprocess holds anobject reference, itmustfirstbindtothereferenced
object before invoking anyofitsmethods. Binding results inaproxy being placed
intheprocess's address space, implementing aninterface containing themethods
theprocess caninvoke. Inmany cases, binding isdoneautomatically. When the
underlying system isgiven anobject reference, itneeds awaytolocate theserver
thatmanages theactual object, andplaceaproxy intheclient's address space.
Withimplicitbinding, theclient isoffered asimple mechanism thatallows it
todirectly invoke methods usingonlyareference toanobject. Forexample, C++SEC. 10.3 COMMUNICATION 457
allows overloading theunary member selection operator ("-7") permitting usto
introduce object references asiftheywereordinary pointers asshown inFig.10-
7(a).Withimplicit binding, theclient istransparently bound totheobject atthe
moment thereference isresolved totheactual object. Incontrast, withexplicit
binding. theclient should firstcallaspecial function tobindtotheobject before
itcanactually invoke itsmethods. Explicit binding generally returns apointer toa
proxy thatisthenbecome locally available, asshown inFig.10-7(b).
Figure 10-7. (a)Anexample withimplicit binding using onlyglobal references.
(b)Anexample withexplicit binding using global andlocalreferences.
Implementation ofObject References
Itisclearthatanobject reference mustcontain enough information toallow a
client tobindtoanobject. Asimple object reference would include thenetwork
address ofthemachine where theactual object resides, along withanendpoint
identifying theserver thatmanages theobject, plusanindication ofwhich object.
Notethatpartofthisinformation willbeprovided byanobject adapter. However,
thereareanumber ofdrawbacks tothisscheme.
First,iftheserver's machine crashes andtheserver isassigned adifferent end
pointafterrecovery, allobject references havebecome invalid. Thisproblem can
besolved asisdoneinDCE: havealocaldaemon permachine listen toawell-
known endpointandkeeptrackoftheserver-to-end pointassignments inanend
point table. When binding aclient toanobject, wefirstaskthedaemon forthe
server's current endpoint. Thisapproach requires thatweencode aserver IDinto
theobject reference thatcanbeusedasanindex intotheendpointtable. The
server, intum,isalways required toregister itselfwiththelocaldaemon.
However, encoding thenetwork address oftheserver's machine intoanobject
reference isnotalways agoodidea.Theproblem withthisapproach isthatthe
server cannever move toanother machine without invalidating allthereferences
totheobjects itmanages. Anobvious solution istoexpand theideaofalocal458 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
daemon maintaining anendpointtabletoalocation server thatkeeps trackofthe
machine where anobject's server iscurrently running. Anobject reference would
thencontain thenetwork address ofthelocation server, along withasystemwide
identifier fortheserver. Notethatthissolution comes closetoimplementing flat
namespaces aswediscussed inChap. 5.
What wehavetacitly assumed sofaristhattheclient andserver havesome-
howalready beenconfigured tousethesameprotocol stack. Notonlydoesthis
mean thattheyusethesametransport protocol, forexample, TCP; furthermore it
means thattheyusethesameprotocol formarshaling andunmarshaling parame-
ters.Theymustalsousethesameprotocol forsetting upaninitial connection,
handle errors andflowcontrol thesameway,andsoon.
Wecansafely dropthisassumption provided weaddmoreinformation inthe
object reference. Suchinformation mayinclude theidentification oftheprotocol
thatisusedtobindtoanobject andofthose thataresupported bytheobject's
server. Forexample, asingle server maysimultaneously support datacoming in
overaTCPconnection, aswellasincoming UDPdatagrams. Itisthentheclient's
responsibility togetaproxy implementation foratleastoneoftheprotocols iden-
tifiedintheobject reference.
Wecaneventakethisapproach onestepfurther, andinclude animplementa-
tionhandle intheobject reference, which refers toacomplete implementation of
aproxy thattheclient candynamically loadwhen binding totheobject. Forex-
ample, animplementation handle could taketheformofaURLpointing toan
archive file,suchasjtp:l/ftp.clientware.orglproxies!javaiproxy-v}.}a.zip. The
binding protocol would thenonlyneedtoprescribe thatsuchafileshould be
dynamically downloaded, unpacked, installed, andsubsequently instantiated. The
benefit ofthisapproach isthattheclient neednotworry about whether ithasan
implementation ofaspecific protocol available. Inaddition, itgives theobject
developer thefreedom todesign object-specific proxies. However, wedoneedto
takespecial security measures toensure theclient thatitcantrustthedownloaded
code.
10.3.2 Static versus Dynamic Remote Method Invocations
Afteraclient isbound toanobject, itcaninvoke theobject's methods through
theproxy. Sucharemote method invocation. orsimply RMI, isverysimilar to
anRPCwhen itcomes toissues suchasmarshaling andparameter passing. An
essential difference between anRMIandanRPCisthatRMIs generally support
systemwide object references asexplained above. Also,itisnotnecessary tohave
onlygeneral-purpose client-side andserver-side stubsavailable. Instead, wecan
moreeasily accommodate object-specific stubsaswealsoexplained.
Theusualwaytoprovide RMIsupport istospecify theobject's interfaces in
aninterface definition language, similar totheapproach followed withRPCs.SEC. 10.3 COMMUNICATION 459
Alternatively. wecanmake useofanobject-based language suchasJava,that
willhandle stubgeneration automatically. Thisapproach ofusingpredefined in-
terface definitions isgenerally referred toasstaticinvocation. Static invocations
require thattheinterfaces ofanobject areknown when theclient application is
being developed. Italsoimplies thatifinterfaces change, thentheclient applica-
tionmustberecompiled before itcanmakeuseofthenewinterfaces.
Asanalternative, method invocations canalsobedoneinamoredynamic
fashion. Inparticular, itissometimes convenient tobeabletocompose amethod
invocation atruntime, alsoreferred toasadynamic invocation. Theessential
difference withstatic invocation isthatanapplication selects atruntime which
method itwillinvoke ataremote object. Dynamic invocation generally takesa
formsuchas
invoke(object, method, inpuLparameters, outpuLparameters);
where object identifies thedistributed object, method isaparameter specifying
exactly which method should beinvoked, input-parameters isadatastructure that
holdsthevalues ofthatmethod's inputparameters, andoutput-parameters refers
toadatastructure where output values canbestored.
Forexample, consider appending aninteger inttoafileobject fobject, for
which theobject provides themethod append. Inthiscase,astaticinvocation
would taketheform
where theoperation id(append) returns anidentifier forthemethod append.
Toillustrate theusefulness ofdynamic invocations, consider anobject
browser thatisusedtoexamine setsofobjects. Assume thatthebrowser supports
remote object invocations. Suchabrowser iscapable ofbinding toadistributed
object andsubsequently presenting theobject's interface toitsuser.Theuser
could thenbeasked tochoose amethod andprovide values foritsparameters,
afterwhich thebrowser candotheactual invocation. Typically, suchanobject
browser should bedeveloped tosupport anypossible interface. Suchanapproach
requires thatinterfaces canbeinspected atruntime, andthatmethod invocations
canbedynamically constructed.
Another application ofdynamic invocations isabatch processing service to
which invocation requests canbehanded along withatimewhen theinvocation
should bedone. Theservice canbeimplemented byaqueue ofinvocation re-
quests, ordered bythetimethatinvocations aretobedone. Themainloopofthe
service would simply waituntilthenextinvocation isscheduled, remove there-
questfromthequeue, andcallinvoke asgiven above.460 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. ]0
10.3.3 Parameter Passing
Because mostRMIsystems support systemwide object references, passing pa-
rameters inmethod invocations isgenerally lessrestricted thaninthecaseof
RPCs. However. therearesome subtleties thatcanmake RMls trickier thanone
might initially expect. aswebriefly discuss inthefollowing pages.
Letusfirstconsider thesituation thatthereareonlydistributed objects. 'In
otherwords. allobjects inthesystem canbeaccessed fromremote machines. In
thatcase,wecanconsistently useobject references asparameters inmethod invo-
cations. References arepassed byvalue, andthuscopied fromonemachine tothe
other. When aprocess isgiven anobject reference astheresult ofamethod invo-
cation, itcansimply bindtotheobject referred towhenneeded later.
Unfortunately, using onlydistributed objects canbehighly inefficient, espe-
cially whenobjects aresmall, suchasintegers, orworse yet,Booleans. Eachinvo-
cation byaclientthatisnotcolocated inthesameserver astheobject, generates a
request between different address spaces or,evenworse; between different ma-
chines. Therefore, references toremote objects andthosetolocalobjects areoften
treated differently.
When invoking amethod withanobject reference asparameter, thatreference
iscopied andpassed asavalue parameter onlywhen itrefers toaremote object.
Inthiscase,theobject isliterally passed byreference. However, when therefer-
encerefers toalocalobject, thatisanobject inthesameaddress space asthecli-
ent,thereferred object iscopied asawhole andpassed along withtheinvocation.
Inotherwords, theobject ispassed byvalue.
These twosituations areillustrated inFig.10-8,which shows aclient program
running onmachine A,andaserver program onmachine C.Theclient hasarefer-
encetoalocalobject 01thatitusesasaparameter when calling theserver pro-
gramonmachine C.Inaddition, itholds areference toaremote object 02resid-
ingatmachine B,which isalsousedasaparameter. When calling theserver, a
copyof01ispassed totheserver onmachine C,along withonlyacopyofthe
reference to02.
Notethatwhether wearedealing withareference toalocalobject orarefer-
encetoaremote object canbehighly transparent, suchasinJava.InJava,thedis-
tinction isvisible onlybecause localobjects areessentially ofadifferent datatype
thanremote objects. Otherwise, bothtypesofreferences aretreated verymuch the
same [seealsoWollrath etal.(1996)]. Ontheotherhand, when using conven-
tional programming languages suchasC,areference toalocalobject canbeas
simple asapointer, which cannever beusedtorefertoaremote object.
Thesideeffect ofinvoking amethod withanobject reference asparameter is
thatwemaybecopying anobject. Obviously, hiding thisaspect isunacceptable,
sothatweareconsequently forced tomake anexplicit distinction between local
anddistributed objects. Clearly, thisdistinction notonlyviolates distribution tran-
sparency, butalsomakes itharder towritedistributed applications.Figure 10-8. Thesituation when passing anobject byreference orbyvalue.
10.3.4 Example: JavaRMI
InJava,distributed objects havebeenintegrated intothelanguage. Animpor-
tantgoalwastokeepasmuch ofthesemantics ofnondistributed objects aspos-
sible.Inotherwords, theJavalanguage developers haveaimed forahighdegree
ofdistribution transparency. However, asweshallsee,Java's developers have
alsodecided tomake distribution apparent where ahighdegree oftransparency
wassimply tooinefficient, difficult, orimpossible torealize.
TheJavaDistributed-Object Model
Javaalsoadopts remote objects astheonlyformofdistributed objects. Recall
thataremote object isadistributed object whose statealways resides onasingle
machine, butwhose interfaces canbemade available toremote processes. Inter-
facesareimplemented intheusualwaybymeans ofaproxy, which offers exactly
thesameinterfaces astheremote object. Aproxy itselfappears asalocalobject
intheclient's address space.
There areonlyafew,butsubtle andimportant, differences between remote
objects andlocalobjects. First,cloning localorremote objects aredifferent. Clon-
ingalocalobject 0results inanewobject ofthesametypeas0withexactly the
samestate.Cloning thusreturns anexactcopyoftheobject thatiscloned. These
semantics arehardtoapply toaremote object. Ifweweretomake anexactcopy
ofaremote object, wewould notonlyhavetoclonetheactual object atitsserver,
butalsotheproxy ateachclient thatiscurrently bound totheremote object. Clon-
ingaremote object istherefore anoperation thatcanbeexecuted onlybythe
server. Itresults inanexactcopyoftheactual object intheserver's address space.461 COMMUNICATION SEC. 10.3462 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Proxies oftheactual object arethusnotcloned. Ifaclient ataremote machine
wants access tothecloned object attheserver, itwillfirsthavetobindtothatob-
jectagain.
JavaRemoteObjectInvocation
Asthedistinction between localandremote objects ishardly visible atthe
language level,Javacanalsohidemostofthedifferences during aremote method
invocation. Forexample, anyprimitive orobject typecanbepassed asaparame-
tertoanRMI,provided onlythatthetypecanbemarshaled. InJavaterminology,
thismeans thatitmustbeserializable. Although, inprinciple, mostobjects can
beserialized, serialization isnotalways allowed orpossible. Typically, platform-
dependent objects suchasfiledescriptors andsockets, cannot beserialized.
Theonlydistinction madebetween localandremote objects during anRMIis
thatlocalobjects arepassed byvalue (including largeobjects suchasarrays),
whereas remote objects arepassed byreference. Inotherwords, alocalobject is
firstcopied afterwhich thecopyisusedasparameter value. Foraremote object, a
reference totheobject ispassed asparameter instead ofacopyoftheobject, as
wasalsoshown inFig.10-8.
InJavaRMI, areference toaremote object isessentially implemented aswe
explained inSec.10.3.3. Suchareference consists ofthenetwork address andend
pointoftheserver, aswellasalocalidentifier fortheactual object intheserver's
address space. Thatlocal identifier isusedonlybytheserver. Aswealso
explained, areference toaremote object alsoneeds toencode theprotocol stack
thatisusedbyaclient andtheserver tocommunicate. Tounderstand howsucha
stackisencoded inthecaseofJavaRMI,itisimportant torealize thateachobject
inJavaisaninstance ofaclass. Aclass, intum,contains animplementation of
oneormoreinterfaces.
Inessence, aremote object isbuiltfromtwodifferent classes. Oneclasscon-
tainsanimplementation ofserver-side code,which wecalltheserver class. This
classcontains animplementation ofthatpartoftheremote object thatwillberun-
ningonaserver. Inotherwords, itcontains thedescription oftheobject's state,as
wellasanimplementation ofthemethods thatoperate onthatstate. Theserver-
sidestub,thatis,theskeleton, isgenerated fromtheinterface specifications ofthe
object.
Theotherclasscontains animplementation oftheclient-side code, which we
calltheclient class. Thisclasscontains animplementation ofaproxy. Likethe
skeleton, thisclassisalsogenerated fromtheobject's interface specification. In
itssimplest form, theonlythingaproxy doesistoconvert eachmethod callintoa
message thatissenttotheserver-side implementation oftheremote object, and
convert areplymessage intotheresult ifamethod call.Foreachcall,itsetsupa
connection withtheserver, which issubsequently tomdown when thecallisfin-
ished. Forthispurpose, theproxy needs theserver's network address andendSEC. 10.3 COMMUNICATION 463
pointasmentioned above. Thisinformation, along withthelocalidentifier ofthe
object attheserver, isalways stored aspartofthestateofaproxy.
Consequently, aproxy hasalltheinformation itneeds toletaclient invoke
methods oftheremote object. InJava,proxies areserializable. Inotherwords, it
ispossible tomarshal aproxy andsenditasaseries ofbytes toanother process,
where itcanbeunmarshaled andusedtoinvoke methods ontheremote object. In
otherwords, aproxy canbeusedasareference toaremote object.
Thisapproach isconsistent withJava's wayofintegrating localanddistrib-
utedobjects. Recall thatinanRMI, alocalobject ispassed bymaking acopyof
it,while aremote object ispassed bymeans ofasystemwide object reference. A
proxy istreated asnothing elsebutalocalobject. Consequently, itispossible to
passaserializable proxy asparameter inanRMI.Thesideeffect isthatsucha
proxy canbeusedasareference totheremote object.
Inprinciple, when marshaling aproxy, itscomplete implementation, thatis,
allitsstateandcode, isconverted toaseries ofbytes. Marshaling thecodelike
thisisnotveryefficient andmayleadtoverylargereferences. Therefore, when
marshaling aproxy inJava, what actually happens isthatanimplementation
handle isgenerated, specifying precisely which classes areneeded toconstruct the
proxy. Possibly, someoftheseclasses firstneedtobedownloaded fromaremote
site.Theimplementation handle replaces themarshaled codeaspartofaremote-
object reference. Ineffect, references toremote objects inJavaareintheorderof
afewhundred bytes.
Thisapproach toreferencing remote objects ishighly flexible andisoneof
thedistinguishing features ofJavaRMI(Waldo, 1998). Inparticular, itallows for
object-specific solutions. Forexample, consider aremote object whose state
changes onlyonceinawhile. Wecantumsuchanobject intoatrulydistributed
object bycopying theentire statetoaclient atbinding time.Eachtimetheclient
invokes amethod, itoperates onthelocalcopy.Toensure consistency, eachinvo-
cation alsochecks whether thestateattheserver haschanged, inwhich casethe
localcopyisrefreshed. Likewise, methods thatmodify thestateareforwarded to
theserver. Thedeveloper oftheremote object willnowhavetoimplement only
thenecessary client-side code, andhaveitdynamically downloaded when thecli-
entbindstotheobject.
Being abletopassproxies asparameters works onlybecause eachprocess is
executing thesameJavavirtual machine. Inotherwords, eachprocess isrunning
inthesameexecution environment. Amarshaled proxy issimply unmarshaled at
thereceiving side,afterwhich itscodecanbeexecuted. Incontrast, inDCEfor
example, passing stubsisoutofthequestion, asdifferent processes mayberun-
ninginexecution environments thatdiffer withrespect tolanguage, operating sys-
tem,andhardware. Instead, aDCEprocess firstneeds to(dynamically) linkina
locally-available stubthathasbeenpreviously compiled specifically fortheproc-
ess'sexecution environment. Bypassing areference toastubasparameter inan
RPC,itispossible torefertoobjects across process boundaries.464 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
10.3.5 Object-Based Messaging
Although RMIisthepreferred wayofhandling communication inobject-
based distributed systems, messaging hasalsofound itswayasanimportant alter-
native. There arevarious object-based messaging systems available, and,ascan
beexpected, offerverymuch thesamefunctionality. Inthissection wewilltakea
closer lookatCORBA messaging, partly because italsoprovides aninteresting
wayofcombining method invocation andmessage-oriented communication.
CORBA isawell-known specification fordistributed systems. Overtheyears,
several implementations havecometoexistence, although itremains tobeseento
whatextent CORBA itselfwilleverbecome trulypopular. However, independent
ofpopularity, theCORBA specifications arecomprehensive (which tomany also
means theyareverycomplex). Recognizing thepopularity ofmessaging systems,
CORBA wasquick toinclude aspecification ofamessaging service.
Whatmakes messaging inCORBA different fromothersystems isitsinherent
object-based approach tocommunication. Inparticular, thedesigners ofthemes-
saging service needed toretain themodel thatallcommunication takesplace by
invoking anobject. Inthecaseofmessaging, thisdesign constraint resulted intwo
forms ofasynchronous method invocations (inaddition tootherforms thatwere
provided byCORBA aswell).
Anasynchronous method invocation isanalogous toanasynchronous RPC:
thecaller continues afterinitiating theinvocation without waiting foraresult. In
CORBA's callback model, aclient provides anobject thatimplements aninter-
facecontaining callback methods. These methods canbecalled bytheunderlying
communication system topasstheresult ofanasynchronous invocation. Anim-
portant design issueisthatasynchronous method invocations donotaffect theori-
ginalimplementation ofanobject. Inotherwords, itistheclient's responsibility
totransform theoriginal synchronous invocation intoanasynchronous one;the
server ispresented withanormal (synchronous) invocation request.
Constructing anasynchronous invocation isdoneintwosteps. First,theorigi-
nalinterface asimplemented bytheobject isreplaced bytwonewinterfaces that
aretobeimplemented byclient-side software only. Oneinterface contains the
specification ofmethods thattheclient cancall.None ofthesemethods returns a
value orhasanyoutput parameter. Thesecond interface isthecallback interface.
Foreachoperation intheoriginal interface, itcontains amethod thatwillbecall-
edbytheclient's runtime system topasstheresults oftheassociated method as
called bytheclient.
Asanexample, consider anobject implementing asimple interface withjust
onemethod:
intadd(in inti,inintj,outintk);
Assume thatthismethod takestwononnegative integers iandjandreturns i+j
asoutput parameter k.Theoperation isassumed toreturn -1iftheoperation didSEC. 10.3 COMMUNICATION 465
notcomplete successfully. Transforming theoriginal (synchronous) method invo-
cation intoanasynchronous onewithcallbacks isachieved byfirstgenerating the
following pairofmethod specifications (forourpurposes, wechoose convenient
names instead offollowing thestrictrulesasspecified inOMG (2004a):
Ineffect, alloutput parameters fromtheoriginal method specification arere-
moved fromthemethod thatistobecalled bytheclient, andreturned asinputpa-
rameters ofthecallback operations. Likewise, iftheoriginal method specified a
return value, thatvalueispassed asaninputparameter tothecallback operation.
Thesecond stepconsists ofcompiling thegenerated interfaces. Asaresult,
theclient isoffered astubthatallows ittoasynchronously invoke sendcb_add.
However, theclient willneedtoprovide animplementation forthecallback inter-
face,inourexample containing themethod replycb_add. Thislastmethod iscall-
edbytheclient's localruntime system (RTS), resulting inanupcall totheclient
application. Notethatthesechanges donotaffect theserver-side implementation
oftheobject. Using thisexample, thecallback model issummarized inFig.10-9.
Figure 10-9. CORBA's callback model forasynchronous method invocation.
Asanalternative tocallbacks, CORBA provides apollingmodel.Inthis
model, theclient isoffered acollection ofoperations topollitslocalRTSfor
incoming results. Asinthecallback model, theclient isresponsible fortransform-
ingtheoriginal synchronous method invocations intoasynchronous ones.Again,
mostoftheworkcanbedonebyautomatically deriving theappropriate method
specifications fromtheoriginal interface asimplemented bytheobject.
Returning toourexample, themethod addwillleadtothefollowing twogen-
erated method specifications (again, weconveniently adopt ourownnaming con-
ventions):466 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Themostimportant difference between thepolling andcallback models isthatthe
method replypolLadd willhavetobeimplemented bytheclient's RTS. Thisim-
plementation canbeautomatically generated frominterface specifications, justas
theclient-side stubisautomatically generated asweexplained forRPCs. Thepol-
lingmodel issummarized inFig.10-10. Again, notice thattheimplementation of
theobject asitappears attheserver's sidedoesnothavetobechanged.
Figure 10-10. CORBA's polling model forasynchronous method invocation.
Whatismissing fromthemodels described sofaristhatthemessages sentbe-
tween aclient andaserver, including theresponse toanasynchronous invocation,
arestored bytheunderlying system incasetheclient orserver isnotyetrunning.
Fortunately, mostoftheissues concerning- suchpersistent communication donot
affect theasynchronous invocation model discussed sofar.What isneeded isto
setupacollection ofmessage servers thatwillallow messages (betheyinvoca-
tionrequests orresponses), tobetemporarily stored untiltheirdelivery cantake
place.
Tothisend,theCOREA specifications alsoinclude interface definitions for
whatarecalled routers, which areanalogous tothemessage routers wediscussed
inChap. 4,andwhich canbeimplemented, forexample, usingIBM's WebSphere
queue managers.
Likewise, JavahasitsownJavaMessaging Service (JMS) which isagain
verysimilar towhatwehavediscussed before [seeSunMicrosystems (2004a)].
Wewillreturn tomessaging moreextensively inChap. 13when wediscuss the
publish/subscribe paradigm.
10.4NAMING
Theinteresting aspect ofnaming inobject-based distributed systems evolves
around thewaythatobject references aresupported. Wealready described these
object references inthecaseofJava.where theyeffectively correspond toport-
ableproxy implementations. However, thisalanguage-dependent wayofbeing
abletorefertoremote objects. Again taking CORBA asanexample, letusseeSEC. 10.4 NAMING 467
howbasic naming canalsobeprovided inalanguage andplatform-independent
way.Wealsodiscuss acompletely different scheme, which isusedintheGlobe
distributed system.
10.4.1 CORBA Object References
Fundamental toCORBA isthewayitsobjects arereferenced. When aclient
holds anobject reference, itcaninvoke themethods implemented bytherefer-
enced object. Itisimportant todistinguish theobject reference thataclient proc-
essusestoinvoke amethod, andtheoneimplemented bytheunderlying RTS.
Aprocess (beitclient orserver) canuseonlyalanguage-specific implemen-
tation ofanobject reference. Inmostcases, thistakestheformofapointer toa
localrepresentation oftheobject. Thatreference cannot bepassed fromprocess A
toprocess B,asithasmeaning onlywithin theaddress space ofprocess A.
Instead, process Awillfirsthavetomarshal thepointer intoaprocess-independent
representation. Theoperation todosoisprovided byitsRTS.Oncemarshaled,
thereference canbepassed toprocess B,which canunmarshal itagain. Notethat
processes AandBmaybeexecuting programs written indifferent languages.
Incontrast, theunderlying RTSwillhaveitsownlanguage-independent
representation ofanobject reference. Thisrepresentation mayevendiffer from
themarshaled version ithands overtoprocesses thatwanttoexchange arefer-
enee.Theimportant thingisthatwhen aprocess refers toanobject, itsunderlying
RTSisimplicitly passed enough information toknow which object isactually
being referenced. Suchinformation isnormally passed bytheclient andserver-
sidestubsthataregenerated fromtheinterface specifications ofanobject.
Oneoftheproblems thatearlyversions ofCORBA hadwasthateachimple-
mentation could decide onhowitrepresented anobject reference. Consequently,
ifprocess Awanted topassareference toprocess Basdescribed above, this
would generally succeed onlyifbothprocesses wereusing thesame CORBA
implementation. Otherwise, themarshaled version ofthereference heldbyproc-
essAwould bemeaningless totheRTSusedbyprocess B.
Current CORBA systems allsupport thesamelanguage-independent repres-
entation ofanobject reference, which iscalled anInteroperable Object Refer-
enceorlOR. Whether ornotaCORBA implementation usesIORsinternally is
notallthatimportant. However, when passing anobject reference between two
different CORBA systems, itispassed asanlOR.AnlORcontains alltheinfor-
mation needed toidentify anobject. Thegeneral layout ofanlORisshown in
Fig.10-11, along withspecific information forthecommunication protocol used
inCORBA.
EachlORstartswitharepository identifier. Thisidentifier isassigned toan
interface sothatitcanbestored andlooked upinaninterface repository. Itisused
toretrieve information onaninterface atruntime, andcanassist in,forexample,468 DISTRIBUTED OBJECT-BASED SYSTEMSCHAP. 10
Figure 10-11. Theorganization ofanlORwithspecific information forIIOP.
typechecking ordynamically constructing aninvocation. Notethatifthisidenti-
fieristobeuseful, boththeclient andserver musthaveaccess tothesameinter-
facerepository, oratleastusethesameidentifier toidentify interfaces.
Themostimportant partofeachlORisformed bywhatarecalled tagged
profiles. Eachsuchprofile contains thecomplete information toinvoke anob-
ject.Iftheobject server supports several protocols, information oneachprotocol
canbeincluded inaseparate tagged profile. CORBA usedtheInternet Inter-
ORB Protocol (IIOP) forcommunication between nodes. (AnORB orObject
Request Broker isthename usedbyCORBA fortheirobject-based runtime sys-
tem.)napisessentially adedicated protocol forsupported remote method invo-
cations. Details ontheprofile usedfornaparealsoshown inFig.10-11.
Thenapprofile isidentified byaProfileID fieldinthetagged profile. Its
bodyconsists offivefields. TheIlOP version fieldidentifies theversion ofnap
thatisusedinthisprofile.
TheHost fieldisastring identifying exactly onwhich hosttheobject is
located. Thehostcanbespecified either bymeans ofacomplete DNSdomain
name (suchassoling.cs.vu.nl), orbyusing thestring representation ofthathost's
IFaddress, suchas130.37.24.11.
ThePortfieldcontains theportnumber towhich theobject's server islisten-
ingforincoming requests.
TheObject keyfieldcontains server-specific information fordemultiplexing
incoming requests totheappropriate object. Forexample, anobject identifier gen-
erated byaCORBA object adapter willgenerally bepartofsuchanobject key.
Also,thiskeywillidentify thespecific adapter.
Finally, thereisaComponents fieldthatoptionally contains moreinformation
needed forproperly invoking thereferenced object. Forexample, thisfieldmay
contain security information indicating howthereference should behandled, or
whattodointhecasethereferenced server is(temporarily) unavailable.SEC. lOA NAMING 469
10.4.2 Globe Object References
Letusnowtakealookatadifferent wayofreferencing objects. InGlobe,
eachdistributed shared object isassigned aglobally unique object identifier
(OlD), which isa256-bit string. AGlobe aIDisatrueidentifier asdefined in
Chap. 5.Inotherwords, aGlobe OlDrefers toatmostonedistributed shared ob-
ject;itisnever reused foranother object; andeachobject hasatmostoneaID.
Globe aIDs canbeusedonlyforcomparing object references. Forexample,
suppose processes Aand.Bareeachbound toadistributed shared object. Each
process canrequest theOlDoftheobject theyarebound to.Ifandonlyifthetwo
aIDsarethesame, thenAandBareconsidered tobebound tothesameobject.
Unlike CORBA references, Globe aIDscannot beusedtodirectly contact an
object. Instead, tolocate anobject, itisnecessary tolookupacontact address for
thatobject inalocation service. Thisservice returns acontact address, which is
comparable tothelocation-dependent object references asusedinCORBA and
otherdistributed systems. Although Globe usesitsownspecific location service,
inprinciple anyofthelocation services discussed inChap. 5would do.
Ignoring someminor details, acontact address hastwoparts. Thefirstoneis
anaddress identifier bywhich thelocation service canidentify theproper leaf
nodetowhich insert ordelete operations fortheassociated contact address areto
forwarded. Recall thatbecause contact addresses arelocation dependent, itisim-
portant toinsert anddelete themstarting atanappropriate leafnode.
'Thesecond partconsists ofactual address information, butthisinformation is
completely opaque tothelocation service. Tothelocation service, anaddress is
justanarray ofbytes thatcanequally stand foranactual network address, a
marshaled interface pointer, orevenacomplete marshaled proxy.
Twokinds ofaddresses arecurrently supported inGlobe. Astacked address
represents alayered protocol suite, where eachlayerisrepresented bythethree-
fieldrecord shown inFig.10-12.
Figure 10-12. Therepresentation ofaprotocol layerinastacked contact address.
TheProtocol identifier isaconstant representing aknown protocol. Typical
protocol identifiers include TCP, UDP, andIP.TheProtocol address fieldcon-
tainsaprotocol-specific address, suchasTCPportnumber, oranIPv4network
address. Finally, anImplementation handle canbeoptionally provided toindicate470 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
where adefault implementation fortheprotocol canbefound. Typically, anim-
plementation handle isrepresented asaURL.
Thesecond typeofcontact address isaninstance address, which consists of
thetwofields shown inFig.10-13. Again, theaddress contains animplementa-
tionhandle, which isnothing butareference toafileinaclassrepository where
animplementation ofalocalobject canbefound. Thatlocalobject should be
loaded bytheprocess thatiscurrently binding totheobject.
Figure 10-13. Therepresentation ofaninstance contact address.
Loading follows astandard protocol, similar toclassloading inJava.Afterthe
implementation hasbeenloaded andthelocalobject created, initialization takes
placebypassing theinitialization string totheobject. Atthatpoint, theobject i-
dentifier hasbeencompleted resolved.
Notethedifference inobject referencing between CORBA andGlobe, adif-
ference which occurs frequently indistributed object-based systems. Where
CORBA references contain exact information where tocontact anobject, Globe
references require anadditional lookup steptoretrieve thatinformation. Thisdis-
tinction alsoappears insystems suchasIce,where theCORBA equivalent is
referred toasadirect reference, andtheGlobe equivalent asanindirect reference
(Henning andSpruiell, 2005).
10.5SYNCHRONIZATION
There areonlyafewissues regarding synchronization indistributed systems
thatarespecific todealing withdistributed objects. Inparticular, thefactthat
implementation details arehidden behind interfaces maycause problems: when a
process invokes a(remote) object, ithasnoknowledge whether thatinvocation
willleadtoinvoking other objects. Asaconsequence, ifanobject isprotected
against concurrent accesses, wemayhaveacascading setoflocksthattheinvok-
ingprocess isunaware of,assketched inFig.10-14(a).
Incontrast, when dealing withdataresources suchasfilesordatabase tables
thatareprotected bylocks, thepattern forthecontrol flowisactually visible to
theprocess using thoseresources, asshown inFig.10-14(b). Asaconsequence,
theprocess canalsoexertmorecontrol atruntime whenthings gowrong, suchas
giving uplocks when itbelieves adeadlock hasoccurred. Notethattransaction
processing systems generally follow thepattern shown inFig.10-14(b).SEC. 10.5 SYNCHRONIZATION 471
Figure 10-14. Differences incontrol flowforlocking objects
Inobject-based distributed systems itistherefore important toknow where
andwhen synchronization takesplace. Anobvious location forsynchronization is
attheobject server. Ifmultiple invocation requests forthesameobject arrive, the
server candecide toserialize thoserequests (andpossibly keepalockonanobject
whenitneeds todoaremote invocation itself).
However, letting theobject server maintain locks complicates matters inthe
casethatinvoking clients crash. Forthisreason, locking canalsobedoneatthe
client side,anapproach thathasbeenadopted inJava.Unfortunately, thisscheme
hasitsowndrawbacks.
Aswementioned before, thedifference between localandremote objects in
Javaisoften difficult tomake. Matters become morecomplicated when objects
areprotected bydeclaring itsmethods tobesynchronized. Iftwoprocesses sim-
ultaneously callasynchronized method, onlyoneoftheprocesses willproceed
while theotherwillbeblocked. Inthisway,wecanensure thataccess toanob-
ject's internal dataiscompletely serialized. Aprocess canalsobeblocked inside
anobject, waiting forsomecondition tobecome true.
.Logically, blocking inaremote object issimple. Suppose thatclient Acallsa
synchronized method ofaremote object. Tomake access toremote objects look
always exactly thesameastolocalobjects, itwould benecessary toblock Ain
theclient-side stubthatimplements theobject's interface andtowhich Ahas
direct access. Likewise, another client onadifferent machine would needtobe
blocked locally aswellbefore itsrequest canbesenttotheserver. Theconse-
quence isthatweneedtosynchronize different clients atdifferent machines. As
wediscussed inChap. 6,distributed synchronization canbefairlycomplex.
Analternative approach would betoallow blocking onlyattheserver. In
principle, thisworks fine,butproblems arisewhenaclient crashes while itsinvo-
cation isbeing handled bytheserver. Aswediscussed inChap. 8,wemayrequire
relatively sophisticated protocols tohandle thissituation, andwhich thatmaysig-
nificantly affect theoverall performance ofremote method invocations.472 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Therefore, thedesigners ofJavaRMIhavechosen torestrict blocking onre-
moteobjects onlytotheproxies (Wollrath etaI.,1996). Thismeans thatthreads
inthesameprocess willbeprevented fromconcurrently accessing thesamere-
mote object, butthreads indifferent processes willnot.Obviously, these syn-
chronization semantics aretricky: atthesyntactic level(i.e.,when reading source
code) wemayseeanice,clean design. Onlywhen thedistributed application is
actually executed, unanticipated behavior maybeobserved thatshould havebeen
dealtwithatdesign time.Hereweseeaclearexample where striving fordistribu-
tiontransparency isnotthewaytogo.
10.6CONSISTENCY ANDREPLICATION
Many object-based distributed systems follow atraditional approach toward
replicated objects, effectively treating themascontainers ofdatawiththeirown
special operations. Asaresult, when weconsider howreplication ishandled in
systems supporting Javabeans, orCORBA-compliant distributed systems, thereis
notreally thatmuchnewtoreport otherthanwhatwehavediscussed inChap. 7.
Forthisreason, wefocus onafewparticular topics regarding consistency and
replication thataremoreprofound inobject-based distributed systems thanothers.
Wewillfirstconsider consistency andmovetoreplicated invocations.
10.6.1EntryConsistency
Aswementioned inChap. 7,data-centric consistency fordistributed objects
comes naturally intheformofentryconsistency. Recall thatinthiscase,thegoal
istogroup operations onshared datausing synchronization variables (e.g.,inthe
formoflocks). Asobjects naturally combine dataandtheoperations onthatdata,
locking objects during aninvocation serializes access andkeeps themconsistent.
Although conceptually associating alockwithanobject issimple, itdoesnot
necessarily 'provide aproper solution when anobject isreplicated. There aretwo
issues thatneedtobesolved forimplementing entryconsistency. Thefirstoneis
thatweneedameans toprevent concurrent execution of'multiple invocations on
thesameobject. Inotherwords, when anymethod ofanobject isbeing executed,
noothermethods maybeexecuted. Thisrequirement ensures thataccess tothe
internal dataofanobject isindeed serialized. Simply usinglocallocking mechan-
ismswillensure thisserialization.
Thesecond issueisthatinthecaseofareplicated object, weneedtoensure
thatallchanges tothereplicated stateoftheobject arethesame. Inotherwords,
weneedtomake surethatnotwoindependent method invocations takeplace on
different replicas atthesametime.Thisrequirement implies thatweneedtoorder
invocations suchthateachreplica seesallinvocations inthesame order. ThisSEC. 10.6 CONSISTENCY AND REPLICATION 473
requirement cangenerally bemetinoneoftwoways: (1)using aprimary-based
approach or(2)usingtotally-ordered multicast tothereplicas.
Inmany cases, designing replicated objects isdonebyfirstdesigning asingle
object, possibly protecting itagainst concurrent access through locallocking, and
subsequently replicating it.Ifweweretouseaprimary-based scheme, thenaddi-
tional effort fromtheapplication developer isneeded toserialize object invoca-
tions.Therefore, itisoftenconvenient toassume thattheunderlying middleware
supports totally-ordered multicasting, asthiswould notrequire anychanges atthe
clients, norwould itrequire additional programming effort from application
developers. Ofcourse, howthetotally ordered multicasting isrealized bythe
middleware should betransparent. Foralltheapplication mayknow itsimple-
mentation mayuseaprimary-based scheme, butitcould equally wellbebased on
Lamport clocks.
However, eveniftheunderlying middle wareprovides totally-ordered multi-
casting, moremaybeneeded toguarantee orderly object invocation. Theproblem
isoneofgranularity: although allreplicas ofanobject server mayreceive invoca-
tionrequests inthesameorder, weneedtoensure thatallthreads inthoseservers
process those requests inthecorrect order aswell.Theproblem issketched in
Fig.10-15.
Figure to-IS. Deterministic thread scheduling forreplicated object servers.
Multithreaded (object) servers simply pickupanincoming request, passiton
toanavailable thread, andwaitforthenextrequest tocome in.Theserver's
thread scheduler subsequently allocates theCPUtorunnable threads. Ofcourse, if
themiddleware hasdoneitsbesttoprovide atotalordering forrequest delivery,
thethread schedulers should operate inadeterministic fashion inordernottomix
theordering ofmethod invocations onthesameobject. Inotherwords, Ifthreads474 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
rlandrTfrom Fig.10-15 handle thesame incoming (replicated) invocation re-
quest, theyshould bothbescheduled before r~andr~,respectively.
Ofcourse, simply scheduling allthreads deterministically isnotnecessary. In
principle, ifwealready have totally-ordered request delivery, weneed onlyto
ensure thatallrequests forthesamereplicated object arehandled intheorder they
weredelivered. Such anapproach would allow invocations fordifferent objects to
beprocessed concurrently, andwithout further restrictions from thethread sched-
uler.Unfortunately, onlyfewsystems existthatsupport suchconcurrency.
Oneapproach, described inBasile etaI.(2002), ensures thatthreads sharing
thesame (local) lockarescheduled inthesame order onevery replica. Atthe
basics liesaprimary-based scheme inwhich oneofthereplica servers takes the
leadindetermining, foraspecific lock,which thread goesfirst.Animprovement
thatavoids frequent communication between servers isdescribed inBasile etal.
(2003). Notethatthreads thatdonotshare alockcanthusoperate concurrently on
eachserver.
Onedrawback ofthisscheme isthatitoperates atthelevel oftheunderlying
operating system, meaning thatevery lockneeds tobemanaged. Byproviding ap-
plication-level information, ahugeimprovement inperformance canbemade by
identifying onlythose locks thatareneeded forserializing access toreplicated ob-
jects(Taiani etaI.,2005). Wereturn tothese issues when wediscuss faulttoler-
anceforJava.
Replication Frameworks
Aninteresting aspect ofmost distributed object-based systems isthatby
nature oftheobject technology itisoften possible tomake aclean separation be-
tween devising functionality andhandling extra-functional issues suchasreplica-
tion. Asweexplained inChap. 2,apowerful mechanism toaccomplish this
separation isformed byinterceptors.
Babaoglu etal.(2004) describe aframework inwhich theyuseinterceptors to
replicate Javabeans forJ2EE servers. Theideaisrelatively simple: invocations to
objects areintercepted atthree different points, asalsoshown inFig.10-16:
1.Attheclient sidejustbefore theinvocation ispassed tothestub.
2.Inside theclient's stub,where theinterception forms partofthe
replication algorithm.
3.Attheserver side,justbefore theobject isabout tobeinvoked.
Thefirstinterception isneeded when itturns outthatthecaller isreplicated.
Inthatcase, synchronization withtheother callers maybeneeded aswemaybe
dealing withareplicated invocation asdiscussed before.SEC. 10.6 CONSISTENCY AND REPLICATION 475
Figure 10-16. Ageneral framework forseparating replication algorithms from
objects inanEJBenvironment.
Onceithasbeendecided thattheinvocation canbecarried out,theintercep-
torintheclient-side stubcantakedecisions onwhere tobeforward therequest to,
orpossibly implement afail-over mechanism whenareplica cannot bereached.
Finally, theserver-side interceptor handles theinvocation. Infact,thisinter-
ceptor issplitintotwo.Atthefirstpoint, justaftertherequest hascomeinandbe-
foreitishanded overtoanadapter, thereplication algorithm getscontrol. Itcan
thenanalyze forwhom therequest isintended allowing ittoactivate, ifnecessary,
anyreplication objects thatitneeds tocarryoutthereplication. Thesecond point
isjustbefore theinvocation, allowing thereplication algorithm to,forexample,
getandsetattribute values ofthereplicated object.
Theinteresting aspect isthattheframework canbesetupindependent ofany
replication algorithm, thusleading toacomplete separation ofobject functionality
andreplication ofobjects.
10.6.2Replicated Invocations
Another problem thatneeds tobesolved isthatofreplicated invocations.
Consider anobject Acalling another object Basshown inFig.10-17. Object Bis
assumed tocallyetanother object C.IfBisreplicated, eachreplica ofBwill,in
principle, callCindependently. Theproblem isthatCisnowcalled multiple
times instead ofonlyonce. Ifthecalled method onCresults inthetransfer of
$100,000, thenclearly, someone isgoing tocomplain sooner orlater.
There arenotmany general-purpose solutions tosolve theproblem ofrepli-
cated invocations. Onesolution istosimply forbid it(Maassen etaI.,2001),
which makes sense when performance isatstake. However, whenreplicating for
faulttolerance, thefollowing solution proposed byMazouni etale(1995) maybe
deployed. Their solution isindependent ofthereplication policy, thatis,theexact
details ofhowreplicas arekeptconsistent. Theessence istoprovide areplica-
tion-aware communication layerontopofwhich (replicated) objects execute.
When areplicated object Binvokes another replicated object C,theinvocation476 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
Figure 10-17. Theproblem ofreplicated method invocations.
request isfirstassigned thesame, unique identifier byeachreplica ofB.Atthat
point, acoordinator ofthereplicas ofBforwards itsrequest toallthereplicas of
object C,while theotherreplicas ofBholdbacktheircopyoftheinvocation re-
quest, asshown inFig.lO-18(a). Theresult isthatonlyasingle request isfor-
warded toeachreplica ofC.
Figure 10-18. (a)Forwarding aninvocation request fromareplicated object to
another replicated object. (b)Returning areplyfromonereplicated object toan-
other.
Thesamemechanism isusedtoensure thatonlyasingle replymessage isre-
turned tothereplicas ofB.Thissituation isshown inFig.lO-18(b). AcoordinatorSEC. 10.6 CONSISTENCY AND REPLICATION 477
ofthereplicas ofCnotices itisdealing withareplicated reply message thathas
beengenerated byeachreplica ofC.However, onlythecoordinator forwards that
reply tothereplicas ofobject B,while theother replicas ofCholdbacktheircopy
ofthereply message.
When areplica ofBreceives areply message foraninvocation request ithad
either forwarded toCorheldbackbecause itwasnotthecoordinator, thereply is
thenhanded totheactual object.
Inessence, thescheme justdescribed isbased onusing multicast communica-
tion,butinpreventing thatthesame message ismulticast bydifferent replicas. As
such, itisessentially asender-based scheme. Analternative solution istoleta
receiving replica detect multiple copies ofincoming messages belonging tothe
same invocation, andtopassonlyonecopytoitsassociated object. Details ofthis
scheme areleftasanexercise.
10.7FAULT TOLERANCE
Likereplication, faulttolerance inmostdistributed object-based systems use
thesame mechanisms asinother distributed systems, following theprinciples we
discussed inChap. 8.However, when itcomes tostandardization, CORBA argu-
ablyprovides themostcomprehensive specification.
10.7.1 Example: Fault-Tolerant CORBA
Thebasic approach fordealing withfailures inCORBA istoreplicate objects
intoobject groups. Such agroup consists ofoneormore identical copies ofthe
same object. However, anobject group canbereferenced asifitwereasingle ob-
ject.Agroup offers thesame interface asthereplicas itcontains. Inother words,
replication istransparent toclients. Different replication strategies aresupported,
including primary-backup replication, active replication, andquorum-based repli-
cation. These strategies have allbeen discussed inChap. 7.There arevarious
other properties associated withobject groups, thedetails ofwhich canbefound
inOMO (2004a).
Toprovide replication andfailure transparency asmuch aspossible, object
groups should notbedistinguishable fromnormal CORBA objects, unless anap-
plication prefers otherwise. Animportant issue, inthisrespect, ishowobject
groups arereferenced. Theapproach followed istouseaspecial kindoflOR,
called anInteroperable Object Group Reference (IOGR). Thekeydifference
withanormal lORisthatanIOOR contains multiple references todifferent ob-
jects, notably replicas inthesame object group. Incontrast, anlORmayalsocon-
tainmultiple references, butallofthem willrefer tothesameobject, although
possibly using adifferent access protocol.Whenever aclient passes anIOGR toitsruntime system (RTS), thatRTS
attempts tobindtooneofthereferenced replicas. InthecaseoflIOP, theRTS
maypossibly useadditional information itfindsinoneoftheIIOPprofiles ofthe
lOGR. Suchinformation canbestored intheComponents fieldwediscussed pre-
viously. Forexample, aspecific lIOPprofile mayrefertotheprimary orabackup
ofanobject group, asshown inFig.10-19, bymeans oftheseparate tags
TAGYRIMARYand TAGJ3ACKUP, respectively.
Figure 10-19. Apossible organization ofanIOGR foranobject group having a
primary andbackups.
Ifbinding tooneofthereplicas fails,theclient RTSmaycontinue byattempt-
ingtobindtoanother replica, thereby following anypolicy fornextselecting a
replica thatitsuitstobest.Totheclient. thebinding procedure iscompletely tran-
sparent; itappears asiftheclient isbinding toaregular CORBA object.
AnExample Architecture
Tosupport object groups andtohandle additional failure management, itis
necessary toaddcomponents toCORBA. Onepossible architecture ofafault-
tolerant version ofCORBA isshown inFig.10-20. Thisarchitecture isderived
fromtheEternal system (Moser etal.,1998: andNarasimhan etal.,2000), which
provides afaulttolerance infrastructure constructed ontopoftheTotem reliable
group communication system (Moser etal.,1996).
There areseveral components thatplayanimportant roleinthisarchitecture.
Byfarthemostimportant oneisthereplication manager, which isresponsible
forcreating andmanaging agroup ofreplicated objects. Inprinciple, thereisonly
onereplication manager, although itmaybereplicated forfaulttolerance.
Aswehavestated, toaclient thereisnofundamental difference between an
object group andanyothertypeofCORBA object. Tocreate anobject group, a
client simply invokes thenormal create.iobject operation asoffered, inthiscase.CHAP. 10 DISTRIBUTED OBJECT-BASED SYSTEMS 478SEC. 10.7 FAULT TOLERANCE 479
Figure 10-20. Anexample architecture ofafault-tolerant CORBA system.
bythereplication manager, specifying thetypeofobject tocreate. Theclient
remains unaware ofthefactthatitisimplicitly creating anobject group. The
number ofreplicas thatarecreated when starting anewobject group isnormally
determined bythesystem-dependent default value. Thereplica manager isalso
responsible forreplacing areplica inthecaseofafailure, thereby ensuring that
thenumber ofreplicas doesnotdropbelow aspecified minimum.
Thearchitecture alsoshows theuseofmessage-level interceptors. Inthecase
oftheEternal system, eachinvocation isintercepted andpassed toaseparate rep-
lication component thatmaintains therequired consistency foranobject group
andwhich ensures thatmessages arelogged toenable recovery.
Invocations aresubsequently senttotheothergroup members using reliable,
totally-ordered multicasting. Inthecaseofactive replication, aninvocation re-
questispassed toeachreplica object byhanding ittothatobject's underlying run-
timesystem. However, inthecaseofpassive replication, aninvocation request is
passed onlytotheRTSoftheprimary, whereas theother servers onlylogthe
invocation request forrecovery purposes. When theprimary hascompleted the
invocation, itsstateisthenmulticast tothebackups.
Thisarchitecture isbased onusing interceptors. Alternative solutions existas
well,including thoseinwhich faulttolerance hasbeenincorporated intheruntime
system (potentially affecting interoperability), orinwhich special services are
usedontopoftheRTStoprovide faulttolerance. Besides thesedifferences, prac-
ticeshows thatthereareother problems not(yet)covered bytheCORBA stan-
dard.Asanexample ofoneproblem thatoccurs inpractice, ifreplicas arecreated
ondifferent implementations, thereisnoguarantee thatthisapproach willactually
work. Areview ofthedifferent approaches andanassessment offaulttolerance in
CORBA isdiscussed inFelber andNarasimhan (2004).480 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. ]0
10.7.2Example: Fault-Tolerant Java
Considering thepopularity ofJavaasalanguage andplatform fordeveloping
distributed applications, some effort hasalsobeen intoadding faulttolerance to
theJavaruntime system. Aninteresting approach istoensure thattheJavavirtual
machine canbeusedforactive replication.
Active replication essentially dictates thatthereplica servers execute asdeter-
ministic finite-state machines (Schneider, 1990). Anexcellent candidate inJava
tofulfill thisroleistheJavaVirtual Machine (JVM). Unfortunately, theJVM is
notdeterministic atall.There arevarious causes fornondeterministic behavior,
identified independently byNapper etal.(2003) andFriedman andKama (2003):
1.JVM canexecute native code, thatis,code thatisexternal tothe
JVM andprovided tothelatter through aninterface. TheJVM treats
native code likeablack box:itseesonlytheinterface, buthasno
clueabout the(potentially nondeterministic) behavior thatacall
causes. Therefore, inorder tousetheNM foractive replication, itis
necessary tomake surethatnative code behaves inadeterministic
way.
2.Input datamaybesubject tonondeterminism. Forexample, ashared
variable thatcanbemanipulated bymultiple threads maychange for
different instances oftheJVM as10nQ asthreads areallowed to ...
operate concurrently. Tocontrol thisbehavior, shared datashould at
theveryleastbeprotected through locks. Asitturned out,theJava
runtime environment didnotalways adhere tothisrule,despite its
support formultithreading.
3.Inthepresence offailures, different JVMs willproduce different out-
putrevealing thatthemachines havebeenreplicated. Thisdifference
maycause problems when theJVMs need tobrought back intothe
same state. Matters aresimplified ifonecanassume thatalloutput is
idempotent (i.e.,cansimply bereplayed), oristestable sothatone
cancheck whether output wasproduced before acrash ornot.Note
thatthisassumption isnecessary inorder toallow areplica server to
decide whether ornotitshould re-execute anoperation.
Practice shows thatturning theJVM intoadeterministic finite-state machine
isbynomeans trivial. Oneproblem thatneeds tobesolved isthefactthatreplica
servers maycrash. Onepossible organization istolettheservers runaccording to
aprimary-backup scheme. Insuchascheme, oneserver coordinates allactions
thatneed tobeperformed, andfrom timetotimeinstructs thebackup todothe
same. Careful coordination between primary andbackup isrequired, ofcourse.SEC. 10.7 FAULT TOLERANCE 481
Note thatdespite thefactthatreplica servers areorganized inaprimary-
backup setting, wearestilldealing withactive replication: thereplicas arekeptup
todatebyletting eachofthemexecute thesameoperations inthesame order.
However, toensure thesamenondeterministic behavior byalloftheservers, the
behavior ofoneserver istakenastheonetofollow.
Inthissetting, theapproach followed byFriedman andKama (2003) istolet
theprimary firstexecute theinstructions ofwhatiscalled aframe. Aframe con-
sistsoftheexecution ofseveral context switches andendseither because all
threads areblocking forI/Otocomplete, orafterapredefined number ofcontext
switches hastakenplace. Whenever athread issues anI/Ooperation, thethread is
blocked bytheJVMputonhold.When aframe starts, theprimary letsallI/Ore-
quests proceed, oneaftertheother, andtheresults aresenttotheotherreplicas. In
thisway,atleastdeterministic behavior withrespect toI/Ooperations isenforced.
Theproblem withthisscheme iseasily seen:theprimary isalways ahead of
theotherreplicas. There aretwosituations weneedtoconsider. First,ifareplica
server otherthantheprimary crashes, norealharmisdoneexcept thatthedegree
offaulttolerance drops. Ontheotherhand, when theprimary crashes, wemay
findourselves inasituation thatdata(orrather, operations) arelost.
Tominimize thedamage, theprimary works onaper-frame basis. Thatis,it
sends update information totheotherreplicas onlyaftercompletion ofitscurrent
frame. Theeffect ofthisapproach isthatwhentheprimary isworking onthek-th
frame, thattheotherreplica servers havealltheinformation needed toprocess the
frame preceding thek-thone.Thedamage canbelimited bymaking frames small,
atthepriceofmorecommunication between theprimary andthebackups.
10.8SECURITY
Obviously, security playsanimportant roleinanydistributed system andob-
ject-based onesarenoexception. When considering mostobject-based distributed
systems, thefactthatdistributed objects areremote objects immediately leadstoa
situation inwhich security architectures fordistributed systems areverysimilar.
Inessence, eachobject isprotected through standard authentication andauthoriza-
tionmechanisms, liketheoneswediscussed inChap. 9.
Tomake clearhowsecurity canfitinspecifically inanobject-based distrib-
utedsystem, weshalldiscuss thesecurity architecture fortheGlobe system. As
wementioned before, Globe supports trulydistributed objects inwhich thestate
ofasingle object canbespread andreplicated across multiple machines. Remote
objects arejustaspecial caseofGlobe objects. Therefore, byconsidering the
Globe security architecture, wecanalsoseehowitsapproach canbeequally
applied tomore traditional object-based distributed systems. After discussing
Globe, webriefly takealookatsecurity intraditional object-based systems.482 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
10.8.1 Example: Globe
Aswesaid,Globe isoneofthefewdistributed object-based systems inwhich
anobject's statecanbephysically distributed andreplicated across multiple ma-
chines. Thisapproach alsointroduces specific security problems, which haveled
toanarchitecture asdescribed inPopescu eta1.(2002).
Overview
When weconsider thegeneral caseofinvoking amethod onaremote object,
thereareatleasttwoissues thatareimportant fromasecurity perspective: (1)is
thecaller invoking thecorrect object and(2)isthecaller allowed toinvoke that
method. Werefertothesetwoissues assecure object binding andsecure meth-
odinvocation, respectively. Theformer haseverything todowithauthentication,
whereas thelatterinvolves authorization. ForGlobe andother systems thatsup-
porteither replication ormoving objects around, wehaveanadditional problem,
namely thatofplatform security. Thiskindofsecurity comprises twoissues.
First,howcantheplatform towhich a(local) object iscopied beprotected against
anymalicious codecontained intheobject, andsecondly, howcantheobject be
protected against amalicious replica server.
Being abletocopyobjects toother hosts alsobrings upanother problem.
Because theobject server thatishosting acopyofanobject neednotalways be
fullytrusted, theremustbeamechanism thatprevents thatevery replica server
hosting anobject frombeing allowed toalsoexecute anyofanobject's methods.
Forexample, anobject's owner maywanttorestrict theexecution ofupdate
methods toasmall group ofreplica servers, whereas methods thatonlyreadthe
stateofanobject maybeexecuted byanyauthenticated server. Enforcing such
policies canbedonethrough reverse access control, which wediscuss inmore
detail below.
There areseveral mechanisms deployed inGlobe toestablish security. First,
every Globe object hasanassociated public/private keypair,referred toastheob-
jectkey.Thebasicideaisthatanyone whohasknowledge about anobject's
private keycansettheaccess policies forusersandservers. Inaddition, every
replica hasanassociated replica key,which isalsoconstructed asapublic/private
keypair.Thiskeypairisgenerated bytheobject server currently hosting thespe-
cificreplica. Aswewillsee,thereplica keyisusedtomake surethataspecific
replica ispartofagiven distributed shared object. Finally, eachuserisalso
assumed tohaveaunique public/private keypair,known astheuserkey.
These keysareusedtosetthevarious access rights intheformofcertificates.
Certificates arehanded outperobject. There arethreetypes, asshown inFig.10-
21.Ausercertificate isassociated withaspecific userandspecifies exactly
which methods thatuserisallowed toinvoke. Tothisend,thecertificate containsSEC. 10.8
abitstring Uwiththesamelength asthenumber ofmethods available fortheob-
ject.U(i]=1ifandonlyiftheuserisallowed toinvoke method Mi'Likewise,
thereisalsoareplicacertificate thatspecifies, foragiven replica server, which
methods itisallowed toexecute. Italsohasanassociated bitstring R,where
R[i]=iifandonlyiftheserver isallowed toexecute method Mi'
Figure 10-21. Certificates inGlobe: (a)ausercertificate, (b)areplica certifi-
cate,(c)anadministrative certificate.
Forexample, theusercertificate inFig.10-21(a) tellsthatAlice(whocanbe
identified through herpublic keyxu;»hastherighttoinvoke methods M2,M5,
M6,andM7(notethatwestartindexing Uat0).Likewise, thereplica certificate
states thattheserver owning Kkepl isallowed toexecute methods M0,M1,M5,
M6, andM7·
Anadministrative certificate canbeusedbyanyauthorized entity toissue
userandreplica certificates. Inthecase,theRand Ubitstrings specify forwhich
methods andwhich entities acertificate canbecreated. Moreover, thereisbit
indicating whether anadministrative entity candelegate (partof)itsrights to
someone else.NotethatwhenBobinhisroleasadministrator creates ausercerti-
ficate forAlice, hewillsignthatcertificate withhisownsignature, notthatofthe
object. Asaconsequence, Alice's certificate willneedtobetraced backtoBob's
administrative certificate, andeventually toanadministrative certificate signed
withtheobject's private key.
Administrative certificates comeinhandy whenconsidering thatsomeGlobe
objects maybemassively replicated. Forexample, anobject's owner maywantto
manage onlyarelatively smallsetofpermanent replicas, butdelegate thecreation
ofserver-initiated replicas totheservers hosting thosepermanent replicas. Inthat
case,theowner maydecide toallow apermanent replica toinstall otherreplicas
forread-only access byallusers. Whenever Alice wants toinvoke aread-only
method, shewillsucceed (provided sheisauthorized). However, whenwanting to
invoke anupdate method, shewillhavetocontact oneofthepermanent replicas,
asnoneoftheotherreplica servers isallowed toexecute suchmethods.
Asweexplained, thebinding process inGlobe requires thatanobject identi-
fier(OlD) isresolved toacontact address. Inprinciple, anysystem thatsupportsSECURITY 483484 DISTRIBUTED OBJECT· BASED SYSTEMS CHAP. 10
flatnames canbeusedforthispurpose. Tosecurely associate anobject's public
keytoitsDID, wesimply compute theDIDasa160-bit secure hashofthepublic
key.Inthisway,anyone canverify whether agiven public keybelongs toagiven
DID. These identifier arealsoknown asself-certifying names,aconcept
pioneered intheSecure FileSystem (Mazieres etaI.,1999), which wewilldiscuss
inChap. IJ.
Wecanalsocheck .whether areplica Rbelongs toanobject O.Inthatcase,
wemerely needtoinspect thereplica certificate forR,andcheck whoissued it.
Thesigner maybeanentity withadministrative rights, inwhich caseweneedto
inspect itsadministrative certificate. Thebottom lineisthatwecanconstruct a
chain ofcertificates ofwhich thelastoneissigned using theobject's private key.
Inthatcase,weknow thatRispartofO.
Tomutually protect objects andhosts against each other, techniques for
mobile code, asdescribed inChap. 9aredeployed. Detecting thatobjects have
been tampered withcanbedone withspecial auditing techniques which wewill
describe inChap. J2.
SecureMethodInvocation
Letusnowlookintothedetails ofsecurely invoking amethod ofaGlobe ob-
ject.Thecomplete pathfrom requesting aninvocation toactually executing the
operation atareplica issketched inFig.10-22. Atotalof13stepsneedtobeexe-
cuted insequence, asshown inthefigure anddescribed inthefollowing text.
Figure 10-22. Secure method invocation inGlobe.SEC. 10.8 SECURITY 485
-l-. First,anapplication issues ainvocation request bylocally calling the
associatedmethod, just.like calling aprocedure inanRPC.
2.Thecontrol subobject checks theuserpermissions withtheinforma-
tionstored inthelocalsecurity object. Inthiscase,thesecurity ob-
jectshould haveavalidusercertificate.
3.Therequest ismarshaled andpassed on.
4.Thereplication subobject requests themiddleware tosetupasecure
channel toasuitable replica.
5.Thesecurity object firstinitiates areplica lookup. Toachieve this
goal,itcould useanynaming service thatcanlookupreplicas that
havebeenspecified tobeabletoexecute certain methods. TheGlobe
location service hasbeenmodified tohandle suchlookups (Ballin-
tijn,2003).
6.Onceasuitable replica hasbeenfound, thesecurity subobject canset
upasecure channel withitspeer,afterwhich control isreturned to
thereplication subobject. Notethatpartofthisestablishment re-
quires thatthereplica proves itisallowed tocarryouttherequested
invocation.
7.Therequest isnowpassed ontothecommunication subobject.
8.Thesubobject encrypts andsigns therequest sothatitcanpass
through thechannel.
9.Afteritsreceipt, therequest isdecrypted andauthenticated.
10.Therequest isthensimply passed ontotheserver-side replication
subobject.
11.Authorization takesplace: inthiscasetheusercertificate fromthe
client-side stubhasbeenpassed tothereplica sothatwecanverify
thattherequest canindeed becarried out.
12.Therequest isthenunmarshaled.
13.Finally, theoperation canbeexecuted.
Although thismayseem tobearelatively largenumber ofsteps, theexample
shows howasecure method invocation canbebroken down intosmallunits,each
unitbeing necessary toensure thatanauthenticated client cancarryoutanauthor-
izedinvocation atanauthenticated replica. Virtually allobject-based distributed
systems follow these steps. Thedifference withGlobe isthatasuitable replica
needs tobelocated, andthatthisreplica needs toprove itmayexecute themethod
call.Weleavesuchaproofasanexercise tothereader.486 DISTRIBUTED OBJECT-BASED SYSTEMS CHAP. 10
10.8.2SecurityforRemoteObjects
When usingremote objects weoftenseethattheobject reference itselfisim-
plemented asacomplete client-side stub,containing alltheinformation thatis
needed toaccess theremote object. Initssimplest form, thereference contains the
exactcontact address fortheobject andusesastandard marshaling andcommuni-
cation protocol toshipaninvocation totheremote object.
However, insystems suchasJava,theclient-side stub(called aproxy) canbe
virtually anything. Thebasicideaisthatthedeveloper ofaremote object also
develops theproxy andsubsequently registers theproxy withadirectory service.
When aclient islooking fortheobject, itwilleventually contact thedirectory ser-
vice,retrieve theproxy, andinstall it.There areobviously someserious problems
withthisapproach.
First,ifthedirectory service ishijacked, thenanattacker maybeabletore-
turnabogus proxy totheclient. Ineffect, suchaproxy maybeabletocomprom-
iseallcommunication between theclient andtheserver hosting theremote object,
damaging bothofthem.
Second, theclient hasnowaytoauthenticate theserver: itonlyhastheproxy
andallcommunication withtheserver necessarily goesthrough thatproxy. This
maybeanundesirable situation, especially because theclient nowsimply needs to
trusttheproxy thatitwilldoitsworkcorrectly.
Likewise, itmaybemoredifficult fortheserver toauthenticate theclient.
Authentication maybenecessary when sensitive information issenttotheclient.
Also,because client authentication isnowtiedtotheproxy, wemayalsohavethe
situation thatanattacker isspoofing aclient causing damage totheremote object.
Lietal.(2004b) describe ageneral security architecture thatcanbeusedto
makeremote object Invocations safer.Intheirmodel, theyassume thatproxies are
indeed provided bythedeveloper ofaremote object andregistered withadirec-
toryservice. Thisapproach isfollowed inJavaRMI,butalsoJini(SunMicrosys-
terns,2005).
Thefirstproblem tosolveistoauthenticate aremote object. Intheirsolution,
LiandMitchell propose atwo-step approach. First, theproxy which isdown-
loaded fromadirectory service issigned bytheremote object allowing theclient
toverify itsorigin. Theproxy; intum,willauthenticate theobject using TLSwith
server authentication, aswediscussed inChap. 9.Note thatitistheobject
developer's tasktomake surethattheproxy indeed properly authenticates theob-
ject.Theclient willhavetorelyonthisbehavior, butbecause itiscapable of
authenticating theproxy, relying onobject authentication isatthesamelevelas
trusting theremote object tobehave decently.
Toauthenticate theclient, aseparate authenticator isused.When aclient is
looking uptheremote object, itwillbedirected tothisauthenticator fromwhich it
downloads anauthentication proxy. Thisisaspecial proxy thatoffers aninter-
facebywhich theclient canhaveitselfauthenticated bytheremote object. IfthisSEC. 10.8 SECURITY 487
authentication succeeds. thentheremote object (oractually, itsobject server) will
passontheactual proxy totheclient. Note thatthisapproach allows forauthenti-
cation independent oftheprotocol usedbytheactual proxy, which isconsidered
animportant adyantage.
Another important advantage ofseparating client authentication isthatitis
nowpossible topassdedicated proxies toclients. Forexample, certain clients may
beallowed torequest onlyexecution ofread-only methods. Insuchacase, after
authentication hastaken place, theclient willbehanded aproxy thatoffers only
suchmethods, andnoother. More refined access control caneasily beenvisaged.
10.9SUMMARY
Most object-based distributed systems usearemote-object model inwhich an
object ishosted byserver thatallows remote clients todomethod invocations. In
many cases, these objects willbeconstructed atruntime, effectively meaning that
theirstate, andpossibly alsocode isloaded intoanobject server when aclient
doesaremote invocation. Globe isasystem inwhich trulydistributed shared ob-
jects aresupported. Inthiscase, anobject's statemaybephysically distributed
andreplicated across multiple machines.
Tosupport distributed objects, itisimportant toseparate functionality from
extra-functional properties such asfault tolerance orscalability. Tothisend,
advanced object servers havebeendeveloped forhosting objects. Anobject server
provides many services tobasic objects, including facilities forstoring objects, or
toensure serialization ofincoming requests. Another important roleisproviding
theillusion totheoutside world thatacollection ofdataandprocedures operating
onthatdatacorrespond totheconcept ofanobject. Thisroleisimplemented by
means ofobject adapters.
When itcomes tocommunication, theprevalent waytoinvoke anobject isby
means ofaremote method invocation (RMI), which isverysimilar toanRPC. An
important difference isthatdistributed objects generally provide asystemwide ob-
jectreference, allowing aprocess toaccess anobject from anymachine. Global
object reference solve many oftheparameter-passing problems thathinder access
transparency ofRPCs.
There aremany different ways inwhich these object references canbeimple-
mented, ranging fromsimple passive datastructures describing precisely where a
remote object canbecontacted, toportable codethatneedsimply beinvoked bya
client. Thelatter approach isnowcommonly adopted forJavaRMI.
There arenospecial measures inmost systems tohandle object synchroniza-
tion. Animportant exception isthewaythatsynchronized Java methods are
treated: thesynchronization takes place onlybetween clients running onthesame
machine. Clients running ondifferent machines needtotakespecial synchroniza-
tionmeasures. These measures arenotpartoftheJavalanguage.488 DISTRffiUTED OBJECT-BASED SYSTEMS CHAP. 10
Entry consistency isanobvious consistency model fordistributed objects and
is(often implicitly) supported inmany systems. Itisobvious aswecannaturally
associate aseparate lockforeachobject. Oneoftheproblems resulting from
replicating objects arereplicated invocations. Thisproblem ismore evident be-
causeobjects tendtobetreated asblackboxes.
Faulttolerance indistributed object-based systems verymuch follows theap-
proaches usedforotherdistributed systems. Oneexception isformed bytryingto
maketheJavavirtual machine faulttolerant byletting itoperate asadeterministic
finitestatemachine. Then, byreplicating anumber ofthesemachines, weobtain a
natural wayforproviding faulttolerance.
Security fordistributed objects evolves around theideaofsupporting secure
method invocation. Acomprehensive example thatgeneralizes theseinvocations
toreplicated objects isGlobe. Asitturnsout,itispossible tocleanly separate pol-
iciesfrommechanisms. Thisistrueforauthentication aswellasauthorization.
Special attention needs tobepaidtosystems inwhich theclient isrequired to
download aproxy fromadirectory service, asiscommonly thecaseforJava.
PROBLEMS
1.Wemade adistinction between remote objects anddistributed objects. What isthe
difference?
2.Why isituseful todefine theinterfaces ofanobject inanInterface Definition
Language?
3.Some implementations ofdistributed-object middleware systems areentirely based on
dynamic method invocations. Even static invocations arecompiled todynamic ones.
What isthebenefit ofthisapproach?
4.Outline asimple protocol thatimplements at-most-once semantics foranobject invo-
cation. .
5.Should theclient andserver-side objects forasynchronous method invocation beper-
sistent?
6.Inthetext,wementioned thatanimplementation ofCORBA's asynchronous method
invocation donotaffect theserver-side implementation ofanobject. Explain whythis
isthecase.
7.Give anexample inwhich the(inadvertent) useofcallback mechanisms caneasily
leadtoanunwanted situation.
8.Isitpossible foranobject tohavemore thanoneservant?
9.Isitpossible tohave system-specific implementations ofCORBA object references
while stillbeing abletoexchange references withother CORBA-based systems?CHAP. 10 PROBLEMS 489
10.Howcanweauthenticate thecontact addresses returned byalookup service forsecure
Globe objects?
11.What isthekeydifference between object references inCORBA andthose inGlobe?
12.Consider Globe. Outline asimple protocol bywhich asecure channel issetupbe-
tween auserproxy (which hasaccess totheAlice's private key)andareplica thatwe
know forcertain canexecute agiven method.
13.Giveanexample implementation ofanobject reference thatallows aclient tobindto
atransient remote object.
14.Javaandother languages support exceptions, which areraised when anerroroccurs.
Howwould youimplement exceptions inRPCs andRMls?
15.Howwould youincorporate persistent asynchronous communication intoamodel of
communication based onRMls toremote objects?
16.Consider adistributed object-based system thatsupports object replication, inwhich
allmethod invocations aretotally ordered. Also, assume thatanobject invocation is
atomic (e.g.,because every object isautomatically locked when invoked). Does sucha
system provide entry consistency? What about sequential consistency'?
17.Describe areceiver-based scheme fordealing withreplicated invocations, asmen-
tioned inthetext.11
DISTRIBUTED FILE SYSTEMS
Considering thatsharing dataisfundamental todistributed systems, itisnot
surprising thatdistributed filesystems formthebasisformany distributed applica-
tions. Distributed filesystems allow multiple processes toshare dataoverlong
periods oftimeinasecure andreliable way.Assuch, theyhavebeenusedasthe
basic layer fordistributed systems andapplications. Inthischapter, weconsider
distributed filesystems asaparadigm forgeneral-purpose distributed systems.
11.1ARCHITECTURE
Westartourdiscussion ondistributed filesystems bylooking athowtheyare
generally organized. Most systems arebuiltfollowing atraditional client-server
architecture, butfullydecentralized solutions existaswell. Inthefollowing, we
willtakealookatbothkinds oforganizations.
11.1.1Client-Server Architectures
Many distributed filessystems areorganized along thelinesofclient-server
architectures. withSunMicrosystem's Network FileSystem(NFS) being oneof
themost widely-deployed onesforUNIX-based systems. WewilltakeNFSasa
canonical example forserver-based distributed tilesystems throughout thischap-
ter.Inparticular, weconcentrate onNFSv3, thewidely-used thirdversion ofNFS
491492 DISTRIBUTED FILE SYSTEMS CHAP. 11
(Callaghan, 2000) andNFSv4, themost recent, fourth version (Shepler etal.,
2003). Wewilldiscuss thedifferences between them aswell.
Thebasic ideabehind NFSisthateachfileserver. provides astandardized
view ofitslocal filesystem. Inother words, itshould notmatter howthatlocal
filesystem isimplemented; eachNFSserver supports thesame model. Thisap-
proach hasbeen adopted forother distributed filessystems aswell. NFScomes
withacommunication protocol thatallows clients toaccess thefilesstored ona
server, thusallowing aheterogeneous collection ofprocesses, possibly running on
different operating systems andmachines, toshare acommon filesystem.
Themodel underlying NFSandsimilar systems isthatofaremote fileser-
vice. Inthismodel, clients areoffered transparent access toafilesystem thatis
managed byaremote server. However, clients arenormally unaware oftheactual
location offiles. Instead, theyareoffered aninterface toafilesystem thatissimi-
lartotheinterface offered byaconventional local filesystem. Inparticular, the
client isoffered onlyaninterface containing various fileoperations, buttheserver
isresponsible forimplementing those operations. Thismodel istherefore also
referred toastheremote access model. Itisshown inFig.11-I(a).
Figure 11-1. (a)Theremote access model. (b)Theupload/download model.
Incontrast, intheupload/download model aclient accesses afilelocally
afterhaving downloaded itfrom theserver, asshown inFig.11-l(b).When the
client isfinished withthefile,itisuploaded backtotheserver again sothatitcan
beusedbyanother client. TheInternet's FTPservice canbeusedthiswaywhen a
client downloads acomplete file,modifies it,andthenputsitback.
NFShasbeenimplemented foralarge number ofdifferent operating systems,
although theUNIX-based versions arepredominant. Forvirtually allmodern UNIX
systems, NFSisgenerally implemented following thelayered architecture shown
inFig.11-2.
Aclient accesses thefilesystem using thesystem callsprovided byitslocal
operating system. However, thelocalUNIX filesystem interface isreplaced byanSEC. 11.1 ARCHITECTURE 493
Figure 11-2.ThebasicNf'S architecture forUNIX systems.
interface totheVirtual FileSystem (VFS), which bynowisadefactostandard
forinterfacing todifferent (distributed) filesystems (Kleiman, 1986). Virtually
allmodem operating systems provide VFS,andnotdoing somoreorlessforces
developers tolargely reimplement hugeofanoperating system when adopting a
newfile-system structure. WithNFS, operations ontheVFSinterface areeither
passed toalocalfilesystem, orpassed toaseparate component known asthe
~FSclient, which takescareofhandling access tofilesstored ataremote server.
In:N'FS, allclient-server communication isdonethrough RPCs. TheNFSclient •..
implements theNFSfilesystem operations asRPCs totheserver. Notethatthe
operations offered bytheVFSinterface canbedifferent fromthoseoffered bythe
NFSclient. Thewhole ideaoftheVFSistohidethedifferences between various
filesystems.
Ontheserver side,weseeasimilar organization. TheNFSserver isresponsi-
bleforhandling incoming client requests. TheRPCstubunmarshals requests and
theNFSserver converts themtoregular VFSfileoperations thataresubsequently
passed totheVFSlayer. Again, theVFSisresponsible forimplementing alocal
filesystem inwhich theactual filesarestored.
Animportant advantage ofthisscheme isthatNFSislargely independent of
localfilesystems. Inprinciple, itreally doesnotmatter whether theoperating sys-
temattheclient orserver implements aUNIX filesystem, aWindows 2000file
system, orevenanoldMS-DOS filesystem. Theonlyimportant issueisthatthese
filesystems arecompliant withthefilesystem model offered byNFS. Forex-
ample, MS-DOS withitsshortfilenames cannot beusedtoimplement anNFS
server inafullytransparent way.494 DISTRIBUTED ALE SYSTEMS CHAP. II
FileSystem Model
Thefilesystem model offered byNFSisalmost thesameastheoneoffered
byUNIX-based systems. Filesaretreated asuninterpreted sequences ofbytes.
Theyarehierarchically organized intoanaming graph inwhich nodes represent
directories andfiles.NFSalsosupports hardlinksaswellassymbolic links, like
anyUNIX filesystem. Filesarenamed, butareotherwise accessed bymeans ofa
UNIX-like filehandle. which wediscuss indetail below. Inotherwords, toaccess
afile,aclient mustfirstlookupitsname inanaming service andobtain theasso-
ciated filehandle. Furthermore, eachfilehasanumber ofattributes whose values
canbelooked upandchanged. Wereturn tofilenaming indetail laterinthis
chapter.
Fig.11-3shows thegeneral fileoperations supported byNFSversions 3and
4,respectively. Thecreate operation isusedtocreate afile,buthassomewhat dif-
ferent meanings inNFSv3 andNFSv4. Inversion 3,theoperation isusedfor
creating regular files.Special filesarecreated usingseparate operations. Thelink
operation isusedtocreate hardlinks. Symlink isusedtocreate symbolic links.
Mkdir isusedtocreate subdirectories. Special files,suchasdevice files,sockets,
andnamed pipesarecreated bymeans ofthemknod operation.
Thissituation ischanged completely inNFSv4, where create isusedfor
creating nonregular files,which include symbolic links, directories, andspecial
files.Hardlinksarestillcreated using aseparate linkoperation, butregular files
arecreated bymeans oftheopenoperation, which isnewtoNFSandisamajor
deviation fromtheapproach tofilehandling inolderversions. Upuntilversion 4,
NFSwasdesigned toallow itsfileservers tobestateless. Forreasons wediscuss
laterinthischapter, thisdesign criterion hasbeenabandoned inNFSv4, inwhich
itisassumed thatservers willgenerally maintain statebetween operations onthe
samefile.
Theoperation rename isusedtochange thename ofanexisting filethesame
asinUNIX.
Filesaredeleted bymeans oftheremove operation. Inversion 4,thisopera-
tionisusedtoremove anykindoffile.Inprevious versions, aseparate rmdiroper-
ationwasneeded toremove asubdirectory. Afileisremoved byitsname andhas
theeffect thatthenumber ofhardlinkstoitisdecreased byone.Ifthenumber of
linksdrops tozero,thefilemaybedestroyed.
Version 4allows clients toopenandclose(regular) files.Opening anonexist-
ingfilehasthesideeffect thatanewfileiscreated. Toopenafile,aclient pro-
videsaname, along withvarious values forattributes. Forexample, aclient may
specify thatafileshould beopened forwriteaccess. Afterafilehasbeensuccess-
fullyopened, aclient canaccess thatfilebymeans ofitsfilehandle. Thathandle
isalsousedtoclose thefile,bywhich theclient tellstheserver thatitwillno
longer needtohaveaccess tothefile.Theserver, intum,canrelease anystateit
maintained toprovide thatclient access tothefile.SEC. 11.1 ARCHITECTURE 495
Figure 11-3. Anincomplete listoffilesystem operations supported byNFS.
Thelookup operation isusedtolookupafilehandle foragivenpathname. In
NFSv3, thelookup operation willnotresolve aname beyond amount point.
(Recall fromChap. 5thatamount pointisadirectory thatessentially represents a
linktoasubdirectory inaforeign name space.) Forexample, assume thatthe
name /remote/vu refers toamount pointinanaming graph. When resolving the
name/remote/vu/mbox, thelookup operation inNFSv3 willreturn thefilehandle
forthemount pointIremotelvu along withtheremainder ofthepathname (i.e.,
mboxy. Theclient isthenrequired toexplicitly mount thefilesystem thatisneed-
edtocomplete thenamelookup. Afilesystem inthiscontext isthecollection of
files,attributes, directories, anddatablocks thatarejointly implemented asalogi-
calblock device (Tanenbaum andWoodhull, 2006).
Inversion 4,matters havebeensimplified. Inthiscase,lookup willattempt to
resolve theentire name, evenifthismeans crossing mount points. Notethatthis
approach ispossible onlyifafilesystem hasalready beenmounted atmount
points. Theclient isabletodetect thatamount pointhasbeencrossed byinspect-
ingthefilesystem identifier thatislaterreturned whenthelookup completes.
There isaseparate operation readdir toreadtheentries inadirectory. This
operation returns alistof(name, filehandle) pairsalong withattribute values that496 DISTRIBUTED FILESYSTEMS CHAP. 11
theclient requested. Theclient canalsospecify howmany entries should bere-
turned. Theoperation returns anoffset thatcanbeusedinasubsequent callto
readdir inordertoreadthenextseries ofentries.
Operation readlink isusedtoreadthedataassociated withasymbolic link.
Normally, thisdatacorresponds toapathname thatcanbesubsequently looked
up.Notethatthelookup operation cannot handle symbolic links. Instead, when a
symbolic linkisreached, name resolution stopsandtheclient isrequired tofirst
callreadlink tofindoutwhere nameresolution should continue.
Fileshavevarious attributes associated withthem. Again, thereareimportant
differences between NFSversion 3and4,which wediscuss indetail later.Typi-
calattributes include thetypeofthefile(telling whether wearedealing withadi-
rectory, asymbolic link,aspecial file,etc.),thefilelength, theidentifier ofthe
filesystem thatcontains thefile,andthelasttimethefilewasmodified. Fileattri-
butescanbereadandsetusingtheoperations getattr andsetattr, respectively.
Finally, thereareoperations forreading datafromafile,andwriting datatoa
file.Reading databymeans oftheoperation read iscompletely straightforward.
Theclient specifies theoffset andthenumber ofbytestoberead.Theclient isre-
turned theactual number ofbytesthathavebeenread,alongwithadditional status
information (e.g.,whether theend-of-file hasbeenreached).
Writing datatoafileisdoneusingthewrite operation. Theclient again speci-
fiestheposition inthefilewhere writing should start,thenumber ofbytes tobe
written, andthedata.Inaddition, itcaninstruct theserver toensure thatalldata
aretobewritten tostable storage (wediscussed stable storage inChap. 8).N""FS
servers arerequired tosupport storage devices thatcansurvive power supply
failures, operating system failures, andhardware failures.
11.1.2 Cluster-Based Distributed FileSystems
NFSisatypical example formany distributed filesystems, which aregener-
allyorganized according toatraditional client-server architecture. Thisarchitec-
tureisoftenenhanced forserver clusters withafewdifferences.
Considering thatserver clusters areoftenusedforparallel applications, itis
notsurprising thattheirassociated filesystems areadjusted accordingly. One
well-known technique istodeploy file-striping techniques, bywhich asingle file
isdistributed across multiple servers. Thebasicideaissimple: bydistributing a
largefileacross multiple servers, itbecomes possible tofetchdifferent partsin
parallel. Ofcourse, suchanorganization works wellonlyiftheapplication isor-
ganized insuchawaythatparallel dataaccess makes sense. Thisgenerally re-
quires thatthedataasstored inthefilehaveaveryregular structure, forexample,
a(dense) matrix.
Forgeneral-purpose applications, orthose withirregular ormany different .
typesofdatastructures, filestriping maynotbeaneffective tool.Inthosecases. it
isoftenmoreconvenient topartition thefilesystem asawhole andsimply storeSEC. 11.1 ARCHITECTURE 497
different filesondifferent servers, butnottopartition asingle fileacross multiple
servers. Thedifference between thesetwoapproaches isshown inFig.11-4.
More interesting arethecasesoforganizing adistributed filesystem forvery
large datacenters suchasthose usedbycompanies likeAmazon andGoogle.
These companies offerservices toWebclients resulting inreadsandupdates toa
massive number offilesdistributed across literally tensofthousands ofcomputers
[seealsoBarroso etal.(2003)]. Insuchenvironments, thetraditional assumptions
concerning distributed filesystems nolonger hold.Forexample, wecanexpect
thatatanysingle moment therewillbeacomputer malfunctioning.
Toaddress theseproblems, Google, forexample, hasdeveloped itsownGoo-
glefilesystem (GFS), ofwhich thedesign isdescribed inGhemawat etal.
(2003). Google filestendtobeverylarge, commonly ranging uptomultiple giga-
bytes, where eachonecontains lotsofsmaller objects. Moreover, updates tofiles
usually takeplace byappending datarather thanoverwriting partsofafile.These
observations, along withthefactthatserver failures arethenormrather thanthe
exception, leadtoconstructing clusters ofservers asshown inFig.11-5.,-, ,-,
Figure 11-4. Thedifference between (a)distributing whole filesacross several
servers and(b)striping filesforparallel access.
Figure 11-S. Theorganization ofaGoogle cluster ofservers.
EachGFScluster consists ofasingle master along withmultiple chunk ser-
vers. EachGFSfileisdivided intochunks of64Mbyte each,afterwhich these498 DISTRIBUTED FILE SYSTEMSCHAP. 11
chunks aredistributed across whatarecalled chunk servers. Animportant obser-
vation isthataGFSmaster iscontacted onlyformetadata information. Inparticu-
lar,aGFSclient passes afilename andchunk index tothemaster, expecting a
contact address forthechunk. Thecontact address contains alltheinformation to
access thecorrect chunk server toobtain therequired filechunk.
Tothisend,theGFSmaster essentially maintains anamespace, along witha
mapping fromfilename tochunks. Eachchunk hasanassociated identifier that
willallow achunk server tolookup itup.Inaddition, themaster keeps trackof
where achunk islocated. Chunks arereplicated tohandle failures, butnomore
thanthat.Aninteresting feature isthattheGFSmaster doesnotattempt tokeep
anaccurate account ofchunk locations. Instead, itoccasionally contacts thechunk
servers toseewhich chunks theyhavestored.
Theadvantage ofthisscheme issimplicity. Notethatthemaster isincontrol
ofallocating chunks tochunk servers. Inaddition, thechunk servers keepan
account ofwhattheyhavestored. Asaconsequence, oncethemaster hasobtained
chunk locations, ithasanaccurate picture ofwhere dataisstored. However, mat-
terswould become complicated ifthisviewhadtobeconsistent allthetime.For
example, every timeachunk server crashes orwhen aserver isadded, themaster
would needtobeinformed. Instead, itismuch simpler torefresh itsinformation
fromthecurrent setofchunk servers through polling. GFSclients simply getto
know which chunk servers themaster believes isstoring therequested data.
Because chunks arereplicated anyway, thereisahighprobability thatachunk is
available onatleastoneofthechunk servers.
Whydoesthisscheme scale? Animportant design issueisthatthemaster is
largely incontrol, butthatitdoesnotformabottleneck duetoallthework it
needs todo.Twoimportant typesofmeasures havebeentaken toaccommodate
scalability.
First,andbyfarthemostimportant one,isthatthebulkoftheactual workis
donebychunk servers. When aclient needs toaccess data,itcontacts themaster
tofindoutwhich chunk servers holdthatdata.After that,itcommunicates only
withthechunk servers. Chunks arereplicated according toaprimary-backup
scheme. When theclient isperforming anupdate operation, itcontacts thenearest
chunk server holding thatdata,andpushes itsupdates tothatserver. Thisserver
willpushtheupdate tothenextclosest oneholding thedata,andsoon.Once all
updates havebeenpropagated, theclient willcontact theprimary chunk server,
whowillthenassign asequence number totheupdate operation andpassitonto
thebackups. Meanwhile, themaster iskeptoutoftheloop.
Second, the(hierarchical) name space forfilesisimplemented using asimple
single-level table, inwhich pathnames aremapped tometadata (such asthe
equivalent ofinodes intraditional filesystems). Moreover, thisentire tableiskept
inmainmemory, along withthemapping offilestochunks. Updates onthesedata
arelogged topersistent storage. When thelogbecomes toolarge, acheckpoint is
made bywhich themain-memory dataisstored insuchawaythatitcanbeSEC. 11.1 ARCHITECTURE 499
immediately mapped backintomainmemory. Asaconsequence, theintensity of
I/OofaGFSmaster isstrongly reduced.
Thisorganization allows asingle master tocontrol afewhundred chunk ser-
vers,which isaconsiderable sizeforasingle cluster. Bysubsequently organizing
aservice suchasGoogle intosmaller services thataremapped ontoclusters, itis
nothardtoimagine thatahugecollection ofclusters canbemade towork
together.
11.1.3Symmetric Architectures
Ofcourse, fullysymmetric organizations thatarebased onpeer-to-peer tech-
nology alsoexist. Allcurrent proposals useaDHT-based system fordistributing
data,combined withakey-based lookup mechanism. Animportant difference is
whether theybuildafilesystem ontopofadistributed storage layer, orwhether
whole filesarestored ontheparticipating nodes.
Anexample ofthefirsttypeoffilesystem isIvy,adistributed filesystem that
isbuiltusing aChord DHT-based system. Ivyisdescribed inMuthitacharoen et
al.(2002). Their system essentially consists ofthreeseparate layers asshown in
Fig.11-6. Thelowest layerisformed byaChord system providing basicdecen-
tralized lookup facilities. Inthemiddle isafullydistributed block-oriented stor-
agelayer. Finally, ontopthereisalayerimplementing anNFS-like filesystem.
Figure 11-6. Theorganization oftheIvydistributed filesystem.
Datastorage inIvyisrealized byaChord-based, block-oriented distributed
storage system called DHash(Dabek etal.,2001). Inessence, DHash isquite
simple. Itonlyknows about datablocks, eachblock typically having asizeof8
KB.Ivyusestwokinds ofdatablocks. Acontent-hash blockhasanassociated
key,which iscomputed asthesecure hashoftheblock's content. Inthisway,
whenever ablock islooked up,aclient canimmediately verify whether thecor-
rectblock hasbeenlooked up,orthatanother orcorrupted version isreturned.500 DISTRIBUTED FILESYSTEMS CHAP. II
Furthermore, Ivyalsomakes useofpublic-key blocks, which areblocks having a
public keyaslookup key,andwhose content hasbeensigned withtheassociated
private key.
Toincrease availability, DHash replicates every block Btothekimmediate
successors oftheserver responsible forstoring B.Inaddition, looked upblocks
arealsocached alongtheroutethatthelookup request followed.
Files areimplemented asaseparate datastructure ontopofDHash. To
achieve thisgoal,eachusermaintains alogofoperations itcarries outonfiles.
Forsimplicity, weassume thatthereisonlyasingle userpernodesothateach
nodewillhaveitsownlog.Alogisalinked listofimmutable records, where each
record contains alltheinformation related toanoperation ontheIvyfilesystem.
Eachnodeappends records onlytoitsown,local, log.Onlyalog'sheadismut-
able,andpoints tothemostrecently appended record. Eachrecord isstored ina
separate content-hash block, whereas alog'sheadiskeptinapublic-key block.
There aredifferent types ofrecords, roughly corresponding tothedifferent
operations supported byNFS.Forexample, whenperforming anupdate operation
onafile,awrite record iscreated, containing thefile'sidentifier along withthe
offset forthepilepointer andthedatathatisbeing written. Likewise, thereare
records forcreating files(i.e.,adding anewinode), manipulating directories, etc.
Tocreate anewfilesystem, anodesimply creates anewlogalong withanew
inode thatwillserveastheroot.Ivydeploys whatisknown asanNFSloopback
server which isjustalocaluser-level server thataccepts NFSrequests fromlocal
clients. InthecaseofIvy,thisNFSserver supports mounting thenewly created
filesystem allowing applications toaccess itasanyotherNFSfilesystem.
When performing areadoperation, thelocalIvyNFSserver makes apass
overthelog,collecting datafromthoserecords thatrepresent writeoperations on
thesameblock ofdata,allowing ittoretrieve themostrecently stored values.
Notethatbecause eachrecord isstored asaDHash block, multiple lookups across
theoverlay network maybeneeded toretrieve therelevant values.
Instead ofusing aseparate block-oriented storage layer, alternative designs
propose todistribute whole filesinstead ofdatablocks. Thedevelopers ofKosha
(Buttetal.2004) propose todistribute filesataspecific directory level. Intheir
approach, eachnodehasamount pointnamed /kosha containing thefilesthatare
tobedistributed usingaDHT-based system. Distributing filesatdirectory levelI
means thatallfilesinasubdirectory /kosha/a willbestored atthesamenode.
Likewise, distribution atlevel 2implies thatallfilesstored insubdirectory
/kosha/aJaa arestored atthesamenode. Taking alevel-I distribution asanex-
ample, thenoderesponsible forstoring filesunder/koshaJa isfound bycomputing
thehashofaandtaking thatasthekeyinalookup.
Thepotential drawback ofthisapproach isthatanodemayrunoutofdisk
space tostoreallthefilescontained inthesubdirectory thatitisresponsible for.
Again, asimple solution isfound inplacing abranch ofthatsubdirectory onan-
othernodeandcreating asymbolic linktowhere thebranch isnowstored.SEC. 11.2 PROCESSES 501
11.2PROCESSES
When itcomes toprocesses, distributed filesystems havenounusual proper-
ties.Inmany cases, therewillbedifferent typesofcooperating processes: storage
servers andfilemanagers, justaswedescribed above forthevarious organiza-
tions.
Themostinteresting aspect concerning filesystem processes iswhether ornot
theyshould bestateless. NFSisagoodexample illustrating thetrade-offs. Oneof
itslong-lasting distinguishing features (compared toother distributed filesys-
tems), wasthefactthatservers werestateless. Inotherwords, theNFSprotocol
didnotrequire thatservers maintained anyclient state. Thisapproach wasfol-
lowed inversions 2and3,buthasbeenabandoned forversion 4.
Theprimary advantage ofthestateless approach issimplicity. Forexample,
when astateless server crashes, thereisessentially noneedtoenterarecovery
phase tobringtheserver toaprevious state.However, asweexplained inChap. 8,
westillneedtotakeintoaccount thattheclient cannot begiven anyguarantees
whether ornotarequest hasactually beencarried out.
Thestateless approach intheNFSprotocol could notalways befullyfollowed
inpractical implementations. Forexample; locking afilecannot easily bedoneby
astateless server. InthecaseofNFS,aseparate lockmanager isusedtohandle
thissituation. Likewise, certain authentication protocols require thattheserver
maintains stateonitsclients. Nevertheless, NFSservers could generally be
designed insuchawaythatonlyverylittleinformation onclients needed tobe
maintained. Forthemostpart,thescheme worked adequately.
Starting withversion 4,thestateless approach wasabandoned, although the
newprotocol isdesigned insuchawaythataserver doesnotneedtomaintain
much information about itsclients. Besides thosejustmentioned, thereareother
reasons tochoose forastateful approach. Animportant reason isthatNFSversion
4isexpected toalsoworkacross wide-area networks. Thisrequires thatclients
canmake effective useofcaches, intumrequiring anefficient cache consistency
protocol. Suchprotocols oftenworkbestincollaboration withaserver thatmain-
tainssomeinformation onfilesasusedbyitsclients. Forexample, aserver may
associate aleasewitheachfileithands outtoaclient, promising togivetheclient
exclusive readandwriteaccess untiltheleaseexpires orisrefreshed. Wereturn
tosuchissues laterinthischapter.
Themostapparent difference withtheprevious versions isthesupport forthe
openoperation. Inaddition, NFSsupports callback procedures bywhich aserver
candoanRPCtoaclient. Clearly, callbacks alsorequire aserver tokeeptrackof
itsclients.
Similar reasoning hasaffected thedesign ofotherdistributed filesystems. By
andlarge, itturnsoutthatmaintaining afullystateless design canbequitediffi-
cult,oftenleading tobuilding stateful solutions asanenhancement, suchasisthe
casewithNFSfilelocking.502 DISTRIBUTED FILESYSTEMS CHAP. 11
11.3COMMUNICATION
Aswithprocesses, thereisnothing particularly special orunusual about com-
munication indistributed filesystems. Many ofthemarebased onremote proce-
durecalls(RPCs), although some interesting enhancements havebeenmade to
support special cases. Themainreason forchoosing anRPCmechanism isto
make thesystem independent fromunderlying operating systems, networks, and
transport protocols.
11.3.1 RPCs inNFS
Forexample, inNFS,allcommunication between aclient andserver proceeds
along theOpen Network Computing RPC(ONC RPC) protocol, which isfor-
mally defined inSrinivasan (1995a), along withastandard forrepresenting mar-
shaled data(Srinivasan, 1995b). ONCRPCissimilar tootherRPCsystems aswe
discussed inChap. 4.
Every NFSoperation canbeimplemented asasingle remote procedure callto
afileserver. Infact,upuntilNFSv4, theclient wasmaderesponsible formaking
theserver's lifeaseasyaspossible bykeeping requests relatively simple. Forex-
ample, inordertoreaddatafromafileforthefirsttime,aclient normally first
hadtolookupthefilehandle using thelookup operation, afterwhich itcould
issueareadrequest, asshown inFig.11-7(a).
Figure 11-7. (a)Reading datafrom afileinNFSversion 3.(b)Reading data
using acompound procedure inversion 4.
Thisapproach required twosuccessive RPCs. Thedrawback became apparent
when considering theuseofNFSinawide-area system. Inthatcase,theextra
latency ofasecond RPCledtoperformance degradation. Tocircumvent such
problems, NFSv4 supports compound procedures bywhich several RPCs canbe
grouped intoasingle request, asshown inFig.11-7(b).SEC. 11.3 COMMUNICATION 503
Inourexample, theclient combines thelookup andreadrequest intoasingle
RPC.Inthecaseofversion 4,itisalsonecessary toopenthefilebefore reading
cantakeplace. Afterthefilehandle hasbeenlooked up,itispassed totheopen
operation, afterwhich theserver continues withthereadoperation. Theoverall
effect inthisexample isthatonlytwomessages needtobeexchanged between
theclient andserver.
There arenotransactional semantics associated withcompound procedures.
Theoperations grouped together inacompound procedure aresimply handled in
theorder asrequested. Ifthereareconcurrent operations fromotherclients, then
nomeasures aretakentoavoid conflicts. Ifanoperation failsforwhatever reason,
thennofurther operations inthecompound procedure areexecuted, andthere-
sultsfound sofararereturned totheclient. Forexample, iflookup fails,asue-
ceeding openisnotevenattempted.
11.3.2 TheRPC2 Subsystem
Another interesting enhancement toRPCs hasbeendeveloped aspartofthe
Coda filesystem (Kistler andSatyanarayanan, 1992). RPC2 isapackage that
offers reliable RPCs ontopofthe(unreliable) UDPprotocol. Eachtimearemote
procedure iscalled, theRPC2 client codestartsanewthread thatsends aninvoca-
tionrequest totheserver andsubsequently blocks untilitreceives ananswer. As
request processing maytakeanarbitrary timetocomplete, theserver regularly
sendsbackmessages totheclient toletitknowitisstillworking ontherequest. If
theserver dies,sooner orlaterthisthread willnotice thatthemessages have
ceased andreport backfailure tothecalling application.
Aninteresting aspect ofRPC2 isitssupport forsideeffects. Asideeffect isa
mechanism bywhich theclient andserver cancommunicate using anapplica-
tion-specific protocol. Consider, forexample, aclient opening afileatavideo
server. What isneeded inthiscaseisthattheclient andserver setupacontinuous
datastream withanisochronous transmission mode. Inotherwords, datatransfer
fromtheserver totheclient isguaranteed tobewithin aminimum andmaximum
end-to-end delay.
RPC2 allows theclient andtheserver tosetupaseparate connection for
transferring thevideodatatotheclient ontime.Connection setupisdoneasaside
effect ofanRPCcalltotheserver. Forthispurpose, theRPC2 runtime system
provides aninterface ofside-effect routines thatistobeimplemented bytheap-
plication developer. Forexample, thereareroutines forsetting upaconnection
androutines fortransferring data.These routines areautomatically called bythe
RPC2 runtime system attheclient andserver, respectively, buttheirimplementa-
tionisotherwise completely independent ofRPC2. Thisprinciple ofsideeffects is
shown inFig.11-8.
Another feature ofRPC2 thatmakes itdifferent fromotherRPCsystems isits
support formulticasting. Animportant design issueinCoda isthatservers keepFigure 11-8. Sideeffects inCoda's RPC2 system.
trackofwhich clients havealocalcopyofafile.When afileismodified, aserver
invalidates localcopies bynotifying theappropriate clients through anRPC.
Clearly, ifaserver cannotify onlyoneclient atatime,invalidating allclients may
takesometime,asillustrated inFig.11-9(a).
Figure 11-9. (a)Sending aninvalidation message oneatatime. (b)Sending in-
validation messages inparallel.
Theproblem iscaused bythefactthatanRPCmayoccasionally fail.Invali-
dating filesinastrictsequential ordermaybedelayed considerably because the
server cannot reach apossibly crashed client, butwillgiveuponthatclient only
afterarelatively longexpiration time.Meanwhile, otherclients willstillberead-
ingfromtheirlocalcopies.
Analternative (andbetter) solution isshown inFig.11-9(b). Here, instead of
invalidating eachcopyonebyone.theserver sends aninvalidation message toall
clients atthesametime.Asaconsequence, allnonfailing clients arenotified in
thesametimeasitwould taketodoanimmediate RPC. Also, theserver notices504 DISTRIBUTED FILESYSTEMS CHAP. 11SEC. 11.3 COMMUNICATION 505
within theusual expiration timethatcertain clients arefailing torespond tothe
RPC,andcandeclare suchclients asbeing crashed.
Parallel RPCs areimplemented bymeans oftheMultiRPC system, which is
partoftheRPC2 package (Satyanarayanan andSiegel, 1990). Animportant
aspect ofMultiRPC isthattheparallel invocation ofRPCs isfullytransparent to
thecallee. Inotherwords, thereceiver ofaMuitiRPC callcannot distinzuish that"-
callfromanormal RPC. Atthecaller's side,parallel execution isalsolargely
transparent. Forexample, thesemantics ofMultiRPC inthepresence offailures
aremuch thesameasthatofanormal RPC.Likewise, theside-effect mechanisms
canbeusedinthesamewayasbefore.
MultiRPC isimplemented byessentially executing multiple RPCs inparallel.
Thismeans thatthecaller explicitly sends anRPCrequest toeachrecipient. How-
ever,instead ofimmediately waiting foraresponse, itdefers blocking untilallre-
quests havebeensent.Inotherwords, thecaller invokes anumber ofone-way
RPCs, afterwhich itblocks untilallresponses havebeenreceived fromthenon-
failing recipients. Analternative approach toparallel execution ofRPCs inMul-
tiRPC isprovided bysetting upamulticast group, andsending anRPCtoall
group members usingIFmulticast.
11.3.3File-Oriented Communication inPlan9
Finally, itisworth mentioning acompletely different approach tohandling
communication indistributed filesystems. Plan9(Pikeetal.,1995). isnotso
much adistributed filesystem, butrather afile-based distributed system. Allre-
sources areaccessed inthesame way,namely withfile-like syntax andopera-
tions, including evenresources suchasprocesses andnetwork interfaces. This
ideaisinherited fromUNIX, which alsoattempts toofferfile-like interfaces tore-
sources, butithasbeenexploited much further andmoreconsistently inPlan9.
Toillustrate, network interfaces arerepresented byafilesystem, inthiscasecon-
sisting ofacollection ofspecial files.Thisapproach issimilar toUNIX, although
network interfaces inUNIX arerepresented bytilesandnotfilesystems. (Note
thatafilesystem inthiscontext isagain thelogical block device containing all
thedataandmetadata thatcomprise acollection offiles.) InPlan9,forexample,
anindividual TCPconnection isrepresented byasubdirectory consisting ofthe
filesshown inFig.11-10.
Thefilectlisusedtosendcontrol commands totheconnection. Forexample,
toopenatelnet session toamachine withIPaddress 192.31.231.42 usingport23,
requires thatthesender writes thetextstring "connect 192.31.231.42!23" tofile
ctl.Thereceiver would previously havewritten thestring "announce 23"toits
ownctlfile,indicating thatitcanaccept incoming session requests.
Thedatafileisusedtoexchange databysimply performing readandwrite
operations. These operations follow theusualUNIX semantics forfileoperations.506 DISTRIBUTED FILESYSTEMS CHAP. ]]
Figure 11-10. Filesassociated withasingle TCPconnection inPlan9.
Forexample, towritedatatoaconnection, aprocess simply invokes theoperation
res=write(td, but, nbytes);
where fdisthefiledescriptor returned afteropening thedatafile,bufisapointer
toabuffer containing thedatatobewritten, andnbytes isthenumber ofbytesthat
should beextracted fromthebuffer. Thenumber ofbytes actually written isre-
turned andstored inthevariable res.
Thefilelisten isusedtowaitforconnection setuprequests. After aprocess
hasannounced itswillingness toaccept newconnections, itcandoablocking
read onfilelisten. Ifarequest comes in,thecallreturns afiledescriptor toanew
etlfilecorresponding toanewly-created connection directory. Itisthusseenhow
acompletely file-oriented approach toward communication canberealized.
11.4NAMING
Naming arguably plays animportant roleindistributed filesystems. Invir-
tually allcases, names areorganized inahierarchical name space likethose we
discussed inChap. 5.Inthefollowing wewillagain consider NFSasarepres-
entative forhownaming isoftenhandled indistributed filesystems.
11.4.1 Naming inNFS
Thefundamental ideaunderlying theNFSnaming model istoprovide clients
complete transparent access toaremote filesystem asmaintained byaserver.
Thistransparency isachieved byletting aclient beabletomount aremote file
system intoitsownlocalfilesystem, asshown inFig.11-11.
Instead ofmounting anentire filesystem, NFSallows clients tomount only
partofafilesystem. asalsoshown inFig.11-11. Aserver issaidtoexport adi-
rectory when itmakes thatdirectory anditsentries available toclients. An
exported directory canbemounted intoaclient's localname space.SEC. 11.4
Figure 11-11. Mounting (partof)aremote filesystem inNFS.
This design approach hasaserious implication: inprinciple, users donot
share name spaces. Asshown inFig.11-11, thefilenamed Iremotelvulmbox at
client Aisnamed /work/me/mbox atclient B.Afile's name therefore depends on
howclients organize theirownlocalname space, andwhere exported directories
aremounted. Thedrawback ofthisapproach inadistributed filesystem isthat
sharing filesbecomes much harder. Forexample, Alice cannot tellBobabout a
fileusing thename sheassigned tothatfile,forthatname mayhaveacompletely
different meaning inBob's name space offiles.
There areseveral ways tosolve thisproblem, butthemostcommon oneisto
provide eachclient withaname space thatispartly standardized. Forexample,
eachclient maybeusing thelocaldirectory lusr/bin tomount afilesystem con-
taining astandard collection ofprograms thatareavailable toeveryone. Likewise,
thedirectory Ilocal maybeusedasastandard tomount alocalfilesystem thatis
located ontheclient's host.
AnNFSserver canitselfmount directories thatareexported byother servers.
However, itisnotallowed toexport those directories toitsownclients. Instead, a
client willhavetoexplicitly mount suchadirectory fromtheserver thatmaintains
it,asshown inFig.11-12. Thisrestriction comes partly from simplicity. Ifa
server could export adirectory thatitmounted fromanother server, itwould have
toreturn special filehandles thatinclude anidentifier foraserver. NFSdoesnot
support suchfilehandles.
Toexplain thispoint inmore detail, assume thatserver Ahosts afilesystem
FSA from which itexports thedirectory Ipackages. Thisdirectory contains asub-
directory /draw thatactsasamount point forafilesystem FSsthatisexported by
server Bandmounted byA.LetAalsoexport Ipackagesldraw toitsownclients,NAMING 507CHAP. 11
Figure 11-12. Mounting nested directories frommultiple servers inNFS.
andassume thataclient hasmounted /packages intoitslocaldirectory /bin as
shown inFig.11-12.
Ifname resolution isiterative (asisthecaseinNFSv3), thentoresolve the
name/bin/draw/install, theclient contacts server Awhen ithaslocally resolved
/binandrequests Atoreturn afilehandle fordirectory /draw. Inthatcase,server
Ashould return afilehandle thatincludes anidentifier forserver B,foronlyBcan
resolve therestofthepathname, inthiscase/install. Aswehavesaid,thiskind
ofnameresolution isnotsupported byNFS.
Name resolution inNFSv3 (andearlier versions) isstrictly iterative inthe
sense thatonlyasingle filename atatimecanbelooked up.Inother words,
resolving aname suchas/bin/draw/install requires threeseparate callstotheNFS
server. Moreover, theclient isfullyresponsible forimplementing theresolution of
apathname. NFSv4 alsosupports recursive name lookups. Inthiscase,aclient
canpassacomplete pathnametoaserver andrequest thatserver toresolve it.
There isanother peculiarity withNFSnamelookups thathasbeensolved with
version 4.Consider afileserver hosting several filesystems. Withthestrictitera-
tivenameresolution inversion 3,whenever alookup wasdoneforadirectory on
which another filesystem wasmounted, thelookup would return thefilehandle of"
thedirectory. Subsequently reading thatdirectory would return itsoriginal con-
tent,notthatoftherootdirectory ofthemounted filesystem.DISTRIBUTED FILESYSTEMS 508SEC. tt.4 NAMING 509
FileHandles
Afilehandle isareference toafilewithin afilesystem. Itisindependent of
thename ofthefileitrefers to.Afilehandle iscreated bytheserver thatishost-
ingthefilesystem andisunique withrespect toallfilesystems exported bythe
server. Itiscreated when thefileiscreated. Theclient iskeptignorant ofthe
actual content ofafilehandle; itiscompletely opaque. Filehandles were32bytes
inNFSversion 2,butwerevariable upto64bytesinversion 3and128bytesin
version 4.Ofcourse, thelength ofafilehandle isnotopaque.
Ideally, afilehandle isimplemented asatrueidentifier forafilerelative toa
filesystem. Foronething, thismeans thataslongasthefileexists, itshould have
oneandthesamefilehandle. Thispersistence requirement allows aclient tostore
afilehandle locally oncetheassociated filehasbeenlooked upbymeans ofits
name. Onebenefit isperformance: asmostfileoperations require afilehandle in-
steadofaname, theclient canavoid having tolookupaname repeatedly before
every fileoperation. Another benefit ofthisapproach isthattheclient cannow
access thefileindependent ofits(current) names.
Because afilehandle canbelocally stored byaclient, itisalsoimportant that
aserver doesnotreuseafilehandle afterdeleting afile.Otherwise, aclient may
mistakenly access thewrong filewhenitusesitslocally stored filehandle.
Notethatthecombination ofiterative name lookups andnotletting alookup
operation allow crossing amount pointintroduces aproblem withgetting anini-
tialfilehandle. Inordertoaccess filesinaremote filesystem, aclient willneed
toprovide theserver withafilehandle ofthedirectory where thelookup should
takeplace, along withthename ofthefileordirectory thatistoberesolved.
NFSv3solves thisproblem through aseparate mount protocol, bywhich aclient
actually mounts aremote filesystem. Aftermounting, theclient ispassed backthe
rootfilehandleofthemounted filesystem, which itcansubsequently useasa
starting pointforlooking upnames.---------'fo explain. assume thatinourprevious example thatbothfilesystems FSA
andFSB arehosted byasingleserver, Iftheclient hasmounted /packages intoits
localdirectory /bin,thenlooking upthefilenamedraw attheserver would return
thefilehandle fordraw. Asubsequent calltotheserver forlisting thedirectory
entries ofdraw bymeans ofreaddir would thenreturn thelistofdirectory entries
thatwereoriginally stored inFSA insubdirectory /packages/draw. Onlyifthecli-
enthadalsomounted filesystem FSB, would itbepossible toproperly resolve the
pathnamedraw/install relative to/bin.
NFSv4 solves thisproblem byallowing lookups tocrossmount points ata
server. Inparticular, lookup returns thefilehandle ofthemounted directory in-
steadofthatoftheoriginal directory. Theclient candetect thatthelookup has
crossed amount pointbyinspecting thefilesystem identifier ofthelooked upfile.
Ifrequired, theclient canlocally mount thatfilesystem aswell.510 DISTRIBUTED FILESYSTEMS CHAP. 11
InNFSv4, thisproblem issolved byproviding aseparate operation putrootfh
thattellstheserver tosolve allfilenames relative totherootfilehandle of.the file,~
system itmanages. Therootfilehandle canbeusea-fOIOok upanyother file
handle intheserver's filesystem. Thisapproach hastheadditional benefit that
there isnoneed foraseparate mount protocol. Instead, mounting canbein-
tegrated intotheregular protocol forlooking upfiles. Aclient cansimply mount a
remote filesystem byrequesting theserver toresolve names relative tothefile
system's rootfilehandle using putrootfh.
Automounting
Aswementioned, theNFSnaming model essentially provides users withtheir
ownname space. Sharing inthismodel maybecome difficult ifusers name the
same filedifferently. Onesolution tothisproblem istoprovide eachuserwitha
local name space thatispartly standardized, andsubsequently mounting remote
filesystems thesame foreachuser.
Another problem withtheNFSnaming model hastodowithdeciding when a
remote filesystem should bemounted. Consider alarge system withthousands of
users. Assume thateachuserhasalocaldirectory !home thatisusedtomount the
home directories ofother users. Forexample, Alice's home directory maybe
locally available toheras!home/alice, although theactual filesarestored onare-
mote server. Thisdirectory canbeautomatically mounted when Alice logsinto
herworkstation. Inaddition, shemayhave access toBob's public filesbyac-
cessing Bob's directory through /home/bob.
Thequestion, however, iswhether Bob's home directory should alsobe
mounted automatically when Alice logsin.Thebenefit ofthisapproach would be
thatthewhole business ofmounting filesystems would betransparent toAlice.
However, ifthispolicy werefollowed forevery user,logging incould incur alot
ofcommunication andadministrative overhead. Inaddition, itwould require that
allusers areknown inadvance. Amuch better approach istotransparently mount
another user's home directory ondemand, thatis,when itisfirstneeded.
On-demand mounting ofaremote filesystem (oractually anexported direc-
tory) ishandled inNFSbyanautomounter, which runsasaseparate process on
theclient's machine. Theprinciple underlying anautomounter isrelatively sim-.
ple.Consider asimple automounter implemented asauser-level NFSserver ona
UNIX operating system. Foralternative implementations, seeCallaghan (2000).
Assume thatforeach user, thehome directories ofallusers areavailable
through thelocal directory !home, asdescribed above. When aclient machine
boots, theautomounter starts withmounting thisdirectory. Theeffect ofthislocal
mount isthatwhenever aprogram attempts toaccess /home, theUNIX kernel will
forward alookup operation totheNFSclient. which inthiscase, willforward the
request totheautomounter initsroleasNFSserver. asshown inFig.11-13.SEC. 11.4 NAMING 511
Figure 11-13. Asimple automounter forNFS.
Forexample, suppose thatAlice logsin.Theloginprogram willattempt to
readthedirectory /home/alice tofindinformation suchasloginscripts. Theauto-
mounter willthusreceive therequest tolookupsubdirectory /home/alice, for
which reason itfirstcreates asubdirectory /alice in/home. Itthenlooks upthe
NFSserver thatexports Alice's home directory tosubsequently mount thatdirec-
toryin/home/alice. Atthatpoint, theloginprogram canproceed.
Theproblem withthisapproach isthattheautomounter willhavetobeinvol-
vedinallfileoperations toguarantee transparency. Ifareferenced fileisnotlo-
callyavailable because thecorresponding filesystem hasnotyetbeenmounted,
theautomounter willhavetoknow. Inparticular, itwillneedtohandle allread
andwriterequests, evenforfilesystems thathavealready beenmounted. Thisap-
proach mayincuralargeperformance problem. Itwould bebetter tohavetheauto
mounter onlymountlunmount directories, butotherwise stayoutoftheloop.
Asimple solution istolettheautomounter mount directories inaspecial
subdirectory, andinstall asymbolic linktoeachmounted directory. Thisapproach
isshown inFig.11-14.
Inourexample, theuserhome directories aremounted assubdirectories of
/tmp_mnt. When Alice logsin,theautomounter mounts herhome directory in
/tmp_mnt/home/alice andcreates asymbolic link/home/alice thatrefers tothat
subdirectory. Inthiscase,whenever Aliceexecutes acommand suchas
Is-I/home/alice
theNFSserver thatexports Alice's home directory iscontacted directly without
further involvement oftheautomounter.512 DISTRIBUTED FILESYSTEMS CHAP. 11
Figure 11-14. Using symbolic linkswithautomounting.
11.4.2 Constructing aGlobal Name Space
Large distributed systems arecommonly constructed bygluing together vari-
ouslegacy systems intoonewhole. When itcomes tooffering shared access to
files,having aglobal name space isabout theminimal gluethatonewould liketo
have. Atpresent, filesystems aremostly opened forsharing byusing primitive
means suchasaccess through FTP.Thisapproach, forexample, isgenerally used
inGridcomputing.
More sophisticated approaches arefollowed bytrulywide-area distributed file
systems, buttheseoftenrequire modifications tooperating system kernels inorder
tobeadopted. Therefore, researchers havebeenlooking forapproaches toin-
tegrate existing filesystems intoasingle, global name space butusing onlyuser-
level solutions. Onesuchsystem, simply called Global Name Space Service
(GNS) isproposed byAnderson eta1.(2004).
GNSdoesnotprovide interfaces toaccess files.Instead, itmerely provides
themeans tosetupaglobal name space inwhich several existing name spaces
havebeenmerged. Tothisend,aGNSclient maintains avirtual treeinwhich
eachnodeiseither adirectory orajunction. Ajunction isaspecial nodethat
indicates that.name resolution istobetaken overbyanother process, andassuch
bears someresemblance withamount pointintraditional filesystem. There are
fivedifferent typesofjunctions, asshown inFig.11-15.
AGNSjunction simply refers toanother GNSinstance, which isjustanother
virtual treehosted atpossibly another process. Thetwological junctions contain
information thatisneeded tocontact alocation service. Thelatterwillprovide the
contact address foraccessing afilesystem andafile,respectively. Aphysical
file-system namerefers toafilesystem atanother server, andcorresponds largely
toacontact address thatalogical junction would need.Forexample, aURLsuch
asftp:l/ftp.cs.vu.nllpub would contain alltheinformation toaccess filesatthe
indicated FrPserver. Analogously, aURLsuchashttp/rwww.cs.vu.nl/index.hnn
isatypical example ofaphysical filename.SEC. 11.4 NAMING 513
Figure 11-15. Junctions inGNS.
Obviously, ajunction should contain alltheinformation needed tocontinue
nameresolution. There aremany waysofdoing this,butconsidering thatthereare
somany different filesystems, eachspecific junction willrequire itsownimple-
mentation. Fortunately, there arealsomany common ways ofaccessing remote
files,including protocols forcommunicating withNFSservers, FTPservers, and
Windows-based machines (notably CIFS).
GNShastheadvantage ofdecoupling thenaming offilesfromtheiractual lo-
cation. Innowaydoesavirtual treerelate towhere filesanddirectories arephysi-
callyplaced. Inaddition, byusing alocation service itisalsopossible tomove
filesaround without rendering theirnames unresolvable. Inthatcase,thenew
physical location needs toberegistered atthelocation service. Notethatthisis
completely thesameaswhatwehavediscussed inChap. 5.
11.5SYNCHRONIZATION
Letusnowcontinue ourdiscussion byfocusing onsynchronization issues in
distributed filesystems. There arevarious issues thatrequire ourattention. Inthe
firstplace, synchronization forfilesystems would notbeanissueiffileswerenot
shared. However, inadistributed system, thesemantics offilesharing becomes a
bittricky when performance issues areatstake. Tothisend,different solutions
havebeenproposed ofwhich wediscuss themostimportant onesnext.
11.5.1Semantics ofFileSharing
When twoormoreuserssharethesamefileatthesametime,itisnecessary
todefine thesemantics ofreading andwriting precisely toavoid problems. Insin-
gle-processor systems thatpermit processes toshare files, suchasUNIX, the
semantics normally statethatwhenareadoperation follows awriteoperation, the
readreturns thevalue justwritten, asshown inFig.11-16(a). Similarly, when
twowrites happen inquick succession, followed byaread,thevalue readisthe
value stored bythelastwrite. Ineffect, thesystem enforces anabsolute time514 DISTRIBUTED FILESYSTEMS CHAP. II
ordering onalloperations andalways returns themostrecent value. Wewillrefer
tothismodel asUNIX semantics. Thismodel iseasytounderstand andstraight-
forward toimplement.
Figure 11-16. (a)Onasingle processor. when aread follows awrite, thevalue
returned bytheread isthevalue justwritten. (b)Inadistributed system with
caching, obsolete values maybereturned.
Inadistributed system, UNIX semantics canbeachieved easily aslongas
thereisonlyonefileserver andclients donotcache files.Allreads andwrites go
directly tothefileserver, which processes them strictly sequentially. Thisap-
proach givesUNIX semantics (except fortheminor problem thatnetwork delays
maycause areadthatoccurred amicrosecond afterawritetoarrive attheserver
firstandthusgetstheoldvalue).
Inpractice, however, theperformance ofadistributed system inwhich allfile
requests mustgotoasingle server isfrequently poor.Thisproblem isoftensolved
byallowing clients tomaintain localcopies ofheavily-used filesintheirprivate
(local) caches. Although wewilldiscuss thedetails offilecaching below, forthe
moment itissufficient topointoutthatifaclient locally modifies acached file
andshortly thereafter another client readsthefilefromtheserver, thesecond cli-
entwillgetanobsolete file,asillustrated inFig.11-16(b).SEC. 11.5 SYNCHRONIZATION 515
Onewayoutofthisdifficulty istopropagate allchanges tocached filesback
totheserver immediately. Although conceptually simple, thisapproach isineffi-
cient. Analternative solution istorelaxthesemantics offilesharing. Instead of
requiring areadtoseetheeffects ofallprevious writes, onecanhaveanewrule
thatsays:"Changes toanopenfileareinitially visible onlytotheprocess (orpos-
siblymachine) thatmodified thefile.Onlywhenthefileisclosed arethechanges
made visible tootherprocesses (ormachines)." Theadoption ofsucharuledoes
notchange whathappens inFig.11-16(b). butitdoesredefine theactual behavior
(Bgetting theoriginal value ofthefile)asbeing thecorrect one.When Acloses
thetile,itsends acopytotheserver, sothatsubsequent readsgetthenewvalue,
asrequired. .
Thisruleiswidely-implemented andisknown assession semantics. Most
distributed filesystems implement session semantics. Thismeans thatalthough in
theory theyfollow theremote access model ofFig.ll-l(a), mostimplementations
make useoflocalcaches, effectively implementing theupload/download model of
Fig.11-l(b).
Usingsession semantics raises thequestion ofwhathappens iftwoormore
clients aresimultaneously caching andmodifying thesamefile.Onesolution isto
saythataseachfileisclosed inturn,itsvalue issentbacktotheserver, sothe
finalresult depends onwhose close request ismostrecently processed bythe
server. Alesspleasant, buteasier toimplement alternative istosaythatthefinal
result isoneofthecandidates, butleavethechoice ofwhich oneunspecified.
Acompletely different approach tothesemantics offilesharing inadistrib-
utedsystem istomakeallfilesimmutable. There isthusnowaytoopenafilefor
writing. Ineffect, theonlyoperations onfilesarecreate andread.
What ispossible istocreate anentirely newfileandenteritintothedirectory
system under thename ofaprevious existing file,which nowbecomes inacces-
sible(atleastunder thatname). Thusalthough itbecomes impossible tomodify
thefilex,itremains possible toreplace xbyanewfileatomically. Inotherwords,
although filescannot beupdated, directories canbe.Oncewehavedecided that
filescannot bechanged atall,theproblem ofhowtodealwithtwoprocesses, one
ofwhich iswriting onafileandtheotherofwhich isreading it,justdisappears,
greatly simplifying thedesign.
What doesremain istheproblem ofwhathappens whentwoprocesses tryto
replace thesamefileatthesametime.Aswithsession semantics, thebestsolu-
tionhereseems tobetoallow oneofthenewfilestoreplace theoldone,either
thelastoneornondeterministically.
Asomewhat stickier problem iswhattodoifafileisreplaced while another
process isbusyreading it.Onesolution istosomehow arrange forthereader to
continue using theoldfile,evenifitisnolonger inanydirectory, analogous to
thewayUNIX allows aprocess thathasafileopentocontinue usingit,evenafter
ithasbeendeleted fromalldirectories. Another solution istodetect thatthefile
haschanged andmakesubsequent attempts toreadfromitfail.516 DISTRIBUTED FILESYSTEMS CHAP. 11
Afourth waytodealwithshared filesinadistributed system istouse
atom\%ic transactions. Tosummarize briefly. toaccess afileoragroup offiles,a
process firstexecutes some typeofBEGIN_TRANSACTION primitive tosignal
thatwhatfollows mustbeexecuted indivisibly. Thencome system callstoread
andwriteoneormorefiles.When therequested workhasbeencompleted, an
END_ TRANSACTION primitive isexecuted. Thekeyproperty ofthismethod is
thatthesystem guarantees thatallthecallscontained within thetransaction Will
becarried outinorder, without anyinterference fromother, concurrent tran-
sactions. Iftwoormoretransactions startupatthesametime,thesystem ensures
thatthefinalresult isthesameasiftheywereallruninsome(undefined) sequen-
tialorder.
InFig.11-17 wesummarize thefourapproaches wehavediscussed fordeal-
ingwithshared filesinadistributed system.
Figure 11-17. Fourwaysofdealing withtheshared filesinadistributed system.
11.5.2 FileLocking
Notably inclient-server architectures withstateless servers, weneedaddition-
alfacilities forsynchronizing access toshared files.Thetraditional wayofdoing
thisistomakeuseofalockmanager. Without exception, alockmanager follows
thecentralized locking scheme aswediscussed inChap. 6.
However, matters arenotassimple aswejustsketched. Although acentral
lockmanager isgenerally deployed, thecomplexity inlocking comes fromthe
needtoallow concurrent access tothesamefile.Forthisreason, agreatnumber
ofdifferent locksexist,andmoreover, thegranularity oflocksmayalsodiffer. Let
usconsider NFSv4 again.
Conceptually, filelocking inNFSv4 issimple. There areessentially onlyfour
operations related tolocking, asshown inFig.11-18. NFSv4 distinguishes read
locksfromwritelocks. Multiple clients cansimultaneously access thesamepart
ofafileprovided theyonlyreaddata.Awritelockisneeded toobtain exclusive
access tomodify partofafile.
Operation lockisusedtorequest areadorwritelockonaconsecutive range
ofbytesinafile.Itisanonblocking operation: ifthelockcannot begranted due
toanother conflicting lock,theclient getsbackanerrormessage andhastopoll
theserver atalatertime.There isnoautomatic retry. Alternatively, theclient canSEC. 11.5 SYNCHRONIZATION 517
Figure 11-18. NFSv4 operations related tofilelocking.
request tobeputonaFIFO-ordered listmaintained bytheserver. Assoonasthe
conflicting lockhasbeenremoved, theserver willgrantthenextlocktotheclient
atthetopofthelist,provided itpollstheserver before acertain timeexpires. This
approach prevents theserver fromhaving tonotify clients, while stillbeing fairto
clients whose lockrequest could notbegranted because grants aremade inFIFO
order.
Thelocktoperation isusedtotestwhether aconflicting lockexists. Forex-
ample, aclient cantestwhether thereareanyreadlocksgranted onaspecific
range ofbytesinafile,before requesting awritelockforthosebytes. Inthecase
ofaconflict, therequesting client isinformed exactly whoiscausing theconflict
andonwhich range ofbytes. Itcanbeimplemented moreefficiently thanlock,be-
cause thereisnoneedtoattempt toopenafile.
Removing alockfromafileisdonebymeans ofthelockuoperation.
Locks aregranted foraspecific time(determined bytheserver). Inother
words, theyhaveanassociated lease. Unless aclient renews theleaseonalockit
hasbeengranted, theserver willautomatically remove it.Thisapproach isfol-
lowed forother server-provided resources aswellandhelps inrecovery after
failures. Using therenew operation, aclient requests theserver torenew thelease
onitslock(and,infact,otherresources aswell).
Inaddition totheseoperations, there isalsoanimplicit waytolockafile,
referred toassharereservation. Share reservation iscompletely independent
fromlocking, andcanbeusedtoimplement NFSforWindows-based systems.
When aclient opens afile,itspecifies thetypeofaccess itrequires (namely
READ, WRITE, orBOTH), andwhich typeofaccess theserver should denyother
clients (NONE, READ, WRITE, orBOTH). Iftheserver cannot meettheclient's
requirements, theopenoperation willfailforthatclient. InFig.11-19 weshow
exactly whathappens when anewclient opens afilethathasalready beensuc-
cessfully opened byanother client. Foranalready opened file,wedistinguish two
different statevariables. Theaccess statespecifies howthefileiscurrently being
accessed bythecurrent client. Thedenial statespecifies whataccesses bynewcli-
entsarenotpermitted.
InFig.11-19(a), weshowwhathappens when aclient triestoopenafilere-
questing aspecific typeofaccess, given thecurrent denial stateofthatfile.518 DISTRIBUTED FILESYSTEMS CHAP. 11
Figure 11-19. Theresult ofanopen operation withshare reservations inNFS.
(a)When theclient requests shared access given thecurrent denial state.
(b)When theclient requests adenial stategiven thecurrent fileaccess state.
Likewise, Fig.11-19(b) shows theresult ofopening afilethatiscurrently being
accessed byanother client, butnowrequesting certain access types tobedisal-
lowed.
NFSv4 isbynomeans anexception when itcomes tooffering synchroniza-
tionmechanisms forshared files.Infact,itisbynowaccepted thatanysimple set
ofprimitives suchasonlycomplete-file locking, reflects poordesign. Complexity
inlocking schemes comes mostly fromthefactthatafinegranularity oflocking is
required toallow forconcurrent access toshared files.Some attempts toreduce
complexity while keeping performance havebeentaken [see,e.g.,Bums etal.
(2001)], butthesituation remains somewhat unsatisfactory. Intheend,wemaybe
looking atcompletely redesigning ourapplications forscalability rather thantry-
ingtopatch situations thatcome fromwanting toshare datathewaywedidin
nondistributed systems.
11.5.3SharingFilesinCoda
Thesession semantics inNFSdictate thatthelastprocess thatcloses afile
willhaveitschanges propagated totheserver; anyupdates inconcurrent, butear-
liersessions willbelost.Asomewhat moresubtle approach canalsobetaken. To
accommodate filesharing, theCodafilesystem (Kistler andSatyanaryanan, 1992)
usesaspecial allocation scheme thatbears somesimilarities tosharereservations
inNFS.Tounderstand howthescheme works. thefollowing isimportant. When a
client successfully opens afile1,anentire copyoffistransferred totheclient'sSEC. 11.5 SYNCHRONIZA nON 519
machine. Theserver records thattheclient hasacopyoff.Sofar,thisapproach is
similar toopendelegation inNFS.
Nowsuppose client Ahasopened filefforwriting. When another client B
wants toopenfaswell,itwillfail.Thisfailure iscaused bythefactthatthe
server hasrecorded thatclient Amight havealready modified f.Ontheother
hand, hadclient Aopened fforreading, anattempt byclient Btogetacopyfrom
theserver forreading would succeed. Anattempt byBtoopenforwriting would
succeed aswell.
Nowconsider whathappens whenseveral copies offhave beenstored locally
atvarious clients. Given whatwehavejustsaid,onlyoneclient willbeableto
modify f.Ifthisclient modifies fandsubsequently closes thefile,thefilewillbe
transferred backtotheserver. However, every otherclient mayproceed toreadits
localcopydespite thefactthatthecopyisactually outdated.
Thereason forthisapparently inconsistent behavior isthatasession istreated
asatransaction inCoda. Consider Fig.11-20, which shows thetimelinefortwo
processes, AandB.Assume Ahasopened fforreading, leading tosession SA·
Client Bhasopened fforwriting, shown assession S8·
Figure 11·20. Thetransactional behavior insharing filesinCoda.
When Bcloses session S8'ittransfers theupdated version offtotheserver,
which willthensendaninvalidation message toA.Awillnowknow thatitis
reading fromanolderversion off.However, fromatransactional pointofview,
thisreally doesnotmatter because session SAcould beconsidered tohavebeen
scheduled before session S8.
11.6CONSISTENCY ANDREPLICATION
Caching andreplication playanimportant roleindistributed filesystems,
mostnotably when theyaredesigned tooperate overwide-area networks. Inwhat
follows, wewilltakealookatvarious aspects related toclient-side caching offile520 DISTRIBUTED FILESYSTEMS CHAP. 11
data,aswellasthereplication offileservers. Also, weconsider theroleofrepli-
cation inpeer-to-peer file-sharing systems.
11.6.1 Client-Side Caching
Toseehowclient-side caching isdeployed inpractice, wereturn toourex-
ample systems NFSandCoda.
Caching inNFS
Caching inNFSv3 hasbeenmainly leftoutside oftheprotocol. Thisapproach
hasledtotheimplementation ofdifferent caching policies, mostofwhich never
guaranteed consistency. Atbest,cached datacould bestaleforafewseconds
compared tothedatastored ataserver. However, implementations alsoexistthat
allowed cached datatobestalefor30seconds without theclient knowing. This
stateofaffairs islessthandesirable.
NFSv4 solves someoftheseconsistency problems, butessentially stillleaves
cache consistency tobehandled inanimplementation-dependent way.Thegener-
alcaching model thatisassumed byNFSisshown inFig.11-21. Eachclient can
haveamemory cache thatcontains datapreviously readfromtheserver. Inaddi-
tion,theremayalsobeadiskcache thatisadded asanextension tothememory
cache, usingthesameconsistency parameters.
Figure 11-21. Client-side caching inNFS.
Typically, clients cache filedata,attributes, filehandles, anddirectories. Dif-
ferent strategies existtohandle consistency ofthecached data,cached attributes,
andsoon.Letusfirsttakealookatcaching filedata.
NFSv4 supports twodifferent approaches forcaching filedata.Thesimplest
approach iswhen aclient opens afileandcaches thedataitobtains fromthe
server astheresult ofvarious readoperations. Inaddition, writeoperations canbe
carried outinthecache aswell.When theclient closes thefile,NFSrequires thatSEC. 11.6 CONSISTENCY AND REPLICA nON 521
ifmodifications havetakerrpl-a€e,th~ cached datamustbeflushed backtothe
server. Thisapproach corresponds toimplementing session semantics asdiscussed
earlier.
Once (partot)afilehasbeencached, aclient cankeepitsdatainthecache
evenafterclosing thefile.Also, several clients onthesamemachine cansharea
single cache. NFSrequires thatwhenever aclient opens apreviously closed file
thathasbeen(partly) cached, theclient mustimmediately revalidate thecached
data.Revalidation takesplace bychecking when thefilewaslastmodified and
invalidating thecache incaseitcontains staledata.
InNFSv4 aserver maydelegate someofitsrights toaclient when afileis
opened. Opendelegation takes place when theclient machine is.allowed to
locally handle openandcloseoperations fromotherclients onthesamemachine.
Normally, theserver isincharge ofchecking whether opening afileshould
succeed ornot,forexample, because sharereservations needtobetaken intoac-
count. Withopendelegation, theclient machine issometimes allowed tomake
suchdecisions, avoiding theneedtocontact theserver.
.Forexample, ifaserver hasdelegated theopening ofafiletoaclient thatre-
quested write permissions, filelocking requests fromother clients onthesame
machine canalsobehandled locally. Theserver willstillhandle locking requests
fromclients onothermachines, bysimply denying thoseclients access tothefile.
Notethatthisscheme doesnotworkinthecaseofdelegating afiletoaclient that
requested onlyreadpermissions. Inthatcase,whenever another localclient wants
tohavewritepermissions, itwillhavetocontact theserver; itisnotpossible to
handle therequest locally.
Animportant consequence ofdelegating afiletoaclient isthattheserver
needs tobeabletorecall thedelegation, forexample, when another client ona
different machine needs toobtain access rights tothefile.Recalling adelegation
requires thattheserver candoacallback totheclient, asillustrated inFig.11-22.
Figure 11-22. Using theNFSv4 callback mechanism torecall filedelegation.
Acallback isimplemented inNFSusing itsunderlying RPCmechanisms.
Note, however, thatcallbacks require thattheserver keeps trackofclients to
which ithasdelegated afile.Here, weseeanother example where anNFSserver522 DISTRIBUTED FILE SYSTEMS CHAP. 11
-----------------
cannolonger beimplemented inastateless manner. Note, how-ever,lfiatihe com-
bination ofdelegation andstateful servers mayleadtovarious problems inthe
presence ofclient andserver failures. Forexample, what should aserver dowhen
ithaddelegated afiletoanowunresponsive client? Aswediscuss shortly, leases
willgenerally formanadequate practical solution.
Clients canalsocache attribute values, butarelargely leftontheirownwhen
itcomes tokeeping cached values consistent. Inparticular, attribute values ofthe
same filecached bytwodifferent clients maybedifferent unless theclients keep
these attributes mutually consistent. Modifications toanattribute value should be
immediately forwarded totheserver, thusfollowing awrite-through cache coher-
encepolicy.
Asimilar approach isfollowed forcaching filehandles (orrather; thename-
to-file handle mapping) anddirectories. Tomitigate theeffects ofinconsistencies,
NFSusesleases oncached attributes, filehandles, anddirectories. After some
timehaselapsed, cache entries arethusautomatically invalidated andrevalidation
isneeded before theyareusedagain.
Client-Side Caching inCoda
Client-side caching iscrucial totheoperation ofCoda fortworeasons. First,
caching isdonetoachieve scalability. Second, caching provides ahigher degree
offaulttolerance astheclient becomes lessdependent ontheavailability ofthe
server. Forthese tworeasons, clients inCoda always cache entire files. Inother
words, when afileisopened foreither reading orwriting, anentire copy ofthe
fileistransferred totheclient, where itissubsequently cached.
Unlike many other distributed filesystems. cache coherence inCoda ismain-
tained bymeans ofcallbacks. Wealready came across thisphenomenon when dis-
cussing file-sharing semantics. Foreachfile,theserver from which aclient had
fetched thefilekeeps track ofwhich clients have acopy ofthatfilecached lo-
cally. Aserver issaidtorecord acallback promise foraclient. When aclient
updates itslocal copy ofthefileforthefirsttime, itnotifies theserver, which, in
tum,sends aninvalidation message totheother clients. Such aninvalidation mes-
sageiscalled acallback break, because theserver willthendiscard thecallback
promise itheldfortheclient itjustsentaninvalidation.
Theinteresting aspect ofthisscheme isthataslongasaclient knows ithasan
outstanding callback promise attheserver, itcansafely access thefilelocally. In
particular, suppose aclient opens afileandfinds itisstillinitscache. Itcanthen
usethatfileprovided theserver stillhasacallback promise onthefileforthatcli-
ent.Theclient willhavetocheck withtheserver ifthatpromise stillholds. Ifso,
there isnoneedtotransfer thefilefromtheserver totheclient again.
Thisapproach isillustrated inFig.11-23, which isanextension ofFig.11-20.
When client Astarts session SA,theserver records acallback promise. Thesame
happens when Bstarts session SB'However, when Bcloses SB,theserver breaksFigure 11-23. Theuseoflocalcopies when opening asession inCoda.
Theconsequence isthatwhen Alaterwants toopensession SA,itwillfindits
localcopyofftobeinvalid, sothatitwillhavetofetchthelatest version fromthe
server. Ontheother hand, when Bopens session Ss,itwillnotice thattheserver
stillhasanoutstanding callback promise implying thatBcansimply re-use the
localcopyitstillhasfromsession SB'
Client-Side Caching forPortable Devices
Oneimportant development formany distributed systems isthatmany storage
devices cannolonger beassumed tobepermanently connected tothesystem
through anetwork. Instead, users havevarious types ofstorage devices thatare
semi-permanently connected, forexample, through cradles ordocking stations.
Typical examples include PDAs, laptop devices, butalsoportable multimedia de-
vices suchasmovie andaudio players.
Inmostcases, anexplicit upload/download model isusedformaintaining files
onportable storage devices. Matters canbesimplified ifthestorage device is
viewed aspartofadistributed filesystem. Inthatcase, whenever afileneeds to
beaccessed, itmaybefetched fromthelocaldevice orovertheconnection tothe
restofthesystem. These twocases needtobedistinguished.
Tolia etal.(2004) propose totakeaverysimple approach bystoring locally a
cryptographic hashofthedatacontained infiles. These hashes arestored onthe
portable device andusedtoredirect requests forassociated content. Forexample,
when adirectory listing isstored locally, instead ofstoring thedataofeachlisted
tile,onlythecomputed hasisstored. Then, when afileisfetched, thesystem will
firstcheck whether thefileislocally available andup-to-date. Note thatastaleSEC. 11.6
itspromise tocallback client Abysending Aacallback break. Notethatduetothe
transactional semantics ofCoda, when client Acloses session SA,nothing special
happens; theclosing issimply accepted asonewould expect.523 CONSISTENCY AND REPLICATION524 DISTRIBUTED FILESYSTEMS CHAP. ]1
filewillhaveadifferent hashthantheonestored inthedirectory listing. Ifthefile
islocally available, itcanbereturned totheclient, otherwise adatatransfer will
needtotakeplace.
Obviously, whenadevice isdisconnected itwillbeimpossible totransfer any
data.Various techniques existtoensure withhighprobability thatlikely to-be-
usedfilesareindeed stored locally onthedevice. Compared totheon-demand
datatransfer approach inherent tomostcaching schemes, inthesecaseswewould
needtodeploy file-prefetching techniques. However, formany portable storage
devices, wecanexpect thattheuserwillusespecial programs topre-install files
onthedevice.
11.6.2 Server-Side Replication
Incontrast toclient-side caching, server-side replication indistributed file
systems islesscommon. Ofcourse, replication isapplied when availability isat
stake, butfromaperformance perspective itmakes more sense todeploy caches
inwhich awhole file,orotherwise largepartsofit,aremade locally available toa
client. Animportant reason whyclient-side caching issopopular isthatpractice
shows thatfilesharing isrelatively rare.When sharing takesplace, itisoftenonly
forreading data,inwhich casecaching isanexcellent solution.
Another problem withserver-side replication forperformance isthatacombi-
nation ofahighdegree ofreplication andalowread/write ratiomayactually
degrade performance. Thisiseasytounderstand when realizing thatevery update
operation needs tobecarried outatevery replica. Inotherwords, foranN-fold
replicated file,asingle update request willleadtoanN-fold increase ofupdate
operations. Moreover, concurrent updates needtobesynchronized, leading to
morecommunication andfurther performance reduction.
Forthesereasons, fileservers aregenerally replicated onlyforfaulttolerance.
Inthefollowing, weillustrate thistypeofreplication fortheCodafilesystem.
Server Replication inCoda
Codaallows fileservers tobereplicated. Aswementioned, theunitofrepli-
cation isacollection offilescalled avolume. Inessence, avolume corresponds
toaUNIX diskpartition, thatis,atraditional filesystem liketheonesdirectly sup-
ported byoperating systems, although volumes aregenerally much smaller. The
collection ofCoda servers thathaveacopyofavolume, areknown asthat
volume's Volume Storage Group, orsimply VSG. Inthepresence offailures, a
client maynothaveaccess toallservers inavolume's VSG. Aclient's Accessi-
bleVolume Storage Group (AVSG) foravolume consists ofthose servers in
thatvolume's VSGthattheclient cancontact atthemoment. IftheAVSGis
empty, theclient issaidtobedisconnected.SEC. 11.6 CONSISTENCY AND REPLICA nON 525
Coda usesareplicated-write protocol tomaintain consistency ofareplicated
volume. Inparticular, itusesavariant ofRead-One, Write-All (ROW A),which
wasexplained inChap. 7.When aclient needs toreadafile,itcontacts oneofthe
members initsAVSGofthevolume towhich thatfilebelongs. However, when
closing asession onanupdated file,theclient transfers itinparallel toeach
member intheAVSG. Thisparallel transfer isaccomplished bymeans ofMul-
tiRPC asexplained before.
Thisscheme works fineaslongastherearenofailures, thatis,foreachclient,
thatclient's AVSGofavolume isthesameasitsVSG. However, inthepresence
offailures, things maygowrong. Consider avolume thatisreplicated across three
servers 81,82,and83,Forclient A,assume itsAVSGcovers servers 81and82
whereas client Bhasaccess onlytoserver 83,asshown inFig.11-24.
Codausesanoptimistic strategy forfilereplication. Inparticular, bothAand
Bwillbeallowed toopenafile,f,forwriting, update theirrespective copies, and
transfer theircopybacktothemembers intheirAVSG. Obviously, therewillbe
different versions oftstored intheVSG. Thequestion ishowthisinconsistency
canbedetected andresolved.
Thesolution adopted byCodaisdeploying aversioning scheme. Inparticular,
aserver SjinaVSGmaintains aCoda version vector CV\ti(f) foreachfiletcon-
tained inthatVSG. IfCV\ti(f)U] =k,thenserver Sjknows thatserver ~hasseen
atleastversion koffilefCV\ti(f)[i] isthenumber ofthecurrent version oft
stored atserver 8i. Anupdate oftatserver Sjwillleadtoanincrement of
CV\ti(f)[i]. Notethatversion vectors arecompletely analogous tothevector
timestamps discussed inChap. 6.
Returning toourthree-server example, CV\ti(f) isinitially equalto[1,1,1] for
eachserver Sj.When client Areadstfrom oneoftheservers initsAVSG, say81,
italsoreceives CWI (f).After updating f,clientAmulticasts ftoeachserver in
itsAVSG, thatis,81and82,Bothservers willthenrecord thattheirrespective
copyhasbeenupdated, butnotthatof83,Inotherwords,Figure 11-24. Twoclients withadifferent AVSG forthesamereplicated file.526DISTRIBUTED FILESYSTEMSCHAP. 11
Meanwhile, client Bwillbeallowed toopenasession inwhich itreceives a
copyofffromserver S3,andsubsequently update faswell.When closing itsses-
sionandtransferring theupdate toS3,server S3willupdate itsversion vector to
CW3(f)=[l,1,2J.When thepartition ishealed, thethreeservers willneedtoreintegrate their
copies off.Bycomparing theirversion vectors, theywillnotice thataconflict has
occurred thatneeds toberepaired. Inmany cases, conflict resolution canbeauto-
mated inanapplication-dependent way,asdiscussed inKumar andSatyanaray-
anan(1995). However, therearealsomany cases inwhich users willhaveto
assist inresolving aconflict manually, especially when different users have
changed thesamepartofthesamefileindifferent ways.
11.6.3 Replication inPeer-to-Peer FileSystems
Letusnowexamine replication inpeer-to-peer file-sharing systems. Here,
replication alsoplaysanimportant role,notably forspeeding upsearch andlook-
uprequests, butalsotobalance loadbetween nodes. Animportant property in
thesesystems isthatvirtually allfilesarereadonly.Updates consist onlyinthe
formofadding filestothesystem. Adistinction should bemadebetween unstruc-
turedandstructured peer-to-peer systems.
Unstructured Peer-to-Peer Systems
Fundamental tounstructured peer-to-peer systems isthatlooking updataboils
down tosearching thatdatainthenetwork. Effectively, thismeans thatanode
willsimply haveto,forexample, broadcast asearch query toitsneighbors, from
where thequery maybeforwarded, andsoon.Obviously, searching through ~~
broadcasting isgenerally notagoodidea,andspecial measures needtobetaken
toavoid performance problems. Searching inpeer-to-peer systems isdiscussed
extensively inRisson andMoors (2006).
Independent ofthewaybroadcasting islimited, itshould beclearthatiffiles
arereplicated, searching becomes easier andfaster. Oneextreme istoreplicate a
fileatallnodes, which would imply thatsearching foranyfilecanbedoneen-
tirelylocal. However, given thatnodes havealimited capacity, fullreplication is
outofthequestion. Theproblem isthentofindanoptimal replication strategy,
where optimality isdefined bythenumber ofdifferent nodes thatneedtoprocess
aspecific query before afileisfound.
Cohen andShenker (2002) haveexamined thisproblem, assuming thatfile
replication canbecontrolled. Inotherwords, assuming thatnodes inanunstruc-
turedpeer-to-peer system canbeinstructed toholdcopies offiles,whatisthenthe.-
bestallocation offilecopies tonodes?
Letusconsider twoextremes. Onepolicy istouniformly distribute 11copies
ofeachfileacross theentire network. Thispolicy ignores thatdifferent filesmaySEC. 11.6 CONSISTENCY AND REPLICATION 527
havedifferent request rates, thatis,thatsomefilesaremorepopular thanothers.
Asanalternative, another policy istoreplicate filesaccording tohowoftenthey
aresearched for:themorepopular afileis,themorereplicas wecreate anddistri-
buteacross theoverlay.
Asasideremark, notethatthislastpolicy maymake itveryexpensive to
locate unpopular files.Strange asthismayseem, suchsearches mayprove tobe
increasingly important fromaneconomic pointofview. Thereasoning issimple:
withtheInternet allowing fastandeasyaccess totonsofinformation, exploiting
nichemarkets suddenly becomes attractive. So,ifyouareinterested ingetting the
rightequipment for,let'ssayarecumbent bicycle, theInternet istheplace togo
toprovided itssearch facilities willallow youtoefficiently discover theappropri-
ateseller.
Quite surprisingly, itturnsoutthattheuniform andthepopular policy perform
justasgoodwhenlooking attheaverage number ofnodes thatneedtobequeried.
Thedistribution ofqueries isthesameinbothcases, andsuchthatthedistribution
ofdocuments inthepopular policy follows thedistribution ofqueries. Moreover,
itturnsoutthatanyallocation "between" thesetwoisbetter. Obtaining suchan
allocation isdoable, butnottrivial.
Replication inunstructured peer-to-peer systems happens naturally when
users download filesfromothers andsubsequently make themavailable tothe
community. Controlling thesenetworks isverydifficult inpractice, except when
partsarecontrolled byasingle organization. Moreover, asindicated bystudies
conducted onBitTorrent, thereisalsoanimportant social factor whenitcomes to
replicating filesandmaking themavailable (Pouwelse etal.,2005). Forexample,
somepeople showaltruistic behavior, orsimply continue tomake filesnolonger
available thanstrictly necessary aftertheyhavecompleted theirdownload. The
question comes tomindwhether systems canbedevised thatexploit thisbehavior.
Structured Peer-to-Peer Systems
Considering theefficiency oflookup operations instructured peer-to-peer sys-
tems,replication isprimarily deployed tobalance theloadbetween thenodes. We
already encountered inChap. 5howa"structured" form ofreplication, as
exploited byRamasubramanian andSirer(2004b) could evenreduce theaverage
lookup stepstoO(1).However, when itcomes toloadbalancing, different ap-
proaches needtobeexplored.
Onecommonly applied method istosimply replicate afilealong thepaththat
aquery hasfollowed fromsource todestination. Thisreplication policy willhave
theeffect thatmostreplicas willbeplaced closetothenoderesponsible forstor-
ingthefile,andwillthusindeed offload thatnodewhen thereisahighrequest
rate.However, suchareplication policy doesnottaketheloadofothernodes into
account, andmaythuseasily leadtoanimbalanced system.528 DISTRIBUTED FILESYSTEMS CHAP. 11
Toaddress theseproblems, Gopalakrishnan etal.(2004) propose adifferent
scheme thattakes thecurrent loadofnodes along thequery route intoaccount.
Theprincipal ideaistostorereplicas atthesource nodeofaquery, andtocache
pointers tosuchreplicas innodes alongthequery routefromsource todestination.
More specifically, when aquery fromnodePtoQisrouted through nodeR,R
willcheck whether anyofitsfilesshould beoffloaded toP.Itdoessobysimply
looking atitsownquery load.IfRisserving toomany lookup requests forfilesit
iscurrently storing incomparison totheloadimposed onP,itcanaskPtoinstall
copies ofR'smostrequested files.Thisprinciple issketched inFig.11-25.
Figure 11-25. Balancing loadinapeer-to-peer system byreplication.
IfPcanaccept fileffromR,eachnodevisited ontheroute fromPtoRwill
install apointer forftoP,indicating thatareplica offcanbefound atP.
Clearly, disseminating information onwhere replicas arestored isimportant
forthisscheme towork. Therefore, when routing aquery through theoverlay, a
nodemayalsopassoninformation concerning thereplicas itishosting. Thisin-
formation maythenleadtofurther installment ofpointers, allowing nodes totake
informed decisions ofredirecting requests tonodes thatholdareplica ofare-
quested file.These pointers areplaced inalimited-size cache andarereplaced
following asimple least-recently usedpolicy (i.e.,cached pointers referring to
filesthatarenever asked for,willberemoved quickly).
11.6.4FileReplication inGridSystems
Asourlastsubject concerning replication offiles,letusconsider whathap-
pensinGridcomputing. Naturally, performance playsacrucial roleinthisareaas
many Gridapplications arehighly compute-intensive. Inaddition, weseethatap-
plications oftenalsoneedtoprocess vastamounts ofdata.Asaresult, much effort
hasbeenputintoreplicating filestowhere applications arebeing executed. The
means todoso,however, are(somewhat) surprisingly simple.
Akeyobservation isthatinmany Gridapplications dataarereadonly.Data
areoftenproduced fromsensors, orfromotherapplications, butrarely updated or
otherwise modified aftertheyareproduced andstored. Asaresult, datareplica-
tioncanbeapplied inabundance, andthisisexactly whathappens.SEC. 11.6 CONSISTENCY AND REPLICATION 529
Unfortunately, thesizeofthedatasetsaresometimes soenormous thatspe-
cialmeasures need tobetaken toavoid thatdataproviders (i.e.,those machine
storing datasets)become overloaded duetotheamount ofdatatheyneedtotrans-
feroverthenetwork. Ontheother hand, because much ofthedataisheavily repli-
cated, balancing theloadforretrieving copies islessofanissue.
Replication inGridsystems mainly evolves around theproblem oflocating
thebestsources tocopydatafrom. Thisproblem canbesolved byspecial replica
location services, verysimilar tothelocation services wediscussed fornaming
systems. Oneobvious approach thathasbeendeveloped fortheGlobus toolkit is
touseaDHT-based system suchasChord fordecentralized lookup ofreplicas
(CaietaI.,2004). Inthiscase, aclient passes afilename toanynodeoftheser-
vice,where itisconverted toakeyandsubsequently looked up.Theinformation
returned totheclient contains contact addresses fortherequested files.
Tokeepmatters simple, located filesaresubsequently downloaded fromvari-
oussitesusing anFTP-like protocol, afterwhich theclient canregister itsown
replicas withthereplication location service. Thisarchitecture isdescribed in
more detail inChervenak etal.(2005), buttheapproach isfairly straightforward.
11.7FAULT TOLERANCE
Fault tolerance indistributed filesystems ishandled according totheprinci-
pleswediscussed inChap. 8.Aswealready mentioned, inmany cases, replica-
tionisdeployed tocreate fault-tolerant server groups. Inthissection, wewill
therefore concentrate onsome special issues infaulttolerance fordistributed file
systems.
11.7.1 Handling Byzantine Failures
Oneoftheproblems thatisoften ignored when dealing withfaulttolerance is
thatservers mayexhibit arbitrary failures. Inother words, most systems donot
consider theByzantine failures wediscussed inChap. 8.Besides complexity, the
reason forignoring these typeoffailures hastodowiththestrong assumptions
thatneed tobemade regarding theexecution environment. Notably, itmust be
assumed thatcommunication delays arebounded.
Inpractical settings, suchanassumption isnotrealistic. Forthisreason, Cas-
troandLiskov (2002) havedevised asolution forhandling Byzantine failures that
canalsooperate innetworks suchastheInternet. Wediscuss thisprotocol here,as
itcan(andhasbeen) directly applied todistributed filesystems, notably anNFS-
based system. Ofcourse, there areother applications aswell.Thebasic ideaisto
deploy active replication byconstructing acollection offinite statemachines and
tohave thenonfaulty processes inthiscollection execute operations inthesame
order. Assuming thatatmostkprocesses failatonce, aclient sends anoperation530 DISTRIBUTED FILESYSTEMS CHAP. 11
totheentire group andaccepts ananswer thatisreturned byatleastk+]dif-
ferent processes.
Toachieve protection against Byzantine failures, theserver group must con-
sistofatleast3k+]processes. Thedifficult partinachieving thisprotection isto
ensure thatnonfaulty processes execute alloperations inthesame order. Asimple
means toachieve thisgoalistoassign acoordinator thatsimply serializes allop-
erations byattaching asequence number toeachrequest. Theproblem. ofcourse,
isthatthecoordinator mayfail.
Itiswithfailing coordinators thattheproblems start. Very much likewithvir-
tualsynchrony, processes gothrough aseries ofviews, where ineachview the
members agree onthenonfaulty processes, andinitiate aview change when the
current master appears tobefailing. Thislatter canbedetected ifweassume that
sequence numbers arehanded outoneaftertheother, sothatagap,oratimeout
foranoperation mayindicate thatsomething iswrong. Note thatprocesses may
falsely conclude thatanewviewneeds tobeinstalled. However, thiswillnotaf-
fectthecorrectness ofthesystem.
Animportant partoftheprotocol relies onthefactthatrequests canbecor-
rectly ordered. Tothisend,aquorum mechanism isused: whenever aprocess
receives arequest toexecute operation 0withnumber ninviewv,itsends thisto
allother processes, andwaits untilithasreceived aconfirmation from atleast2k
others thathave seenthesame request. Inthisway, weobtain aquorum ofsize
2k+1fortherequest. Such aconfirmation iscalled aquorum certificate. In
essence, ittellsusthatasufficiently large number ofprocesses have stored the
same request andthatitisthussafetoproceed.
Thewhole protocol consists offivephases, shown inFig.11-26.
Figure 11-26. Thedifferent phases inByzantine faulttolerance.
During thefirstphase, aclient sends arequest totheentire server group. Once the
master hasreceived therequest, itmulticasts asequence number inapre-prepare
phase sothattheassociated operation willbeproperly ordered. Atthatpoint. the
slave replicas needtoensure thatthemaster's sequence number isaccepted bya
quorum, provided thateachofthem accepts themaster's proposal. Therefore, ifaSEC. 11.7 FAULT TOLERANCE 531
slaveaccepts theproposed sequence number, itmulticasts thisacceptance tothe
others. During thecommit phase, agreement hasbeenreached andallprocesses
inform eachotherandexecute theoperation, afterwhich theclient canfinally see
theresult.
When considering thevarious phases, itmayseem thataftertheprepare
phase. allprocesses should haveagreed onthesameordering ofrequests. How-
ever,thisistrueonlywithin thesameview: iftherewasaneedtochange toanew
view, different processes mayhavethesamesequence number fordifferent opera-
tions, butwhich wereassigned indifferent views. Forthisreason, weneedthe
commit phase aswell,inwhich eachprocess nowtellstheothers thatithasstored
therequest initslocallog,andforthecurrent view. Asaconsequence, evenif
thereisaneedtorecover fromacrash, aprocess willknow exactly which se-
quence number hadbeenassigned, andduring which view.
Again, acommitted operation canbeexecuted assoonasanonfaulty process
hasseenthesame2kcommit messages (andtheyshould match itsowninten-
tions). Again, wenowhaveaquorum of2k+1forexecuting theoperation. Of
course, pending operations withlower sequence numbers should beexecuted first.
Changing toanewviewessentially follows theviewchanges forvirtual syn-
chrony asdescribed inChap. 8.Inthiscase,aprocess needs tosendinformation
onthepre-prepared messages thatitknows of,aswellasthereceived prepared
messages fromtheprevious view.Wewillskipfurther details here.
Theprotocol hasbeenimplemented foranNFS-based filesystem, along with
various important optimizations andcarefully crafted datastructures, ofwhich the
details canbefound inCastro andLiskov (2002). Adescription ofawrapper that
willallow theincorporation ofByzantine faulttolerance withlegacy applications
canbefound inCastro etal.(2003).
11.7.2 HighAvailability inPeer-to-Peer Systems
Anissuethathasreceived special attention isensuring availability inpeer-to
peersystems. Ontheonehand, itwould seem thatbysimply replicating files
availability iseasytoguarantee. Theproblem, however, isthattheunavailabilitj
ofnodes issohighthatthissimple reasoning nolonger holds. Asweexplained iI
Chap. 8,thekeysolution tohighavailability isredundancy. When itcomes t<
files,thereareessentially twodifferent methods torealize redundancy: replicatior
anderasure coding.
Erasure coding isawell-known technique bywhich afileispartitioned intc
mfragments which aresubsequently recoded inton>mfragments. Thecrucia
issueinthiscoding scheme isthatanysetofmencoded fragments issufficient tc
reconstruct theoriginal file.Inthiscase, theredundancy factor isequal tc
rec=.n/m. Assuming anaverage nodeavailability ofa,andarequired fileunavai-
lability ofE,weneedtoguarantee thatatleastmfragments areavailable, thatis:532 DISTRIBUTED FILESYSTEMS CHAP. 11
Ifwecompare thistoreplicating files,weseethatfileunavailability iscompletely
dictated bytheprobability thatallitsrrep replicas areunavailable. Ifweassume
thatnodedepartures areindependent andidentically distributed. wehave
1-E=1-(1-a/rep
Applying some algebraic manipulations andapproximations. wecanexpress the
difference between replication anderasure coding byconsidering theratiorrep/'rec
initsrelation totheavailability aofnodes. Thisrelation isshown inFig.11-27,
forwhich wehaveset111=5[seealsoBhagwan etal.(2004) andRodrigues and
Liskov (2005)].
Figure 11-27. Theratiorrep/rec asafunction ofnodeavailability a.
What weseefromthisfigure isthatunder allcircumstances, erasure coding
requires lessredundancy thansimply replicating files.Inotherwords, replicating
filesforincreasing availability inpeer-to-peer networks inwhich nodes regularly
come andgoislessefficient fromastorage perspective thanusing erasure coding
techniques.
Onemayargue thatthesesavings instorage arenotreally anissueanymore as
diskcapacity isoftenoverwhelming. However, when realizing thatmaintaining
redundancy willimpose communication, thenlower redundancy isgoing tosave
bandwidth usage. Thisperformance gainisnotably important when thenodes
correspond tousermachines connected totheInternet through asymmetric DSL
orcable lines, where outgoing linksoftenhaveacapacity ofonlyafewhundred
Kbps.
11.8SECURITY
Many ofthesecurity principles thatwediscussed inChap. 9aredirectly
applied todistributed filesystems. Security indistributed filesystems organized
along aclient-server architecture istohavetheservers handle authentication andSEC. 11.8 SECURITY 533
access control. Thisisastraightforward wayofdealing withsecurity, anapproach
thathasbeenadopted, forexample, insystems suchasNFS.
Insuchcases, itiscommon tohaveaseparate authentication service, suchas
Kerberos, while thefileservers simply handle authorization. Amajor drawback of
thisscheme isthatitrequires centralized administration ofusers, which may
severely hinder scalability. Inthefollowing, wefirstbriefly discuss security in
NFSasanexample ofthetraditional approach, afterwhich wepayattention to
alternative approaches.
11.8.1 Security inNFS
Aswementioned before, thebasicideabehind NFSisthataremote filesys-
temshould bepresented toclients asifitwerealocalfilesystem. Inthislight,it
should come asnosurprise thatsecurity inNFSmainly focuses onthecommuni-
cation between aclient andaserver. Secure communication means thatasecure
channel between thetwoshould besetupaswediscussed inChap. 9.
Inaddition tosecure RPCs, itisnecessary tocontrol fileaccesses. which are
handled bymeans ofaccess control fileattributes inNFS. Afileserver isin
charge ofverifying theaccess rights ofitsclients, aswewillexplain below. Com-
bined withsecure RPCs, theNFSsecurity architecture isshown inFig.11-28.
Figure 11-28. TheNFSsecurity architecture.
Secure RPCs
Because NFSislayered ontopofanRPCsystem, setting upasecure channel
inNFSboilsdown toestablishing secure RPCs. UpuntilNFSv4, asecure RPC
meant thatonlyauthentication wastakencareof.There werethreewaysfordoing
authentication. Wewillnowexamine eachoneintum.534 DISTRIBUTED ALE SYSTEMSI
CHAP. 11
Themostwidely-used method, onethatactually hardly doesanyauthentica-
tion,isknown assystem authentication. InthisUNIX-based method. aclient sim-
plypasses itseffective userIDandgroup IDtotheserver, along withalistof
groups itclaims tobeamember of.Thisinformation issenttotheserver asun-
signed plaintext. Inotherwords. theserver hasnowayatallofverifying whether
theclaimed userandgroup identifiers areactually associated withthesender. In
essence, theserver assumes thattheclient haspassed aproper loginprocedure,
andthatitcantrusttheclient's machine.
Thesecond authentication method inolderNFSversions usesDiffie-Hellman
keyexchange toestablish asession key,leading towhatiscaJJed secure NFS.
Weexplained howDiffie-Hellman keyexchange works inChap. 9.Thisapproach
ismuch better thansystem authentication, butismorecomplex. forwhich reason
itisimplemented lessfrequently. Diffie-Hellman canbeviewed asapublic-key
cryptosystem. Initially, therewasnowaytosecurely distribute aserver's public
key,butthiswaslatercorrected withtheintroduction ofasecure name service. A
pointofcriticism hasalways beentheuseofrelatively smallpublic keys, which
areonly192bitsinNFS.Ithasbeenshown thatbreaking aDiffie-Hellman sys-
temwithsuchshortkeysisnearly trivial (Lamacchia andOdlyzko, 1991).
Thethirdauthentication protocol isKerberos, which wealsodescribed in
Chap. 9.
With theintroduction ofNFSv4, security isenhanced bythesupport for
RPCSEC_GSS. RPCSEC_GSS isageneral security framework thatcansupport
amyriad ofsecurity mechanism forsetting upsecure channels (Eisler etaI.,
1997). Inparticular, itnotonlyprovides thehooks fordifferent authentication
systems, butalsosupports message integrity andconfidentiality, twofeatures that
werenotsupported inolderversions ofNFS.
RPCSEC_GSS isbased onastandard interface forsecurity services, namely
GSS-API, which isfullydescribed inLinn(1997). TheRPCSEC_GSS islayered
ontopofthisinterface, leading totheorganization shown inFig.11-29.
ForNFSv4, RPCSEC_GSS should beconfigured withsupport forKerberos
V5.Inaddition, thesystem mustalsosupport amethod known asLIPKEY,
described inEisler (2000). LIPKEY isapublic-key system thatallows clients to
beauthenticated usingapassword while servers canbeauthenticated using apub-
lickey.
Theimportant aspect ofsecure RPCinNFSisthatthedesigners havechosen
nottoprovide theirownsecurity mechanisms, butonlytoprovide astandard way
forhandling security. Asaconsequence, proven security mechanisms, suchKer-
beros, canbeincorporated intoanNFSimplementation without affecting other
partsofthesystem. Also, ifanexisting security mechanisms turns outtobe
flawed (such asinthecaseofDiffie-Hellman when using small keys), itcan
easily bereplaced.
Itshould benoted thatbecause RPCSEC_GSS isimplemented aspartofthe
RPClayerthatunderlies theNFSprotocols. itcanalsobeusedforolderversionsSEC. 11.8 SECURITY 535
Figure 11-29. Secure RPC'in NrSv4.
ofNFS. However, thisadaptation totheRPClayer became available onlywith
theintroduction ofNFSv4.
Access Control
Authorization inNFSisanalogous tosecure RPC: itprovides themechanisms
butdoesnotspecify anyparticular policy. Access control issupported bymeans
oftheACLfileattribute. Thisattribute isalistofaccess control entries, where
eachentry specifies theaccess rights foraspecific userorgroup. Many oftheop-
erations thatNFS distinguishes withrespect toaccess control arerelatively
straightforward andinclude those forreading, writing, andexecuting files, mani-
pulating fileattributes, listing directories, andsoon.
Noteworthy isalsothesynchronize operation thatessentially tellswhether a
process thatiscolocated withaserver candirectly access afile,bypassing the
NFSprotocol forimproved performance. TheNFSmodel foraccess control has
much richer semantics thanmost UNIX models. Thisdifference comes from the
requirements thatNFSshould beabletointeroperate withWindows systems. The
underlying thought isthatitismuch easier tofittheUNIX model ofaccess control
tothatofWindows, thentheother wayaround.
Another aspect thatmakes access control different from filesystems suchas
inUNIX, isthataccess canbespecified fordifferent users anddifferent groups.
Traditionally, access toafileisspecified forasingle user(theowner ofthefile),
asingle group ofusers (e.g., members ofaproject team), andforeveryone else.
NFShasmany different kinds ofusersandprocesses, asshown inFig.11-30.536 DISTRIBUTED FILESYSTEMS CHAP. ]1
Figure 11-30. Thevarious kinds ofusers andprocesses distinguished byNFS
withrespect toaccess control.
11.8.2 Decentralized Authentication
Oneofthemainproblems withsystems suchasNFSisthatinordertoprop-
erlyhandle authentication, itisnecessary thatusersareregistered through acen-
tralsystem administration. Asolution tothisproblem isprovided byusing the
Secure FileSystems (SFS) incombination withdecentralized authentication ser-
vers.Thebasic idea.described infulldetail inKaminsky etaI.(2003) isquite
simple. What othersystems lackisthepossibility forausertospecify thatare-
mote userhascertain privileges onhisfiles.Invirtually allcases, usersmustbe
globally known toallauthentication servers. Asimpler approach would betolet
Alice specify that"Bob, whose details canbefound atX,"hascertain privileges.
Theauthentication server thathandles Alice's credentials could thencontact
server Xtogetinformation onBob.
Animportant problem tosolveistohaveAlice's server know forsureitis
dealing withBob's authentication server. Thisproblem canbesolved using self-
certifying names, aconcept introduced inSFS(Mazieres etaI.,1999) aimed at
separating keymanagement fromfile-system security. Theoverall organization of
SFSisshown inFig.11-31. Toensure portability across awiderange ofma-
chines, SFShasbeenintegrated withvarious NFSv3 components. Ontheclient
machine, therearethreedifferent components. notcounting theuser's program.
TheNFSclient isusedasaninterface touserprograms, andexchanges informa-
tionwithanSFSclient. Thelatterappears totheNFSclient asbeingjustanother
NFSserver.
TheSFSclient isresponsible forsetting upasecure channel withanSFS
server. Itisalsoresponsible forcommunicating withalocally-available SFSuser
agent, which isaprogram thatautomatically handles userauthentication. SFSSEC. 11.8 SECURITY 537
Figure 11-31. Theorganization ofSFS.
doesnotprescribe howuserauthentication should takeplace. Incorrespondence
withitsdesign goals, SFSseparates suchmatters andusesdifferent agents fordif-
ferent user-authentication protocols.
'Ontheserver sidetherearealsothreecomponents. TheNFSserver isagain
usedforportability reasons. Thisserver communicates withtheSFSserver which
operates asanNFSclient totheNFSserver. TheSFSserver forms thecoreproc-
essofSFS.Thisprocess isresponsible forhandling filerequests fromSFSclients.
Analogous totheSFSagent, anSFSserver communicates withaseparate authen-
tication server tohandle userauthentication.
What makes SFSunique incomparison tootherdistributed filesystems isits
organization ofitsname space. SFSprovides aglobal namespace thatisrooted in
adirectory called /sfs. AnSFSclient allows itsuserstocreate symbolic links
within thisnamespace. More importantly, SFSusesself-certifying pathnames to
name itsfiles.Suchapathname essentially carries alltheinformation toauthenti-
catetheSFSserver thatisproviding thefilenamed bythepathname. Aself-
certifying pathname consists ofthreeparts,asshown inFig.11-32.
Figure 11-32. Aself-certifying pathname inSFS.
Thefirstpartofthename consists ofalocation LOC, which iseither aDNS
domain name identifying theSFSserver, oritscorresponding IPaddress. SFS538 DISTRIBUTED ALE SYSTEMS CHAP. 11
assumes thateachserver Shasapublic keyKs.Thesecond partofaself-
certifying pathname isahostidentifier HIDthatiscomputed bytaking acrypto-
graphic hashHovertheserver's location anditspublic key:
HIDisrepresented bya32-digit number inbase32.Thethirdpartisformed by
thelocalpathnameontheSFSserver under which thefileisactually stored. '
Whenever aclient accesses anSFSserver, itcanauthenticate thatserver by
simply asking itforitspublic key.Using thewell-known hashfunction H,thecli-
entcanthencompute HIDandverify itagainst thevalue found inthepathname.
Ifthetwomatch. theclient knows itistalking totheserver bearing thename as
found inthelocation.
Howdoesthisapproach separate keymanagement fromfilesystem security?
Theproblem thatSFSsolves isthatobtaining aserver's public keycanbecom-
pletely separated fromfilesystem security issues. Oneapproach togetting theser-
ver'skeyisletting aclient contact theserver andrequesting thekeyasdescribed
above. However. itisalsopossible tolocally storeacollection ofkeys, forex-
ample bysystem administrators. Inthiscase,thereisnoneedtocontact aserver.
Instead, when resolving apathname, theserver's keyislooked uplocally after
which thehostIDcanbeverified usingthelocation partofthepathname.
Tosimplify matters, naming transparency canbeachieved byusing symbolic
links. Forexample, assume aclient wants toaccess afilenamed
Tohidethehostill,ausercancreate asymbolic link
andsubsequently useonlythepathname /sfs/vucs/home/steen/mbox .Resolution
ofthatname willautomatically expand tothefullSFSpathname, andusing the
public keyfound locally, authenticate theSFSserver named sjs.vu.cs.nl.
Inasimilar fashion, SFScanbesupported bycertification authorities. Typi-
cally, suchanauthority would maintain linkstotheSFSservers forwhich itis
acting. Asanexample, consider anSFScertification authority CAthatrunsthe
SFSserver named
Assuming theclienthasalready installed asymbolic link
thecertification authority could useanother symbolic link
thatpoints totheSFSserver sfs.vu.cs.nl. Inthiscase,aclient cansimply refertoSEC. 11.8 SECURITY 539
/certsfs/vucs/home/steen/mbox knowing thatitisaccessing afileserver whose
public keyhasbeencertified bythecertification authority CA.
Returning toourproblem ofdecentralized authentication, itshould nowbe
clearthatwehaveallthemechanisms inplacetoavoidrequiring Bobtoberegis-
teredatAlice's authentication server. Instead, thelattercansimply contact Bob's
server provided itisgiven aname. Thatname already contains apublic keyso
thatAlice's server canverify theidentity ofBob's server. After that,Alice's
server canaccept Bob's privileges asindicated byAlice. Assaid,thedetails of
thisscheme canbefound inKaminsky etal.(2003).
11.8.3 Secure Peer-to-Peer File-Sharing Systems
Sofar,wehavediscussed distributed filesystems thatwererelatively easyto
secure. Traditional systems either usestraightforward authentication andaccess
control mechanisms extended withsecure communication, orwecanleverage
traditional authentication toacompletely decentralized scheme. However, matters
become complicated when dealing withfullydecentralized systems thatrelyon
collaboration, suchasinpeer-to-peer file-sharing systems.
Secure Lookups inDHT-Based Systems
There arevarious issues todealwith(Castro etal.,2002a; andWallach,
2002). Letusconsider DHT-based systems. Inthiscase,weneedtorelyon
secure lookup operations, which essentially boildown toaneedforsecure rout-
ing.Thismeans thatwhenanonfaulty nodelooksupakeyk,itsrequest isindeed
forwarded tothenoderesponsible forthedataassociated withk,oranodestoring
acopyofthatdata.Secure routing requires thatthreeissues aredealtwith:
1.Nodes areassigned identifiers inasecure way.
2.Routing tables aresecurely maintained.
3.Lookup requests aresecurely forwarded between nodes.
When nodes arenotsecurely assigned theiridentifier, wemayfacetheprob-
lemthatamalicious nodecanassign itselfanIDsothatalllookups forspecific
keyswillbedirected toitself, orforwarded along theroutethatitispartof.This
situation becomes moreserious when nodes canteamup,effectively allowing a
group toformahuge"sink" formany lookup requests. Likewise, without secure
identifier assignment, asingle nodemayalsobeabletoassign itselfmany identi-
fiers,alsoknown asaSybilattack, creating thesameeffect (Douceur, 2002).
More general thantheSybil attack isanattack bywhich amalicious node
controls somanyofanonfaulty node's neighbors, thatitbecomes virtually impos-
sibleforcorrect nodes tooperate properly. Thisphenomenon isalsoknown asan540 DISTRIBUTED FILESYSTEMS CHAP. 11
eclipseattack,andisanalyzed inSingh etal.(2006). Defending yourself against
suchanattack isdifficult. Onereasonable solution istoconstrain thenumber of
incoming edges foreachnode. Inthisway,anattacker canhaveonlyalimited
number ofcorrect nodes pointing toit.Toalsoprevent anattacker fromtaking
overallincoming linkstocorrect nodes, thenumber ofoutgoing linksshould also
beconstrained [seealsoSingh etal.(2004)]. Problematic inallthesecasesisthat
acentralized authority isneeded forhanding outnodeidentifiers. Obviously, such
anauthority goesagainst thedecentralized nature ofpeer-to-peer systems.
When routing tables canbefilled inwithalternative nodes. asisoften the
casewhen optimizing fornetwork proximity, anattacker caneasily convince a
nodetopoint tomalicious nodes. Notethatthisproblem doesnotoccur when
therearestrong constraints onfilling routing tableentries, suchasinthecaseof
Chord. Thesolution, therefore, istomixchoosing alternatives withamorecon-
strained filling oftables [ofwhich details aredescribed inCastro etal.(2002a)].
Finally, todefend against message-forwarding attacks, anode maysimply
forward messages along several routes. Onewaytodothisistoinitiate alookup
fromdifferent source nodes.
SecureCollaborative Storage
However, themerefactthatnodes arerequired tocollaborate introduces more
problems. Forexample, collaboration maydictate thatnodes should offerabout
thesameamount ofstorage thattheyusefromothers. Enforcing thispolicy canbe
quitetricky. Onesolution istoaapply asecure trading ofstorage, asforSamsara,
asdescribed inCoxandNoble (2003).
Theideaisquitesimple: when aserver Pwants tostoreoneofitsfilesfon
another server Q,itmakes storage available ofasizeequal tothatoff,and
reserves thatspace exclusively forQ.Inotherwords, Qnowhasanoutstanding
claimatA,asshown inFig.11-33.
Figure 11·33. Theprinciple ofstorage claims intheSamsara peer-to-peer system.
Tomake thisscheme work, eachparticipant reserves anamount ofstorage
anddivides thatintoequal-sized chunks. Eachchunk consists ofincompressibleSEC. 11.8 SECURITY 541
data. InSamsara, chunk c,consists ofa160-bit hashvalue hicomputed overa
secret passphrase Wconcatenated withthenumber i.Nowassume thatclaims are
handed outinunitsof256bytes. Inthatcase, thefirstclaim iscomputed bytaking
thefirst12chunks along withthefirst16bytes ofnextchunk. These chunks are
concatenated andencrypted using aprivate keyK.Ingeneral, claim C,iscom-
puted as
11.9SUMMARY
Distributed filesystems form animportant paradigm forbuilding distributed
systems. They aregenerally organized according totheclient-server model, with
client-side caching andsupport forserver replication tomeet scalability require-
ments. Inaddition, caching andreplication areneeded toachieve highavailability.
More recently, symmetric architectures suchasthose inpeer-to-peer file-sharing
systems haveemerged. Inthese cases, animportant issueiswhether whole filesor
datablocks aredistributed.where k=jxI3. Whenever Pwants tomake useofstorage atQ,Qreturns acollec-
tionofclaims thatPisnowforced tostore. Ofcourse, Qneednever storeitsown
claims. Instead, itcancompute when needed. '.
Thetricknowisthatonceinawhile, Qmaywanttocheck whether Pisstill
storing itsclaims. IfPcannot prove thatitisdoing so,Qcansimply discard P's
data.Oneblunt wayofletting Pprove itstillhastheclaims isreturning copies to
Q.Obviously, thiswillwaste alotofbandwidth. Assume thatQhadhanded out
claims Cj\, •••,CjktoP.Inthatcase, Qpasses a160-bit string dtoP,andre-
quests ittocompute the160-bit hashd1ofdconcatenated withCj\ .Thishashis
thentobeconcatenated withCj2, producing ahashvalue d2,andsoon.Inthe
end.Pneedonlyreturn dntoprove itstillholds alltheclaims.
Ofcourse, Qmayalsowant toreplicate itsfilestoanother node, sayR.In
doing so,itwillhave toholdclaims forR.However, ifQisrunning outof
storage, buthasclaimed storage atP,itmaydecide topassthose claims toRin-
stead. Thisprinciple works asfollows.
Assume thatPisholding aclaim CQforQ,andQissupposed toholdaclaim
CRforR.Because thereisnorestriction onwhatQcanstoreatP,Qmight aswell
decide tostore CRatP.Then, whenever Rwants tocheck whether Qisstillhold-
ingitsclaim, Qwillpassavalue dtoQandrequest ittocompute thehashofd
concatenated withCR'Todoso,Qsimply passes dontoP,requests Ptocompute
thehash, andreturns theresult toR.Ifitturns outthatPisnolonger holding the
claim, Qwillbepunished byR,andQ,inturn,canpunish Pbyremoving stored
data.542 DISTRIBUTED FILESYSTEMS CHAP. II
Instead ofbuilding adistributed filesystem directly ontopofthetransport
layeritiscommon practice toassume theexistence ofanRPClayer, sothatall
operations canbesimply expressed asRPCs toafileserver instead ofhaving to
useprimitive message-passing operations. Some variants ofRPC havebeen
developed, suchastheMultiRPC provided inCoda, which allows anumber of
servers tobecalled inparallel.
Whatmakes distributed filesystems different fromnondistributed filesystems
isthesemantics ofsharing files.Ideally, afilesystem allows aclient toalways
readthedatathathavemostrecently beenwritten toafile.These UNIX file-
sharing semantics areveryhardtoimplement efficiently inadistributed system.
NFSsupports aweaker formknown assession semantics, bywhich thefinalver-
sionofafileisdetermined bythelastclient thatcloses afile,which ithadprevi-
ouslyopened forwriting. InCoda, filesharing adheres totransactional semantics
inthesensethatreading clients willonlygettoseethemostrecent updates ifthey
reopen afile.Transactional semantics inCodadonotcover alltheACID proper-
tiesofregular transactions. Inthecasethatafileserver staysincontrol ofallop-
erations, actual UNIX semantics canbeprovided, although scalability isthenan
issue. Inallcases, itisnecessary toallow concurrent updates onfiles,which
brings relatively intricate locking andreservation schemes intoplay.
Toachieve acceptable performance, distributed filesystems generally allow
clients tocache anentire file.Thiswhole-file caching approach issupported, for
example, inNFS,although itisalsopossible tostoreonlyverylargechunks ofa
file.Onceafilehasbeenopened and(partly) transferred totheclient, allopera-
tionsarecarried outlocally. Updates areflushed totheserver when thefileis
closed again.
_Replication alsoplays animportant roleinpeer-to-peer systems, although
matters arestrongly simplified because filesaregenerally read-only. More impor-
tantinthesesystems istrying toreach acceptable loadbalance, asnaive replica-
tionschemes caneasily leadtohotspotsholding many filesandthusbecome
potential bottlenecks.
Faulttolerance isusually dealtwithusingtraditional methods. However, itis
alsopossible tobuild filesystems thatcandealwithByzantine failures, even
when thesystem asawhole isrunning ontheInternet. Inthiscase,byassuming
reasonable timeouts andinitiating newserver groups (possibly based onfalse
failure detection), practical solutions canbebuilt.Notably fordistributed filesys-
tems,oneshould consider toapply erasure coding techniques toreduce theoverall
replication factor whenaiming foronlyhighavailability.
Security isofparamount importance foranydistributed system, including file
systems. NFShardly provides anysecurity mechanisms itself, butinstead imple-
ments standardized interfaces thatallow different existing security systems tobe
used, suchas,forexample Kerberos. SFSisdifferent inthesense itallows file
names toinclude information onthefileserver's public key.Thisapproach sim-
plifies keymanagement inlarge-scale systems. Ineffect, SFSdistributes akeybySEC. 11.9 SlThtlMARY 543
including itinthename ofafile.SFScanbeusedtoimplement adecentralized
authentication scheme. Achieving security inpeer-to-peer file-sharing systems is
difficult, partly because oftheassumed collaborative nature inwhich nodes will
always tendtoactselfish. Also,making lookups secure turnsouttobeadifficult
problem thatactually requires acentral authority forhanding outnodeidentifiers.
PROBLElVIS
1.Isafileserver implementing NFSversion 3required tobestateless?
2.Explain whether ornotNFSistobeconsidered adistributed filesystem.
3.Despite thatGFSscales well, itcould beargued thatthemaster isstillapotential
bottleneck. What would beareasonable alternative toreplace it?
4.Using RPC2's sideeffects isconvenient forcontinuous datastreams. Giveanother ex-
ample inwhich itmakes sense touseanapplication-specific protocol nexttoRPC.
5.NFSdoesnotprovide aglobal, shared name space. Isthere awaytomimic sucha
name space?
6.Give asimple extension totheNFSlookup operation thatwould allow iterative name
lookup incombination withaserver exporting directories thatitmounted fromanother
server.
7.InUNIX-based operating systems, opening afileusing afilehandle canbedoneonly
inthekernel. Give apossible implementation ofanNFSfilehandle forauser-level
NFSserver foraUNIX system.
8.Using anautomounter thatinstalls symbolic links asdescribed inthetextmakes it
harder tohidethefactthatmounting istransparent. Why?
9.Suppose thatthecurrent denial stateofafileinNFSisWRITE. Isitpossible thatan-
other client canfirstsuccessfully openthatfileandthenrequest awritelock?
10.Taking intoaccount cache coherence asdiscussed inChap. 7,which kindofcache-
coherence protocol doesNFSimplement?
11.Does NFSimplement entryconsistency?
12.Westated thatNFSimplements theremote access model tofilehandling. Itcanbe
argued thatitalsosupports theupload/download model. Explain why.
13.InNFS, attributes arecached using awrite-through cache coherence policy. Isit
necessary toforward allattributes changes immediately?
14.What calling semantics doesRPC2 provide inthepresence offailures?
15.Explain howCoda solves read-write conflicts onafilethatisshared between multiple
readers andonlyasingle writer.544 DISTRIBUTED FILE SYSTEMS CHAP. 11
16.Using self-certifying pathnames, isaclient always ensured itiscommunicating witha
nonmalicious server?
17.(Labassignment) Oneoftheeasiest ways forbuilding aUNIX-based distributed sys-
tem,istocouple anumber ofmachines bymeans ofNFS. Forthisassignment. youare
toconnect twofilesystems ondifferent computers bymeans ofNFS. Inparticular,
install anNFSserver ononemachine suchthatvarious parts ofitsfilesystem are
automatically mounted when thefirstmachine boots.
18.(Labassignment) Tointegrate UNIX-based machines withWindows clients, onecan
make useofSamba servers. Extend theprevious assignment bymaking aUNIX-hased
system available toaWindows client. byinstalling andconfiguring aSamba server.
Atthesame time. thefilesystem should remain accessible through NFS.12
DISTRIBUTED
WEB-BASED SYSTEMS
TheWorldWide Web(WWW) canbeviewed asahugedistributed system
consisting ofmillions ofclients andservers foraccessing linked documents.
Servers maintain collections ofdocuments, while clients provide users aneasy-
to-use interface forpresenting andaccessing thosedocuments.
TheWebstarted asaproject atCERN, theEuropean Particle Physics Labora-
toryinGeneva, toletitslargeandgeographically dispersed group ofresearchers
access shared documents using asimple hypertext system. Adocument could be
anything thatcould bedisplayed onauser's computer terminal, suchaspersonal
notes, reports, figures, blueprints, drawings, andsoon.Bylinking documents to
eachother, itbecame easytointegrate documents fromdifferent projects intoa
newdocument without thenecessity forcentralized changes. Theonlythingneed-
edwastoconstruct adocument providing linkstootherrelevant documents [see
alsoBerners-Lee etal.(1994)].
TheWebgradually grewslowly tositesotherthanhigh-energy physics, but
popularity sharply increased when graphical userinterfaces became available,
notably Mosaic (Vetter etal.,1994). Mosaic provided aneasy-to-use interface to
present andaccess documents bymerely clicking amouse button. Adocument
wasfetched fromaserver, transferred toaclient, andpresented onthescreen. To
auser,therewasconceptually nodifference between adocument stored locally or
inanother partoftheworld. Inthissense, distribution wastransparent.
545546 DISTRIBUTED WEB-BASED SYSTEMS CHAP. L2'
Since 1994, Web developments havebeeninitiated bytheWorld Wide Web
Consortium, acollaboration between CERN andMJ.T. Thisconsortium isre-
sponsible forstandardizing protocols, improving interoperability, andfurther en-
hancing thecapabilities oftheWeb. Inaddition, weseemany newdevelopments
takeplace outside thisconsortium, notalways leading tothecompability one
would hopefor.Bynow, theWebismore thanjustasimple document-based sys-
tem.Notably withtheintroduction ofWebservices weareseeing ahuge distrib-
utedsystem emerging inwhich services rather thanjustdocuments arebeing
used, composed, andoffered toanyuserormachine thatcanfinduseofthem.
Inthischapter wewilltakeacloser lookatthisrapidly growing andpervasive
system. Considering thattheWebitself issoyoung andthatsomuch aschanged
insuchashort time, ourdescription canonlybeasnapshot ofitscurrent state.
However, asweshall see,many concepts underlying Web technology arebased
ontheprinciples discussed inthefirstpartofthisbook. Also, wewillseethatfor
many concepts, there isstillmuch room forimprovement.
12.1ARCHITECTURE
Thearchitecture ofWeb-based distributed systems isnotfundamentally dif-
ferent fromother distributed systems. However, itisinteresting toseehowtheini-
tialideaofsupporting distributed documents hasevolved since itsinception in
1990s. Documents turned from being purely static andpassive todynamically
generated containing allkinds ofactive elements. Furthermore, inrecent years,
many organizations havebegun supporting services instead ofjustdocuments. In
thefollowing, wediscuss thearchitectural impacts ofthese shifts.
12.1.1 Traditional Web-Based Systems
Unlike many ofthedistributed systems wehavebeendiscussing sofar,Web-
based distributed systems arerelatively new.Inthissense. itissomewhat difficult
totalkabout traditional Web-based systems, although there isaclear distinction
between thesystems thatwere available atthebeginning andthose thatareused
today. .
Many Web-based systems arestillorganized asrelatively simple client-server
architectures. ThecoreofaWebsiteisformed byaprocess thathasaccess toa
localfilesystem storing documents. Thesimplest waytorefertoadocument isby
means ofareference called aUniform Resource Locator (URL). Itspecifies
where adocument islocated, often byembedding theDNS name ofitsassociated
server along withafilename bywhich theserver canlookupthedocument inits
localfilesystem. Furthermore. aURL specifies theapplication-level protocol for
transferring thedocument across thenetwork. There areseveral different proto-
colsavailable, asweexplain below.SEC. 12.1 ARCHITECTURE 547
Aclient interacts withWebservers through aspecial application known asa
browser. Abrowser isresponsible forproperly displaying adocument. Also, a
browser accepts inputfromausermostly byletting theuserselect areference to
another document, which itthensubsequently fetches anddisplays. Thecommu-
nication between abrowser andWebserver isstandardized: theybothadhere to
theHyperText Transfer Protocol (HTTP) which wewilldiscuss below. This
leadstotheoverall organization shown inFig.12-1.
Figure 12-1.Theoverall organization ofatraditional Website.
TheWebhasevolved considerably sinceitsintroduction. Bynow,thereisa
wealth ofmethods andtoolstoproduce information thatcanbeprocessed byWeb
clients andWebservers. Inthefollowing, wewillgointodetail onhowtheWeb
actsasadistributed system. However, weskipmostofthemethods andtoolsused
toconstruct Webdocuments, astheyoftenhavenodirect relationship tothedis-
tributed nature oftheWeb.Agoodintroduction onhowtobuildWeb-based appli-
cations canbefound inSebesta (2006).
WebDocuments
Fundamental totheWebisthatvirtually allinformation comes intheformof
adocument. Theconcept ofadocument istobetaken initsbroadest sense: not
onlycanitcontain plain text,butadocument mayalsoinclude allkinds of
dynamic features suchasaudio, video, animations andsoon.Inmanycases, spe-
cialhelper applications areneeded tomakeadocument "come tolife." Suchin-
terpreters willtypically beintegrated withauser's browser.
Mostdocuments canberoughly divided intotwoparts: amainpartthatatthe
veryleastactsasatemplate forthesecond part,which consists ofmanydifferent
bitsandpieces thatjointly constitute thedocument thatisdisplayed inabrowser.
Themainpartisgenerally written inamarkup language, verysimilar tothetype
oflanguages thatareusedinword-processing systems. Themostwidely-used
markup language intheWebisHTML, which isanacronym forHyperText548 DISTRIBUTED WEB-BASED SYSTEMS CHAP. ]2
Markup Language. Asitsname suggests, HT1\1L allows theembedding oflinks
toother documents. When activating suchlinksinabrowser, thereferenced docu-
mentwillbefetched fromitsassociated server.
Another, increasingly important markup language istheExtensible Markup
Language (XML) which, asitsname suggests, provides much more flexibility in
defining whatadocument should looklike.Themajor difference between HTML
andXML isthatthelatter includes thedefinitions oftheelements thatmark upa
document. Inother words, itisameta-markup language. Thisapproach provides a
lotofflexibility when itcomes tospecifying exactly whatadocument looks like:
there isnoneedtosticktoasingle model asdictated byafixed markup language
suchasHTML.
HTML andXML canalsoinclude allkinds oftagsthatrefer toembedded
documents, thatis,references tofilesthatshould beincluded tomake adocu-
ment complete. Itcanbeargued thattheembedded documents turnaWeb docu-
ment intosomething active. Especially when considering thatanembedded docu-
ment canbeacomplete program thatisexecuted on-the-fly aspartofdisplaying
information, itisnothardtoimagine thekindofthings thatcanbedone.
Embedded documents come inallsorts andflavors. Thisimmediately raises
anissue howbrowsers canbeequipped tohandle thedifferent fileformats and
ways tointerpret embedded documents. Essentially, weneed onlytwothings: a
wayofspecifying thetypeofanembedded document, andawayofallowing a
browser tohandle dataofaspecific type.
Each (embedded) document hasanassociated MIME type. MIME stands for
Multipurpose Internet MailExchange and,asitsname suggests, wasoriginally
developed toprovide information onthecontent ofamessage body thatwassent
aspartofelectronic mail. MIME distinguishes various types ofmessage contents.
These types arealsousedintheWWW, butitisnoted thatstandardization isdif-
ficult withnewdataformats showing upalmost daily.
MIME makes adistinction between top-level types andsubtypes. Some com-
montop-level types areshown inFig.12-2andinclude types fortext,image.
audio, andvideo. There isaspecial application typethatindicates thatthedocu-
ment contains datathatarerelated toaspecific application. Inpractice, onlythat
application willbeabletotransform thedocument intosomething thatcanbe
understood byahuman.
Themultipart typeisusedforcomposite documents, thatis,documents that
consists ofseveral parts where eachpartwillagain haveitsownassociated top-
leveltype.
Foreach top-level type, there maybeseveral subtypes available, ofwhich
some arealsoshown inFig.12-2. Thetypeofadocument isthenrepresented asa
combination oftop-level type andsubtype, such as,forexample, applica-
tion/PDF. Inthiscase, itisexpected thataseparate application isneeded for
processing thedocument, which isrepresented inPDF. Many subtypes areexperi-
mental, meaning thataspecial format isusedrequiring itsownapplication attheSEC. 12.1 ARCHITECTURE 549
Figure 12-2. Sixtop-level MIME types andsome common subtypes.
user'sside.Inpractice, itistheWeb server whowillprovide thisapplication,
either asaseparate program thatwillrunaside abrowser, orasaso-called plug-
inthatcanbeinstalled aspartofthebrowser.
This(changing) variety ofdocument types forces browsers tobeextensible.
Tothisend,some standardization hastaken place toallow plug-ins adhering to
certain interfaces tobeeasily integrated inabrowser. When certain types become
popular enough, theyareoften shipped withbrowsers ortheirupdates. Wereturn
tothisissuebelow when discussing client-side software.
Multitiered Architectures
Thecombination ofHTML (oranyother markup language suchasXML)
withscripting provides apowerful means forexpressing documents. However, we
havehardly discussed where documents areactually processed, andwhatkindof
processing takes place. TheWWW started outastherelatively simple two-tiered
client-server system shown previously inFig.12-1.Bynow, thissimple architec-
turehasbeenextended withnumerous components tosupport theadvanced type
ofdocuments wejustdescribed.
Oneofthefirstenhancements tothebasic architecture wassupport forsimple
userinteraction bymeans oftheCommon Gateway Interface orsimply CGI.
CGIdefines astandard waybywhich aWebserver canexecute aprogram taking
userdataasinput. Usually, userdatacome from anHTML form; itspecifies the550
program thatistobeexecuted attheserver side,along withparameter values that
arefilledinbytheuser.Once theformhasbeencompleted, theprogram's name
andcollected parameter values aresenttotheserver, asshown inFig.12-3.
Figure 12-3. Theprinciple ofusing server-side CGIprograms.
When theserver seestherequest itstartstheprogram named intherequest
andpasses ittheparameter values. Atthatpoint, theprogram simply doesitswork
andgenerally returns theresults intheformofadocument thatissentbacktothe
user's browser tobedisplayed.
CGIprograms canbeassophisticated asadeveloper wants. Forexample, as
shown inFig.12-3,many programs operate onadatabase localtotheWebserver.
Afterprocessing thedata,theprogram generates anHT1\1L document andreturns
thatdocument totheserver. Theserver willthenpassthedocument totheclient.
Aninteresting observation isthattotheserver, itappears asifitisasking theCGI
program tofetchadocument. Inotherwords, theserver doesnothing butdelegate
thefetching ofadocument toanexternal program.
Themaintaskofaserver usedtobehandling client requests bysimply fetch-
ingdocuments. WithCGIprograms, fetching adocument could bedelegated in
suchawaythattheserver would remain unaware ofwhether adocument had
beengenerated onthefly,oractually readfromthelocalfilesystem. Notethatwe
havejustdescribed atwo-tiered organization ofserver-side software.
However, servers nowadays domuch morethanjustfetching documents. One
ofthemostimportant enhancements isthatservers canalsoprocess adocument
-before passing ittotheclient. Inparticular, adocument maycontain aserver-side
script, which isexecuted bytheserver when thedocument hasbeenfetched lo-
cally. Theresult ofexecuting ascript issentalong withtherestofthedocument
totheclient. Thescript itselfisnotsent.Inotherwords, using aserver-side script
changes adocument byessentially replacing thescript withtheresults ofitsex-
ecution.
Asserver-side processing ofWebdocuments increasingly requires moreflexi-
bility, itshould come asnosurprise thatmany Websitesarenoworganized asa
three-tiered architecture consisting ofaWebserver. anapplication server, anda
database. TheWebserver isthetraditional Webserver thatwehadbefore; theDISTRIBUTED WEB-BASED SYSTEMS CHAP. 12SEC. 12.1 ARCHITECTURE 551
application server runsallkinds ofprograms thatmayor maynotaccess thethird
tier.consisting ofadatabase. Forexample, aserver mayaccept acustomer's
query, search itsdatabase ofmatching products, andthenconstruct aclickable
Webpagelisting theproducts found. Inmany cases theserver isresponsible for
running Javaprograms, called servlets, thatmaintain things likeshopping carts,
implement recommendations, keeplistsoffavorite items, andsoon.
Thisthree-tiered organization introduces aproblem, however: adecrease in
performance. Although fromanarchitectural pointofviewitmakes sense todis-
tinguish threetiers,practice shows thattheapplication server anddatabase are
potential bottlenecks. Notably improving database performance cantumouttobe
anastyproblem. Wewillreturn tothisissuebelow when discussing caching and
replication assolutions toperformance problems.
12.1.2 WebServices
Sofar,wehaveimplicitly assumed thattheclient-side software ofaWeb-
based system consists ofabrowser thatactsastheinterface toauser.This
assumption isnolonger universally trueanymore. There isarapidly growing
group ofWeb-based systems thatareoffering general services toremote applica-
tionswithout immediate interactions fromendusers. Thisorsanization leadsto <-
theconcept ofWebservices (Alonso etaI.,2004).
WebServices Fundamentals
Simply stated, aWebservice isnothing butatraditional service (e.g.,ana-
ming service, aweather-reporting service, anelectronic supplier, etc.)thatis
made available overtheInternet. What makes aWebservice special isthatit
adheres toacollection ofstandards thatwillallow ittobediscovered andac-
cessed overtheInternet byclient applications thatfollow thosestandards aswell.
Itshould come asnosurprise then,thatthosestandards formthecoreofWebser-
vicesarchitecture [seealsoBooth etal.(2004)].
Theprinciple ofproviding andusing aWebservice isquitesimple, andis
shown inFig.12-4. Thebasicideaisthatsomeclient application cancallupon
theservices asprovided byaserver application. Standardization takesplacewith
respect tohowthoseservices aredescribed suchthattheycanbelooked upbya
client application. Inaddition, weneedtoensure thatservice callproceeds along
therulessetbytheserver application. Notethatthisprinciple isnodifferent from
whatisneeded torealize aremote procedure call.
Animportant component intheWebservices architecture isformed byadi-
rectory service storing service descriptions. Thisservice adheres totheUniversal
Description, Discovery andIntegration standard (UDDI). Asitsname sug-
gests, UDOr prescribes thelayout ofadatabase containing service descriptions
thatwillallow Webservice clients tobrowse forrelevant services.552 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Figure 12-4. Theprinciple ofaWebservice.
Services aredescribed bymeans oftheWebServices Definition Language
(WSDL) which isaformal language verymuch thesameastheinterface defini-
tionlanguages usedtosupport RPC-based communication. AWSDL description
contains theprecise definitions oftheinterfaces provided byaservice, thatis,pro-
cedure specification, datatypes, the(logical) location ofservices, etc.Animpor-
tantissueofaWSDL description isthatcanbeautomatically translated to.client-
sideandserver-side stubs, again, analogous tothegeneration ofstubsinordinary
RPC-based systems.
Finally, acoreelement ofaWebservice isthespecification ofhowcommuni-
cation takesplace. Tothisend,theSimple Object Access Protocol (SOAP) is
used,which isessentially aframework inwhich much ofthecommunication be-
tween twoprocesses canbestandardized. Wewilldiscuss SOAP indetail below,
where itwillalsobecome clearthatcalling theframework simple isnotreally jus-
tified.
WebServices Composition andCoordination
Thearchitecture described sofarisrelatively straightforward: aservice isim-
plemented bymeans ofanapplication anditsinvocation takesplace according to
aspecific standard. Ofcourse, theapplication itselfmaybecomplex and,infact,
itscomponents maybecompletely distributed across alocal-area network. Insuch
cases, theWebservice ismostlikely implemented bymeans ofaninternal proxy
ordaemon thatinteracts withthevarious components constituting thedistributedSEC. 12.1 ARCHITECTURE 553
application. Inthatcase,alltheprinciples wehavediscussed sofarcanbereadily
applied aswehavediscussed.
Inthemodel sofar,aWebservice isoffered intheformofasingle invoca-
tion.Inpractice, much morecomplex invocation structures needtotakeplacebe-
foreaservice canbeconsidered ascompleted. Forexample, takeanelectronic
bookstore. Ordering abookrequires selecting abook, paying, andensuring its
delivery. From aservice perspective, theactual service should bemodeled asa
transaction consisting ofmultiple stepsthatneedtobecarried outinaspecific
order. Inotherwords, wearedealing withacomplex service thatisbuiltfroma
number ofbasicservices.
Complexity increases when considering Webservices thatareoffered by
combining Webservices fromdifferent providers. Atypical example isdevising a
Web-based shop.Mostshops consist roughly ofthreeparts: afirstpartbywhich
thegoods thataclient requires areselected, asecond onethathandles thepay-
mentofthose goods, andathirdonethattakescareofshipping andsubsequent
tracking ofgoods. Inordertosetupsuchashop,aprovider maywanttomakeuse
ofaelectronic bankservice thatcanhandle payment, butalsoaspecial delivery
service thathandles theshipping ofgoods. Inthisway,aprovider canconcentrate
onitscorebusiness, namely theoffering ofgoods.
Inthese scenarios itisimportant thatacustomer seesacoherent service:
namely ashopwhere hecanselect, pay,andrelyonproper delivery. However, in-
ternally weneedtodealwithasituation inwhich possibly threedifferent organi-
zations needtoactinacoordinated way.Providing proper support forsuchcom-
posite services forms anessential element ofWebservices. There areatleasttwo
classes ofproblems thatneedtobesolved. First,howcanthecoordination be-
tween Webservices, possibly fromdifferent organizations, takeplace? Second,
howcanservices beeasily composed?
Coordination among Webservices istackled through coordination protocols.
Suchaprotocol prescribes thevarious stepsthatneedtotakeplacefor(compos-
ite)service tosucceed. Theissue, ofcourse, istoenforce theparties taking partin
suchprotocol takethecorrect stepsattherightmoment. There arevarious waysto
achieve this;thesimplest istohaveasingle coordinator thatcontrols themes-
sages exchanged between theparticipating parties.
However, although various solutions exist,fromtheWebservices perspective
itisimportant tostandardize thecommonalities incoordination protocols. For
one,itisimportant thatwhen apartywants toparticipate inaspecific protocol,
thatitknows withwhich otherprocess(es) itshould communicate. Inaddition, it
mayverywellbethataprocess isinvolved inmultiple coordination protocols at
thesame time.Therefore, identifying theinstance ofaprotocol isimportant as
well.Finally, aprocess should know which roleitistofulfill.
These issues arestandardized inwhatisknown as\VebServices Coordina-
tion(Frend etal.,2005). From anarchitectural pointofview,itdefines aseparate
service forhandling coordination protocols. Thecoordination ofaprotocol ispart554 DISTRIBUTED WEB-BASED SYSTEMS CHAP. ]2
ofthisservice. Processes canregister themselves asparticipating inthecoordina-
tionsothattheirpeersknow aboutthem.
Tomake matters concrete, consider acoordination service forvariants ofthe
two-phase protocol (2PC) wediscussed inChap. 8.Thewhole ideaisthatsucha
service would implement thecoordinator forvarious protocol instances. Oneobvi-
ousimplementation isthatasingle process playstheroleofcoordinator formulti-
pleprotocol instances. Analternative isthathaveeachcoordinator beimplemen-
tedbyaseparate thread.
Aprocess canrequest theactivation ofaspecific protocol. Atthatpoint, it
willessentially bereturned anidentifier thatitcanpasstootherprocesses forreg-
istering asparticipants inthenewly-created protocol instance. Ofcourse, allparti-
cipating processes willberequired toimplement thespecific interfaces ofthepro-
tocolthatthecoordination service issupporting. Onceallparticipants haveregis-
tered, thecoordinator cansendtheVOTE_REQUEST, COMMIT, andothermes-
sagesthatarepartofthe2PCprotocol totheparticipants whenneeded.
Itisnotdifficult toseethatduetothecommonality in,forexample, 2PCpro-
tocols, standardization ofinterfaces andmessages toexchange willmake itmuch
easier tocompose andcoordinate Webservices. Theactual workthatneeds tobe
doneisnotverydifficult. Inthisrespect, theadded value ofacoordination service
istobesought entirely inthestandardization.
Clearly, acoordination service already offers facilities forcomposing aWeb
service outofotherservices. There isonlyonepotential problem: howtheservice
iscomposed ispublic. Inmany cases, thisisnotadesirable property, asitwould
allow anycompetitor tosetupexactly thesamecomposite service. What isneed-
ed,therefore, arefacilities forsetting upprivate coordinators. Wewillnotgointo
anydetails here,astheydonottouch upontheprinciples ofservice composition
inWeb-based systems. Also, thistypeofcomposition isstillverymuch influx
(andmaycontinue tobesoforalongtime). Theinterested reader isreferred to
(Alonso etaI.,2004).
12.2PROCESSES
Wenowturntothemostimportant processes usedinWeb-based systems and
theirinternal organization. .
12.2.1Clients
Themostimportant Webclient isapieceofsoftware called aWebbrowser,
which enables ausertonavigate through Webpages byfetching thosepages from
servers andsubsequently displaying themontheuser"sscreen. Abrowser typi-
callyprovides aninterface bywhich hyperlinks aredisplayed insuchawaythat
theusercaneasily select themthrough asingle mouse click.SEC. l2.2 PROCESSES 555
Web browsers usedtobesimple programs, butthatwaslongago.Logically,
theyconsist ofseveral components, shown inFig.12-5[seealsoGrosskurth and
Godfrey (2005)].
Figure 12-5. Thelogical components ofaWebbrowser.
Animportant aspect ofWebbrowsers isthattheyshould (ideally) beplatform
independent. Thisgoalisoften achieved bymaking useofstandard graphical
libraries, shown asthedisplay backend,along withstandard networking libraries.
Thecoreofabrowser isformed bythebrowser engine andtherendering en-
gine. Thelatter contains allthecode forproperly displaying documents aswe
explained before. Thisrendering attheveryleast requires parsing HTML or
XML, butmayalsorequire script interpretation. Inmostcase, there isonlyanin-
terpreter forJavascript included, butintheory other interpreters maybeincluded
aswell. Thebrowser engine provides themechanisms foranendusertogoovera
document, select partsofit,activate hyperlinks, etc.
Oneoftheproblems thatWeb browser designers have tofaceisthata
browser should beeasily extensible sothatit,inprinciple, cansupport anytypeof
document thatisreturned byaserver. Theapproach followed inmostcases isto
offer facilities forwhatareknown asplug-ins. Asmentioned before, aplug-in is
asmall program thatcanbedynamically loaded intoabrowser forhandling aspe-
cific document type. Thelatter isgenerally given asaMIME type. Aplug-in
should belocally available. possibly afterbeing specifically transferred byauser
from aremote server. Plug-ins normally offer astandard interface tothebrowser
and,likewise, expect astandard interface fromthebrowser. Logically, theyform
anextension oftherendering engine shown inFig.12-5.
Another client-side process thatisoften usedisaWeb proxy (Luotonen and
Altis, 1994). Originally, suchaprocess wasusedtoallow abrowser tohandle ap-
plication-level protocols other thanHTTP, asshown inFig.12-6. Forexample, to
transfer afilefrom anFTPserver, thebrowser canissue anHTTP request toa
localFTPproxy, which willthenfetch thefileandreturn itembedded asHTTP.556 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Figure 12-6. Using aWebproxy when thebrowser doesnotspeak FTP.
Bynow.mostWebbrowsers arecapable ofsupporting avariety ofprotocols,
orcanotherwise bedynamically extended todoso.andforthatreason donot
needproxies. However, proxies arestillusedforotherreasons. Forexample, a
proxy canbeconfigured forfiltering requests andresponses (bringing itcloseto
anapplication-level firewall), logging, compression, butmostofallcaching. We
return toproxy caching below. Awidely-used Webproxy isSquid, which has
beendeveloped asanopen-source project. Detailed information onSquid canhe
found inWessels (2004).
12.2.2 TheApache WebServer
Byfarthemostpopular Webserver isApache, which isestimated tobeused
tohostapproximately 70%ofallWebsites.Apache isacomplex piece ofsoft-
ware, andwiththenumerous enhancements tothetypes ofdocuments thatare
nowoffered intheWeb,itisimportant thattheserver ishighly configurable and
extensible, andatthesametimelargely independent ofspecific platforms.
Making theserver platform independent isrealized byessentially providing
itsownbasicruntime environment, which isthensubsequently implemented for
different operating systems. Thisruntime environment, known astheApache
Portable Runtime (APR), isalibrary thatprovides aplatform-independent inter-
faceforfilehandling, networking, locking, threads, andsoon.When extending
Apache (aswewilldiscuss shortly), portability islargely guaranteed provided that
onlycallstotheAPRaremade andthatcallstoplatform-specific libraries are
avoided.
Aswesaid,Apache istailored notonlytoprovide flexibility (inthesense that
itcanbeconfigured toconsiderable detail), butalsothatitisrelatively easyto
extend itsfunctionality. Forexample, laterinthischapter wewilldiscuss adaptive
replication inGlobule, ahome-brew content delivery network developed inthe
authors' group attheVrijeUniversiteit Amsterdam. Globule isimplemented asan
extension toApache, based ontheAPR, butalsolargely independent ofother
extensions developed forApache.
From acertain perspective, Apache canbeconsidered asacompletely general
server tailored toproduce aresponse toanincoming request. Ofcourse, thereare
allkinds ofhidden dependencies andassumptions bywhich Apache turnsoutto
beprimarily suited forhandling requests forWebdocuments. Forexample, asweSEC. 12.2 PROCESSES 557
mentioned. Webbrowsers andservers useHTTP astheircommunication protocol.
HTTP isvirtually always implemented ontopofTCP, forwhich reason thecore
ofApache assumes thatallincoming requests adhere toaTCP-based connection-
oriented wayofcommunication. Requests based on,forexample, UDP cannot be
properly handled without modifying theApache core.
However, theApache coremakes fewassumptions onhowincoming requests
should behandled. Itsoverall organization isshown inFig.12-7. Fundamental to
thisorganization istheconcept ofahook,which isnothing butaplaceholder fora
specific group offunctions. TheApache coreassumes thatrequests areprocessed
inanumber ofphases, eachphase consisting ofafewhooks. Each hookthusrep-
resents a.group ofsimilar actions thatneedtobeexecuted aspartofprocessing a
request.
Figure 12-7. Thegeneral organization oftheApache Webserver.
Forexample, there isahook totranslate aURL toalocal filename. Such a
translation willalmost certainly needtobedonewhen processing arequest. Like-
wise, there isahook forwriting information toalog,ahook forchecking acli-
ent's identification, ahook forchecking access rights, andahook forchecking
which MIME typetherequest isrelated to(e.g., tomake surethattherequest can
beproperly handled). Asshown inFig.12-7, thehooks areprocessed inapre-
determined order. Itisherethatweexplicitly seethatApache enforces aspecific
flowofcontrol concerning theprocessing ofrequests.
Thefunctions associated withahook areallprovided byseparate modules.
Although inprinciple adeveloper could change thesetofhooks thatwillbeSS8 DISTRIBUTED WEB-BASED SYSTEMS CHAP. ]2
processed byApache, itisfarmore common towrite modules containing the
functions thatneedtobecalled aspartofprocessing thestandard hooks provided
byunmodified Apache. Theunderlying principle isfairly straightforward. Every
hookcancontain asetoffunctions thateachshould match aspecific function pro-
totype (i.e.,listofparameters andreturn type). Amodule developer willwrite
functions forspecific hooks. When compiling Apache, thedeveloper specifies
which function should beadded towhich hook. Thelatter isshown inFig.12-7as
thevarious linksbetween functions andhooks.
Because there maybetensofmodules, eachhook willgenerally contain sev-
eralfunctions. Normally. modules areconsidered tobemutual independent, so
thatfunctions inthesame hook willbeexecuted insome arbitrary order. How-
ever, Apache canalsohandle module dependencies byletting adeveloper specify
anordering inwhich functions from different modules should beprocessed. By
andlarge, theresult isaWebserver thatisextremely versatile. Detailed informa-
tiononconfiguring Apache, aswellasagood introduction tohowitcanbe
extended canbefound inLaurie andLaurie (2002).
12.2.3 WebServer Clusters
Animportant problem related totheclient-server nature oftheWebisthata
Webserver caneasily become overloaded. Apractical solution employed inmany
designs istosimply replicate aserver onacluster ofservers anduseaseparate
mechanism, suchasafrontend,toredirect client requests tooneofthereplicas.
Thisprinciple isshown inFig.12-8, andisanexample ofhorizontal distribution
aswediscussed inChap. 2.
Figure 12-8. Theprinciple ofusing aserver cluster incombination withafront
endtoimplement aWebservice.
Acrucial aspect ofthisorganization isthedesign ofthefront end.asitcan
become aserious performance bottleneck, whatwillallthetraffic passing through
it.Ingeneral, adistinction ismade between front ends operating astransport-
layer switches, andthose thatoperate attheleveloftheapplication layer.SEC. 12.2 PROCESSES 559
Whenever aclient issues anHTTP request, itsetsupaTCPconnection tothe
server. Atransport-layer switch simply passes thedatasentalong theTCPcon-
nection tooneoftheservers, depending onsome measurement oftheserver's
load.Theresponse fromthatserver isreturned totheswitch, which willthenfor-
wardittotherequesting client. Asanoptimization, theswitch andservers can
collaborate inimplementing aTCPhandotT, aswediscussed inChap. 3.The
maindrawback ofatransport-layer switch isthattheswitch cannot takeinto
account thecontent oftheHTTP request thatissentalong theTCPconnection. At
best,itcanonlybaseitsredirection decisions onserver loads.
Asageneral rule,abetter approach istodeploy content-aware request dis-
tribution, bywhich thefrontendfirstinspects anincoming HTTP request, and
thendecides which server itshould forward thatrequest to.Content-aware distri-
bution hasseveral advantages. Forexample, ifthefrontendalways forwards re-
quests forthesamedocument tothesameserver, thatserver maybeabletoeffec-
tively cache thedocument resulting inhigher response times. Inaddition, itispos-
sibletoactually distribute thecollection ofdocuments among theservers instead
ofhaving toreplicate eachdocument foreachserver. Thisapproach makes more
efficient useoftheavailable storage capacity andallows using dedicated servers
tohandle special documents suchasaudioorvideo.
Aproblem withcontent-aware distribution isthatthefrontendneeds todoa
lotofwork. Ideally, onewould liketohavetheefficiency ofTCPhandoff andthe
functionality ofcontent-aware distribution. What weneedtodoisdistribute the
workofthefrontend,andcombine thatwithatransport-layer switch, asproposed
inAronetal.(2000). Incombination withTCPhandoff, thefrontendhastwo
tasks. First, when arequest initially comes in,itmustdecide which server will
handle therestofthecommunication withtheclient. Second, thefrontendshould
forward theclient's TCPmessages associated withthehanded-off TCPconnec-
tion.
Figure 12-9.Ascalable content-aware cluster ofWebservers.560 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
These twotaskscanbedistributed asshown inFig.12-9. Thedispatcher is
responsible fordeciding towhich server aTCPconnection should behanded off;
adistributor monitors incoming TCPtraffic forahanded-off connection. The
switch isusedtoforward TCPmessages toadistributor. When aclient firstcon-
tactstheWebservice, itsTCPconnection setupmessage isforwarded toadistri-
butor, which intumcontacts thedispatcher toletitdecide towhich server the
connection should behanded off.Atthatpoint, theswitch isnotified thatitshould
sendallfurther TCPmessages forthatconnection totheselected server.
There arevarious other alternatives andfurther refinements forsetting up
Webserver clusters. Forexample, instead ofusing anykindoffrontend,itisalso
possible touseround-robin DNSbywhich asingle domain name isassociated
withmultiple IPaddresses. Inthiscase,when resolving thehostname ofaWeb
site,aclient browser would receive alistofmultiple addresses, eachaddress cor-
responding tooneoftheWebservers. Normally, browsers choose thefirstaddress
onthelist.However, whatapopular DNSserver suchasBIND doesiscirculate
theentries ofthelistitreturns (Albitz andLiu,2001). Asaconsequence, we
obtain asimple distribution ofrequests overtheservers inthecluster.
Finally, itisalsopossible nottouseanysortofintermediate butsimply to
giveeachWebserver withthesameIPaddress. Inthatcase,wedoneedtoas-
sumethattheservers areallconnected through asingle broadcast LAN. What will
happen isthatwhenanHTTP request arrives, theIProuter connected tothatLAN
willsimply forward ittoallservers, whothenrunthesamedistributed algorithm
todeterministically decide which ofthemwillhandle therequest.
Thedifferent waysoforganizing Webclusters andalternatives liketheones
wediscussed above, aredescribed inanexcellent survey byCardellini et
aL(2002). Theinterested reader isreferred totheirpaper forfurther details and
references.
12.3COMMUNICATION
When itcomes toWeb-based distributed systems, thereareonlyafewcom-
munication protocols thatareused.First. fortraditional Websystems, HTTP is
thestandard protocol forexchanging messages. Second, when considering \Yeb
services, SOAP isthedefault wayformessage exchange. Bothprotocols willbe
discussed inafairamount ofdetail inthissection.
12.3.1 Hypertext Transfer Protocol
Allcommunication intheWebbetween clients andservers isbased onthe
Hypertext Transfer Protocol (HTTP). HTTP isarelatively simple client-server
protocol: aclient sends arequest message toaserver andwaits foraresponse
message. Animportant property ofHTTP isthatitisstateless. Inother words. itSEC. 12.3 COMMUNICATION 561
doesnothaveanyconcept ofopenconnection anddoesnotrequire aserver to
maintain information onitsclients. HTTP isdescribed inFielding etal.(1999).
HTTPConnections
HTTP isbased onTCP.Whenever aclient issues arequest toaserver, itfirst
setsupaTCPconnection totheserver andthensends itsrequest message onthat
connection. Thesame connection isusedforreceiving theresponse. Byusing
TCPasitsunderlying protocol, HTTP neednotbeconcerned about lostrequests
andresponses. Aclient andserver maysimply assume thattheirmessages makeit
totheotherside.Ifthings dogowrong, forexample, theconnection isbroken ora
time-out occurs anerrorisreported. However, ingeneral, noattempt ismade to
recover fromthefailure.
Oneoftheproblems withthefirstversions ofHTTP wasitsinefficient useof
TCPconnections. EachWebdocument isconstructed fromacollection ofdif-
ferent filesfromthesameserver. Toproperly display adocument, itisnecessary
thatthesefilesarealsotransferred totheclient. Eachofthesefilesis,inprinciple,
justanother document forwhich theclient canissueaseparate request totheser-
verwhere theyarestored.
InHTTP version 1.0andolder, eachrequest toaserver required setting upa
separate connection, asshown inFig.12-10(a). When theserver hadresponded,
theconnection wasbroken down again. Suchconnections arereferred toasbeing
nonpersistent. Amajor drawback ofnonpersistent connections isthatitisrela-
tively costly tosetupaTCPconnection. Asaconsequence, thetimeitcantaketo
transfer anentire document withallitselements toaclient maybeconsiderable.
Figure 12·10. (a)Using nonpersistent connections. (b)Using persistent connections.
NotethatHTTP doesnotpreclude thataclient setsupseveral connections
simultaneously tothesame server. Thisapproach isoften usedtohidelatency562 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
caused bytheconnection setuptime,andtotransfer datainparallel fromtheser-
vertotheclient. Many browsers usethisapproach toimprove performance.
Another approach thatisfollowed inHTTP version 1.1istomake useofa
persistent connection, which canbeusedtoissueseveral requests (andtheirre-
spective responses), without theneedforaseparate connection foreach(re-
quest. response )-pair. Tofurther improve performance, aclient canissueseveral
requests inarowwithout waiting fortheresponse tothefirstrequest (alsorefer-
redtoaspipelining). Using persistent connections isillustrated inFig.12-]O(b).
HTTP Methods
HTTP hasbeendesigned asageneral-purpose client-server protocol oriented
toward thetransfer ofdocuments inbothdirections. Aclient canrequest eachof
theseoperations tobecarried outattheserver bysending arequest message con-
taining theoperation desired totheserver. Alistofthemostcommonly-used re-
questmessages isgiven inFig.12-11.
Figure 12-11. Operations supported byHTTP.
HTTP assumes thateachdocument mayhaveassociated metadata, which are
stored inaseparate header thatissentalong witharequest orresponse. Thehead
operation issubmitted totheserver when aclient doesnotwanttheactual docu-
ment, butrather onlyitsassociated metadata. Forexample, using theheadopera-
tionwillreturn thetimethereferred document wasmodified. Thisoperation can
beusedtoverify thevalidity ofthedocument ascached bytheclient. Itcanalso
beusedtocheck whether adocument exists, without having toactually transfer
thedocument.
Themostimportant operation isget.Thisoperation isusedtoactually fetcha
document fromtheserver andreturn ittotherequesting client. Itisalsopossible
tospecify thatadocument should bereturned onlyifithasbeenmodified aftera
specific time.Also, HTTP allows documents tohaveassociated tags.(character
strings) andtofetchadocument onlyifitmatches certain tags.
Theputoperation istheopposite ofthegetoperation. Aclient canrequest a
server tostoreadocument under agiven name (which issentalong withthere-SEC. 12.3 COMMUNICATION 563
quest). Ofcourse, aserver willingeneral notblindly execute putoperations, but
willonlyaccept suchrequests fromauthorized clients. Howthesesecurity issues
aredealtwithisdiscussed later.
Theoperation postissomewhat similar tostoring adocument, except thata
client willrequest datatobeadded toadocument orcollection ofdocuments. A
typical example isposting anarticle toanewsgroup. Thedistinguishing feature,
compared toaputoperation isthatapostoperation tellstowhich group ofdocu-
ments anarticle should be"added." Thearticle issentalong withtherequest. In
contrast, aputoperation carries adocument andthenameunder which theserver
isrequested tostorethatdocument.
Finally, thedelete operation isusedtorequest aserver toremove thedocu-
mentthatisnamed inthemessage senttotheserver. Again, whether ornotdele-
tionactually takesplacedepends onvarious security measures. Itmayevenbethe
casethattheserver itself doesnothavetheproper permissions todelete the
referred document. Afterall,theserver isjustauserprocess.
HTTP Messages
Allcommunication between aclient andserver takesplacethrough messages.
HTTP recognizes onlyrequest andresponse messages. Arequest message con-
sistsofthreeparts, asshown inFig.12-12(a). Therequest lineismandatory and
identifies theoperation thattheclient wants theserver tocarryoutalong witha
reference tothedocument associated withthatrequest. Aseparate fieldisusedto
identify theversion ofHTTP theclient isexpecting. Weexplain theadditional
message headers below.
Aresponse message startswithastatus linecontaining aversion number and
alsoathree-digit status code, asshown inFig.12-12(b). Thecodeisbriefly ex-
plained withatextual phrase thatissentalong aspartofthestatus line.Forex-
ample, status code200indicates thatarequest couldbehonored, andhastheasso-
ciated phrase "OK." Other frequently usedcodes are:
400(BadRequest)
403(Forbidden)
404(NotFound).
Arequest orresponse message maycontain additional headers. Forexample,
ifaclient hasrequested apostoperation foraread-only document, theserver will
respond withamessage having status code405("Method NotAllowed") along
withanAllow message header specifying thepermitted operations (e.g.,headand
get).Asanother example, aclient maybeinterested onlyinadocument ifithas
notbeenmodified sincesometimeT.Inthatcase,theclient's getrequest isaug-
mented withanIf-Modified-Since message header specifying valueT.564 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Figure 12-12. (a)HTTP request message. (b)HTTP response message.
Fig.12-13 shows anumber ofvalidmessage headers thatcanbesentalong
witharequest orresponse. Mostoftheheaders areself-explanatory, sowewill
notdiscuss everyoneofthem.
There arevarious message headers thattheclient cansendtotheserver ex-
plaining whatitisabletoaccept asresponse. Forexample, aclient maybeableto
accept responses thathavebeencompressed using thegzipcompression program
available onmostWindows andUNIX machines. Inthatcase,theclient willsend
anAccept-Encoding message header along withitsrequest, withitscontent con-
taining "Accept-Encoding:gzip." Likewise, anAccept message header canbe
usedtospecify, forexample, thatonlyHTML Webpages maybereturned.
There aretwomessage headers forsecurity, butaswediscuss laterinthissec-
tion,Websecurity isusually handled withaseparate transport-layer protocol.
TheLocation andReferer message header areusedtoredirectaclient toan-
otherdocument (notethat"Referer" ismisspelled inthespecification). Redirect-
ingcorresponds totheuseofforwarding pointers forlocating adocument. asSEC. 12.3 COMMUNICATION 565
Figure 12-13. Some HTTP message headers.
explained inChap. 5.When aclient issues arequest fordocument D,theserver
maypossibly respond withaLocation message header, specifying thattheclient
should reissue therequest, butnowfordocument D'.When usingthereference to
D',theclient canaddaReferer message header containing thereference toDto
indicate whatcaused theredirection. Ingeneral, thismessage header isusedto
indicate theclient's mostrecently requested document.
TheUpgrade message header isusedtoswitch toanother protocol. Forex-
ample, client andserver mayuseHTTP/l.l initially onlytohaveageneric wayof
setting upaconnection. Theserver mayimmediately respond withtelling thecli-
entthatitwants tocontinue communication withasecure version ofHTTP, such
asSHTTP (Rescorla andSchiffman, 1999). Inthatcase,theserver willsendan
Upgrade message header withcontent "Upgrade:SHTTP."566 DISTRIBUTED WEB;.BASED SYSTEMS CHAP. 12
12.3.2 Simple Object Access Protocol
Where HTTP isthestandard communication protocol fortraditional Web-
based distributed systems, theSimple Object Access Protocol (S()AP)forms the
standard forcommunication withWebservices (Gudgin etaI.,20(3). SOAP has
made HTTP evenmoreimportant thanitalready was:mostSOAP cornmunica-
tionsareimplemented through HTTP. SOAP byitselfisnotadirticult protocol.
Itsmainpurpose istoprovide arelatively simple means toletdifferent parties
whomayknow verylittleofeachotherbeabletocommunicate. Jnotherwords,
theprotocol isdesigned withtheassumption thattwocommunicating parties have
verylittlecommon knowledge.
Based onthisassumption, itshould come asnosurprise thatSOAP messages
arelargely based onXML. Recall thatXML isameta-markup language, meaning
thatanXML description includes thedefinition oftheelements Ihatareusedto
describe adocument. Inpractice, thismeans thatthedefinition ()f thesyntax as
usedforamessage ispartofthatmessage. Providing thissyntax allows areceiver
toparseverydifferent typesofmessages. Ofcourse, themeaning ofamessage is
stillleftundefined, andthusalsowhatactions totakewhenamessage comes in.If
thereceiver cannot make anysense outofthecontents ofamessage. noprogress
canbemade.
ASOAP message generally consists oftwoparts, which arejointly putinside
whatiscalled aSOAP envelope. Thebodycontains theactual m~ssage, whereas
theheader isoptional, containing information relevant fornodes along thepath
fromsender toreceiver. Typically, suchnodes consist ofthevarious processes in
amultitiered implementation ofaWebservice. Everything intheenvelope is
expressed inXML, thatis,theheader andthebody.
Strange asitmayseem, aSOAP envelope doesnotcontain theaddress ofthe
recipient. Instead, SOAP explicitly assumes thattherecipient isspecified bythe
protocol thatisusedtotransfer messages. Tothisend,SOAP sp<;cifies bindings
tounderlying transfer protocols. Atpresent, twosuchbindings exist: onetoHTTP
andonetoSMTP, theInternet mail-transfer protocol. So,forexample, when a
SOAP message isbound toHTTP, therecipient willbespecified intheformofa
URL, whereas abinding toSMTP willspecify therecipient intheformofane-
mailaddress.
These twodifferent types ofbindings alsoindicate twodifferent styles of
interactions. Thefirst,mostcommon one.istheconversational exchange style.
Inthisstyle,twoparties essentially exchange structured documents. Forexample,
suchadocument maycontain acomplete purchase orderasonewould fillinwhen
electronically booking aflight. Theresponse tosuchanorder could beaconfir-
mation document, nowcontaining anorder number, flight information. aseat
reservation, andperhaps alsoabarcodethatneeds tobescanned when boarding.
Incontrast, anRPC-style exchange adheres closer tothetraditional request-
response behavior when invoking aWebservice. Inthiscase,theSOAP messageSEC. 11.3 COMMUNICATION 567
willidentify explicitly theprocedure tobecalled, andalsoprovide alistofparam-
etervalues asinputtothatcall.Likewise, theresponse willbeaformal message
containing theresponse tothecall.
Typically, anRPC-style exchange issupported byabinding toHTTP,
whereas aconversational stylemessage willbebound toeither SMTP orHTIP.
However, inpractice, mostSOAP messages aresentoverHTTP.
Animportant observation isthat,although XMLmakes itmuch easier tousea
general parser because syntax definitions arenowpartofamessage, theXML
syntax itselfisextremely verbose. Asaresult, parsing XML messages inpractice
oftenintroduces aserious performance bottleneck (Allman, 2003). Inthisrespect,
itissomewhat surprising thatimproving XML performance receives-relatively lit-
tleattention, although solutions areunderway (see,e.g.,Kostoulas etal.,2006).
Figure 12-14. Anexample ofanXML-based SOAP message.
What isequally surprising isthatmany people believe thatXML specif-
ications canbeconveniently readbyhuman beings. Theexample shown in
Fig.12-14 istaken fromtheofficial SOAP specification (Gudgin etal.,2003).
Discovering whatthisSOAP message conveys requires somesearching, anditis
nothardtoimagine thatobscurity ingeneral maycomeasanatural by-product of
using XML. Thequestion thencomes tomind, whether thetext-based approach as
followed forXML hasbeentherightone:noonecanconveniently readXML
documents, andparsers areseverely slowed down.
12.4NAMING
TheWebusesasingle naming system torefertodocuments. Thenames used
arecalled Uniform Resource Identifiers orsimply URIs (Berners-Lee etal.,
2005). URIscome intwoforms. AUniform Resource Locator (URL) isaURI568 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
thatidentifies adocument byincluding information onhowandwhere toaccess
thedocument. Inother words, aURL isalocation-dependent reference toadocu-
ment. Incontrast, aUniform Resource Name (URN) actsastrueidentifier as
discussed inChap. 5.AURN isusedasaglobally unique, location-independent,
andpersistent reference toadocument.
Theactual syntax ofaURIisdetermined byitsassociated scheme. Thename
ofascheme ispartoftheURI. Many different schemes havebeendefined, and'in
thefollowing wewillmention afewofthem along withexamples oftheirassoci-
atedURIs. Thehttpscheme isthebestknown, butitisnottheonlyone.We
should alsonotethatthedifference between URL andURN isgradually diminish-
ing.Instead, itisnowcommon tosimply define URIname spaces [seealsoDaigle
etal.(2002)].
Inthecase'ofURLs, weseethattheyoften contain information onhowand
where toaccess adocument. Howtoaccess adocument isgenerally reflected by
thename ofthescheme thatispartoftheURL, suchashttp,ftp, ortelnet. Where
adocument islocated isembedded inaURL bymeans oftheDNS name ofthe
server towhich anaccess request canbesent,although anIPaddress canalsobe
used. Thenumber oftheportonwhich theserver willbelistening forsuchre-
quests isalsopartoftheURL; when leftout,adefault portisused. Finally, a
URLalsocontains thename ofthedocument tobelooked upbythatserver, lead-
ingtothegeneral structures shown inFig.12-15.
Figure 12-15. Often-used structures forURLs. (a)Using onlyaDNS name.
(b)Combining aDNS name withaportnumber. (c)Combining anIPaddress
withaportnumber.
Resolving aURL suchasthose shown inFig.12-15 isstraightforward. Ifthe
server isreferred tobyitsDNS name, thatname willneed toberesolved tothe
server's IPaddress. Using theportnumber contained intheURL, theclient can
thencontact theserver using theprotocol named bythescheme, andpassitthe
document's name thatforms thelastpartoftheURL.SEC. 12.4 NAMING 569
Figure 12-16. Examples ofURIs.
Although URLs arestillcommonplace intheWeb, various separate URI
name spaces have been proposed forother kinds ofWebresources. Fig.12-16
shows anumber ofexamples ofURIs. ThehttpURIisusedtotransfer documents
using HTTP asweexplained above. Likewise, there isanftpURIforfiletransfer
using FTP.
Animmediate form ofdocuments issupported bydata URIs (Masinter,
1998). InsuchaURI,thedocument itself isembedded intheURI,similar toem-
bedding thedataofafileinaninode (Mullender andTanenbaum, 1984). Theex-
ample shows aURIcontaining plain textfortheGreek character string aPr·URIs areoften usedaswellforpurposes other thanreferring toadocument.
Forexample, atelnet URIisusedforsetting upatelnet session toaserver. There
arealsoURIs fortelephone-based communication asdescribed inSchulzrinne
(2005). ThetelURIasshown inFig.12-16 essentially embeds onlyatelephone
number andsimply letstheclient toestablish acallacross thetelephone network.
Inthiscase, theclient willtypically beatelephone. Themodem URIcanbeused
tosetupamodem-based connection withanother computer. Intheexample, the
URIstates thattheremote modem should adhere totheITU-T V32standard.
12.5SYNCHRONIZATION
Synchronization hasnotbeen much ofanissue formost traditional Web-
based systems fortworeasons. First, thestrict client-server organization ofthe
Web, inwhich servers never exchange information withother servers (orclients
withother clients) means thatthere isnothing much tosynchronize. Second, the
Webcanbeconsidered asbeing aread-mostly system. Updates aregenerally done
byasingle person orentity, andhardly everintroduce write-write conflicts.
However, things arechanging. Forexample, there isanincreasing demand to
provide support forcollaborative authoring ofWeb documents. Inother words,570 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
theWebshould provide support forconcurrent updates ofdocuments byagroup
ofcollaborating users orprocesses. Likewise, withtheintroduction ofWeb ser-
vices, wearenowseeing aneed forservers tosynchronize witheachother and
thattheiractions arecoordinated. Wealready discussed coordination inWebser-
vices above. Wetherefore briefly paysome attention tosynchronization forcolla-
borative maintenance ofWebdocuments.
Distributed authoring ofWebdocuments ishandled through aseparate proto-
col,namely WebDAV (Goland etal.,1999). WebDAV stands forWebDistri-
butedAuthoring andVersioning andprovides asimple means tolockashared
document, andtocreate, delete, copy, andmove documents fromremote Webser-
vers.Webriefly describe synchronization assupported inWebDA V.Anoverview
ofhowWebDA Vcanbeused inapractical setting isprovided inKimetal.
(2004).
Tosynchronize concurrent access toashared document, WebDA Vsupports a
simple locking mechanism. There aretwotypes ofwrite locks. Anexclusive write
lockcanbeassigned toasingle client, andwillprevent anyother client from
modifying theshared document while itislocked. There isalsoashared write
lock, which allows multiple clients tosimultaneously update thedocument. Be-
cause locking takes place atthegranularity ofanentire document, shared write
locks areconvenient when clients modify different parts ofthesame document.
However, theclients, themselves, willneedtotakecarethatnowrite-write con-
flictsoccur.
Assigning alockisdonebypassing alocktoken totherequesting client. The
server registers which client currently hasthelocktoken. Whenever theclient
wants tomodify thedocument, itsends anHTTP postrequest totheserver, along
withthelocktoken. Thetoken shows thattheclient haswrite-access tothedocu-
ment, forwhich reason theserver willcarry outtherequest.
Animportant design issue isthatthereisnoneedtomaintain aconnection be-
tween theclient andtheserver while holding thelock. Theclient cansimply
disconnect from theserver afteracquiring thelock. andreconnect totheserver
when sending anHTTP request.
Note thatwhen aclient holding alocktoken crashes. theserver willoneway
ortheother have toreclaim the10ck.WebDAV does notspecify howservers
should handle these andsimilar situations, butleaves thatopentospecific imple-
mentations. Thereasoning isthatthebestsolution willdepend onthetypeofdoc-
uments thatWebDAV isbeing usedfor.Thereason forthisapproach isthatthere
isnogeneral waytosolve theproblem oforphan locks inaclean way.
12.6CONSISTENCY ANDREPLICATION
Perhaps oneofthemost important systems-oriented developments inWeb-
based distributed systems isensuring thataccess toWeb documents meets
stringent performance andavailability requirements. These requirements haveledSEC. 12.6 CONSISTENCY AND REPLICATION 571
tonumerous proposals forcaching andreplicating Webcontent, ofwhich various
oneswillbediscussed inthissection. Where theoriginal schemes (which arestill
largely deployed) havebeen targeted toward supporting static content, much
effort isalsobeing putintosupport dynamic content, thatis,supporting docu-
ments thataregenerated astheresult ofarequest, aswellasthose containing
scripts andsuch.Anexcellent andcomplete picture ofWebcaching andreplica-
tionisprovided byRabinovich andSpatscheck (2002).
12.6.1 WebProxy Caching
Client-side caching generally occurs attwoplaces. Inthefirst.place, most
browsers areequipped withasimple caching facility. Whenever adocument is
fetched itisstored inthebrowser's cache fromwhere itisloaded thenexttime.
Clients cangenerally configure caching byindicating whenconsistency checking
should takeplace, asweexplain forthegeneral casebelow.
Inthesecond place, aclient's siteoftenrunsaWebproxy. Asweexplained, a
Webproxy accepts requests fromlocalclients andpasses these toWebservers.
When aresponse comes in,theresult ispassed totheclient. Theadvantage ofthis
approach isthattheproxy cancache theresult andreturn thatresult toanother cli-
ent,ifnecessary. Inotherwords, aWebproxy canimplement ashared cache.
Inaddition tocaching atbrowsers andproxies, itisalsopossible toplace
caches thatcover aregion, orevenacountry, thusleading tohierarchical caches.
Suchschemes aremainly usedtoreduce network traffic, buthavethedisadvan-
tageofpotentially incurring ahigher latency compared tousing nonhierarchical
schemes. Thishigher latency iscaused bytheneedfortheclient tocheck multiple
caches rather thanjustoneinthenonhierarchical scheme. However, thishigher
latency isstrongly related tothepopularity ofadocument: forpopular documents,
thechance offinding acopyinacache closer totheclient ishigher thanfora
unpopular document.
Asanalternative tobuilding hierarchical caches, onecanalsoorganize caches
forcooperative deployment asshown inFig.12-17. Incooperative caching or
distributed caching, whenever acache missoccurs ataWebproxy, theproxy
firstchecks anumber ofneighboring proxies toseeifoneofthemcontains there-
quested document. Ifsuchacheck fails,theproxy forwards therequest tothe
Webserver responsible forthedocument. Thisscheme isprimarily deployed with
Webcaches belonging tothesameorganization orinstitution thatarecolocated in
thesameLAN. Itisinteresting tonotethatastudybyWolman etal.(1999) shows
thatcooperative caching maybeeffective foronlyrelatively small groups ofcli-
ents(intheorderoftensofthousands ofusers). However, suchgroups canalsobe
serviced byusing asingle proxy cache, which ismuch cheaper interms ofcom-
munication andresource usage.
Acomparison between hierarchical andcooperative caching byRodriguez et
al.(2001) makes clearthatthere arevarious trade-offs tomake. Forexample,572 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
because cooperative caches aregenerally connected through high-speed links, the
transmission timeneeded tofetchadocument ismuch lower thanforahierarchi-
calcache. Also,asistobeexpected, storage requirements arelessstrictforcoop-
erative caches thanhierarchical ones.Also, theyfindthatexpected latencies for
hierarchical caches arelower thanfordistributed caches.
Different cache-consistency protocols havebeendeployed intheWeb. To
guarantee thatadocument returned fromthecache isconsistent, someWebprox-
iesfirstsendaconditional HTTP getrequest totheserver withanadditional If-
Modified-Since request header, specifying thelastmodification timeassociated
withthecached document. Onlyifthedocument hasbeenchanged since that
time,willtheserver return theentire document. Otherwise, theWebproxy can
simply return itscached version totherequesting localclient. Following theter-
minology introduced inChap. 7,thiscorresponds toapull-based protocol.
Unfortunately, thisstrategy requires thattheproxy contacts aserver foreach
request. Toimprove performance atthecostofweaker consistency, thewidely-
usedSquid Webproxy (Wessels, 2004) assigns anexpiration timeT'expire that
depends onhowlongagothedocument waslastmodified when itiscached. In
particular, if1Jast.JTlodijied isthelastmodification timeofadocument (asrecorded
byitsowner), andTcached isthetimeitwascached, then
witha=0.2(thisvalue hasbeenderived frompractical experience). UntilTexpire,
thedocument isconsidered validandtheproxy willnotcontact theserver. After
theexpiration time,theproxy requests theserver tosendafreshcopy, unless itFigure 12-17. Theprinciple ofcooperative caching.SEC. 12.6 CONSISTENCY AND REPLICATION 573
hadnotbeenmodified. Inother words, when a=0,thestrategy isthesame asthe
previous onewediscussed.
Note thatdocuments thathavenotbeenmodified foralongtimewillnotbe
checked formodifications assoonasrecently modified documents. Theobvious
drawback isthataproxy mayreturn aninvalid document, thatis,adocument that
isolder thanthecurrent version stored attheserver. Worse yet,there isnoway
fortheclient todetect thefactthatitjustreceived anobsolete document.
Asanalternative tothepull-based protocol isthattheserver notifies proxies
thatadocument hasbeenmodified bysending aninvalidation. Theproblem with
thisapproach forWebproxies isthattheserver mayneedtokeeptrack ofalarge
number ofproxies, inevitably leading toascalability problem. However, bycom-
bining leases andinvalidations, CaoandLiu(1998) show thatthestatetobe
maintained attheserver canbekeptwithin acceptable bounds. Notethatthisstate
islargely dictated bytheexpiration times setforleases: thelower, thelesscaches
aserver needs tokeep track of.Nevertheless, invalidation protocols forWeb
proxy caches arehardly everapplied.
Acomparison ofWebcaching consistency policies canbefound inCaoand
Oszu (2002). Their conclusion isthatletting theserver sendinvalidations can
outperform anyother method interms ofbandwidth andperceived client latency,
while maintaining cached documents consistent withthose attheorigin server.
These findings holdforaccess patterns asoftenobserved forelectronic commerce
applications.
Another problem withWeb proxy caches isthattheycanbeusedonlyfor
static documents, thatis,documents thatarenotgenerated on-the-fly byWebser-
versastheresponse toaclient's request. These dynamically generated documents
areoften unique inthesense thatthesame request fromaclient willpresumably
leadtoadifferent response thenexttime. Forexample, many documents contain
advertisements (called banners) which change forevery request made. Wereturn
tothissituation below when wediscuss caching andreplication forWebapplica-
tions.
Finally, weshould alsomention thatmuch research hasbeenconducted to
findoutwhatthebestcache replacement strategies are.Numerous proposals exist,
butby-and-Iarge, simple replacement strategies suchasevicting theleastrecently
usedobject work wellenough. Anin-depth survey ofreplacement strategies is
presented inPodling andBoszormenyi (2003).
12.6.2Replication forWebHostingSystems
Astheimportance oftheWebcontinues toincrease asavehicle fororganiza-
tions topresent themselves andtodirectly interact withendusers, weseeashift
between maintaining thecontent ofaWeb siteandmaking surethatthesiteis
easily andcontinuously accessible. Thisdistinction haspaved thewayforcontent
delivery networks (CDNs). Themain ideaunderlying these CDNs isthattheyactasaWebhosting service, providing aninfrastructure fordistributing andrepli-
cating theWebdocuments ofmultiple sitesacross theInternet. Thesizeofthe
infrastructure canbeimpressive. Forexample, asof2006, Akamai isreported to
haveover18,000 servers spread across 70countries.
Thesheer sizeofaCON requires thathosted documents areautomatically
distributed andreplicated, leading tothearchitecture ofaself-managing system as
wediscussed inChap. 2.Inmostcases, alarge-scale CONisorganized along the
linesofafeedback-control loop,asshown inFig.12-]8andwhich isdescribed
extensively inSivasubramanian etal.(2004b).
Figure 12-18. Thegeneral organization ofaCDN asafeedback-control system
(adapted fromSivasubramanian etal..2004b).
There areessentially threedifferent kinds ofaspects related toreplication in
Webhosting systems: metric estimation, adaptation triggering, andtaking approp-
riatemeasures. Thelattercanbesubdivided intoreplica placement decisions, con-
sistency enforcement, andclient-request routing. Inthefollowing, webriefly pay
attention toeachthese.
Metric Estimation
Aninteresting aspect ofCONs isthattheyneedtomake atrade-off between
many aspects when itcomes tohosting replicated content. Forexample, access
timesforadocument maybeoptimal ifadocument ismassively replicated. butat
thesametimethisincurs afinancial cost,aswellasacostinterms ofbandwidth
usage fordisseminating updates. Byandlarge, therearemany proposals foresti-
mating howwellaCONisperforming. These proposals canbegrouped intosev-
eralclasses.
First,therearelatency metrics, bywhich thetimeismeasured foranaction.
forexample, fetching adocument, totakeplace. Trivial asthismayseem.
estimating latencies becomes difficult when, forexample, aprocess deciding on574 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12SEC. 12.6 CONSISTENCY AND REPLICA nON 575
theplacement ofreplicas needs toknow thedelaybetween aclient andsomere-
moteserver. Typically, analgorithm globally positioning nodes asdiscussed in
Chap. 6willneedtobedeployed.
Instead ofestimating latency, itmaybemoreimportant tomeasure theavail-
ablebandwidth between twonodes. Thisinformation isparticularly important
whenlargedocuments needtobetransferred, asinthatcasetheresponsiveness of
thesystem islargely dictated bythetimethatadocument canbetransferred.
There arevarious toolsformeasuring available bandwidth, butinallcasesitturns
outthataccurate measurements canbedifficult toattain. Further information can
befound inStrauss etal.(2003).
Another classconsists ofspatial metrics which mainly consist ofmeasuring
thedistance between nodes interms ofthenumber ofnetwork-level routing hops,
orhopsbetween autonomous systems. Again, determining thenumber ofhopsbe-
tween twoarbitrary nodes canbeverydifficult, andmayalsonotevencorrelate
withlatency (Huffaker etaI.,2002). Moreover, simply looking atrouting tables is
notgoing towork when low-level techniques suchasmulti-protocol label
switching (MPLS) aredeployed. MPLS circumvents network-level routing by
using virtual-circuit techniques toimmediately andefficiently forward packets to
theirdestination [seealsoGuichard etal.(2005)]. Packets maythusfollow com-
pletely different routes thanadvertised inthetables ofnetwork-level routers.
Athirdclassisformed bynetwork usage metrics which mostoftenentails
consumed bandwidth. Computing consumed bandwidth interms ofthenumber of
bytestotransfer isgenerally easy.However, todothiscorrectly, weneedtotake
intoaccount howoftenthedocument isread,howoftenitisupdated, andhow
oftenitisreplicated. Weleavethisasanexercise tothereader.
Consistency metrics tellustowhatextent areplica isdeviating fromitsmas-
tercopy. Wealready discussed extensively howconsistency canbemeasured in
thecontext ofcontinuous consistency inChap. 7(YuandVahdat, 2002).
Finally, financial metrics formanother classformeasuring howwellaCDN
isdoing. Although nottechnical atall,considering thatmostCDNoperate ona
commercial basis, itisclearthatinmany casesfinancial metrics willbedecisive.
Moreover, thefinancial metrics areclosely related totheactual infrastructure of
theInternet. Forexample, mostcommercial CDNs placeservers attheedgeofthe
Internet, meaning thattheyhirecapacity fromISPsdirectly servicing endusers.
Atthispoint, business models become intertwined withtechnological issues, an
areathatisnotatallwellunderstood. There isonlyfewmaterial available onthe
relation between financial performance andtechnological issues (Janiga etaI.,
20(H).
Fromtheseexamples itshould become clearthatsimply measuring theperfor-
mance ofaCDN, orevenestimating itsperformance maybyitself bean
extremely complex task.Inpractice, forcommercial CDNs theissuethatreally
counts iswhether theycanmeettheservice-level agreements thathavebeenmade
withcustomers. These agreements areoftenformulated simply interms ofhow576 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
quickly customers aretobeserviced. ItisthenuptotheCDNtomake surethat
theseagreements aremet. •..
Adaptation Triggering
Another question thatneeds tobeaddressed iswhen andhowadaptations are
tobetriggered. Asimple model istoperiodically estimate metrics andsubse-
quently takemeasures asneeded. Thisapproach isoftenseeninpractice. Special
processes located attheservers collect information andperiodically check for
changes.
Amajor drawback ofperiodic evaluation isthatsudden changes maybe
missed. Onetypeofsudden change thatisreceiving considerable attention isthat
offlashcrowds. Aflashcrowdisasudden burstinrequests foraspecific Web
document. Inmany cases, thesetypeofbursts canbringdown anentire service, in
tumcausing acascade ofservice outages aswitnessed during several events inthe
recent history oftheInternet.
Handling flashcrowds isdifficult. Averyexpensive solution istomassively
replicate aWebsiteandassoonasrequest ratesstarttorapidly increase, requests
should beredirected tothereplicas tooffload themaster copy. Thistypeofover-
provisioning isobviously notthewaytogo.Instead, whatisneeded isaflash-
crowdpredictor thatwillprovide aserver enough timetodynamically install
replicas ofWebdocuments, afterwhich itcanredirect requests when thegoing
getstough. Oneoftheproblems withattempting topredict flashcrowds isthat
theycanbesoverydifferent. Fig.12-19 shows access traces forfourdifferent
Websitesthatsuffered fromaflashcrowd. Asapointofreference, Fig.12-19(a)
shows regular access traces spanning twodays.There arealsosomeverystrong
peaks, butotherwise thereisnothing shocking going on.Incontrast, Fig.12-19(b)
shows atwo-day tracewithfoursudden flashcrowds. There isstillsomeregular-
ity,which maybediscovered afterawhile sothatmeasures canbetaken. How-
ever,thedamage maybebeendonebefore reaching thatpoint.
Fig.12-19(c) shows atracespanning sixdayswithatleasttwoflashcrowds.
Inthiscase,anypredictor isgoing tohaveaserious problem, asitturnsoutthat
bothincreases inrequest ratearealmost instantaneously. Finally, Fig.12-19(d)
shows asituation inwhich thefirstpeakshould probably cause noadaptations,
butthesecond obviously should. Thissituation turns outtobethetypeof
behavior thatcanbedealtwithquitewellthrough runtime analysis.
Onepromising method topredict flashcrowds isusing asimple linear extra-
polation technique. Baryshikov etal.(2005) propose tocontinuously measure the
number ofrequests toadocument during aspecific timeinterval [t-W,t), where
Wisthewindowsize. Theinterval itselfisdivided intosmall slots, where for
eachslotthenumber ofrequests arecounted. Then. byapplying simple linear
regression. wecanfitacurve ftexpressing thenumber ofaccesses asafunction
oftime. Byextrapolating thecurve totimeinstances beyond t,weobtain aSEC. 12.6
Figure 12-19. Onenormal andthree different access patterns reflecting flash-
crowd behavior (adapted fromBaryshnikov etal.,2005).
prediction forthenumber ofrequests. Ifthenumber ofrequests arepredicted to
exceed agiven threshold, analarm israised.
Thismethod works remarkably wellformultple access patterns. Unfortun-
ately, thewindow sizeaswellasdetermining whatthealarm threshold aresup-
posed tobedepends highly ontheWebserver traffic. Inpractice, thismeans that
much manual finetuning isneeded toconfigure anidealpredictor foraspecific
site.Itisyetunknown howflash-crowd predictors canbeautomatically config-
ured.
Adjustment Measures
Asmentioned, thereareessentially onlythree(related) measures thatcanbe
taken tochange thebehavior ofaWebhosting service: changing theplacement of
replicas, changing consistency enforcement, anddeciding onhowandwhen to
redirect client requests. Wealready discussed thefirsttwomeasures extensively
inChap. 7.Client-request redirection deserves some moreattention. Before we
discuss someofthetrade-offs, letusfirstconsider howconsistency andreplica-
tionaredealtwithinapractical setting byconsidering theAkamai situation
(Leighton andLewin, 2000; andDilley etal.,2002).
Thebasic ideaisthateachWebdocument consists ofamain HTML (or
XML) pageinwhich several otherdocuments suchasimages, video, andaudioCONSISTENCY AND REPLICATION 577578
have been embedded. Todisplay theentire document, itisnecessary thatthe
embedded documents arefetched bytheuser's browser aswell.Theassumption is
thatthese embedded documents rarely change, forwhich reason itmakes sense to
cache orreplicate them.
Each embedded document isnormally referenced through aURL. However,
inAkamai's CON, suchaURL ismodified suchthatitrefers toavirtualghost,
which isareference toanactual server intheCON. TheURL alsocontains the
hostname oftheorigin server forreasons weexplain next.Themodified URL is
resolved asfollows, asisalsoshown inFig.12-20.
Figure 12-20. Theprincipal working oftheAkamai CDN.
Thename ofthevirtual ghost includes aONS name suchasghosting. com,
which isresolved bytheregular ONS naming system toaCON DNS server (the
result ofstep3).Each suchONS server keeps track ofservers close totheclient.
Tothisend,anyoftheproximity metrics wehave discussed previously could be
used. Ineffect, theCON ONS servers redirects theclient toareplica server best
forthatclient (step4),which could mean theclosest one,theleast-loaded one.or
acombination ofseveral suchmetrics (theactual redirection policy ispropri-
etary).
Finally, theclient forwards therequest fortheembedded document tothese-
lected CDN server. Ifthisserver doesnotyethave thedocument, itfetches it
from theoriginal Web server (shown asstep6).caches itlocally, andsubse-
quently passes ittotheclient. Ifthedocument wasalready intheCDN server's
cache, itcanbereturned forthwith. Notethatinorder tofetch theembedded docu-
ment, thereplica server must beabletosendarequest totheorigin server. for
which reason itshostname isalsocontained intheembedded document's URL.
Aninteresting aspect ofthisscheme isthesimplicity bywhich consistency of
documents canbeenforced. Clearly, whenever amain document ischanged. aDISTRIBUTED WEB-BASED SYSTEMS CHAP. 12SEC. 12.6 CONSISTENCY AND REPLICATION 579
client willalways beabletofetchitfromtheorigin server. Inthecaseofembed-
deddocuments, adifferent approach needs tobefollowed asthesedocuments are,
inprinciple, fetched fromanearby replica server. Tothisend,aURL foran
embedded document notonlyrefers toaspecial hostnamethateventually leadsto
aCDN DNSserver, butalsocontains aunique identifier thatischanged every
timetheembedded document changes. Ineffect, thisidentifier changes thename
oftheembedded document. Asaconsequence, when theclient isredirected toa
specific CDN server, thatserver willnotfindthenamed document initscache
andwillthusfetchitfromtheorigin server. Theolddocument willeventually be
evicted fromtheserver's cache asitisnolonger referenced.
Thisexample already shows theimportance ofclient-request redirection. In
principle, byproperly redirecting clients, aCDN canstayincoritrol when it
comes toclient-perceived performance, butalsotaking intoaccount global system
performance by,forexample, avoiding thatrequests aresenttoheavily loaded
servers. These so-called adaptive redirection policiescanbeapplied wheninfor-
mation onthesystem's current behavior isprovided totheprocesses thattake
redirection decisions. Thisbrings uspartly backtothemetric estimation tech-
niques discussed previously.
Besides thedifferent policies, animportant issueiswhether request redirec-
tionistransparent totheclient ornot.Inessence, thereareonlythreeredirection
techniques: TCPhandoff, DNSredirection, andHTTP redirection. Wealready
discussed TCPhandoff. Thistechnique isapplicable onlyforserver clusters and
doesnotscaletowide-area networks.
DNSredirection isatransparent mechanism bywhich theclient canbekept
completely unaware ofwhere documents arelocated. Akamai's two-level redirec-
tionisoneexample ofthistechnique. Wecanalsodirectly deploy DNStoreturn
oneofseveral addresses aswediscussed before. Note, however, thatDNSre-
direction canbeapplied onlytoanentire site:thenameofindividual documents
doesnotfitintotheDNSnamespace.
HTTP redirection, finally, isanontransparent mechanism. When aclient re-
quests aspecific document, itmaybegiven analternative URLaspartofan
HTTP response message towhich itisthenredirected. Animportant observation
isthatthisURLisvisible totheclient's browser. Infact,theusermaydecide to
bookmark thereferral URL, potentially rendering theredirection policy useless.
12.6.3Replication ofWebApplications
Uptothispointwehavemainly concentrated oncaching andreplicating static
Webcontent. Inpractice, weseethattheWebisincreasingly offering more
dynamically generated content, butthatitisalsoexpanding toward offering ser-
vices thatcanbecalled byremote applications. Alsointhesesituations wesee
thatcaching andreplication canhelpconsiderably inimproving theoverall580 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
performance, although themethods toreach suchimprovements aremoresubtle
thanwhatwediscussed sofar[seealsoContietal.(2005)].
When considering improving performance ofWebapplications through cach-
ingandreplication, matters arecomplicated bythefactthatseveral solutions can
bedeployed, withnosingle onestanding outasthebest.Letusconsider the
edge-server situation assketched inFig.]2-2]. Inthiscase,weassume aCDN,in
which eachhosted sitehasanorigin server thatactsastheauthoritative siteforall
readandupdate operations. Anedgeserver isusedtohandle client requests, and
hastheability tostore(partial) information asalsokeptatanorigin server.
Figure 12-21. Alternatives forcaching andreplication withWebapplications.
Recall thatinanedge-server architecture, Webclients request datathrough an
edgeserver, which, intum,getsitsinformation fromtheorigin server associated
withthespecific Websitereferred tobytheclient. Asalsoshown inFig.12-21,
weassume thattheorigin server consists ofadatabase fromwhich responses are
dynamically created. Although wehaveshown onlyasingle Webserver, itis
common toorganize eachserver according toamultitiered architecture aswedis-
cussed before. Anedgeserver cannowberoughly organized along thefollowing
lines.
First,toimprove performance, wecandecide toapply fullreplication ofthe
datastored attheorigin server. Thisscheme works wellwhenever theupdate ratio
islowandwhen queries require anextensive database search. Asmentioned
above, weassume thatallupdates arecarried outattheorigin server, which takes
responsibility forkeeping thereplicas andtheedgeservers inaconsistent state.
Readoperations canthustakeplaceattheedgeservers. Hereweseethatreplicat-
ingforperformance willfailwhen theupdate ratioishigh. aseachupdate willSEC. 12.6 CONSISTENCY AND REPLICATION 581
incurcommunication overawide-area network tobringthereplicas intoacon-
sistent state.Asshown inSivasubramanian etal.(2004a), theread/update ratiois
thedetermining factor towhatextent theorigin database inawide-area setting
should bereplicated.
Another caseforfullreplication iswhenqueries aregenerally complex. Inthe
caseofarelational database, thismeans thataquery requires thatmultiple tables
needtobesearched andprocessed, asisgenerally thecasewithajoinoperation.
Opposed tocomplex queries aresimple onesthatgenerally require access toonly
asingle tableinordertoproduce aresponse. Inthelattercase,partial replication
bywhich onlyasubset ofthedataisstored attheedgeserver maysuffice.
Theproblem withpartial replication isthatitmaybeverydifficult tomanu-
allydecide which dataisneeded attheedgeserver. Sivasubramanian etal.(2005)
propose tohandle thisautomatically byreplicating records according tothesame
principle thatGlobule replicates itsWebpages. Aswediscussed inChap. 2,this
means thatanorigin server analyzes access traces fordatarecords onwhich it
subsequently bases itsdecision onwhere toplacerecords. Recall thatinGlobule,
decision-making wasdriven bytaking thecostintoaccount forexecuting readand
update operations oncedatawasinplace (andpossibly replicated). Costs are
expressed inasimple linear function:
withmk being aperformance metric (such asconsumed bandwidth) andWk>0
therelative weight indicating howimportant thatmetric is.
Analternative topartial replication istomake useofcontent-aware caches.
Thebasicideainthiscaseisthatanedgeserver maintains alocaldatabase thatis
nowtailored tothetypeofqueries thatcanbehandled attheorigin server. To
explain, inafull-fledged database system aquery willoperate onadatabase in
which thedatahasbeenorganized intotables suchthat,forexample, redundancy
isminimized. Suchdatabases arealsosaidtobenormalized.
Insuchdatabases, anyquery thatadheres tothedataschema can,inprinciple,
beprocessed, although perhaps atconsiderable costs. Withcontent-aware caches,
anedgeserver maintains adatabase thatisorganized according tothestructure of
queries. What thismeans isthatqueries areassumed toadhere toalimited num-
beroftemplates, effectively meaning thatthedifferent kindsofqueries thatcan
beprocessed isrestricted. Inthesecases, whenever aquery isreceived, theedge
server matches thequery against theavailable templates, andsubsequently looks
initslocaldatabase tocompose aresponse, ifpossible. Iftherequested dataisnot
available, thequery isforwarded totheorigin server afterwhich theresponse is
cached before returning ittotheclient.
Ineffect, whattheedgeserver isdoing ischecking whether aquery canbe
answered withthedatathatisstored locally. Thisisalsoreferred toasaquery
containment check. Notethatsuchdatawasstored locally asresponses toprevi-
ously issued queries. Thisapproach works bestwhenqueries tendtoberepeated.582 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Partofthecomplexity ofcontent-aware caching comes from thefactthatthe
dataattheedgeserver needs tobekeptconsistent. Tothisend,theorigin server
needs toknow which records areassociated withwhich templates, sothatany
update ofarecord, oranyupdate ofatable, canbeproperly addressed by,forex-
ample, sending aninvalidation message totheappropriate edge servers. Another
source ofcomplexity comes fromthefactthatqueries stillneedtobeprocessed, at
edgeservers. Inother words, there isnonnegligible computational power needed
tohandle queries. Considering thatdatabases often formaperformance bottleneck
inWebservers, alternative solutions maybeneeded. Finally, caching results from
queries thatspanmultiple tables (i.e., when queries arecomplex) such thata
query containment check canbecarried outeffectively isnottrivial. Thereason is
thattheorganization oftheresults maybeverydifferent from theorganization of
thetables onwhich thequery operated.
These observations leadustoathirdsolution, namely content-blind caching,
described indetail bySivasubramanian etal.(2006). Theideaofcontent-blind
caching isextremely simple: when aclient submits aquery toanedge server, the
server firstcomputes aunique hashvalue forthatquery. Using thishashvalue, it
subsequently looks initscache whether ithasprocessed thisquery before. Ifnot,
thequery isforwarded totheorigin andtheresult iscached before returning itto
theclient. Ifthequery hadbeenprocessed before, thepreviously cached result is
returned totheclient.
Themain advantage ofthisscheme isthereduced computational effort thatis
required fromanedgeserver incomparison tothedatabase approaches described
above. However, content-blind caching canbewasteful interms ofstorage asthe
caches maycontain much more redundant dataincomparison tocontent-aware
caching ordatabase replication. Note thatsuchredundancy alsocomplicates the
process ofkeeping thecache uptodateastheorigin server mayneed tokeepan
accurate account ofwhich updates canpotentially affect cached query results.
These problems canbealleviated when assuming thatqueries canmatch onlya
limited setofpredefined templates aswediscussed above.
Obviously, these techniques canbeequally welldeployed fortheupcoming
generation ofWebservices, butthere isstillmuch research needed before stable
solutions canbeidentified.
12.7FAULTTOLERANCE
Fault tolerance intheWeb-based distributed systems ismainly achieved
through client-side caching andserver replication. Nospecial methods areincor-
porated in,forexample, HTTP toassist faulttolerance orrecovery. Note, howev-
er,thathighavailability intheWeb isachieved through redundancy thatmakes
useofgenerally available techniques incrucial services such asDNS. asanSEC. 12.7 FAULT TOLERANCE 583
example wementioned before, DNSallows several addresses tobereturned asthe
result ofaname lookup. Intraditional Web-based systems, faulttolerance canbe
relatively easytoachieve considering thestateless design ofservers, along with
theoftenstaticnature oftheprovided content.
When itcomes toWebservices, similar observations hold:hardly anynewor
special techniques areintroduced todealwithfaults (Birman, 2005). However, it
should beclearthatproblems ofmasking failures andrecoveries canbemore
severe. Forexample, Webservices support wide-area distributed transactions and
solutions willdefinitely havetodealwithfailing participating services orunreli-
ablecommunication.
Even moreimportant isthatinthecaseofWebservices wemayeasily be
dealing withcomplex calling graphs. Notethatinmany Web-based systems com-
puting follows asimple two-tiered client-server calling convention. Thismeans
thataclient callsaserver, which thencomputes aresponse without theneedof
additional external services. Assaid,faulttolerance canoftenbeachieved bysim-
plyreplicating theserver orrelying partly onresult caching.
Thissituation nolonger holds forWebservices. Inmany cases, wearenow
dealing withmultitiered solutions inwhich servers alsoactasclients. Applying
replication toservers means thatcallers andcallees needtohandle replicated
invocations, justasinthecaseofreplicated objects aswediscussed backin
Chap. 10.
Problems areaggravated forservices thathavebeendesigned tohandle
Byzantine failures. Replication ofcomponents plays acrucial rolehere,butso
doestheprotocol thatclients execute. Inaddition, wenowhavetofacethesitua-
tionthataByzantine fault-tolerant (BFT) service mayneedtoactasaclient of
another nonreplicated service. Asolution tothisproblem isproposed inMerideth
etal.(2005) thatisbased ontheBFfsystem proposed byCastro andLiskov
(2002), which wediscussed inChap. 11.
There arethreeissues thatneedtobehandled. First,clients ofaBFTservice
should seethatservice asjustanother Webservice. Inparticular, thismeans that
theinternal replication ofthatservice should behidden fromtheclient, alongwith
aproper processing ofresponses. Forexample, aclient needs tocollect k+1
identical answers fromupto2k+Iresponses, assuming thattheBFfservice is
designed tohandle atmostkfailing processes. Typically, thistypeofresponse
processing canbehidden away inclient-side stubs, which canbeautomatically
generated fromWSDL specifications,
Second, aBFfservice should guarantee internal consistency whenacting asa
client. Inparticular, itneeds tohandle thecasethattheexternal service itiscal-
linguponreturns different answers todifferent replicas. Thiscould happen, for
example, when theexternal service itselfisfailing forwhatever reason. Asare-
sult,thereplicas mayneedtorunanadditional agreement protocol asanexten-
siontotheprotocols theyarealready executing toprovide Byzantine faulttoler-
ance.Afterexecuting thisprotocol, theycansendtheiranswers backtotheclient.584 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Finally. external services should alsotreataBFTservice acting asaclient, as
asingle entity. Inparticular, aservice cannot simply accept arequest coming
fromasingle replica, butcanproceed onlywhen ithasreceivedatleastk+I
identical requests fromdifferent replicas.
These threesituations leadtothreedifferent pieces ofsoftware thatneedtobe
integrated intotoolkits fordeveloping Webservices. Details andperformance
evaluations canbefound inMerideth etal.(2005).
12.8SECURITY
Considering theopennature oftheInternet, devising asecurity architecture
thatprotects clients andservers against various attacks iscrucially important.
Mostofthesecurity issues intheWebdealwithsetting upasecure channel be-
tween aclient andserver. Thepredominant approach forsetting upasecure chan-
nelintheWebistousetheSecure Socket Layer (SSL), originally implemented
byNetscape. Although SSLhasnever beenformally standardized, mostWebcli-
entsandservers nevertheless support it.Anupdate ofSSLhasbeenformally laid
downinRFC2246andRFC3546, nowreferred toastheTransport Layer Secu-
rity(TLS) protocol (Dierks andAllen, 1996;andBlake-Wilson etaI.,2003).
Asshown inFig.12-22, TLSisanapplication-independent security protocol
thatislogically layered ontopofatransport protocol. Forreasons ofsimplicity,
TLS(andSSL)implementations areusually based onTCP. TLScansupport a
variety ofhigher-level protocols, including HTTP, aswediscuss below. Forex-
ample, itispossible toimplement secure versions ofFTPorTelnet usingTLS.
Figure 12-22. Theposition ofTLSintheInternet protocol stack.
TLSitselfisorganized intotwolayers. Thecoreoftheprotocol isformed by
theTLSrecord protocol layer, which implements asecure channel between a
client andserver. Theexact characteristics ofthechannel aredetermined during
itssetup, butmayinclude message fragmentation andcompression, which are
applied inconjunction withmessage authentication, integrity, andconfidentiality.SEC. 12.8 SECURITY 585
Setting upasecure channel proceeds intwophases, asshown inFig.12-23.
First,theclient informs theserver ofthecryptographic algorithms itcanhandle,
aswellasanycompression methods itsupports. Theactual choice isalways made
bytheserver, which reports itschoice backtotheclient. These firsttwomessages
shown inFig.12-23.
Figure 12-23. TLSwithmutual authentication.
Inthesecond phase, authentication takesplace. Theserver isalways required
toauthenticate itself, forwhich reason itpasses theclient acertificate containing
itspublic keysigned byacertification authority CA.Iftheserver requires thatthe
client beauthenticated, theclient willhavetosendacertificate totheserver as
well,shown asmessage 4inFig.12-23.
Theclient generates arandom number thatwillbeusedbybothsidesforcon-
structing asession key,andsends thisnumber totheserver, encrypted withthe
server's public key.Inaddition, ifclientauthentication isrequired, theclient signs
thenumber withitsprivate key,leading tomessage 5inFig.12-23. (Inreality, a
separate message issentwithascrambled andsigned version oftherandom num-
ber,establishing thesameeffect.) Atthatpoint, theserver canverify theidentity
oftheclient, afterwhich thesecure channel hasbeensetup.
12.9SUMMARY
Itcanbeargued thatWeb-based distributed systems havemadenetworked ap-
plications popular withendusers. Using thenotion ofaWebdocument asthe
means forexchanging information comes closetothewaypeople oftencommuni-
cateinoffice environments andothersettings. Everyone understands whatapaper
document is,soextending thisconcept toelectronic documents isquitelogical for
mostpeople.
Thehypertext support asprovided toWebendusershasbeenofparamount
importance totheWeb's popularity. Inaddition, endusersgenerally seeasimple586 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
client-server architecture inwhich documents aresimply fetched fromaspecific
site.However, modem Websitesareorganized along multitiered architectures in
which afinalcomponent ismerely responsible forgenerating HTML orXML
pages asresponses thatcanbedisplayed attheclient.
Replacing theenduserwithanapplication hasbrought usWebservices. From
atechnological pointofview,Webservices bythemselves aregenerally notspec-
tacular, although theyarestillintheirinfancy. Whatisimportant, however, isthat
verydifferent services needtobediscovered andbeaccessible toauthorized cli-
ents.Asaresult, hugeefforts arespentonstandardization ofservice descriptions,
communications, directories, andvarious interactions. Again. eachstandard byit-
selfdoesnotrepresent particularly newinsights, butbeing astandard contributes
totheexpansion ofWebservices.
Processes intheWebaretailored tohandling HTTP requests, ofwhich the
Apache Webserver isacanonical example. Apache hasproven tobeaversatile
vehicle forhandling HTTP-based systems, butcanalsobeeasily extended to
facilitate specific needs suchasreplication.
AstheWeboperates overtheInternet, much attention hasbeenpaidto
improving performance through caching andreplication. More orlessstandard
techniques havebeendeveloped forclient-side caching, butwhenitcomes torep-
lication considerable advances havebeenmade. Notably whenreplication ofWeb
applications isatstake, itturnsoutthatdifferent solutions willneedtoco-exist for
attaining optimal performance.
Bothfaulttolerance andsecurity aregenerally handled using standard tech-
niques thathavesincelongbeenapplied formany othertypesofdistributed sys-
tems.
PROBLEMS
1.Towhatextent ise-mail partoftheWeb's document model?
2.Inmany cases, Web sitesaredesigned tobeaccessed byusers. However, when it
comes toWebservices, weseethatWebsitesbecome dependent oneachother. Con-
sidering thethree-tiered architecture ofFig.12-3, where would youexpect toseethe
dependency occur?
3.TheWebusesafile-based approach todocuments bywhich aclient firstfetches afile
before itisopened anddisplayed. 'What istheconsequence ofthisapproach formul-
timedia files?
4.Onecould argue thatfromantechnological point ofviewWebservices donotaddress
anynewissues. What isthecompelling argument toconsider Webservices important?CHAP. 12 PROBLEMS 587
5.What would bethemainadvantage ofusing thedistributed server discussed inChap. 3
toimplement aWeb server cluster, incomparison tothewaythesuchclusters are
organized asshown inFig.12-9.What isanobvious disadvantage?
6.Why dopersistent connections generally improve performance compared tononper-
sistent connections?
7.SOAP isoften saidtoadhere toRPCsemantics. Isthisreally true?
8.Explain thedifference between aplug-in, anapplet, aservlet, andaCGIprogram.
9.InWebDA V,isitsufficient foraclient toshow onlythelocktoken totheserver in
order toobtain writepermissions?
10.Instead ofletting aWebproxy compute anexpiration timeforadocument, aserver
could dothisinstead. What would bethebenefit ofsuchanapproach?
11.WithWebpages becoming highly personalized (because theycanbedynamically gen-
erated onaper-client basisondemand), onecould argue thatWebcaches willsoonall
beobsolete. Yet,thisismost likely notgoing tohappen anytimeintheimmediate
future. Explain why.
12.Does theAkamai CDN follow apull-based orpush-based distribution protocol?
13.Outline asimple scheme bywhich anAkamai CDN server canfindoutthatacached
embedded document isstalewithout checking thedocument's validity attheoriginal
server.
14.Would itmake sense toassociate areplication strategy witheachWebdocument sepa-
rately, asopposed tousing oneoronlyafewglobal strategies?
15.Assume thatanonreplicated document ofsizesbytes isrequested rtimes persecond.
Ifthedocument isreplicated tokdifferent servers, andassuming thatupdates arepro-
pagated separately toeachreplica, when willreplication becheaper thanwhen the
document isnotreplicated?
16.Consider aWebsiteexperiencing aflashcrowd. What could beanappropriate meas-
uretotakeinorder toensure thatclients arestillserviced well?
17.There are,inprinciple, three different techniques forredirecting clients toservers:
TCPhandoff, DNS-based redirection, andHTTP-based redirection. What arethemain
advantages anddisadvantages ofeachtechnique?
18.Giveanexample inwhich aquery containment check asperformed byanedgeserver
supporting content-aware caching willreturn successfully.
19.(Lab assignment) Setupasimple Web-based system byinstalling andconfiguring
theApache Webserver foryourlocal machine suchthatitcanbeaccessed from a
localbrowser. Ifyouhavemultiple computers inalocal-area network, make surethat
theserver canbeaccessed fromanybrowser onthatnetwork.
20.(Lab assignment) WebDAV issupported bytheApache Webserver andallows mul-
tipleusers toshare filesforreading andwriting overtheInternet. Install andconfigure588 DISTRIBUTED WEB-BASED SYSTEMS CHAP. 12
Apache foraWebDAV-enabled directory inalocal-area network. Testtheconfigura-
tionbyusing aWebDAV client.13
DISTRIBUTED
COORDINATION-BASED SYSTEMS
Intheprevious chapters wetookalookatdifferent approaches todistributed
systems, ineachchapter focusing onasingle datatypeasthebasisfordistribu-
tion.Thedatatype,beingeither anobject, file,or(Web) document, hasitsorigins
innondistributed systems. Itisadapted fordistributed systems insuchawaythat
many issues about distribution canbemadetransparent tousersanddevelopers.
Inthischapter weconsider ageneration ofdistributed systems thatassume
thatthevarious components ofasystem areinherently distributed andthatthereal
problem indeveloping suchsystems liesincoordinating theactivities ofdifferent
components. Inotherwords, instead ofconcentrating onthetransparent distribu-
tionofcomponents, emphasis liesonthecoordination ofactivities between those
components.
Wewillseethatsomeaspects ofcoordination havealready beentouched up-
onintheprevious chapters, especially whenconsidering event-based systems. As
itturns out,many conventional distributed systems aregradually incorporating
mechanisms thatplaya keyroleincoordination-based systems.
Before taking alookatpractical examples ofsystems, wegiveabriefintro-
duction tothenotion ofcoordination indistributed systems.
13.1INTRODUCTION TOCOORDINATION MODELS
Keytotheapproach followed incoordination-based systems istheclean
separation between computation andcoordination. Ifweviewadistributed system
asacollection of(possibly multithreaded) processes, thenthecomputing partofa
589590 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
distributed system isformed bytheprocesses, eachconcerned withaspecific
computational activity, which inprinciple, iscarried outindependently fromthe
activities ofotherprocesses.
Inthismodel, thecoordination partofadistributed system handles thecom-
munication andcooperation between processes. Itforms thegluethatbinds the
activities performed byprocesses intoawhole (Gelernter andCarriero, 1992). In
distributed coordination-based systems, thefocus isonhowcoordination between
theprocesses takesplace.
Cabri etal.(2000) provide ataxonomy ofcoordination models formobile
agents thatcanbeapplied equally tomany other types ofdistributed systems.
Adapting theirterminology todistributed systems ingeneral, wemake adistinc-
tionbetween models along twodifferent dimensions, temporal andreferential, as
shown inFig.13-1.
Figure 13-1. Ataxonomy ofcoordination models (adapted fromCabri etal.,2000).
When processes aretemporally andreferentially coupled, coordination takes
placeinadirect way,referred toasdirect coordination. Thereferential coupling
generally appears intheformofexplicit referencing incommunication. Forex-
ample, aprocess cancommunicate only-ifitknows thename oridentifier ofthe
otherprocesses itwants toexchange information with.Temporal coupling means
thatprocesses thatarecommunicating willbothhavetobeupandrunning. This
coupling isanalogous tothetransient message-oriented communication wedis-
cussed inChap. 4. .
Adifferent typeofcoordination occurs whenprocesses aretemporally decou-
pled,butreferentially coupled, which werefertoasmailbox coordination. In
thiscase,thereisnoneedfortwocommunicating processes toexecute atthe
sametimeinordertoletcommunication takeplace. Instead, communication takes
place byputting messages ina(possibly shared) mailbox. Thissituation isanalo-
goustopersistent message-oriented communication asdescribed inChap. 4.Itis
necessary toexplicitly address themailbox thatwillholdthemessages thatareto
beexchanged. Consequently, thereisareferential coupling.
Thecombination ofreferentially decoupled andtemporally coupled systems
formthegroup ofmodels formeeting-oriented coordination. Inreferentially
decoupled systems, processes donotknow eachotherexplicitly. Inotherwords.
when aprocess wants tocoordinate itsactivities withotherprocesses, itcannotSEC. 13.1 INTRODUCTION TOCOORDINATION MODELS 591
directly refertoanother process. Instead, thereisaconcept ofameeting inwhich
processes temporarily group together tocoordinate theiractivities. Themodel
prescribes thatthemeeting processes areexecuting atthesametime.
Meeting-based systems areoftenimplemented bymeans ofevents, likethe
onessupported byobject-based distributed systems. Inthischapter, wediscuss an-
othermechanism forimplementing meetings, namely publish/subscribe systems.
Inthese systems, processes cansubscribe tomessages containing information on
specific subjects, while other processes produce (i.e.,publish) suchmessages.
Mostpublish/subscribe systems require thatcommunicating processes areactive
atthesametime;hence thereisatemporal coupling. However, thecommunicat-
ingprocesses mayotherwise remain anonymous.
Themostwidely-known coordination model isthecombination ofreferen- .
tiallyandtemporally decoupled processes, exemplified bygenerative communi-
cationasintroduced intheLinda programming system byGelemter (1985). The
keyideaingenerative communication isthatacollection ofindependent proc-
essesmake useofashared persistent dataspace oftuples. Tuplesaretagged data
records consisting ofanumber (butpossibly zero)typed fields. Processes canput
anytypeofrecord intotheshared dataspace (i.e.,theygenerate communication
records). Unlike thecasewithblackboards, thereisnoneedtoagree inadvance
onthestructure oftuples. Only thetagisusedtodistinguish between tuples
representing different kindsofinformation.
Aninteresting feature ofthese shared dataspaces isthattheyimplement an
associative search mechanism fortuples. Inotherwords, whenaprocess wants to
extract atuplefromthedataspace, itessentially specifies (some of)thevalues of
thefields itisinterested in.Anytuplethatmatches thatspecification isthenre-
moved fromthedataspace andpassed totheprocess. Ifnomatch could befound,
theprocess canchoose toblock untilthere isamatching tuple. Wedefer the
details onthiscoordination model tolaterwhendiscussing concrete systems.
Wenotethatgenerative communication andshared dataspaces areoftenalso
considered tobeforms ofpublish/subscribe systems. Inwhatfollows, weshall
adopt thiscommonality aswell.Agoodoverview ofpublish/subscribe systems
(andtaking arather broad perspective) canbefound inEugster etal.(2003). In
thischapter wetaketheapproach thatinthesesystems thereisatleastreferential
decoupling between processes, butpreferably alsotemporal decoupling.
13.2ARCHITECTURES
Animportant aspect ofcoordination-based systems isthatcommunication
takes place bydescribing thecharacteristics ofdataitems thataretobe
exchanged. Asaconsequence, naming playsacrucial role.Wereturn tonaming
laterinthischapter, butfornowtheimportant issueisthatinmany cases, data
items arenotexplicitly identified bysenders andreceivers.592 DISTRIBUTED COORDINA nON-BASED SYSTEMS CHAP. 13
13.2.1 Overall Approach
Letusfirstassume thatdataitems aredescribed byaseries ofattributes. A
dataitemissaidtobepublished whenitismade available forotherprocesses to
read.Tothatend.asubscription needs tobepassed tothemiddleware, contain-
ingadescription ofthedataitems thatthesubscriber isinterested in.Such a
description typically consists ofsome (attribute, value) pairs, possibly combined
with(attribute, range) pairs. Inthelattercase,thespecified attribute isexpected
totakeonvalues within aspecified range. Descriptions cansometimes begiven
using allkinds ofpredicates formulated overtheattributes, verysimilar innature
toSQL-like queries inthecaseofrelational databases. Wewillcome across these
typesofdescriptors laterinthischapter.
Wearenowconfronted withasituation inwhich subscriptions needtobe
matched against dataitems, asshown inFig.13-2. When matching succeeds,
therearetwopossible scenarios. Inthefirstcase,themiddleware maydecide to
forward thepublished datatoitscurrent setofsubscribers, thatis,processes with
amatching subscription. Asanalternative, themiddleware canalsoforward a
notification atwhich pointsubscribers canexecute areadoperation toretrieve
thepublished dataitem.
Figure 13-2. Theprinciple ofexchanging dataitems between publishers andsubscribers.
Inthose casesinwhich dataitems areimmediately forwarded tosubscribers,
themiddleware willgenerally notofferstorage ofdata.Storage iseither explicitly
handled byaseparate service, oristheresponsibility ofsubscribers. Inother
words, wehaveareferentially decoupled, buttemporally coupled system.
Thissituation isdifferent when notifications aresentsothatsubscribers need
toexplicitly readthepublished data.Necessarily, themiddleware willhaveto
store dataitems. Inthese situations there areadditional operations fordata
management. Itisalsopossible toattach aleasetoadataitemsuchthatwhen the
leaseexpires thatthedataitemisautomatically deleted.
Inthemodel described sofar,wehaveassumed thatthereisafixed setofn
attributes aI,... ,anthatisusedtodescribe dataitems. Inparticular, eachpub-
lished dataitemisassumed tohaveanassociated vector «abvI)'...,(an'1',J> ofSEC. 13.2 ARCHITECTURES 593
(attribute. value) pairs. Inmany coordination-based systems, thisassumption is
false.Instead, whathappens isthatevents arepublished, which canbeviewed as
dataitems withonlyasingle specified attribute.
Events complicate theprocessing ofsubscriptions. Toillustrate, consider a
subscription suchas"notify when room R4.20 isunoccupied andthedooris
unlocked." Typically, adistributed system supporting suchsubscriptions canbe
implemented byplacing independent sensors formonitoring room occupancy
(e.g.,motion sensors) andthoseforregistering thestatus ofadoorlock.Following
theapproach sketched sofar,wewould needtocompose suchprimitive events
intoapublishable dataitemtowhich processes canthensubscribe. Event compo-
sition turnsouttobeadifficult task,notably when theprimitive events aregen-
erated fromsources dispersed across thedistributed system.
Clearly, incoordination-based systems suchasthese, thecrucial issueisthe
efficient andscalable implementation ofmatching subscriptions todataitems,
along withtheconstruction ofrelevant dataitems. From theoutside, acoordina-
tionapproach provides lotsofpotential forbuilding verylarge-scale distributed
systems duetothestrong decoupling ofprocesses. Ontheotherhand,asweshall
seenext,devising scalable implementations without losing thisindependence is
notatrivial exercise.
13.2.2 Traditional Architectures
Thesimplest solution formatching dataitemsagainst subscriptions istohave
acentralized client-server architecture. Thisisatypical solution currently adopted
bymany publish/subscribe systems, including IBM's WebSphere (IBM, 2005c)
andpopular implementations forSun's JMS(SunMicrosystems. 2004a). Like-
wise, implementations forthemoreelaborate generative communication models
suchasJini(SunMicrosystems, 2005b) andJavaSpaces (Freeman etal.,1999) are
mostly based oncentral servers. Letustakealookattwotypical examples.
Example: JiniandJavaSpaces
Jiniisadistributed system thatconsists ofamixture ofdifferent butrelated
elements. Itisstrongly related totheJavaprogramming language, although many
ofitsprinciples canbeimplemented equally wellinotherlanguages. Animpor-
tantpartofthesystem isformed byacoordination model forgenerative commu-
nication. Jiniprovides temporal andreferential decoupling ofprocesses through a
coordination system called JavaSpaces (Freeman etaI.,1999), derived from
Linda. AJavaSpace isashared dataspace thatstores tuples representing atyped
setofreferences toJavaobjects. Multiple JavaSpaces maycoexist inasingle Jini
system.
Tuples arestored inserialized form. Inother words, whenever aprocess
wants tostoreatuple, thattupleisfirstmarshaled, implying thatallitsfields are594 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
marshaled aswell.Asaconsequence, when atuplecontains twodifferent fields
thatrefertothesameobject, thetupleasstored inaJavaSpace implementation
willholdtwomarshaled copies ofthatobject.
AtupleisputintoaJavaSpace bymeans ofawriteoperation, which first
marshals thetuplebefore storing it.Eachtimethewriteoperation iscalled ona
tuple, another marshaled copyofthattupleisstored intheJavaSpace, asshown in
Fig.13-3.Wewillrefertoeachmarshaled copyasatuple instance.
BWrite B Read T
Insert a
copy ofB
,---"'---
;A [[J Return C
: (and optionally
Tuple instance ! IBl [[Jr--- remove it)
~ :C' ••• .,I l
---A-ja~aspace----~'
Theinteresting aspect ofgenerative communication inJiniisthewaythat
tupleinstances arereadfromaJavaSpace. Toreadatupleinstance, aprocess pro-
vides another tuple thatitusesasatemplate formatching tuple instances as
stored inaJavaSpace. Likeanyothertuple, atemplate tupleisatyped setofob-
jectreferences. Onlytupleinstances ofthesametypeasthetemplate canberead
fromaJavaSpace. Afieldinthetemplate tupleeither contains areference toan
actual object orcontains thevalueNULL. Forexample, consider theclass
Thenatemplate declared as
willmatch thetuple
Tomatch atupleinstance inaJavaSpace against atemplate tuple, thelatteris
marshaled asusual, including itsNULL fields. Foreachtupleinstance ofthesame
typeasthetemplate, afield-by-field comparison ismade withthetemplate tuple.Figure B-3. Thegeneral organization ofaJavaSpace inJini.SEC. 13.2 ARCHITECTURES 595
Twofields match iftheybothhaveacopyofthesame reference orifthefieldin
thetemplate tuple isNULL. Atuple instance matches atemplate tuple ifthere is
apairwise matching oftheirrespective fields.
When atuple instance isfound thatmatches thetemplate tuple provided as
partofareadoperation, thattuple instance isunmarshaled andreturned tothe
reading process. There isalsoatakeoperation thatadditionally removes thetuple
instance from theJavaSpace. Bothoperations block thecaller untilamatching tu-
pleisfound. Itispossible tospecify amaximum blocking time. Inaddition, there
arevariants thatsimply return immediately ifnomatching tupleexisted.
Processes thatmake useofJavaSpaces neednotcoexist atthesame time. In
fact,ifaJavaSpace isimplemented using persistent storage, acomplete Jinisys-
temcanbebrought down andlaterrestarted without losing anytuples.
Although Jinidoesnotsupport it,itshould beclear thathaving acentral
server allows subscriptions tobefairly elaborate. Forexample, atthemoment two
nonnull fields match iftheyareidentical. However, realizing thateachfieldrep-
resents anobject, matching could alsobeevaluated byexecuting anobject-specif-
iccomparison operator [seealsoPicco etal.(2005)]. Infact,ifsuchanoperator
canbeoverridden byanapplication, more-or-less arbitrary comparison semantics
canbeimplemented. Itisimportant tonotethatsuchcomparisons mayrequire an
extensive search through currently stored dataitems. Such searches cannot be
easily efficiently implemented inadistributed way. Itisexactly forthisreason
thatwhen elaborate matching rules aresupported wewillgenerally seeonlycen-
tralized implementations.
Another advantage ofhaving acentralized implementation isthatitbecomes
easier toimplement synchronization primitives. Forexample, thefactthataproc-
esscanblock untilasuitable dataitemispublished, andthensubsequently exe-
cuteadestructive readbywhich thematching tuple isremoved, offers facilities
forprocess synchronization without processes needing toknow eachother. Again,
synchronization indecentralized systems isinherently difficult aswealsodis-
cussed inChap. 6.Wewillreturn tosynchronization below.
Example: TIBlRendezvous
Analternative solution tousing central servers istoimmediately disseminate
published dataitems totheappropriate subscribers using multicasting. Thisprin-
ciple isused inTIBlRendezvous, ofwhich thebasic architecture isshown in
Fig.13-4(TIBCO, 2005) Inthisapproach, adataitemisamessage tagged witha
compound keyword describing itscontent, suchasnews.comp.os. books. Asub-
scriber provides (parts of)akeyword, orindicating themessages itwants to
receive, suchasnews.comp. *.books. These keywords aresaidtoindicate thesub-
jectofamessage.
Fundamental toitsimplementation istheuseofbroadcasting common in
local-area networks, although italsousesmore efficient communication facilities596 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
Figure 13-4. Theprinciple ofapublish/subscribe system asimplemented in
TlB/Rendezvous.
when possible. Forexample, ifitisknown exactly where asubscriber resides,
point-to-point messages willgenerally beused.Eachhostonsuchanetwork will
runarendezvous daemon, which takescarethatmessages aresentanddelivered
according totheirsubject. Whenever amessage ispublished, itismulticast to
eachhostonthenetwork running arendezvous daemon. Typically, multicasting is
implemented using thefacilities offered bytheunderlying network, suchasIP-
multicasting orhardware broadcasting.
Processes thatsubscribe toasubject passtheirsubscription totheirlocaldae-
mon.Thedaemon constructs atableof(process, subject), entries andwhenever a
message onsubject Sarrives, thedaemon simply checks initstableforlocalsub-
scribers, andforwards themessage toeachone.Iftherearenosubscribers forS,
themessage isdiscarded immediately.
When using multicasting asisdoneinTIB/Rendezvous, there isnoreason
whysubscriptions cannot beelaborate andbemorethanstring comparison asis
currently thecase.Thecrucial observation hereisthatbecause messages arefor-
warded toeverynodeanyway, thepotentially complex matching ofpublished data
against subscriptions canbedoneentirely locally without further network commu-
nication. However, asweshalldiscuss later,simple comparison rulesarerequired
whenever matching across wide-area networks isneeded.
13.2.3Peer-to-Peer Architectures
Thetraditional architectures followed bymostcoordination-based systems
suffer fromscalability problems (although theircommercial vendors willstate
otherwise). Obviously, having acentral server formatching subscriptions topub-
lished datacannot scalebeyond afewhundred clients. Likewise, using multicast-
ingrequires special measures toextend beyond therealm oflocal-area networks.SEC. 13.2 ARCHITECTURES 597
Moreover, ifscalability istobeguaranteed, further restrictions ondescribing sub-
scriptions anddataitemsmaybenecessary.
Much research hasbeenspentonrealizing coordination-based systems using
peer-to-peer technology. Straightforward implementations existforthosecasesin
which keywords areused, asthesecanbehashed tounique identifiers forpub-
lished data.Thisapproach hasalsobeenusedformapping (attribute, value) pairs
toidentifiers. Inthesecases, matching reduces toastraightforward lookup ofani-
dentifier, which canbeefficiently implemented inaDHT-based system. Thisap-
proach works wellforthemoreconventional publish/subscribe systems asillus-
trated byTamandJacobsen (2003), butalsoforgenerative communication (Busi
etaI.,2004).
Matters become complicated formoreelaborate matching schemes. Notori-
ously difficult arethecasesinwhich ranges needtobesupported andonlyvery
fewproposals exist. Inthefollowing, wediscuss onesuchproposal, devised by
oneoftheauthors andhiscolleagues (Voulgaris etaI.,2006).
Example: AGossip-Based Publish/Subscribe System
Consider apublish/subscribe system inwhich dataitems canbedescribed by
means ofNattributes aI,...,aNwhose value canbedirectly mapped toafloat-
ing-point number. Suchvalues include, forexample, floats, integers, enumera-
tions, booleans, andstrings. Asubscription stakestheformofatupleof(attri-
bute.value/ranees nairs.suchas
Inthisexample, sspecifies thata1should beequalto3.0,anda4should lieinthe
interval [0.0,0.5).Other attributes areallowed totakeonanyvalue. Forclarity,
assume thatevery nodeienters onlyonesubscription s..
Note thateach subscription Siactually specifies asubset S,intheN-
dimensional space offloating-point numbers. Suchasubset isalsocalled ahyper-
space. Forthesystem asawhole, onlypublished datawhose description fallsin
theunion S=uSjofthese hyperspaces isofinterest. Thewhole ideaisto
automatically partition SintoMdisjoint hyperspaces S1,...,SMsuchthateach
fallscompletely inoneofthesubscription hyperspaces Si,andtogether theycover_1) 1__ •• .•Jr J"- 11 I .•I .•
Moreover, thesystem keeps Mminimal inthesense thatthereisnopartitioning
withfewer parts 8m. Thewhole ideaistoregister, foreachhyperspace 8m,
exactly those nodes iforwhich 8mcSj.Inthatcase,when adataitemispub-
lished, thesystem needmerely findthe8mtowhich thatitembelongs, fromwhich
pointitcanforward theitemtotheassociated nodes.Tothisend,nodes regularly exchange subscriptions using anepidemic proto-
col.Iftwonodes iandjnotice thattheirrespective subscriptions intersect, thatis
Sij==S,nSj=t0theywillrecord thisfactandkeepreferences toeach other. If
theydiscover athirdnodekwithSijk ==Sij()Sk=t0,thethree ofthem willcon-
necttoeachother sothatadataitemdfromSijk canbeefficiently disseminated.
NotethatifSij-Sijk =t0,nodes iandjwillmaintain theirmutual references, but
nowassociate itstrictly withSij-Sijk'
Inessence, what weareseeking isameans tocluster nodes intoMdifferent
groups, suchthatnodes iandjbelong tothesame group ifandonlyiftheirsub-
scriptions S,andSjintersect. Moreover, nodes inthesame group should beorgan-
izedintoanoverlay network thatwillallow efficient dissemination ofadataitem
inthehyperspace associated withthatgroup. Thissituation forasingle attribute is
sketched inFig.13-5.
Figure 13-5. Grouping nodes forsupporting range queries in·apeer-to-peer
publish/subscribe system.
Here, weseeatotalofseven nodes inwhich thehorizontal linefornode i
indicates itsrange ofinterest forthevalue ofthesingle attribute. Also shown is
thegrouping ofnodes intodisjoint ranges ofinterests forvalues oftheattribute.
Forexample, nodes 3,4,7,and10willbegrouped together representing theinter-
val[16.5, 21.0]. Anydataitemwithavalue inthisrange should bedisseminated
toonlythese fournodes. .
Toconstruct these groups, thenodes areorganized intoagossip-based un-
structured network. Each node maintains alistofreferences toother neighbors
(i.e.,apartialview), which itperiodically exchanges withoneofitsneighbors as
described inChap. 2.Such anexchange willallow anodetolearn about random
other nodes inthesystem. Every node keeps track ofthenodes itdiscovers with'
overlapping interests (i.e.,withanintersecting subscription).
Atacertain moment, every node iwillgenerally have references toother
nodes withoverlapping interests. Aspartofexchanging information withanodej,
node iorders these nodes bytheiridentifiers andselects theonewiththelowest598 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13SEC. 13.2 ARCHITECTURES 599
identifier i1>j,suchthatitssubscription overlaps withthatofnodej,thatis,
Sj,il==s.,nSj::l= 0.
Thenextonetobeselected isi2>i1suchthatitssubscription alsooverlaps
withthatofj,butonlyifitcontains elements notyetcovered bynodeir-Inother
words, weshould have thatSj,il,iz ==(Siz-Sj,i) (JSj::l= 0.This process isre-
peated until allnodes thathave anoverlapping interest withnode ihave been
inspected, leading toanordered listi1<i2<...<ill'Note thatanode ikisin
thislistbecause itcovers aregion Rofcommon interest tonode iandjnotyet
jointly covered bynodes withalower identifier thanik.Ineffect, node ikisthe
first nodethatnodejshould forward adataitemtothatfallsinthisunique region
R.Thisprocedure canbeexpanded toletnode iconstruct abidirectional ring.
Sucharingisalsoshown inFig.13-5.
Whenever adataitemdispublished, itisdisseminated asquickly aspossible
toanynode thatisinterested init.Asitturns out,withtheinformation available
atevery nodefinding anodeiinterested indissimple. From thereon,nodeineed
simply forward dalong theringofsubscribers fortheparticular range thatdfalls
into.Tospeed updissemination, short-cuts aremaintained foreachringaswell.
Details canbefound inVoulgaris etal.(2006).
Discussion
Anapproach somewhat similar tothisgossip-based solution inthesense that
itattempts tofindapartitioning ofthespace covered bytheattribute's values, but
which usesaDHT-based system isdescribed inGupta etal.(2004). Inanother
proposal described inBharambe (2004), eachattribute a,ishandled byaseparate
process Pi,which intumpartitions therange ofitsattribute across multiple proc-
esses. When adataitemdispublished, itisforwarded toeachPi,where itissub-
sequently stored attheprocess responsible forthed'svalue ofa..
Allthese approaches areillustrative forthecomplexity when mapping anon-
trivial publish/subscribe system toapeer-to-peer network. Inessence, thiscom-
plexity comes fromthefactthatsupporting search inattribute-based naming sys-
temsisinherently difficult toestablish inadecentralized fashion. Wewillagain
come across these difficulties when discussing replication.
13.2.4 Mobility andCoordination
Atopic thathasreceived considerable attention intheliterature ishowto
combine publish/subscribe solutions with node mobility. Inmany cases, itis
assumed thatthere isafixed basic infrastructure withaccess points formobile
nodes. Under these assumptions, theissue becomes howtoensure thatpublished
messages arenotdelivered more thanonce toasubscriber whoswitches access
points. Onepractical solution tothisproblem istoletsubscribers keeptrack ofthe
messages theyhavealready received andsimply discard duplicates. Alternative,600 DISTRIBUTED COORDINA nON-BASED SYSTEMS CHAP. 13
butmore intricate solutions comprise routers thatkeep track ofwhich messages
havebeensenttowhich subscribers (see,e.g.,Caporuscio etaI.,2003).
Example: Lime
Inthecaseofgenerative communication, several solutions have been pro-
posed tooperate ashared dataspace inwhich (some of)thenodes aremobile. A
canonical example inthiscaseisLime (Murphy etaI.,2001), which strongly re-
sembles theJavaSpace model wediscussed previously.
InLime, eachprocess hasitsownassociated dataspace, butwhen processes
areineachother's proximity suchthattheyareconnected, theirdataspaces be-
come shared. Theoretically, being connected canmean thatthere isaroute ina
jointunderlying network thatallows twoprocesses toexchange data. Inpractice,
however, iteither means thattwoprocesses aretemporarily located onthesame
physical host,ortheirrespective hosts cancommunicate witheachother through a
(single hop)wireless link.Formally, theprocesses should bemember ofthesame
group andusethesame group communication protocol.
Figure 13-6.Transient sharing oflocaldataspaces inLime.
Thelocal dataspaces ofconnected processes form atransiently shared data-
space thatwillallow processes toexchange tuples, asshown inFig.13-6. Forex-
ample, when aprocess Pexecutes awrite operation, theassociated tuple isstored
intheprocess's local dataspace. Inprinciple, itstays there untilthere isamatch-
ingtake operation, possibly fromanother process thatisnowinthesame group as
P.Inthisway,thefactthatweareactually dealing withacompletely distributed
shared dataspace istransparent forparticipating processes. However, Lime also
allows breaking thistransparency byspecifying exactly forwhom atuple is
intended. Likewise, read andtake operations canhave anadditional parameter
specifying fromwhich process atuple isexpected.
Tobetter control howtuples aredistributed, dataspaces cancarry outwhat are
known asreactions. Areaction specifies anaction tobeexecuted when atupleSEC. 13.2 ARCHITECTURES 601
matching agiven template isfound inthelocaldataspace. Eachtimeadataspace
changes, anexecutable reaction isselected atrandom, oftenleading toafurther
modification ofthedataspace. Reactions spanthecurrent shared dataspace, but
thereareseveral restrictions toensure thattheycanbeexecuted efficiently. For
example, inthecaseofweak reactions, itisonlyguaranteed thattheassociated
actions areeventually executed, provided thematching dataisstillaccessible.
Theideaofreactions hasbeentakenastepfurther inTOTA.where eachtuple
hasanassociated codefragment telling exactly howthattupleshould bemoved
between dataspaces, possibly alsoincluding transformations (Mamei andZam-
bonelli, 2004).
13.3PROCESSES
There isnothing really special about theprocesses usedinpublish/subscribe
systems. Inmostcases, efficient mechanisms needtobedeployed forsearching in
apotentially largecollection ofdata.Themainproblem isdevising schemes that
work wellindistributed environments. Wereturn tothisissuebelow when dis-
cussing consistency andreplication.
13.4COMMUNICATION
Communication inmany publish/subscribe systems isrelatively simple. For
example, invirtually every Java-based system. allcommunication proceeds
through remote method invocations. Oneimportant problem thatneeds tobe
handled when publish/subscribe systems arespread across awide-area system is
thatpublished datashould reach onlytherelevant subscribers. Aswedescribed
above, using aself-organizing method bywhich nodes inapeer-to-peer system
areautomatically clustered, afterwhich dissemination takesplace percluster is
onesolution. Analternative solution istodeploy content-based routing.
13.4.1Content-Based Routing
Incontent-based routing,thesystem isassumed tobebuiltontopofa
point-to-point network inwhich messages areexplicitly routed between nodes.
Crucial inthissetupisthatrouters cantakerouting decisions byconsidering the
content ofamessage. More precisely, itisassumed thateachmessage carries a
description ofitscontent, andthatthisdescription canbeusedtocut-off routes for
which itisknown thattheydonotleadtoreceivers interested inthatmessage.
Apractical approach toward content-based routing isproposed inCarzaniga
etal.(2004). Consider apublish/subscribe system consisting ofNservers to
which clients (i.e.,applications) cansendmessages, orfromwhich theycanread602 DISTRIBUTED COORDINA nON-BASED SYSTEMSCHAP. 13
incoming messages. Weassume thatinorder toreadmessages, anapplication will
have previously provided theserver withadescription ofthekindofdataitis
interested in.Theserver, inturn,willnotify theapplication when relevant data
hasarrived.
Carzaniga eta1.propose atwo-layered routing scheme inwhich thelowest
layer consists ofashared broadcast treeconnecting theNservers. There arevari-
ousways forsetting upsuchatree,ranging fromnetwork-level multicast support
toapplication-level multicast treesaswediscussed inChap. 4.Here, wealsoas-
sume thatsuchatreehasbeensetupwiththeNservers asendnodes, along witha
collection ofintermediate nodes forming therouters. Notethatthedistinction be-
tween aserver andarouter isonlyalogical one:asingle machine mayhostboth
kinds ofprocesses.
Consider firsttwoextremes forcontent-based routing, assuming weneed to
support onlysimple subject-based publish/subscribe inwhich each message is
tagged withaunique (noncompound) keyword. Oneextreme solution istosend
each published message toevery server, andsubsequently lettheserver check
whether anyofitsclients hadsubscribed tothesubject ofthatmessage. In
essence, thisistheapproach followed inTIBlRendezvous.
Figure 13-7. Naive content-based routing.
Theother extreme solution istoletevery server broadcast itssubscriptions to
allother servers. Asaresult, every server willbeabletocompile alistof(subject,
destination) pairs. Then, whenever anapplication submits amessage onsubject s,
itsassociated server prepends thedestination servers tothatmessage. When the
message reaches arouter, thelatter canusethelisttodecide onthepaths thatthe
message should follow, asshown inFig.13-7.
Taking thislastapproach asourstarting point, wecanrefine thecapabilities
ofrouters fordeciding where toforward messages to.Tothatend,each server
broadcasts itssubscription across thenetwork sothatrouters cancompose rout-
ingfilters. Forexample, assume thatnode 3inFig.13-7subscribes tomessages
forwhich anattribute aliesintherange [0,3], butthatnode 4wants messages
withaE[2,5]. Inthiscase, router R"}.willcreate arouting filter asatable withanSEC. 13.4 COMMUNICATION 603
entryforeachofitsoutgoing links(inthiscasethree: onetonode3,onetonode
4,andonetoward router R1),asshown inFig.13-8.
Figure 13-8. Apartially filledrouting table.
More interesting iswhathappens atrouter R1.Inthisexample, thesubscrip-
tionsfromnodes 3and4dictate thatanymessage withalyingintheinterval
[0,3]u[2,5]=[0,5]should beforwarded along thepathtorouter Rz,andthisis
precisely theinformation thatR1willstoreinitstable. Itisnotdifficult toima-
ginethatmoreintricate subscription compositions canbesupported.
Thissimple example alsoillustrates thatwhenever anodeleaves thesystem,
orwhen itisnolonger interested inspecific messages, itshould cancel itssub-
scription andessentially broadcast thisinformation toallrouters. Thiscancella-
tion,intum,mayleadtoadjusting various routing filters. Lateadjustments willat
worst leadtounnecessary traffic asmessages maybeforwarded along paths for
which therearenolonger subscribers. Nevertheless, timely adjustments areneed-
edtokeepperformance atanacceptable level.
Oneoftheproblems withcontent-based routing isthatalthough theprinciple
ofcomposing routing filters issimple, identifying thelinksalongwhich anincom-
ingmessage mustbeforwarded canbecompute-intensive. Thecomputational
complexity comes fromtheimplementation ofmatching attribute values tosub-
scriptions, which essentially boilsdown toanentry-by-entry comparison. How
thiscomparison canbedoneefficiently isdescribed inCarzaniga etal.(2003).
13.4.2Supporting Composite Subscriptions
Theexamples sofarformrelatively simple extensions torouting tables. These
extensions suffice when subscriptions taketheformofvectors of(attribute,
value/range) pairs. However, thereisoftenaneedformoresophisticated expres-
sions ofsubscriptions. Forexample, itmaybeconvenient toexpress composi-
tionsofsubscriptions inwhich aprocess specifies inasingle subscription thatitis
interested inverydifferent types ofdataitems. Toillustrate, aprocess maywant
toseedataitemsonstocks fromIBManddataontheirrevenues, butsending data
items ofonlyonekindisnotuseful.
Tohandle subscription compositions, LiandJacobsen (2005) proposed to
design routers analogous toruledatabases. Ineffect, subscriptions aretransformed
intorulesstating under which conditions published datashould beforwarded, and604 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
along which outgoing links. Itisnotdifficult toimagine thatthismayleadto
content-based routing schemes thatarefarmoreadvanced thantherouting filters
described above. Supporting subscription composition isstrongly related tona-
mingissues incoordination-based systems, which wediscuss next.
13.5NAMING
Letusnowpaysomemoreattention tonaming incoordination-based systems.
Sofar,wehavemostly assumed thatevery published dataitemhasanassociated
vector of11(attribute, value) pairsandthatprocesses cansubscribe todataitems
byspecifying predicates overthese attribute values. Ingeneral, thisnaming
scheme canbereadily applied, although systems differ withrespect toattribute
types, values. andthepredicates thatcanbeused.
Forexample. withJavaSpaces wesawthatessentially onlycomparison for
equality issupported, although thiscanberelatively easily extended inapplica-
tion-specific ways. Likewise, many commercial publish/subscribe systems sup-
portonlyrather primitive string-comparison operators.
Oneoftheproblems wealready mentioned isthatinmany cases wecannot
simply assume thatevery dataitemistagged withvalues forallattributes. Inpar-
ticular, wewillseethatadataitemhasonlyoneassociated (attribute, value) pair,
inwhich caseitisalsoreferred toasanevent. Support forsubscribing toevents,
andnotably composite events largely dictates thediscussion onnaming issues in
publish/subscribe systems. What wehavediscussed sofarshould beconsidered as
themoreprimitive means forsupporting coordination indistributed systems. We
nowaddress inmoredepth events andeventcomposition.
When dealing withcomposite events, weneedtotaketwodifferent issues into
account. Thefirstoneistodescribe compositions. Suchdescriptions formthe
basisforsubscriptions. Thesecond issueishowtocollect (primitive) events and
subsequently match themtosubscriptions. Pietzuch etal.(2003) haveproposed a
general framework forevent composition indistributed systems. Wetakethis
framework asthebasisforourdiscussion.
13.5.1Describing Composite Events
Letusfirstconsider someexamples ofcomposite events togiveabetter idea
ofthecomplexity thatwemayneedtodealwith. Fig.13-9shows examples of
increasingly complex composite events. Inthisexample, R4.20 could beanair-
conditioned andsecured computer room.
Thefirsttwosubscriptions arerelatively easy.S1isanexample thatcanbe
handled byaprimitive discrete event, whereas S2isasimple composition oftwo
discrete events. Subscription S3ismorecomplex asitrequires thatthesystem can
alsoreport time-related events. Matters arefurther complicated ifsubscriptionsSEC. 13.5 NAMING 605
Figure 13-9. Examples ofevents inadistributed system.
involve aggregated values required forcomputing gradients (S4)oraverages (S5)'
NotethatinthecaseofS5wearerequiring acontinuous monitoring ofthesystem
inordertosendnotifications ontime.
Thebasic ideabehind anevent-composition language fordistributed systems
istoenable theformulation ofsubscriptions interms ofprimitive events. Intheir
framework, Pietzuch etal.provide arelatively simple language foranextended
typeoffinite-state machine (FSM). Theextensions allow forthespecification of
sojourn times instates, aswellasthegeneration ofnew(composite) events. The
precise details oftheirlanguage arenotimportant forourdiscussion here.What is
important isthatsubscriptions canbetranslated intoFSMs.
Figure 13-10. Thefinite statemachine forsubscription S3fromFig.13-9.
Togiveanexample, Fig.13-10 shows theFSMforsubscription S3from
Fig.13-9. Thespecial caseisgiven bythetimed state, indicated bythelabel
"t=1Os"which specifies thatatransition tothefinalstateismadeifthedooris
notlocked within 10seconds.
Much morecomplex subscriptions canbedescribed. Animportant aspect is
thatthese FSMs canoftenbedecomposed intosmaller FSMs thatcommunicate
bypassing events toeachother. Notethatsuchanevent communication would
normally trigger astatetransition attheFSMforwhich thateventisintended. For
example, assume thatwewanttoautomatically tumoffthelights inroomR4.20606 DISTRIBUTED COORDINA nON-BASED SYSTEMS CHAP. 13
after2seconds when wearecertain thatnobody isthereanymore (andthedooris
locked). Inthatcase,wecanreusetheFSMfromFig.13-10 ifweletitgenerate
aneventforasecond FSMthatwilltrigger thelighting, asshown inFig.13-11
Figure 13-11. Twocoupled FSMs.
Theimportant observation hereisthatthesetwoFSMs canbeimplemented as
separate processes inthedistributed system. Inthiscase,theFSMforcontrolling
thelighting willsubscribe tothecomposed event thatistriggered when R4.20 is
unoccupied andthedoorislocked. Thisleads todistributed detectors which we
discuss next.
13.5.2 Matching Events andSubscriptions
Nowconsider apublish/subscribe system supporting composite events. Every
subscription isprovided intheformofanexpression thatcanbetranslated intoa
finitestatemachine (FSM). Statetransitions areessentially triggered byprimitive
events thattakeplace, suchasleaving aroomorlocking adoor.
Tomatch events andsubscriptions, wecanfollow asimple, naive implemen-
tation inwhich every subscriber runsaprocess implementing thefinite statema-
chine associated withitssubscription. Inthatcase,alltheprimitive events thatare
relevant foraspecific subscription willhavetobeforwarded tothesubscriber.
Obviously, thiswillgenerally notbeveryefficient.
Amuch better approach istoconsider thecomplete collection ofsubscrip-
tions, anddecompose subscriptions intocommunicating finite statemachines,
suchthatsomeoftheseFSMs areshared between different subscriptions. Anex-
ample ofthissharing wasshown inFig.13-11. Thisapproach toward handling
subscriptions leadstowhatareknown asdistributed event detectors. Notethat
adistribution ofevent detectors issimilar innature tothedistributed resolution ofSEC. 13.5 NAMING 607
names invarious naming systems. Primitive events leadtostatetransitions inrela-
tively simple finite statemachines, inturntriggering thegeneration ofcomposite
events. Thelattercanthenleadtostatetransitions inotherFSMs, againpossibly
leading tofurther event generation. Ofcourse, events translate tomessages that
aresentoverthenetwork toprocesses thatsubscribed tothem.
Besides optimizing through sharing, breaking down subscriptions intocom-
municating FSMs alsohasthepotential advantage ofoptimizing network usage.
Consider again theevents related tomonitoring thecomputer roomwedescribed
_above. Assuming thatthereonlyprocesses interested inthecomposite events, it
makes sense tocompose theseevents closetothecomputer room. Suchaplace-
mentwillprevent having tosendtheprimitive events across thenetwork. More-
over,when considering Fig.13-9,weseethatwemayonlyneedtosendthealarm
when noticing thattheroom isunoccupied for10seconds while thedooris
unlocked. Such anevent willgenerally occur rarely incomparison to,forex-
ample, (un)locking thedoor.
Decomposing subscriptions intodistributed event detectors, andsubsequently
optimally placing themacross adistributed system isstillsubject tomuch re-
search. Forexample, thelastwordonsubscription languages hasnotbeensaid,
andespecially thetrade-off between expressiveness andefficiency ofimplemen-
tations willattract alotofattention. Inmostcases, themoreexpressive alanguage
is,themore unlikely there willbeanefficient distributed implementation.
Current proposals suchasbyDemers etal.(2006) andbyLiuandJacobsen (2004)
confirm this.Itwilltakesomeyearsbefore weseethesetechniques being applied
tocommercial publish/subscribe systems.
13.6SYNCHRONIZATION
Synchronization incoordination-based systems isgenerally restricted tosys-
temssupporting generative communication. Matters arerelatively straightforward
when onlyasingle server isused.Inthatcase,processes canbesimply blocked
untiltuples become available, butitisalsosimpler toremove them. Matters
become complicated when theshared dataspace isreplicated anddistributed a-
crossmultiple servers, aswedescribe next.
13.7CONSISTENCY ANDREPLICATION
Replication playsakeyroleinthescalability ofcoordination-based systems,
andnotably thoseforgenerative communication. Inthefollowing, wefirstconsid-
ersome standard approaches ashavebeenexplored inanumber ofsystems such
asJavaSpaces. Next, wedescribe somerecent results thatallow forthedynamic
andautomatic placement oftuples depending ontheiraccess patterns.608 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
13.7.1 Static Approaches
Thedistributed implementation ofasystem supporting generative communi-
cation frequently requires special attention. Weconcentrate onpossible distrib-
utedimplementations ofaJavaSpace server, thatis,animplementation bywhich
thecollection oftuple instances maybedistributed andreplicated across. several
machines. Anoverview ofimplementation techniques fortuple-based runtime
systems isgiven byRowstron (2001).
General Considerations
Anefficient distributed implementation ofaJavaSpace hastosolve twoprob-
lems:
1.Howtosimulate associative addressing without massive searching.
2.Howtodistribute tuple instances among machines andlocate them
later.
Thekeytobothproblems istoobserve thateachtuple isatyped datastructure.
Splitting thetuple space intosubspaces, eachofwhose tuples isofthesame type
simplifies programming andmakes certain optimizations possible. Forexample,
because tuples aretyped, itbecomes possible todetermine atcompile timewhich
subspace acalltoawrite, read, ortake operates on.Thispartitioning means that
onlyafraction ofthesetoftuple instances hastobesearched.
Inaddition, eachsubspace canbeorganized asahashtable using (partof)its
i-thtuple fieldasthehashkey.Recall thatevery fieldinatuple instance isa
marshaled reference toanobject. JavaSpaces doesnotprescribe howmarshaling
should bedone. Therefore, animplementation maydecide tomarshal areference
insuchawaythatthefirstfewbytes areusedasanidentifier ofthetypeofthe
object thatisbeing marshaled. Acalltoawrite, read, ortake operation canthen
beexecuted bycomputing thehashfunction oftheithfieldtofindtheposition in
thetable where thetuple instance belongs. Knowing thesubspace andtableposi-
tioneliminates allsearching. Ofcourse, iftheithfieldofaread ortake operation
isNULL, hashing isnotpossible, soacomplete search ofthesubspace isgener-
allyneeded. Bycarefully choosing thefieldtohashon,however, searching can
often beavoided.
Additional optimizations arealsoused. Forexample, thehashing scheme
described above distributes thetuples ofagiven subspace intobinstorestrict
searching toasingle bin.Itispossible toplace different binsondifferent ma-
chines, bothtospread theloadmore widely andtotakeadvantage oflocality. If
thehashing function isthetypeidentifier modulo thenumber ofmachines, the
number ofbinsscales linearly withthesystem size[seealsoBjornson (1993)].SEC. 13.7 CONSISTENCY AND REPLICATION609
Onanetwork ofcomputers, thebestchoice depends onthecommunication
architecture. Ifreliable broadcasting isavailable, aserious candidate istorepli-
cateallthesubspaces infullonallmachines, asshown inFig.13-12. When a
writeisdone, thenewtupleinstance isbroadcast andentered intotheappropriate
subspace oneachmachine. Todoareadortakeoperation, thelocalsubspace is
searched. However, sincesuccessful completion ofatakerequires removing the
tupleinstance fromtheJavaSpace, adelete protocol isrequired toremove itfrom
allmachines. Toprevent raceconditions anddeadlocks, atwo-phase commit pro-
tocolcanbeused.
Figure 13-12. AJavaSpace canbereplicated onallmachines. Thedotted lines
show thepartitioning oftheJavaSpace intosubspaces. (a)Tuples arebroadcast
onwrite. (b)reads arelocal, buttheremoving aninstance when calling take
mustbebroadcast.
Thisdesign isstraightforward, butmaynotscalewellasthesystem grows in
thenumber oftupleinstances andthesizeofthenetwork. Forexample, imple-
menting thisscheme across awide-area network isprohibitively expensive.
Theinverse design istodowrites locally, storing thetupleinstance onlyon
themachine thatgenerated it,asshown inFig.13-13. Todoareadortake,a
process mustbroadcast thetemplate tuple. Eachrecipient thenchecks toseeifit
hasamatch, sending backareplyifitdoes.
Ifthetupleinstance isnotpresent, orifthebroadcast isnotreceived atthe
machine holding thetuple, therequesting machine retransmits thebroadcast re-
quest adinfinitum, increasing theinterval between broadcasts untilasuitable
tupleinstance materializes andtherequest canbesatisfied. Iftwoormoretuple610 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
Figure 13-13. Nonreplicated JavaSpace. (a)Awrite isdonelocally. (b)Aread
ortakerequires thetemplate tuple tobebroadcast inorder tofindatuple in-
stance.
instances aresent,theyaretreated likelocalwrites andtheinstances areeffec-
tively moved fromthemachines thathadthemtotheonedoing therequest. In
fact,theruntime system canevenmove tuples around onitsowntobalance the
load.Carriero andGelemter (1986) usedthismethod forimplementing theLinda
tuplespace onaLAN.
These twomethods canbecombined toproduce asystem withpartial replica-
tion.Asasimple example, imagine thatallthemachines logically formarec-
tangular grid,asshown inFig.13-14. When aprocess onamachine Awants to
doawrite, itbroadcasts (orsends bypoint-to-point message) thetupletoallma-
chines initsrowofthegrid.When aprocess onamachine Bwants toreadortake
atupleinstance, itbroadcasts thetemplate tupletoallmachines initscolumn.
Duetothegeometry, therewillalways beexactly onemachine thatseesboththe
tupleinstance andthetemplate tuple(Cinthisexample), andthatmachine makes
thematch andsends thetupleinstance totheprocess requesting forit.Thisap-
proach issimilar tousingquorum-based replication aswediscussed inChap. 7.
Theimplementations wehavediscussed sofarhaveserious scalability prob-
lemscaused bythefactthatmulticasting isneeded either toinsert atupleintoa
tuplespace, ortoremove one.Wide-area implementations oftuplespaces donot
exist.Atbest,several different tuplespaces cancoexist inasingle system, where
eachtuplespace itselfisimplemented onasingle server oronalocal-area net-
work. Thisapproach isused,forexample, inPageSpaces (Ciancarini etal.,1998)SEC. 13.7 CONSISTENCY AND REPLICATION 611
Figure 13-14. Partial broadcasting oftuples andtemplate tuples.
andWCL (Rowstron andWray, 1998). InWCL, eachtuple-space server is
responsible foranentire tuple space. Inotherwords, aprocess willalways be
directed toexactly oneserver. However, itispossible tomigrate atuplespacetoa
different server toenhance performance. Howtodevelop anefficient wide-area
implementation oftuplespaces isstillanopenquestion.
13.7.2 Dynamic Replication
Replication incoordination-based systems hasgenerally beenrestricted to
staticpolicies forparallel applications likethosediscussed above. Incommercial
applications, wealsoseerelatively simple schemes inwhich entire dataspaces or
otherwise statically predefined partsofadatasetaresubject toasingle policy
(GigaS paces, 2005). Inspired bythefine-grained replication ofWebdocuments
inGlobule, performance improvements canalsobeachieved whendifferentiating
replication between thedifferent kinds ofdatastored inadataspace. Thisdif-
ferentiation issupported byGSpace, which webriefly discuss inthissection.
GSpace Overview
GSpace isadistributed coordination-based system thatisbuiltontopofJava-
Spaces (Russello etal.,2004, 2006). Distribution andreplication oftuples in
GSpace isdonefortwodifferent reasons: improving performance andavailability.
Akeyelement inthisapproach istheseparation ofconcerns: tuples thatneedto612 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
bereplicated foravailability mayneedtofollow adifferent strategy thanthosefor
which performance isatstake. Forthisreason, thearchitecture ofGSpace has
beensetuptosupport avariety ofreplication policies, andsuchthatdifferent
tuples mayfoUow different policies.
Figure 13-15. Internal organization ofaGSpace kernel.
Theprincipal working isrelatively simple. Every application isoffered anin-
terface witharead,write, andtakeinterface, similar towhatisoffered byJava-
Spaces. However, every callispicked upbyalocalinvocation handler which
looks upthepolicy thatshould befollowed forthespecific call.Apolicy issel-
ectedbased onthetypeandcontent ofthetuple/template thatispassed aspartof
thecall.Every policy isidentified byatemplate, similar tothewaythattemplates
areusedtoselect tuples inotherJava-based shared dataspaces aswediscussed
previously.
Theresult ofthisselection isareference toadistribution manager, which im-
plements thesameinterface, butnowdoesitaccording toaspecific replication
policy. Forexample, ifamaster/slave policy hasbeenimplemented, areadopera-
tionmaybeimplemented byimmediately reading atuplefromthelocally avail-
abledataspace. Likewise, awriteoperation mayrequire thatthedistribution man-
agerforwards theupdate tothemaster nodeandawaits anacknowledgment be-
foreperforming theoperation locally.
Finally, every GSpace kernel hasalocaldataspace, called aslice, which is
implemented asafull-fledged, nondistributed version ofJave.Spaces.
Inthisarchitecture (ofwhich some components arenotshown forclarity),
policy descriptors canbeadded atruntime, andlikewise. distribution managers
canbechanged aswell.Thissetupallows forafine-grained tuning ofthedistribu-
tionandreplication oftuples, andasisshown inRussello etal.(2004), suchfine-
tuning allows formuch higher performance thanisachievable withanyfixed, glo-
balstrategy thatisapplied toalltuples inadataspace.SEC. 13.7 CONSISTENCY AND REPLICA nON 613
Adaptive Replication
However, themostimportant aspect withsystems suchasGSpace isthatrep-
lication management isautomated. Inotherwords, rather thanletting theapplica-
tiondeveloper figure outwhich combination ofpolicies isthebest,itisbetter to
letthesystem monitor access patterns andbehavior andsubsequently adopt poli-
ciesasnecessary.
Tothisend,GSpace follows thesameapproach asinGlobule: itcontinuously
measures consumed network bandwidth. latency, andmemory usage anddepend-
ingonwhich ofthesemetrics isconsidered mostimportant, places tuples ondif-
ferent nodes andchooses themostappropriate waytokeepreplicas consistent.
Theevaluation ofwhich policy isthebestforagiventupleisdonebymeans ofa
central coordinator which simply collects traces fromthenodes thatconstitute the
GSpace system.
Aninteresting aspect isthatfromtimetotimewemayneedtoswitch from
onereplication policy toanother. There areseveral waysinwhich suchatransi-
tioncantakeplace. AsGSpace aimstoseparate mechanisms frompolicies asbest
aspossible, itcanalsohandle different transition policies. Thedefault caseisto
temporarily freeze alloperations foraspecific typeoftuple, remove allreplicas
andreinsert thetupleintotheshared dataspace butnowfollowing thenewly
selected replication policy. However, depending onthenewreplication policy, a
different wayofmaking thetransition maybepossible (andcheaper). Forex-
ample, when switching fromnoreplication tomaster/slave replication, oneap-
proach could betolazily copytuples totheslaves whentheyarefirstaccessed.
13.8FAULTTOLERANCE
When considering thatfaulttolerance isfundamental toanydistributed sys-
tem,itissomewhat surprising howrelatively littleattention hasbeenpaidtofault
tolerance incoordination-based systems, including basic publish/subscribe sys-
temsaswellasthosesupporting generative communication. Inmostcases, atten-
tionfocuses onensuring efficient reliability ofdatadelivery, which essentially
boilsdown toguaranteeing reliable communication. When themiddleware isalso
expected tostoredataitems, asisthecasewithgenerative communication, some
effort ispaidtoreliable storage. Letustakeacloser lookatthesetwocases.
13.8.1ReliablePublish-Subscribe Communication
Incoordination-based systems where published dataitems arematched only
against livesubscribers, reliable communication playsacrucial role.Inthiscase,
faulttolerance ismostoftenimplemented through theimplementation ofreliable
multicast systems thatunderly theactual publish/subscribe software. There are614 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. ]3
several issues thataregenerally taken careof.First,independent ofthewaythat
content-based routing takesplace. areliable multicast channel issetup.Second,
process faulttolerance needs tobehandled. Letustakealookhowthesematters
areaddressed inTIBlRendezvous.
Example: FaultTolerance inTIBlRendezvous
TIB/Rendezvous assumes thatthecommunication facilities oftheunderlying
network areinherently unreliable. Tocompensate forthisunreliability. whenever
arendezvous daemon publishes amessage toother daemons, itwillkeepthat
message foratleast60seconds. When publishing amessage, adaemon attaches a
(subject independent) sequence number tothatmessage. Areceiving daemon can
detect itismissing amessage bylooking atsequence numbers (recall thatmes-
sagesaredelivered toalldaemons). When amessage hasbeenmissed, thepub-
lishing daemon isrequested toretransmit themessage.
Thisformofreliable communication cannot prevent thatmessages maystill
belost.Forexample, ifareceiving daemon requests aretransmission ofames-
sagethathasbeenpublished morethan60seconds ago,thepublishing daemon
willgenerally notbeabletohelprecover thislostmessage. Under normal cir-
cumstances, thepublishing andsubscribing applications willbenotified thata
communication errorhasoccurred. Errorhandling isthenlefttotheapplications
todealwith.
Much ofthereliability ofcommunication inTIBlRendezvous isbased onthe
reliability offered bytheunderlying network. TIBlRendezvous alsoprovides reli-
ablemulticasting using (unreliable) IPmulticasting asitsunderlying communica-
tionmeans. Thescheme followed inTIB/Rendezvous isatransport-level multi-
castprotocol known asPragmatic General Multicast (PGM), which is
described inSpeakman eta1.(2001). Wewilldiscuss PGM briefly.
PGM doesnotprovide hardguarantees thatwhen amessage ismulticast it
willeventually bedelivered toeachreceiver. Fig.13-16(a) shows asituation in
which amessage hasbeenmulticast along atree,butithasnotbeendelivered to
tworeceivers. PG11 relies onreceivers detecting thattheyhavemissed messages
forwhich theywillsendaretransmission request (i.e.,aNAK) tothesender. This
request issentalong thereverse pathinthemulticast treerooted atthesender. as
shown inFig.13-16(b). Whenever aretransmission request reaches anintermedi-
atenode, thatnodemaypossibly havecached therequested message, atwhich
pointitwillhandle theretransmission. Otherwise, thenodesimply forwards the
NAKtothenextnodetoward thesender. Thesender isultimately responsible for
retransmitting amessage.
PGM takesseveral measures toprovide ascalable solution toreliable multi-
casting. First,ifanintermediate nodereceives several retransmission requests for
exactly thesamemessage, onlyoneretransmission request isforwarded toward615
Figure 13-16. Theprinciple ofPGM. (a)Amessage issentalong amulticast
tree. (b)Arouter willpassonlyasingle NAK foreachmessage. (c)Amessage
isretransmitted onlytoreceivers thathaveasked forit.
thesender. Inthisway,anattempt ismade toensure thatonlyasingle NAK
reaches thesender, sothatafeedback implosion isavoided. Wealready camea-
crossthisproblem inChap. 8whendiscussing scalability issues inreliable multi-
casting.
Asecond measure taken byPGM istoremember thepaththrough which a
NAK traverses fromreceivers tothesender, asisshown inFig.13-16(c). When
thesender finally retransmits therequested message, PGM takes carethatthe
message ismulticast onlytothose receivers thathadrequested retransmission.
Consequently, receivers towhich themessage hadbeensuccessfully delivered are
notbothered byretransmissions forwhich theyhavenouse.
Besides thebasicreliability scheme andreliable multicasting through PGM,
TIB/Rendezvous provides further reliability bymeans ofcertified message
delivery. Inthiscase,aprocess usesaspecial communication channel forsend-
ingorreceiving messages. Thechannel hasanassociated facility, called aledger,
forkeeping trackofsentandreceived certified messages. Aprocess thatwants to
receive certified messages registers itselfwiththesender ofsuchmessages. In
effect, registration allows thechannel tohandle further reliability issues forwhich
therendezvous daemons provide nosupport. Mostoftheseissues arehidden from
applications andarehandled bythechannel's implementation.
When aledger isimplemented asafile,itbecomes possible toprovide reli-
ablemessage delivery eveninthepresence ofprocess failures. Forexample, when
areceiving process crashes, allmessages itmisses untilitrecovers again are
stored inasender's ledger. Uponrecovery, thereceiver simply contacts theledger
andrequests themissed messages toberetransmitted.
Toenable themasking ofprocess failures, TIB/Rendezvous provides asimple
means toautomatically activate ordeactivate processes. Inthiscontext, anactiveFAULT TOLERANCE SEC. 13.8616 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
process normally responds toallincoming messages, while aninactive onedoes
not.Aninactive process isarunning process thatcanhandle onlyspecial events
asweexplain shortly.
Processes canbeorganized intoagroup, witheachprocess having aunique
rankassociated withit.Therankofaprocess isdetermined byits(manually
assigned) weight, butnotwoprocesses inthesame group mayhavethesame
rank.Foreachgroup, TIB/Rendezvous willattempt tohaveagroup-specific num-
berofprocesses active, called thegroup's active goal. Inmany cases. theactive
goalissettoonesothatallcommunication withagroup reduces toaprimary-
based protocol asdiscussed inChap. 7.
Anactive process regularly sendsamessage toallothermembers inthegroup
toannounce thatitisstillupandrunning. Whenever suchaheartbeat message is
missing, themiddleware willautomatically activate thehighest-ranked process
thatiscurrently inactive. Activation isaccomplished byacallback toanaction
operation thateachgroup member isexpected toimplement. Likewise, when a
previously crashed process recovers againandbecomes active, thelowest-ranked
currently active process willbeautomatically deactivated.
Tokeepconsistent withtheactive processes, special measures needtobe
takenbyaninactive process before itcanbecome active. Asimple approach isto
letaninactive process subscribe tothesame messages asanyother group
member. Anincoming message isprocessed asusual, butnoreactions areever
published. Notethatthisscheme isakintoactive replication.
13.8.2 Fault Tolerance inShared Dataspaces
When dealing withgenerative communication, matters become morecompli-
cated. Asalsonoted inTolksdorf andRowstron (2000), assoonasfaulttolerance
needs tobeincorporated inshared dataspaces, solutions canoftenbecome soinef-
ficient thatonlycentralized implementations arefeasible. Insuchcases, tradi-
tional solutions areapplied, notably using acentral server thatisbacked upin
usingasimple primary-backup protocol, incombination withcheckpointing.
Analternative istodeploy replication moreaggressively byplacing copies of
dataitems across thevarious machines. Thisapproach hasbeen adopted in
GSpace, essentially deploying thesamemechanisms itusesforimproving perfor-
mance through replication. Tothisend,eachnodecomputes itsavailability, which
isthenusedincomputing theavailability ofasingle (replicated) dataitem
(Russello etat.2006).
Tocompute itsavailability, anoderegularly writes atimestamp topersistent
storage, allowing ittocompute thetimewhen itisup,andthetimewhen itwas
down. More precisely. availability iscomputed interms ofthemean timeto
failure (MTTF) andthemean timetorepair (MTTR):SEC. 13.8 FAULT TOLERANCE 617
Notethatitisnecessary toregularly logtimestamps andthatTf:art canbe
taken onlyasabestestimate ofwhen acrash occurred. However, thethuscom-
puted availability willbepessimistic, astheactual timethatanodecrashed forthe
eh timewillbeslightly laterthanTran. Also,instead oftaking averages sincethe
beginning, itisalsopossible totakeonlythelastNcrashes intoaccount.
Figure 13-17. Thetimelineofanodeexperiencing failures.
InGSpace, eachtypeofdataitemhasanassociated primary nodethatis
responsible forcomputing thattype's availability. Given thatadataitemisrepli-
cated across mnodes, itsavailability iscomputed byconsidering theavailability
a,ofeachofthemnodes leading to:Tocompute MITF andMITR, anodesimply looks atthelogged timestamps. as
shown inFig.13-17. Thiswillallow ittocompute theaverages forthetimebe-
tween failures, leading toanavailability of:
Bysimply taking theavailability ofadataitemintoaccount, aswellasthoseof
allnodes, theprimary cancompute anoptimal placement foradataitemthatwill
satisfy theavailability requirements foradataitem.Inaddition, itcanalsotake
other factors intoaccount, suchasbandwidth usage andCPUloads. Notethat
placement maychange overtimeifthesefactors fluctuate.
13.9SECURITY
Security incoordination-based systems poses adifficult problem. Ontheone
handwehavestated thatprocesses should bereferentially decoupled, butonthe
otherhandweshould alsoensure theintegrity andconfidentiality ofdata.Thisse-
curity isnormally implemented through secure (multicast) channels, which effec-
tively require thatsenders andreceivers canauthenticate eachother. Suchauthen-
tication violates referential decoupling.618 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
Tosolvethisproblem therearedifferent approaches. Onecommon approach
istosetupanetwork ofbrokers thathandle theprocessing ofdataandsubscrip-
tions.Client processes willthencontact thebrokers, whothentakecareofauthen-
tication andauthorization. Notethatsuchanapproach doesrequire thattheclients
trustthebrokers. However, asweshallseelater,bydifferentiating between types
ofbrokers, itisnotnecessary thataclient hastotrustallbrokers comprising the
system.
Bynature ofdatacoordination, authorization naturally translates toconfiden-
tiality issues. WewiIJnowtakeacloser lookattheseissues, following thediscus-
sionaspresented inWang etal.(2002).
13.9.1Confidentiality
Oneimportant difference between many distributed systems andcoordi-
nation-based onesisthatinordertoprovide efficiency, themiddleware needs to
inspect thecontent ofpublished data.Without being abletodoso,themiddleware
canessentially onlyflooddatatoallpotential subscribers. Thisposes theproblem
ofinformation confidentiality which refers tothefactthatitissometimes im-
portant todisallow themiddleware toinspect published data.Thisproblem canbe
circumvented through end-to-end encryption; therouting substrate onlysees
source anddestination addresses.
Ifpublished dataitems arestructured inthesense thatevery itemcontains
multiple fields, itispossible todeploy partial secrecy. Forexample, dataregard-
ingrealestate mayneedtobeshipped between agents ofthesame office with
branches atdifferent locations, butwithout revealing theexactaddress ofthepro-
perty. Toallow forcontent-based routing, theaddress fieldcould beencrypted,
while thedescription oftheproperty could bepublished intheclear. Tothisend,
Khurana andKoleva (2006) propose touseaper-field encryption scheme asintro-
duced inBertino andFerrari (2002). Inthiscase,theagents belonging tothe
same branch would share thesecret keyfordecrypting theaddress. field. Of
course, this"Violates referential decoupling, butwewilldiscuss apotential solution
tothisproblem later.
Moreproblematic isthecasewhennoneofthe.fields maybedisclosed tothe
middleware inplaintext. Theonlysolution thatremains isthatcontent-based rout-
ingtakesplace ontheencrypted data.Asrouters gettoseeonlyencrypted data.
possibly onaper-field basis, subscriptions willneedtobeencoded insuchaway
thatpartial matching cantakeplace. Notethatapartial match isthebasisthata
router usestodecide which outgoing linkapublished dataitemshould befor-
warded on.
Thisproblem comes veryclosetoquerying andsearching through encrypted
data,something clearly nexttoimpossible toachieve. Asitturnsout,maintaining
ahighdegree ofsecrecy while stilloffering reasonable performance isknown toSEC. 13.9 SECURITY 619
beverydifficult (Kantarcioglu andClifton, 2005). Oneoftheproblems isthatif
per-field encryption isused,itbecomes much easier tofindoutwhatthedataisall
about.
Having toworkonencrypted dataalsobrings uptheissueofsubscription
confidentiality, which refers tothefactthatsubscriptions maynotbedisclosed to
themiddleware either. Inthecaseofsubject-based addressing schemes, onesolu-
tionistosimply useper-field encryption andapply matching onastrictfield-by-
fieldbasis. Partial matching canbeaccommodated inthecaseofcompound key-
words, which canberepresented asencrypted setsoftheirconstituents. Asub-
scriber would thensendencrypted forms ofsuchconstituents andlettherouters
check forsetmembership, asalsosuggested byRaiciu andRosenblum (2005). As
itturnsout,itisevenpossible tosupport range queries, provided anefficient
scheme canbedevised forrepresenting intervals. Apotential solution isdiscussed
inLietal.(2004a).
Finally, publication confidentiality isalsoanissue. Inthiscase,weare
touching uponthemoretraditional access control mechanisms inwhich certain
processes should notevenbeallowed toseecertain messages. Insuchcases, pub-
lishers maywanttoexplicitly restrict thegroup ofpossible subscribers. Inmany
cases, thiscontrol canbeexerted out-of-band atthelevelofthepublishing and
subscribing applications. However, itmayconvenient thatthemiddleware offers a
service tohandle suchaccess control.
Decoupling Publishers fromSubscribers
Ifitisnecessary toprotect dataandsubscriptions fromthemiddleware,
Khurana andKoleva (2006) propose tomake useofaspecial accounting service
(AS), which essentially sitsbetween clients (publishers andsubscribers) andthe
actual publish/subscribe middleware. Thebasic ideaistodecouple publishers
fromsubscribers while stillproviding information confidentiality. Intheirscheme,
subscribers register theirinterest inspecific dataitems, which aresubsequently
routed asusual. Thedataitems areassumed tocontain fields thathavebeen
encrypted. Toallow fordecryption, onceamessage should bedelivered toasub-
scriber, therouter passes ittotheaccounting service where itistransformed intoa
message thatonlythesubscriber candecrypt. Thisscheme isshown inFig.13-18.
Apublisher registers itselfatanynodeofthepublish/subscribe network, that
is,atabroker. Thebroker forwards theregistration information totheaccounting
service which thengenerates apublic keytobeusedbythepublisher, andwhich
issigned bytheAS.Ofcourse, theASkeeps theassociated private keytoitself.
When asubscriber registers, itprovides anencryption keythatisforwarded bythe
broker. Itisnecessary togothrough aseparate authentication phase toensure that
onlylegitimate subscribers register. Forexample, brokers should generally notbe
allowed tosubscribe forpublished data.620 DISTRIBUTED COORDINATION-BASED SYSTEMS CHAP. 13
Figure 13-18. Decoupling publishers fromsubscribers using anadditional trust-
edservice.
Ignoring many details, when adataitemispublished, itscritical fields will
havebeenencrypted bythepublisher. When thedataitemarrives atabroker who
wishes topassitontoasubscriber. theformer requests theAStotransform the
message byfirstdecrypting it,andthenencrypt itwiththekeyprovided bythe
subscriber. Inthisway, thebrokers willnever gettoknow about content that
should bekeptsecret, while atthesame time, publishers andsubscribers need not
share keyinformation.
Ofcourse. itiscrucial thataccounting service itself canscale. Various meas-
urescanbetaken. butonereasonable approach istointroduce realms inasimilar
waythatKerberos does. Inthiscase, messages intransmission mayneed tobe
transformed byre-encrypting them using thepublic keyofaforeign accounting
service. Fordetails, werefertheinterested reader to(Khurana andKoleva, 20(6).
13.9.2SecureSharedDataspaces
Very littlework hasbeendone when itcomes tomaking shared dataspaces
secure. Acommon approach istosimply encrypt thefields ofdataitems andlet
matching takeplace onlywhen decryption succeeds andcontent matches witha
subscription. Thisapproach isdescribed inVitek etal.(2003). Oneofthemajor
problems withthisapproach isthatkeysmayneedtobeshared between publish-
ersandsubscribers, orthatthedecryption keysofthepublishers should beknown
toauthorized subscribers.
Ofcourse, iftheshared dataspace istrusted (i.e.,theprocesses implementing
thedataspace areallowed toseethecontent oftuples), matters become much sim-
pler. Considering thatmost implementations make useofonlyasingle server,
extending thatserver withauthentication andauthorization mechanisms isoften
theapproach followed inpractice.SEC. 13.10 SUMMARY 621
13.10SUMMARY
Coordination-based distributed systems playanimportant roleinbuilding dis-
tributed applications. Most ofthese systems focus onreferential uncoupling of
processes, meaning thatprocesses neednotexplicitly refertoeachothertoenable
communication. Inaddition, itisalsopossible toprovide temporal decoupling by
which processes donothavetocoexist inordertocommunicate.
Animportant group ofcoordination-based systems isformed bythosesystems
thatfollow thepublish/subscribe paradigm asisdoneinTIBlRendezvous. Inthis
model, messages donotcarrytheaddress oftheirreceiver(s), butinstead aread-
dressed byasubject. Processes thatwishtoreceive messages should subscribe to
aspecific subject; themiddleware willtakecarethatmessages arerouted from
publishers tosubscribers.
More sophisticated arethesystems inwhich subscribers canformulate predi-
catesovertheattributes ofpublished dataitems. Insuchcases, wearedealing
withcontent-based publish/subscribe systems. Forefficiency, itisimportant that
routers caninstall filters suchthatpublished dataisforwarded onlyacross those
outgoing linksforwhich itisknown thattherearesubscribers.
Another group ofcoordination-based systems usesgenerative communication,
which takesplace bymeans ofashared dataspace oftuples. Atupleisatyped
datastructure similar toarecord. Toreadatuplefromatuplespace, aprocess
specifies whatitislooking forbyproviding atemplate tuple. Atuplethatmatches
thar'ternplate isthenselected andreturned totherequesting process. Ifnomatch
could befound, theprocess blocks.
Coordination-based systems aredifferent frommanyotherdistributed systems
inthattheyconcentrate fullyonproviding aconvenient wayforprocesses tocom-
municate without knowing eachotherinadvance. Also,communication maycon-
tinueinananonymous way.Themainadvantage ofthisapproach isflexibility as
itbecomes easier toextend orchange asystem whileitcontinues tooperate.
Theprinciples ofdistributed systems asdiscussed inthefirstpartofthebook
apply equally welltocoordination-based systems, although caching andreplica-
tionplayalessprominent roleincurrent implementations. Inaddition, naming is
strongly related toattribute-based searching assupported bydirectory services.
Problematic isthesupport forsecurity, asitessentially violates thedecoupling be-
tween publishers andsubscribers. Problems arefurther aggravated when the
middle ware should beshielded fromthecontent ofpublished data,making it
much moredifficult toprovide efficient solutions.
PROBLEMS
1.What typeofcoordination model would youclassify themessage-queuing systems
discussed inChap. 41622 DISTRIBUTED COORDINA nON-BASED SYSTEMS CHAP. 13
2.Outline animplementation ofapublish/subscribe system based onamessage-queuing
system likethatofIBMWebSphere.
3.Explain whydecentralized coordination-based systems haveinherent scalability prob-
lems.
4.Towhatisasubject name inTIBlRendezvous actually resolved, andhowdoesname
resolution takeplace?
5.Outline asimple implementation fortotally-ordered message delivery ina
TIB/Rendezvous system.
6.Incontent-based routing suchasusedintheSiena system, which wedescribed inthe
text,wemaybeconfronted withaserious management problem. Which problem is
that?
7.Assume aprocess isreplicated inaTIBlRendezvous system. Give twosolutions to
avoid sothatmessages fromthisreplicated process arenotpublished more thanonce.
8.Towhatextent doweneedtotally-ordered multicasting when processes arereplicated
inaTIBlRendezvous system?
9.Describe asimple scheme forPGM thatwillallow receivers todetect missing mes-
sages, eventhelastoneinaseries.
10.Howcould acoordination model based ongenerative communication beimplemented
inTIBlRendezvous?
11.Alease period inJiniisalways specified asaduration andnotasanabsolute timeat
which theleaseexpires. Whyisthisdone?
12.What arethemostimportant scalability problems inJini?
13.Consider adistributed implementation ofaJavaSpace inwhich tuples arereplicated a-
cross several machines. Giveaprotocol todelete atuple suchthatraceconditions are
avoided when twoprocesses trytodelete thesame tuple.
14.Suppose thatatransaction TinJinirequires alockonanobject thatiscurrently locked
byanother transaction T'.Explain whathappens.
15.Suppose thataJiniclient caches thetuple itobtained fromaJavaSpace sothatitcan
avoid having togototheJavaSpace thenexttime. Does thiscaching make anysense?
16.Answer theprevious question, butnowforthecasethataclient caches theresults re-
turned byalookup service.
17.Outline asimple implementation ofafault-tolerant JavaSpace.
18.Insome subject-based publish/subscribe systems, secure solutions aresought inend-
to-end encryption beteen publishers andsubscribers. However, thisapproach may
violate theinitial design goals ofcoordination-based systems. How?14
READING LIST
AND BIBLIOGRAPHY
Intheprevious 13chapters wehavetouched uponavariety oftopics. This
chapter isintended asanaidtoreaders interested inpursuing theirstudyofdistri-
buted systems further. Section 13.1isalistofsuggested readings. Section 13.2is
analphabetical bibliography ofallbooks andarticles citedinthisbook.
14.1SUGGESTIONS FORFURTHER READING
14.1.1 Introduction andGeneral Works
Coulouris etal.,Distributed Systems-Concepts andDesign
Agood general textondistributed systems. Itscoverage issimilar tothe
material found inthisbook, butisorganized completely different. There ismuch
material ondistributed transactions, along withsomeoldermaterial ondistributed
shared memory systems.
Foster andKesselman, TheGrid2:Blueprint foraNewComputing Infrastructure
Thisisthesecond edition ofabookinwhich many Gridexperts highlight
various issues oflarge-scale Gridcomputing. Thebookcovers alltheimportant
topics, including many examples oncurrent andfuture applications.
623624 READING LISTANDBIBLIOGRAPHY CHAP. 14
Neuman, "Scale inDistributed Systems"
Oneofthefewpapers thatprovides asystematic overview ontheissueof
scaleindistributed systems. Ittakesalookatcaching, replication, anddistribution
asscaling techniques, andprovides anumber ofrule-of-thumbs toapplying these
techniques fordesigning large-scale systems.
Silberschatz etaI.,Applied Operating System Concepts
Ageneral textbook onoperating systems including material ondistributed
systems withanemphasis onfilesystems anddistributed coordination.
Verissimo andRodrigues, Distributed Systems forSystems Architects
Anadvanced reading ondistributed systems, basically covering thesame
material asinthisbook. Relatively moreemphasis isputonfaulttolerance and
real-time distributed systems. Attention isalsopaidtomanagement ofdistributed
systems.
ZhaoandGuibas, Wireless Sensor Networks
Many books on(wireless) sensor networks describe thesesystems fromanet-
working approach. Thisbooktakesamoresystems perspective, which makes itan
attractive readforthoseinterested indistributed systems. Thebookgives agood
coverage ofwireless sensor networks.
14.1.2Architecture
Babaoglu etal.,Self-star Properties inComplex Information Systems
Much hasbeensaidabout self-* systems, butnotalways withthedegree of
substance thatwould bepreferred. Thisbookcontains acollection ofpapers from
authors withavariety ofbackgrounds thatconsider howself-* aspects, findtheir
wayintomodem computer systems.
BassetaI.,Software Architecture inPractice
Thiswidely usedbookgives anexcellent practical introduction andoverview
onsoftware architecture. Although thefocusisnotspecifically toward distributed
systems, itprovides anexcellent basisforunderstanding thevarious ways that
complex software systems canbeorganized.
Hellerstein etaI.,Feedback Control ofComputing Systems
Forthosereaders withsome mathematical background, thisbookprovides a
thorough treatment onhowfeedback control loopscanbeapplied to(distributed)
computer systems. Assuch,itforms analternative basisformuch oftheresearch
onself-* andautonomic computing systems.SEC. 14.1 SUGGESTIONS FORFURTHER READING 625
Luaetal.,"ASurvey andComparison ofPeer-to-Peer Overlay Network
Schemes"
Anexcellent survey ofmodem peer-to-peer systems, covering structured as
wellasunstructured networks. Thispaper forms agood introduction forthose
wanting togetdeeper intothesubject butdonotreally know where tostart.
Oram, Peer-to-Peer: Harnessing thePower ofDisruptive Technologies
Thisbook bundles anumber ofpapers onthefirstgeneration ofpeer-to-peer
networks. Itcovers various projects aswellasimportant issues suchassecurity,
trust, andaccountability. Despite thefactthatpeer-to-peer technology hasmade a
lotofprogress, thisbook isstillvaluable forunderstanding many. ofthebasic
issues thatneeded tobeaddressed.
White etaI.,"AnArchitectural Approach toAutonomic Computing"
Written bythetechnical people behind theideaofautonomic computing, this
short paper gives ahigh-level overview oftherequirements thatneed tobemet
forself-* systems.
14.1.3Processes
Andrews, Foundations ofMultithreaded, Parallel, andDistributed Programming
Ifyoueverneedathorough introduction toprogramming parallel anddistri-
buted systems, thisisthebook tolookfor.
Lewis andBerg, Multithreaded Programming withPthreads
Pthreads form thePoSIX standard forimplementing threads foroperating
systems andarewidely supported byUNIX -based systems. Although theauthors
concentrate onPthreads, thisbook provides agood introduction tothread pro-
gramming ingeneral. Assuch, itforms asolidbasis fordeveloping multithreaded
clients andservers.
Schmidt etaI.,Pattern-Oriented Software Architecture-Patterns forConcurrent
andNetworked Objects
Researchers havealsolooked atcommon design patterns indistributed sys-
tems. These patterns caneasethedevelopment ofdistributed systems asthey
allow programmers toconcentrate more onsystem-specific issues. Inthisbook,
design patterns arediscussed forservice access, event handling, synchronization,
andconcurrency.
Smith andNair, Virtual Machines: Versatile Platforms forSystems andProcesses
These authors have alsopublished abrief overview ofvirtualization inthe
May2005 issue ofComputer, butthisbookgoesintomany ofthe(often intricate)626 READING LIST AND BffiLIOGRAPHY CHAP. 14
details ofvirtual machines. Aswehavementioned inthetext,virtual machines
arebecoming increasingly important fordistributed systems. Thisbookforms an
excellent introduction intothesubject.
Stevens andRago, Advanced Programming intheUNIX Environment
Ifthereiseveraneedtopurchase asingle volume onprogramming onUNIX
systems, thisisthebooktoconsider. Likeotherbooks written bythelateRichard
Stevens, thisvolume contains awealth ofdetailed information onhowtodevelop
servers andothertypes ofprograms. Thissecond edition hasbeenextended by
Rago, whoisalsowellknown forbooks onsimilar topics.
14.1.4Communication
Birrell andNelson, "Implementing Remote Procedure Calls"
Aclassical paper onthedesign andimplementation ofoneofthefirstremote
procedure callsystems.
Hohpe andWoolf, Enterprise Integration Patterns
Likeothermaterial ondesign patterns thisbookprovides high-level over-
views onhowtoconstruct messaging solutions. Thebookforms anexcellent read
forthose wanting todesign message-oriented solutions, andcovers awealth of
patterns thatcanbefollowed during thedesign phase.
Peterson andDavie, Computer Networks, ASystems Approach
Analternative textbook tocomputer networks which takesasomewhat simi-
larapproach asthisbookbyconsidering anumber ofprinciples andhowthey
applytonetworking.
Steinmetz andNahrstedt, Multimedia Systems
Agoodtextbook (although poorly copyedited) covering many aspects of(dis-
tributed) systems formultimedia processing, together forming afineintroduction
intothesubject.
14.1.5Naming
Albitz andLiu,DNSandBIND
BIND isapublicly available andwidely-used implementation ofaDNS
server. Inthisbook, allthedetails arediscussed onsetting upaDNS domain
usingBIND. Assuch,itprovides alotofpractical information onthelargest dis-
tributed naming service inusetoday.SEC. 14.1 SUGGESTIONS FORFURTHER READING 627
Balakrishnan etaI.,"Looking upDatainP2PSystems"
Aneasy-to-read andgoodintroduction intolookup mechanisms inpeer-to-
peersystems. Onlyafewdetails areprovided ontheactual working ofthese
mechanisms, butforming agoodstarting-point forfurther reading.
Balakrishnan etaI.,"ALayered Naming Architecture fortheInternet"
Inthispaper, theauthors argue tocombine structured naming withflatnam-
ing,thereby distinguishing threedifferent levels: (1)human-friendly names which
aretobemapped toservice identifiers, (2)theservice identifiers which aretobe
mapped toendpoint identifiers thatuniquely identify ahost,and(3)theend
points thataretobemapped tonetwork addresses. Ofcourse, forthosepartsthat
onlyidentifiers areused,onecanconveniently useaDHT-based system.
Loshin, BigBook ofLightweight Directory Access Protocol (LDAP) RFCs
LDAP-based systems arewidely usedindistributed systems. Theultimate
source forLDAP services aretheRFCs aspublished bytheJETF. Loshin hascol-
lected alltherelevant onesinasingle volume, making itthecomprehensive
source fordesigning andimplementing LDAP services.
Needham, "Names"
Aneasy-to-read andexcellent article ontheroleofnames indistributed sys-
tems. Emphasis isonnaming systems asdiscussed inSection 5.3,using DEC's
GNSasanexample.
Pitoura andSamaras, "Locating Objects inMobile Computing"
Thisarticle canbeusedasacomprehensive introduction tolocation services.
Theauthors discuss various kinds oflocation services, including those usedin
telecommunications systems. Thearticle hasanextensive listofreferences that
canbeusedasstarting pointforfurther reading.
Saltzer, "Naming andBinding Objects"
Although written in1978andfocused onnondistributed systems, thispaper
should bethestarting pointforanyresearch onnaming. Theauthor provides an
excellent treatment ontherelation between names andobjects, and,inparticular,
whatittakestoresolve anametoareferenced object. Separate attention ispaidto
theconcept ofclosure mechanisms.
14.1.6Synchronization
Guerraoui andRodrigues, Introduction toReliable Distributed Programming
Asomewhat misleading titleforabookthatlargely concentrates ondistri-
buted algorithms thatachieve reliability. Thebookhasaccompanying software
thatallows many ofthetheoretical descriptions tobetested inpractice.628 READING LIST AND BIBLIOGRAPHY CHAP. ]4
Lynch, Distributed Algorithms
Using asingle framework, thebook describes many different kinds ofdistri-
buted algorithms. Three different timing models areconsidered: simple synchro-
nousmodels, asynchronous models without anytiming assumptions, andpartially
synchronous models, which come close torealsystems. Once yougetusedtothe
theoretical notation, youwillfindthisbookcontaining many useful algorithms.
Raynal andSinghal, "Logical Time: Capturing Causality inDistributed Systems"
Thispaper describes inrelatively simple terms three types oflogical clocks:
scalar time(i.e.,Lamport timestamps), vector time, andmatrix time. Inaddition,
thepaper describes various implementations thathavebeen usedinanumber of
practical andexperimental distributed systems.
Tel,Introduction toDistributed Algorithms
Analternative introductory textbook fordistributed algorithms, which concen-
trates solely onsolutions formessage-passing systems. Although quite theoretical,
inmany cases thereader canquite easily construct solutions forrealsystems.
14.1.7Consistency andReplication
Adve andGharachorloo, "Shared Memory Consistency Models: ATutorial"
Until recently, there havebeenmany groups developing distributed systems in
which thephysically dispersed memories where joined together intoasingle vir-
tualaddress space, leading towhat areknown asdistributed shared memory sys-
tems. Various memory consistency models havebeendesigned forthese systems
andform thebasis forthemodels discussed inChap. 7.Thispaper provides an
excellent introduction intothese memory consistency models.
GrayetaI.,"The Dangers ofReplication andaSolution"
Thepaper discusses thetrade-off between replication implementing sequen-
tialconsistency models (called eager replication) andlazyreplication. Bothforms
ofreplication areformulated fortransactions. Theproblem witheager replication
isitspoor scalability, whereas lazyreplication mayeasily leadtodifficult or
impossible conflict resolutions. Theauthors propose ahybrid scheme.
Saito andShapiro, "Optimistic Replication"
Thepresents presents ataxonomy ofoptimistic replication algorithms asused
forweak consistency models. Itdescribes analternative wayoflooking atreplica-
tionanditsassociated consistency protocols. Aninteresting issue isthediscussion
onscalability ofvarious solutions. Thepaper alsoincludes alarge number ofuse-
fulreferences.SEC. 14.1 SUGGESTIONS FORFURTHER READING 629
Sivasubramanian etaI.,"Replication forWebHosting Systems"
Inthispaper, theauthors discuss themany aspects thatneedtobeaddressed
tohandle replication forWebhosting systems, including replica placement, con-
sistency protocols, androuting requests tothebestreplica. Thepaper also
includes anextensive listofrelevant material.
Wiesmann etaI.,"Understanding Replication inDatabases andDistributed Sys-
tems"
Traditionally, therehasbeenadifference between dealing withreplication in
distributed databases andingeneral-purpose distributed systems. Indatabases, the
mainreason forreplication usedtobetoimprove performance. Ingeneral-purpose
distributed, replication hasoften beendoneforimproving faulttolerance. The
papers presents aframework thatallows solutions fromthesetwoareastobemore
easily compared.
14.1.8FaultTolerance
Marcus andStern, Blueprints forHighAvailability
There aremany issues tobeconsidered whendeveloping (distributed) systems
forhighavailability. Theauthors ofthisbooktakeapragmatic approach and
touch uponmany ofthetechnical andnontechnical issues.
Birman, Reliable Distributed Systems
Written byanauthority inthefield,thisbookcontains awealth ofinformation
onthepitfalls ofdeveloping highly dependable distributed systems. Theauthor
provides many examples fromacademia andindustry toillustrate whatcango
wrong andwhatcanbedoneabout it.Thecovers awidevariety oftopics, includ-
ingclient/server computing, Webservices, object-based systems (CORBA), and
alsopeer-to-peer systems.
Cristian andFetzer, TheTimed Asynchronous Distributed System Model"
Thepaper discusses amorerealistic model fordistributed systems otherthan
thepuresynchronous orasynchronous cases. Twoimportant assumptions arethat
services arecomplete within aspecific timeinterval, andthatcommunication is
unreliable andsubject toperformance failures. Thepaper demonstrates theappli-
cability ofthismodel forcapturing important properties ofrealdistributed sys-
tems.
Guerraoui andSchiper, "Software-Based Replication forFaultTolerance"
Abriefandclearoverview onhowreplication indistributed systems canbe
applied forimproving faulttolerance. Discusses primary-backup replication as
wellasactive replication, andrelates replication togroup communication.630 READING LIST AND BIBLIOGRAPHY CHAP. 14
Jalote, Fault Tolerance inDistributed Systems
Oneofthefewtextbooks entirely directed toward fault tolerance indistri-
buted systems. Thebook covers reliable broadcasting, recovery, replication, and
process resilience. There isaseparate chapter onsoftware design faults.
14.1.9Security
Anderson, Security Engineering: AGuide toBuilding Dependable Distributed
Systems
Oneoftheveryfewbooks thatsuccessfully aimsatcovering thewhole secu-
rityarea. Thebook discusses thebasics suchaspasswords, access control, and
cryptography. Security istightly coupled toapplication domains, andsecurity in
several domains isdiscussed: themilitary, banking, medical systems, among oth-
ers.Finally, social, organizational, andpolitical aspects arediscussed aswell. A
great starting point forfurther reading andresearch.
Bishop, Computer Security: ArtandScience
Although thisbook isnotspecifically written fordistributed systems, itcon-
tains awealth ofinformation ofgeneral issues forcomputer security, including
many ofthetopics discussed inChap. 9.Furthermore, there ismaterial onsecurity
policies, assurance. evaluation, andmany implementation issues.
Blaze etal,"The RoleofTrust Management inDistributed Systems Security"
Thepaper argues thatlarge-scale distributed systems should beabletogrant
access toaresource using asimpler approach thancurrent ones. Inparticular, if
thesetofcredentials accompanying arequest isknown tocomply withalocal
security policy, therequest should begranted. Inother words, authorization
should takeplace without separating authentication andaccess control. Thepaper
explains thismodel andshows howitcanbeimplemented.
Kaufman etal.,Network Security
Thisauthoritative andfrequently witty book isthefirstplace tolookforan
introduction tonetwork security. Secret andpublic keyalgorithms andprotocols,
message hashes, authentication, Kerberos, ande-mail areallexplained atlength.
Thebestparts aretheinterauthor (andevenintra-author) discussions, labeled by
subscripts, asin:"12could notgetmeltobeveryspecific ..."
Menezes atal.,Handbook ofApplied Cryptography
Thetitlesaysitall.Thebook provides thenecessary mathematical back-
ground tounderstand themany different cryptographic solutions forencryption,
hashing, andsoon.Separate chapters aredevoted toauthentication, digital signa-
tures, keyestablishment, andkeymanagement.SEC. 14.1 SUGGESTIONS FORFURTHER READING 631
Rafaeli andHutchison, ASurvey ofKeyManagement forSecure Group Communi-
cation
Thetitlesaysitall.Theauthors discuss various schemes thatcanbeusedin
thosesystems where process groups needtocommunicate andinteract inasecure
way.Thepaper concentrates onthemeans tomanage anddistribute keys.
Schneier, Secrets andLies
Bythesameauthor asApplied Cryptography, thisbookfocuses onexplaining
security issues fornontechnical people. Animportant observation isthatsecurity
isnotjustatechnological issue. Infact,whatcanbelearned fromreading this
bookisthatperhaps mostofthesecurity-related riskshavetodowithhumans and
thewayweorganize things. Assuch, itsupplements much ofthematerial we
presented inChap. 8.
14.1.10Distributed Object-Based Systems
Emmerich, Engineering Distributed Objects
Anexcellent book devoted entirely toremote-object technology, paying
specific attention toCORBA, DCOM, andJavaRMI.Assuch,itprovides agood
basisforcomparing these threepopular object models. Inaddition, material is
presented ondesigning systems usingremote objects, handling different forms of
communication, locating objects, persistence, transactions, andsecurity.
Fleury andReverbel, "TheJBoss Extensible Server"
Many Webapplications arebased ontheJBoss J2EE object server. Inthis
paper, theoriginal developers ofthatserver outline theunderlying principles and
general design.
Henning, "TheRiseandFallofCORBA"
Written byanexpert onCORBA development (butwhohascome toother
insights), thisarticle contains strong arguments against theuseofCORBA. Most
salient isthefactthatHenning believes thatCORBA issimply toocomplex and
thatitdoesnotmakethelivesofdevelopers ofdistributed systems anyeasier.
Henning andVinoski, Advanced CORBA Programming withC++
Ifyouneedmaterial onprogramming CORBA, andinthemeantime learning
alotonwhatCORBA means inpractice, thisbookwillbeyourchoice. Written
bytwopeople involved inspecifying anddeveloping CORBA systems, thebook
isfullofpractical andtechnical details without being limited totoaspecific
CORBA implementation.632 READING LISTANDBIBLIOGRAPHY CHAP. 14
14.1.11Distributed FileSystems
Blanco etaI.,"ASurvey ofDataManagement inPeer-to-Peer Systems"
Anextensive survey, covering many important peer-to-peer systems. The
authors describe datamanagement issues including dataintegration, query pro-
cessing, anddataconsistency. Pate, UNIX Filesystems: Evolution, Design, and
Implementation '
Thisbookdescribes many ofthefilesystems thathavebeendeveloped for
UNIX systems, butalsocontains aseparate chapter ondistributed filesystems. It
givesanoverview ofthevarious NFSversions, aswellasfilesystems forserver
clusters.
Satyanarayanan, "TheEvolution ofCoda"
Codaisanimportant distributed filessystem forsupporting mobile users. In
particular, ithasadvanced features forsupporting whatareknown asdiscon-
nected operations, bywhich ausercancontinue toworkonhisownsetoffiles
without having contact withthemainservers. Thisarticle describes howthesys-
temhasevolved overtheyearsasnewrequirements surfaced.
ZhuetaI.,"Hibernator: Helping DiskArrays Sleep through theWinter"
Datacenters useanincredible number ofdiskstogettheirworkdone. Obvi-
ously, thisrequires avastamount ofenergy. Thispaper describes various tech-
niqueshow energy consumption canbebrought down by,forexample, distin-
guishing hotdatafromdatathatisnotaccessed sooften.
14.1.12Distributed Web-Based Systems
Alonso etal.,WebServices: Concepts, Architectures andApplications
Thepopularity andintricacy ofWebservices hasledtoanendless stream of
documents, toomany thatcanbecharacterized onlyasgarbage. Incontrast, thisis
oneofthose veryfewbooks thatgives acrystal-clear description ofwhatWeb
services areallabout. Highly recommended asanintroduction tothenovice, an
overview forthosewhohavereadtoomuch ofthegarbage, andanexample for
thoseproducing thegarbage.
Chappell, Understanding .NET
Theapproach thatMicrosoft hastaken tosupport thedevelopment ofWeb
services, istocombine many oftheirexisting techniques intoasingle framework,
along withadding anumber ofnewfeatures. Theresult iscalled .NET. This
approach hascaused much confusion onwhatthisframework actually is.David
Chappell doesagoodjobofexplaining matters.SEC. 14.1 SUGGESTIONS FORFURTHER READING 633
Fielding, "Principled Design oftheModem WebArchitecture"
Fromthechiefdesigner oftheApache Webserver, thispaper discusses agen-
eralapproach onhowtoorganize Webapplications suchthattheycanmake best
useofthecurrent setofprotocols.
Podling andBoszormenyi, "ASurvey ofWebCache Replacement Strategies"
Wehavebarely touched uponthework thatneeds tobedonewhen Web
caches become full.Thispaper gives anexcellent overview onthechoices that
canbemadetoevictcontent fromcaches whentheyfillup.
Rabinovich andSpatscheck, WebCaching andReplication
Anexcellent bookthatprovides anoverview aswellasmany details oncon-.
tentdistribution intheWeb.
Sebesta, Programming theWorld Wide Web
Wehavebarely touched upontheactual development ofWebapplications,
which generally involves using amyriad oftoolsandtechniques. Thisbookpro-
vides acomprehensive overview andforms agoodstarting pointfordeveloping
Websites.
14.1.13Distributed Coordination-Based Systems
Cabri etaI.,"Uncoupling Coordination: Tuple-based Models forMobility"
Theauthors giveagoodoverview ofLinda-like systems thatcanoperate in
mobile, distributed environments. Thispaper alsoshows thatthereisstillalotof
research being conducted inafieldthatwasinitiated morethan15yearsago.
Pietzuch andBacon, "Hermes: ADistrib. Event-Based Middleware Architecture"
Hermes isadistributed publish/subscribe system developed atCambridge
University, UK.Ithasbeenusedasthebasisformany experiments inlarge-scale
event-based systems, including security. Thispaper describes thebasicorganiza-
tionofHermes.
Wells etaI.,"Linda Implementations inJavaforConcurrent Systems"
Forthose interested inmodem implementations oftuplespaces inJava,this
paper provides agoodoverview. Itismoreorlessfocused oncomputing instead
ofgeneral tuple-space applications, butnevertheless demonstrates thevarious
tradeoffs thatneedtobemade whenperformance isatstake.
Zhao etaI.,"Subscription Propagation inHighly-Available Publish/Subscribe
Middleware' ,
Although afairlytechnical article, thispaper givesagoodideaofsomeofthe
issues thatplayarolewhen availability isanimportant design criterion in634 READING LIST AND BIBLIOGRAPHY CHAP. 14
publish/subscribe systems. Inparticular, theauthors consider howsubscription
updates canbepropagated when routing paths havebeenmade redundant to
achieve highavailability. Itisnothardtoimagine that,forexample, out-of-order
message delivery caneasily occur. Suchcasesneedtobedealtwith.
14.2ALPHABETICAL BIBLIOGRAPHY
ABADI, M.andNEEDHAM, R.:"Prudent Engineering Practice forCryptographic Proto-
cols." IEEE Trans. Softw. Eng., (22)1:6-15, Jan.1996. Cited onpage400.
ABDULLAm. S.andRINGWOOD, G.:"Garbage Collecting theInternet: ASurvey ofDis-
tributed Garbage Collection." ACM Comput. Surv., (30)3:330-373, Sept. 1998. Cited on
page186.
ABERER, K.andHAUSWIRTH, M.:"Peer-to-Peer Systems." InSingh, M.(ed.), The
Practical Handbook ofInternet Computing, chapter 35.Boca Raton, FL:eRC Press, 2005.
Cited onpage15.
ABERER, K.,ALIMA, L.0.,GHODSI, A.,GIRDZIJAUSKAS, S.,HAUSWIRTH, M.,and
HARIDI, S.:"The Essence ofP2P: AReference Architecture forOverlay Networks."
Proc. Fifth Int'l Con! Peer-to-Peer Comput., (Konstanz, Germany). LosAlamitos, CA:
IEEE Computer Society Press, 2005. pp.11-20. Cited onpage44.
ADAR, E.andHUBERMAN, B.A.:"Free Riding onGnutella." Hewlett Packard, Informa-
tionDynamics Lab,Jan.2000. Cited onpage53.
AIYER, A.,ALVISI, L.,CLEMENT, A.,DAHLIN, M.,andMARTIN, J.-P.: "BAR Fault
Tolerance forCooperative Services." Proc. 20thSymp. Operating System Principles;
(Brighton, UK). NewYork, NY:ACM Press, 2005. pp.45-58. Cited onpage335.
AKYILDIZ, I.F.,SU,W.,SANKARASUBRAMANIAM, Y.,andCAYIRCI, E.:"ASurvey
onSensor Networks." IEEE Commun. Mag., (40)8:102-114, Aug. 2002. Cited onpage
28.
AKYILDIZ, I~F.,WANG, X.,andWANG, W.:"Wireless Mesh Networks: ASurvey."
Compo Netw., (47)4:445-487, Mar.2005. Cited onpage28.
ALBITZ, P.andLIU,C.:DNSandBIND. Sebastopol, CA:O'Reilly &Associates, 4thed.,
2001. Cited onpages 210,560,626.
ALLEN, R.andLOWE-NORRIS, A.:Windows 2000 Active Directory. Sebastopol, CA:
O'Reilly &Associates. 2nded.,2003. Cited onpage221.
ALLMAN, M.:"AnEvaluation ofXML-RPC." Perf. Eva/. ne«,(30)4:2-11, Mar. 2003.
Cited onpage567.
ALONSO, G.,CASATI, F.,KUNO, H.,andMACmRAJU, V.:WebServices: Concepts,
Architectures andApplications. Berlin: Springer-Verlag, 2004. Cited onpages 20,551,
554,632.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 635
ALVISI, L.andMARZULLO, K.:"Message Logging: Pessimistic, Optimistic, Causal, and
Optimal." IEEE Trans. Softw. Eng., (24)2:149-159, Feb.1998. Cited onpages 370,371.
AMAR, L.,BARAK, A.,andSHILOH, A.:"The MOSIX Direct FileSystem Access
Method forSupporting Scalable Cluster FileSystems." Cluster Comput., (7)2:141-150,
Apr.2004. Cited onpage18.
ANDERSON, O.T.,LUAN, L.,EVERHART, C.,PEREIRA, M.,SARKAR, R.,andXU,J.:
"Global Namespace forFiles." IBMSyst.J.,(43)4:702-722, Apr.2004. Cited onpage
512.
ANDERSON, R.:Security Engineering -AGuideto Building Dependable Distributed Sys-
tems. NewYork: JohnWiley, 2001. Cited onpage630.
ANDERSON, T.,BERSHAD, B.,LAZOWSKA, E.,andLEVY, H.:"Scheduler Activations:
Efficient Kernel Support fortheUser-Level Management ofParallelism." Proc. 13th
Symp. Operating System Principles. NewYork, NY:ACM Press, 1991. pp.95-109. Cited
onpage75.
ANDREWS, G.:Foundations ofMultithreaded, Parallel, andDistributed Programming.
Reading, MA:Addison-Wesley, 2000. Cited onpages 232,625.
ANDROUTSELLIS-THEOTOKIS, S.andSPTh'ELLIS, D.:"ASurvey ofPeer-to-Peer Con-
tentDistribution Technologies." ACM Comput. Surv., (36)4:335-371, Dec.2004. Cited on
page44.
ARAUJO, F.andRODRIGUES, L.:"Survey onPosition-Based Routing." Technical
Report MINEMA TR-01, University ofLisbon, Oct.2005. Cited onpage261.
ARKILLS, B.:LDAP Directories Explained: AnIntroduction andAnalysis. Reading, MA:
Addison-Wesley, 2003. Cited onpage218.
ARON, M.,SANDERS, D.,DRUSCHEL, P.,andZWAENEPOEL, W.:"Scalable Content-
aware Request Distribution inCluster-based Network Servers." Proc. USENlX Ann.
Techn. Con! USENIX, 2000. pp.323-336. Cited onpage559.
ATTIYA, H.andWELCH, J.:Distributed Computing Fundamentals, Simulations, and
Advanced Topics. NewYork: JohnWiley, 2nded.,2004. Cited onpage232.
AVIZIENIS, A.,LAPRIE, J.-C., RANDELL, B.,andLANDWEHR, C.:"Basic Concepts and
Taxonomy ofDependable andSecure Computing." IEEE Trans. Depend. Secure Comput.,
(1)1:11-33, Jan.2004. Cited onpage323.
AWADALLAH, A.andROSENBLUM, M.:"The vMatrix: ANetwork ofVirtual Machine
Monitors forDynamic Content Distribution." Proc. Seventh WebCaching Workshop,
(Boulder, CO),2002. Cited onpage80.
AWADALLAH, A.andROSENBLUM, M.:"The vMatrix: Server Switching." Proc. Tenth
Workshop onFuture Trends inDistributed Computing Systems, (Suzhou, China). Los
Alamitos, CA:IEEE Computer Society Press, 2004. pp.110-118. Cited onpage94.
BABAOGLU, 0.,JELASITY, M.,MONTRESOR, A.,FETZER, C.,LEONARDI, S.,VAN
MOORSEL, A.,andVANSTEEN, M.(eds.): Self-star Properties inComplex Information
Systems, vol.3460 ofLect. Notes Compo Sc.Berlin: Springer-Verlag, 2005. Cited on
pages 59,624.636 READING LIST AND BIBLIOGRAPHY CHAP. 14
BABAOGLU. O.andTOUEG, S.:"Non-Blocking Atomic Commitment." InMullender, S.
(ed.), Distributed Systems, pp.147-168. Wokingham: Addison-Wesley, 2nded.,1993.
Cited onpage359.
BABCOCK, B.,BABU, S.,DATAR, M.,MOTWANI, R.,andWIDOM, J.:"Models and
Issues inDataStream Systems." Proc. 21stSymp. onPrinciples ofDistributed Computing,
(Monterey, CA).NewYork, NY:ACM Press, 2002. pp.1-16. Cited onpage 158.
BAL, H.:TheShared Data-Object Model asaParadigm forProgramming Distributed
Systems. Ph.D..Thesis, Vrije Universiteit, Amsterdam, 1989. Cited onpage449.
BALAKRISHNAN, H.,KAASHOEK, M.F.,KARGER, D.,MORRIS, R.,andSTOICA, I.:
"Looking upDatainP2PSystems." Commun. ACM, (46)2:43-48, Feb.2003. Cited on
pages 44,188,627.
BALAKRISHNAN, H.,LAKSHMINARA YANAN, K.,RATNASAMY, S.,SHENKER, S.,
STOIC A,I.,andWALFlSH, M.:"ALayered Naming Architecture fortheInternet." Proe.
SIGCOMM, (Portland, OR). NewYork, NY:ACM Press, 2004. pp.343-352. Cited on
page626.
BALAZINSKA, M.,BALAKRISHNAN, H.,andKARGER, D.:"INSfTwine: AScalable
Peer-to-Peer Architecture forIntentional Resource Discovery." Proc. First lnt'l Conf,
Pervasive Computing, vol.2414 ofLeet. Notes Compo Sc.,(Zurich, Switzerland). Berlin:
Springer-Verlag, 2002. pp.195-210. Cited onpages 222,223.
BALLINTUN, G.:Locating Objects inaWide-area System. Ph.D. thesis, Vrije Universi-
teitAmsterdam, 2003. Cited onpages 192,485.
BARA TTO, R.A.,NlEH, J.,andKIM, L.:"THINC: ARemote Display Architecture for
Thin-Client Computing." Proc. 20thSymp. Operating System Principles, (Brighton, UK).
NewYork, NY:ACM Press, 2005. pp.277-290. Cited onpages 85,86.
BARBORAK, M.,MALEK, M.,andDAHBURA, A.:"The Consensus Problem inFault-
Tolerant Computing." ACM Comput. Surv., (25)2:171-220, June1993. Cited-on page335.
BARHAM, P., DRAGO VIC,B., FRASER, K., HAND, S., HARRIS, T., HO,A.,
NEUGEBAR, R.,PRATT, I.,andWARFIELD, A.:"Xen andtheArtofVirtualization."
Proc. 19thSymp. Operating System Principles, (Bolton Landing, }\"'Y). New York, NY:
ACM Press, 2003. pp.164-177. Cited onpage81.
BARKER, W.:-"Recommendation fortheTriple Data Encryption Algorithm (TDEA)
Block Cipher." NIST Special Publication 800-67, May2004. Cited onpage393.
BARRON, D.:Pascal -TheLanguage anditsimplementation. New York: JohnWiley,
1981. Cited onpage110.
BARROSO, L.,DEAM, J.,andHOLZE, U.:"Web Search foraPlanet: TheGoogle Cluster
Architecture." IEEE Micro, (23)2:21-28, Mar.2003. Cited onpage497.
BARYSHNIKOV, Y.,COFFMAN, E.G.,PIERRE, G.,RUBENSTEIN, D.,SQUILLAN-
TE,M.,andYIMWADSANA, T.:"Predictability ofWeb-Server Traffic Congestion." Proc.
Tenth WebCaching Workshop, (Sophia Antipolis, France). IEEE, 2005. pp.97-103. Cited
onpage576.SEC. 14.2 ALPHABETICAL BmLIOGRAPHY 637
BASILE, C.,KALBARCZYK, Z.,andIYER, R.K.:"APreemptive Deterministic Schedul-
ingAlgorithm forMultithreaded Replicas." Proc. Int'lCon! Dependable Systems and
Networks, (SanFrancisco, CA).LosAlamitos, CA:IEEE Computer Society Press, 2003.
pp.149-158. Cited onpage474.
BASILE, c,WHISNANT, K.,KALBARCZYK, Z.,andIYER, R.K.:"Loose Synchroniza-
tionofMultithreaded Replicas." Proc. 21stSymp. onReliable Distributed Systems,
(Osaka, Japan). LosAlamitos, CA:IEEE Computer Society Press, 2002. pp.250-255.
Cited onpage474.
BASS, L.,CLEMENTS, P.,andKAZMAN, R.:Software Architecture inPractice. Reading,
MA:Addison-Wesley, 2nd-ed., 2003. Cited onpages 34,35,36,624.
BAVIER, A., BOWMAN, M., CHUN, B., CULLER, D., KARLIN, S.,J.\<IUIR, S.,
PETERSON, L.,ROSCOE, T.,SPALINK, T.,andWAWRZONIAK, M.:"Operating System
Support forPlanetary-Scale Network Services." Proc. First Symp. Networked Systems
Design andImpl., (SanFrancisco, CA). Berkeley, CA:USENIX, 2004. pp.245-266.
Cited onpages 99,102.
BERNERS-LEE, T.,CAILLIAU, R.,NIELSON, H.F.,andSECRET, A.:"The World-Wide
Web." Commun. ACM, (37)8:76-82, Aug. 1994. Cited onpage545.
BERJ.'ffiRS-LEE, T.,FIELDING, R.,andMASINTER, L.:"Uniform Resource Identifiers
(URI): Generic Syntax." RFC3986, Jan.2005. Cited onpage567.
BERt"JSTEIN, P.:"Middleware: AModel forDistributed System Services." Commun.
ACM, (39)2:87-98, Feb.1996. Cited onpage20.
BERJ."JSTEIN, P.,HADZILACOS, V.,andGOODMAN, N.:Concurrency Control and
Recovery inDatabase Systems. Reading, MA: Addison-Wesley, 1987. Cited onpages
355,363.
BERSHAD, B.,ZEKAUSKAS, M.,andSAWDON, W.:"The Midway Distributed Shared
Memory System." Proc. COMPCON. IEEE, 1993. pp.528-537. Cited onpage286.
BERTINO, E.andFERRARI, E.:"Secure andSelective Dissemination ofXML Docu-
ments." ACM Trans. In!Syst.Sec.,(5)3:290-331, 2002. Cited onpage618.
BHAGWAN, R.,TATI, K.,CHENG, Y.,SAVAGE, S.,andVOELKER, G.M.:"Total Recall:
Systems Support forAutomated Availability Management." Proc. FirstSymp. Networked
Systems Design andImpl., (SanFrancisco, CA). Berkeley, CA:USENIX, 2004. pp.337-
350.Cited onpage532.
BHARAMBE, A.R.,AGRAWAL, M.,andSESHAN, S.:"Mercury: Supporting Scalable
Multi-Attribute Range Queries." Proc. SIGCOMM, (Portland, OR).NewYork, NY:ACM
Press, 2004. pp.353-366. Cited onpages 225,599.
BIRMAN, K.:Reliable Distributed Systems: Technologies, WebServices, andApplica-
tions. Berlin: Springer-Verlag, 2005. Cited onpages 90,335,582,629.
BIRMAN, K.:"AResponse toCheriton andSkeen's Criticism ofCausal andTotally
Ordered Communication." Oper. Syst.Rev.,(28)1:11-21, Jan.1994. Cited onpage251.
BIRMAN, K.andJOSEPH, T.:"Reliable Communication inthePresence ofFailures."
ACM Trans. Compo Syst., (5)1:47-76, Feb.1987. Cited onpage350.638 READING LIST AND BIBLIOGRAPHY CHAP. 14
BIRMAN~ K.~SCHIPER, A.,andSTEPHENSON, P.:"Lightweight Causal andAtomic
Group Multicast." ACM Trans. Compo Syst., (9)3:272-314, Aug.1991. Cited onpage353.
BIRMAN, K.andVANRENESSE~ R.(eds.): Reliable Distributed Computing withtheIsis
Toolkit. LosAlamitos, CA:IEEE Computer Society Press, 1994. Cited onpage251.
BIRRELL, A.andNELSON, B.:"Implementing Remote Procedure Calls." ACM Trans.
Compo Syst., (2)1:39-59, Feb.1984. Cited onpages 126,626.
BISHOP~ M.:Computer Security: ArtandScience. Reading, MA:Addison-Wesley, 2003.
Cited onpages 385,630.
BJORNSON, R.:Linda onDistributed Memory Multicomputers. Ph.D. Thesis, Yale
University, Department ofComputer Science, 1993. Cited onpage608.
BLACK~ A.andARTSY, Y.:"Implementing Location Independent Invocation." IEEE
Trans. Par.Distr. Syst., (J)1:107-119,Jan.1990. Cited onpage186.
BLAIR, G.,COULSON, G.,and GRACE, P.:"Research Directions inReflective
Middleware: theLancaster Experience." Proc. Third Workshop Reflective &Adaptive
Middleware, (Toronto, Canada). NewYork, NY:ACM Press, 2004. pp.262-267. Cited on
page58.
BLAIR, G.andSTEFANI, J.-B.: Open Distributed Processing andMultimedia. Reading,
MA:Addison-Wesley, 1998. Cited onpages 8,165.
BLAKE-WILSON, S.,NYSTROM~ M.,HOPWOOD, D.~MIKKELSEN~ J.~andWRIGHT, T.:
"Transport Layer Security (TLS) Extensions." RFC3546, June2003. Cited onpage584.
BLANCO~ R.~AHMED~ 1'\.,HADALLER~ D.,SUNG, L.G.A.~LI,H.~andSOLIMAN~ M.A.:
"ASurvey ofDataManagement inPeer-to-Peer Systems." Technical Report CS-2006-18,
University ofWaterloo, Canada. June2006. Cited onpage632.
BLAZE~ M.~FEIGENBACM, J.,IOANNIDIS, J.~andKEROMYTIS~ A.:"The RoleofTrust
Management inDistributed Systems Security." InVitek, J.andJensen. C.(eds.), Secure
Internet Programming: Security Issues forMobile andDistributed Objects, vol.1603of
Lect.Notes Compo Sc.,pp.185-210. Berlin: Springer-Verlag, 1999. Cited onpage630.
BLAZE, M.:Caching inLarge-Scale Distributed FileSystems. Ph.D. thesis, Department
ofComputer Science, Princeton University, Jan.1993. Cited onpage301.
BONNET, P.,GEHRKE, J.,andSESHADRI, P.:"Towards Sensor Database Systems."
Proc. Second1nt'l Con! Mobile Data Mgt., vol.1987ofLect. Notes Compo Sc.,(Hong
Kong, China). Berlin: Springer-Verlag, 2002. pp.3-14. Cited onpage29.
BOOTH, D.~HAAS~ H.,MCCABE, F:,NEWCOMER, E.,CHAMPION, M..FERRIS, C.,and
ORCHARD, D.:"Web Services Architecture." W3C Working Group ~ote, Feb.2004.
Cited onpage551.
BOUCHENAK, S., BOYER, F., HAGIMONT, D., KRAKOWIAK, S., MOS, A.,
DEPALMA3, N.~QUEMA3~ V.,andSTEFANI, J.-B.: "Architecture-Based Autonomous
Repair Management: AnApplication toJ2EE Clusters." Proc. 24thSymp. onReliable
Distributed Systems, (Orlando. FL). LosAlamitos, CA:IEEE Computer Society Press,
2005. pp.13-24. Cited onpage65.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 639
BREWER. E.:"Lessons fromGiant-Scale Services." IEEE Internet Comput., (5)4:46-55,
July2001. Cited onpage98.
BRUNETON, E.,COUPAYE, T.,LECLERCQ, M.,QUEMA, V.,andSTEFANI, J.-B.: "An
Open Component Model andItsSupport inJava." Proe. Seventh Int'lSymp. Component-
based Softw. Eng., vol.3054 ofLeet. Notes Compo Se.,(Edinburgh, UK). Berlin:
Springer- Verlag, 2004. pp.7-22. Cited onpage65.
BUDHUARA, N.,MARZULLO, K.,SCHNEIDER, F.,andTOUEG, S.:"The Primary-
Backup Approach." InMullender, S.(ed.), Distributed Systems, pp.199-216. Wokingham:
Addison-Wesley, 2nded.,1993. Cited onpage308.
BUDHIRAJA, N.andMARZULLO, K.:"Tradeoffs inImplementing Primary-Backup Pro-
tocols." Technical Report TR92-1307, Department ofComputer Science, Cornell Univer-
sity,1992. Cited onpage309.
BURNS, R.C.,REES, R.M.,STOCKMEYER, L.J.,andLONG, D.D.E.:"Scalable Session
Locking foraDistributed FileSystem." Cluster Computing, (4)4:295-306, Oct.2001.
Cited onpage518.
BUSI, N.,MONTRESOR, A.,andZAVATTARO, G.:"Data-driven Coordination inPeer-
to-Peer Information Systems." Int'l J.Coop. Inf.Syst., (13)1:63-89, Mar.2004. Cited on
page597.
BUTT, A.R.,JOHNSON, T.A.,ZHENG, Y.,andHU,Y.c,"Kosha: APeer-to-Peer
Enhancement fortheNetwork FileSystem." Proc. Int'l Conf. Supercomputing, (Washing-
ton,DC). LosAlamitos, CA:IEEE Computer Society Press, 2004. pp.51-61. Cited on
page500.
CABRI, G.,FERRARI, L.,LEONARDI, L.,MA1.\fEI, M.,andZAMBONELLI, F.:"Uncou-
pling Coordination: Tuple-based Models forMobility." InBellavista, Paolo andCorradi,
Antonio (eds.), TheHandbook ofMobile Middleware. London, UK:CRC Press, 2006.
Cited onpage633.
CABRI, G.,LEONARDI, L.,andZAMBONELLI, F.:"Mobile-Agent Coordination Models
forInternet Applications." IEEE Computer, (33)2:82-89, Feb.2000. Cited onpage590.
CAl,M.,CHERVENAK, A.,andFRANK, M.:"APeer-to-Peer Replica Location Service
Based onADistributed Hash Table." Proc. High Perf. Comput., Netw., &Storage Conf.,
(Pittsburgh, PA).NewYork, NY:ACM Press, 2004. pp.56-67. Cited onpage529.
CALLAGHAN, B.:NFSIllustrated. Reading, MA:Addison-Wesley, 2000. Cited onpages
492,510.
CANDEA, G.,BROWN, A.B.,FOX, A.,andPATTERSON, D.:"Recovery-Oriented Com-
puting: Building Multitier Dependability." IEEE Computer, (37)11:60-67, Nov. 2004a.
Cited onpage372.
CANDEA, G.,KAWAMOTO, S.,FUJIKI, Y.,FRIEDMAN, G.,andFOX. A.:"Microreboot:
ATechnique forCheap Recovery." Proc. Sixth Symp. onOperating System Design and
Implementation, (SanFrancisco, CA). Berkeley, CA:USENIX, 2004b. pp.31-44. Cited
onpage372.640 READING LIST AND BIBLIOGRAPHY CHAP. 14
CANDEA, G.,KICIMAN, E.,KAWAMOTO, S.,andFOX, A.:"Autonomous Recovery in
Componentized Internet Applications." Cluster Comput., (9)2:175-190, Feb.2006. Cited
onpage372.
CANTIN, J.•LIPASTI, M.,andSMITH, J.:"The Complexity ofVerifying Memory Coher-
enceandConsistency." IEEE Trans. Par.Distr. Syst., (16)7:663-671, July2005. Cited on
page288.
CAO, L.andOSZU, T.:"Evaluation ofStrong Consistency WebCaching Techniques."
World Wide Web,(5)2:95-123, June2002. Cited onpage573.
CAO. P.andL1U,c,"Maintaining Strong Cache Consistency intheWorld Wide Web."
IEEE Trans. Comp., (47)4:445-457, Apr.1998. Cited onpage573.
CAPORUSCIO, M.,CARZANIGA, A.,andWOLF, A.L.:"Design andEvaluation ofaSup-
port Service forMobile, Wireless Publish/Subscribe Applications." IEEE Trans.
Softw. Eng., (29)12:1059-1071, Dec.2003. Cited onpage600.
CARDELLINI, v.•CASALICCmO, E.,COLAJANNI, M.,andYU,P.:"The State oftheArt
inLocally Distributed Web-Server Systems." ACM Comput. Surv., (34)2:263-311, June
2002. Cited onpage560.
CARRIERO, N.andGELERNTER, D.:"The SlNet's Linda Kernel." ACM Trans.
Compo Syst., (32)2:110-129, May1986. Cited onpage609.
CARZANIGA, A.,RUTHERFORD, M.J.,andWOLF, A.L.:"ARouting Scheme for
Content-Based Networking." Proc. 23rd INFOCOM Conf, (Hong Kong, China). Los
Alamitos, CA:IEEE Computer Society Press, 2004. Cited onpage601.
CARZANIGA, A.andWOLF, A.L.:"Forwarding inaContent-based Network." Proc.
SIGCOMM, (Karlsruhe, Germany). NewYork, NY:ACM Press, 2003. pp.163-174. Cited
onpage603.
CASTRO, M.,DRUSCHEL, P.,GANESH, A.,ROWSTRON, A.,andWALLACH, D.S.:
"Secure Routing forStructured Peer-to-Peer Overlay Networks." Proc. Fifth Symp. on
Operating System Design andImplementation, (Boston, MA). New York, NY:ACM
Press, 2002a. pp.299-314. Cited onpages 539,540.
CASTRO, M.,DRUSCHEL, P.,BU,Y.C.,andROWSTRON, A.:"Topology-aware Routing
inStructured Peer-to-Peer Overlay Networks." Technical Report MSR-TR-2002-82,
Microsoft Research, Cambridge, UK,June2002b. Cited onpage190. .
CASTRO, M.,RODRIGUES, R.,andLISKOV, B.:"BASE: Using Abstraction toImprove
Fault Tolerance." ACM Trans. Compo Syst., (21)3:236-269, Aug. 2003. Cited onpage
531.
CASTRO, M.,COSTA, M.,andROWSTRON, A.:"Debunking Some Myths about Struc-
tured andUnstructured Overlays." Proc. Second Symp. Networked Systems Design and
Imp!., (Boston, MA). Berkeley, CA:USENIX, 2005. Cited onpage49.
CASTRO, M.,DRUSCHEL, P.,KERM.4.RREC, A.-M., andROWSTRON, A.:"Scribe: A
Large-Scale andDecentralized Application-Level Multicast Infrastructure." IEEE
J.Selected Areas Commun., (20)8: 100-110, Oct.2002. Cited onpage167.
CASTRO, M.andLISKOV, B.:"Practical Byzantine Fault Tolerance andProactive
Recovery." ACM Trans. Compo Syst., (20)4:398-461, Nov.2002. Cited onpages 529,531,
583.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 641
CHAPPELL, D.:Understanding .NET. Reading, MA: Addison-Wesley, 2002. Cited on
page632.
CHERITON, D.andMANN, T.:"Decentralizing aGlobal Naming Service forImproved
Performance andFault Tolerance." ACM Trans. Compo Syst., (7)2:147-183, May 1989.
Cited onpage203.
CHERITON, D.andSKEEN, D.:"Understanding theLimitations ofCausally andTotally
Ordered Communication." Proc. 14thSymp. Operating System Principles. ACM, 1993.
pp.44-57. Cited onpage251.
CHERVENAK, A.,SCHULER, R.,KESSELMAN, C.,KOR..\.NDA, S.,andMOE, B.:"Wide
AreaDataReplication forScientific Collaborations." Proc. Sixth Int'lWorkshop onGrid
Computing, (Seattle, WA). NewYork, NY:ACM Press, 2005. Cited onpage529.
CHERVENAK, A.,FOSTER, I.,KESSELMAN, C.,SALISBURY, C.,andTUECKE, S.:"The
Data Grid: Towards anArchitecture fortheDistributed Management andAnalysis of
Large Scientific Datasets." J.Netw. Compo App., (23)3:187-200, July2000. Cited onpage
380.
CHESWICK, W.andBELLOVIN, S.:Firewalls andInternet Security. Reading, MA:
Addison-Wesley, 2nded.,2000. Cited onpage418.
CHOW, R.andJOHNSON, T.:Distributed Operating Systems andAlgorithms. Reading,
MA:Addison-Wesley, 1997. Cited onpages 363,366.
CHUN, B.andSPALINK, T.:"Slice Creation andManagement." Technical Report PDN-
03.,.013, PlanetLab Consortium, July2003. Cited onpage101.
CIANCARINI, P.,TOLKSDORF, R.,VITALI, F.,andKNOCHE, A.:"Coordinating Multi-
agent Applications ontheWWW: AReference Architecture." IEEE Trans. Softw. Eng.,
(24)5:362-375, May1998. Cited onpage610.
CLARK, c.,FRASER, K.,HAND, S.,HANSEN, J.G.,JUL,E.,LIMPACH, C.,PRATT, I.,
andWARFIELD, A.:"Live Migration ofVirtual Machines." Proc. Second Symp.
Networked Systems Design andImpl., (Boston, MA). Berkeley, CA:USENIX, 2005.
Cited onpage 111.
CLARK, D.:"The Design Philosophy oftheDARPA Internet Protocols." Proc.
SIGCOMM, (Austin, TX).NewYork, NY:ACM Press, 1989. pp.106-114. Cited onpage
91.
CLEMENT, L.,HATELY, A.,VONRIEGEN, c.,andROGERS, T.:"Universal Description.
Discovery andIntegration (UDDI)." Technical Report, OASIS UDDI, 2004. Cited on
page222.
COHEN, B.:"Incentives Build Robustness inBittorrent." Proc. First Workshop all
Economics ofPeer-to-Peer Systems, (Berkeley, CA),2003. Cited onpage53.
COHEN, D.:"OnHoly Wars andaPleaforPeace." IEEE Computer, (14)10:48-54, Oct.
1981. Cited onpage131.
COHEN, E.andSHENKER, S.:"Replication Strategies inUnstructured Peer-to-Peer Net-
works." Proc. SIGCOMM, (Pittsburgh, PA).NewYork, NY:ACM Press, 2002. pp.177-
190.Cited onpage526.642 READING LIST AND BIBLIOGRAPHY CHAP. 14
COMER, D.:lnternetworking withTCPIIP, Volume I:Principles, Protocols, andArchitec-
ture. Upper Saddle River, NJ:Prentice Hall,5thed.,2006. Cited onpage 121.
CONTI, M.,GREGORI, E.,andLAPENNA, W.:"Content Delivery Policies inRep1i-
catedWeb Services: Client-Side vs.Server-Side." Cluster Comput., (8)47-60, Jan.2005.
Cited onpage579.
COPPERSMITH, D.:"The Data Encryption Standard (DES) anditsStrength Against
Attacks." IBMJ.Research andDevelopment, (38)3:243-250, May 1994. Cited onpage
394.
COULOURIS, G.,DOLLIMORE, J.,andKINDBERG, T.:Distributed Systems, Concepts
andDesign. Reading, MA:Addison-Wesley, 4thed.,2005. Cited onpage623.
COX, L.andNOBLE, B.:"Samsara: Honor Among Thieves inPeer-to-Peer Storage."
Proc. 19thSymp. Operating System Principles, (Bolton Landing, NY). New York, NY:
ACM Press, 2003. pp.120-131. Cited onpage540.
COYLER, A.,BLAIR, G.,andRASHID, A.:"Managing Complexity InMiddleware." Proc.
Second AOSD Workshop onAspects, Components, andPatterns forInfrastructure
Software, 2003. Cited onpage58.
CRESPO, A.andGARCIA-MOILINA, H.:"Semantic Overlay Networks forP2PSys-
terns." Technical Report, Stanford University, Department ofComputer Science, 2003.
Cited onpage225.
CRISTIAN, F.:"Probabilistic Clock Synchronization." Distributed Computing, (3)146-
158,1989. Cited onpage240.
CRISTIAN, F.:"Understanding Fault-Tolerant Distributed Systems." Commun. ACM,
(34)2:56-78, Feb.1991. Cited onpage324.
CRISTIAN, F.andFETZER, C.:"The Timed Asynchronous Distributed System Model."
IEEE Trans. Par.Distr. Syst.,(10)6:642-657, June1999. Cited onpage629.
CROWLEY, C.:Operating Systems, ADesign-Oriented Approach. Chicago: Irwin, 1997.
Cited onpage 197.
DABEK, F.,COX, R.,KAASHOEK, F.,andMORRIS, R.:"Vivaldi: ADecentralized Net-
work Coordinate System." Proc. SIGCOMM, (Portland, OR). New York, NY:ACM
Press, 2004a. Cited onpage263. .
DABEK, F.,KAASHOEK, M.F.,KARGER, D.,MORRIS, R.,andSTOICA. I.:"Wide-area
Cooperative Storage withCFS." Proc. 18thSymp. Operating System Principles. ACM,
2001. Cited onpage499.
DABEK, F.,LI,J.,SIT,E.,ROBERTSON, J.,KAASHOEK, M.F.,and MORRIS, R.:
"Designing adhtforlowlatency andhighthroughput." Proc. FirstSymp. Networked Sys-
temsDesign andImpl., (SanFrancisco, CA). Berkeley, CA:USENIX, 2004b. pp.85-98.
Cited onpage191.
DAIGLE, L.,VAN GULIK, D.,IANNELLA, R.,andFALTSTROM, P.:"Uniform Resource
Names (URN) Namespace Definition Mechanisms." RFC3406, Oct.2002. Cited onpage
568.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 643
DAVIE,B.,CHARNY, A.,BENNET, J.,BENSON, K.,BOUDEC, J.L.,COURTNEY, W.,
S.DAVARI, FIROIU, V.,andSTll..IADIS, D.:"AnExpedited Forwarding PHB (Per-Hop
Behavior)." RFC3246, Mar.2002. Cited onpage161.
DAY,J.andZIMMERMAN, H.:"The OSIReference Model." Proceedings oftheIEEE,
(71)12:1334-1340, Dec.1983. Cited onpage117.
DEERING, S.,ESTRIN, D.•FARINACCI, D.,JACOBSON, V.,LIU,C.-G., andWEI,L.:
"The PIM Architecture forWide-Area Multicast Routing." IEEE/ACM Trans. Netw.,
(4)2:153-162, Apr.1996. Cited onpage183.
DEERING, S.andCHERITON, D.:"Multicast Routing inDatagram Internetworks and
Extended LANs." ACM Trans. Compo Syst., (8)2:85-110, May1990. Cited onpage183.
DEMERS, A.,GEHRKE, J.,HONG, M.,RIEDEW ALD, M.,andWHITE; W.:"Towards
Expressive Publish/Subscribe Systems." Proc. Tenth Int'l Conf. onExtended Database
Technology, (Munich, Germany), 2006. Cited onpage607.
DEMERS, A.,GREENE, D.,HAUSER, C.,IRISH, W., LARSON, J.,SHENKER, S.,
STURGIS, H.,SWINEHART, D.,andTERRY, D.:"Epidemic Algorithms forReplicated
Database Maintenance." Proc. SixthSymp. onPrinciples ofDistributed Computing, (Van-
couver). ACM, 1987. pp.1-12. Cited onpages 170,172.
DEUTSCH, P.,SCHOULTZ, R.,FALTSTROM, P.,andWEIDER, C.:"Architecture ofthe
WHOIS++ Service." RFC1835, Aug. 1995. Cited onpage63.
D\'FAGO, X.,SHIPER, A.,andURBrA}N, P.:"Total Order Broadcast andMulticast Algo-
rithms: Taxonomy andSurvey." ACM Comput. Surv., (36)4:372-421, Dec.2004. Cited on
page344.
DIAO, Y.,HELLERSTEIN, J.,PAREKH, S.,GRIFFITH, R.,KAISER, G.,andPHUNG, D.:
"AControl Theory Foundation forSelf-Managing Computing Systems." IEEE J.Selected
Areas Commun., (23)12:2213-2222, Dec.2005. Cited onpage60.
DIERKS, T.andALLEN, C.:"The Transport Layer Security Protocol." RFC2246, Jan.
1996. Cited onpage584.
DIFFIE, W.andHELLMA~, M.:"New Directions inCryptography." IEEE Trans. Infor-
mation Theory, (IT-22)6:644-654, Nov. 1976. Cited onpage429.
DILLEY, J.,MAGGS, B.,PARIKH, J.,PROKOP, H.,SITARAMAN, R.,andWEIHL, B.:
"Globally Distributed Content Delivery." IEEE Internet Comput., (6)5:50-58, Sept. 2002.
Cited onpage577.
DIOT, C.,LEVINE, B.,LYLES, B.,KASSEM, H.,andBALENSIEFEN, D.:"Deployment
Issues fortheIPMulticast Service andArchitecture." IEEE Network, (14)1:78-88, Jan.
2000. Cited onpage166.
DOORN, J.H.andRIVERO, L.C.(eds.): Database Integrity: Challenges andSolutions.
Hershey, PA:IdeaGroup, 2002. Cited onpage384.
DOUCEUR, J.R.:"The Sybil Attack." Proc. First Int'lWorkshop onPeer-to-Peer Sys-
tems, vol.2429 ofLect. Notes Compo Sc.Berlin: Springer-Verlag, 2002. pp.251-260.
Cited onpage539.644 READING LIST AND BIBLIOGRAPHY CHAP. 14
DUBOIS, M.,SCHEURICH, C.,andBRIGGS, F.:"Synchronization, Coherence, andEvent
Ordering inMultiprocessors." IEEE Computer, (21)2:9~21, Feb.1988. Cited onpage283.
DUNAGAN, J.,HARVEY, N.J.A.,JONES, M.B.,KOSTIC, D.,THEII\IER. M.,and
WOLMAN, A.:"FUSE: Lightweight Guaranteed Distributed Failure Notification." Proc.
Sixth Symp. onOperating System Design andImplementation, (San Francisco, CA).
Berkeley, CA:USENIX, 2004. Cited onpage336.
DUVVURI, V.,SHENOY, P.,andTEWARI, R.:"Adaptive Leases: AStrong Consistency
Mechanism fortheWorld Wide Web:' IEEE Trans. Know. Data Eng., (15)5:1~66-1276,
Sept.2003. Cited onpage304.
EDDON, G.andEDDON, H.:Inside Distributed COM. Redmond, WA:Microsoft Press,
1998. Cited onpage 136.
EISLER, M.:"LIPKEY -ALowInfrastructure Public KeyMechanism Using SPKM."
RFC2847, June2000. Cited onpage534.
EISLER, M.,CHIU, A.,andLING, 1...:"RPCSEC_GSS Protocol Specification." RFC
2203, Sept. 1997. Cited onpage534.
ELNOZAHY, E.N.andPLANK, J.S.:"Checkpointing forPeta-Scale Systems: ALook
intotheFuture ofPractical Rollback-Recovery." IEEE Trans. Depend. Secure Comput.,
(1)2:97-108, Apr.2004. Cited onpage368.
ELNOZAHY, E.,ALVIS I,L.,WANG, Y.-M., andJOHNSON, D.:"ASurvey ofRollback-
Recovery Protocols inMessage-Passing Systems." ACM Comput. Surv., (34)3:375-408,
Sept.2002. Cited onpages 366,372.
ELSON, J.,GIROD, 1...,andESTRIN, D.:"Fine-Grained Network Time Synchronization
using Reference Broadcasts." Proc. Fifth Symp. onOperating System Design andImple-
mentation, (Boston, MAJ. NewYork, NY:ACM Press, 2002. pp.147-163. Cited onpage
242.
EMMERICH, W.:Engineering Distributed Objects. NewYork: JohnWiley, 2000. Cited
onpage631.
EUGSTER, P.,FELBER. P.,GUERRAOUI, R.,andKERl\lARREC, A.-M.: "The Many
Faces ofPublish/Subscribe." ACM Comput. Surv., (35)2:114-131, June2003. Cited on
pages 35,59L
EUGSTER, P.,GUERRAOUI, R.,KERMARREC, A.-M., and~IASSOULI'E, 1...:"Epidemic
Information Dissemination inDistributed Systems." IEEE Computer, (37)5:60-67, May
2004. Cited onpage170.
FARMER, W.M.,GUTTMAN, J.D.,andSWARUP, Y.:"Security forMobile Agents:
Issues andRequirements:' Proc. 19thNational Information S....•.stems Security Conf., 1996.
pp.591-597. Cited onpage421.
FELBER, P.andNARASIMHAN, P.:"Experiences, Strategies, andChallenges inBuilding
Fault-Tolerant CORBA Systems." IEEE Computer, (53)5:497-511, May2004. Cited on
page479.
FERGUSON, N.andSCHNEIER, B.:Practical Cryptography. New York: John Wiley.
2003. Cited onpages 391.400.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 645
FIELDING, R.,GETTYS, J.,MOGUL, J.,FRYSTYK, H.,MASINTER. L.,LEACH, P.,and
BERNERS-LEE, T.:"Hypertext Transfer Protocol -HTTP/1.1." RFC 2616, June 1999.
Cited onpages 122,560.
FIELDING, R.T.andTAYLOR, R.N.:"Principled Design oftheModem WebArchitec-
ture." ACM Trans. Internet Techn., (2)2:115-150, 2002. Cited onpage633.
FILMAN, R.E.,ELRAD, T.,CLARKE, S.,andAKSIT, M.(eds.): Aspect-Oriented Software
Development. Reading, MA:Addison-Wesley, 2005. Cited onpage57.
FISCHER, M.,LYNCH, N.,andPATTERSON, M.:"Impossibility ofDistributed Con-
sensus withoneFaulty Processor:' J.ACM, (32)2:374-382, Apr.1985. Cited onpage334.
FLEURY, M.andREVERBEL, F.:"The JBoss Extensible Server." Proc. Middleware
2003, vol.2672 ofLect. Notes Compo Sc.,(RiodeJaneiro, Brazil). Berlin: Springer-
Verlag, 2003. pp.344-373.Cited onpage631.
FLOYD, S.,JACOBSON, V.,MCCANNE, S.,LID,C.-G., andZHANG, L.:"AReliable Mul-
ticast Framework forLight-weight Sessions andApplication Level Framing." IEEE/ACM
Trans. Netw., (5)6:784-803, Dec.1997. Cited onpages 345,346.
FOSTER, I.andKESSELMAN, C.:TheGrid2:Blueprintfor aNewComputing Infrastruc-
ture. SanMateo, CA:Morgan Kaufman, 2nded.,2003. Cited onpages 380,623.
FOSTER, I.,KESSELMAN, C.,TSUDIK, G.,andTUECKE, S.:"ASecurity Architecture
forComputational Grids." Proc. Fifth Con! Computer andCommunications Security.
ACM, 1998. pp.83-92. Cited onpages 380,382,383.
FOSTER, I.,KESSELMAN, C.,andTUECKE, S.:"The Anatomy oftheGrid, Enabling
Scalable Virtual Organizations." Journal ofSupercomputer Applications, (15)3:200-222,
Fall2001. Cited onpage19.
FOSTER, I.,KISHIMOTO, H.,andSAVVA,A.:"The Open Grid Services Architecture,
Version 1.0."GGFInformational Document GFD-I.030, Jan.2005. Cited onpage20.
FOWLER, R.:Decentralized Object Finding Using Forwarding Addresses. Ph.D. Thesis,
University ofWashington, Seattle, 1985. Cited onpage184.
FRANKLIN, M.J.,CAREY, M.J.,andLIVNY, M.:"Transactional Client-Server Cache
Consistency: Alternatives andPerformance." ACM Trans. Database Syst., (22)3:315-363,
Sept. 1997. Cited onpages 313,314.
FREEMAN, E.,HUPFER, S.,andARNOLD, K.:JavaSpaces, Principles, Patterns and
Practice. Reading, MA:Addison-Wesley, 1999. Cited onpage593.
FREUND, R.:"Web Services Coordination, Version 1.0,Feb.2005. Cited onpage553.
FRIEDMAN, R.andKAMA, A.:"Transparent Fault-Tolerant Java Virtual Machine."
Proc. 22nd Symp. onReliable Distributed Systems, (Florence, Italy). IEEE Computer
Society Press: IEEE Computer Society Press, 2003. pp.319-328. Cited onpages 480,
481.
FUGGETTA, A.,PICCO, G.P.,andVIGNA, G.:"Understanding Code Mobility." IEEE
Trans. Softw. Eng., (24)5:342-361, May1998. Cited onpage105.
GAMMA, E.,HELM, R.,JOHNSON, R.,andVLISSIDES, J.:Design Patterns, Elements of
Reusable Object-Oriented Software. Reading, MA: Addison-Wesley, 1994. Cited on
pages 418,446.646 READING LIST AND BIBLIOGRAPHY CHAP. 14
GARBACKI, P.,EPEMA, D••andVANSTEEN, M.:"ATwo-Level Semantic Caching
Scheme forSuper-Peer Networks." Proc. Tenth WebCaching Workshop, (Sophia Antipo-
lis,France). IEEE, 2005. Cited onpage51.
GARCIA-MOLINA, H.:"Elections inaDistributed Computing System." IEEE Trans.
Comp., (31)1:48-59, Jan.1982. Cited onpage264.
GARMAN, J.:Kerberos: TheDefinitive Guide. Sebastopol, CA:O'Reilly &Associates,
2003. Cited onpages 411,442. '
GELERNTER, D.:"Generative Communication inLinda." ACM Trans. Prog, Lang. Syst., -
(7)1:80-112, 1985. Cited onpage591.
GELERNTER, D.andCARRIERO, N.:"Coordination Languages andtheirSignificance."
Commun. ACM, (35)2:96-107, Feb.1992. Cited onpage590.
GHEMA WAT,S.,GOBI OFF,H.,andLEUNG, S.-T.:"The Google FileSystem." Proc.
]9thSymp. Operating System Principles, (Bolton Landing, NY). New York, NY:ACM
Press, 2003. pp.29-43. Cited onpage497.
GIFFORD, D.:"Weighted Voting forReplicated Data." Proc. Seventh Symp. Operating
System Principles. ACM, 1979. pp.150-162. Cited onpage311.
GIGASPACES: GigaSpaces Cache 5.0Documentation. NewYork. NY,2005. Cited on
page611.
GIL,T.M.andPOLETTO, M.:"'MULTOPS: aData-Structure forBandwidth Attack
Detection." Proc. Tenth USENIX Security Symp., (Washington, DC). Berkeley, CA:
USENIX, 2001. pp.23-38. Cited onpage427.
GLADNEY, H.:"Access Control forLarge Collections." ACM Trans. In!Syst.,
(15)2:154-194, Apr.1997. Cited onpage418.
GOLAND, Y.,WHITEHEAD, E.,FAIZI, A.,CARTER. S.,andJENSEN, D.:"HTTP Exten-
sionsforDistributed Authoring -WEBDAV." RFC2518, Feb.1999. Cited onpage569.
GOLLMANN, D.:Computer Security. NewYork: JohnWiley, 2nded.,2006. Cited on
page384.
GONG, L.andSCHEMERS, R.:"Implementing Protection Domains intheJavaDevelop-
ment Kit1.2." Proc. Svmp. Network andDistributed System Security. Internet Society,
1998. pp.125-134. Cited onpage426.
GOPALAKRISR.""iAN, Y.,SILAGHI, B.,BHATTACHARJEE, B.,and KELEHER, P.:
"Adaptive Replication inPeer-to-Peer Systems." Proc. 24thInt'l Con! onDistributed
Computing Systems, (Tokyo). LosAlamitos, CA:IEEE Computer Society Press, 2004. pp.
360-369. Cited onpage527.
GRAY, C.andCHERITON, D.:"Leases: AnEfficient Fault-Tolerant Mechanism forDis-
tributed FileCache Consistency." Proc. ]2thSymp. Operating System Principles, (Litch-
fieldPark, AZ).NewYork, NY:ACM Press, 1989. pp.202-210. Cited onpage304.
GRAY, J.,HELLAND, P.,O'NEIL, P.,andSASHNA, D.:"The Dangers ofReplication and
aSolution." Proc. SIGMOD lnt'lCon! onManagement OfData. ACM, 1996. pp.173-
182.Cited onpages 276.628.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 647
GRAY, J.andREUTER, A.:Transaction Processing: Concepts andTechniques. San
Mateo, CA:Morgan Kaufman, 1993. Cited onpage21.
GRAY,J.:"Notes onDatabase Operating Systems." InBayer, R.,Graham, R.,andSeeg-
muller, G.(eds.), Operating Systems: AnAdvanced Course, vol.60ofLect.Notes Comp:
Sc.,pp.393-481. Berlin: Springer-Verlag, 1978. Cited onpage355.
GRIMM, R.,DAVIS,J.,LEMAR, E.,MACBETH, A.,SWANSON, S.,ANDERSON, T.,
BERSHAD, B.,BORRIELLO, G.,GRIBBLE, S.,andWETHERALL, D.:"System Support
forPervasive Applications." ACM Trans. Compo Syst., (22)4:421-486, Nov. 2004. Cited
onpage25.
GROPP, W., HUSS·LEDERMAN, S.,LUl\ISDAINE, A., LUSK, E.,NITZBERG, B.,
SAPHIR, W.,andSNIR, M.:MPI: TheComplete Reference -TheMPI-2 Extensions.
Cambridge, MA:MITPress, 1998a. Cited onpage145. .
GROPP, W.,LUSK, E.,andSKJELLUM, A.:Using MPI, Portable Parallel Programming
withtheMessage-Passing Interface. Cambridge, MA:MITPress, 2nded.,1998b. Cited
onpage145.
GROSS KURTH, A.andGODFREY, M.W.: "AReference Architecture forWeb
Browsers." Proc. 21stlnt'lCon! Softw. Mainten., (Budapest, Hungary). LosAlamitos,
CA:IEEE Computer Society Press, 2005. pp.661-664. Cited onpage554.
GUDGIN, M.,HADLEY, ~I.,MENDELSOHN, N.,MOREAU, J.•J.,andNIELSE~, H.F.:
"SOAP Version 1.2."W3C Recommendation, June2003. Cited onpages 565,567.
GUERRAOUI, R.andRODRIGUES, L.:Introduction toReliable Distributed Program-
ming. Berlin: Springer-Verlag, 2006. Cited onpages 232,627.
GUERRAOUI, R.andSCHIPER, A.:"Software-Based Replication forFault Tolerance."
IEEE Computer, (30)4:68-74, Apr.1997. Cited onpages 328,629.
GUICHARD, J.,FAUCHEUR, F.L.,andVASSEUR, J.·P.: Definitive MPLS Network
Designs. Indianapolis, IN:Cisco Press, 2005. Cited onpage575.
GULBRANDSEN, A.,VIXIE, P.,andESIBOV, L.:"AdnsITforspecifying thelocation of
services (dnssrv)." RFC2782, Feb.2000. Cited onpage211.
GUPTA, A.,SAHIN, O.D.,AGRAWAL, D.,andABBADI, A.E.:"Meghdoot: Content-
Based Publish/Subscribe overP2PNetworks." Proc. Middleware 2004, vol.3231ofLect.
Notes Compo Sc.,(Toronto. Canada). Berlin: Springer-Verlag, 2004. pp.254-273. Cited on
page599.
GUSELLA, R.andZATTl,S.:"The Accuracy oftheClock Synchronization Achieved by
TEMPO inBerkeley UNIX 4.3BSO." IEEE Trans. Softw. Eng., (15)7:847-853, July1989.
Cited onpage241.
HADZILACOS, V.andTOUEG, S.:"Fault-Tolerant Broadcasts andRelated Problems." In
Mullender, S.(ed.), Distributed Systems, pp.97-145. Wokingham: Addison-Wesley, 2nd
ed.,1993. Cited onpages 324,352.
HALSALL, F.:Multimedia Communications: Applications, Networks, Protocols andStan-
dards. Reading, MA:Addison-Wesley, 2001. Cited onpages 157,160.648 READING LIST AND BIBLIOGRAPHY CHAP. 14
HANDURUKANDE. S~KERMARREC, A.-M., FESSANT, F.L.,andMASSOULI'E, L.:
"Exploiting Semantic Clustering intheeDonkey P2Pnetwork." Proc. llthSIGOPS Euro-
pean Workshop, (Leuven, Belgium). New York, NY:ACM Press, 2004. Cited onpage
226.
HELDER, D.A.andJAMIN, S.:"End-Host Multicast Communication Using Switch-Trees
Protocols." Proc. Second lnt'lSymp. Cluster Comput. &Grid, (Berlin, Germany). Los
Alamitos, CA:IEEE Computer Society Press, 2002. pp.419-424. Cited onpage ]69.
HELLERSTEIN, J.L.,DIAO, Y.,PAREKH, S.,andTILBURY, D.M.:Feedback Control of
Computing Systems. NewYork: JohnWiley, 2004. Cited onpages 60,624.
HENNING, M.:"ANewApproach toObject-Oriented Middleware." iEEE Internet Com-
put.,(8)1:66-75, Jan.2004. Cited onpage454.
HENNING, M.:"The RiseandFallofCORBA." ACM Queue, (4)5,2006. Cited onpage
631.
HENNING, M.andSPRUIELL, M.:Distributed Programming withIce.ZeroC Inc.,Bris-
bane, Australia, May2005. Cited onpages 455,470.
HENNING, M.andVINOSKI, S.:Advanced CORBA Programming withC++. Reading,
MA:Addison-Wesley, 1999. Cited onpage631.
HOCHSTETLER, S.andBERINGER, B.:"Linux Clustering with CSM andGPFS."
Technical Report SG24-6601-02, International Technical Support Organization, IBM,
Austin, TX,Jan.2004. Cited onpage98.
HOHPE, G.andWOOLF, B.:Enterprise Integration Patterns: Designing, Building, and
Deploying Messaging Solutions. Reading, MA:Addison-Wesley, 2004. Cited onpages
152,626.
HOROWITZ, M.andLUNT, S.:"FTP Security Extensions." RFC2228, Oct.1997. Cited
onpage122.-
HOWES, T.:"The String Representation ofLDAP Search Filters." RFC2254, Dec.1997.
Cited onpage221.
HUA CHU, Y.,RAO, S.G.,SESHAN, S.,andZHANG, H.:"ACaseforEndSystem Multi-
cast." IEEE J.Selected Areas Commun., (20)8:1456-1471, Oct.2002. Cited onpage168.
HUFFAKER, B.,FOMENKOV, M.,PLUMMER, D.J.,MOORE, D.,andCLAFFY, K.:
"Distance Metrics intheInternet." Proc. Int'lTelecommun. Symp., (Natal RN,Brazil).
LosAlamitos, CA:IEEE Computer Society Press, 2002. Cited onpage575.
HUNT, G.,NAHUM, E.,andTRACEY, J.:"Enabling Content-Based Load Distribution for
Scalable Services." Technical Report, IBM TJ.Watson Research Center, May 1997.
Cited onpage94.
HUTTO, P.andAHAMAD, M.:"Slow Memory: Weakening Consistency toEnhance Con-
currency inDistributed Shared Memories." Proc. Tenth Int'l Con! onDistributed Com-
puting Systems. IEEE, 1990. pp.302-311. Cited onpage284.
ffiM: WebSphere MQApplication Programming Guide, May2005a. Cited onpage152.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 649
IBM: WebSphere MQIntercommunication, May2005b. Cited onpage152.
IBM: WebSphere MQPublish/Subscribe User's Guide, May2005c. Cited onpage593.
IBM: WebSphere MQSystem Administration, lVlay2005d. Cited onpage152.
ISO:"Open Distributed Processing Reference Model." International Standard ISOIlEC IS
10746. 1995. Cited onpage5.
JAEGER, T.,PRAKASH, A.,LIEDTKE, J.,andISLAM, N.:"Flexible Control ofDown-
loaded Executable Content." ACM Trans. InfSyst.Sec.,(2)2:177-228, May1999. Cited
onpage426.
JALOTE, P.:Fault Tolerance inDistributed Systems. Englewood Cliffs, NJ:Prentice
Hall, 1994. Cited onpages 312,322,630.
JANIC. M.:Multicast inNetwork andApplication Layer. Ph.d.Thesis, Delft University of
Technology, TheNetherlands, Oct.1005. Cited onpage166.
JANIGA, M.J.,DIBNER, G.,andGOVERNALI, F.J.:"Internet Infrastructure: Content
Delivery." Goldman Sachs Global Equity Research, Apr.2001. Cited onpage575.
JELASITY, M.,GUERRAOUI, R.,KERMARREC, A.-M., andVANSTEEN, M.:"The Peer
Sampling Service: Experimental Evaluation ofUnstructured Gossip-Based Implementa-
tions." Proc. Middleware 2004, vol.3231 ofLect. Notes Compo Sc.,(Toronto, Canada).
Berlin: Springer-Verlag, 2004. pp.79-98. Cited onpage47.
JELASITY, M.,VOULGARIS, S.,GUERRAOUI, R.,KERMARREC, A.-M., andVAN
STEE~, M.:"Gossip-based PeerSampling." Technical Report, VrijeUniversiteit, Depart-
mentofComputer Science. Sept. 2005a. Cited onpages 47,49,171,226.
JELASITY, M.andBABAOGLU,O.: "T-Man: Gossip-based Overlay Topology Manage-
ment." Proc. Third Int'l Workshop Eng.Self-Organising App., (Utrecht, TheNetherlands),
2005. Cited onpages 49,50.
JELASITY, M.,MONTRESOR, A.,andBABAOGLU,O.: "Gossip-based Aggregation in
Large Dynamic Networks." ACM Trans. Compo Syst., (23)3:219-252. Aug. 2005b. Cited
onpage 173.
JIN,J. andNAHRSTEDT, K.:"QoS Specification Languages forDistributed Multimedia
Applications: ASurvey andTaxonomy." IEEE Multimedia, (11)3:74-87, July2004. Cited
onpage 160.
JING, J.,HELAL, A.,andELMAGARMID, A.:"Client-Server Computing inMobile
Environments." ACM Contput. Surv., (31)2:117-157, June1999. Cited onpage41.
JOHl'\SON, B.:"AnIntroduction totheDesign andAnalysis ofFault-Tolerant Systems."
InPradhan, D.K. (ed.), Fault-Tolerant Computer System Design, pp.1-87.Upper Saddle
River, NJ:Prentice Hall, 1995. Cited onpage326.
JOHNSON, D.,PERKINS, C.,andARKKO, J.:"Mobility Support forIPv6." RFC 3775,
June2004. Cited onpage186.
JOSEPH, J.,ERNEST, M.,andFELLENSTEIN, C.:"Evolution ofgridcomputing architec-
tureandgridadoption models." IBMSyst.J.,(43)4:624-645, Apr.2004. Cited onpage20.650 READING LIST AND BIBLIOGRAPHY CHAP. 14
JUL,E.•LEVY, H.,HUTCHINSON, N.,andBLACK, A.: "Fine-Grained Mobility inthe
Emerald System." ACM Trans. Compo Syst., (6)1:109-133, Feb.1988. Cited onpage186.
JUNG, J.,SIT,E.,BALAKRISHNAN, H.,andMORRIS, R.:"DNS Performance andthe
Effectiveness ofCaching." IEEE/ACM Trans. Netw., (10)5:589 -603,Oct.2002. Cited on
page216.
KAHN, D.:TheCodebreakers. NewYork: Macmillan, 1967. Cited onpage391.
KAMINSKY, M.,SAVVIDES, G.,MAZIhRES, D.,andKAASHOEK, M.F.:"Decentralized
UserAuthentication inaGlobal FileSystem." Proc. 19thSymp. Operating System Princi-
ples,(Bolton Landing, NY). NewYork, NY:ACM Press, 2003. pp.60-73. Cited onpages
535,538.
KANTARCIOGLU, M.andCLIFTON, C.:"Security Issues inQuerying Encrypted Data."
Proc. 19thConf. Data &Appl. Security, vol.3654ofLect. Notes Compo Sc.,(Storrs, CT).
Berlin: Springer-Verlag, 2005. pp.325-337. Cited onpage618.
KARNIK, N.andTRIPATHI, A.:"Security intheAjanta Mobile Agent System." Software
-Practice &Experience, (31)4:301-329, Apr.2001. Cited onpage421.
KASERA, S.,KUROSE, J.,andTOWSLEY, D.:"Scalable Reliable Multicast Using Multi-
pleMulticast Groups." Proc. Int'lConf. Measurements andModeling ofComputer Sys-
tems. ACM, 1997. pp.64-74. Cited onpage346.
KATZ, E.,BUTLER, M.,andMCGRATH, R.:"AScalable HTTP Server: TheNCSA Pro-
totype." Compo Netw. &ISDN Syst., (27)2:155-164, Sept. 1994. Cited onpage76.
KAUFMAN, C.,PERLMAN, R.,andSPECINER, M.:Network Security: Private Communi-
cation inaPublic World. Englewood Cliffs, NJ:Prentice Hall, 2nded.,2003. Cited on
pages 400,630.
KENT, S.:"Internet Privacy Enhanced Mail." Commun. ACM, (36)8:48-60, Aug. 1993.
Cited onpage431.
KEPHART, J.O.andCHESS, D.M.:"The Vision ofAutonomic Computing." IEEE Com-
puter, (36)1:41-50, Jan.2003. Cited onpage59.
KHOSHAFIAN, S.andBUCKIEWICZ, M.:Introduction toGroupware, Workflow, and
Workgroup Computing. NewYork: JohnWiley, 1995. Cited onpage151.
KHURANA, H.andKOLEVA, R.:"Scalable Security andAccounting Services for
Content-Based Publish Subscribe Systems." Int'lJ.E-Business Res., (2),2006. Cited on
pages 618,619,620.
KIM, S.,PAN, K.,SIl\1])ERSON, E.,andWHITEHEAD, J.:"Architecture andDataModel
ofaWebDAV-based Collaborative System." Proc. Collaborative Techn. Symp.\jR, (San
Diego, CAY,2004. pp.48-55. Cited onpage570.
KISTLER, J.andSATYANARYANAN, M.:"Disconnected Operation intheCoda FileSys-
tem." ACM Trans. Compo Syst., (10)1:3-25, Feb.1992. Cited onpages 503,518.
KLEIMAN, S.:"Vnodes: anArchitecture forMultiple FileSystem Types inUNIX." Proc.
Summer Techn. Con! USENIX, 1986. pp.238-247. Cited onpage493.
KOHL, J.,NEUMAN, B.,andT'SO, T.:"The Evolution oftheKerberos Authentication
System." InBrazier, F.andJohansen, D.(eds.), Distributed Open Systems, pp.78-94. Los
Alamitos, CA:IEEE Computer Society Press, 1994. Cited onpage411.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 651
KON, F.,COSTA, F.,CAMPBELL, R.,andBLAIR, G.:"The Case forReflective
Middleware." Commun. ACM, (45)6:33-38, June2002. Cited onpage57.
KOPETZ, H.andVERISSIMO, P.:"Real Time andDependability Concepts." InMul-
lender, S.(ed.), Distributed Systems, pp.411-446. Wokingham: Addison-Wesley, 2nded.,
1993. Cited onpage322.
KOSTOULAS, M.G.,MATSft,M.,MENDELSOHN, N.,PERKINS, E.,HEIFETS, A.,and
MERCALDI. M.:"XML Screamer: AnIntegrated Approach toHigh Performance XML
Parsing, Validation andDeserialization." Proc. 15thInt'lWWW Conf., (Edinburgh, Scot-
land). NewYork, NY:ACM Press, 2006. Cited onpage567.
KUMAR, P.andSATYANARA YANAN, M.:"Flexible andSafeResolution ofFileCon-
flicts." Proc. Winter Techn. Con! USENIX, 1995. pp.95-106. Cited onpage526.
LAI,A.andNIEH, J.:"Limits ofWide-Area Thin-Client Computing." Proc. Int'lCon!
Measurements andModeling ofComputer Systems, (Marina DelRey,CA). New York,
NY:ACM Press, 2002. pp.228-239. Cited onpage84.
LAMACCHI..-\., B.andODLYZKO, A.:"Computation ofDiscrete Logarithms inPrime
Fields." Designs, Codes, andCryptography, (1)1:47-62, May1991. Cited onpage534.
LAMPORT, L.:"Time, Clocks, andtheOrdering ofEvents inaDistributed System."
Commun. ACA1, (21)7:558-565, July1978. Cited onpage244.
LAMPORT, L.:"How toMake aMultiprocessor Computer thatCorrectly Executes Mul-
tiprocessor Programs." IEEE Trans. Comp., (C-29)9:690-691, Sept. 1979. Cited onpage
282.
LAMPORT, L.,SHOSTAK, R.,andPAESE, M.:"Byzantine Generals Problem." ACM
Trans. Prog. Lang. Syst., (4)3:382-401, July1982. Cited onpages 326,332,334.
LAMPSON, B.,ABADI, M.,BURROWS, M.,andWOBBER, E.:"Authentication inDistri-
buted Systems: Theory andPractice." ACM Trans. Compo Syst., (10)4:265-310, Nov.
1992. Cited onpage397.
LAPRIE, J.-C.: "Dependability -ItsAttributes, Impairments andMeans." InRandell, B.,
Laprie, J.-c., Kopetz, H.,andLittlewood, B.(eds.), Predictably Dependable Computing
Systems, pp.3-24. Berlin: Springer-Verlag, 1995. Cited onpage378.
LAURIE, B.andLAURIE, P.:Apache: TheDefinitive Guide. Sebastopol, CA:O'Reilly &
Associates, 3rded.,2002. Cited onpage558.
LEFF, A.andRAYFIELD, J.T.:"Alternative Edge-server Architectures forEnterprise
JavaBeans Applications." Proc. Middleware 2004, vol.3231 ofLect. Notes Compo Sc.,
(Toronto, Canada). Berlin: Springer-Verlag, 2004. pp.195-211. Cited onpage52.
LEIGHTON, F.andLEWIN, D.:"Global Hosting System." United States Patent, Number
6,108,703, Aug.2000. Cited onpage577.
LEVIEN, R.(ed.): Signposts inCyberspace: TheDomain Name System andInternet Navi-
gation. Washington, DC:National Academic Research Council, 2005. Cited onpage210.
LEVINE, B.andGARCIA-LUNA-ACEVES, J.:"AComparison ofReliable Multicast Pro-
tocols." ACM Multimedia Systems Journal, (6)5:334-348, 1998. Cited onpage345.652 READING LIST AND BIBLIOGRAPHY CHAP. ]4
LEWIS. B.andBERG, D.J.:Multithreaded Programming withPthreads. Englewood
Cliffs, NJ:Prentice Han,2nded.,]998.Cited onpages 70,625.
L1,G.and JACOBSEN, H.-A.: "Composite Subscriptions inContent-Based
Publish/Subscribe Systems:' Proc. Middleware 2005, vol.3790ofLect. Notes Compo Sc.,
(Grenoble, France). Berlin: Springer-Verlag, 2005. pp.249-269. Cited onpage603.
LI..I.,LV,C;andSHI,W.:"An Efficient Scheme forPreserving Confidentiality in
Content-Based Publish-Subscribe Systems." Technical Report GIT-CC-04-01, Georgia
Institute ofTechnology, College ofComputing, 2004a. Cited onpage6]9.
LI.N.,MITCHELL, J.c.,andTONG, D.:"Securing JavaRMI-based Distributed Applica-
tions." Proc. 20thAnn. Computer Security Application Conf., (Tucson, AZ). ACSA.
2004b. Cited onpage486.
I..ILJA, D.:"Cache Coherence inLarge-Scale Shared-Memory Multiprocessors: Issues and
Comparisons," ACM Comput. Surv., (25)3:303-338, Sept. 1993. Cited onpage3]3.
LIN,M.-J. andMARZULLO, K.:"Directional Gossip: Gossip inaWide-Area Network."
InProc. Third European Dependable Computing Conf., vol.]667ofLect. Notes Compo
sc..pp.364-379. Berlin: Springer-Verlag, Sept. 1999. Cited onpage172.
LIN,S.-D., LlAN, Q.,CHEN, M.,,andZHANG, Z.:"APractical Distributed Mutual Exclu-
sionProtocol inDynamic Peer-to-Peer Systems." Proc. Third Int'l Workshop onPeer-to-
PeerSystems, vol.3279ofLect.Notes Compo Sc.,(LaJolla, CA).Berlin: Springer-Verlag,
2004. pp.1]-21.Cited onpages 254,255.
LING, B.C;KICIMAN, E.,andFOX, A.:"Session State: Beyond SoftState." Proc. First
Symp. Networked Systems Design andImpl., (San Francisco, CA). Berkeley, CA:
USENIX, 2004. pp.295-308. Cited onpage91.
LINN, J.:"Generic Security Service Application Program Interface, version 2."RFC
2078, Jan.1997. Cited onpage534.
LIU,c.-c., ESTRIN, D.,SHENKER, S.,andZHANG, L.:"Local Error Recovery inSRM:
Comparison ofTwo Approaches." IEEE/ACM Trans. Netw., (6)6:686-699, Dec. 1998.
Cited onpage346.
LIU,H.andJACOBSEN, H.-A.: "Modeling Uncertainties inPublish/Subscribe Systems."
Proc. 20thInt'lCon! Data Engineering, (Boston, MA). LosAlamitos, CA:IEEE Com-
puter Society Press, 2004. pp.510-522. Cited onpage607.
LO,V.,ZHOU, D.,r.ruY.,GauthierDickey, c,andLI,.I.:"Scalable Supemode Selection
inPeer-to-Peer Overlay Networks." Proc. Second HotTopics inPeer-to-Peer Systems,
(LaJolla, CA),2005. Cited onpage269.
LOSHIN, P.(ed.): BigBook ofLightweight Directory Access Protocol (LDAP) RFCs. San
Mateo, CA:Morgan Kaufman, 2000. Cited onpage627.
LUA, E.K.,CROW CROFT, J.,PIAS, M.,SHARMA, R.,andLIM,S.:"ASurvey andCom-
parison ofPeer-to-Peer Overlay Network Schemes." IEEE Communications Surveys &
Tutorials, (7)2:22-73, Apr.2005. Cited onpages 15,44, 625.
LUI,J.,MISRA, V.,andRUBENSTEIN, D.:"OntheRobustness ofSoftState Protocols."
Proc. 12thInt'l Con! onNetwork Protocols, (Berlin, Germany). LosAlamitos, CA:IEEE
Computer Society Press, 2004. pp.50-60. Cited onpage91.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 653
LUOTONEN, A.andALTIS, K.:"World-Wide WebProxies." Compo Netw. &ISDN Syst.,
(27)2:1845-1855, 1994. Cited onpage555.
LYNCH, N.:Distributed Algorithms. SanMateo, CA:Morgan Kaufman, 1996. Cited on
pages 232,263,628.
MAASSEN, J.,KIELMANN, T.,andBAL, H.E.:"Parallel Application Experience with
Replicated Method Invocation." Cone. &Comput.: Prac. Exp., (13)8-9:681-712, 2001.
Cited onpage475.
MACGREGOR, R.,DURBIN, D.,OWLETT, J.,andYEOl.\tL..\.i."lS, A.:JavaNetwork Security.
Upper Saddle River, NJ:Prentice Hall, 1998. Cited onpage422.
MADDEN, S.R.,FRANKLIN, M.J.,HELLERSTEIN, J.M~andHONG, W.:"TinyDB: An
Acquisitional Query Processing System forSensor Networks." ACM Trims. Database
Syst., (30)1:122-173,2005. Cited onpage30.
MAKPANGOU, M.,GOURHANT, Y.,LENARZUL, J..P.,andSHAPIRO, M.:"Fragmented
Objects forDistributed Abstractions." InCasavant, T.andSinghal, M.(eds.), Readings in
Distributed Computing Systems, pp.170-186. LosAlamitos, CA:IEEE Computer Society
Press, 1994. Cited onpage449.
MALKHI, D.andREITER, M.:"Secure Execution ofJavaApplets using aRemote Play-
ground." IEEE Trans. Softw. Eng., (26)12:1197-1209, Dec.2000. Cited onpage424.
MAMEI, M.andZAMBONELLI, F.:"Programming Pervasive andMobile Computing
Applications withtheTOTA Middleware." Proc. Second Int'lConf. Pervasive Computing
andCommunications (PerCom), (Orlando, FL). LosAlamitos, CA:IEEE Computer
Society Press, 2004. pp.263-273. Cited onpage601.
MANOLA, F.andMILLER, E.:"RDF Primer." W3C Recommendation, Feb.2004. Cited
onpage218.
MARCUS, E.andSTERN, H.:Blueprints forHigh Availability. NewYork: JohnWiley,
2nded.,2003. Cited onpage629.
MASCOLO, C.,CAPRA, L.,andEMMERICH, W.:"Principles ofMobile Computing
Middleware." InMahmoud, Qusay H.(ed.), Middleware forCommunications, chapter 12.
NewYork: JohnWiley, 2004. Cited onpage25.
MASINTER, L.:"The DataURLScheme." RFC2397, Aug. 1998. Cited onpage568.
MAZIERES, D.,KAMINSKY, M.,KAASHOEK, M.,andWITCHEL, E.:"Separating Key
Management from FileSystem Security." Proc. 17thSymp. Operating System Principles.
ACM, 1999. pp.124-139. Cited onpages 484,536.
MAZOUNI, K.,GARBINATO, B.,andGUERRAOUI, R.:"Building Reliable Client-Server
Software Using Actively Replicated Objects." InGraham, I.,Magnusson, B.,Meyer, B.,
andNerson, J.-M(eds.), Technology ofObject Oriented Languages andSystems, pp.37-
53.Englewood Cliffs, NJ:Prentice Hall,1995. Cited onpage475.
MCKINLEY, P.,SADJADI, S~KASTEN, E.,andCHENG, B.:"Composing Adaptive
Software." IEEE Computer, (37)7:56-64, Jan.2004. Cited onpage57.
MEHTA, N.,MEDVIOOVIC, N.,andPHADKE, S.:"Towards ATaxonomy OfSoftware
Connectors." Proc. 22nd lnt'lConj. onSoftware Engineering, (Limerick, Ireland). New
York, NY:ACM Press, 2000. pp.178-187. Cited onpage34.654 READING LIST AND BIBLIOGRAPHY CHAP. 14
MENEZES, A.J.,VAN OORSCHOT, P.C.,andVANSTONE, S.A.:Handbook ofApplied
Cryptography. BocaRaton: CRCPress, 3rded.,]996. Cited onpages 391,430.431,630.
MERIDETH, M.G.,IYENGAR, A.,MlKALSEN, T.,TAl,S.,ROUVELLOU, I.,and
NARASIMHAN, P.:"Thema: Byzantine-Fault-Tolerant Middleware forWeb-Service
Applications." Proc. 24thSymp. onReliable Distributed Systems, (Orlando, FL). Los
Alamitos, CA:IEEE Computer Society Press, 2005. pp.13]-142. Cited onpage583.
MEYER, B.:Object-Oriented Software Construction. Englewood Cliffs, NJ:Prentice
Hall,2nded..1997. Cited onpage445.
MILLER, B.N.,KONSTAN, J.A.,andRIEDL, J.:"PocketLens: Toward aPersonal
Recommender System." ACM Trans. In!Syst., (22)3:437-476, July2004. Cited onpage
27.
MILLS, D.L.:Computer Network Time Synchronization: TheNetwork Time Protocol.
BocaRaton, FL:CRCPress, 2006. Cited onpage241.
MILLS, D.L.:"Network Time Protocol (version 3):Specification, Implementation, and
Analysis." RFC1305, July1992. Cited onpage241.
MILOJICIC, D.,DOUGLIS, F.,PAINDAVEINE, Y.,WHEELER, R.,andZHOU, S.:"Pro-
cessMigration." ACM Comput. Surv., (32)3:241-299, Sept.2000. Cited onpage103.
MIN, S.L.andBAER, J.-L.: "Design andAnalysis ofaScalable Cache Coherence Scheme
Based onClocks andTimestamps." IEEE Trans. Par.Distr. Syst., (3)1:25-44, Jan.1992.
Cited onpage313.
MIRKOVIC, J.,DIETRICH, S.,andANDPETER REIHER, D.D.:Internet Denial ofSer-
vice:Attack andDefense Mechanisms. Englewood Cliffs, NJ:Prentice Hall, 2005. Cited
onpage428.
MIRKOVIC, J.andREIHER, P.:"ATaxonomy ofDDoS Attack andDDoS Defense
Mechanisms." ACM Compo Commun. Rev.,(34)2:39-53, Apr.2004. Cited onpage428.
MOCKAPETRIS, P.:"Domain Names -Concepts andFacilities." RFC 1034, Nov. 1987.
Cited onpages 203,210.
MONSON-HAEFEL, R.,BURKE, B.,andLABOUREY, S.:Enterprise JavaBeans. Sebas-
topol, CA:O'Reilly &Associates, 4thed.,2004. Cited onpage447.
MOSER, L.,MELLIAR-SMITH, P.,AGARWAL, D.,BUDHIA, R.,and LINGLEY-
PAPADOPOULOS, C.:"Totem: AFault-Tolerant Multicast Group Communication Sys-
tem." Commun. ACM, (39)4:54-63, Apr.1996. Cited onpage478.
MOSER, L.,MELLIOR-SMITH, P.,andNARASThJHAK, P.:"Consistent Object Replica-
tionintheEternal System." Theory andPractice ofObject Systems, (4)2:81-92, 1998.
Cited onpage478.
MULLENDER, S.andTANENBAUM, A.:"Immediate Files." Software -Practice &
Experience, (14)3:365-368, 1984. Cited onpage568.
MUNTZ, D.andHONEYMAN, P.:"Multi-level Caching inDistributed FileSystems."
Proc. Winter Techn. Conf. USENIX, 1992. pp.305-313. Cited onpage301.
MURPHY, A.,PICCO, G.,andROMAN, G.-C.: "Lime: AMiddleware forPhysical and
Logical Mobility." Proc. 21st111t'1Con! onDistr. Computing Systems, (Phoenix, AZ).
LosAlamitos, CA:IEEE Computer Society Press, 2001. pp.524-533. Cited onpage600.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 655
MUTHITACHAROEN, A.,MORRIS, R.,GIL,T.,andCHEN, B.:"Ivy: AReadlWrite
Peer-to-Peer FileSystem." Proc. FifthSymp. onOperating System Design andImplemen-
tation, (Boston, MA). NewYork, NY:ACM Press, 2002. pp.31-44. Cited onpage499.
NAPPER, J.,ALVISI, L.,andVIN,H.M.:"AFault-Tolerant JavaVirtual Machine." Proc.
Int'lConf. Dependable Systems andNetworks, (SanFrancisco, CA). LosAlamitos, CA:
IEEE Computer Society Press, 2003. pp.425-434. Cited onpage480.
NARASIMHAN, P.,MOSER, L.,andMELLIAR-SMITH, P.:"The Eternal System." In
Urban, 1.andDasgupta, P.(eds.), Encyclopedia ofDistributed Computing. Dordrecht, The
Netherlands: Kluwer Academic Publishers, 2000. Cited onpage478.
NAYATE, A.,DAHLIN, M.,andIYENGAR, A.:"Transparent Information Dissemination."
Proc. Middleware 2004, voL3231 ofLect. Notes Compo Sc.,(Toronto, Canada). Berlin:
Springer-Verlag, 2004. pp.212-2~1. Cited onpage52.
NEEDHAM, R.andSCHROEDER, M.:"Using Encryption forAuthentication inLarge
Networks ofComputers." Commun. ACM, (21)12:993-999, Dec. 1978. Cited onpage
402.
NEEDHAM, R.:"Names." InMullender, S.(ed.), Distributed Systems, pp.315-327. Wok-
ingham: Addison-Wesley, 2nded.,1993. Cited onpage627.
NELSON, B.:Remote Procedure Call. Ph.D. Thesis, Carnegie-Mellon University, 1981.
Cited onpage342.
NEUMAN, B.:"Scale inDistributed Systems." InCasavant, T.andSinghal, M.(eds.),
Readings inDistributed Computing Systems, pp.463-489. LosAlamitos, CA:IEEE Com-
puter Society Press, 1994. Cited onpages 9,12,624.
NEUMAN, B.:"Proxy-Based Authorization andAccounting forDistributed Systems."
Proc. 13thInt'lConf. onDistributed Computing Systems. IEEE, 1993. pp.283-291. Cited
onpage437.
NEUMAN, C.,YU,T.,HARTMAN, S.,andRAEBURN, K.:"The Kerberos Network
Authentication Service." RFC4120, July2005. Cited onpage411.
NEUMANN, P.:"Architectures andFormal Representations forSecure Systems." Techni-
calReport, Computer Science Laboratory, SRIInternational, Menlo Park, CA,Oct.1995.
Cited onpage388.
NG,E.andZHANG, H.:"Predicting Internet Network Distance withCoordinates-Based
Approaches." Proc. 21stINFOCOM Conf., (New York, NY). LosAlamitos, CA:IEEE
Computer Society Press, 2002. Cited onpage262.
NIEMELA, E.andLATVAKOSKI, J.:"Survey ofRequirements andSolutions forUbiqui-
tousSoftware." Proc. Third Int'lConf. Mobile &Ubiq. Multimedia, (College Park, MY),
2004. pp.71-78. Cited onpage25.
NOBLE, B.,FLEIS, B.,andKIM, M.:"ACaseforfluid Replication." Proc. NetStore'99,
1999. Cited onpage30I.
OBRACZKA, K.:"Multicast Transport Protocols: ASurvey andTaxonomy." IEEE Com-
mun.Mag., (36)1:94-102, Jan.1998. Cited onpage166.656 READING LIST AND BIBLIOGRAPHY CHAP. 14
OMG: "The Common Object Request Broker: Core Specification, revision 3.0.3." OMG
Document formal/04-03-12, Object Management Group, Framingham, MA,Mar. 2004a.
Cited onpages 54,454,465,477.
OMG: "UML 2.0Superstructure Specification." OMG Document ptc/04-1O-02, Object
Management Group, Framingham, MA,Oct.2004b. Cited onpage34.
OPPENHEIMER, D.,ALBRECHT,J., PATTERSON,D., andVAHDAT, A.:"Design and
Implementation Tradeoffs forWide-Area Resource Discovery." Proc. l-tthInt'l Symp. on
High Performance Distributed Computing, (Research Triangle Park, NC). LosAlamitos,
CA:IEEE Computer Society Press, 2005. Cited onpage224.
ORAM, A.(ed.): Peer-to-Peer: Harnessing thePower ofDisruptive Technologies. Sebas-
topol, CA:O'Reilly &Associates, 2001. Cited onpages 15,625.
OZSU, T.andVALDURIEZ, P.:Principles ofDistributed Database Systems. Upper Saddle
River, NJ:Prentice Hall,2nded.,1999. Cited onpages 43,298.
PAl,V.,ARON, M.,BANGA, G.,SVENDSEN, M.,DRUSCHEL, P.,ZWAENEPOEL, W.,
andNAHUM, E.:"Locality-Aware Request Distribution inCluster-Based Network
Servers." Proc. Eighth Int'lCon! Architectural Support forProgramming Languages and
Operating Systems, (SanJose, CA). New York, NY:ACM Press, 1998. pp.205-216.
Cited onpage94.
PANZIERI, F.andSHRIV ASTAVA, S.:"Rajdoot: ARemote Procedure CallMechanism
withOrphan Detection andKilling." IEEE Trans. Softw. Eng., (14)1:30-37, Jan.1988.
Cited onpage342.
PARTRIDGE, c,MENDEZ, T.,andMILLIKEN, W.:"Host Anycasting Service." RFC
1546, Nov.1993. Cited onpage228.
PATE, S.:UNIX Filesystems: Evolution, Design, andImplementation. New York: John
Wiley, 2003. Cited onpage631.
PEASE, M.,SHOSTAK, R.,andLAMPORT, L.:"Reaching Agreement inthePresence of
Faults." J.ACM, (27)2:228-234, Apr.1980. Cited onpage326.
PERKINS, C.,HODSON, 0.,andHARDMAN, V.:"ASurvey ofPacket Loss Recovery
Techniques forStreaming Audio." IEEE Network, (12)5:40-48, Sept. 1998. Cited onpage
162.
PETERSON, L.andDAVIE, B.:Computer Networks, ASystems Approach. SanMateo,
CA:Morgan Kaufman, 3rded.,2003. Cited onpage626.
PETERSON, L.,BAVIER, A.,FIUCZYNSKI, M.,MUIR, S:,andROSCOE, T.:"Towards a
Comprehensive PlanetLab Architecture." Technical Report PDN-05-030, PlanetLab Con-
sortium, June2005. Cited onpage99.
PFLEEGER, C.:Security inComputing. Upper Saddle River, NJ:Prentice Hall, 3rded.,
2003. Cited onpages 378,394.
PICCO, G.,BALZAROTTI, D.,.andCOSTA, P.:"LighTS: ALightweight, Customizable
Tuple Space Supporting Context-Aware Applications." Proc. Symp. Applied Computing,
(Santa Fe,NM). NewYork, NY:ACM Press, 2005. pp.413-419. Cited onpage595.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 657
PIERRE, G.andVANSTEEN, M.:"Globule: ACollaborative Content Delivery Network."
IEEE Commun. Mag., (44)8, Aug.1006. Cited onpages 54,63.
PIERRE, G.,VAN STEEN, M.,andTANENBAUM, A.:"Dynamically Selecting Optimal
Distribution Strategies forWeb Documents." IEEE Trans. Comp., (51)6:637-651, June
2002. Cited onpage64.
PIETZUCH, P.R.andBACON, J.M.:"Hermes: ADistributed Event-Based Middleware
Architecture." Proc. Workshop onDistributed Event-Based Systems, (Vienna, Austria).
LosAlamitos, CA:IEEE Computer Society Press, 2002. Cited onpage633.
PIKE, R., PRESOTTO, D., DORWARD, S., FLANDRENA, B., THOMPSON, K.,
TRICKEY, H.,andWINTERBOTTOM, P.:"Plan 9fromBellLabs." Computing Systems,
(8)3:221-254, Summer 1995. Cited onpages 197,505.
PINZARI, G.:"NX XProtocol Compression." Technical Report D-309/3-NXP-DOC,
NoMachine, Rome, Italy, Sept.2003. Cited onpage84.
PITOURA, E.andSAMARAS, G.:"Locating Objects inMobile Computing." IEEE Trans.
Know. DataEng., (13)4:571-592, July2ool. Cited onpages 192,627.
PLAINFOSSE, D.andSHAPIRO, M.:"ASurvey ofDistributed Garbage Collection Tech-
niques." InProc. Int'lWorkshop OllMemory Management, vol.986ofLeet. Notes Compo
Sc.,pp.211-249. Berlin: Springer-Verlag, Sept. 1995. Cited onpage186.
PLUMMER, D.:"Ethernet Address Resolution Protocol." RFC826,Nov. 1982. Cited on
page183.
PODLING, S.andBOSZORMENYI, L.:"ASurvey ofWeb Cache Replacement Stra-
tegies." ACM Comput. Surv., (35)4:374-398, Dec.2003. Cited onpages 573,632.
POPESCU, B.,VAN STEEN, M.,andTANENBAUM, A.:"ASecurity Architecture for
Object-Based Distributed Systems." Proc. 18thAnn. Computer Security Application
Conf, (LasVegas, NA).ACSA, 2002. Cited onpage482.
POSTEL, J.:"Simple MailTransfer Protocol." RFC821,Aug.1982. Cited onpage151.
POSTEL, J.andREYNOLDS, J.:"File Transfer Protocol." RFC995,Oct.1985. Cited on
page122.
POTZL, H.,ANDERSON, M.,andSTEINBRINK, B.:"Linux-VServer: Resource Efficient
Context Isolation." FreeSoftware Magazine, no.5,June2005. Cited onpage103.
POUWELSE, J.,GARBACKI, P.,EPEMA, D.,andSIPS, H.:"AMeasurement Study ofthe
BitTorrent Peer-to-Peer File-Sharing System." Technical Report PDS-2004-003, Techni-
calUniversity Delft. Apr.2004. Cited onpage53.
POUWELSE, J.A.,GARBACKI, P.,EPEMA, D.H.J.,andSIPS, H.J.:"The Bittorrent P2P
File-Sharing System: Measurements andAnalysis." Proc. Fourth Int'l Workshop on
Peer-to-Peer Systems, vol.3640ofLect. Notes Compo Sc.,(Ithaca, NY). Berlin: Springer-
Verlag, 2005. pp.205-216. Cited onpage527.
QIN,F.,TUCEK, J.,SUNDARESAN, J.,andZHOU, Y.:"Rx:Treating Bugs asAllergies -
ASafeMethod toSurvive Software Failures." Proc. 20thSymp. Operating System Princi-
ples,(Brighton, UK). NewYork, NY:ACM Press, 2005. pp.235-248. Cited onpage372.658 READING LIST AND BIBLIOGRAPHY CHAP. 14
QIU,L.,PADMANABHAN. V.,andVOELKER, G.:"OnthePlacement ofWeb Server
Replicas." Proc. 20thINFOCOM Conf., (Anchorage (AK». LosAlamitos, CA:IEEE
Computer Society Press, 2001. pp.1587-1596. Cited onpages 296.'297.
RABINOVICH, M.andSPASTSCHECK, 0.:WebCaching andReplication. Reading, MA:
Addison-Wesley, 2002. Cited onpages 52,570,633.
RABINOVICH, M.,RABINOVICH, I.,RAJARAMAN, R.,andAGGARWAL, A.:"A
Dynamic Object Replication andMigration Protocol foranInternet Hosting Service."
Proc. 19thInt'l Con): onDistributed Computing Systems. IEEE, 1999. pp.JOI-I13. Cited
onpage299.
RADIA, S.:Names, Contexts, andClosure Mechanisms inDistributed Computing Environ-
ments. Ph.D. Thesis, University ofWaterloo, Ontario, 1989. Cited onpage198.
RADOSLAVOV, P.,GOVINDAN, R.,andESTRIN, D.:"Topology-Informed Internet
Replica Placement." Proc. Sixth WebCaching Workshop, (Boston, MA). Amsterdam:
North-Holland, 2001. Cited onpage296.
RAFAELI, S.andHUTCHISON, D.:"ASurvey ofKeyManagement forSecure Group
Communication." ACM Comput. Surv., (35)3:309-329, Sept.2003. Cited onpage631.
RAICIU, C.and ROSENBLUM, D.:"Enabling Confidentiality inContent-Based
Publish/Subscribe Infrastructures." Technical Report RN/05/30, Department ofComputer
Science, University College London, 2005. Cited onpage619.
RAMANATHAN, P.,SHIN, K.,andBUTLER, R.:"Fault-Tolerant Clock Synchronization
inDistributed Systems." IEEE Computer, (23)10:33-42, Oct.1990. Cited onpage238.
RAMASUBRAMANIAN, V.andSIRER, E.G.:"The Design andImplementation ofaNext
Generation Name Service fortheInternet." Proc. SIGCOMM, (Portland, OR).NewYork,
NY:ACM Press, 2004a. Cited onpage215.
RAMASUBRAMANIAN, V.andSIRER, E.G.:"Beehive: 0(1) Lookup Performance for
Power-Law Query Distributions inPeer-to-Peer Overlays." Proc. First Symp. Networked
Systems Design andImpl., (SanFrancisco, CA). Berkeley, CA:USENIX, 2004b. pp.99-
112.Cited onpages 216,527.
RATNASAMY, S.,FRANCIS,P., HANDLEY, M.,KARP, R.,andSCHENKER, S.:"AScal-
ableContent-Addressable Network." Proc. SIGCOMM. ACM, 2001. pp.161-p2. Cited
onpage45.
RAYNAL, M.andSINGHAL, M.:"Logical Time: Capturing Causality inDistributed Sys-
tems." IEEE Computer, (29)2:49-56, Feb.1996. Cited onpages 246,628.
REITER, M.:"How toSecurely Replicate Services." ACM Trans. Prog. Lang. Syst.,
(16)3:986-1009, May1994. Cited onpages 409.411.
REITER, M.,BIRMAN, K.,andVAN RENESSE. R.:"ASecurity Architecture forFault-
Tolerant Systems." ACM Trans. Compo Syst., (12)4:340-371, Nov. 1994. Cited onpage
433.
RESCORLA, E.andSCHIFFMAN, A.:"The Secure HyperText Transfer Protocol." RFC
2660, Aug. 1999. Cited onpage565.SEC. 14.2 ALPHABETICAL BffiLIOGRAPHY 659
REYNOLDS, J.andPOSTEL, J.:"Assigned Numbers." RFC 1700, Oct.1994. Cited on
page89.
RICART, G.andAGRAWALA, A.:"AnOptimal Algorithm forMutual Exclusion inCom-
puter Networks." Commun. ACM, (24)1:9-17, Jan.1981. Cited onpage255.
RISSON, J.andMOORS, T.:"Survey ofResearch towards Robust Peer-to-Peer Networks:
Search Methods." Compo Netw., (50),2006. Cited onpages 47,226.
RIYEST, R.:"The MD5 Message Digest Algorithm." RFC 1321, Apr. 1992. Cited on
page395.
RIVEST, R.,SHAMIR, A.,andADLE.MAN, L.:"AMethod forObtaining Digital Signa-
tures andPublic-key Cryptosystems." Commun. ACM, (21)2:120-126, Feb.1978. Cited
onpage394. .
RIZZO, L.:"Effective Erasure Codes forReliable Computer Communication Protocols."
ACJ1 Compo Commun. Rev.,(27)2:24-36, Apr.1997. Cited onpage364.
RODRIGUES, L.,FONSECA, H.,andVERISSIMO, P.:"Totally Ordered Multicast in
Large-Scale Systems." Proc. 16thInt'l Con! onDistributed Computing Systems. IEEE,
1996. pp.503-510. Cited onpage311.
RODRIGUES, R.andLISKOV, B.:"High Availability inDHTs: Erasure Coding vs.Repli-
cation." Proc. Fourth Int'l Workshop onPeer-to-Peer Systems, (Ithaca, NY), 2005. Cited
onpage532.
RODRIGUEZ, P.,SPANNER, C.,andBIERSACK, E.:"Analysis ofWebCaching Architec-
ture: Hierarchical andDistributed Caching." IEEE/ACM Trans. Netw., (21)4:404-418,
Aug.2001. Cited onpage571.
ROSENBLUM, M.andGARFINKEL, T.:"Virtual Machine Monitors: Current Technology
andFuture Trends." IEEE Computer, (38)5:39-47, May2005. Cited onpage82.
ROUSSOS, G.,MARSH, A.J.,andMAGLA VERA, S.:"Enabling Pervasive Computing
withSmart Phones." IEEE Pervasive Comput., (4)2:20-26, Apr.2005. Cited onpage25.
ROWSTRON, A.:"Run-time Systems forCoordination." InOmicini, A.,Zambonelli, F.,
Klusch, M.,andTolksdorf, R.(eds.), Coordination ofInternet Agents: Models, Technolo-
giesandApplications, pp.78-96. Berlin: Springer-Verlag, 2001. Cited onpage607.
ROWSTRON, A.andDRUSCHEL, P.:"Pastry: Scalable, Distributed Object Location and
Routing forLarge-Scale Peer-to-Peer Systems." Proc. Middleware 2001, vol.2218 of
Lect. Notes Compo Sc.Berlin: Springer-Verlag, 2001. pp.329-350. Cited onpages 167,
191,216.
ROWSTRON, A.andWRAY,S.:"ARun-Time System forWCL." InBal,H.,Belkhouche,
B.,andCardelli, L.(eds.), Internet Programming Languages, vol.1686ofLect. Notes
Compo Sc.,pp.78-96. Berlin: Springer-Verlag, 1998. Cited onpage610.
RUSSELLO, G.,CHAUDRON, M.,andVAN STEEN, M.:"Adapting Strategies forDistri-
buting DatainShared DataSpace." Proc. Int'lSymp. Distr. Objects &Appl. (DOA), vol.
3291 ofLect. Notes Compo Sc.,(Agia Napa, Cyprus). Berlin: Springer-Verlag, 2004. pp.
1225-1242. Cited onpages 611,612.660 READING LIST AND BIBLIOGRAPHY CHAP. 14
RUSSELLO. G.,CHAUDRON, M.,VANSTEEN, M.,andBOKHAROUSS. I.:"Dynamically
Adapting Tuple Replication forManaging Availability inaShared Data Space." Sc.
Compo Programming, (63),2006; Cited onpages 6]1,616.
SADJADI, S.andMCKINLEY, P.:"ASurvey ofAdaptive Middleware." Technical Report
MSU-CSE-03-35, Michigan State University, Computer Science andEngineering, Dec.
2003. Cited onpage55.
SAITO, Y.andSHAPIRO, M.:"Optimistic Replication." ACM Comput. Surv., (37)]:42-
81,Mar.2005. Cited onpage628.
SALTZER, J.andSCHROEDER, M.:"The Protection ofInformation inComputer Sys-
tems." Proceedings oftheIEEE, (63)9:1278-1308, Sept. 1975. Cited onpage416.
SALTZER, J.:"Naming andBinding Objects:' InBayer, R..Graham, R.,andSeegmuller,
G.(eds.), Operating Systems: AnAdvanced Course, vol.60ofLeet.Notes Compo Sc.,pp.
99-208. Berlin: Springer-Verlag, 1978. Cited onpage627.
SALTZER, J.,REED, D.,andCLARK, D.:"End-to-End Arguments inSystem Design."
ACM Trans. Camp. Syst., (2)4:277-288, Nov. ]984. Cited onpage252.
SANDHU, R.S.,COYNE, E.J.,FEINSTEIK H.1.,.,andYOUMAN, C.E.:"Role-Based
Access Control Models." IEEE Computer, (29)2:38-47, Feb.1996. Cited onpage417.
SAROIU, S.,GUMMADI, P.K.,andGRIBBLE, S.D.:"Measuring andAnalyzing the
Characteristics ofNapster andGnutella Hosts." ACMMultimedia Syst., (9)2:170-184,
Aug.2003. Cited onpage53.
SATYANARAYANAN,M.: "The Evolution ofCoda." ACM Trans. Camp. Syst., (20)2:85-
124,May2002. Cited onpage632.
SATYANARAYANAN, M.andSIEGEL. E.:"Parallel Communication inaLarge Distri-
buted System." IEEE Trans. Comp., (39)3:328-348. Mar.1990. Cited onpage505.
SAXENA, P.andRAI,J.:"ASurvey ofPermission-based Distributed Mutua] Exclusion
Algorithms." Computer Standards andInterfaces, (25)2:159-181, May2003. Cited on
page252.
SCHMIDT, D.,STAL, M.,ROHNERT. H.,and BUSCHMANN, F.:Pattern-Oriented
Software Architecture -Patterns forConcurrent andNetworked Objects. Nev.' York:
JohnWiley, 2000. Cited onpages 55,625.
SCHNEIDER, F.:"Implementing Fault- Tolerant Services Using theState Machine
Approach: ATutorial." ACM Comput. SUn' ..(22)4:299-320, Dec. 1990. Cited onpages
248,303,480.
SCHNEIER, B.:Applied Cryptography. NewYork: JohnWiley, 2nded.,1996. Cited on
pages 391.411.
SCHNEIER, B.:Secrets andLies. NewYork: JohnWiley, 2000. Cited onpages 391,630.
SCHULZRINNE, H.:"The telURIforTelephone Numbers." RFC3966, Jan.2005. Cited
onpage569.
SCHULZRINNE, H.,CASNER, S.,FREDERICK, R..andJACOBSON, V.:"RTP: ATrans-
portProtocol forReal-Time Applications." RFC3550, July2003. Cited onpage] 21.SEC. 14.2 ALPHABETICAL BmLIOGRAPHY 661
SEBESTA, R.:Programming theWorld Wide Web. Reading, MA:Addison-Wesley, 3rd
ed.,2oo6. Cited onpages 547,633.
SHAPIRO, M.,DICKMAN, P.,andPLAINFOSSE, D.:"SSP Chains: Robust, Distributed
References Supporting Acyclic Garbage Collection." Technical Report 1799, INRIA,
Rocquencourt, France, Nov. 1992. Cited onpage184.
SHAW,M.andCLEMENTS, P.:"AField Guide toBoxology: Preliminary Classification
ofArchitectural Styles forSoftware Systems." Proc. 21st Int'l Compo Softw. &
Appl. Conf.. 1997. pp.6-13. Cited onpage34.
SHEPLER, S., CALLAGHAN, B., ROBINSON, D., THURLOW, R., BEAME, c.,
EISLER, M.,andNOVECK, D.:"Network FileSystem (NFS) Version 4Protocol." RFC
3530, Apr.2003. Cited onpages 201,492.
SHEm, A.P.andLARSON, J.A.:"Federated Database Systems forManaging Distri-
buted, Heterogeneous, andAutonomous Databases." ACMComput. Surv., (22)3: 183-236,
Sept. 1990. Cited onpage299.
SHOOMAN, M.L.:Reliability ofComputer Systems andNetworks: Fault Tolerance,
Analysis, andDesign. NewYork: JohnWiley, 2002. Cited onpage322.
SILBERSCHATZ, A.,GALVIN, P.,andGAGi'Ii~, G.:Operating System Concepts. New
York: JohnWiley, 7thed.,2005. Cited onpages 197,624.
SINGH, A.,CASTRO, M.,DRUSCHEL, P.,andROWSTRON, A.:"Defending Against
Eclipse Attacks onOverlay Networks." Proc. 11thSIGOPS European Workshop, (Leu-
ven,Belgium). NewYork, NY:ACM Press, 2004. pp.115-120. Cited onpage539.
SINGH, A.,NGAN, T.-W., DRUSCHEL, P.,andWALLACH, D.S.:"Eclipse Attacks on
Overlay Networks: Threats andDefenses." Proc. 25thINFOCOM Corf; (Barcelona,
Spain). LosAlamitos, CA:IEEE Computer Society Press, 2006. Cited onpage539.
SINGHAL, M.andSHIVARATRI, N.:Advanced Concepts inOperating Systems: Distri-
buted, Database, andMultiprocessor Operating Systems. NewYork: McGraw-Hill, 1994.
Cited onpage364.
SIVASUBRAMANIAN, S.,PIERRE, G.,andVANSTEEN, M.:"Replicating WebApplica-
tions On-Demand." Proc. First lnt'lCon! Services Comput., (Shanghai, China). Los
Alamitos, CA:IEEE Computer Society Press, 2004a. pp.227-236. Cited onpage580.
SIVASUBRAMANIAN, S.,PIERRE, G.,VANSTEEN, M.,andALONSO, G.:"GlobeCBC:
Content-blind Result Caching forDynamic WebApplications." Technical Report, Vrije
Universiteit, Department ofComputer Science, Jan.2006. Cited onpage582.
SIVASUBRAMANIAN, S.,SZYMANIAK, M.,PIERRE, G.,andVANSTEEN, M.:"Replica-
tionforWebHosting Systems." ACM Comput. Surv., (36)3:1-44, Sept. 2004b. Cited on
pages 299,573,629.
SIVASUBRAMANIAN, S.,ALONSO, G.,PIERRE, G.,andVAN STEEN, M.:"GlobeDB:
Autonomic DataReplication forWebApplications." Proc. 14thInt'lWWW Conf), (Chiba,
Japan). NewYork, NY:ACM Press, 2005. pp.33-42. Cited onpage581.
SIVRIKAYA, F.andYENER, B.:"Time Synchronization inSensor Networks: ASurvey."
IEEE Network, (18)4:45-50, July2004. Cited onpage242.662 READING LIST AND BIBLIOGRAPHY CHAP. ]4
SKEEN, D.:"Nonblocking Commit Protocols." Proc. SIGMOD IIlt'IConf. onManage-
mentOfData. ACM, 1981. pp.133-142. Cited onpage359.
SKEEN, D.andSTONEBRAKER, M.:"AFormal Model ofCrash Recovery inaDistri-
buted System." IEEE Trans. Softw. Eng., (SE-9)3:219-228, Mar. ]983. Cited onpage
361.
SMITH, J.andNAIR, R.:"The Architecture ofVirtual Machines." IEEE Computer,
(38)5:32-38, May2005. Cited onpages 80,81.
SMITH, J.andNAIR, R.:Virtual Machines: Versatile Platforms forSystems and
Processes. SanMateo, CA:Morgan Kaufman, 2005. Cited onpage625.
SNIR, M.,OTTO, S.,HUSS-LEDERMAN, S.,WALKER, D.,andDONGARRA, J.:MPI: The
Complete Reference -TheMPICore. Cambridge, MA:MITPress. 1998. Cited onpage
145.
SPEAKMAN, T., CROWCROFT, J., GEMMELL,J., FARINACCI, D., LI~,S.,
LESHCHINER, D., LUBY, M., MONTGOMERY, T., RIZZO, L., TWEEDLY, A.,
BHASKAR, N.,EDMONSTONE, R.,SUMANASEKERA, R.,andVICISANO, L.:"PGM
Reliable Transport Protocol Specification." RFC3208, Dec.2001. Cited onpage6]4.
SPECHT, S.M.andLEE,R.B.:"Distributed Denial ofService: Taxonomies ofAttacks,
Tools, andCountermeasures." Proc. Int'l Workshop onSecurity inParallel andDistri-
buted Systems, (SanFrancisco, CA),2004. pp.543-550. Cited onpage427.
SPECTOR, A.:"Performing Remote Operations Efficiently onaLocal Computer Net-
work." Commun. ACM, (25)4:246-260, Apr.1982. Cited onpage339.
SRINIVASAN, R.:"RPC: Remote Procedure CallProtocol Specification Version 2."RFC
1831, Aug. 1995a. Cited onpage502.
SRINIVASAN, R.:"XDR: External Data Representation Standard;" RFC 1832, Aug.
1995b. Cited onpage502.
SRIPANIDKULCHAI, K.,MAGGS, B.,andZIL-\.NG, H.:"Efficient Content Location
Using Interest-Based Locality inPeer-to-Peer Systems." Proc. 22nd INFOCOM Conf.,
(SanFrancisco, CA). LosAlamitos, CA:IEEE Computer Society Press, 2003. Cited on
page225. .
STEIN, L.:Web Security, AStep-by-Step Reference Guide. Reading, MA: Addison-
Wesley, 1998. Cited onpage432.
STEINDER, M.andSETHI, A.:"ASurvey ofFault Localization Techniques inComputer
Networks." Sc.Compo Programming, (53)165-194. May2004. Cited onpage372.
STEINER, J.,NEUMAN, C.,andSCHILLER, J.:"Kerberos: AnAuthentication Service for
Open Network Systems." Proc. Winter Techn. Conf. USENIX, 1988. pp.191-202. Cited
onpage411.
STEINMETZ, R.:"Human Perception ofJitter andMedia Synchronization." IEEE
J.Selected Areas Commun., (14)1:61-72, Jan.1996. Cited onpage163.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 663
STEINMETZ, R.andNAHRSTEDT, K.:Multimedia Systems. Berlin: Springer-Verlag.
2004. Cited onpages 93,157,160,626.
STEVENS, W.:UNIX Network Programming -Networking APIs: Sockets andXTI.
Englewood Cliffs, NJ:Prentice Hall,2nded.,1998. Cited onpages 76,142.
STEVENS, W.:UNIX Network Programming -lnterprocess Communication. Englewood
Cliffs, NJ:Prentice Hall,2nded.,1999. Cited onpages 70,136.
STEVENS, W.andRAGO, S.:Advanced Programming intheUNIX Environment. Read-
ing,MA:Addison-Wesley, 2nded.,2005. Cited onpages 72,626.
STOICA, I.,MORRIS, R.,LffiEN-NOWELL, D.,KARGER, D.R.,KAASHOEK, M.F.,
DABEK, F.,andBALAKRISHNAN, H.:"Chord: AScalable Peer-to-peer Lookup Protocol
forInternet Applications." IEEE/ACM Trans. Netw., (11)1:17-32, Feb.2003. Cited on
pages 44,188. .
STOJl\'IENOVIC, I.:"Position-based Routing inAdHocNetworks." IEEE Commun.
Mag., (40)7:128-134, July2002. Cited onpage261.
STRAUSS, J.,KATABI, D.,andKAASHOEK, F.:"AMeasurement Study ofAvailable
Bandwidth Estimation Tools." Proc. Third Internet Measurement Conf, (Miami Beach,
FL,USA). NewYork, NY:ACM Press, 2003. pp.39-44. Cited onpage575.
SUGERMAN, J.,VENKITACHALAM, G.,andLIM,B.-H.: "Virtualizing I/ODevices on
VMware Workstation sHosted Virtual Machine Monitor." Proc. USENIX Ann.
Techn. Conf, (Boston, MA). Berkeley, CA:USENIX, 2001. pp.1-14. Cited onpage81.
SUNMICROSYSTEMS: JavaMessage Service, Version 1.1.SunMicrosystems, Mountain
Ciew, Calif., Apr.2004a. citedonpages 466,593.
SUNMICROSYSTEMS: Java Remote Method Invocation Specification, JDK 1.5.Sun
Microsystems, Mountain View, Calif., 2004b. Cited onpage122.
SUNMICROSYSTEMS: EJB3.0Simplified API. SunMicrosystems, Mountain View,
Calif., Aug.2005a. Cited onpage447.
SUNMICROSYSTEMS: Jini Technology Starter Kit,Version 2.1,Oct.2oo5b. Cited on
pages 486,593.
SUNDARARAMAN, B.,BUY, U.,andKSHEMKALYANI,A. D.:"Clock Synchronization
forWireless Sensor Networks: ASurvey." Ad-Hoc Networks, (3)3:281-323, May2005.
Cited onpage242.
SZYMANIAK, M.,PIERRE, G.,andVAN STEEN, M.:"Scalable Cooperative Latency
Estimation." Proc. Tenth lnt'lConf Parallel andDistributed Systems, (Newport Beach,
CA).LosAlamitos, CA:IEEE Computer Society Press, 2004. pp.367-376. Cited onpage
263.
SZYMANIAK, M.,PIERRE, G.,andVANSTEEN, M.:"ASingle-Homed AdhocDistri-
buted Server." Technical Report IR-CS-013, Vrije Universiteit, Department ofComputer
Science, Mar.2005. Cited onpage96.
SZYMANIAK, M.,PIERRE, G.,andVANSTEEN, M.:"Latency-driven replica place-
ment." IPSJDigital Courier, (2),2006. Cited onpage297.664 READING LIST AND BIBLIOGRAPHY CHAP. 14
TAIANI, F.,.~ABRE, J.-C., andKILLUIAN, M.-O.: "AMulti-Level Meta-Object Protocol
forFault-Tolerance inComplex Architectures." Proc. Int'l Conf. Dependable Systems and
Networks, (Yokohama, Japan). LosAlamitos, CA:IEEE Computer Society Press, 2005.
pp.270-279. Cited onpage474.
TAM, D.,AZIMI, R.,andJACOBSEN, H.-A.: "Building Content-Based Publish/Subscribe
Systems withDistributed Hash Tables." Proc. FirstInt'IWorkshop onDatabases, Infor-
mation Systems andPeer-to-Peer Computing, vol.2944ofLect.Notes Compo Sc.,(Berlin,
Germany). Berlin: Springer-Verlag, 2003. pp.138-152. Cited onpage597.
TAN, S.-W., WATERS, G.,andCRAWFORD,J.: "ASurvey andPerformance Evaluation
ofScalable Tree-based Application Layer Multicast Protocols." Technical Report 9-03,
University ofKent, UK,July2003. Cited onpage169.
TANENBAUM, A.:Computer Networks. Upper Saddle River, NJ:Prentice Hall, 4thed.,
2003. Cited onpages 117,336.
TANENBAUM, A.,MULLENDER, S.,andVANRENESSE, R.:"Using Sparse Capabilities
inaDistributed Operating System." Proc. SixthInt'l Conf. onDistributed Computing Sys-
tems. IEEE, 1986. pp.558-563. Cited onpage435.
TANENBAUM, A.,VANRENESSE, R.,VAN STAVEREN, H.,SHARP, G.,MULLEI\'DER,
S.,JANSEN, J.,andVAN ROSSUM, G.:"Experiences with theAmoeba Distributed
Operating System." Commun. ACM, (33)12:46-63, Dec.1990. Cited onpage415.
TANENBAUM, A.andWOODHULL, A.:Operating Systems, Design andImplementation.
Englewood Cliffs, NJ:Prentice Hall,3rded.,2006. Cited onpages 197,495.
TANISCH, P.:"Atomic Commit inConcurrent Computing." IEEE Concurrency, (8)4:34-
41,Oct.2000. Cited onpage355.
TARTALJA, I.andMILUTINOVIC, V.:"Classifying Software-Based Cache Coherence
Solutions." IEEE Softw., (14)3:90-101, May1997. Cited onpage313.
TEL,G.:Introduction toDistributed Algorithms. Cambridge, UK:Cambridge University
Press, 2nded.,2000. Cited onpages 232,263,628.
TERRY, D.,DEMERS, A.,PETERSEN, K.,SPREITZER, M., THElMER, M., and
WELSH, B.:"Session Guarantees forWeakly Consistent Replicated Data." Proc. Third
Int'l Conf. onParallel andDistributed Information Systems, (Austin, TX). LosAlamitos,
CA:IEEE Computer Society Press, 1994. pp.140-149. Cited onpages 290,293,295.
TERRY, D.,PETERSEN, K.,SPREITZER, M.,andTHEIMER, M.:"The Case forNon-
transparent Replication: Examples from Bayou." IEEE Data Engineering, (21)4:12-20.
Dec.1998. Cited onpage290. -
mOMAS, R.:"AMajority Consensus Approach toConcurrency Control forMultiple
Copy Databases." ACM Trans. Database Syst., (4)2:180-209, June1979. Cited onpage
311.
TIBCO: TIB/Rendezvous Concepts, Release 7.4.TIBCO Software Inc.,PaloAlto. CA,
July2005. Cited onpages 54,595.
TOLIA, N.,HARKES, J.,KOZUCH, M.,andSATYANARAYAN, M.:"Integrating Portable
andDistributed Storage." Proc. Third USENIX Conf. FileandStorage Techn., (Boston.
MA). Berkeley, CA:USENIX, 2004. Cited onpage523.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 665
TOLKSDORF, R.andROWSTRON, A.:"Evaluating Fault Tolerance Methods forLarge-
scaleLinda-like systems." Proc. Int'l Con! onParallel andDistributed Processing Tech-
niques andApplications, vol.2,(LasVegas, NV), 2000. pp.793-800. Cited onpage616.
TOWSLEY, D.,KUROSE, J.,andPINGALI, S.:"AComparison ofSender-Initiated and
Receiver-Initiated Reliable Multicast Protocols." IEEE J.Selected Areas Commun.,
(15)3:398-407, Apr.1997. Cited onpage345.
TRIPATHI, A.,KARNIK, N.,VORA, M.,AHMED, T.,andSINGH, R.:"Mobile Agent Pro-
gramming inAjanta." Proc. 19thInt'lCan! onDistributed Computing Systems. IEEE,
1999. pp.190-197. Cited onpage422.
TUREK, J.andSHASHA, S.:"The Many Faces ofConsensus inDistributed Systems."
IEEE Computer, (25)6:8-17, June1992. Cited onpages 332,335.
UMAR, A.:Object-Oriented Client/Server Internet Environments. Upper Saddle River,
NJ:Prentice Hall, 1997. Cited onpage41.
UPnP Forum: "UPnP Device Architecture Version 1.0.1, Dec.2003. Cited onpage26.
VAN RENESSE, R.,BIRMAN, K.,andVOGELS, W.:"Astrolabe: ARobust andScalable
Technology forDistributed System Monitoring, Management, andDataMining." ACM
Trans. Compo Syst., (21)2:164-206, May2003. Cited onpage61.
VAN STEEN, M.,HAUCK, F.,HOMBURG, P.,andTANENBAUM, A.:"Locating Objects
inWide-Area Systems." IEEE Commun., (36)1:104-109, Jan.1998. Cited onpage192.
VASUDEV AN,S.,KUROSE, J.F.,andTOWSLEY, D.F.:"Design andAnalysis ofa
Leader Election Algorithm forMobile AdHocNetworks." Proc. 12thInt'lConf. onNet-
work Protocols, (Berlin, Germany). LosAlamitos, CA:IEEE Computer Society Press,
2004. pp.350-360. Cited onpages 267,268.
VEIGA, L.andFERREIRA, P.:"Asynchronous Complete Distributed Garbage Collec-
tion." Proc. 19thInt'lParallel &Distributed Processing Symp., (Denver, CO).LosAlam-
itos,CA:IEEE Computer Society Press, 2005. Cited onpage186.
VELAZQUEZ, M.:"ASurvey ofDistributed Mutual Exclusion Algorithms." Technical
Report CS-93-116, University ofColorado atBoulder, Sept. 1993. Cited onpage252.
VERISSIMO, P.andRODRIGUES, L.:Distributed Systems forSystems Architects. Dor-
drecht, TheNetherlands: Kluwer Academic Publishers, 2001. Cited onpage624.
VETTER, R.,SPELL, C.,andWARD, C.:"Mosaic andtheWorld-Wide Web." IEEE Com-
puter, (27)10:49-57, Oct.1994. Cited onpage545.
VITEK, J.,BRYCE, c.,andORIOL, M.:"Coordinating Processes withSecure Spaces." Sc.
Compo Programming, (46)1-2,2003. Cited onpage620.
VOGELS, W.:"Tracking Service Availability inLong Running Business Activities."
Proc. First Int'lConf. Service Oriented Comput., vol.2910 ofLect.Notes Camp. Sc.,
(Trento, Italy). Berlin: Springer-Verlag, 2003. pp.395-408. Cited onpage336.
VOULGARIS, S.andVANSTEEN, M.:"Epidemic-style Management ofSemantic Over-
laysforContent-Based Searching." Proc. 11thlnt'lConf. Parallel andDistributed Com-
puting (Euro-Par), vol.3648 ofLect. Notes Camp. Sc.,(Lisbon, Portugal). Berlin:
Springer-Verlag, 2005. pp.1143-1152. Cited onpage226.666 READING LIST AND BIBLIOGRAPHY CHAP. 14
VOULGARIS, S.•RIVfERE, E.,KERMARREC, A.-M., andVANSTEEN, M.:"Sub-2-Sub:
Self-Organizing Content-Based Publish andSubscribe forDynamic andLarge Scale Col-
laborative Networks." Proc. Fifth InnWorkshop onPeer-to-Peer Systems, (Santa Bar-
bara,CA),2006. Cited onpage597.
VOYDOCK, V.andKENT, S.:"Security Mechanisms inHigh-Level Network Protocols."
ACM Comput. Surv., (15)2:135-171, June1983. Cited onpage397.
WAH, B.W.,SUoX.,andLIN,D.:"ASurvey ofError-Concealment Schemes forReal-
Time Audio andVideo Transmissions overtheInternet." Proc. Int'l Symp. Multimedia
Softw. Eng., (Taipei, Taiwan). LosAlamitos, CA:IEEE Computer Society Press, 2000. pp.
17-24. Cited onpage162.
WAHBE, R.,LUCCO, S.,ANDERSON, T.,andGRAHAM,~S.: "Efficient Software-based
Fault Isolation." Proc. 14thSymp. Operating System Prt1iciples. ACM, 1993. pp.203-
216.Cited onpage422.
WALDO, J.:"Remote Procedure Calls andJavaRemote Method Invocation." IEEE Con-
currency, (6)3:5-7, July1998. Cited onpage463.
WALFISH, M.,BALAKRISHNAN, H.,,andSHENKER, S.:"Untangling theWeb from
DNS." Proc. First Symp. Networked Systems Design andImp!., (San Francisco, CA). '
Berkeley, CA:USENIX, 2004. pp.225-238. Cited onpage215.
WALLACH, D.:"ASurvey ofPeer-to-Peer Security Issues." Proc. Int'l Symp. Softw.
Security, vol.2609 ofLect. Notes Compo Sc.,(Tokyo, Japan). Berlin: Springer-Verlag,
2002. pp.42-57. Cited onpage539.
WALLACH, D.,BALFANZ, D.,DEAN, D.,andFELTEN, E.:"Extensible Security Archi-
tectures forJava." Proc. 16thSymp. Operating System Principles. ACM, 1997. pp.116-
128.Cited onpages 424,426.
WANG, C.,CARZANIGA, A.,EVANS, D.,andWOLF, A.L.:"Security Issues andRequire-
ments forInternet-Scale Publish-Subscribe Systems." Proc. 35thHawaii Int'l Conf Sys-
temSciences, vol.9.IEEE, 2002. pp.303-310. Cited onpage618.
WANG, H.,LO,M.K.,andWANG, C.:"Consumer Privacy Concerns about Internet Mark-
eting." Commun. ACM, (41)3:63-70, Mar. 1998. Cited onpage4.
WATTS, D.J.:Small Worlds, TheDynamics ofNetworks between Order andRandomness.
Princeton, NJ:Princeton University Press, 1999. Cited onpage226. .
WELLS, G.,CHALMERS, A.,andCLAYTON, P.:"Linda Implementations inJava for
Concurrent Systems." Cone. &Comput.: Prac. Exp., (16)10:1005-1022, Aug. 2004.
Cited onpage633.
WESSELS, D.:Squid: TheDefinitive Guide. Sebastopol, CA:O'Reilly &Associates,
2004. Cited onpages 556,572.
WHITE, S.R.,HANSON, J.E.,WHALLEY, I.,CHESS, D.M.,,andKEPHART, J.0.:"An
Architectural Approach toAutonomic Computing." Proc. First Int'l Conf. Autonomic
Comput.,(New York, NY). LosAlamitos, CA:IEEE Computer Society Press, 2004. pp.
2-9.Cited onpage625.
WIERINGA, R.andDEJONGE, W.:"Object Identifiers, Keys, andSurrogates-Object
Identifiers Revisited." Theory andPractice ofObject Systems, (1)2:101-114, 1995. Cited
onpage181.SEC. 14.2 ALPHABETICAL BIBLIOGRAPHY 667
WIESMANN, M.,PEDONE, F.,SCHIPER, A.,KEMME, B.,andALONSO, G.:"Under-
standing Replication inDatabases andDistributed Systems." Proc. 20thInt'l Conf. on
Distributed Computing Systems. IEEE, 2000. pp.264-274. Cited onpage276.
WOLLRA TH,A.,RIGGS, R.,andWALDO, J.:"ADistributed Object Model fortheJava
System." Computing Systems, (9)4:265-290, Fall1996. Cited onpages 460,472.
WOLMAN, A.,VOELKER, G.,SHARMA, N.,CARDWELL, N.,KARLIN, A.,and
LEVY, H.:"OntheScale andPerformance ofCooperative WebProxy Caching." Proc.
17thSymp. Operating System Principles. ACM, 1999. pp.16-31. Cited onpage571.
WU,D.,HOU, Y.,ZHU, W.,ZHANG, Y.,andPEHA, J.:"Streaming Video overtheInter-
net:Approaches andDirections." IEEE Trans. Circuits &Syst.Video Techn., (11)1:1-20,
Feb.2001. Cited onpage159.
YANG, B.andGARCIA-MOLINA, H.:"Designing aSuper-Peer Network." Proc. 19th
Int'l Con! Data Engineering, (Bangalore, India). LosAlamitos, CA:IEEE Computer
Society Press, 2003. pp.49-60. Cited onpage51.
YANG, M.,ZHANG, Z.,LI,X.,andDAI,Y.:"AnEmpirical Study ofFree-Riding Behavior
intheMaze P2PFile-Sharing System." Proc. Fourth Int'lWorkshop onPeer-to-Peer Sys-
tems, Lect. Notes Compo Sc.,(Ithaca, NY). Berlin: Springer-Verlag, 2005. Cited onpage
53.
YELLIN, D.:"Competitive Algorithms fortheDynamic Selection ofComponent Imple-
mentations." IBMSyst.J.,(42)1:85-97, Jan.2003. Citedon page58.
YU,H.andVAHDAT, A.:"Efficient Numerical Error Bounding forReplicated Network
Services." InAbbadi, AmrEl,Brodie, Michael L.,Chakravarthy, Sharma, Dayal,
Umeshwar, Kamel, Nabil, Schlageter, Gunter, andWhang, Kyu-Young (eds.), Proc.26th
Int'lCon! VeryLarge Data Bases, (Cairo, Egypt). SanMateo, CA:Morgan Kaufman,
2000. pp.123-133. Cited onpage306.
YU,H.andVAHDAT, A.:"Design andEvaluation ofaConit-Based Continuous Con-
sistency Model forReplicated Services." ACM Trans. Compo Syst., (20)3:239-282, 2002.
Cited onpages 277,279,575.
ZHANG, C.andJACOBSEN, H.-A.: "Resolving Feature Convolution inMiddleware Sys-
tems." Proc. 19thOOPSLA, (Vancouver, Canada). NewYork, NY:ACM Press, 2004. pp.
188-205. Cited onpage58.
ZHAO, B.,HUANG, L.,STRIBLING, J.,RHEA, S.,JOSEPH, A.,andKUBIATOWICZ, J.:
"Tapestry: AResilient Global-Scale Overlay forService Deployment." IEEE J.Selected
Areas Commun., (22)1:41-53, Jan.2004. Cited onpage216.
ZHAO, F.andGUIBAS, L.:Wireless Sensor Networks. SanMateo, CA:Morgan Kaufman,
2004. Cited onpages 28,624.
ZHAO, Y.,STURMAN, D.,andBHOLA, S.:"Subscription Propagation inHighly-Available
Publish/Subscribe Middleware." Proc. Middleware 2004, vol.3231ofLect.Notes Compo
Sc.,(Toronto, Canada). Berlin: Springer-Verlag, 2004. pp.274-293. Cited onpage633.
ZHU, Q.,CHEN, Z.,TAN, L.,ZHOU, Y.,KEETON, K.,andWILKES, J.:"Hibernator:
Helping Disk Arrays Sleep through theWinter." Proc. 20thSymp. Operating System
Prin., (Brighton, UK). NewYork,NY:ACM Press, 2005. pp.177-190. Cited onpage632.668 READING LIST AND BIBLIOGRAPHY CHAP. 14
ZHUANG, S.Q.,GEELS. D.•STOICA. I.,andKATZ, R.H.:"OnFailure Detection Algo-
rithms inOverlay Networks." Proc. 24thINFOCOM Conf., (Miami, FL).LosAlamitos,
CA:IEEE Computer Society Press, 2005. Cited onpage335.
ZOGG,J.-M.: "GPS Basics." Technical Report GPS-X-02007, UBlox, Mar.2002. Cited
onpage236.
ZWICKY, E.,COOPER, S.,CHAPMAN, D.,andRUSSELL, D.:Building Internet Firewalls.
Sebastopol, CA:O'Reilly &Associates, 2nded.,2000. Cited onpage418.INDEX
A
Absolute pathname, 196
Access control, 413-428
NFS, 535-536
Access control list,415
Access control matrix, 415-416
Access point, 180
Access right, 414
Access transparency, 5
Accessible volume storage group, Coda, 524
ACID (see Atomic Consistent Isolated
Durable properties)
ACL (see Access Control List)
Activation policy, 453
Active goal,616
Active replication, 303,311
Adapter, object, 446,453-454
Adaptive redirection policy, 579
Adaptive software, 57-58
Address, 180-182
Address identifier, 469
Address resolution protocol, 183Administrational layer, 203
Agent, mobile, 420-422
Agreement, Byzantine, 332-335
Agreement infaulty systems, 331-335
Akamai,579
Alias, 199
Anti-entropy model, 171
Apache, 556-558
Apache portable runtime, 556-557
API(see Application Programming Interface)
Append-only log,421
Application layer, 118,122
Application layering, 38-40
Application-level gateway, 419
Application-level multicasting, 166-170
Application programming interface, 81
APR(see Apache Portable Runtime)
Arbitrary failure, 325
Architectural style, 34-36
Architecture, 33-67,54-59
centralized, 36-43
client-server, 491-496
data-centered, 35
669670
Architecture (continued)
decentralized, 43-51
distributed filesystems, 491-500
event-based, 35
hybrid, 52-54
multitiered, 41-43,549-551
object-based systems, 443-451
peer-to-peer, 596-599
publish/subscribe, 35
referentially decoupled, 35
software, 33
symmetric, 499-500
system, 33,36-54
traditional, 593-596
virtual machine, 80-82
Web-based system, 546-554
AS(see Authentication Server)
AS(see Autonomous System)
Aspect-oriented software development, 57
Assured forwarding, 161
Astrolabe, 61-63
Asymmetric cryptosystem, 390
Asynchronous communication, 12,125
Asynchronous method invocation, 464
Asynchronous RPC, 134-135
Asynchronous system, 332
Asynchronous transmission mode, 158
At-least-once semantics, 339
At-most-once operation, 140,339
Atomic consistent isolated durable
property, 21-23
Atomic multicast, 331,348-355
Atomic transaction, 21
Atomicity, 122
Attack, security, 389-391
Attribute. 592
Attribute-based naming, 217-226
Attribute certificate, 435-437
Attribute certification authority, 437
Attribute-value tree,223
Auditing, 379,380
Authentication, 379-380, 397-405, 411-412,
486-487,532-534,536-539
decentralized, 536-539
using akeydistribution center, 400-404
using apublic key.404-405INDEX
Authentication (coutinucdi
using ashared secret, 398-400
using Needham-Schroeder, 401-404
Authentication proxy. 486
Authentication server. 412
Authorization, 122.377,380,414,434-439
Authorization management. 434-435
Automounter, 510-512
Autonomic computing. 60
Autonomic system, 34
Autonomous system. 296
Availability, 203-205, 322531-532, 616-617
AVSG (see Accessi bleVolume Storage GroUT
AVTree (see Attribute-Value Tree)
B
Backward recovery, 363
BAN (see Body AreaNetwork)
Banner ad,573
BAR faulttolerance, 335
Berkeley clock algorithm, 241-242
Berkeley sockets, 141-142
BFT(see Byzantine Fault Tolerance)
Bigendian format, 131
Binding, 66,137,456-458,566
object, 444,456-458
object, explicit, 457
object, implicit, 457
Binding byidentifier, 108
Binding bytype, 108
Binding byvalue, 108
BitTorrent, 53-54
Blocking commit protocol, 359
Body areanetwork, 27
Broker. 54
Browser, 547
Bully algorithm, 264
Bytecodeverifier, 423
Byzantine agreement problem, 332
Byzantine failure, 325,529-531
Byzantine faulttolerance, 583-584c
Cache, 15,301
client-side, 520-524
Coda, 522-523
NFS, 520-522
portable devices, 523-524
Web, 571-573
Cache-coherence protocol, 313-314
Cache hit,301
Call-by -copy/restore, 127
Call-by-reference, 127
Call-by-value, 127
Callback break, 522
Callback model, 464
Callback promise, 522
CAN (see Content Addressable Network)
Canonical name, 211
Capability, 415,435-437
Care-of address, 96,186
Causal consistency, 284-286
Causality, 249
Causally-ordered multicasting, 250-251
CDN (see Content Delivery Network)
Centralized system, 2
Certificate, 172,417,430,432,
437-439,482-483
Certificate lifetime, 432
Certificate revocation list,432
Certification authority, 430
Certified message delivery, 615
CGI(see Common Gateway Interface)
Challenge-response protocol, 398
Channel control function, 157
Checkpoint, 363
Checkpointing,366-369
coordinated, 369
independent, 367-368
Checksum, 119
Chunk server, 497
Ciphertext, 389
Class, object, 445
Class loader, Java.423
Client, 11,20,37,82-88
thin,84-86
Web, 554-556INDEX 671
Client-based protocol, 303
Client-centric consistency, 288-295
Client class, 462-463
Client interface, 66
Client-server architectures, 491-496
Client-server communication, 125-140,
336-339, 493
Client-side caching, 520-524
Client stub,128-129
Clock skew, 233
Clock synchronization, 232-244
wireless, 242-244
Clock tick,233
Closure mechanism, 198-199
Cluster, server, 92-98
Webserver, 558-560
Cluster-based filesystems, 496-499
Cluster computing, 17-18
Cluster management, 98-103
CoA(see Care-of Address)
Coda
filecaching, 522-523
filesharing, 518-519
server replication, 524-526
Coda version vector, 525
Code migration, 103-112
Code-signing, 425
Coherence detection strategy, 313
Coherence enforcement strategy, 314
Collaborative distributed system, 53-54
Collaborative storage, 540-541
Common gateway interface, 549-550
Communication, 115-174
filesystem, 502-506
fundamentals, 116-125
message-oriented, 140-157
multicast, 166-174
Plan9,505-506
publish/subscribe, 613-616
reliable, 336-342
RPC, 125-140
stream-oriented. 157-166
using objects, 456-466
Web, 560-567
Communication subobject, Globe, 450
Complex service, 553672
Complex stream, I59
Component, 34
Component repair, 65-66
Composite localobject, 450
Composite service, 553
Composition, 603
Compound document, 86-87
Compound procedure, 502
Concurrency transparency, 6
Concurrent events, 245
Concurrent operations, 285
Concurrent server, 89
Confidential group communication, 408-409
Confidentiality, 378
Conit,278-281
Connection oriented, 117
Connectionless protocol, 117
Connector, 34
Consistency, 15
filesystem, 519-529
object-based systems, 472-477
Web, 570-582
Consistency andreplication, 273-318
Consistency model, 276-295, 288
client-centric consistency, 288-295,315-317
data-centric, 276-288
Eventual consistency, 289-291
monotonic-read consistency, 291-292
monotonic-write consistent, 292-293
read-your-writes consistency, 294-295
sequential consistency, 281-288
writes-follow-read, 295
Consistency protocol, 306-317
Consistency vs.coherence, 288
Contact address, 96,469
Content addressable network, 46
Content-aware cache, 581
Content-aware request distribution, 559
Content-based routing, 601
Content-blind caching, 582
Content delivery network, 511,556,573-579
Content distribution, 302-305
Content-hash block. 499
Continuous consistency, 278,306-308
Continuous media, 158-160
Control subobject, Globe, 451INDEX
Conversational exchange style. 566
Cookie, 92
Cooperative caching, 571-573
Coordinated checkpointing, 369
Coordination-based system, 589-621
architecture, 591-601
communication, 601-604
consistency andreplication, 607-613
faulttolerance, 613-167
introduction, 589-591
naming, 604-607
security, 617-620
Coordination model, 589-59 J
Coordination protocol, 553
CORBA,464
faulttolerance, 477-479
naming, 467-468
Counter, 233
Crash failure, 324
CRL(see Certificate Revocation List)
Cryptography, 389-396
DES, 391-394
RSA,394-395
D
Data-centered architecture, 35
Dataencryption standard, 392-394
Datalinklayer, 118-119
Datastore, 277
Datastream, 158
DeE(see Distributed Computing Environment -
DDoS (see Distributed Denial ofService attack
Deadlock, 252
Death certificate, 173
Decentralized architecture, 43-51
Decentralized authentication, 536-539
Decision support system, 40
Decryption, 389
Deferred synchronous RPC, 134
Delegation, 437-439
Denial-of-service attack, 427-428
Dependable system, 322
DES(see DataEncryption Standard)INDEX
Destination queue, 147
DHash,499
DHT (see Distributed HashTable)
DIB(see Directory Information Base)
Differentiated service, 161
Diffie-Hellman keyexchange, 429-430
Digital signature, 405-407
Direct coordination, 590
Directional gossiping, 172
Directory information base,219
Directory information tree,220
Directory node, 195
Directory service, 136,217-218
Directory service agent, 221
Directory table, 196
Directory useragent, 221
Disconnected operation, 524
Discrete media, 158
Dispatcher, 77
Distributed caching, 571-573
Distributed commit, 355-363
Distributed computing environment,
135-140,463
daemon, 139
Distributed computing systems, 17-20
Distributed denial ofservice attack, 427-428
Distributed event detector, 606
Distributed fileservice, 136
Distributed filesystem, 491-541
Distributed hashtable, 44,188-191,222-225
secure, 539-540
Distributed information system, 20-24
Distributed object, 444-446
compile-time, 445-446
run-time, 445-446
Distributed pervasive systems, 24-30
Distributed server, 95
Distributed shared object, 449
Globe, 449-451
Distributed snapshot, 366
Distributed system, 2
collaborative, 53-54
communication, 115-176
consistency andreplication, 273-318
definition, 2
faulttolerance, 321-374673
Distributed system (continued)
filesystems, 491-543
goals, 3-16
home, 26-27
naming, 179-228
object-based systems, 443-487
pervasive, 24-26
pitfalls, 16
processes 69-113
security, 377-439
synchronization, 231-271
thread, 75-79
types, 17-30
virtualization, 79-80
Web-based, 545-586
Distributed timeservice, 136
Distributed transaction, 20
Distribution, 13
Distribution transparency, 4-7,87-88
DIT(see Directory Information Tree)
DNS(see Domain Name System)
Domain, 14,192,210
Domain name, 210
Domain name system, 10,96,209-217
implementation, 212-217
name space, 210-212
Domino effect, 367
Drag-and-drop, 86
DSA(see Directory Service Agent)
DUA (see Directory UserAgent)
Durable, 22
Dynamic invocation, 459
E
EAI(see Enterprise Application Integration)
Eclipse attack, 540
Edge server system, 52
EJB(see Enterprise JavaBean)
Election algorithm, 263-270
bully, 264-266
large-scale, 269-270
ring,266-267
wireless, 267-269
Embedded document, 548674 INDEX
Encryption, 379,389
Endpoint, 89,139
End-to-end argument, 252
Enterprise application integration, 20-23. 151
Enterprise Javabean, 446-448
Entity bean, 448
Entry consistency, 287,472-475
Epidemic protocol, 170
Erasure coding, 531
Erasure correction, 364
Error. 323
Event, 593,604
Event-based architecture, 35
Eventual consistency, 289-291
Exactly-once semantics, 339
Exception, 338
Expedited forwarding, 161
Expiration, orphan, 342
Explicit binding, 457
Exporting files,NFS, 506-509
Extensible markup language, 548
Extensible system, 8
F
Fail-safe fault, 326
Fail-silent system, 326
Fail-stop failure, 326
Failure, Byzantine, 325-326, 529-531
remote procedure call,337-342
Failure detection, 335-336
Failure masking, 326-328
Failure model, 324-326
Failure transparent system, 6
Fastened resource, 108
Fatclient, 42
Fault, 322
Fault tolerance, 321-374
basic concepts, 322-328
client-server communication, 336-342
CORBA,477-479
distributed commit, 355-363
filesystem, 529-532Fault tolerance (continued)
group communication, 343-355
introduction, 322-328
Java, 480-481
object-based systems, 477-481
process resilence, 328-336
recovery, 363-373
Web, 582-584
FEC(see Forward EITor Correction)
Feedback analysis component, 61
Feedback control, 345-348
Feedback control loop,60
Feedback control system, 60-61
Feedback suppression, 345
Filehandle, 494
NFS, 509-510
Filelocking, 516-518
Fileserver, 6,77-78,201,324,387,492
Filesharing, Coda, 518-519
Filesharing semantics, 513-516
session, 515
UNIX, 514
File-striping technique, 496
Filesystem, cluster-based, 496-499
distributed, 494,496
symmetric, 499-500
Filesystem communication, 502-506
Filesystem consistency, 519-529
Filesystem failures, Byzantine, 529-531
Filesystem faulttolerance, 529-532
Filesystem naming, 506-513
Filesystem processes, 501
Filesystem replication, 519-529
Filesystem security, 532-541
Filesystem synchronization, 513-519
Filetransfer protocol, 122
Finger table, 188
Firewall, 418-420
Fixed resource, 108
Flash crowd, 297,576
Flash-crowd predictor, 576
Flatgroup, 329
Flatnaming, 182-195
Flush message, 354
Forward errorcorrection, 162
Forward recovery, 363-365INDEX
Forwarder, 167
Forwarding pointer, 184
Frame, 119
NM,481
Frequency, clock, 239
FrP(see FileTransfer Protocol)
G
Gateway, application level, 419
packet-filtering, 419
proxy, 420
Generative communication, 591
Gentle reincarnation, 342
Geographical scalability, 15
Geometric overlay network, 260
GFS(see Google FileSystem)
Global layer, 203
Global name, 196
Global name space, 512-513
Global positioning system, 236-238
Globe, 448-451
Globe location service, 191-195
Globe object model, 449-451
Globe object reference, 469-470
Globe security, 482-485
Globe shared object, 448-451
Globe subobjects, 450-451
Globule 63-65
Globus, 380-384
GNS(see Global Name Space Service)
Google filesystem, 497
Gossip-based communication, 170-174
Gossiping, 63
GPS(see Global Positioning System)
Grandorphan, 342
Gridcomputing, 17-20
Group, flat,329
hierarchical, 329
object, 477
protection, 417
Group communication, confidential, 408-409
reliable, 343-355
secure, 408-411675
Group management, secure, 433-434
Group membership, 329-330
Group server. 329
Group view, 349
Groupware, 4
H
Happens-before relationship, 244,340
Hardlink,199
Hash function, 391,395-396
Header, message, 117
Health caresystems, 27-28
Heartbeat message, 616
Helper application, 167,547
Hierarchical cache, 571
Hierarchical group, 329
Highavailability inpeer-to-peer systems, 531-532
HoA(see Home Address)
Holding register, 233
Home address, 96
Home agent, 96,186
Home-based. naming, 186-187
Home location, 186
Home network, 96
Hook, Apache, 557
Horizontal distribution, 44
HTML (see HyperText Markup Language)
HTTP (see Hypertext Transfer Protocol)
Human-friendly name, 182
Hybrid architecture, 52-54
Hyperlink,554-555
Hypertext markup language, 548
Hypertext transfer protocol, 122,547,560-561
messages, 563-565
methods, 562-563
I
Ice,454-456
Idempotent operation, 37,140,341
Identifier, 180-182676
IDL(see Interface Definition Language)
IIOP(see Internet Inter-ORB Protocol)
Implementation handle, object, 458
Implicit binding, 456
In-network dataprocessing, 28-29
In-place editing, 86
Incremental snapshot, 369
Indegree, 49
Independent checkpointing, 368
Infected node. 170
Information confidentiality, 618
Instance address, 470
Integrity, 378
message, 405-408
Interceptor, 55-57
Interface, 8
object, 444
Interface definition language, 8,134,137
Intermittent fault, 323
International atomic time, 235
Internet inter-ORB protocol, 468
Internet policy registration authority, 431
Internet protocol, 120
Internet search engine, 39
Internet service provider, 52
Interoperability, 8
Interoperable object group
reference, 477
Interoperable object reference, 467
Intruder, 389
Invalidation protocol, 302
Invocation, dynamic, 458-459
Javaobject, 462,463
object, 451-453,458-459
replicated, 475-477
secure, 484-485
static, 458-459
IOGR (see Interoperable Object
Group Reference)
lOR(see Interoperable Object Reference)
IP(see Internet Protocol)
IPRA (see Internet Policy
Registration Authority)
ISOOSI(see Open Systems
Interconnection Reference Model)INDEX
Isochronous transmission mode, ]59
Isolated, 22
ISP(see Internet Service Provider)
Iterative lookup. 191
Iterative name resolution, 206
Iterative server, 89
J
Jade, 65-66
Javabean, 446-448
Javaclassloader. 423
Javafaulttolerance, 480-48]
Javamessaging service, 466
Javaobject invocation, 462,463
Javaobject model, 461-462
Javaplayground, 424
Javaremote object invocation, 462-463
Javasandbox, 422
Javasecurity, 420-425
Javavirtual machine, 422
Javascript, 13,555
JavaSpace, 593-595, 607-610
Jini.486,593-595
JMS(see JavaMessaging Service)
Junction, 512
JVM(see JavaVirtual Machine)
K
Kfaulttolerant, 331
KDC (see KeyDistribution Center)
Kerberos. 4]1-413
Kernel mode, 72,75
Key.object, 482
Keydistribution, 430-432
Keydistribution center, 401
Keyestablishment, 429-430
Keymanagement, 428-432L
Lamport clock, 244-252, 255,311
LAN (see Local AreaNetwork)
Landmark, 262
Layered architecture, 34
Layered protocol, 116-124
LDAP (see Lightweight Directory
Access Protocol)
Leader-election, 52
Leafdomain, 192
Leafnode, 195
Leap second, 235
Lease, 304
Ledger, 615
Lightweight directory access
protocol, 218-226
Lightweight process, 74-75
Linkstress, 168
Little endian format, 131
Local alias, 155
Local-area network, 1,99-101, 110,
419,445,467,505,548
Local name, 196
Local object, Globe, 449
Local representative, Globe, 449
Local-write protocol, 310-311
Location independent name, 181
Location record, 192
Location server, 458
Location transparency, 5
Logical clock, 244-252
LWP(see Lightweight Process)
M
Machine instruction, 81
Mailbox coordination, 590
Maintainability, 323
Managerial layer, 203
Managing overlay networks, 156-157
Markup language, 547
Matched, 592
Maximum driftrate,clock, 239INDEX 677
MCA (see Message Channel Agent)
MD5 hashfunction, 395
Mean solarsecond, 235
Mean timetofailure, 616
Mean timetorepair, 616
Meeting-oriented coordination, 590
Membership management, 45
Mesh network, 28
Message broker, 149-150
Message channel, 152
Message channel agent, 153
Message confidentiality, 405-408
Message digest, 395
Message-driven bean, 448
Message integrity, 405-408
Message-level interceptor, 57
Message logging, 364,369-372
Message ordering, 351-352
Message-oriented communication, 140-157
Message-oriented middleware, 24,145
Message-passing interface, 142-145
Message queue interface, 155
Message-queuing model, 145-147
Message-queuing system, 145-157
Message transfer, 154-156
Messaging, object based, 464-466
Messaging service, Java,466
Method, HTTP, 562-563
object, 444
Method invocation, secure, 484-485
Metric estimation, CDN, 574-576
Metric estimation component, 61
Middleware, 3,54-59, 122-124
Middleware protocol. 122-124
Migration, code, 103-112
Migration transparency, 5
MIME type,548-549
Mirror site,298
Mirroring, 298
Mobile agent, 104
Mobile code, 420-427
Model, distributed filesystem, 494-496
Globe object, 449-451
Javaobject, 461-462
Module, Apache, 557
MOM (see Message-Oriented Middleware)678
Monotonic-read consistency. 291-292
Monotonic-write consistent. 292-293
MOSIX, ]8
Mother nature, 15
Motion picture experts group, 165
Mounting, 199-202
Mounting point, 200,495
MPEG (see Motion Picture Experts Group)
MPI(see Message-Passing Interface)
MPLS (see Multi-Protocol Label Switching)
MQI(see Message Queue Interface)
MTTF (see Mean Time ToFailure)
MTTR (see Mean Time ToRepair)
Multi-protocol labelswitching, 575
Multicast, atomic, 348-355
reliable, 351-352
Multicast communication, 166-174
Multicasting, 305
feedback control, 345-348
reliable, 343-344
RPC2, 503-504
scalable, 345
Multicomputer, 142-143
Multiprocessor, 72,77,231,282,286,313
Multipurpose internet mailexchange, 548
MultiRPC, 505
Multithreaded server, 77-79
Multithreading, 72
Multitiered architecture, 41-43, 549-551
Mutual exclusion, 252-260
centralized algorithm, 253-254
decentralized algotithm, 254-255
distributed algorithm, 255-258
token ringalgorithm, 258-259
N
Name, 180-182
Name resolution, 198-202
implementation, 205-209
Name resolver, 206
Name space, 195-198
DNS.21O-212
global, 512-513
implementation, 202-209INDEX
Name space distribution, 203-205
Name space management, 426
Name-to-address binding, 182
Naming, 179-228
attribute-based, 217-226
CORBA, 467-468
filesystem, 506-513
flat,182-195
object-based. 466-470
structured. 195-217
Web, 567-569
Naming system, 217
Needham-Schroeder protocol, 401
Nested transaction, 22
Network, bodyarea.27
localarea,1
mesh, 28
sensor, 28-30
widearea,2
Network filesystem. 20I,491
Network filesystem access control, 535-536
Network filesystem caching, 520-522
Network filesystem client, 493
Network filesystem loopback server, 500
Network filesystem naming, 506-511
Network filesystem RPC, 502-503
Network filesystem RPC2, 503-505
Network filesystem security, 533-536
Network filesystem server, 493
Network layer, 118,120
Network timeprotocol, 240-241
NFS(see Network FileSystem)
Node manager, PlanetLab, 100
Nonce. 402
Nonpersistent connection, 561-562
Normalized database, 581
Notification, 592
NTP(see Network Time Protocol)
o
Object. 414
interface, 444
persistent, 446Object (continued)
remote, 445
state. 444
transient, 446
Object adapter, 446,453-454
Object-based architecture, 35
Object-based messaging, 464-466
Object-based naming, 466-470
Object-based system processes, 451-456 _
Object-based systems, 443-487
consistency, 472-477
faulttolerance, 477-481
replication, 472-477
security, 481-487
Object binding, 444,456-458
explicit, 457
implicit, 457
Object class, 445
Object group, 477
Object implementation handle, 458
Object invocation, 451-453, 458-459
Java, 462,463
parameter passing, 460-461
Object key,482
Object method, 444
Object model, Globe, 449A51
Java, 461-462
Object proxy, 444
Object reference, 457-458
Globe, 469-470
Object requXest broker, 468
Object server, 451-454
Object synchronization, 470-472
Object wrapper, 453-454
OGSA (see Open GridServices
Architecture)
Omission failure, 325
ONC RPC(see Open Network
Computing RPC)
One-phase commit protocol, 355
One-way function, 391
One-way RPC, 135
Open delegation, 521
Open distributed system. 7
Open gridservices architecture, 20
Open network computing RPC, 502INDEX 679
Open Systems Interconnection
Reference Model, 117
Openness, degree 7-9
Operating system, 70,128,387
Optimistic logging protocol, 372
ORB (see Object Request Broker)
Orca, 449
Ordered message delivery, 251-252
Origin server, 54
Orphan, 341-342, 370
Orphan extermination, 342
OSImodel, 117
Out-of-band, 90
Overlay network, 44,148
Owner capability, 435
p
Packet, 120
Packet-filtering gateway, 419
Parameter marshaling, 130,462
Parameter passing, 127,130,458,460-461
Partial replication, 581
Partial view, 47.225.598
Pathname, 196
PCA(see Policy Certification Authority)
Peer-to-peer system, 44-52
filereplication, 526-529
security, 539-540
highavailability, 531-532
structured,44A6,527-528
unstructured. 526-527
Peet-to-peer system. unstructured, 47-49
PEM (see Privacy Enhanced Mail)
Permanent fault. 324
Permanent replica, 298-300,483
Permission-based approach, 252
Persistence, 40
Persistent communication, 124
Persistent connection. 562
Persistent object, 446
Pessimistic logging protocol, 372
PGM (see Pragmatic General Multicast)
Physical clock, 233-236680
Physical layer, ]]8-119
Piecewise deterministic model, 370
Pingmessage, 335
Pipelining, 562
Plaintext, 389
Plan9,communication, 505-506
PlanetLab, 99-103
Platform security, 482
Playground, Java, 424
Plug-in, Browser, 549
browser, 555
Policy andmechanism, 8-9
Policy certification authority, 431
Polling model, 465
Port,89,139
Portability, 8
Position-based routing, 261
Pragmatic general multicast, 614
Primary-backup protocol, 308
Primary-based protocol, 308-311
Prime factor, 394
Primitive localobject, 450
Privacy, 4,92,412,431
Privacy enhanced mail,431
Process, 69-113
filesystem, 501
object-based system, 451-456
Web, 554-560
Process group, flat,329
hierarchical, 329
Process migration, 103
Process table, 70
Process virtual machine, 81
Program stream, 165
Protection domain, 416-418
Protocol, 117
address resolution, 183
blocking commit, 359
cache-coherence, 313-314
challenge-response, 398
client-based, 303
connectionless, 117
coordination, 553
epidemic, 170
filetransfer, 122
higher-level, 121-122INDEX
Protocol (continued)
hypertext transfer, 122,547,560
Internet, 120
invalidation, 302
layered, 116-124
lightweight directory access, 218-226
local-write, 310-311
logging, 372
lower-level, 119-120
middleware, 122-]24
Needham-Schroeder, 401
network time,240-241
one-phase commit, 355
optimistic logging, 372
pessimistic logging, 372
primary-backup, 308
primary-based, 308-311
pull-based, 303
push-based, 303
quorum-based, 311-313
real-time transport, 121
remote-write, 308-309
replicated-write, 311-313
replication, 348
server-based, 303
simple object access, 552,566
TCP,121
three-phase commit, 361-363
transport, 120-121
two-phase commit, 355-360
X,83-84
Protocol stack, 119
Protocol suite, 119
Proximity neighbor selection, 191
Proximity routing, 191
Proxy, 437,486
object, 444
Proxy cache, 571,573
Proxy gateway, 420
Public keyauthentication, 404-405
Public-key block, 500
Public-key certificate, 430
Public-key cryptosystem, 390
Publication confidentiality, 619
Publish/subscribe system, 24,35,151,591
Push-based protocol, 303Q
QoS(see Quality ofService)
Quality ofservice, 160-162
Query containment check, 581
Queue manager, 148,152
Queue name, 147
Quorum-based protocol, 311-313
Quorum certificate, 530
R
Random graph, 47
RBS(see Reference Broadcast
Synchronization)
RDF(see Resource Description
Framework)
RDN (see Relative Distinguished Name)
RDP(see Relative Delay Penalty)
Read-one. write-all, 312
Read-only state, 421
Read quorum, 312
Read-write conflict, 289
Read-your-writes consistency, 294-295
Real-time transport protocol, 121
Receiver-based logging, 365
Receiver-initiated mobility, 106
Recommender, 27
Recovery, failure, 363-373
Recovery line,367
Recovery-oriented computing, 372
Recursi velookup, 191
Recursi vename resolution, 207
Redirect, 564
Reduced interfaces forsecure
system component, 388
Reference, Globe object, 469-470
object, 457-458
Reference broadcast synchronization, 242
Reference clock, 241
Reference monitor, 415-4L8, 424
Referentially decoupled architecture, 35
Reflection attack, 399
Reincarnation, 342INDEX 681
Relative delay penalty, 168
Relative distinguished name, 219
Relative pathname, 196
Relay, 148
Reliability, 322
Reliable causally-ordered multicast, 352
Reliable communication, 336-355
client-server, 336-342
group, 343-355
Reliable FIFO-ordered multicast, 351
Reliable group communication, 343-355
Reliable multicast, 343-345
Reliable unordered multicast, 351
Relocation transparency, 5
Remote access model, 492
Remote fileservice, 492
Remote method invocation, 24,458
Java,461-463
Remote object, 445
Remote object security, 486-487
Remote procedure call,24,125-140,337,
342,387,502-505
call-by-copy/restore, 127
call-by-reference, 127
call-by-value, 127
client stub,128
failure, 337-342
failure duetoclient crash, 341-342
failure duetolostreply, 342
failure duetolostrequest, 338
failure duetoserver crash, 338-340
failure tolocate server, 337-338
NFS, 502-503
parameter marshaling, 130
secure, 533-535
server stub,128
Remote procedure call2,503-505
Remote-write protocol, 308-309
Removed node, 171
Rendezvous daemon, 596
Rendezvous node. 169
Repair management domain, 66
Replica, client-initiated. 30I
server-initiated. 299-301
Replica certificate, 483
Replica key.482682 INDEX
Replica location service, 529
Replica management 296-305
Replica-server placement 261,296-298, 574
Replicated component, 14
Replicated-write protocol, 311-313
Replication, filesystem, 519-529
object-based systems, 472-477
peer-to-peer, 526-529
server-side, 524-526
Web, 570-582
Webapplications, 579-582
Replication framework, 474-475
Replication invocation, 475-477
Replication manager, CORBA, 478
Replication subobject, Globe, 450
Replication transparency, 6
Request broker, object, 468
Request-level interceptor. 56
Request line,563
Request-reply behavior, 37
Resilence, process, 328-336
Resource description framework, 218
Resource proxy, 382
Resource record, 210
Resource virtualization, 79
Response failure, 325
Reverse access control, 482
Revoking acertificate, 432
RISSC (see Reduced Interfaces for
Secure System Component)
Rivest, Shamir, Adleman
algorithm, 394-395
RMI(see Remote Method Invocation)
Role, 384.418
Rollback, 367,369
Root, 167.196-197,199,206,208-210,510
Rootfilehandle, 509-510
Rootnode. 192
Rootserver, 182
Round, gossip-based, 171
Round-robin DNS, 560
Router, CORBA, 466
Routing, 120
Routing filter, 602
ROW A(see Read-One, Write-All)
RPC(see Remote Procedure Call)RPC-style exchange, 566
RPC2 (see Remote Procedure Ca1J~)
RSA(see Rivest, Shamir, Adleman nlgorithmj j,
RTP(see Real-Time Transport Prolllcol)
Rumor spreading. 171
Runtime system, Ice,454-456
s
S-box,393
Safety, 323
Sandbox, Java,422
Scalability, 9-16
geographical, 15
Scalable multicasting. 345
Scalable reliable multicasting, 345
Scaling techniques, 12-15
Scheduler activation, 75
Scheme, 568
Script, server-side, 550-551
SCS(see SliceCreation Service)
Secret sharing, 409
Secure channel, 397-413
Secure filesystem, 536
Secure filesystem client, 536
Secure filesystem server, 537
Secure filesystem useragent, 536
Secure group communication, 408-4 J1
Secure group management, 433-434
Secure method invocation, 482,484-485
Secure NFS, 534 '
Secure object binding, 482
Secure replicated servers, 409-41 1
Secure RPC, 533-535
Secure socket layer, 386,584
Secure storage, 540-541
Security, 377-439
access control, 413-428
cryptographic, 389-396
filesystem, 532-541
Globe, 482-485
Globus, 380-384
introduction, 378-396
Java, 420-425Security tcontinuedi
NFS, 533-536
object-based systems, 481-487
peer-to-peer, 539-540
remote object, 486-487
secure channels, 396-413
Web, 584-585
Security attacks, 389-391
Security design issues, 384-389
Security management, 428-439
Security manager, Java,423
Security mechanism, 379
Security policy, 379
Security service, 136
Security threats, 378-380
Selective revealing, 422
Self-certifying filesystem, 536-539
Self-certifying name, 484
Self-certifying pathname, 537
Self-managing system, 59-66
Self-star system, 59
Semantic overlay network, 50,225
Semantic proximity 50,226
Semantics, filesharing, 513-516
Semantics subobject, Globe, 450
Sender-based logging, 365
Sender-initiated, 106
Sensor network, 28-30
Sequencer, 311
Sequential consistency, 281-288
Serializability, 22
Serializable parameter marshaling, 462
Servant, 454
Servent,44
Server, 37,88-103
Apache, 556-558
multithreaded, 77-79
object, 451-454
Web, 556-560
Server-based protocol, 303
Server cluster, 92-98
Server interface, 66
Server port,435
Server replication, Coda, 524-526
Server-side replication, 524-526
Server-side script, 550-551INDEX 683
Server stub,128-129
Service, Web, 546
Service-oriented architecture, 20
Service provider, 101
Servlet, 551
Session, 316
Session key,398,407-408
Session semantics, 515
Session state, 91
SFS(see Secure FileSystem)
Shadow, 411
Share reservation, 517
Shared dataspace, 36
Shared-nothing architecture, 298
Shared objects, Globe, 448-451
Sideeffect, RPC2, 503
Simple object access protocol, 552,566-567
envelop, 566
Simple stream, 159
Single-processor system, 2
Single sign-on, 413
Single-system image, 18
Skeleton, object, 445
Skew, clock, 239
Slice, 100
Sliceauthority, 101
Slicecreation service, 101
Small-world effect, 226
SMDS (see Switched Multi-Megabit DataService)
SOAP (see Simple Object Access Protocol)
Socket, 141-142
Berkeley, 141-142
Softstate, 91
Software architecture, 33
Solar day,234
Solar second, 234
Source queue, 147
Squid, 556
SRM (see Scalable Reliable Multicasting)
SSL(see Secure Socket Layer)
SSPchain, 184-186
Stable message, 371
Stable storage, 365-366
Stack introspection, 425-426
Stacked address, 469
Starvation, 252684
State, object 4.:J.4
Statemachine replication, 248
Statetransition failure, 325
Stateful server. 91
Stateful session bean, 448
Stateless server. 90
Stateless session bean, 448
Statelessness, 66
Static invocation, 459
Status line,563
Stratum- 1server, 241
Stream-oriented communication, 157-166
Stream synchronization, 163-166
Stretch, 168
Striping, 496-497
Strong collision resistance, 391
Strong consistency, 15,274
Strong mobility, 106
Structured naming, 195-217
Stubgeneration, 132-134
Subject, 414,595
Subscription, 592
Subscription confidentiality, 619
Substream, 159
Superpeer, 50-52, 269
Superserver, 89
Susceptible node, 171
Switch-tree, 169
Switched multi-megabit dataservice, 386
Sybil attack, 539
Symbolic link,199
Symmetric cryptosystem, 390
Synchronization, 125,163-164,
231-271, 286-287
election algorithms, 263-270
filesystem, 513-519
logical clock, 244-252
mutual exclusion, 252-260
object, 470-472
physical clock, 232-244
stream, 163-166
Web, 569-570
Synchronization variable, 286
Synchronized object, 471
Synchronous communication, 11,125
Synchronous system, 332INDEX
Synchronous transmission mode. 159
System architecture, 33,36-54
System call,81
T
Tag,562
Tagged profile, 468
TAl(see International Atomic Time)
TCB(see Trusted Computing Base)
TCP(see Transmission Control prolocol)
TCPhandoff, 94,559
Template, 594
TGS(see Ticket Granting Service)
Thinclient, 42,84-86
Thin-client approach, 83
THINC,86
Thread, 70-79
distributed system, 75-79
implementation, 73-75
worker, 77-78
Thread context, 71
Three-phase commit protocol, 361
Three-tiered architecture, 42
Threshold scheme, 411
TIBnRendezvous,595
Ticket, 401,412
Ticket granting service, 412
Time server, 240-242
Timer, 233
Timing failure, 325
TLS(see Transport Layer Security)
TLSrecord protocol layer, 584
TMR (see Triple Modular Redundancy)
Token, 252,258
Token-based solution, 252
Topology-based assignment ofnode identifier, ~
Topology management, network, 49-50
Total-ordered delivery, 352
Totally-ordered multicast, 247-248
TPmonitor, 23
Tracker, 53
Transaction, 21
Transaction processing monitor, 23Transaction processing system, 20-23
Transactional RPC, 21
Transient communication, 125
Transient fault, 323
Transient object, 446
Transit ofthesun,234
Transition policy, 613
Transmission control protocol, 121
Transmission mode, asynchronous, 158
isosynchronous, 158
synchronous, 158
Transparency, 4
access, 5
concurrency, 6
degree, 6-7
distribution, 4-7
failure, 6
location, 5
migration, 5
relocation, 5
replication, 6
Transport layer, 118,120-121
Transport-layer security, 584
Transport-layer switch, 94
Treecost,168
Triangle inequality, 262
Triple DES, 394
Triple modular redundancy, 327-328
Trust model, 431
Trusted computing base,387
Tuple, 591
Tuple instance, 594
Two-phase commit protocol, 355-360
Two-tiered architecture, 41
u
UDDI (see Universal Directory
andDiscovery Integration)
UDP(see Universal Datagram Protocol)
Unattached resource, 108
Unicasting, 305
Uniform resource identifier, 567INDEX 685
Uniform resource locator, 546,567
Uniform resource name, 568.
Universal coordinated time,236
Universal description, discovery
andintegration, 551-552
Universal directory anddiscovery
integration, 222
Universal plugandplay,26
UNIX filesharing semantics, 514
Upload/download model, 492
UPnP (see Universal PlugaNdPlay)
URI(see Uniform Resource Identifier)
URL (see Uniform Resource Locator)
URN (see Uniform Resource Name)
Usercertificate, 482
Userkey,482
Userproxy, 382
UTC(see Universal Coordinated Time)
v
Vector clock, 248-252
Vertical distribution, 43
Vertical fragmentation, 43
VFS(see Virtual FileSystem)
View, 307
View change, 349
Virtual fileSystem, 493
Virtual ghost, 578
Virtual machine, 80-82
Java,422
Virtual machine monitor, 82
Virtual organization, 18-19
Virtual synchrony, 349-350
implementation, 352-355
Virtualization, 79-82
VMM (see Virtual Machine Monitor)
Volume, Coda, 524
Volume storage group, Coda, 524
Voting, 311
Vserver,99
VSG(see Volume Storage Group)686 INDEX
w
WAN(see Wide-Area Network)
Weak collision resistance, 391
Weak consistency. 288
Weak mobility, 106
Webapplication replication, 579-582
Webbrowser, 547,554
Webcaching, 571-573
Webclient. 554-556
Webcommunication, 560-567
Webconsistency, 570-582
Webdistributed authoring and
versioning, 570
Webdocument, 547-549
Webfaulttolerance, 582-584
Webnaming, 567-569
Webproxy, 555
Webreplication, 570-582
Websecurity, 584-585
Webserver, 556-560
Webserver cluster, 558-560
Webservice, 546,551-554
Webservices composition, 552-554
Webservices coordination, 552-4
Webservices definition language, 552
Websynchronization, 569-570
WebDAV,570
WebSphere MQ,152-157
Wide-area network, 2
Window manager, 84
Window size,576
Wireless clock synchronization, 242-244
Wireless election algorithm, 267-269
Worker thread, 77-78
Wrapper, object, 453-454
Write-back cache, 314
Write quorum, 312
Write-through cache, 314
Write-write conflict, 289
Writes-follow-read, 295
WSDL (seeWebServices Definition Language)
WWW(seeWorld Wide Web)x
Xkernel, 83
Xprotocol, 83-84
Xwindow system, 83-84, 87
XlOpen transport interface, 141
XML (seeExtensible Markup Language)
XTI(seeXlOpen Transport Interface)
z
Zipf-like distribution, 216
Zone, 14,203
Zonetransfer, 212